[
  {
    "id": "arXiv:2210.04894",
    "title": "A Computationally Efficient, Robust Methodology for Evaluating Chemical  Timescales with Detailed Chemical Kinetics",
    "abstract": "Turbulent reacting flows occur in a variety of engineering applications such as chemical reactors and power generating equipment (gas turbines and internal combustion engines). Turbulent reacting flows are characterized by two main timescales, namely, flow timescales and chemical (or reaction) timescales. Understanding the relative timescales of flow and reaction kinetics plays an important role, not only in the choice of models required for the accurate simulation of these devices but also their design/optimization studies. There are several definitions of chemical timescales, which can largely be classified as algebraic or eigenvalue-based methods. The computational complexity (and hence cost) depends on the method of evaluation of the chemical timescales and size of the chemical reaction mechanism. The computational cost and robustness of the methodology of evaluating the reaction times scales is an important consideration in large-scale multi-dimensional simulations using detailed chemical mechanisms. In this work, we present a computational efficient and robust methodology to evaluate chemical timescales based on the algebraic method. Comparison of this novel methodology with other traditional methods is presented for a range of fuel-air mixtures, pressures and temperatures conditions. Additionally, chemical timescales are also presented for fuel-air mixtures at conditions of relevance to power generating equipment. The proposed method showed the same temporal characteristics as the eigenvalue-based methods with no additional computational cost for all the 1cases studied. The proposed method thus has the potential for use with multidimensional turbulent reacting flow simulations which require the computation of the Damkohler number. ",
    "url": "https://arxiv.org/abs/2210.04894",
    "authors": [
      "S. M. Aithal"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.04897",
    "title": "Robust Adaptive Neural Network Control of Time-Varying State Constrained  Nonlinear Systems",
    "abstract": "This paper deals with the tracking control problem for a very simple class of unknown nonlinear systems. In this paper, we presents a design strategy for tracking control of time-varying state constrained nonlinear systems in an adaptive framework. The controller is designed using the backstepping method. While designing it, Barrier Lyapunov Function (BLF) is used so that the state variables do not contravene its constraints. In order to cope with the unknown dynamics of the system, an online approximator is designed using a neural network with a novel adaptive law for its weight update. To make the controller robust and computationally inexpensive, a disturbance observer is proposed to cope with the disturbance along with neural network approximation error and the time derivative of virtual control input. The effectiveness of the proposed approach is demonstrated through a simulation study. ",
    "url": "https://arxiv.org/abs/2210.04897",
    "authors": [
      "Pankaj Kumar Mishra",
      "Nishchal K Verma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.04932",
    "title": "NeRF2Real: Sim2real Transfer of Vision-guided Bipedal Motion Skills  using Neural Radiance Fields",
    "abstract": "We present a system for applying sim2real approaches to \"in the wild\" scenes with realistic visuals, and to policies which rely on active perception using RGB cameras. Given a short video of a static scene collected using a generic phone, we learn the scene's contact geometry and a function for novel view synthesis using a Neural Radiance Field (NeRF). We augment the NeRF rendering of the static scene by overlaying the rendering of other dynamic objects (e.g. the robot's own body, a ball). A simulation is then created using the rendering engine in a physics simulator which computes contact dynamics from the static scene geometry (estimated from the NeRF volume density) and the dynamic objects' geometry and physical properties (assumed known). We demonstrate that we can use this simulation to learn vision-based whole body navigation and ball pushing policies for a 20 degrees of freedom humanoid robot with an actuated head-mounted RGB camera, and we successfully transfer these policies to a real robot. Project video is available at https://sites.google.com/view/nerf2real/home ",
    "url": "https://arxiv.org/abs/2210.04932",
    "authors": [
      "Arunkumar Byravan",
      "Jan Humplik",
      "Leonard Hasenclever",
      "Arthur Brussee",
      "Francesco Nori",
      "Tuomas Haarnoja",
      "Ben Moran",
      "Steven Bohez",
      "Fereshteh Sadeghi",
      "Bojan Vujatovic",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04954",
    "title": "Using Immersive Virtual Reality to Enhance Social Interaction among  Older Adults: A Multi-site Study",
    "abstract": "Research examining older adults interactions with Virtual Reality (VR) and the impact of social VR experiences on outcomes such as social engagement has been limited, especially among older adults. This multi-site pilot study evaluated the feasibility and acceptability of a novel social virtual reality (VR) program that paired older adults from different geographic locations (New York City, Tallahassee, and Ithaca, N.Y) who engaged in virtual travel and productive engagement activities together. The sample included 36 individuals aged 60 and older, 25 percent of whom had cognitive impairment (CI). Older adults with and without CI reported high levels of engagement in the VR environment and perceived the social VR program to be enjoyable and usable. Perceived Spatial Presence was a central driver of the positive outcomes. Most also indicated a willingness to reconnect with their VR partner in the future. The data also identified important areas for improvement in the program, such as the use of more realistic and responsive avatars, controllers with larger controls, and more time for training. Overall, these findings suggest that VR social applications may foster social engagement among older adults. ",
    "url": "https://arxiv.org/abs/2210.04954",
    "authors": [
      "Saleh Kalantari",
      "Tong Bill Xu",
      "Armin Mostafavi",
      "Andrew Dilanchian",
      "Benjamin Kim",
      "Walter Boot",
      "Sara Czaja"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.04958",
    "title": "Mining Causality from Continuous-time Dynamics Models: An Application to  Tsunami Forecasting",
    "abstract": "Continuous-time dynamics models, such as neural ordinary differential equations, have enabled the modeling of underlying dynamics in time-series data and accurate forecasting. However, parameterization of dynamics using a neural network makes it difficult for humans to identify causal structures in the data. In consequence, this opaqueness hinders the use of these models in the domains where capturing causal relationships carries the same importance as accurate predictions, e.g., tsunami forecasting. In this paper, we address this challenge by proposing a mechanism for mining causal structures from continuous-time models. We train models to capture the causal structure by enforcing sparsity in the weights of the input layers of the dynamics models. We first verify the effectiveness of our method in the scenario where the exact causal-structures of time-series are known as a priori. We next apply our method to a real-world problem, namely tsunami forecasting, where the exact causal-structures are difficult to characterize. Experimental results show that the proposed method is effective in learning physically-consistent causal relationships while achieving high forecasting accuracy. ",
    "url": "https://arxiv.org/abs/2210.04958",
    "authors": [
      "Fan Wu",
      "Sanghyun Hong",
      "Dobsub Rim",
      "Noseong Park",
      "Kookjin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.04959",
    "title": "Characterization of anomalous diffusion through convolutional  transformers",
    "abstract": "The results of the Anomalous Diffusion Challenge (AnDi Challenge) have shown that machine learning methods can outperform classical statistical methodology at the characterization of anomalous diffusion in both the inference of the anomalous diffusion exponent alpha associated with each trajectory (Task 1), and the determination of the underlying diffusive regime which produced such trajectories (Task 2). Furthermore, of the five teams that finished in the top three across both tasks of the AnDi challenge, three of those teams used recurrent neural networks (RNNs). While RNNs, like the long short-term memory (LSTM) network, are effective at learning long-term dependencies in sequential data, their key disadvantage is that they must be trained sequentially. In order to facilitate training with larger data sets, by training in parallel, we propose a new transformer based neural network architecture for the characterization of anomalous diffusion. Our new architecture, the Convolutional Transformer (ConvTransformer) uses a bi-layered convolutional neural network to extract features from our diffusive trajectories that can be thought of as being words in a sentence. These features are then fed to two transformer encoding blocks that perform either regression or classification. To our knowledge, this is the first time transformers have been used for characterizing anomalous diffusion. Moreover, this may be the first time that a transformer encoding block has been used with a convolutional neural network and without the need for a transformer decoding block or positional encoding. Apart from being able to train in parallel, we show that the ConvTransformer is able to outperform the previous state of the art at determining the underlying diffusive regime in short trajectories (length 10-50 steps), which are the most important for experimental researchers. ",
    "url": "https://arxiv.org/abs/2210.04959",
    "authors": [
      "Nicol\u00e1s Firbas",
      "\u00d2scar Garibo-i-Orts",
      "Miguel \u00c1ngel Garcia-March",
      "J. Alberto Conejero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.04962",
    "title": "Domain-Specific Word Embeddings with Structure Prediction",
    "abstract": "Complementary to finding good general word embeddings, an important question for representation learning is to find dynamic word embeddings, e.g., across time or domain. Current methods do not offer a way to use or predict information on structure between sub-corpora, time or domain and dynamic embeddings can only be compared after post-alignment. We propose novel word embedding methods that provide general word representations for the whole corpus, domain-specific representations for each sub-corpus, sub-corpus structure, and embedding alignment simultaneously. We present an empirical evaluation on New York Times articles and two English Wikipedia datasets with articles on science and philosophy. Our method, called Word2Vec with Structure Prediction (W2VPred), provides better performance than baselines in terms of the general analogy tests, domain-specific analogy tests, and multiple specific word embedding evaluations as well as structure prediction performance when no structure is given a priori. As a use case in the field of Digital Humanities we demonstrate how to raise novel research questions for high literature from the German Text Archive. ",
    "url": "https://arxiv.org/abs/2210.04962",
    "authors": [
      "Stephanie Brandl",
      "David Lassner",
      "Anne Baillot",
      "Shinichi Nakajima"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04977",
    "title": "Domain-guided data augmentation for deep learning on medical imaging",
    "abstract": "While domain-specific data augmentation can be useful in training neural networks for medical imaging tasks, such techniques have not been widely used to date. Here, we test whether domain-specific data augmentation is useful for medical imaging using a well-benchmarked task: view classification on fetal ultrasound FETAL-125 and OB-125 datasets. We found that using a context-preserving cut-paste strategy, we could create valid training data as measured by performance of the resulting trained model on the benchmark test dataset. When used in an online fashion, models trained on this data performed similarly to those trained using traditional data augmentation (FETAL-125 F-score 85.33+/-0.24 vs 86.89+/-0.60, p-value 0.0139; OB-125 F-score 74.60+/-0.11 vs 72.43+/-0.62, p-value 0.0039). Furthermore, the ability to perform augmentations during training time, as well as the ability to apply chosen augmentations equally across data classes, are important considerations in designing a bespoke data augmentation. Finally, we provide open-source code to facilitate running bespoke data augmentations in an online fashion. Taken together, this work expands the ability to design and apply domain-guided data augmentations for medical imaging tasks. ",
    "url": "https://arxiv.org/abs/2210.04977",
    "authors": [
      "Chinmayee Athalye",
      "Rima Arnaout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04979",
    "title": "Label-free segmentation from cardiac ultrasound using self-supervised  learning",
    "abstract": "Background: Segmentation and measurement of cardiac chambers is critical in echocardiography but is also laborious and poorly reproducible. Neural networks can assist, but supervised approaches require the same laborious manual annotations, while unsupervised approaches have fared poorly in ultrasound to date. Objectives: We built a pipeline for self-supervised (no manual labels required) segmentation of cardiac chambers, combining computer vision, clinical domain knowledge, and deep learning. Methods: We trained on 450 echocardiograms (145,000 images) and tested on 8,393 echocardiograms (4,476,266 images; mean age 61 years, 51% female), using the resulting segmentations to calculate structural and functional measurements. We also tested our pipeline against external images from an additional 10,030 patients (20,060 images) with available manual tracings of the left ventricle. Results: r2 between clinically measured and pipeline-predicted measurements were similar to reported inter-clinician variation for LVESV and LVEDV (pipeline vs. clinical r2= 0.74 and r2=0.65, respectively), LVEF and LV mass (r2= 0.46 and r2=0.54), left and right atrium volumes (r2=0.7 and r2=0.6), and right ventricle area (r2=0.47). When binarized into normal vs. abnormal categories, average accuracy was 0.81 (range 0.71-0.95). A subset of the test echocardiograms (n=553) had corresponding cardiac MRI; correlation between pipeline and CMR measurements was similar to that between clinical echocardiogram and CMR. Finally, in the external dataset, our pipeline accurately segments the left ventricle with an average Dice score of 0.83 (95% CI 0.83). Conclusions: Our results demonstrate a human-label-free, valid, and scalable method for segmentation from ultrasound, a noisy but globally important imaging modality. ",
    "url": "https://arxiv.org/abs/2210.04979",
    "authors": [
      "Danielle L. Ferreira",
      "Zaynaf Salaymang",
      "Rima Arnaout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04989",
    "title": "On Designing Day Ahead and Same Day Ridership Level Prediction Models  for City-Scale Transit Networks Using Noisy APC Data",
    "abstract": "The ability to accurately predict public transit ridership demand benefits passengers and transit agencies. Agencies will be able to reallocate buses to handle under or over-utilized bus routes, improving resource utilization, and passengers will be able to adjust and plan their schedules to avoid overcrowded buses and maintain a certain level of comfort. However, accurately predicting occupancy is a non-trivial task. Various reasons such as heterogeneity, evolving ridership patterns, exogenous events like weather, and other stochastic variables, make the task much more challenging. With the progress of big data, transit authorities now have access to real-time passenger occupancy information for their vehicles. The amount of data generated is staggering. While there is no shortage in data, it must still be cleaned, processed, augmented, and merged before any useful information can be generated. In this paper, we propose the use and fusion of data from multiple sources, cleaned, processed, and merged together, for use in training machine learning models to predict transit ridership. We use data that spans a 2-year period (2020-2022) incorporating transit, weather, traffic, and calendar data. The resulting data, which equates to 17 million observations, is used to train separate models for the trip and stop level prediction. We evaluate our approach on real-world transit data provided by the public transit agency of Nashville, TN. We demonstrate that the trip level model based on Xgboost and the stop level model based on LSTM outperform the baseline statistical model across the entire transit service day. ",
    "url": "https://arxiv.org/abs/2210.04989",
    "authors": [
      "Jose Paolo Talusan",
      "Ayan Mukhopadhyay",
      "Dan Freudberg",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04996",
    "title": "Graph2Vid: Flow graph to Video Grounding forWeakly-supervised Multi-Step  Localization",
    "abstract": "In this work, we consider the problem of weakly-supervised multi-step localization in instructional videos. An established approach to this problem is to rely on a given list of steps. However, in reality, there is often more than one way to execute a procedure successfully, by following the set of steps in slightly varying orders. Thus, for successful localization in a given video, recent works require the actual order of procedure steps in the video, to be provided by human annotators at both training and test times. Instead, here, we only rely on generic procedural text that is not tied to a specific video. We represent the various ways to complete the procedure by transforming the list of instructions into a procedure flow graph which captures the partial order of steps. Using the flow graphs reduces both training and test time annotation requirements. To this end, we introduce the new problem of flow graph to video grounding. In this setup, we seek the optimal step ordering consistent with the procedure flow graph and a given video. To solve this problem, we propose a new algorithm - Graph2Vid - that infers the actual ordering of steps in the video and simultaneously localizes them. To show the advantage of our proposed formulation, we extend the CrossTask dataset with procedure flow graph information. Our experiments show that Graph2Vid is both more efficient than the baselines and yields strong step localization results, without the need for step order annotation. ",
    "url": "https://arxiv.org/abs/2210.04996",
    "authors": [
      "Nikita Dvornik",
      "Isma Hadji",
      "Hai Pham",
      "Dhaivat Bhatt",
      "Brais Martinez",
      "Afsaneh Fazly",
      "Allan D. Jepson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05001",
    "title": "Social Media Personal Event Notifier Using NLP and Machine Learning",
    "abstract": "Social media apps have become very promising and omnipresent in daily life. Most social media apps are used to deliver vital information to those nearby and far away. As our lives become more hectic, many of us strive to limit our usage of social media apps because they are too addictive, and the majority of us have gotten preoccupied with our daily lives. Because of this, we frequently overlook crucial information, such as invitations to weddings, interviews, birthday parties, etc., or find ourselves unable to attend the event. In most cases, this happens because users are more likely to discover the invitation or information only before the event, giving them little time to prepare. To solve this issue, in this study, we created a system that will collect social media chat and filter it using Natural Language Processing (NLP) methods like Tokenization, Stop Words Removal, Lemmatization, Segmentation, and Named Entity Recognition (NER). Also, Machine Learning Algorithms such as K-Nearest Neighbor (KNN) Algorithm are implemented to prioritize the received invitation and to sort the level of priority. Finally, a customized notification will be delivered to the users where they acknowledge the upcoming event. So, the chances of missing the event are less or can be planned. ",
    "url": "https://arxiv.org/abs/2210.05001",
    "authors": [
      "Pavithiran G",
      "Sharan Padmanabhan",
      "Ashwin Kumar BR",
      "Vetriselvi A"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05008",
    "title": "Fast Hierarchical Learning for Few-Shot Object Detection",
    "abstract": "Transfer learning based approaches have recently achieved promising results on the few-shot detection task. These approaches however suffer from ``catastrophic forgetting'' issue due to finetuning of base detector, leading to sub-optimal performance on the base classes. Furthermore, the slow convergence rate of stochastic gradient descent (SGD) results in high latency and consequently restricts real-time applications. We tackle the aforementioned issues in this work. We pose few-shot detection as a hierarchical learning problem, where the novel classes are treated as the child classes of existing base classes and the background class. The detection heads for the novel classes are then trained using a specialized optimization strategy, leading to significantly lower training times compared to SGD. Our approach obtains competitive novel class performance on few-shot MS-COCO benchmark, while completely retaining the performance of the initial model on the base classes. We further demonstrate the application of our approach to a new class-refined few-shot detection task. ",
    "url": "https://arxiv.org/abs/2210.05008",
    "authors": [
      "Yihang She",
      "Goutam Bhat",
      "Martin Danelljan",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05018",
    "title": "LidarNAS: Unifying and Searching Neural Architectures for 3D Point  Clouds",
    "abstract": "Developing neural models that accurately understand objects in 3D point clouds is essential for the success of robotics and autonomous driving. However, arguably due to the higher-dimensional nature of the data (as compared to images), existing neural architectures exhibit a large variety in their designs, including but not limited to the views considered, the format of the neural features, and the neural operations used. Lack of a unified framework and interpretation makes it hard to put these designs in perspective, as well as systematically explore new ones. In this paper, we begin by proposing a unified framework of such, with the key idea being factorizing the neural networks into a series of view transforms and neural layers. We demonstrate that this modular framework can reproduce a variety of existing works while allowing a fair comparison of backbone designs. Then, we show how this framework can easily materialize into a concrete neural architecture search (NAS) space, allowing a principled NAS-for-3D exploration. In performing evolutionary NAS on the 3D object detection task on the Waymo Open Dataset, not only do we outperform the state-of-the-art models, but also report the interesting finding that NAS tends to discover the same macro-level architecture concept for both the vehicle and pedestrian classes. ",
    "url": "https://arxiv.org/abs/2210.05018",
    "authors": [
      "Chenxi Liu",
      "Zhaoqi Leng",
      "Pei Sun",
      "Shuyang Cheng",
      "Charles R. Qi",
      "Yin Zhou",
      "Mingxing Tan",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05033",
    "title": "Multilingual Representation Distillation with Contrastive Learning",
    "abstract": "Multilingual sentence representations from large models can encode semantic information from two or more languages and can be used for different cross-lingual information retrieval tasks. In this paper, we integrate contrastive learning into multilingual representation distillation and use it for quality estimation of parallel sentences (find semantically similar sentences that can be used as translations of each other). We validate our approach with multilingual similarity search and corpus filtering tasks. Experiments across different low-resource languages show that our method significantly outperforms previous sentence encoders such as LASER, LASER3, and LaBSE. ",
    "url": "https://arxiv.org/abs/2210.05033",
    "authors": [
      "Weiting Tan",
      "Kevin Heffernan",
      "Holger Schwenk",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05047",
    "title": "Improving Retrieval Augmented Neural Machine Translation by Controlling  Source and Fuzzy-Match Interactions",
    "abstract": "We explore zero-shot adaptation, where a general-domain model has access to customer or domain specific parallel data at inference time, but not during training. We build on the idea of Retrieval Augmented Translation (RAT) where top-k in-domain fuzzy matches are found for the source sentence, and target-language translations of those fuzzy-matched sentences are provided to the translation model at inference time. We propose a novel architecture to control interactions between a source sentence and the top-k fuzzy target-language matches, and compare it to architectures from prior work. We conduct experiments in two language pairs (En-De and En-Fr) by training models on WMT data and testing them with five and seven multi-domain datasets, respectively. Our approach consistently outperforms the alternative architectures, improving BLEU across language pair, domain, and number k of fuzzy matches. ",
    "url": "https://arxiv.org/abs/2210.05047",
    "authors": [
      "Cuong Hoang",
      "Devendra Sachan",
      "Prashant Mathur",
      "Brian Thompson",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05052",
    "title": "Risk Automatic Prediction for Social Economy Companies using Camels",
    "abstract": "Governments have to supervise and inspect social economy enterprises (SEEs). However, inspecting all SEEs is not possible due to the large number of SEEs and the low number of inspectors in general. We proposed a prediction model based on a machine learning approach. The method was trained with the random forest algorithm with historical data provided by each SEE. Three consecutive periods of data were concatenated. The proposed method uses these periods as input data and predicts the risk of each SEE in the fourth period. The model achieved 76\\% overall accuracy. In addition, it obtained good accuracy in predicting the high risk of a SEE. We found that the legal nature and the variation of the past-due portfolio are good predictors of the future risk of a SEE. Thus, the risk of a SEE in a future period can be predicted by a supervised machine learning method. Predicting the high risk of a SEE improves the daily work of each inspector by focusing only on high-risk SEEs. ",
    "url": "https://arxiv.org/abs/2210.05052",
    "authors": [
      "Joseph Gallego-Mejia",
      "Daniela Martin-Vega",
      "Fabio Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.05059",
    "title": "Improving Robustness of Retrieval Augmented Translation via Shuffling of  Suggestions",
    "abstract": "Several recent studies have reported dramatic performance improvements in neural machine translation (NMT) by augmenting translation at inference time with fuzzy-matches retrieved from a translation memory (TM). However, these studies all operate under the assumption that the TMs available at test time are highly relevant to the testset. We demonstrate that for existing retrieval augmented translation methods, using a TM with a domain mismatch to the test set can result in substantially worse performance compared to not using a TM at all. We propose a simple method to expose fuzzy-match NMT systems during training and show that it results in a system that is much more tolerant (regaining up to 5.8 BLEU) to inference with TMs with domain mismatch. Also, the model is still competitive to the baseline when fed with suggestions from relevant TMs. ",
    "url": "https://arxiv.org/abs/2210.05059",
    "authors": [
      "Cuong Hoang",
      "Devendra Sachan",
      "Prashant Mathur",
      "Brian Thompson",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05061",
    "title": "InQMAD: Incremental Quantum Measurement Anomaly Detection",
    "abstract": "Streaming anomaly detection refers to the problem of detecting anomalous data samples in streams of data. This problem poses challenges that classical and deep anomaly detection methods are not designed to cope with, such as conceptual drift and continuous learning. State-of-the-art flow anomaly detection methods rely on fixed memory using hash functions or nearest neighbors that may not be able to constrain high-frequency values as in a moving average or remove seamless outliers and cannot be trained in an end-to-end deep learning architecture. We present a new incremental anomaly detection method that performs continuous density estimation based on random Fourier features and the mechanism of quantum measurements and density matrices that can be viewed as an exponential moving average density. It can process potentially endless data and its update complexity is constant $O(1)$. A systematic evaluation against 12 state-of-the-art streaming anomaly detection algorithms using 12 streaming datasets is presented. ",
    "url": "https://arxiv.org/abs/2210.05061",
    "authors": [
      "Joseph Gallego-Mejia",
      "Oscar Bustos-Brinez",
      "Fabio Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05076",
    "title": "ConchShell: A Generative Adversarial Networks that Turns Pictures into  Piano Music",
    "abstract": "We present ConchShell, a multi-modal generative adversarial framework that takes pictures as input to the network and generates piano music samples that match the picture context. Inspired by I3D, we introduce a novel image feature representation method: time-convolutional neural network (TCNN), which is used to forge features for images in the temporal dimension. Although our image data consists of only six categories, our proposed framework will be innovative and commercially meaningful. The project will provide technical ideas for work such as 3D game voice overs, short-video soundtracks, and real-time generation of metaverse background music.We have also released a new dataset, the Beach-Ocean-Piano Dataset (BOPD) 1, which contains more than 3,000 images and more than 1,500 piano pieces. This dataset will support multimodal image-to-music research. ",
    "url": "https://arxiv.org/abs/2210.05076",
    "authors": [
      "Wanpeng Fan",
      "Yuanzhi Su",
      "Yuxin Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.05083",
    "title": "Convergence of Bi-Virus Epidemic Models with Non-Linear Rates on  Networks -- A Monotone Dynamical Systems Approach",
    "abstract": "We study convergence properties of competing epidemic models of the Susceptible-Infected-Susceptible (SIS) type. The SIS epidemic model has seen widespread popularity in modelling the spreading dynamics of contagions such as viruses, infectious diseases, or even rumors/opinions over contact networks (graphs).We analyze the case of two such viruses spreading on overlaid graphs, with non-linear rates of infection spread and recovery. We call this the non-linear bi-virus model and, building upon recent results, obtain precise conditions for global convergence of the solutions to a trichotomy of possible outcomes: a virus-free state, a single-virus state, and to a coexistence state. Our techniques are based on the theory of monotone dynamical systems (MDS), in contrast to Lyapunov based techniques that have only seen partial success in determining convergence properties in the setting of competing epidemics. We demonstrate how the existing works have been unsuccessful in characterizing a large subset of the model parameter space for bi-virus epidemics, including all scenarios leading to coexistence of the epidemics. To the best of our knowledge, our results are the first in providing complete convergence analysis for the bi-virus system with nonlinear infection and recovery rates on general graphs. ",
    "url": "https://arxiv.org/abs/2210.05083",
    "authors": [
      "Vishwaraj Doshi",
      "Shailaja Mallick",
      "Do Young eun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.05087",
    "title": "Approximation of nearly-periodic symplectic maps via  structure-preserving neural networks",
    "abstract": "A continuous-time dynamical system with parameter $\\varepsilon$ is nearly-periodic if all its trajectories are periodic with nowhere-vanishing angular frequency as $\\varepsilon$ approaches 0. Nearly-periodic maps are discrete-time analogues of nearly-periodic systems, defined as parameter-dependent diffeomorphisms that limit to rotations along a circle action, and they admit formal $U(1)$ symmetries to all orders when the limiting rotation is non-resonant. For Hamiltonian nearly-periodic maps on exact presymplectic manifolds, the formal $U(1)$ symmetry gives rise to a discrete-time adiabatic invariant. In this paper, we construct a novel structure-preserving neural network to approximate nearly-periodic symplectic maps. This neural network architecture, which we call symplectic gyroceptron, ensures that the resulting surrogate map is nearly-periodic and symplectic, and that it gives rise to a discrete-time adiabatic invariant and a long-time stability. This new structure-preserving neural network provides a promising architecture for surrogate modeling of non-dissipative dynamical systems that automatically steps over short timescales without introducing spurious instabilities. ",
    "url": "https://arxiv.org/abs/2210.05087",
    "authors": [
      "Valentin Duruisseaux",
      "Joshua W. Burby",
      "Qi Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2210.05097",
    "title": "Repainting and Imitating Learning for Lane Detection",
    "abstract": "Current lane detection methods are struggling with the invisibility lane issue caused by heavy shadows, severe road mark degradation, and serious vehicle occlusion. As a result, discriminative lane features can be barely learned by the network despite elaborate designs due to the inherent invisibility of lanes in the wild. In this paper, we target at finding an enhanced feature space where the lane features are distinctive while maintaining a similar distribution of lanes in the wild. To achieve this, we propose a novel Repainting and Imitating Learning (RIL) framework containing a pair of teacher and student without any extra data or extra laborious labeling. Specifically, in the repainting step, an enhanced ideal virtual lane dataset is built in which only the lane regions are repainted while non-lane regions are kept unchanged, maintaining the similar distribution of lanes in the wild. The teacher model learns enhanced discriminative representation based on the virtual data and serves as the guidance for a student model to imitate. In the imitating learning step, through the scale-fusing distillation module, the student network is encouraged to generate features that mimic the teacher model both on the same scale and cross scales. Furthermore, the coupled adversarial module builds the bridge to connect not only teacher and student models but also virtual and real data, adjusting the imitating learning process dynamically. Note that our method introduces no extra time cost during inference and can be plug-and-play in various cutting-edge lane detection networks. Experimental results prove the effectiveness of the RIL framework both on CULane and TuSimple for four modern lane detection methods. The code and model will be available soon. ",
    "url": "https://arxiv.org/abs/2210.05097",
    "authors": [
      "Yue He",
      "Minyue Jiang",
      "Xiaoqing Ye",
      "Liang Du",
      "Zhikang Zou",
      "Wei Zhang",
      "Xiao Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05098",
    "title": "IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces",
    "abstract": "The ability to extract high-quality translation dictionaries from monolingual word embedding spaces depends critically on the geometric similarity of the spaces -- their degree of \"isomorphism.\" We address the root-cause of faulty cross-lingual mapping: that word embedding training resulted in the underlying spaces being non-isomorphic. We incorporate global measures of isomorphism directly into the skipgram loss function, successfully increasing the relative isomorphism of trained word embedding spaces and improving their ability to be mapped to a shared cross-lingual space. The result is improved bilingual lexicon induction in general data conditions, under domain mismatch, and with training algorithm dissimilarities. We release IsoVec at https://github.com/kellymarchisio/isovec. ",
    "url": "https://arxiv.org/abs/2210.05098",
    "authors": [
      "Kelly Marchisio",
      "Neha Verma",
      "Kevin Duh",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05102",
    "title": "COMBO: Pre-Training Representations of Binary Code Using Contrastive  Learning",
    "abstract": "Compiled software is delivered as executable binary code. Developers write source code to express the software semantics, but the compiler converts it to a binary format that the CPU can directly execute. Therefore, binary code analysis is critical to applications in reverse engineering and computer security tasks where source code is not available. However, unlike source code and natural language that contain rich semantic information, binary code is typically difficult for human engineers to understand and analyze. While existing work uses AI models to assist source code analysis, few studies have considered binary code. In this paper, we propose a COntrastive learning Model for Binary cOde Analysis, or COMBO, that incorporates source code and comment information into binary code during representation learning. Specifically, we present three components in COMBO: (1) a primary contrastive learning method for cold-start pre-training, (2) a simplex interpolation method to incorporate source code, comments, and binary code, and (3) an intermediate representation learning algorithm to provide binary code embeddings. Finally, we evaluate the effectiveness of the pre-trained representations produced by COMBO using three indicative downstream tasks relating to binary code: algorithmic functionality classification, binary code similarity, and vulnerability detection. Our experimental results show that COMBO facilitates representation learning of binary code visualized by distribution analysis, and improves the performance on all three downstream tasks by 5.45% on average compared to state-of-the-art large-scale language representation models. To the best of our knowledge, COMBO is the first language representation model that incorporates source code, binary code, and comments into contrastive code representation learning and unifies multiple tasks for binary code analysis. ",
    "url": "https://arxiv.org/abs/2210.05102",
    "authors": [
      "Yifan Zhang",
      "Chen Huang",
      "Yueke Zhang",
      "Kevin Cao",
      "Scott Thomas Andersen",
      "Huajie Shao",
      "Kevin Leach",
      "Yu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05103",
    "title": "Leveraging Artificial Intelligence on Binary Code Comprehension",
    "abstract": "Understanding binary code is an essential but complex software engineering task for reverse engineering, malware analysis, and compiler optimization. Unlike source code, binary code has limited semantic information, which makes it challenging for human comprehension. At the same time, compiling source to binary code, or transpiling among different programming languages (PLs) can provide a way to introduce external knowledge into binary comprehension. We propose to develop Artificial Intelligence (AI) models that aid human comprehension of binary code. Specifically, we propose to incorporate domain knowledge from large corpora of source code (e.g., variable names, comments) to build AI models that capture a generalizable representation of binary code. Lastly, we will investigate metrics to assess the performance of models that apply to binary code by using human studies of comprehension. ",
    "url": "https://arxiv.org/abs/2210.05103",
    "authors": [
      "Yifan Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05111",
    "title": "Deep learning model compression using network sensitivity and gradients",
    "abstract": "Deep learning model compression is an improving and important field for the edge deployment of deep learning models. Given the increasing size of the models and their corresponding power consumption, it is vital to decrease the model size and compute requirement without a significant drop in the model's performance. In this paper, we present model compression algorithms for both non-retraining and retraining conditions. In the first case where retraining of the model is not feasible due to lack of access to the original data or absence of necessary compute resources while only having access to off-the-shelf models, we propose the Bin & Quant algorithm for compression of the deep learning models using the sensitivity of the network parameters. This results in 13x compression of the speech command and control model and 7x compression of the DeepSpeech2 models. In the second case when the models can be retrained and utmost compression is required for the negligible loss in accuracy, we propose our novel gradient-weighted k-means clustering algorithm (GWK). This method uses the gradients in identifying the important weight values in a given cluster and nudges the centroid towards those values, thereby giving importance to sensitive weights. Our method effectively combines product quantization with the EWGS[1] algorithm for sub-1-bit representation of the quantized models. We test our GWK algorithm on the CIFAR10 dataset across a range of models such as ResNet20, ResNet56, MobileNetv2 and show 35x compression on quantized models for less than 2% absolute loss in accuracy compared to the floating-point models. ",
    "url": "https://arxiv.org/abs/2210.05111",
    "authors": [
      "Madhumitha Sakthi",
      "Niranjan Yadla",
      "Raj Pawate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05118",
    "title": "Boosting Adversarial Robustness From The Perspective of Effective Margin  Regularization",
    "abstract": "The adversarial vulnerability of deep neural networks (DNNs) has been actively investigated in the past several years. This paper investigates the scale-variant property of cross-entropy loss, which is the most commonly used loss function in classification tasks, and its impact on the effective margin and adversarial robustness of deep neural networks. Since the loss function is not invariant to logit scaling, increasing the effective weight norm will make the loss approach zero and its gradient vanish while the effective margin is not adequately maximized. On typical DNNs, we demonstrate that, if not properly regularized, the standard training does not learn large effective margins and leads to adversarial vulnerability. To maximize the effective margins and learn a robust DNN, we propose to regularize the effective weight norm during training. Our empirical study on feedforward DNNs demonstrates that the proposed effective margin regularization (EMR) learns large effective margins and boosts the adversarial robustness in both standard and adversarial training. On large-scale models, we show that EMR outperforms basic adversarial training, TRADES and two regularization baselines with substantial improvement. Moreover, when combined with several strong adversarial defense methods (MART and MAIL), our EMR further boosts the robustness. ",
    "url": "https://arxiv.org/abs/2210.05118",
    "authors": [
      "Ziquan Liu",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05119",
    "title": "Exploring CNN-based models for image's aesthetic score prediction with  using ensemble",
    "abstract": "In this paper, we proposed a framework of constructing two types of the automatic image aesthetics assessment models with different CNN architectures and improving the performance of the image's aesthetic score prediction by the ensemble. Moreover, the attention regions of the models to the images are extracted to analyze the consistency with the subjects in the images. The experimental results verify that the proposed method is effective for improving the AS prediction. Moreover, it is found that the AS classification models trained on XiheAA dataset seem to learn the latent photography principles, although it can't be said that they learn the aesthetic sense. ",
    "url": "https://arxiv.org/abs/2210.05119",
    "authors": [
      "Ying Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05121",
    "title": "Current injection and voltage insertion attacks against the VMG-KLJN  secure key exchanger",
    "abstract": "In this paper, the vulnerability of the Vadai, Mingesz and Gingl (VMG)- Kirchhoff-Law-Johnson-Noise (KLJN) Key Exchanger (Nature, Science Report 5 (2015) 13653) against two active attacks is demonstrated. The security vulnerability arises from the fact that the effective driving impedances are different between the HL and LH cases for the VMG-KLJN scheme; whereas for the ideal KLJN scheme they are same. Two defense schemes are shown against these attacks but each of them can protect against only one of the attack types; but not against the two attacks simultaneously. The theoretical results are confirmed by computer simulations. ",
    "url": "https://arxiv.org/abs/2210.05121",
    "authors": [
      "Shahriar Ferdous",
      "Christiana Chamon",
      "Laszlo B. Kish"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05129",
    "title": "Multi-Object Navigation with dynamically learned neural implicit  representations",
    "abstract": "Understanding and mapping a new environment are core abilities of any autonomously navigating agent. While classical robotics usually estimates maps in a stand-alone manner with SLAM variants, which maintain a topological or metric representation, end-to-end learning of navigation keeps some form of memory in a neural network. Networks are typically imbued with inductive biases, which can range from vectorial representations to birds-eye metric tensors or topological structures. In this work, we propose to structure neural networks with two neural implicit representations, which are learned dynamically during each episode and map the content of the scene: (i) the Semantic Finder predicts the position of a previously seen queried object; (ii) the Occupancy and Exploration Implicit Representation encapsulates information about explored area and obstacles, and is queried with a novel global read mechanism which directly maps from function space to a usable embedding space. Both representations are leveraged by an agent trained with Reinforcement Learning (RL) and learned online during each episode. We evaluate the agent on Multi-Object Navigation and show the high impact of using neural implicit representations as a memory source. ",
    "url": "https://arxiv.org/abs/2210.05129",
    "authors": [
      "Pierre Marza",
      "Laetitia Matignon",
      "Olivier Simonin",
      "Christian Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05130",
    "title": "ACRNet: Attention Cube Regression Network for Multi-view Real-time 3D  Human Pose Estimation in Telemedicine",
    "abstract": "Human pose estimation (HPE) for 3D skeleton reconstruction in telemedicine has long received attention. Although the development of deep learning has made HPE methods in telemedicine simpler and easier to use, addressing low accuracy and high latency remains a big challenge. In this paper, we propose a novel multi-view Attention Cube Regression Network (ACRNet), which regresses the 3D position of joints in real time by aggregating informative attention points on each cube surface. More specially, a cube whose each surface contains uniformly distributed attention points with specific coordinate values is first created to wrap the target from the main view. Then, our network regresses the 3D position of each joint by summing and averaging the coordinates of attention points on each surface after being weighted. To verify our method, we first tested ACRNet on the open-source ITOP dataset; meanwhile, we collected a new multi-view upper body movement dataset (UBM) on the trunk support trainer (TruST) to validate the capability of our model in real rehabilitation scenarios. Experimental results demonstrate the superiority of ACRNet compared with other state-of-the-art methods. We also validate the efficacy of each module in ACRNet. Furthermore, Our work analyzes the performance of ACRNet under the medical monitoring indicator. Because of the high accuracy and running speed, our model is suitable for real-time telemedicine settings. The source code is available at https://github.com/BoceHu/ACRNet ",
    "url": "https://arxiv.org/abs/2210.05130",
    "authors": [
      "Boce Hu",
      "Chenfei Zhu",
      "Xupeng Ai",
      "Sunil K. Agrawal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05135",
    "title": "X-NeRF: Explicit Neural Radiance Field for Multi-Scene 360$^{\\circ} $  Insufficient RGB-D Views",
    "abstract": "Neural Radiance Fields (NeRFs), despite their outstanding performance on novel view synthesis, often need dense input views. Many papers train one model for each scene respectively and few of them explore incorporating multi-modal data into this problem. In this paper, we focus on a rarely discussed but important setting: can we train one model that can represent multiple scenes, with 360$^\\circ $ insufficient views and RGB-D images? We refer insufficient views to few extremely sparse and almost non-overlapping views. To deal with it, X-NeRF, a fully explicit approach which learns a general scene completion process instead of a coordinate-based mapping, is proposed. Given a few insufficient RGB-D input views, X-NeRF first transforms them to a sparse point cloud tensor and then applies a 3D sparse generative Convolutional Neural Network (CNN) to complete it to an explicit radiance field whose volumetric rendering can be conducted fast without running networks during inference. To avoid overfitting, besides common rendering loss, we apply perceptual loss as well as view augmentation through random rotation on point clouds. The proposed methodology significantly out-performs previous implicit methods in our setting, indicating the great potential of proposed problem and approach. Codes and data are available at https://github.com/HaoyiZhu/XNeRF. ",
    "url": "https://arxiv.org/abs/2210.05135",
    "authors": [
      "Haoyi Zhu",
      "Hao-Shu Fang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05143",
    "title": "Time-aware topic identification in social media with pre-trained  language models: A case study of electric vehicles",
    "abstract": "Recent extensively competitive business environment makes companies to keep their eyes on social media, as there is a growing recognition over customer languages (e.g., needs, interests, and complaints) as source of future opportunities. This research avenue analysing social media data has received much attention in academia, but their utilities are limited as most of methods provide retrospective results. Moreover, the increasing number of customer-generated contents and rapidly varying topics have made the necessity of time-aware topic evolution analyses. Recently, several researchers have showed the applicability of pre-trained semantic language models to social media as an input feature, but leaving limitations in understanding evolving topics. In this study, we propose a time-aware topic identification approach with pre-trained language models. The proposed approach consists of two stages: the dynamics-focused function for tracking time-varying topics with language models and the emergence-scoring function to examine future promising topics. Here we apply the proposed approach to reddit data on electric vehicles, and our findings highlight the feasibility of capturing emerging customer topics from voluminous social media in a time-aware manner. ",
    "url": "https://arxiv.org/abs/2210.05143",
    "authors": [
      "Byeongki Jeong",
      "Janghyeok Yoon",
      "Jaewoong Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.05145",
    "title": "Retrieval Augmentation for T5 Re-ranker using External Sources",
    "abstract": "Retrieval augmentation has shown promising improvements in different tasks. However, whether such augmentation can assist a large language model based re-ranker remains unclear. We investigate how to augment T5-based re-rankers using high-quality information retrieved from two external corpora -- a commercial web search engine and Wikipedia. We empirically demonstrate how retrieval augmentation can substantially improve the effectiveness of T5-based re-rankers for both in-domain and zero-shot out-of-domain re-ranking tasks. ",
    "url": "https://arxiv.org/abs/2210.05145",
    "authors": [
      "Kai Hui",
      "Tao Chen",
      "Zhen Qin",
      "Honglei Zhuang",
      "Fernando Diaz",
      "Mike Bendersky",
      "Don Metzler"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05146",
    "title": "CSS: Combining Self-training and Self-supervised Learning for Few-shot  Dialogue State Tracking",
    "abstract": "Few-shot dialogue state tracking (DST) is a realistic problem that trains the DST model with limited labeled data. Existing few-shot methods mainly transfer knowledge learned from external labeled dialogue data (e.g., from question answering, dialogue summarization, machine reading comprehension tasks, etc.) into DST, whereas collecting a large amount of external labeled data is laborious, and the external data may not effectively contribute to the DST-specific task. In this paper, we propose a few-shot DST framework called CSS, which Combines Self-training and Self-supervised learning methods. The unlabeled data of the DST task is incorporated into the self-training iterations, where the pseudo labels are predicted by a DST model trained on limited labeled data in advance. Besides, a contrastive self-supervised method is used to learn better representations, where the data is augmented by the dropout operation to train the model. Experimental results on the MultiWOZ dataset show that our proposed CSS achieves competitive performance in several few-shot scenarios. ",
    "url": "https://arxiv.org/abs/2210.05146",
    "authors": [
      "Haoning Zhang",
      "Junwei Bao",
      "Haipeng Sun",
      "Huaishao Luo",
      "Wenye Li",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05151",
    "title": "UGformer for Robust Left Atrium and Scar Segmentation Across Scanners",
    "abstract": "Thanks to the capacity for long-range dependencies and robustness to irregular shapes, vision transformers and deformable convolutions are emerging as powerful vision techniques of segmentation.Meanwhile, Graph Convolution Networks (GCN) optimize local features based on global topological relationship modeling. Particularly, they have been proved to be effective in addressing issues in medical imaging segmentation tasks including multi-domain generalization for low-quality images. In this paper, we present a novel, effective, and robust framework for medical image segmentation, namely, UGformer. It unifies novel transformer blocks, GCN bridges, and convolution decoders originating from U-Net to predict left atriums (LAs) and LA scars. We have identified two appealing findings of the proposed UGformer: 1). an enhanced transformer module with deformable convolutions to improve the blending of the transformer information with convolutional information and help predict irregular LAs and scar shapes. 2). Using a bridge incorporating GCN to further overcome the difficulty of capturing condition inconsistency across different Magnetic Resonance Images scanners with various inconsistent domain information. The proposed UGformer model exhibits outstanding ability to segment the left atrium and scar on the LAScarQS 2022 dataset, outperforming several recent state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2210.05151",
    "authors": [
      "Tianyi Liu",
      "Size Hou",
      "Jiayuan Zhu",
      "Zilong Zhao",
      "Haochuan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05152",
    "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "abstract": "Semantic segmentation is a classic computer vision problem dedicated to labeling each pixel with its corresponding category. As a basic task for advanced tasks such as industrial quality inspection, remote sensing information extraction, medical diagnostic aid, and autonomous driving, semantic segmentation has been developed for a long time in combination with deep learning, and a lot of work has been accumulated. However, neither the classic FCN-based works nor the popular Transformer-based works have attained fine-grained localization of pixel labels, which remains the main challenge in this field. Recently, with the popularity of autonomous driving, the segmentation of road scenes has received more and more attention. Based on the cross-task consistency theory, we incorporate edge priors into semantic segmentation tasks to obtain better results. The main contribution is that we provide a model-agnostic method that improves the accuracy of semantic segmentation models with zero extra inference runtime overhead, verified on the datasets of road and non-road scenes. From our experimental results, our method can effectively improve semantic segmentation accuracy. ",
    "url": "https://arxiv.org/abs/2210.05152",
    "authors": [
      "Dan Zhang",
      "Rui Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05156",
    "title": "Task-Aware Specialization for Efficient and Robust Dense Retrieval for  Open-Domain Question Answering",
    "abstract": "Given its effectiveness on knowledge-intensive natural language processing tasks, dense retrieval models have become increasingly popular. Specifically, the de-facto architecture for open-domain question answering uses two isomorphic encoders that are initialized from the same pretrained model but separately parameterized for questions and passages. This bi-encoder architecture is parameter-inefficient in that there is no parameter sharing between encoders. Further, recent studies show that such dense retrievers underperform BM25 in various settings. We thus propose a new architecture, Task-aware Specialization for dense Retrieval (TASER), which enables parameter sharing by interleaving shared and specialized blocks in a single encoder. Our experiments on five question answering datasets show that \\ourmodel\\ can achieve superior accuracy, surpassing BM25, while using about 60% of the parameters as bi-encoder dense retrievers. In out-of-domain evaluations, TASER is also empirically more robust than bi-encoder dense retrievers. ",
    "url": "https://arxiv.org/abs/2210.05156",
    "authors": [
      "Hao Cheng",
      "Hao Fang",
      "Xiaodong Liu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05175",
    "title": "Variability Matters : Evaluating inter-rater variability in  histopathology for robust cell detection",
    "abstract": "Large annotated datasets have been a key component in the success of deep learning. However, annotating medical images is challenging as it requires expertise and a large budget. In particular, annotating different types of cells in histopathology suffer from high inter- and intra-rater variability due to the ambiguity of the task. Under this setting, the relation between annotators' variability and model performance has received little attention. We present a large-scale study on the variability of cell annotations among 120 board-certified pathologists and how it affects the performance of a deep learning model. We propose a method to measure such variability, and by excluding those annotators with low variability, we verify the trade-off between the amount of data and its quality. We found that naively increasing the data size at the expense of inter-rater variability does not necessarily lead to better-performing models in cell detection. Instead, decreasing the inter-rater variability with the expense of decreasing dataset size increased the model performance. Furthermore, models trained from data annotated with lower inter-labeler variability outperform those from higher inter-labeler variability. These findings suggest that the evaluation of the annotators may help tackle the fundamental budget issues in the histopathology domain ",
    "url": "https://arxiv.org/abs/2210.05175",
    "authors": [
      "Cholmin Kang",
      "Chunggi Lee",
      "Heon Song",
      "Minuk Ma",
      "S ergio Pereira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05189",
    "title": "Neural Networks are Decision Trees",
    "abstract": "In this manuscript, we show that any neural network having piece-wise linear activation functions can be represented as a decision tree. The representation is equivalence and not an approximation, thus keeping the accuracy of the neural network exactly as is. This equivalence shows that neural networks are indeed interpretable by design and makes the \\textit{black-box} understanding obsolete. We share equivalent trees of some neural networks and show that besides providing interpretability, tree representation can also achieve some computational advantages. The analysis holds both for fully connected and convolutional networks, which may or may not also include skip connections and/or normalizations. ",
    "url": "https://arxiv.org/abs/2210.05189",
    "authors": [
      "Caglar Aytekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05197",
    "title": "Mixed-modality Representation Learning and Pre-training for Joint  Table-and-Text Retrieval in OpenQA",
    "abstract": "Retrieving evidences from tabular and textual resources is essential for open-domain question answering (OpenQA), which provides more comprehensive information. However, training an effective dense table-text retriever is difficult due to the challenges of table-text discrepancy and data sparsity problem. To address the above challenges, we introduce an optimized OpenQA Table-Text Retriever (OTTeR) to jointly retrieve tabular and textual evidences. Firstly, we propose to enhance mixed-modality representation learning via two mechanisms: modality-enhanced representation and mixed-modality negative sampling strategy. Secondly, to alleviate data sparsity problem and enhance the general retrieval ability, we conduct retrieval-centric mixed-modality synthetic pre-training. Experimental results demonstrate that OTTeR substantially improves the performance of table-and-text retrieval on the OTT-QA dataset. Comprehensive analyses examine the effectiveness of all the proposed mechanisms. Besides, equipped with OTTeR, our OpenQA system achieves the state-of-the-art result on the downstream QA task, with 10.1\\% absolute improvement in terms of the exact match over the previous best system. \\footnote{All the code and data are available at \\url{https://github.com/Jun-jie-Huang/OTTeR}.} ",
    "url": "https://arxiv.org/abs/2210.05197",
    "authors": [
      "Junjie Huang",
      "Wanjun Zhong",
      "Qian Liu",
      "Ming Gong",
      "Daxin Jiang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.05210",
    "title": "Robust Human Matting via Semantic Guidance",
    "abstract": "Automatic human matting is highly desired for many real applications. We investigate recent human matting methods and show that common bad cases happen when semantic human segmentation fails. This indicates that semantic understanding is crucial for robust human matting. From this, we develop a fast yet accurate human matting framework, named Semantic Guided Human Matting (SGHM). It builds on a semantic human segmentation network and introduces a light-weight matting module with only marginal computational cost. Unlike previous works, our framework is data efficient, which requires a small amount of matting ground-truth to learn to estimate high quality object mattes. Our experiments show that trained with merely 200 matting images, our method can generalize well to real-world datasets, and outperform recent methods on multiple benchmarks, while remaining efficient. Considering the unbearable labeling cost of matting data and widely available segmentation data, our method becomes a practical and effective solution for the task of human matting. Source code is available at https://github.com/cxgincsu/SemanticGuidedHumanMatting. ",
    "url": "https://arxiv.org/abs/2210.05210",
    "authors": [
      "Xiangguang Chen",
      "Ye Zhu",
      "Yu Li",
      "Bingtao Fu",
      "Lei Sun",
      "Ying Shan",
      "Shan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05211",
    "title": "A Win-win Deal: Towards Sparse and Robust Pre-trained Language Models",
    "abstract": "Despite the remarkable success of pre-trained language models (PLMs), they still face two challenges: First, large-scale PLMs are inefficient in terms of memory footprint and computation. Second, on the downstream tasks, PLMs tend to rely on the dataset bias and struggle to generalize to out-of-distribution (OOD) data. In response to the efficiency problem, recent studies show that dense PLMs can be replaced with sparse subnetworks without hurting the performance. Such subnetworks can be found in three scenarios: 1) the fine-tuned PLMs, 2) the raw PLMs and then fine-tuned in isolation, and even inside 3) PLMs without any parameter fine-tuning. However, these results are only obtained in the in-distribution (ID) setting. In this paper, we extend the study on PLMs subnetworks to the OOD setting, investigating whether sparsity and robustness to dataset bias can be achieved simultaneously. To this end, we conduct extensive experiments with the pre-trained BERT model on three natural language understanding (NLU) tasks. Our results demonstrate that \\textbf{sparse and robust subnetworks (SRNets) can consistently be found in BERT}, across the aforementioned three scenarios, using different training and compression methods. Furthermore, we explore the upper bound of SRNets using the OOD information and show that \\textbf{there exist sparse and almost unbiased BERT subnetworks}. Finally, we present 1) an analytical study that provides insights on how to promote the efficiency of SRNets searching process and 2) a solution to improve subnetworks' performance at high sparsity. The code is available at https://github.com/llyx97/sparse-and-robust-PLM. ",
    "url": "https://arxiv.org/abs/2210.05211",
    "authors": [
      "Yuanxin Liu",
      "Fandong Meng",
      "Zheng Lin",
      "Jiangnan Li",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05212",
    "title": "On Scrambling Phenomena for Randomly Initialized Recurrent Networks",
    "abstract": "Recurrent Neural Networks (RNNs) frequently exhibit complicated dynamics, and their sensitivity to the initialization process often renders them notoriously hard to train. Recent works have shed light on such phenomena analyzing when exploding or vanishing gradients may occur, either of which is detrimental for training dynamics. In this paper, we point to a formal connection between RNNs and chaotic dynamical systems and prove a qualitatively stronger phenomenon about RNNs than what exploding gradients seem to suggest. Our main result proves that under standard initialization (e.g., He, Xavier etc.), RNNs will exhibit \\textit{Li-Yorke chaos} with \\textit{constant} probability \\textit{independent} of the network's width. This explains the experimentally observed phenomenon of \\textit{scrambling}, under which trajectories of nearby points may appear to be arbitrarily close during some timesteps, yet will be far away in future timesteps. In stark contrast to their feedforward counterparts, we show that chaotic behavior in RNNs is preserved under small perturbations and that their expressive power remains exponential in the number of feedback iterations. Our technical arguments rely on viewing RNNs as random walks under non-linear activations, and studying the existence of certain types of higher-order fixed points called \\textit{periodic points} that lead to phase transitions from order to chaos. ",
    "url": "https://arxiv.org/abs/2210.05212",
    "authors": [
      "Vaggos Chatziafratis",
      "Ioannis Panageas",
      "Clayton Sanford",
      "Stelios Andrew Stavroulakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05232",
    "title": "DCL-Net: Deep Correspondence Learning Network for 6D Pose Estimation",
    "abstract": "Establishment of point correspondence between camera and object coordinate systems is a promising way to solve 6D object poses. However, surrogate objectives of correspondence learning in 3D space are a step away from the true ones of object pose estimation, making the learning suboptimal for the end task. In this paper, we address this shortcoming by introducing a new method of Deep Correspondence Learning Network for direct 6D object pose estimation, shortened as DCL-Net. Specifically, DCL-Net employs dual newly proposed Feature Disengagement and Alignment (FDA) modules to establish, in the feature space, partial-to-partial correspondence and complete-to-complete one for partial object observation and its complete CAD model, respectively, which result in aggregated pose and match feature pairs from two coordinate systems; these two FDA modules thus bring complementary advantages. The match feature pairs are used to learn confidence scores for measuring the qualities of deep correspondence, while the pose feature pairs are weighted by confidence scores for direct object pose regression. A confidence-based pose refinement network is also proposed to further improve pose precision in an iterative manner. Extensive experiments show that DCL-Net outperforms existing methods on three benchmarking datasets, including YCB-Video, LineMOD, and Oclussion-LineMOD; ablation studies also confirm the efficacy of our novel designs. ",
    "url": "https://arxiv.org/abs/2210.05232",
    "authors": [
      "Hongyang Li",
      "Jiehong Lin",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05234",
    "title": "It Takes Two: Masked Appearance-Motion Modeling for Self-supervised  Video Transformer Pre-training",
    "abstract": "Self-supervised video transformer pre-training has recently benefited from the mask-and-predict pipeline. They have demonstrated outstanding effectiveness on downstream video tasks and superior data efficiency on small datasets. However, temporal relation is not fully exploited by these methods. In this work, we explicitly investigate motion cues in videos as extra prediction target and propose our Masked Appearance-Motion Modeling (MAM2) framework. Specifically, we design an encoder-regressor-decoder pipeline for this task. The regressor separates feature encoding and pretext tasks completion, such that the feature extraction process is completed adequately by the encoder. In order to guide the encoder to fully excavate spatial-temporal features, two separate decoders are used for two pretext tasks of disentangled appearance and motion prediction. We explore various motion prediction targets and figure out RGB-difference is simple yet effective. As for appearance prediction, VQGAN codes are leveraged as prediction target. With our pre-training pipeline, convergence can be remarkably speed up, e.g., we only require half of epochs than state-of-the-art VideoMAE (400 v.s. 800) to achieve the competitive performance. Extensive experimental results prove that our method learns generalized video representations. Notably, our MAM2 with ViT-B achieves 82.3% on Kinects-400, 71.3% on Something-Something V2, 91.5% on UCF101, and 62.5% on HMDB51. ",
    "url": "https://arxiv.org/abs/2210.05234",
    "authors": [
      "Yuxin Song",
      "Min Yang",
      "Wenhao Wu",
      "Dongliang He",
      "Fu Li",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05236",
    "title": "Planning Assembly Sequence with Graph Transformer",
    "abstract": "Assembly sequence planning (ASP) is the essential process for modern manufacturing, proven to be NP-complete thus its effective and efficient solution has been a challenge for researchers in the field. In this paper, we present a graph-transformer based framework for the ASP problem which is trained and demonstrated on a self-collected ASP database. The ASP database contains a self-collected set of LEGO models. The LEGO model is abstracted to a heterogeneous graph structure after a thorough analysis of the original structure and feature extraction. The ground truth assembly sequence is first generated by brute-force search and then adjusted manually to in line with human rational habits. Based on this self-collected ASP dataset, we propose a heterogeneous graph-transformer framework to learn the latent rules for assembly planning. We evaluated the proposed framework in a series of experiment. The results show that the similarity of the predicted and ground truth sequences can reach 0.44, a medium correlation measured by Kendall's $\\tau$. Meanwhile, we compared the different effects of node features and edge features and generated a feasible and reasonable assembly sequence as a benchmark for further research. Our data set and code is available on https://github.com/AIR-DISCOVER/ICRA\\_ASP. ",
    "url": "https://arxiv.org/abs/2210.05236",
    "authors": [
      "Lin Ma",
      "Jiangtao Gong",
      "Hao Xu",
      "Hao Chen",
      "Hao Zhao",
      "Wenbing Huang",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05241",
    "title": "STSC-SNN: Spatio-Temporal Synaptic Connection with Temporal Convolution  and Attention for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs), as one of the algorithmic models in neuromorphic computing, have gained a great deal of research attention owing to temporal information processing capability, low power consumption, and high biological plausibility. The potential to efficiently extract spatio-temporal features makes it suitable for processing the event streams. However, existing synaptic structures in SNNs are almost full-connections or spatial 2D convolution, neither of which can extract temporal dependencies adequately. In this work, we take inspiration from biological synapses and propose a spatio-temporal synaptic connection SNN (STSC-SNN) model, to enhance the spatio-temporal receptive fields of synaptic connections, thereby establishing temporal dependencies across layers. Concretely, we incorporate temporal convolution and attention mechanisms to implement synaptic filtering and gating functions. We show that endowing synaptic models with temporal dependencies can improve the performance of SNNs on classification tasks. In addition, we investigate the impact of performance vias varied spatial-temporal receptive fields and reevaluate the temporal modules in SNNs. Our approach is tested on neuromorphic datasets, including DVS128 Gesture (gesture recognition), N-MNIST, CIFAR10-DVS (image classification), and SHD (speech digit recognition). The results show that the proposed model outperforms the state-of-the-art accuracy on nearly all datasets. ",
    "url": "https://arxiv.org/abs/2210.05241",
    "authors": [
      "Chengting Yu",
      "Zheming Gu",
      "Da Li",
      "Gaoang Wang",
      "Aili Wang",
      "Erping Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05243",
    "title": "Cross-modal Search Method of Technology Video based on Adversarial  Learning and Feature Fusion",
    "abstract": "Technology videos contain rich multi-modal information. In cross-modal information search, the data features of different modalities cannot be compared directly, so the semantic gap between different modalities is a key problem that needs to be solved. To address the above problems, this paper proposes a novel Feature Fusion based Adversarial Cross-modal Retrieval method (FFACR) to achieve text-to-video matching, ranking and searching. The proposed method uses the framework of adversarial learning to construct a video multimodal feature fusion network and a feature mapping network as generator, a modality discrimination network as discriminator. Multi-modal features of videos are obtained by the feature fusion network. The feature mapping network projects multi-modal features into the same semantic space based on semantics and similarity. The modality discrimination network is responsible for determining the original modality of features. Generator and discriminator are trained alternately based on adversarial learning, so that the data obtained by the feature mapping network is semantically consistent with the original data and the modal features are eliminated, and finally the similarity is used to rank and obtain the search results in the semantic space. Experimental results demonstrate that the proposed method performs better in text-to-video search than other existing methods, and validate the effectiveness of the method on the self-built datasets of technology videos. ",
    "url": "https://arxiv.org/abs/2210.05243",
    "authors": [
      "Xiangbin Liu",
      "Junping Du",
      "Meiyu Liang",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.05248",
    "title": "Self-supervised debiasing using low rank regularization",
    "abstract": "Spurious correlations can cause strong biases in deep neural networks, impairing generalization ability. While most of existing debiasing methods require full supervisions on either spurious attributes or target labels, training a debiased model from a limited amount of both annotations is still an open issue. To overcome such limitations, we first examined an interesting phenomenon by the spectral analysis of latent representations: spuriously correlated, easy-to-learn attributes make neural networks inductively biased towards encoding lower effective rank representations. We also show that a rank regularization can amplify this bias in a way that encourages highly correlated features. Motivated by these observations, we propose a self-supervised debiasing framework that is potentially compatible with unlabeled samples. We first pretrain a biased encoder in a self-supervised manner with the rank regularization, serving as a semantic bottleneck to enforce the encoder to learn the spuriously correlated attributes. This biased encoder is then used to discover and upweight bias-conflicting samples in a downstream task, serving as a boosting to effectively debias the main model. Remarkably, the proposed debiasing framework significantly improves the generalization performance of self-supervised learning baselines and, in some cases, even outperforms state-of-the-art supervised debiasing approaches. ",
    "url": "https://arxiv.org/abs/2210.05248",
    "authors": [
      "Geon Yeong Park",
      "Chanyong Jung",
      "Jong Chul Ye",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05250",
    "title": "Digital twins for city simulation: Automatic, efficient, and robust mesh  generation for large-scale city modeling and simulation",
    "abstract": "The concept of creating digital twins, connected digital models of physical systems, is gaining increasing attention for modeling and simulation of whole cities. The basis for building a digital twin of a city is the generation of a 3D city model, often represented as a mesh. Creating and updating such models is a tedious process that requires manual work and considerable effort, especially in the modeling of building geometries. In the current paper, we present a novel algorithm and implementation for automatic, efficient, and robust mesh generation for large-scale city modeling and simulation. The algorithm relies on standard, publicly available data, in particular 2D cadastral maps (building footprints) and 3D point clouds obtained from aerial scanning. The algorithm generates LoD1.2 city models in the form of both triangular surface meshes, suitable for visualisation, and high-quality tetrahedral volume meshes, suitable for simulation. Our tests demonstrate good performance and scaling and indicate good avenues for further optimization based on parallelisation. The long-term goal is a generic digital twin of cities volume mesh generator that provides (nearly) real-time mesh manipulation in LoD2.x. ",
    "url": "https://arxiv.org/abs/2210.05250",
    "authors": [
      "Vasilis Naserentin",
      "Anders Logg"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.05252",
    "title": "Graph Neural Network Policies and Imitation Learning for Multi-Domain  Task-Oriented Dialogues",
    "abstract": "Task-oriented dialogue systems are designed to achieve specific goals while conversing with humans. In practice, they may have to handle simultaneously several domains and tasks. The dialogue manager must therefore be able to take into account domain changes and plan over different domains/tasks in order to deal with multidomain dialogues. However, learning with reinforcement in such context becomes difficult because the state-action dimension is larger while the reward signal remains scarce. Our experimental results suggest that structured policies based on graph neural networks combined with different degrees of imitation learning can effectively handle multi-domain dialogues. The reported experiments underline the benefit of structured policies over standard policies. ",
    "url": "https://arxiv.org/abs/2210.05252",
    "authors": [
      "Thibault Cordier",
      "Tanguy Urvoy",
      "Fabrice Lef\u00e8vre",
      "Lina M. Rojas-Barahona"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05253",
    "title": "Constrained Deployment Optimization in Integrated Access and Backhaul  Networks",
    "abstract": "Integrated access and backhaul (IAB) is one of the promising techniques for 5G networks and beyond (6G), in which the same node/hardware is used to provide both backhaul and cellular services in a multi-hop fashion. Due to the sensitivity of the backhaul links with high rate/reliability demands, proper network planning is needed to make the IAB network performing appropriately and as good as possible. In this paper, we study the effect of deployment optimization on the coverage of IAB networks. We concentrate on the cases where, due to either geographical or interference management limitations, unconstrained IAB node placement is not feasible in some areas. To that end, we propose various millimeter wave (mmWave) blocking-aware constrained deployment optimization approaches. Our results indicate that, even with limitations on deployment optimization, network planning boosts the coverage of IAB networks considerably. ",
    "url": "https://arxiv.org/abs/2210.05253",
    "authors": [
      "Charitha Madapatha",
      "Behrooz Makki",
      "Hao Guo",
      "Tommy Svensson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05268",
    "title": "Component-Wise Natural Gradient Descent -- An Efficient Neural Network  Optimization",
    "abstract": "Natural Gradient Descent (NGD) is a second-order neural network training that preconditions the gradient descent with the inverse of the Fisher Information Matrix (FIM). Although NGD provides an efficient preconditioner, it is not practicable due to the expensive computation required when inverting the FIM. This paper proposes a new NGD variant algorithm named Component-Wise Natural Gradient Descent (CW-NGD). CW-NGD is composed of 2 steps. Similar to several existing works, the first step is to consider the FIM matrix as a block-diagonal matrix whose diagonal blocks correspond to the FIM of each layer's weights. In the second step, unique to CW-NGD, we analyze the layer's structure and further decompose the layer's FIM into smaller segments whose derivatives are approximately independent. As a result, individual layers' FIMs are approximated in a block-diagonal form that trivially supports the inversion. The segment decomposition strategy is varied by layer structure. Specifically, we analyze the dense and convolutional layers and design their decomposition strategies appropriately. In an experiment of training a network containing these 2 types of layers, we empirically prove that CW-NGD requires fewer iterations to converge compared to the state-of-the-art first-order and second-order methods. ",
    "url": "https://arxiv.org/abs/2210.05268",
    "authors": [
      "Tran Van Sang",
      "Mhd Irvan",
      "Rie Shigetomi Yamaguchi",
      "Toshiyuki Nakata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05276",
    "title": "RoHNAS: A Neural Architecture Search Framework with Conjoint  Optimization for Adversarial Robustness and Hardware Efficiency of  Convolutional and Capsule Networks",
    "abstract": "Neural Architecture Search (NAS) algorithms aim at finding efficient Deep Neural Network (DNN) architectures for a given application under given system constraints. DNNs are computationally-complex as well as vulnerable to adversarial attacks. In order to address multiple design objectives, we propose RoHNAS, a novel NAS framework that jointly optimizes for adversarial-robustness and hardware-efficiency of DNNs executed on specialized hardware accelerators. Besides the traditional convolutional DNNs, RoHNAS additionally accounts for complex types of DNNs such as Capsule Networks. For reducing the exploration time, RoHNAS analyzes and selects appropriate values of adversarial perturbation for each dataset to employ in the NAS flow. Extensive evaluations on multi - Graphics Processing Unit (GPU) - High Performance Computing (HPC) nodes provide a set of Pareto-optimal solutions, leveraging the tradeoff between the above-discussed design objectives. For example, a Pareto-optimal DNN for the CIFAR-10 dataset exhibits 86.07% accuracy, while having an energy of 38.63 mJ, a memory footprint of 11.85 MiB, and a latency of 4.47 ms. ",
    "url": "https://arxiv.org/abs/2210.05276",
    "authors": [
      "Alberto Marchisio",
      "Vojtech Mrazek",
      "Andrea Massa",
      "Beatrice Bussolino",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05280",
    "title": "ME-D2N: Multi-Expert Domain Decompositional Network for Cross-Domain  Few-Shot Learning",
    "abstract": "Recently, Cross-Domain Few-Shot Learning (CD-FSL) which aims at addressing the Few-Shot Learning (FSL) problem across different domains has attracted rising attention. The core challenge of CD-FSL lies in the domain gap between the source and novel target datasets. Though many attempts have been made for CD-FSL without any target data during model training, the huge domain gap makes it still hard for existing CD-FSL methods to achieve very satisfactory results. Alternatively, learning CD-FSL models with few labeled target domain data which is more realistic and promising is advocated in previous work~\\cite{fu2021meta}. Thus, in this paper, we stick to this setting and technically contribute a novel Multi-Expert Domain Decompositional Network (ME-D2N). Concretely, to solve the data imbalance problem between the source data with sufficient examples and the auxiliary target data with limited examples, we build our model under the umbrella of multi-expert learning. Two teacher models which can be considered to be experts in their corresponding domain are first trained on the source and the auxiliary target sets, respectively. Then, the knowledge distillation technique is introduced to transfer the knowledge from two teachers to a unified student model. Taking a step further, to help our student model learn knowledge from different domain teachers simultaneously, we further present a novel domain decomposition module that learns to decompose the student model into two domain-related sub parts. This is achieved by a novel domain-specific gate that learns to assign each filter to only one specific domain in a learnable way. Extensive experiments demonstrate the effectiveness of our method. Codes and models are available at https://github.com/lovelyqian/ME-D2N_for_CDFSL. ",
    "url": "https://arxiv.org/abs/2210.05280",
    "authors": [
      "Yuqian Fu",
      "Yu Xie",
      "Yanwei Fu",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05287",
    "title": "Revisiting and Advancing Chinese Natural Language Understanding with  Accelerated Heterogeneous Knowledge Pre-training",
    "abstract": "Recently, knowledge-enhanced pre-trained language models (KEPLMs) improve context-aware representations via learning from structured relations in knowledge graphs, and/or linguistic knowledge from syntactic or dependency analysis. Unlike English, there is a lack of high-performing open-source Chinese KEPLMs in the natural language processing (NLP) community to support various language understanding applications. In this paper, we revisit and advance the development of Chinese natural language understanding with a series of novel Chinese KEPLMs released in various parameter sizes, namely CKBERT (Chinese knowledge-enhanced BERT).Specifically, both relational and linguistic knowledge is effectively injected into CKBERT based on two novel pre-training tasks, i.e., linguistic-aware masked language modeling and contrastive multi-hop relation modeling. Based on the above two pre-training paradigms and our in-house implemented TorchAccelerator, we have pre-trained base (110M), large (345M) and huge (1.3B) versions of CKBERT efficiently on GPU clusters. Experiments demonstrate that CKBERT outperforms strong baselines for Chinese over various benchmark NLP tasks and in terms of different model sizes. ",
    "url": "https://arxiv.org/abs/2210.05287",
    "authors": [
      "Taolin Zhang",
      "Junwei DOng",
      "Jianing Wang",
      "Chengyu Wang",
      "Ang Wang",
      "Yinghui Liu",
      "Jun Huang",
      "Yong Li",
      "Xiaofeng He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05311",
    "title": "CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection",
    "abstract": "Although few-shot object detection (FSOD) has attracted great research attention, no work yet exists that studies FSOD across the different domains seen in real-world scenarios. In this paper, we propose a new study of the cross-domain few-shot object detection (CD-FSOD) benchmark, consisting of image data from a diverse data domain. On the proposed benchmark, we evaluate state-of-art FSOD approaches, and analyze the impact of detection models and pre-training datasets on performance. The results reveal several key findings: (1) the existing FSOD approaches tend to fall, and even underperform the naive fine-tuning model; 2) the pre-training datasets and detection architectures play an important role, and the right choice can boost the performance of the target tasks significantly. Besides, we also analyze the reasons for existing FSOD approaches' failure, and introduce a strong baseline that uses a mutually-beneficial manner to alleviate the overfitting problem. Our approach is remarkably superior to existing approaches by significant margins (\\%2.3 on average) on the proposed benchmark and also achieves competitive performance on the FSOD benchmark. ",
    "url": "https://arxiv.org/abs/2210.05311",
    "authors": [
      "Wuti Xiong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05314",
    "title": "Client Error Clustering Approaches in Content Delivery Networks (CDN)",
    "abstract": "Content delivery networks (CDNs) are the backbone of the Internet and are key in delivering high quality video on demand (VoD), web content and file services to billions of users. CDNs usually consist of hierarchically organized content servers positioned as close to the customers as possible. CDN operators face a significant challenge when analyzing billions of web server and proxy logs generated by their systems. The main objective of this study was to analyze the applicability of various clustering methods in CDN error log analysis. We worked with real-life CDN proxy logs, identified key features included in the logs (e.g., content type, HTTP status code, time-of-day, host) and clustered the log lines corresponding to different host types offering live TV, video on demand, file caching and web content. Our experiments were run on a dataset consisting of proxy logs collected over a 7-day period from a single, physical CDN server running multiple types of services (VoD, live TV, file). The dataset consisted of 2.2 billion log lines. Our analysis showed that CDN error clustering is a viable approach towards identifying recurring errors and improving overall quality of service. ",
    "url": "https://arxiv.org/abs/2210.05314",
    "authors": [
      "Ermiyas Birihanu",
      "Jiyan Mahmud",
      "P\u00e9ter Kiss",
      "Adolf Kamuzora",
      "Wadie Skaf",
      "Tom\u00e1\u0161 Horv\u00e1th",
      "Tam\u00e1s Jursonovics",
      "Peter Pogrzeba",
      "Imre Lend\u00e1k"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05316",
    "title": "Sizing up the Batteries: Modelling of Energy-Harvesting Sensor Nodes in  a Delay Tolerant Network",
    "abstract": "For energy-harvesting sensor nodes, rechargeable batteries play a critical role in sensing and transmissions. By coupling two simple Markovian queue models in a delay-tolerant networking setting, we consider the problem of battery sizing for these sensor nodes to operate effectively: given the intended energy depletion and overflow probabilities, how to decide the minimal battery capacity that is required to ensure opportunistic data exchange despite the inherent intermittency of renewable energy generation. ",
    "url": "https://arxiv.org/abs/2210.05316",
    "authors": [
      "Jeremiah D. Deng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.05327",
    "title": "A Causal Analysis of Harm",
    "abstract": "As autonomous systems rapidly become ubiquitous, there is a growing need for a legal and regulatory framework to address when and how such a system harms someone. There have been several attempts within the philosophy literature to define harm, but none of them has proven capable of dealing with with the many examples that have been presented, leading some to suggest that the notion of harm should be abandoned and \"replaced by more well-behaved notions\". As harm is generally something that is caused, most of these definitions have involved causality at some level. Yet surprisingly, none of them makes use of causal models and the definitions of actual causality that they can express. In this paper we formally define a qualitative notion of harm that uses causal models and is based on a well-known definition of actual causality (Halpern, 2016). The key novelty of our definition is that it is based on contrastive causation and uses a default utility to which the utility of actual outcomes is compared. We show that our definition is able to handle the examples from the literature, and illustrate its importance for reasoning about situations involving autonomous systems. ",
    "url": "https://arxiv.org/abs/2210.05327",
    "authors": [
      "Sander Beckers",
      "Hana Chockler",
      "Joseph Y. Halpern"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05333",
    "title": "Routing Schemes for Hybrid Communication Networks in Unit-Disk Graphs",
    "abstract": "Hybrid communication networks provide multiple modes of communication with varying characteristics. The $\\mathsf{HYRBID}$ model was introduced to unlock theoretical study of such networks. It combines two fundamentally different communication modes. A \\emph{local} mode, which restricts communication among nodes to a given graph and a \\emph{global} mode where any two nodes may communicate in principle, but only very little such communication can take place per unit of time. We are interested in the fast computation of \\emph{routing schemes}, where nodes have to compute small labels and routing tables that allow for efficient routing of messages in the local network, which typically offers the majority of the throughput. Recent work has shown that using the $\\mathsf{HYRBID}$ model admits a tremendous speed-up compared to what would be possible if either communication mode were used in isolation. However, it was also shown that the computation of routing schemes takes polynomial rounds in the $\\mathsf{HYRBID}$ model if general graphs are used as local graph even when large labels are allowed. Coy et al.\\ [OPODIS'21] bypass this lower bound by restricting the local graph to unit-disc-graphs, and solve the problem deterministically with running time, label size, and size of routing tables all in $O(\\log n)$. However they assume that the unit disk graph has no ``radio holes'', which makes the graph much simpler (topologically similar to a tree). In this work we show how to generalize the algorithm to \\emph{any} unit disk graph with running time $O(h^2 \\!+\\! \\log n)$ where $h$ is the number of radio holes, which preserves the prior guarantees if $h$ is small. ",
    "url": "https://arxiv.org/abs/2210.05333",
    "authors": [
      "Sam Coy",
      "Artur Czumaj",
      "Christian Scheideler",
      "Philipp Schneider",
      "Julian Werthmann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.05338",
    "title": "FusionDeepMF: A Dual Embedding based Deep Fusion Model for  Recommendation",
    "abstract": "Traditional Collaborative Filtering (CF) based methods are applied to understand the personal preferences of users/customers for items or products from the rating matrix. Usually, the rating matrix is sparse in nature. So there are some improved variants of the CF method that apply the increasing amount of side information to handle the sparsity problem. Only linear kernel or only non-linear kernel is applied in most of the available recommendation-related work to understand user-item latent feature embeddings from data. Only linear kernel or only non-linear kernel is not sufficient to learn complex user-item features from side information of users. Recently, some researchers have focused on hybrid models that learn some features with non-linear kernels and some other features with linear kernels. But it is very difficult to understand which features can be learned accurately with linear kernels or with non-linear kernels. To overcome this problem, we propose a novel deep fusion model named FusionDeepMF and the novel attempts of this model are i) learning user-item rating matrix and side information through linear and non-linear kernel simultaneously, ii) application of a tuning parameter determining the trade-off between the dual embeddings that are generated from linear and non-linear kernels. Extensive experiments on online review datasets establish that FusionDeepMF can be remarkably futuristic compared to other baseline approaches. Empirical evidence also shows that FusionDeepMF achieves better performances compared to the linear kernels of Matrix Factorization (MF) and the non-linear kernels of Multi-layer Perceptron (MLP). ",
    "url": "https://arxiv.org/abs/2210.05338",
    "authors": [
      "Supriyo Mandal",
      "Abyayananda Maiti"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05343",
    "title": "Printing variability of copy detection patterns",
    "abstract": "Copy detection pattern (CDP) is a novel solution for products' protection against counterfeiting, which gains its popularity in recent years. CDP attracts the anti-counterfeiting industry due to its numerous benefits in comparison to alternative protection techniques. Besides its attractiveness, there is an essential gap in the fundamental analysis of CDP authentication performance in large-scale industrial applications. It concerns variability of CDP parameters under different production conditions that include a type of printer, substrate, printing resolution, etc. Since digital off-set printing represents great flexibility in terms of product personalized in comparison with traditional off-set printing, it looks very interesting to address the above concerns for digital off-set printers that are used by several companies for the CDP protection of physical objects. In this paper, we thoroughly investigate certain factors impacting CDP. The experimental results obtained during our study reveal some previously unknown results and raise new and even more challenging questions. The results prove that it is a matter of great importance to choose carefully the substrate or printer for CDP production. This paper presents a new dataset produced by two industrial HP Indigo printers. The similarity between printed CDP and the digital templates, from which they have been produced, is chosen as a simple measure in our study. We found several particularities that might be of interest for large-scale industrial applications. ",
    "url": "https://arxiv.org/abs/2210.05343",
    "authors": [
      "Roman Chaban",
      "Olga Taran",
      "Joakim Tutt",
      "Yury Belousov",
      "Brian Pulfer",
      "Taras Holotyak",
      "Slava Voloshynovskiy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05370",
    "title": "DeepPerform: An Efficient Approach for Performance Testing of  Resource-Constrained Neural Networks",
    "abstract": "Today, an increasing number of Adaptive Deep Neural Networks (AdNNs) are being used on resource-constrained embedded devices. We observe that, similar to traditional software, redundant computation exists in AdNNs, resulting in considerable performance degradation. The performance degradation is dependent on the input and is referred to as input-dependent performance bottlenecks (IDPBs). To ensure an AdNN satisfies the performance requirements of resource-constrained applications, it is essential to conduct performance testing to detect IDPBs in the AdNN. Existing neural network testing methods are primarily concerned with correctness testing, which does not involve performance testing. To fill this gap, we propose DeepPerform, a scalable approach to generate test samples to detect the IDPBs in AdNNs. We first demonstrate how the problem of generating performance test samples detecting IDPBs can be formulated as an optimization problem. Following that, we demonstrate how DeepPerform efficiently handles the optimization problem by learning and estimating the distribution of AdNNs' computational consumption. We evaluate DeepPerform on three widely used datasets against five popular AdNN models. The results show that DeepPerform generates test samples that cause more severe performance degradation (FLOPs: increase up to 552\\%). Furthermore, DeepPerform is substantially more efficient than the baseline methods in generating test inputs(runtime overhead: only 6-10 milliseconds). ",
    "url": "https://arxiv.org/abs/2210.05370",
    "authors": [
      "Simin Chen",
      "Mirazul Haque",
      "Cong Liu",
      "Wei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.05372",
    "title": "DEPTWEET: A Typology for Social Media Texts to Detect Depression  Severities",
    "abstract": "Mental health research through data-driven methods has been hindered by a lack of standard typology and scarcity of adequate data. In this study, we leverage the clinical articulation of depression to build a typology for social media texts for detecting the severity of depression. It emulates the standard clinical assessment procedure Diagnostic and Statistical Manual of Mental Disorders (DSM-5) and Patient Health Questionnaire (PHQ-9) to encompass subtle indications of depressive disorders from tweets. Along with the typology, we present a new dataset of 40191 tweets labeled by expert annotators. Each tweet is labeled as 'non-depressed' or 'depressed'. Moreover, three severity levels are considered for 'depressed' tweets: (1) mild, (2) moderate, and (3) severe. An associated confidence score is provided with each label to validate the quality of annotation. We examine the quality of the dataset via representing summary statistics while setting strong baseline results using attention-based models like BERT and DistilBERT. Finally, we extensively address the limitations of the study to provide directions for further research. ",
    "url": "https://arxiv.org/abs/2210.05372",
    "authors": [
      "Mohsinul Kabir",
      "Tasnim Ahmed",
      "Md. Bakhtiar Hasan",
      "Md Tahmid Rahman Laskar",
      "Tarun Kumar Joarder",
      "Hasan Mahmud",
      "Kamrul Hasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05373",
    "title": "Stable and Efficient Adversarial Training through Local Linearization",
    "abstract": "There has been a recent surge in single-step adversarial training as it shows robustness and efficiency. However, a phenomenon referred to as ``catastrophic overfitting\" has been observed, which is prevalent in single-step defenses and may frustrate attempts to use FGSM adversarial training. To address this issue, we propose a novel method, Stable and Efficient Adversarial Training (SEAT), which mitigates catastrophic overfitting by harnessing on local properties that distinguish a robust model from that of a catastrophic overfitted model. The proposed SEAT has strong theoretical justifications, in that minimizing the SEAT loss can be shown to favour smooth empirical risk, thereby leading to robustness. Experimental results demonstrate that the proposed method successfully mitigates catastrophic overfitting, yielding superior performance amongst efficient defenses. Our single-step method can reach 51% robust accuracy for CIFAR-10 with $l_\\infty$ perturbations of radius $8/255$ under a strong PGD-50 attack, matching the performance of a 10-step iterative adversarial training at merely 3% computational cost. ",
    "url": "https://arxiv.org/abs/2210.05373",
    "authors": [
      "Zhuorong Li",
      "Daiwei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05382",
    "title": "Break the Wall Between Homophily and Heterophily for Graph  Representation Learning",
    "abstract": "Homophily and heterophily are intrinsic properties of graphs that describe whether two linked nodes share similar properties. Although many Graph Neural Network (GNN) models have been proposed, it remains unclear how to design a model so that it can generalize well to the whole spectrum of homophily. This work addresses the challenge by identifying three graph features, including the ego node feature, the aggregated node feature, and the graph structure feature, that are essential for graph representation learning. It further proposes a new GNN model called OGNN (Omnipotent Graph Neural Network) that extracts all three graph features and adaptively fuses them to achieve generalizability across the whole spectrum of homophily. Extensive experiments on both synthetic and real datasets demonstrate the superiority (average rank 1.56) of our OGNN compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.05382",
    "authors": [
      "Xiao Liu",
      "Lijun Zhang",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05384",
    "title": "Morphing Planar Graph Drawings Through 3D",
    "abstract": "In this paper, we investigate crossing-free 3D morphs between planar straight-line drawings. We show that, for any two (not necessarily topologically equivalent) planar straight-line drawings of an $n$-vertex planar graph, there exists a piecewise-linear crossing-free 3D morph with $O(n^2)$ steps that transforms one drawing into the other. We also give some evidence why it is difficult to obtain a linear lower bound (which exists in 2D) for the number of steps of a crossing-free 3D morph. ",
    "url": "https://arxiv.org/abs/2210.05384",
    "authors": [
      "Kevin Buchin",
      "Will Evans",
      "Fabrizio Frati",
      "Irina Kostitsyna",
      "Maarten L\u00f6ffler",
      "Tim Ophelders",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.05397",
    "title": "Analysis of Expected Hitting Time for Designing Evolutionary Neural  Architecture Search Algorithms",
    "abstract": "Evolutionary computation-based neural architecture search (ENAS) is a popular technique for automating architecture design of deep neural networks. In recent years, various ENAS algorithms have been proposed and shown promising performance on diverse real-world applications. In contrast to these groundbreaking applications, there is no theoretical guideline for assigning a reasonable running time (mainly affected by the generation number, population size, and evolution operator) given both the anticipated performance and acceptable computation budget on ENAS problems. The expected hitting time (EHT), which refers to the average generations, is considered to analyze the running time of ENAS algorithms. This paper proposes a general framework for estimating the EHT of ENAS algorithms, which includes common configuration, search space partition, transition probability estimation, and hitting time analysis. By exploiting the proposed framework, we consider the so-called ($\\lambda$+$\\lambda$)-ENAS algorithms with different mutation operators and manage to estimate the lower bounds of the EHT {which are critical for the algorithm to find the global optimum}. Furthermore, we study the theoretical results on the NAS-Bench-101 architecture searching problem, and the results show that the one-bit mutation with \"bit-based fair mutation\" strategy needs less time than the \"offspring-based fair mutation\" strategy, and the bitwise mutation operator needs less time than the $q$-bit mutation operator. To the best of our knowledge, this is the first work focusing on the theory of ENAS, and the above observation will be substantially helpful in designing efficient ENAS algorithms. ",
    "url": "https://arxiv.org/abs/2210.05397",
    "authors": [
      "Zeqiong Lv",
      "Chao Qian",
      "Gary G. Yen",
      "Yanan Sun"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.05401",
    "title": "Not Good Times for Lies: Misinformation Detection on the Russia-Ukraine  War, COVID-19, and Refugees",
    "abstract": "Misinformation spread in online social networks is an urgent-to-solve problem having harmful consequences that threaten human health, public safety, economics, and so on. In this study, we construct a novel dataset, called MiDe-22, having 5,284 English and 5,064 Turkish tweets with their misinformation labels under several recent events, including the Russia-Ukraine war, COVID-19 pandemic, and Refugees. Moreover, we provide the user engagements to the tweets in terms of likes, replies, retweets, and quotes. We present a detailed data analysis with descriptive statistics and temporal analysis, and provide the experimental results of a benchmark evaluation for misinformation detection on our novel dataset. ",
    "url": "https://arxiv.org/abs/2210.05401",
    "authors": [
      "Cagri Toraman",
      "Oguzhan Ozcelik",
      "Furkan \u015eahinu\u00e7",
      "Fazli Can"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.05405",
    "title": "From Earth to Space: A First Deployment of 5G Core Network on Satellite",
    "abstract": "Recent developments in the aerospace industry have led to a dramatic reduction in the manufacturing and launch costs of low Earth orbit satellites. The new trend enables the paradigm shift of satellite-terrestrial integrated networks with global coverage. In particular, the integration of 5G communication systems and satellites has the potential to restructure next-generation mobile networks. By leveraging the network function virtualization and network slicing, the orbital 5G core networks will facilitate the coordination and management of network functions in satellite-terrestrial integrated networks. We are the first to deploy a lightweight 5G core network on a real-world satellite to investigate its feasibility. We conducted experiments to validate the onboard 5G core network functions. The validated procedures include registration and session setup procedures. The results show that the 5G core network can function normally and generate correct signaling. ",
    "url": "https://arxiv.org/abs/2210.05405",
    "authors": [
      "Ruolin Xing",
      "Xiao Ma",
      "Ao Zhou",
      "Schahram Dustdar",
      "Shangguang Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.05406",
    "title": "Code Librarian: A Software Package Recommendation System",
    "abstract": "The use of packaged libraries can significantly shorten the software development cycle by improving the quality and readability of code. In this paper, we present a recommendation engine called Librarian for open source libraries. A candidate library package is recommended for a given context if: 1) it has been frequently used with the imported libraries in the program; 2) it has similar functionality to the imported libraries in the program; 3) it has similar functionality to the developer's implementation, and 4) it can be used efficiently in the context of the provided code. We apply the state-of-the-art CodeBERT-based model for analysing the context of the source code to deliver relevant library recommendations to users. ",
    "url": "https://arxiv.org/abs/2210.05406",
    "authors": [
      "Lili Tao",
      "Alexandru-Petre Cazan",
      "Senad Ibraimoski",
      "Sean Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05408",
    "title": "Private Randomness Agreement and its Application in Quantum Key  Distribution Networks",
    "abstract": "We define a variation on the well-known problem of private message transmission. This new problem called private randomness agreement (PRA) gives two participants access to a public, authenticated channel alongside the main channels, and the 'message' is not fixed a priori. Instead, the participants' aim to agree on a random string completely unknown to a computationally unbounded adversary. We define privacy and reliability, and show that PRA cannot be solved in a single round. We then show that it can be solved in three rounds, albeit with exponential cost, and give an efficient four-round protocol based on polynomial evaluation. ",
    "url": "https://arxiv.org/abs/2210.05408",
    "authors": [
      "Ren\u00e9 B\u00f8dker Christensen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.05437",
    "title": "DPANET:Dual Pooling Attention Network for Semantic Segmentation",
    "abstract": "Image segmentation is a historic and significant computer vision task. With the help of deep learning techniques, image semantic segmentation has made great progresses. Over recent years, based on guidance of attention mechanism compared with CNN which overcomes the problems of lacking of interaction between different channels, and effective capturing and aggregating contextual information. However, the massive operations generated by the attention mechanism lead to its extremely high complexity and high demand for GPU memory. For this purpose, we propose a lightweight and flexible neural network named Dual Pool Attention Network(DPANet). The most important is that all modules in DPANet generate \\textbf{0} parameters. The first component is spatial pool attention module, we formulate an easy and powerful method densely to extract contextual characteristics and reduce the amount of calculation and complexity dramatically.Meanwhile, it demonstrates the power of even and large kernel size. The second component is channel pool attention module. It is known that the computation process of CNN incorporates the information of spatial and channel dimensions. So, the aim of this module is stripping them out, in order to construct relationship of all channels and heighten different channels semantic information selectively. Moreover, we experiments on segmentation datasets, which shows our method simple and effective with low parameters and calculation complexity. ",
    "url": "https://arxiv.org/abs/2210.05437",
    "authors": [
      "Dongwei Sun",
      "Zhuolin Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05438",
    "title": "Parallel Augmentation and Dual Enhancement for Occluded Person  Re-identification",
    "abstract": "Occluded person re-identification (Re-ID), the task of searching for the same person's images in occluded environments, has attracted lots of attention in the past decades. Recent approaches concentrate on improving performance on occluded data by data/feature augmentation or using extra models to predict occlusions. However, they ignore the imbalance problem in the test set and not fully utilize the information from the training data. To alleviate the above problems, we propose a simple but effective method with Parallel Augmentation and Dual Enhancement (PADE) that is robust on both occluded and non-occluded data, and does not require any auxiliary clues. First, we design a parallel augmentation mechanism (PAM) for occluded Re-ID to generate more suitable occluded data to mitigate the negative effects of unbalanced data. Second, we propose the dual enhancement strategy (DES)for global and local features to promote the context information and details. Experimental results on widely used occluded datasets (OccludedDuke, Partial-REID, and Occluded-ReID) and non-occluded datasets (Market-1501 and DukeMTMC-reID) validate the effectiveness of our method. The code will be available soon. ",
    "url": "https://arxiv.org/abs/2210.05438",
    "authors": [
      "Zi wang",
      "Huaibo Huang",
      "Aihua Zheng",
      "Chenglong Li",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05478",
    "title": "Aggregating Layers for Deepfake Detection",
    "abstract": "The increasing popularity of facial manipulation (Deepfakes) and synthetic face creation raises the need to develop robust forgery detection solutions. Crucially, most work in this domain assume that the Deepfakes in the test set come from the same Deepfake algorithms that were used for training the network. This is not how things work in practice. Instead, we consider the case where the network is trained on one Deepfake algorithm, and tested on Deepfakes generated by another algorithm. Typically, supervised techniques follow a pipeline of visual feature extraction from a deep backbone, followed by a binary classification head. Instead, our algorithm aggregates features extracted across all layers of one backbone network to detect a fake. We evaluate our approach on two domains of interest - Deepfake detection and Synthetic image detection, and find that we achieve SOTA results. ",
    "url": "https://arxiv.org/abs/2210.05478",
    "authors": [
      "Amir Jevnisek",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05479",
    "title": "Frequency-Aware Self-Supervised Monocular Depth Estimation",
    "abstract": "We present two versatile methods to generally enhance self-supervised monocular depth estimation (MDE) models. The high generalizability of our methods is achieved by solving the fundamental and ubiquitous problems in photometric loss function. In particular, from the perspective of spatial frequency, we first propose Ambiguity-Masking to suppress the incorrect supervision under photometric loss at specific object boundaries, the cause of which could be traced to pixel-level ambiguity. Second, we present a novel frequency-adaptive Gaussian low-pass filter, designed to robustify the photometric loss in high-frequency regions. We are the first to propose blurring images to improve depth estimators with an interpretable analysis. Both modules are lightweight, adding no parameters and no need to manually change the network structures. Experiments show that our methods provide performance boosts to a large number of existing models, including those who claimed state-of-the-art, while introducing no extra inference computation at all. ",
    "url": "https://arxiv.org/abs/2210.05479",
    "authors": [
      "Xingyu Chen",
      "Thomas H. Li",
      "Ruonan Zhang",
      "Ge Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05482",
    "title": "Descriptive complexity of the generalized spectra of graphs",
    "abstract": "Two graphs are cospectral if their respective adjacency matrices have the same multiset of eigenvalues, and generalized cospectral if they are cospectral and so are their complements. We study generalized cospectrality in relation to logical definability. We show that any pair of graphs that are elementary equivalent with respect to the three-variable counting first-order logic $C^3$ are generalized cospectral, and this is not the case with $C^2$, nor with any number of variables if we exclude counting quantifiers. Using this result we provide a new characterization of the well-known class of distance-regular graphs using the logic $C^3$. We also show that, for controllable graphs (it is known that almost all graphs are controllable), the elementary equivalence in $C^2$ coincides with isomorphism. ",
    "url": "https://arxiv.org/abs/2210.05482",
    "authors": [
      "Aida Abiad",
      "Anuj Dawar",
      "Octavio Zapata"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.05484",
    "title": "Architectural Optimization over Subgroups for Equivariant Neural  Networks",
    "abstract": "Incorporating equivariance to symmetry groups as a constraint during neural network training can improve performance and generalization for tasks exhibiting those symmetries, but such symmetries are often not perfectly nor explicitly present. This motivates algorithmically optimizing the architectural constraints imposed by equivariance. We propose the equivariance relaxation morphism, which preserves functionality while reparameterizing a group equivariant layer to operate with equivariance constraints on a subgroup, as well as the $[G]$-mixed equivariant layer, which mixes layers constrained to different groups to enable within-layer equivariance optimization. We further present evolutionary and differentiable neural architecture search (NAS) algorithms that utilize these mechanisms respectively for equivariance-aware architectural optimization. Experiments across a variety of datasets show the benefit of dynamically constrained equivariance to find effective architectures with approximate equivariance. ",
    "url": "https://arxiv.org/abs/2210.05484",
    "authors": [
      "Kaitlin Maile",
      "Dennis G. Wilson",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05495",
    "title": "MAgNet: Mesh Agnostic Neural PDE Solver",
    "abstract": "The computational complexity of classical numerical methods for solving Partial Differential Equations (PDE) scales significantly as the resolution increases. As an important example, climate predictions require fine spatio-temporal resolutions to resolve all turbulent scales in the fluid simulations. This makes the task of accurately resolving these scales computationally out of reach even with modern supercomputers. As a result, current numerical modelers solve PDEs on grids that are too coarse (3km to 200km on each side), which hinders the accuracy and usefulness of the predictions. In this paper, we leverage the recent advances in Implicit Neural Representations (INR) to design a novel architecture that predicts the spatially continuous solution of a PDE given a spatial position query. By augmenting coordinate-based architectures with Graph Neural Networks (GNN), we enable zero-shot generalization to new non-uniform meshes and long-term predictions up to 250 frames ahead that are physically consistent. Our Mesh Agnostic Neural PDE Solver (MAgNet) is able to make accurate predictions across a variety of PDE simulation datasets and compares favorably with existing baselines. Moreover, MAgNet generalizes well to different meshes and resolutions up to four times those trained on. ",
    "url": "https://arxiv.org/abs/2210.05495",
    "authors": [
      "Oussama Boussif",
      "Dan Assouline",
      "Loubna Benabbou",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2210.05498",
    "title": "Adversarial Contrastive Learning for Evidence-aware Fake News Detection  with Graph Neural Networks",
    "abstract": "The prevalence and perniciousness of fake news have been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on attention mechanisms. Despite their effectiveness, they still suffer from three weaknesses. Firstly, sequential models fail to integrate the relevant information that is scattered far apart in evidences. Secondly, they underestimate much redundant information in evidences may be useless or harmful. Thirdly, insufficient data utilization limits the separability and reliability of representations captured by the model. To solve these problems, we propose a unified Graph-based sEmantic structure mining framework with ConTRAstive Learning, namely GETRAL in short. Specifically, we first model claims and evidences as graph-structured data to capture the long-distance semantic dependency. Consequently, we reduce information redundancy by performing graph structure learning. Then the fine-grained semantic representations are fed into the claim-evidence interaction module for predictions. Finally, an adversarial contrastive learning module is applied to make full use of data and strengthen representation learning. Comprehensive experiments have demonstrated the superiority of GETRAL over the state-of-the-arts and validated the efficacy of semantic mining with graph structure and contrastive learning. ",
    "url": "https://arxiv.org/abs/2210.05498",
    "authors": [
      "Junfei Wu",
      "Weizhi Xu",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05499",
    "title": "Capturing Global Structural Information in Long Document Question  Answering with Compressive Graph Selector Network",
    "abstract": "Long document question answering is a challenging task due to its demands for complex reasoning over long text. Previous works usually take long documents as non-structured flat texts or only consider the local structure in long documents. However, these methods usually ignore the global structure of the long document, which is essential for long-range understanding. To tackle this problem, we propose Compressive Graph Selector Network (CGSN) to capture the global structure in a compressive and iterative manner. Specifically, the proposed model consists of three modules: local graph network, global graph network and evidence memory network. Firstly, the local graph network builds the graph structure of the chunked segment in token, sentence, paragraph and segment levels to capture the short-term dependency of the text. Secondly, the global graph network selectively receives the information of each level from the local graph, compresses them into the global graph nodes and applies graph attention into the global graph nodes to build the long-range reasoning over the entire text in an iterative way. Thirdly, the evidence memory network is designed to alleviate the redundancy problem in the evidence selection via saving the selected result in the previous steps. Extensive experiments show that the proposed model outperforms previous methods on two datasets. ",
    "url": "https://arxiv.org/abs/2210.05499",
    "authors": [
      "Yuxiang Nie",
      "Heyan Huang",
      "Wei Wei",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05506",
    "title": "Extracting Meaningful Attention on Source Code: An Empirical Study of  Developer and Neural Model Code Exploration",
    "abstract": "The high effectiveness of neural models of code, such as OpenAI Codex and AlphaCode, suggests coding capabilities of models that are at least comparable to those of humans. However, previous work has only used these models for their raw completion, ignoring how the model reasoning, in the form of attention weights, can be used for other downstream tasks. Disregarding the attention weights means discarding a considerable portion of what those models compute when queried. To profit more from the knowledge embedded in these large pre-trained models, this work compares multiple approaches to post-process these valuable attention weights for supporting code exploration. Specifically, we compare to which extent the transformed attention signal of CodeGen, a large and publicly available pretrained neural model, agrees with how developers look at and explore code when each answering the same sense-making questions about code. At the core of our experimental evaluation, we collect, manually annotate, and open-source a novel eye-tracking dataset comprising 25 developers answering sense-making questions on code over 92 sessions. We empirically evaluate five attention-agnostic heuristics and ten attention-based post processing approaches of the attention signal against our ground truth of developers exploring code, including the novel concept of follow-up attention which exhibits the highest agreement. Beyond the dataset contribution and the empirical study, we also introduce a novel practical application of the attention signal of pre-trained models with completely analytical solutions, going beyond how neural models' attention mechanisms have traditionally been used. ",
    "url": "https://arxiv.org/abs/2210.05506",
    "authors": [
      "Matteo Paltenghi",
      "Rahul Pandita",
      "Austin Z. Henley",
      "Albert Ziegler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.05509",
    "title": "Finding the global semantic representation in GAN through Frechet Mean",
    "abstract": "The ideally disentangled latent space in GAN involves the global representation of latent space using semantic attribute coordinates. In other words, in this disentangled space, there exists the global semantic basis as a vector space where each basis component describes one attribute of generated images. In this paper, we propose an unsupervised method for finding this global semantic basis in the intermediate latent space in GANs. This semantic basis represents sample-independent meaningful perturbations that change the same semantic attribute of an image on the entire latent space. The proposed global basis, called Fr\\'echet basis, is derived by introducing Fr\\'echet mean to the local semantic perturbations in a latent space. Fr\\'echet basis is discovered in two stages. First, the global semantic subspace is discovered by the Fr\\'echet mean in the Grassmannian manifold of the local semantic subspaces. Second, Fr\\'echet basis is found by optimizing a basis of the semantic subspace via the Fr\\'echet mean in the Special Orthogonal Group. Experimental results demonstrate that Fr\\'echet basis provides better semantic factorization and robustness compared to the previous methods. Moreover, we suggest the basis refinement scheme for the previous methods. The quantitative experiments show that the refined basis achieves better semantic factorization while generating the same semantic subspace as the previous method. ",
    "url": "https://arxiv.org/abs/2210.05509",
    "authors": [
      "Jaewoong Choi",
      "Geonho Hwang",
      "Hyunsoo Cho",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05513",
    "title": "ViFiCon: Vision and Wireless Association Via Self-Supervised Contrastive  Learning",
    "abstract": "We introduce ViFiCon, a self-supervised contrastive learning scheme which uses synchronized information across vision and wireless modalities to perform cross-modal association. Specifically, the system uses pedestrian data collected from RGB-D camera footage as well as WiFi Fine Time Measurements (FTM) from a user's smartphone device. We represent the temporal sequence by stacking multi-person depth data spatially within a banded image. Depth data from RGB-D (vision domain) is inherently linked with an observable pedestrian, but FTM data (wireless domain) is associated only to a smartphone on the network. To formulate the cross-modal association problem as self-supervised, the network learns a scene-wide synchronization of the two modalities as a pretext task, and then uses that learned representation for the downstream task of associating individual bounding boxes to specific smartphones, i.e. associating vision and wireless information. We use a pre-trained region proposal model on the camera footage and then feed the extrapolated bounding box information into a dual-branch convolutional neural network along with the FTM data. We show that compared to fully supervised SoTA models, ViFiCon achieves high performance vision-to-wireless association, finding which bounding box corresponds to which smartphone device, without hand-labeled association examples for training data. ",
    "url": "https://arxiv.org/abs/2210.05513",
    "authors": [
      "Nicholas Meegan",
      "Hansi Liu",
      "Bryan Cao",
      "Abrar Alali",
      "Kristin Dana",
      "Marco Gruteser",
      "Shubham Jain",
      "Ashwin Ashok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05517",
    "title": "DeepMLE: A Robust Deep Maximum Likelihood Estimator for Two-view  Structure from Motion",
    "abstract": "Two-view structure from motion (SfM) is the cornerstone of 3D reconstruction and visual SLAM (vSLAM). Many existing end-to-end learning-based methods usually formulate it as a brute regression problem. However, the inadequate utilization of traditional geometry model makes the model not robust in unseen environments. To improve the generalization capability and robustness of end-to-end two-view SfM network, we formulate the two-view SfM problem as a maximum likelihood estimation (MLE) and solve it with the proposed framework, denoted as DeepMLE. First, we propose to take the deep multi-scale correlation maps to depict the visual similarities of 2D image matches decided by ego-motion. In addition, in order to increase the robustness of our framework, we formulate the likelihood function of the correlations of 2D image matches as a Gaussian and Uniform mixture distribution which takes the uncertainty caused by illumination changes, image noise and moving objects into account. Meanwhile, an uncertainty prediction module is presented to predict the pixel-wise distribution parameters. Finally, we iteratively refine the depth and relative camera pose using the gradient-like information to maximize the likelihood function of the correlations. Extensive experimental results on several datasets prove that our method significantly outperforms the state-of-the-art end-to-end two-view SfM approaches in accuracy and generalization capability. ",
    "url": "https://arxiv.org/abs/2210.05517",
    "authors": [
      "Yuxi Xiao",
      "Li Li",
      "Xiaodi Li",
      "Jian Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05519",
    "title": "Robust and Controllable Object-Centric Learning through Energy-based  Models",
    "abstract": "Humans are remarkably good at understanding and reasoning about complex visual scenes. The capability to decompose low-level observations into discrete objects allows us to build a grounded abstract representation and identify the compositional structure of the world. Accordingly, it is a crucial step for machine learning models to be capable of inferring objects and their properties from visual scenes without explicit supervision. However, existing works on object-centric representation learning either rely on tailor-made neural network modules or strong probabilistic assumptions in the underlying generative and inference processes. In this work, we present \\ours, a conceptually simple and general approach to learning object-centric representations through an energy-based model. By forming a permutation-invariant energy function using vanilla attention blocks readily available in Transformers, we can infer object-centric latent variables via gradient-based MCMC methods where permutation equivariance is automatically guaranteed. We show that \\ours can be easily integrated into existing architectures and can effectively extract high-quality object-centric representations, leading to better segmentation accuracy and competitive downstream task performance. Further, empirical evaluations show that \\ours's learned representations are robust against distribution shift. Finally, we demonstrate the effectiveness of \\ours in systematic compositional generalization, by re-composing learned energy functions for novel scene generation and manipulation. ",
    "url": "https://arxiv.org/abs/2210.05519",
    "authors": [
      "Ruixiang Zhang",
      "Tong Che",
      "Boris Ivanovic",
      "Renhao Wang",
      "Marco Pavone",
      "Yoshua Bengio",
      "Liam Paull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05546",
    "title": "What does a deep neural network confidently perceive? The effective  dimension of high certainty class manifolds and their low confidence  boundaries",
    "abstract": "Deep neural network classifiers partition input space into high confidence regions for each class. The geometry of these class manifolds (CMs) is widely studied and intimately related to model performance; for example, the margin depends on CM boundaries. We exploit the notions of Gaussian width and Gordon's escape theorem to tractably estimate the effective dimension of CMs and their boundaries through tomographic intersections with random affine subspaces of varying dimension. We show several connections between the dimension of CMs, generalization, and robustness. In particular we investigate how CM dimension depends on 1) the dataset, 2) architecture (including ResNet, WideResNet \\& Vision Transformer), 3) initialization, 4) stage of training, 5) class, 6) network width, 7) ensemble size, 8) label randomization, 9) training set size, and 10) robustness to data corruption. Together a picture emerges that higher performing and more robust models have higher dimensional CMs. Moreover, we offer a new perspective on ensembling via intersections of CMs. Our code is at https://github.com/stanislavfort/slice-dice-optimize/ ",
    "url": "https://arxiv.org/abs/2210.05546",
    "authors": [
      "Stanislav Fort",
      "Ekin Dogus Cubuk",
      "Surya Ganguli",
      "Samuel S. Schoenholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05557",
    "title": "OPERA: Omni-Supervised Representation Learning with Hierarchical  Supervisions",
    "abstract": "The pretrain-finetune paradigm in modern computer vision facilitates the success of self-supervised learning, which tends to achieve better transferability than supervised learning. However, with the availability of massive labeled data, a natural question emerges: how to train a better model with both self and full supervision signals? In this paper, we propose Omni-suPErvised Representation leArning with hierarchical supervisions (OPERA) as a solution. We provide a unified perspective of supervisions from labeled and unlabeled data and propose a unified framework of fully supervised and self-supervised learning. We extract a set of hierarchical proxy representations for each image and impose self and full supervisions on the corresponding proxy representations. Extensive experiments on both convolutional neural networks and vision transformers demonstrate the superiority of OPERA in image classification, segmentation, and object detection. Code is available at: https://github.com/wangck20/OPERA. ",
    "url": "https://arxiv.org/abs/2210.05557",
    "authors": [
      "Chengkun Wang",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05564",
    "title": "Hypergraph Convolutional Networks for Weakly-Supervised Semantic  Segmentation",
    "abstract": "Semantic segmentation is a fundamental topic in computer vision. Several deep learning methods have been proposed for semantic segmentation with outstanding results. However, these models require a lot of densely annotated images. To address this problem, we propose a new algorithm that uses HyperGraph Convolutional Networks for Weakly-supervised Semantic Segmentation (HyperGCN-WSS). Our algorithm constructs spatial and k-Nearest Neighbor (k-NN) graphs from the images in the dataset to generate the hypergraphs. Then, we train a specialized HyperGraph Convolutional Network (HyperGCN) architecture using some weak signals. The outputs of the HyperGCN are denominated pseudo-labels, which are later used to train a DeepLab model for semantic segmentation. HyperGCN-WSS is evaluated on the PASCAL VOC 2012 dataset for semantic segmentation, using scribbles or clicks as weak signals. Our algorithm shows competitive performance against previous methods. ",
    "url": "https://arxiv.org/abs/2210.05564",
    "authors": [
      "Jhony H. Giraldo",
      "Vincenzo Scarrica",
      "Antonino Staiano",
      "Francesco Camastra",
      "Thierry Bouwmans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05567",
    "title": "Global Spectral Filter Memory Network for Video Object Segmentation",
    "abstract": "This paper studies semi-supervised video object segmentation through boosting intra-frame interaction. Recent memory network-based methods focus on exploiting inter-frame temporal reference while paying little attention to intra-frame spatial dependency. Specifically, these segmentation model tends to be susceptible to interference from unrelated nontarget objects in a certain frame. To this end, we propose Global Spectral Filter Memory network (GSFM), which improves intra-frame interaction through learning long-term spatial dependencies in the spectral domain. The key components of GSFM is 2D (inverse) discrete Fourier transform for spatial information mixing. Besides, we empirically find low frequency feature should be enhanced in encoder (backbone) while high frequency for decoder (segmentation head). We attribute this to semantic information extracting role for encoder and fine-grained details highlighting role for decoder. Thus, Low (High) Frequency Module is proposed to fit this circumstance. Extensive experiments on the popular DAVIS and YouTube-VOS benchmarks demonstrate that GSFM noticeably outperforms the baseline method and achieves state-of-the-art performance. Besides, extensive analysis shows that the proposed modules are reasonable and of great generalization ability. Our source code is available at https://github.com/workforai/GSFM. ",
    "url": "https://arxiv.org/abs/2210.05567",
    "authors": [
      "Yong Liu",
      "Ran Yu",
      "Jiahao Wang",
      "Xinyuan Zhao",
      "Yitong Wang",
      "Yansong Tang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05568",
    "title": "Improving Long-tailed Object Detection with Image-Level Supervision by  Multi-Task Collaborative Learning",
    "abstract": "Data in real-world object detection often exhibits the long-tailed distribution. Existing solutions tackle this problem by mitigating the competition between the head and tail categories. However, due to the scarcity of training samples, tail categories are still unable to learn discriminative representations. Bringing more data into the training may alleviate the problem, but collecting instance-level annotations is an excruciating task. In contrast, image-level annotations are easily accessible but not fully exploited. In this paper, we propose a novel framework CLIS (multi-task Collaborative Learning with Image-level Supervision), which leverage image-level supervision to enhance the detection ability in a multi-task collaborative way. Specifically, there are an object detection task (consisting of an instance-classification task and a localization task) and an image-classification task in our framework, responsible for utilizing the two types of supervision. Different tasks are trained collaboratively by three key designs: (1) task-specialized sub-networks that learn specific representations of different tasks without feature entanglement. (2) a siamese sub-network for the image-classification task that shares its knowledge with the instance-classification task, resulting in feature enrichment of detectors. (3) a contrastive learning regularization that maintains representation consistency, bridging feature gaps of different supervision. Extensive experiments are conducted on the challenging LVIS dataset. Without sophisticated loss engineering, CLIS achieves an overall AP of 31.1 with 10.1 point improvement on tail categories, establishing a new state-of-the-art. Code will be at https://github.com/waveboo/CLIS. ",
    "url": "https://arxiv.org/abs/2210.05568",
    "authors": [
      "Bo Li",
      "Yongqiang Yao",
      "Jingru Tan",
      "Xin Lu",
      "Fengwei Yu",
      "Ye Luo",
      "Jianwei Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05574",
    "title": "Motion Aware Self-Supervision for Generic Event Boundary Detection",
    "abstract": "The task of Generic Event Boundary Detection (GEBD) aims to detect moments in videos that are naturally perceived by humans as generic and taxonomy-free event boundaries. Modeling the dynamically evolving temporal and spatial changes in a video makes GEBD a difficult problem to solve. Existing approaches involve very complex and sophisticated pipelines in terms of architectural design choices, hence creating a need for more straightforward and simplified approaches. In this work, we address this issue by revisiting a simple and effective self-supervised method and augment it with a differentiable motion feature learning module to tackle the spatial and temporal diversities in the GEBD task. We perform extensive experiments on the challenging Kinetics-GEBD and TAPOS datasets to demonstrate the efficacy of the proposed approach compared to the other self-supervised state-of-the-art methods. We also show that this simple self-supervised approach learns motion features without any explicit motion-specific pretext task. ",
    "url": "https://arxiv.org/abs/2210.05574",
    "authors": [
      "Ayush K. Rai",
      "Tarun Krishna",
      "Julia Dietlmeier",
      "Kevin McGuinness",
      "Alan F. Smeaton",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05577",
    "title": "What Can the Neural Tangent Kernel Tell Us About Adversarial Robustness?",
    "abstract": "The adversarial vulnerability of neural nets, and subsequent techniques to create robust models have attracted significant attention; yet we still lack a full understanding of this phenomenon. Here, we study adversarial examples of trained neural networks through analytical tools afforded by recent theory advances connecting neural networks and kernel methods, namely the Neural Tangent Kernel (NTK), following a growing body of work that leverages the NTK approximation to successfully analyze important deep learning phenomena and design algorithms for new applications. We show how NTKs allow to generate adversarial examples in a ``training-free'' fashion, and demonstrate that they transfer to fool their finite-width neural net counterparts in the ``lazy'' regime. We leverage this connection to provide an alternative view on robust and non-robust features, which have been suggested to underlie the adversarial brittleness of neural nets. Specifically, we define and study features induced by the eigendecomposition of the kernel to better understand the role of robust and non-robust features, the reliance on both for standard classification and the robustness-accuracy trade-off. We find that such features are surprisingly consistent across architectures, and that robust features tend to correspond to the largest eigenvalues of the model, and thus are learned early during training. Our framework allows us to identify and visualize non-robust yet useful features. Finally, we shed light on the robustness mechanism underlying adversarial training of neural nets used in practice: quantifying the evolution of the associated empirical NTK, we demonstrate that its dynamics falls much earlier into the ``lazy'' regime and manifests a much stronger form of the well known bias to prioritize learning features within the top eigenspaces of the kernel, compared to standard training. ",
    "url": "https://arxiv.org/abs/2210.05577",
    "authors": [
      "Nikolaos Tsilivis",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05593",
    "title": "Prototypical VoteNet for Few-Shot 3D Point Cloud Object Detection",
    "abstract": "Most existing 3D point cloud object detection approaches heavily rely on large amounts of labeled training data. However, the labeling process is costly and time-consuming. This paper considers few-shot 3D point cloud object detection, where only a few annotated samples of novel classes are needed with abundant samples of base classes. To this end, we propose Prototypical VoteNet to recognize and localize novel instances, which incorporates two new modules: Prototypical Vote Module (PVM) and Prototypical Head Module (PHM). Specifically, as the 3D basic geometric structures can be shared among categories, PVM is designed to leverage class-agnostic geometric prototypes, which are learned from base classes, to refine local features of novel categories.Then PHM is proposed to utilize class prototypes to enhance the global feature of each object, facilitating subsequent object localization and classification, which is trained by the episodic training strategy. To evaluate the model in this new setting, we contribute two new benchmark datasets, FS-ScanNet and FS-SUNRGBD. We conduct extensive experiments to demonstrate the effectiveness of Prototypical VoteNet, and our proposed method shows significant and consistent improvements compared to baselines on two benchmark datasets. ",
    "url": "https://arxiv.org/abs/2210.05593",
    "authors": [
      "Shizhen Zhao",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05596",
    "title": "Geometry of Radial Basis Neural Networks for Safety Biased Approximation  of Unsafe Regions",
    "abstract": "Barrier function-based inequality constraints are a means to enforce safety specifications for control systems. When used in conjunction with a convex optimization program, they provide a computationally efficient method to enforce safety for the general class of control-affine systems. One of the main assumptions when taking this approach is the a priori knowledge of the barrier function itself, i.e., knowledge of the safe set. In the context of navigation through unknown environments where the locally safe set evolves with time, such knowledge does not exist. This manuscript focuses on the synthesis of a zeroing barrier function characterizing the safe set based on safe and unsafe sample measurements, e.g., from perception data in navigation applications. Prior work formulated a supervised machine learning algorithm whose solution guaranteed the construction of a zeroing barrier function with specific level-set properties. However, it did not explore the geometry of the neural network design used for the synthesis process. This manuscript describes the specific geometry of the neural network used for zeroing barrier function synthesis, and shows how the network provides the necessary representation for splitting the state space into safe and unsafe regions. ",
    "url": "https://arxiv.org/abs/2210.05596",
    "authors": [
      "Ahmad Abuaish",
      "Mohit Srinivasan",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05600",
    "title": "Observability Analysis of Graph SLAM-Based Joint Calibration of Multiple  Microphone Arrays and Sound Source Localization",
    "abstract": "Multiple microphone arrays have many applications in robot audition, including sound source localization, audio scene perception and analysis, etc. However, accurate calibration of multiple microphone arrays remains a challenge because there are many unknown parameters to be identified, including the Euler angles, geometry, asynchronous factors between the microphone arrays. This paper is concerned with joint calibration of multiple microphone arrays and sound source localization using graph simultaneous localization and mapping (SLAM). By using a Fisher information matrix (FIM) approach, we focus on the observability analysis of the graph SLAM framework for the above-mentioned calibration problem. We thoroughly investigate the identifiability of the unknown parameters, including the Euler angles, geometry, asynchronous effects between the microphone arrays, and the sound source locations. We establish necessary/sufficient conditions under which the FIM and the Jacobian matrix have full column rank, which implies the identifiability of the unknown parameters. These conditions are closely related to the variation in the motion of the sound source and the configuration of microphone arrays, and have intuitive and physical interpretations. We also discover several scenarios where the unknown parameters are not uniquely identifiable. All theoretical findings are demonstrated using simulation data. ",
    "url": "https://arxiv.org/abs/2210.05600",
    "authors": [
      "Yuanzheng He",
      "Jiang Wang",
      "Daobilige Su",
      "Kazuhiro Nakadai",
      "Junfeng Wu",
      "Shoudong Huang",
      "Youfu Li",
      "He Kong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05616",
    "title": "Neural Shape Deformation Priors",
    "abstract": "We present Neural Shape Deformation Priors, a novel method for shape manipulation that predicts mesh deformations of non-rigid objects from user-provided handle movements. State-of-the-art methods cast this problem as an optimization task, where the input source mesh is iteratively deformed to minimize an objective function according to hand-crafted regularizers such as ARAP. In this work, we learn the deformation behavior based on the underlying geometric properties of a shape, while leveraging a large-scale dataset containing a diverse set of non-rigid deformations. Specifically, given a source mesh and desired target locations of handles that describe the partial surface deformation, we predict a continuous deformation field that is defined in 3D space to describe the space deformation. To this end, we introduce transformer-based deformation networks that represent a shape deformation as a composition of local surface deformations. It learns a set of local latent codes anchored in 3D space, from which we can learn a set of continuous deformation functions for local surfaces. Our method can be applied to challenging deformations and generalizes well to unseen deformations. We validate our approach in experiments using the DeformingThing4D dataset, and compare to both classic optimization-based and recent neural network-based methods. ",
    "url": "https://arxiv.org/abs/2210.05616",
    "authors": [
      "Jiapeng Tang",
      "Lev Markhasin",
      "Bi Wang",
      "Justus Thies",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05623",
    "title": "A Formal Assisted Approach for Modeling and Testing Security Attacks in  IoT Edge Devices",
    "abstract": "With the rapid growth in the number of IoT devices being added to the network, a major concern that arises is the security of these systems. As these devices are resource constrained, safety measures are difficult to implement on the edge. We propose a novel approach for the detection of IoT device attacks based on the use of formal modeling and mutation testing. Namely, we model the behavior of small IoT devices such as motion sensors and RFID reader as state machines with timeouts. We also model basic IoT attacks; namely, battery draining, sleep deprivation, data falsification, replay, and man in the middle attacks, as special mutants of these specifications. We also consider tests for detecting actual physical device manipulation. Mutation testing is then used to derive tests that distinguish these attacks from the original specifications. The behavior of these mutants is tested in real environment by running the tests on them. Our experiments show that derived the number of attack mutants and tests is small and thus these tests can be executed many times with limited overhead on the physical device. Consequently, our approach is not deterred by related high costs of traditional mutation testing. In addition, we also show that tests derived by our method which cover all IoT attacks do not provide good coverage of mutants derived using traditional mutation code-based operators and this indicates the need of using our method. A framework that implements our approach is presented along with some other relevant case studies. ",
    "url": "https://arxiv.org/abs/2210.05623",
    "authors": [
      "A. Bhanpurawala",
      "K. El-Fakih",
      "I. Zualkernan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.05664",
    "title": "Social Influence Dialogue Systems: A Scoping Survey of the Efforts  Towards Influence Capabilities of Dialogue Systems",
    "abstract": "Dialogue systems capable of social influence such as persuasion, negotiation, and therapy, are essential for extending the use of technology to numerous realistic scenarios. However, existing research primarily focuses on either task-oriented or open-domain scenarios, a categorization that has been inadequate for capturing influence skills systematically. There exists no formal definition or category for dialogue systems with these skills and data-driven efforts in this direction are highly limited. In this work, we formally define and introduce the category of \\emph{social influence dialogue systems} that influence users' cognitive and emotional responses, leading to changes in thoughts, opinions, and behaviors through natural conversations. We present a survey of various tasks, datasets, and methods, compiling the progress across seven diverse domains. We discuss the commonalities and differences between the examined systems, identify limitations, and recommend future directions. This study serves as a comprehensive reference for social influence dialogue systems to inspire more dedicated research and discussion in this emerging area. ",
    "url": "https://arxiv.org/abs/2210.05664",
    "authors": [
      "Kushal Chawla",
      "Weiyan Shi",
      "Jingwen Zhang",
      "Gale Lucas",
      "Zhou Yu",
      "Jonathan Gratch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05667",
    "title": "Human Body Measurement Estimation with Adversarial Augmentation",
    "abstract": "We present a Body Measurement network (BMnet) for estimating 3D anthropomorphic measurements of the human body shape from silhouette images. Training of BMnet is performed on data from real human subjects, and augmented with a novel adversarial body simulator (ABS) that finds and synthesizes challenging body shapes. ABS is based on the skinned multiperson linear (SMPL) body model, and aims to maximize BMnet measurement prediction error with respect to latent SMPL shape parameters. ABS is fully differentiable with respect to these parameters, and trained end-to-end via backpropagation with BMnet in the loop. Experiments show that ABS effectively discovers adversarial examples, such as bodies with extreme body mass indices (BMI), consistent with the rarity of extreme-BMI bodies in BMnet's training set. Thus ABS is able to reveal gaps in training data and potential failures in predicting under-represented body shapes. Results show that training BMnet with ABS improves measurement prediction accuracy on real bodies by up to 10%, when compared to no augmentation or random body shape sampling. Furthermore, our method significantly outperforms SOTA measurement estimation methods by as much as 3x. Finally, we release BodyM, the first challenging, large-scale dataset of photo silhouettes and body measurements of real human subjects, to further promote research in this area. Project website: https://adversarialbodysim.github.io ",
    "url": "https://arxiv.org/abs/2210.05667",
    "authors": [
      "Nataniel Ruiz",
      "Miriam Bellver",
      "Timo Bolkart",
      "Ambuj Arora",
      "Ming C. Lin",
      "Javier Romero",
      "Raja Bala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05669",
    "title": "A generic diffusion-based approach for 3D human pose prediction in the  wild",
    "abstract": "3D human pose forecasting, i.e., predicting a sequence of future human 3D poses given a sequence of past observed ones, is a challenging spatio-temporal task. It can be more challenging in real-world applications where occlusions will inevitably happen, and estimated 3D coordinates of joints would contain some noise. We provide a unified formulation in which incomplete elements (no matter in the prediction or observation) are treated as noise and propose a conditional diffusion model that denoises them and forecasts plausible poses. Instead of naively predicting all future frames at once, our model consists of two cascaded sub-models, each specialized for modeling short and long horizon distributions. We also propose a generic framework to improve any 3D pose forecasting model by leveraging our diffusion model in two additional steps: a pre-processing step to repair the inputs and a post-processing step to refine the outputs. We investigate our findings on four standard datasets (Human3.6M, HumanEva-I, AMASS, and 3DPW) and obtain significant improvements over the state-of-the-art. The code will be made available online. ",
    "url": "https://arxiv.org/abs/2210.05669",
    "authors": [
      "Saeed Saadatnejad",
      "Ali Rasekh",
      "Mohammadreza Mofayezi",
      "Yasamin Medghalchi",
      "Sara Rajabzadeh",
      "Taylor Mordan",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04898",
    "title": "Improving The Reconstruction Quality by Overfitted Decoder Bias in  Neural Image Compression",
    "abstract": "End-to-end trainable models have reached the performance of traditional handcrafted compression techniques on videos and images. Since the parameters of these models are learned over large training sets, they are not optimal for any given image to be compressed. In this paper, we propose an instance-based fine-tuning of a subset of decoder's bias to improve the reconstruction quality in exchange for extra encoding time and minor additional signaling cost. The proposed method is applicable to any end-to-end compression methods, improving the state-of-the-art neural image compression BD-rate by $3-5\\%$. ",
    "url": "https://arxiv.org/abs/2210.04898",
    "authors": [
      "Oussama Jourairi",
      "Muhammet Balcilar",
      "Anne Lambert",
      "Fran\u00e7ois Schnitzler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05051",
    "title": "Spreading Processes with Mutations over Multi-layer Networks",
    "abstract": "A key scientific challenge during the outbreak of novel infectious diseases is to predict how changes to the patterns of interaction in the host population (arising from different countermeasures) impact the spread of infection. Most epidemiological models do not consider the role of mutations in the pathogens or the heterogeneity in the type of contacts over which the infection propagates. However, pathogens often mutate in response to changing environments and medical interventions. Moreover, the spread of infectious diseases depends intimately on the structural properties of the contact network of the host population, e.g., different congregate settings such as schools and offices pose varying risks of transmission. In this work, we propose and analyze a multi-layer multi-strain model that more closely resembles real-world pandemics by simultaneously taking into account the multi-layer structure typical to human contact networks and mutations in the contagion. We derive the probability of emergence of an epidemic, the mean fraction of individuals infected with each strain, and the phase transition point beyond which an epidemic emerges. Our results highlight that existing models fail to fully characterize the epidemic outbreak caused by mutating pathogens on multi-layer contact networks. We demonstrate that the impact of imposing/lifting mitigation measures concerning different contact network layers (e.g., school closures or work-from-home policies) should be evaluated in connection with their impact on the likelihood of the emergence of new pathogen strains. Our work further reinforces the need to develop network-based epidemiological models that simultaneously account for the heterogeneity in the pathogen strains and network structure to better predict the course of the disease outbreak. ",
    "url": "https://arxiv.org/abs/2210.05051",
    "authors": [
      "Mansi Sood",
      "Anirudh Sridhar",
      "Rashad Eletreby",
      "Chai Wah Wu",
      "Simon A. Levin",
      "H. Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.05073",
    "title": "Self-supervised Model Based on Masked Autoencoders Advance CT Scans  Classification",
    "abstract": "The coronavirus pandemic has been going on since the year 2019, and the trend is still not abating. Therefore, it is particularly important to classify medical CT scans to assist in medical diagnosis. At present, Supervised Deep Learning algorithms have made a great success in the classification task of medical CT scans, but medical image datasets often require professional image annotation, and many research datasets are not publicly available. To solve this problem, this paper is inspired by the self-supervised learning algorithm MAE and uses the MAE model pre-trained on ImageNet to perform transfer learning on CT Scans dataset. This method improves the generalization performance of the model and avoids the risk of overfitting on small datasets. Through extensive experiments on the COVID-CT dataset and the SARS-CoV-2 dataset, we compare the SSL-based method in this paper with other state-of-the-art supervised learning-based pretraining methods. Experimental results show that our method improves the generalization performance of the model more effectively and avoids the risk of overfitting on small datasets. The model achieved almost the same accuracy as supervised learning on both test datasets. Finally, ablation experiments aim to fully demonstrate the effectiveness of our method and how it works. ",
    "url": "https://arxiv.org/abs/2210.05073",
    "authors": [
      "Jiashu Xu",
      "Sergii Stirenko"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05167",
    "title": "The Fast and Accurate Approach to Detection and Segmentation of Melanoma  Skin Cancer using Fine-tuned Yolov3 and SegNet Based on Deep Transfer  Learning",
    "abstract": "Melanoma is one of the most serious skin cancers that can occur in any part of the human skin. Early diagnosing melanoma lesions will significantly increase their chances of being cured. Improving melanoma segmentation will help doctors or surgical robots remove the lesion more accurately from body parts. Recently, the learning-based segmentation methods achieved desired results in image segmentation compared to traditional algorithms. This study proposes a new method to improve melanoma skin lesions detection and segmentation by defining a two-step pipeline based on deep learning models. Our methods were evaluated on ISIC 2018 (Skin Lesion Analysis Towards Melanoma Detection Challenge Dataset) well-known dataset. The proposed methods consist of two main parts for real-time detection of lesion location and segmentation. In the detection section, the location of the skin lesion is precisely detected by the fine-tuned You Only Look Once version 3 (F-YOLOv3) and then fed into the fine-tuned Segmentation Network (F-SegNet). Skin lesion localization helps to reduce the unnecessary calculation of whole images for segmentation. The results show that our proposed F-YOLOv3 achieves better performance as 96% in mAP. Compared to state-of-the-art segmentation approaches, our F-SegNet achieves higher performance for accuracy, dice coefficient, and Jaccard index at 95.16%, 92.81%, and 86.2%, respectively. ",
    "url": "https://arxiv.org/abs/2210.05167",
    "authors": [
      "Mohamad Taghizadeh",
      "Karim Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05354",
    "title": "Constructing Prediction Intervals with Neural Networks: An Empirical  Evaluation of Bootstrapping and Conformal Inference Methods",
    "abstract": "Artificial neural networks (ANNs) are popular tools for accomplishing many machine learning tasks, including predicting continuous outcomes. However, the general lack of confidence measures provided with ANN predictions limit their applicability. Supplementing point predictions with prediction intervals (PIs) is common for other learning algorithms, but the complex structure and training of ANNs renders constructing PIs difficult. This work provides the network design choices and inferential methods for creating better performing PIs with ANNs. A two-step experiment is executed across 11 data sets, including an imaged-based data set. Two distribution-free methods for constructing PIs, bootstrapping and conformal inference, are considered. The results of the first experimental step reveal that the choices inherent to building an ANN affect PI performance. Guidance is provided for optimizing PI performance with respect to each network feature and PI method. In the second step, 20 algorithms for constructing PIs, each using the principles of bootstrapping or conformal inference, are implemented to determine which provides the best performance while maintaining reasonable computational burden. In general, this trade-off is optimized when implementing the cross-conformal method, which maintained interval coverage and efficiency with decreased computational burden. ",
    "url": "https://arxiv.org/abs/2210.05354",
    "authors": [
      "Alex Contarino",
      "Christine Schubert Kabban",
      "Chancellor Johnstone",
      "Fairul Mohd-Zaid"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05439",
    "title": "Network Topology Inference based on Timing Meta-Data",
    "abstract": "Consider a processor having access only to meta-data consisting of the timings of data packets and acknowledgment (ACK) packets from all nodes in a network. The meta-data report the source node of each packet, but not the destination nodes or the contents of the packets. The goal of the processor is to infer the network topology based solely on such information. Prior work leveraged causality metrics to identify which links are active. If the data timings and ACK timings of two nodes -- say node 1 and node 2, respectively -- are causally related, this may be taken as evidence that node 1 is communicating to node 2 (which sends back ACK packets to node 1). This paper starts with the observation that packet losses can weaken the causality relationship between data and ACK timing streams. To obviate this problem, a new Expectation Maximization (EM)-based algorithm is introduced -- EM-causality discovery algorithm (EM-CDA) -- which treats packet losses as latent variables. EM-CDA iterates between the estimation of packet losses and the evaluation of causality metrics. The method is validated through extensive experiments in wireless sensor networks on the NS-3 simulation platform. ",
    "url": "https://arxiv.org/abs/2210.05439",
    "authors": [
      "Wenbo Du",
      "Tao Tan",
      "Haijun Zhang",
      "Xianbin Cao",
      "Gang Yan",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.05443",
    "title": "QuCNN : A Quantum Convolutional Neural Network with Entanglement Based  Backpropagation",
    "abstract": "Quantum Machine Learning continues to be a highly active area of interest within Quantum Computing. Many of these approaches have adapted classical approaches to the quantum settings, such as QuantumFlow, etc. We push forward this trend and demonstrate an adaption of the Classical Convolutional Neural Networks to quantum systems - namely QuCNN. QuCNN is a parameterised multi-quantum-state based neural network layer computing similarities between each quantum filter state and each quantum data state. With QuCNN, back propagation can be achieved through a single-ancilla qubit quantum routine. QuCNN is validated by applying a convolutional layer with a data state and a filter state over a small subset of MNIST images, comparing the back propagated gradients, and training a filter state against an ideal target state. ",
    "url": "https://arxiv.org/abs/2210.05443",
    "authors": [
      "Samuel A. Stein",
      "Ying Mao",
      "James Ang",
      "Ang Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05446",
    "title": "Disentangling Causal Effects from Sets of Interventions in the Presence  of Unobserved Confounders",
    "abstract": "The ability to answer causal questions is crucial in many domains, as causal inference allows one to understand the impact of interventions. In many applications, only a single intervention is possible at a given time. However, in some important areas, multiple interventions are concurrently applied. Disentangling the effects of single interventions from jointly applied interventions is a challenging task -- especially as simultaneously applied interventions can interact. This problem is made harder still by unobserved confounders, which influence both treatments and outcome. We address this challenge by aiming to learn the effect of a single-intervention from both observational data and sets of interventions. We prove that this is not generally possible, but provide identification proofs demonstrating that it can be achieved under non-linear continuous structural causal models with additive, multivariate Gaussian noise -- even when unobserved confounders are present. Importantly, we show how to incorporate observed covariates and learn heterogeneous treatment effects. Based on the identifiability proofs, we provide an algorithm that learns the causal model parameters by pooling data from different regimes and jointly maximizing the combined likelihood. The effectiveness of our method is empirically demonstrated on both synthetic and real-world data. ",
    "url": "https://arxiv.org/abs/2210.05446",
    "authors": [
      "Olivier Jeunen",
      "Ciar\u00e1n M. Gilligan-Lee",
      "Rishabh Mehrotra",
      "Mounia Lalmas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05454",
    "title": "Low Complexity Convolutional Neural Networks for Equalization in Optical  Fiber Transmission",
    "abstract": "A convolutional neural network is proposed to mitigate fiber transmission effects, achieving a five-fold reduction in trainable parameters compared to alternative equalizers, and 3.5 dB improvement in MSE compared to DBP with comparable complexity. ",
    "url": "https://arxiv.org/abs/2210.05454",
    "authors": [
      "Mohannad Abu-romoh",
      "Nelson Costa",
      "Antonio Napoli",
      "Jo\u00e3o Pedro",
      "Yves Jaou\u00ebn",
      "Mansoor Yousefi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05490",
    "title": "Pooling Strategies for Simplicial Convolutional Networks",
    "abstract": "The goal of this paper is to introduce pooling strategies for simplicial convolutional neural networks. Inspired by graph pooling methods, we introduce a general formulation for a simplicial pooling layer that performs: i) local aggregation of simplicial signals; ii) principled selection of sampling sets; iii) downsampling and simplicial topology adaptation. The general layer is then customized to design four different pooling strategies (i.e., max, top-k, self-attention, and separated top-k) grounded in the theory of topological signal processing. Also, we leverage the proposed layers in a hierarchical architecture that reduce complexity while representing data at different resolutions. Numerical results on real data benchmarks (i.e., flow and graph classification) illustrate the advantage of the proposed methods with respect to the state of the art. ",
    "url": "https://arxiv.org/abs/2210.05490",
    "authors": [
      "Domenico Mattia Cinque",
      "Claudio Battiloro",
      "Paolo Di Lorenzo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05558",
    "title": "Causal and counterfactual views of missing data models",
    "abstract": "It is often said that the fundamental problem of causal inference is a missing data problem -- the comparison of responses to two hypothetical treatment assignments is made difficult because for every experimental unit only one potential response is observed. In this paper, we consider the implications of the converse view: that missing data problems are a form of causal inference. We make explicit how the missing data problem of recovering the complete data law from the observed law can be viewed as identification of a joint distribution over counterfactual variables corresponding to values had we (possibly contrary to fact) been able to observe them. Drawing analogies with causal inference, we show how identification assumptions in missing data can be encoded in terms of graphical models defined over counterfactual and observed variables. We review recent results in missing data identification from this viewpoint. In doing so, we note interesting similarities and differences between missing data and causal identification theories. ",
    "url": "https://arxiv.org/abs/2210.05558",
    "authors": [
      "Razieh Nabi",
      "Rohit Bhattacharya",
      "Ilya Shpitser",
      "James Robins"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05630",
    "title": "EllipsoNet: Deep-learning-enabled optical ellipsometry for complex thin  films",
    "abstract": "Optical spectroscopy is indispensable for research and development in nanoscience and nanotechnology, microelectronics, energy, and advanced manufacturing. Advanced optical spectroscopy tools often require both specifically designed high-end instrumentation and intricate data analysis techniques. Beyond the common analytical tools, deep learning methods are well suited for interpreting high-dimensional and complicated spectroscopy data. They offer great opportunities to extract subtle and deep information about optical properties of materials with simpler optical setups, which would otherwise require sophisticated instrumentation. In this work, we propose a computational ellipsometry approach based on a conventional tabletop optical microscope and a deep learning model called EllipsoNet. Without any prior knowledge about the multilayer substrates, EllipsoNet can predict the complex refractive indices of thin films on top of these nontrivial substrates from experimentally measured optical reflectance spectra with high accuracies. This task was not feasible previously with traditional reflectometry or ellipsometry methods. Fundamental physical principles, such as the Kramers-Kronig relations, are spontaneously learned by the model without any further training. This approach enables in-operando optical characterization of functional materials within complex photonic structures or optoelectronic devices. ",
    "url": "https://arxiv.org/abs/2210.05630",
    "authors": [
      "Ziyang Wang",
      "Yuxuan Cosmi Lin",
      "Kunyan Zhang",
      "Wenjing Wu",
      "Shengxi Huang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2003.03007",
    "title": "Unifying Graph Embedding Features with Graph Convolutional Networks for  Skeleton-based Action Recognition",
    "abstract": " Title: Unifying Graph Embedding Features with Graph Convolutional Networks for  Skeleton-based Action Recognition ",
    "url": "https://arxiv.org/abs/2003.03007",
    "authors": [
      "Dong Yang",
      "Monica Mengqi Li",
      "Hong Fu",
      "Jicong Fan",
      "Zhao Zhang",
      "Howard Leung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2007.10785",
    "title": "Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review",
    "abstract": " Title: Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review ",
    "url": "https://arxiv.org/abs/2007.10785",
    "authors": [
      "Afshin Shoeibi",
      "Marjane Khodatars",
      "Roohallah Alizadehsani",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Ali Khadem",
      "Delaram Sadeghi",
      "Sadiq Hussain",
      "Assef Zare",
      "Zahra Alizadeh Sani",
      "Javad Bazeli",
      "Fahime Khozeimeh",
      "Abbas Khosravi",
      "Saeid Nahavandi",
      "U. Rajendra Acharya",
      "Juan M. Gorriz",
      "Peng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2008.05348",
    "title": "Approaching Neural Chinese Word Segmentation as a Low-Resource Machine  Translation Task",
    "abstract": " Comments: PACLIC 2022 ",
    "url": "https://arxiv.org/abs/2008.05348",
    "authors": [
      "Pinzhen Chen",
      "Kenneth Heafield"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2009.10939",
    "title": "Scene Graph to Image Generation with Contextualized Object Layout  Refinement",
    "abstract": " Comments: Appeared at IEEE International Conference in Image Processing (ICIP) 2021 ",
    "url": "https://arxiv.org/abs/2009.10939",
    "authors": [
      "Maor Ivgi",
      "Yaniv Benny",
      "Avichai Ben-David",
      "Jonathan Berant",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2010.07602",
    "title": "Vehicular Networks for Combating a Worldwide Pandemic: Preventing the  Spread of COVID-19",
    "abstract": " Comments: Accepted Paper in Smart Health ",
    "url": "https://arxiv.org/abs/2010.07602",
    "authors": [
      "Ahmet M. Elbir",
      "Gokhan Gurbilek",
      "Burak Soner",
      "Anastasios K. Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Sinem Coleri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2010.13735",
    "title": "Personalised Meta-path Generation for Heterogeneous GNNs",
    "abstract": " Title: Personalised Meta-path Generation for Heterogeneous GNNs ",
    "url": "https://arxiv.org/abs/2010.13735",
    "authors": [
      "Zhiqiang Zhong",
      "Cheng-Te Li",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2011.04590",
    "title": "From Eye-blinks to State Construction: Diagnostic Benchmarks for Online  Representation Learning",
    "abstract": " Title: From Eye-blinks to State Construction: Diagnostic Benchmarks for Online  Representation Learning ",
    "url": "https://arxiv.org/abs/2011.04590",
    "authors": [
      "Banafsheh Rafiee",
      "Zaheer Abbas",
      "Sina Ghiassian",
      "Raksha Kumaraswamy",
      "Richard Sutton",
      "Elliot Ludvig",
      "Adam White"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2012.01699",
    "title": "Content-Adaptive Pixel Discretization to Improve Model Robustness",
    "abstract": " Title: Content-Adaptive Pixel Discretization to Improve Model Robustness ",
    "url": "https://arxiv.org/abs/2012.01699",
    "authors": [
      "Ryan Feng",
      "Wu-chi Feng",
      "Atul Prakash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.06028",
    "title": "Synthesis of Winning Attacks on Communication Protocols using  Supervisory Control Theory: Two Case Studies",
    "abstract": " Comments: 31 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2102.06028",
    "authors": [
      "Shoma Matsui",
      "St\u00e9phane Lafortune"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2102.10423",
    "title": "An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks",
    "abstract": " Comments: 13 pages, 15 figures, 8 tables, published in IISWC 2022 ",
    "url": "https://arxiv.org/abs/2102.10423",
    "authors": [
      "Kiran Seshadri",
      "Berkin Akin",
      "James Laudon",
      "Ravi Narayanaswami",
      "Amir Yazdanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2104.08721",
    "title": "Embedding-Enhanced Giza++: Improving Alignment in Low- and High-  Resource Scenarios Using Embedding Space Geometry",
    "abstract": " Comments: AMTA2022 Camera Ready ",
    "url": "https://arxiv.org/abs/2104.08721",
    "authors": [
      "Kelly Marchisio",
      "Conghao Xiong",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.06715",
    "title": "Maximizing Mutual Information Across Feature and Topology Views for  Learning Graph Representations",
    "abstract": " Title: Maximizing Mutual Information Across Feature and Topology Views for  Learning Graph Representations ",
    "url": "https://arxiv.org/abs/2105.06715",
    "authors": [
      "Xiaolong Fan",
      "Maoguo Gong",
      "Yue Wu",
      "Hao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.09947",
    "title": "Indicators of Attack Failure: Debugging and Improving Optimization of  Adversarial Examples",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.09947",
    "authors": [
      "Maura Pintor",
      "Luca Demetrio",
      "Angelo Sotgiu",
      "Ambra Demontis",
      "Nicholas Carlini",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.15788",
    "title": "Exploring Localization for Self-supervised Fine-grained Contrastive  Learning",
    "abstract": " Comments: BMVC 2022 camera-ready. 15 pages (main) with 5 pages appendix ",
    "url": "https://arxiv.org/abs/2106.15788",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Zelin Zang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13767",
    "title": "Stochastic Discontinuous Galerkin Methods for Robust Deterministic  Control of Convection Diffusion Equations with Uncertain Coefficients",
    "abstract": " Comments: 41 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2108.13767",
    "authors": [
      "Pelin \u00c7ilo\u011flu",
      "Hamdullah Y\u00fccel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.09506",
    "title": "MEMO: Test Time Robustness via Adaptation and Augmentation",
    "abstract": " Comments: NeurIPS '22 camera ready. Code: this https URL ",
    "url": "https://arxiv.org/abs/2110.09506",
    "authors": [
      "Marvin Zhang",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.14553",
    "title": "GenURL: A General Framework for Unsupervised Representation Learning",
    "abstract": " Comments: Tech report (revision) with 14 pages and 7 figures ",
    "url": "https://arxiv.org/abs/2110.14553",
    "authors": [
      "Siyuan Li",
      "Zelin Zang",
      "Di Wu",
      "Zhiyuan Chen",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.07495",
    "title": "Distribution-Free Model for Community Detection",
    "abstract": " Comments: 21 pages, 9 figures, 1 table, comments are welcome ",
    "url": "https://arxiv.org/abs/2111.07495",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.10557",
    "title": "HybNet: A Hybrid Deep Learning -- Matched Filter Approach for IoT Signal  Detection",
    "abstract": " Title: HybNet: A Hybrid Deep Learning -- Matched Filter Approach for IoT Signal  Detection ",
    "url": "https://arxiv.org/abs/2111.10557",
    "authors": [
      "Kosta Dakic",
      "Bassel Al Homssi",
      "Margaret Lech",
      "Akram Al-Hourani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.11546",
    "title": "Lightweight Transformer Backbone for Medical Object Detection",
    "abstract": " Title: Lightweight Transformer Backbone for Medical Object Detection ",
    "url": "https://arxiv.org/abs/2111.11546",
    "authors": [
      "Yifan Zhang",
      "Haoyu Dong",
      "Nicholas Konz",
      "Hanxue Gu",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14552",
    "title": "Robust On-Policy Sampling for Data-Efficient Policy Evaluation in  Reinforcement Learning",
    "abstract": " Comments: Published in 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2111.14552",
    "authors": [
      "Rujie Zhong",
      "Duohan Zhang",
      "Lukas Sch\u00e4fer",
      "Stefano V. Albrecht",
      "Josiah P. Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02721",
    "title": "NL-Augmenter: A Framework for Task-Sensitive Natural Language  Augmentation",
    "abstract": " Comments: 39 pages, repository at this https URL ",
    "url": "https://arxiv.org/abs/2112.02721",
    "authors": [
      "Kaustubh D. Dhole",
      "Varun Gangal",
      "Sebastian Gehrmann",
      "Aadesh Gupta",
      "Zhenhao Li",
      "Saad Mahamood",
      "Abinaya Mahendiran",
      "Simon Mille",
      "Ashish Shrivastava",
      "Samson Tan",
      "Tongshuang Wu",
      "Jascha Sohl-Dickstein",
      "Jinho D. Choi",
      "Eduard Hovy",
      "Ondrej Dusek",
      "Sebastian Ruder",
      "Sajant Anand",
      "Nagender Aneja",
      "Rabin Banjade",
      "Lisa Barthe",
      "Hanna Behnke",
      "Ian Berlot-Attwell",
      "Connor Boyle",
      "Caroline Brun",
      "Marco Antonio Sobrevilla Cabezudo",
      "Samuel Cahyawijaya",
      "Emile Chapuis",
      "Wanxiang Che",
      "Mukund Choudhary",
      "Christian Clauss",
      "Pierre Colombo",
      "Filip Cornell",
      "Gautier Dagan",
      "Mayukh Das",
      "Tanay Dixit",
      "Thomas Dopierre",
      "Paul-Alexis Dray",
      "Suchitra Dubey",
      "Tatiana Ekeinhor",
      "Marco Di Giovanni",
      "Tanya Goyal",
      "Rishabh Gupta",
      "Rishabh Gupta",
      "Louanes Hamla",
      "Sang Han",
      "Fabrice Harel-Canada",
      "Antoine Honore",
      "Ishan Jindal",
      "Przemyslaw K. Joniak",
      "Denis Kleyko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12175",
    "title": "Recur, Attend or Convolve? On Whether Temporal Modeling Matters for  Cross-Domain Robustness in Action Recognition",
    "abstract": " Title: Recur, Attend or Convolve? On Whether Temporal Modeling Matters for  Cross-Domain Robustness in Action Recognition ",
    "url": "https://arxiv.org/abs/2112.12175",
    "authors": [
      "Sofia Broom\u00e9",
      "Ernest Pokropek",
      "Boyu Li",
      "Hedvig Kjellstr\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03182",
    "title": "Non-Asymptotic Guarantees for Robust Statistical Learning under Infinite  Variance Assumption",
    "abstract": " Comments: 44 pages ",
    "url": "https://arxiv.org/abs/2201.03182",
    "authors": [
      "Lihu Xu",
      "Fang Yao",
      "Qiuran Yao",
      "Huiming Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2201.03664",
    "title": "Structural measures of similarity and complementarity in complex  networks",
    "abstract": " Comments: Authors' copy of the published version ",
    "url": "https://arxiv.org/abs/2201.03664",
    "authors": [
      "Szymon Talaga",
      "Andrzej Nowak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.07984",
    "title": "AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees",
    "abstract": " Title: AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees ",
    "url": "https://arxiv.org/abs/2201.07984",
    "authors": [
      "Rong Liang",
      "Tiehua Zhang",
      "Yujie Lu",
      "Yuze Liu",
      "Zhen Huang",
      "Xin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00063",
    "title": "Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach",
    "abstract": " Title: Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach ",
    "url": "https://arxiv.org/abs/2202.00063",
    "authors": [
      "Xuezhou Zhang",
      "Yuda Song",
      "Masatoshi Uehara",
      "Mengdi Wang",
      "Alekh Agarwal",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01727",
    "title": "Skeleton-Based Action Segmentation with Multi-Stage Spatial-Temporal  Graph Convolutional Neural Networks",
    "abstract": " Title: Skeleton-Based Action Segmentation with Multi-Stage Spatial-Temporal  Graph Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2202.01727",
    "authors": [
      "Benjamin Filtjens",
      "Bart Vanrumste",
      "Peter Slaets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.05441",
    "title": "Learning Causally Invariant Representations for Out-of-Distribution  Generalization on Graphs",
    "abstract": " Comments: NeurIPS2022, 46 pages, 72 figures ",
    "url": "https://arxiv.org/abs/2202.05441",
    "authors": [
      "Yongqiang Chen",
      "Yonggang Zhang",
      "Yatao Bian",
      "Han Yang",
      "Kaili Ma",
      "Binghui Xie",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10201",
    "title": "OG-SGG: Ontology-Guided Scene Graph Generation. A Case Study in Transfer  Learning for Telepresence Robotics",
    "abstract": " Comments: 19 pages; added additional experimental sections, corrected minor issues, improved explanations ",
    "url": "https://arxiv.org/abs/2202.10201",
    "authors": [
      "Fernando Amodeo",
      "Fernando Caballero",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Luis Merino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11860",
    "title": "Robust Transmission Design for RIS-assisted Secure Multiuser  Communication Systems in the Presence of Hardware Impairments",
    "abstract": " Comments: Revised version in IEEE TWC. Keywords: Reconfigurable intelligent surface (RIS), intelligent reflecting surface (IRS) ",
    "url": "https://arxiv.org/abs/2202.11860",
    "authors": [
      "Zhangjie Peng",
      "Ruisong Weng",
      "Cunhua Pan",
      "Gui Zhou",
      "Marco Di Renzo",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.03265",
    "title": "Efficient Policy Generation in Multi-Agent Systems via Hypergraph Neural  Network",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2203.03265",
    "authors": [
      "Bin Zhang",
      "Yunpeng Bai",
      "Zhiwei Xu",
      "Dapeng Li",
      "Guoliang Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.09095",
    "title": "Automating Code Review Activities by Large-Scale Pre-training",
    "abstract": " Comments: ESEC/FSE 2022, camera-ready version ",
    "url": "https://arxiv.org/abs/2203.09095",
    "authors": [
      "Zhiyu Li",
      "Shuai Lu",
      "Daya Guo",
      "Nan Duan",
      "Shailesh Jannu",
      "Grant Jenks",
      "Deep Majumder",
      "Jared Green",
      "Alexey Svyatkovskiy",
      "Shengyu Fu",
      "Neel Sundaresan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15544",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "abstract": " Comments: To appear at NeurIPS 2022. 18 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2203.15544",
    "authors": [
      "Andrew Dudzik",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.16437",
    "title": "Weakly supervised causal representation learning",
    "abstract": " Comments: Published at NeurIPS 2022. v3: Experiments with higher-dimensional data and larger graphs, improved writing, and added references; matches camera-ready version ",
    "url": "https://arxiv.org/abs/2203.16437",
    "authors": [
      "Johann Brehmer",
      "Pim de Haan",
      "Phillip Lippe",
      "Taco Cohen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.05573",
    "title": "Assessment of convolutional recurrent autoencoder network for learning  wave propagation",
    "abstract": " Title: Assessment of convolutional recurrent autoencoder network for learning  wave propagation ",
    "url": "https://arxiv.org/abs/2204.05573",
    "authors": [
      "Wrik Mallik",
      "Rajeev K. Jaiman",
      "Jasmin Jelovica"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.12581",
    "title": "RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2204.12581",
    "authors": [
      "Marc Rigter",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.08316",
    "title": "Self-Supervised Learning of Multi-Object Keypoints for Robotic  Manipulation",
    "abstract": " Comments: Presented at IEEE ICRA 2022 Workshop 'Reinforcement Learning for Contact-Rich Manipulation' ",
    "url": "https://arxiv.org/abs/2205.08316",
    "authors": [
      "Jan Ole von Hartz",
      "Eugenio Chisari",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.11440",
    "title": "Federated Distillation based Indoor Localization for IoT Networks",
    "abstract": " Title: Federated Distillation based Indoor Localization for IoT Networks ",
    "url": "https://arxiv.org/abs/2205.11440",
    "authors": [
      "Yaya Etiabi",
      "Marwa Chafii",
      "El Mehdi Amhoud"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.02016",
    "title": "Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network?",
    "abstract": " Title: Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network? ",
    "url": "https://arxiv.org/abs/2206.02016",
    "authors": [
      "Chuwei Wang",
      "Shanda Li",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.03466",
    "title": "Adversarial Reprogramming Revisited",
    "abstract": " Title: Adversarial Reprogramming Revisited ",
    "url": "https://arxiv.org/abs/2206.03466",
    "authors": [
      "Matthias Englert",
      "Ranko Lazic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": " Title: EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks ",
    "url": "https://arxiv.org/abs/2206.03491",
    "authors": [
      "Adrien Raison",
      "Pascal Bourdon",
      "David Helbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04564",
    "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "abstract": " Comments: NeurIPS 2022, Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2206.04564",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Herun Wan",
      "Ningnan Wang",
      "Zilong Chen",
      "Binchi Zhang",
      "Qinghua Zheng",
      "Wenqian Zhang",
      "Zhenyu Lei",
      "Shujie Yang",
      "Xinshun Feng",
      "Qingyue Zhang",
      "Hongrui Wang",
      "Yuhan Liu",
      "Yuyang Bai",
      "Heng Wang",
      "Zijian Cai",
      "Yanbo Wang",
      "Lijing Zheng",
      "Zihan Ma",
      "Jundong Li",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.05669",
    "title": "Universality and approximation bounds for echo state networks with  random weights",
    "abstract": " Title: Universality and approximation bounds for echo state networks with  random weights ",
    "url": "https://arxiv.org/abs/2206.05669",
    "authors": [
      "Zhen Li",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07698",
    "title": "Neural Deformable Voxel Grid for Fast Optimization of Dynamic View  Synthesis",
    "abstract": " Comments: Technical Report: 29 pages; project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.07698",
    "authors": [
      "Xiang Guo",
      "Guanying Chen",
      "Yuchao Dai",
      "Xiaoqing Ye",
      "Jiadai Sun",
      "Xiao Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07729",
    "title": "Taxonomy of Benchmarks in Graph Representation Learning",
    "abstract": " Title: Taxonomy of Benchmarks in Graph Representation Learning ",
    "url": "https://arxiv.org/abs/2206.07729",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Sarah McGuire",
      "Xinyi Wang",
      "Anna Little",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09677",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for  Graph Neural Networks",
    "abstract": " Comments: Submitted to Learning on Graphs 2022 and New Frontiers in Graph Learning Workshop (Neurips 2022) ",
    "url": "https://arxiv.org/abs/2206.09677",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.12227",
    "title": "Adversarial Robustness of Deep Neural Networks: A Survey from a Formal  Verification Perspective",
    "abstract": " Title: Adversarial Robustness of Deep Neural Networks: A Survey from a Formal  Verification Perspective ",
    "url": "https://arxiv.org/abs/2206.12227",
    "authors": [
      "Mark Huasong Meng",
      "Guangdong Bai",
      "Sin Gee Teo",
      "Zhe Hou",
      "Yan Xiao",
      "Yun Lin",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.15476",
    "title": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "abstract": " Title: AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2206.15476",
    "authors": [
      "Marius Dragoi",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04122",
    "title": "Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose Data  Integration and Preparation",
    "abstract": " Title: Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose Data  Integration and Preparation ",
    "url": "https://arxiv.org/abs/2207.04122",
    "authors": [
      "Runhui Wang",
      "Yuliang Li",
      "Jin Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2207.09081",
    "title": "Generalizing Goal-Conditioned Reinforcement Learning with Variational  Causal Reasoning",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.09081",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.11957",
    "title": "Uniqueness of a solution to a general class of discrete system defined  on connected graphs",
    "abstract": " Comments: 14 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2207.11957",
    "authors": [
      "Avetik Arakelyan",
      "Farid Bozorgnia"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Combinatorics (math.CO)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.13352",
    "title": "COVID-19 and social media: Beyond polarization",
    "abstract": " Title: COVID-19 and social media: Beyond polarization ",
    "url": "https://arxiv.org/abs/2207.13352",
    "authors": [
      "Giacomo De Nicola",
      "Victor H. Tuekam Mambou",
      "G\u00f6ran Kauermann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2207.13799",
    "title": "Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods",
    "abstract": " Title: Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods ",
    "url": "https://arxiv.org/abs/2207.13799",
    "authors": [
      "Ruben Interian",
      "Ruslan G. Marzo",
      "Isela Mendoza",
      "Celso C. Ribeiro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.01909",
    "title": "Rethinking the Evaluation of Unbiased Scene Graph Generation",
    "abstract": " Title: Rethinking the Evaluation of Unbiased Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2208.01909",
    "authors": [
      "Xingchen Li",
      "Long Chen",
      "Jian Shao",
      "Shaoning Xiao",
      "Songyang Zhang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.05863",
    "title": "GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions",
    "abstract": " Title: GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions ",
    "url": "https://arxiv.org/abs/2208.05863",
    "authors": [
      "Lihang Liu",
      "Donglong He",
      "Xiaomin Fang",
      "Shanzhuo Zhang",
      "Fan Wang",
      "Jingzhou He",
      "Hua Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2209.03042",
    "title": "Graph Neural Networks for Low-Energy Event Classification &  Reconstruction in IceCube",
    "abstract": " Comments: Prepared for submission to JINST ",
    "url": "https://arxiv.org/abs/2209.03042",
    "authors": [
      "R. Abbasi",
      "M. Ackermann",
      "J. Adams",
      "N. Aggarwal",
      "J. A. Aguilar",
      "M. Ahlers",
      "M. Ahrens",
      "J.M. Alameddine",
      "A. A. Alves Jr.",
      "N. M. Amin",
      "K. Andeen",
      "T. Anderson",
      "G. Anton",
      "C. Arg\u00fcelles",
      "Y. Ashida",
      "S. Athanasiadou",
      "S. Axani",
      "X. Bai",
      "A. Balagopal V.",
      "M. Baricevic",
      "S. W. Barwick",
      "V. Basu",
      "R. Bay",
      "J. J. Beatty",
      "K.-H. Becker",
      "J. Becker Tjus",
      "J. Beise",
      "C. Bellenghi",
      "S. Benda",
      "S. BenZvi",
      "D. Berley",
      "E. Bernardini",
      "D. Z. Besson",
      "G. Binder",
      "D. Bindig",
      "E. Blaufuss",
      "S. Blot",
      "F. Bontempo",
      "J. Y. Book",
      "J. Borowka",
      "C. Boscolo Meneguolo",
      "S. B\u00f6ser",
      "O. Botner",
      "J. B\u00f6ttcher",
      "E. Bourbeau",
      "J. Braun",
      "B. Brinson",
      "J. Brostean-Kaiser",
      "R. T. Burley",
      "R. S. Busse",
      "M. A. Campana",
      "E. G. Carnie-Bronca",
      "C. Chen",
      "Z. Chen",
      "D. Chirkin",
      "K. Choi",
      "B. A. Clark",
      "L. Classen",
      "A. Coleman",
      "G. H. Collin",
      "A. Connolly",
      "J. M. Conrad"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2209.03534",
    "title": "CWP: Instance complexity weighted channel-wise soft masks for network  pruning",
    "abstract": " Title: CWP: Instance complexity weighted channel-wise soft masks for network  pruning ",
    "url": "https://arxiv.org/abs/2209.03534",
    "authors": [
      "Jiapeng Wang",
      "Ming Ma",
      "Zhenhua Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08514",
    "title": "Imbalanced Node Processing Method in Graph Neural Network Classification  Task",
    "abstract": " Comments: 6 pages,3 figures ",
    "url": "https://arxiv.org/abs/2209.08514",
    "authors": [
      "Min Liu",
      "Siwen Jin",
      "Luo Jin",
      "Shuohan Wang",
      "Yu Fang",
      "Yuliang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.09482",
    "title": "Incorporating Causal Analysis into Diversified and Logical Response  Generation",
    "abstract": " Comments: Accepted at COLING 2022 ",
    "url": "https://arxiv.org/abs/2209.09482",
    "authors": [
      "Jiayi Liu",
      "Wei Wei",
      "Zhixuan Chu",
      "Xing Gao",
      "Ji Zhang",
      "Tan Yan",
      "Yulin Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14065",
    "title": "LL-GNN: Low Latency Graph Neural Networks on FPGAs for Particle  Detectors",
    "abstract": " Comments: 13 pages and 12 figures ",
    "url": "https://arxiv.org/abs/2209.14065",
    "authors": [
      "Zhiqiang Que",
      "Hongxiang Fan",
      "Marcus Loo",
      "Michaela Blott",
      "Maurizio Pierini",
      "Alexander D Tapper",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2209.14826",
    "title": "Towards Lightweight Black-Box Attacks against Deep Neural Networks",
    "abstract": " Title: Towards Lightweight Black-Box Attacks against Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2209.14826",
    "authors": [
      "Chenghao Sun",
      "Yonggang Zhang",
      "Wan Chaoqun",
      "Qizhou Wang",
      "Ya Li",
      "Tongliang Liu",
      "Bo Han",
      "Xinmei Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00590",
    "title": "Community Learning: Understanding A Community Through NLP for Positive  Impact",
    "abstract": " Comments: The article has been withdrawn as the work is incomplete at this point in time. There are significant evaluations required before this work is ready for pre-print. Furthermore, the dataset of NextDoor used in this paper is also not complete. As of this time this work is not applicable ",
    "url": "https://arxiv.org/abs/2210.00590",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Naveen Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01301",
    "title": "GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient  Link Prediction",
    "abstract": " Title: GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient  Link Prediction ",
    "url": "https://arxiv.org/abs/2210.01301",
    "authors": [
      "Zixiao Wang",
      "Yuluo Guo",
      "Jin Zhao",
      "Yu Zhang",
      "Hui Yu",
      "Xiaofei Liao",
      "Hai Jin",
      "Biao Wang",
      "Ting Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.01849",
    "title": "Link Partitioning on Simplicial Complexes Using Higher-Order Laplacians",
    "abstract": " Comments: Accepted to 22nd IEEE International Conference on Data Mining (ICDM 2022). Fixed some typos in v1 ",
    "url": "https://arxiv.org/abs/2210.01849",
    "authors": [
      "Xinyi Wu",
      "Arnab Sarker",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2210.02040",
    "title": "GT-GAN: General Purpose Time Series Synthesis with Generative  Adversarial Networks",
    "abstract": " Comments: NeurIPs 2022 ",
    "url": "https://arxiv.org/abs/2210.02040",
    "authors": [
      "Jinsung Jeon",
      "Jeonghak Kim",
      "Haryong Song",
      "Seunghyeon Cho",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02226",
    "title": "Null Hypothesis Test for Anomaly Detection",
    "abstract": " Comments: 8 pages, 3 figures. Updated version prepared for submission. All code is now available at this https URL Comments welcome! ",
    "url": "https://arxiv.org/abs/2210.02226",
    "authors": [
      "Jernej F. Kamenik",
      "Manuel Szewc"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2210.03894",
    "title": "GRANITE: A Graph Neural Network Model for Basic Block Throughput  Estimation",
    "abstract": " Comments: 13 pages; 5 figures; published at IISWC 2022; Included IEEE copyright; ",
    "url": "https://arxiv.org/abs/2210.03894",
    "authors": [
      "Ondrej Sykora",
      "Phitchaya Mangpo Phothilimthana",
      "Charith Mendis",
      "Amir Yazdanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.04427",
    "title": "Asymmetric Temperature Scaling Makes Larger Networks Teach Well Again",
    "abstract": " Comments: Accepted By NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.04427",
    "authors": [
      "Xin-Chun Li",
      "Wen-Shu Fan",
      "Shaoming Song",
      "Yinchuan Li",
      "Bingshuai Li",
      "Yunfeng Shao",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04525",
    "title": "SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup  Training",
    "abstract": " Comments: COLING-2022, oral presentation ",
    "url": "https://arxiv.org/abs/2210.04525",
    "authors": [
      "Dan Qiao",
      "Chenchen Dai",
      "Yuyang Ding",
      "Juntao Li",
      "Qiang Chen",
      "Wenliang Chen",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04555",
    "title": "Everything is Varied: The Surprising Impact of Individual Variation on  ML Robustness in Medicine",
    "abstract": " Title: Everything is Varied: The Surprising Impact of Individual Variation on  ML Robustness in Medicine ",
    "url": "https://arxiv.org/abs/2210.04555",
    "authors": [
      "Andrea Campagner",
      "Lorenzo Famiglini",
      "Anna Carobene",
      "Federico Cabitza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04590",
    "title": "The Small Solution Hypothesis for MAPF on Directed Graphs Is True",
    "abstract": " Title: The Small Solution Hypothesis for MAPF on Directed Graphs Is True ",
    "url": "https://arxiv.org/abs/2210.04590",
    "authors": [
      "Bernhard Nebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  }
]