[
  {
    "id": "arXiv:2210.14905",
    "title": "RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding",
    "abstract": "Knowledge graph (KG) reasoning is an important problem for knowledge graphs. It predicts missing links by reasoning on existing facts. Knowledge graph embedding (KGE) is one of the most popular methods to address this problem. It embeds entities and relations into low-dimensional vectors and uses the learned entity/relation embeddings to predict missing facts. However, KGE only uses zeroth-order (propositional) logic to encode existing triplets (e.g., ``Alice is Bob's wife.\"); it is unable to leverage first-order (predicate) logic to represent generally applicable logical \\textbf{rules} (e.g., ``$\\forall x,y \\colon x ~\\text{is}~ y\\text{'s wife} \\rightarrow y ~\\text{is}~ x\\text{'s husband}$''). On the other hand, traditional rule-based KG reasoning methods usually rely on hard logical rule inference, making it brittle and hardly competitive with KGE. In this paper, we propose RulE, a novel and principled framework to represent and model logical rules and triplets. RulE jointly represents entities, relations and logical rules in a unified embedding space. By learning an embedding for each logical rule, RulE can perform logical rule inference in a soft way and give a confidence score to each grounded rule, similar to how KGE gives each triplet a confidence score. Compared to KGE alone, RulE allows injecting prior logical rule information into the embedding space, which improves the generalization of knowledge graph embedding. Besides, the learned confidence scores of rules improve the logical rule inference process by softly controlling the contribution of each rule, which alleviates the brittleness of logic. We evaluate our method with link prediction tasks. Experimental results on multiple benchmark KGs demonstrate the effectiveness of RulE. ",
    "url": "https://arxiv.org/abs/2210.14905",
    "authors": [
      "Xiaojuan Tang",
      "Song-Chun Zhu",
      "Yitao Liang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14906",
    "title": "An Intelligent Decision Support Ensemble Voting Model for Coronary  Artery Disease Prediction in Smart Healthcare Monitoring Environments",
    "abstract": "Coronary artery disease (CAD) is one of the most common cardiac diseases worldwide and causes disability and economic burden. It is the world's leading and most serious cause of mortality, with approximately 80% of deaths reported in low- and middle-income countries. The preferred and most precise diagnostic tool for CAD is angiography, but it is invasive, expensive, and technically demanding. However, the research community is increasingly interested in the computer-aided diagnosis of CAD via the utilization of machine learning (ML) methods. The purpose of this work is to present an e-diagnosis tool based on ML algorithms that can be used in a smart healthcare monitoring system. We applied the most accurate machine learning methods that have shown superior results in the literature to different medical datasets such as RandomForest, XGboost, MLP, J48, AdaBoost, NaiveBayes, LogitBoost, KNN. Every single classifier can be efficient on a different dataset. Thus, an ensemble model using majority voting was designed to take advantage of the well-performed single classifiers, Ensemble learning aims to combine the forecasts of multiple individual classifiers to achieve higher performance than individual classifiers in terms of precision, specificity, sensitivity, and accuracy; furthermore, we have benchmarked our proposed model with the most efficient and well-known ensemble models, such as Bagging, Stacking methods based on the cross-validation technique, The experimental results confirm that the ensemble majority voting approach based on the top 3 classifiers: MultilayerPerceptron, RandomForest, and AdaBoost, achieves the highest accuracy of 88,12% and outperforms all other classifiers. This study demonstrates that the majority voting ensemble approach proposed above is the most accurate machine learning classification approach for the prediction and detection of coronary artery disease. ",
    "url": "https://arxiv.org/abs/2210.14906",
    "authors": [
      "Anas Maach",
      "Jamila Elalami",
      "Noureddine Elalami",
      "El Houssine El Mazoudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14913",
    "title": "AltUB: Alternating Training Method to Update Base Distribution of  Normalizing Flow for Anomaly Detection",
    "abstract": "Unsupervised anomaly detection is coming into the spotlight these days in various practical domains due to the limited amount of anomaly data. One of the major approaches for it is a normalizing flow which pursues the invertible transformation of a complex distribution as images into an easy distribution as N(0, I). In fact, algorithms based on normalizing flow like FastFlow and CFLOW-AD establish state-of-the-art performance on unsupervised anomaly detection tasks. Nevertheless, we investigate these algorithms convert normal images into not N(0, I) as their destination, but an arbitrary normal distribution. Moreover, their performances are often unstable, which is highly critical for unsupervised tasks because data for validation are not provided. To break through these observations, we propose a simple solution AltUB which introduces alternating training to update the base distribution of normalizing flow for anomaly detection. AltUB effectively improves the stability of performance of normalizing flow. Furthermore, our method achieves the new state-of-the-art performance of the anomaly segmentation task on the MVTec AD dataset with 98.8% AUROC. ",
    "url": "https://arxiv.org/abs/2210.14913",
    "authors": [
      "Yeongmin Kim",
      "Huiwon Jang",
      "DongKeon Lee",
      "Ho-Jin Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14944",
    "title": "Detection and Prevention Against Poisoning Attacks in Federated Learning",
    "abstract": "This paper proposes and investigates a new approach for detecting and preventing several different types of poisoning attacks from affecting a centralized Federated Learning model via average accuracy deviation detection (AADD). By comparing each client's accuracy to all clients' average accuracy, AADD detect clients with an accuracy deviation. The implementation is further able to blacklist clients that are considered poisoned, securing the global model from being affected by the poisoned nodes. The proposed implementation shows promising results in detecting poisoned clients and preventing the global model's accuracy from deteriorating. ",
    "url": "https://arxiv.org/abs/2210.14944",
    "authors": [
      "Viktor Valadi",
      "Madeleine Englund",
      "Mark Spanier",
      "Austin O'brien"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14951",
    "title": "TraVaS: Differentially Private Trace Variant Selection for Process  Mining",
    "abstract": "In the area of industrial process mining, privacy-preserving event data publication is becoming increasingly relevant. Consequently, the trade-off between high data utility and quantifiable privacy poses new challenges. State-of-the-art research mainly focuses on differentially private trace variant construction based on prefix expansion methods. However, these algorithms face several practical limitations such as high computational complexity, introducing fake variants, removing frequent variants, and a bounded variant length. In this paper, we introduce a new approach for direct differentially private trace variant release which uses anonymized \\textit{partition selection} strategies to overcome the aforementioned restraints. Experimental results on real-life event data show that our algorithm outperforms state-of-the-art methods in terms of both plain data utility and result utility preservation. ",
    "url": "https://arxiv.org/abs/2210.14951",
    "authors": [
      "Majid Rafiei",
      "Frederik Wangelik",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14957",
    "title": "Disentangled Text Representation Learning with Information-Theoretic  Perspective for Adversarial Robustness",
    "abstract": "Adversarial vulnerability remains a major obstacle to constructing reliable NLP systems. When imperceptible perturbations are added to raw input text, the performance of a deep learning model may drop dramatically under attacks. Recent work argues the adversarial vulnerability of the model is caused by the non-robust features in supervised training. Thus in this paper, we tackle the adversarial robustness challenge from the view of disentangled representation learning, which is able to explicitly disentangle robust and non-robust features in text. Specifically, inspired by the variation of information (VI) in information theory, we derive a disentangled learning objective composed of mutual information to represent both the semantic representativeness of latent embeddings and differentiation of robust and non-robust features. On the basis of this, we design a disentangled learning network to estimate these mutual information. Experiments on text classification and entailment tasks show that our method significantly outperforms the representative methods under adversarial attacks, indicating that discarding non-robust features is critical for improving adversarial robustness. ",
    "url": "https://arxiv.org/abs/2210.14957",
    "authors": [
      "Jiahao Zhao",
      "Wenji Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14958",
    "title": "Constrained Approximate Similarity Search on Proximity Graph",
    "abstract": "Search engines and recommendation systems are built to efficiently display relevant information from those massive amounts of candidates. Typically a three-stage mechanism is employed in those systems: (i) a small collection of items are first retrieved by (e.g.,) approximate near neighbor search algorithms; (ii) then a collection of constraints are applied on the retrieved items; (iii) a fine-grained ranking neural network is employed to determine the final recommendation. We observe a major defect of the original three-stage pipeline: Although we only target to retrieve $k$ vectors in the final recommendation, we have to preset a sufficiently large $s$ ($s > k$) for each query, and ``hope'' the number of survived vectors after the filtering is not smaller than $k$. That is, at least $k$ vectors in the $s$ similar candidates satisfy the query constraints. In this paper, we investigate this constrained similarity search problem and attempt to merge the similarity search stage and the filtering stage into one single search operation. We introduce AIRSHIP, a system that integrates a user-defined function filtering into the similarity search framework. The proposed system does not need to build extra indices nor require prior knowledge of the query constraints. We propose three optimization strategies: (1) starting point selection, (2) multi-direction search, and (3) biased priority queue selection. Experimental evaluations on both synthetic and real data confirm the effectiveness of the proposed AIRSHIP algorithm. We focus on constrained graph-based approximate near neighbor (ANN) search in this study, in part because graph-based ANN is known to achieve excellent performance. We believe it is also possible to develop constrained hashing-based ANN or constrained quantization-based ANN. ",
    "url": "https://arxiv.org/abs/2210.14958",
    "authors": [
      "Weijie Zhao",
      "Shulong Tan",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.14962",
    "title": "Identifying Diversity, Equity, Inclusion, and Accessibility (DEIA)  Indicators for Transportation Systems using Social Media Data: The Case of  New York City during Covid-19 Pandemic",
    "abstract": "The adoption of transportation policies that prioritized highway expansion over public transportation has disproportionately impacted minorities and low-income people by restricting their access to social and economic opportunities and thus resulting in residential segregation. Policymakers, transportation researchers, planners, and practitioners have started acknowledging the need to build a diverse, equitable, inclusive, and accessible (DEIA) transportation system. Traditionally, this has been done through survey-based approaches that are time-consuming and expensive. While there is recent attention on leveraging social media data in transportation, the literature is inconclusive regarding the use of social media data as a viable alternative to traditional sources to identify the latent DEIA indicators based on public reactions and perspectives on social media. This study utilized large-scale Twitter data covering eight counties around the New York City (NYC) area during the initial phase of the Covid-19 lockdown to address this research gap. Natural language processing techniques were used to identify transportation-related major DEIA issues for residents living around NYC by analyzing their relevant tweet conversations. The study revealed that citizens, who had negative sentiments toward the DEIA of their local transportation system, broadly discussed racism, income, unemployment, gender, ride dependency, transportation modes, and dependent groups. Analyzing the socio-demographic information based on census tracts, the study also observed that areas with a higher percentage of low-income, female, Hispanic, and Latino populations share more concerns about transportation DEIA on Twitter. ",
    "url": "https://arxiv.org/abs/2210.14962",
    "authors": [
      "Fariha Nazneen Rista",
      "Khondhaker Al Momin",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.14970",
    "title": "Identifying Crisis Response Communities in Online Social Networks for  Compound Disasters: The Case of Hurricane Laura and Covid-19",
    "abstract": "Online social networks allow different agencies and the public to interact and share the underlying risks and protective actions during major disasters. This study revealed such crisis communication patterns during hurricane Laura compounded by the COVID-19 pandemic. Laura was one of the strongest (Category 4) hurricanes on record to make landfall in Cameron, Louisiana. Using the Application Programming Interface (API), this study utilizes large-scale social media data obtained from Twitter through the recently released academic track that provides complete and unbiased observations. The data captured publicly available tweets shared by active Twitter users from the vulnerable areas threatened by Laura. Online social networks were based on user influence feature ( mentions or tags) that allows notifying other users while posting a tweet. Using network science theories and advanced community detection algorithms, the study split these networks into twenty-one components of various sizes, the largest of which contained eight well-defined communities. Several natural language processing techniques (i.e., word clouds, bigrams, topic modeling) were applied to the tweets shared by the users in these communities to observe their risk-taking or risk-averse behavior during a major compounding crisis. Social media accounts of local news media, radio, universities, and popular sports pages were among those who involved heavily and interacted closely with local residents. In contrast, emergency management and planning units in the area engaged less with the public. The findings of this study provide novel insights into the design of efficient social media communication guidelines to respond better in future disasters. ",
    "url": "https://arxiv.org/abs/2210.14970",
    "authors": [
      "Khondhaker Al Momin",
      "H M Imran Kays",
      "Arif Mohaimin Sadri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.14977",
    "title": "Knowledge Transfer For On-Device Speech Emotion Recognition with Neural  Structured Learning",
    "abstract": "Speech emotion recognition (SER) has been a popular research topic in human-computer interaction (HCI). As edge devices are rapidly springing up, applying SER to edge devices is promising for a huge number of HCI applications. Although deep learning has been investigated to improve the performance of SER by training complex models, the memory space and computational capability of edge devices represents a constraint for embedding deep learning models. We propose a neural structured learning (NSL) framework through building synthesized graphs. An SER model is trained on a source dataset and used to build graphs on a target dataset. A lightweight model is then trained with the speech samples and graphs together as the input. Our experiments demonstrate that training a lightweight SER model on the target dataset with speech samples and graphs can not only produce small SER models, but also enhance the model performance over models with speech samples only. ",
    "url": "https://arxiv.org/abs/2210.14977",
    "authors": [
      "Yi Chang",
      "Zhao Ren",
      "Thanh Tam Nguyen",
      "Kun Qian",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14979",
    "title": "Robust Domain Adaptation for Pre-trained Multilingual Neural Machine  Translation Models",
    "abstract": "Recent literature has demonstrated the potential of multilingual Neural Machine Translation (mNMT) models. However, the most efficient models are not well suited to specialized industries. In these cases, internal data is scarce and expensive to find in all language pairs. Therefore, fine-tuning a mNMT model on a specialized domain is hard. In this context, we decided to focus on a new task: Domain Adaptation of a pre-trained mNMT model on a single pair of language while trying to maintain model quality on generic domain data for all language pairs. The risk of loss on generic domain and on other pairs is high. This task is key for mNMT model adoption in the industry and is at the border of many others. We propose a fine-tuning procedure for the generic mNMT that combines embeddings freezing and adversarial loss. Our experiments demonstrated that the procedure improves performances on specialized data with a minimal loss in initial performances on generic domain for all languages pairs, compared to a naive standard approach (+10.0 BLEU score on specialized data, -0.01 to -0.5 BLEU on WMT and Tatoeba datasets on the other pairs with M2M100). ",
    "url": "https://arxiv.org/abs/2210.14979",
    "authors": [
      "Mathieu Grosso",
      "Pirashanth Ratnamogan",
      "Alexis Mathey",
      "William Vanhuffel",
      "Michael Fotso Fotso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14993",
    "title": "Annotating Privacy Policies in the Sharing Economy",
    "abstract": "Applications (apps) of the Digital Sharing Economy (DSE), such as Uber, Airbnb, and TaskRabbit, have become a main enabler of economic growth and shared prosperity in modern-day societies. However, the complex exchange of goods, services, and data that takes place over these apps frequently puts their end-users' privacy at risk. Privacy policies of DSE apps are provided to disclose how private user data is being collected and handled. However, in reality, such policies are verbose and difficult to understand, leaving DSE users vulnerable to privacy intrusive practices. To address these concerns, in this paper, we propose an automated approach for annotating privacy policies in the DSE market. Our approach identifies data collection claims in these policies and maps them to the quality features of their apps. Visual and textual annotations are then used to further explain and justify these claims. The proposed approach is evaluated with 18 DSE app users. The results show that annotating privacy policies can significantly enhance their comprehensibility to the average DSE user. Our findings are intended to help DSE app developers to draft more comprehensible privacy policies as well as help their end-users to make more informed decisions in one of the fastest growing software ecosystems in the world. ",
    "url": "https://arxiv.org/abs/2210.14993",
    "authors": [
      "Fahimeh Ebrahimi",
      "Miroslav Tushev",
      "Anas Mahmoud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.14997",
    "title": "LiDAR-guided object search and detection in Subterranean Environments",
    "abstract": "Detecting objects of interest, such as human survivors, safety equipment, and structure access points, is critical to any search-and-rescue operation. Robots deployed for such time-sensitive efforts rely on their onboard sensors to perform their designated tasks. However, as disaster response operations are predominantly conducted under perceptually degraded conditions, commonly utilized sensors such as visual cameras and LiDARs suffer in terms of performance degradation. In response, this work presents a method that utilizes the complementary nature of vision and depth sensors to leverage multi-modal information to aid object detection at longer distances. In particular, depth and intensity values from sparse LiDAR returns are used to generate proposals for objects present in the environment. These proposals are then utilized by a Pan-Tilt-Zoom (PTZ) camera system to perform a directed search by adjusting its pose and zoom level for performing object detection and classification in difficult environments. The proposed work has been thoroughly verified using an ANYmal quadruped robot in underground settings and on datasets collected during the DARPA Subterranean Challenge finals. ",
    "url": "https://arxiv.org/abs/2210.14997",
    "authors": [
      "Manthan Patel",
      "Gabriel Waibel",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15009",
    "title": "Hypergraph Artificial Benchmark for Community Detection (h-ABCD)",
    "abstract": "The Artificial Benchmark for Community Detection (ABCD) graph is a recently introduced random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs with similar properties as the well-known LFR one, and its main parameter can be tuned to mimic its counterpart in the LFR model, the mixing parameter. In this paper, we introduce hypergraph counterpart of the ABCD model, h-ABCD, which produces random hypergraph with distributions of ground-truth community sizes and degrees following power-law. As in the original ABCD, the new model h-ABCD can produce hypergraphs with various levels of noise. More importantly, the model is flexible and can mimic any desired level of homogeneity of hyperedges that fall into one community. As a result, it can be used as a suitable, synthetic playground for analyzing and tuning hypergraph community detection algorithms. ",
    "url": "https://arxiv.org/abs/2210.15009",
    "authors": [
      "Bogumi\u0142 Kami\u0144ski",
      "Pawe\u0142 Pra\u0142at",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.15011",
    "title": "Using Deception in Markov Game to Understand Adversarial Behaviors  through a Capture-The-Flag Environment",
    "abstract": "Identifying the actual adversarial threat against a system vulnerability has been a long-standing challenge for cybersecurity research. To determine an optimal strategy for the defender, game-theoretic based decision models have been widely used to simulate the real-world attacker-defender scenarios while taking the defender's constraints into consideration. In this work, we focus on understanding human attacker behaviors in order to optimize the defender's strategy. To achieve this goal, we model attacker-defender engagements as Markov Games and search for their Bayesian Stackelberg Equilibrium. We validate our modeling approach and report our empirical findings using a Capture-The-Flag (CTF) setup, and we conduct user studies on adversaries with varying skill-levels. Our studies show that application-level deceptions are an optimal mitigation strategy against targeted attacks -- outperforming classic cyber-defensive maneuvers, such as patching or blocking network requests. We use this result to further hypothesize over the attacker's behaviors when trapped in an embedded honeypot environment and present a detailed analysis of the same. ",
    "url": "https://arxiv.org/abs/2210.15011",
    "authors": [
      "Siddhant Bhambri",
      "Purv Chauhan",
      "Frederico Araujo",
      "Adam Doup\u00e9",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.15014",
    "title": "Counting Perfect Matchings in Dense Graphs Is Hard",
    "abstract": "We show that the problem of counting perfect matchings remains #P-complete even if we restrict the input to very dense graphs, proving the conjecture in [5]. Here \"dense graphs\" refer to bipartite graphs of bipartite independence number $\\leq 2$, or general graphs of independence number $\\leq 2$. Our proof is by reduction from counting perfect matchings in bipartite graphs, via elementary linear algebra tricks and graph constructions. ",
    "url": "https://arxiv.org/abs/2210.15014",
    "authors": [
      "Nicolas El Maalouly",
      "Yanheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.15030",
    "title": "A Hierarchical Approach to Conditional Random Fields for System Anomaly  Detection",
    "abstract": "Anomaly detection to recognize unusual events in large scale systems in a time sensitive manner is critical in many industries, eg. bank fraud, enterprise systems, medical alerts, etc. Large-scale systems often grow in size and complexity over time, and anomaly detection algorithms need to adapt to changing structures. A hierarchical approach takes advantage of the implicit relationships in complex systems and localized context. The features in complex systems may vary drastically in data distribution, capturing different aspects from multiple data sources, and when put together provide a more complete view of the system. In this paper, two datasets are considered, the 1st comprising of system metrics from machines running on a cloud service, and the 2nd of application metrics from a distributed software system with inherent hierarchies and interconnections amongst its system nodes. Comparing algorithms, across the changepoint based PELT algorithm, cognitive learning-based Hierarchical Temporal Memory algorithms, Support Vector Machines and Conditional Random Fields provides a basis for proposing a Hierarchical Global-Local Conditional Random Field approach to accurately capture anomalies in complex systems, and across various features. Hierarchical algorithms can learn both the intricacies of lower-level or specific features, and utilize these in the global abstracted representation to detect anomalous patterns robustly across multi-source feature data and distributed systems. A graphical network analysis on complex systems can further fine-tune datasets to mine relationships based on available features, which can benefit hierarchical models. Furthermore, hierarchical solutions can adapt well to changes at a localized level, learning on new data and changing environments when parts of a system are over-hauled, and translate these learnings to a global view of the system over time. ",
    "url": "https://arxiv.org/abs/2210.15030",
    "authors": [
      "Srishti Mishra",
      "Tvarita Jain",
      "Dr. Dinkar Sitaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.15034",
    "title": "InfoShape: Task-Based Neural Data Shaping via Mutual Information",
    "abstract": "The use of mutual information as a tool in private data sharing has remained an open challenge due to the difficulty of its estimation in practice. In this paper, we propose InfoShape, a task-based encoder that aims to remove unnecessary sensitive information from training data while maintaining enough relevant information for a particular ML training task. We achieve this goal by utilizing mutual information estimators that are based on neural networks, in order to measure two performance metrics, privacy and utility. Using these together in a Lagrangian optimization, we train a separate neural network as a lossy encoder. We empirically show that InfoShape is capable of shaping the encoded samples to be informative for a specific downstream task while eliminating unnecessary sensitive information. Moreover, we demonstrate that the classification accuracy of downstream models has a meaningful connection with our utility and privacy measures. ",
    "url": "https://arxiv.org/abs/2210.15034",
    "authors": [
      "Homa Esfahanizadeh",
      "William Wu",
      "Manya Ghobadi",
      "Regina Barzilay",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.15042",
    "title": "EW-Tune: A Framework for Privately Fine-Tuning Large Language Models  with Differential Privacy",
    "abstract": "Pre-trained Large Language Models (LLMs) are an integral part of modern AI that have led to breakthrough performances in complex AI tasks. Major AI companies with expensive infrastructures are able to develop and train these large models with billions and millions of parameters from scratch. Third parties, researchers, and practitioners are increasingly adopting these pre-trained models and fine-tuning them on their private data to accomplish their downstream AI tasks. However, it has been shown that an adversary can extract/reconstruct the exact training samples from these LLMs, which can lead to revealing personally identifiable information. The issue has raised deep concerns about the privacy of LLMs. Differential privacy (DP) provides a rigorous framework that allows adding noise in the process of training or fine-tuning LLMs such that extracting the training data becomes infeasible (i.e., with a cryptographically small success probability). While the theoretical privacy guarantees offered in most extant studies assume learning models from scratch through many training iterations in an asymptotic setting, this assumption does not hold in fine-tuning scenarios in which the number of training iterations is significantly smaller. To address the gap, we present \\ewtune, a DP framework for fine-tuning LLMs based on Edgeworth accountant with finite-sample privacy guarantees. Our results across four well-established natural language understanding (NLU) tasks show that while \\ewtune~adds privacy guarantees to LLM fine-tuning process, it directly contributes to decreasing the induced noise to up to 5.6\\% and improves the state-of-the-art LLMs performance by up to 1.1\\% across all NLU tasks. We have open-sourced our implementations for wide adoption and public testing purposes. ",
    "url": "https://arxiv.org/abs/2210.15042",
    "authors": [
      "Rouzbeh Behnia",
      "Mohamamdreza Ebrahimi",
      "Jason Pacheco",
      "balaji Padmanabhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15045",
    "title": "An Optimal Patrolling Strategy for Tree Networks",
    "abstract": "We settle a recent conjecture on a continuous patrolling game. In this zero-sum game, an Attacker chooses a time and place to attack a network for a fixed amount of time. A Patroller patrols the network with the aim of intercepting the attack with maximum probability. The conjecture asserts that a particular patrolling strategy called the E-patrolling strategy is optimal for all tree networks. The conjecture was previously known to be true in a limited class of special cases. The E-patrolling strategy has the advantage of being straightforward to calculate and implement. We prove the conjecture by presenting $\\varepsilon$-optimal strategies for the Attacker which provide upper bounds for the value of the game that come arbitrarily close to the lower bound provided by the E-patrolling strategy. ",
    "url": "https://arxiv.org/abs/2210.15045",
    "authors": [
      "Thomas Lidbetter",
      "Thuy Bui"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.15048",
    "title": "DyREx: Dynamic Query Representation for Extractive Question Answering",
    "abstract": "Extractive question answering (ExQA) is an essential task for Natural Language Processing. The dominant approach to ExQA is one that represents the input sequence tokens (question and passage) with a pre-trained transformer, then uses two learned query vectors to compute distributions over the start and end answer span positions. These query vectors lack the context of the inputs, which can be a bottleneck for the model performance. To address this problem, we propose \\textit{DyREx}, a generalization of the \\textit{vanilla} approach where we dynamically compute query vectors given the input, using an attention mechanism through transformer layers. Empirical observations demonstrate that our approach consistently improves the performance over the standard one. The code and accompanying files for running the experiments are available at \\url{https://github.com/urchade/DyReX}. ",
    "url": "https://arxiv.org/abs/2210.15048",
    "authors": [
      "Urchade Zaratiana",
      "Niama El Khbir",
      "Dennis N\u00fa\u00f1ez",
      "Pierre Holat",
      "Nadi Tomeh",
      "Thierry Charnois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15055",
    "title": "Adaptive Model Learning of Neural Networks with UUB Stability for Robot  Dynamic Estimation",
    "abstract": "Since batch algorithms suffer from lack of proficiency in confronting model mismatches and disturbances, this contribution proposes an adaptive scheme based on continuous Lyapunov function for online robot dynamic identification. This paper suggests stable updating rules to drive neural networks inspiring from model reference adaptive paradigm. Network structure consists of three parallel self-driving neural networks which aim to estimate robot dynamic terms individually. Lyapunov candidate is selected to construct energy surface for a convex optimization framework. Learning rules are driven directly from Lyapunov functions to make the derivative negative. Finally, experimental results on 3-DOF Phantom Omni Haptic device demonstrate efficiency of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.15055",
    "authors": [
      "Pedram Agand",
      "Mahdi Aliyari Shoorehdeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15056",
    "title": "UnfoldML: Cost-Aware and Uncertainty-Based Dynamic 2D Prediction for  Multi-Stage Classification",
    "abstract": "Machine Learning (ML) research has focused on maximizing the accuracy of predictive tasks. ML models, however, are increasingly more complex, resource intensive, and costlier to deploy in resource-constrained environments. These issues are exacerbated for prediction tasks with sequential classification on progressively transitioned stages with ''happens-before'' relation between them.We argue that it is possible to ''unfold'' a monolithic single multi-class classifier, typically trained for all stages using all data, into a series of single-stage classifiers. Each single-stage classifier can be cascaded gradually from cheaper to more expensive binary classifiers that are trained using only the necessary data modalities or features required for that stage. UnfoldML is a cost-aware and uncertainty-based dynamic 2D prediction pipeline for multi-stage classification that enables (1) navigation of the accuracy/cost tradeoff space, (2) reducing the spatio-temporal cost of inference by orders of magnitude, and (3) early prediction on proceeding stages. UnfoldML achieves orders of magnitude better cost in clinical settings, while detecting multi-stage disease development in real time. It achieves within 0.1% accuracy from the highest-performing multi-class baseline, while saving close to 20X on spatio-temporal cost of inference and earlier (3.5hrs) disease onset prediction. We also show that UnfoldML generalizes to image classification, where it can predict different level of labels (from coarse to fine) given different level of abstractions of a image, saving close to 5X cost with as little as 0.4% accuracy reduction. ",
    "url": "https://arxiv.org/abs/2210.15056",
    "authors": [
      "Yanbo Xu",
      "Alind Khare",
      "Glenn Matlin",
      "Monish Ramadoss",
      "Rishikesan Kamaleswaran",
      "Chao Zhang",
      "Alexey Tumanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15068",
    "title": "Improving Adversarial Robustness with Self-Paced Hard-Class Pair  Reweighting",
    "abstract": "Deep Neural Networks are vulnerable to adversarial attacks. Among many defense strategies, adversarial training with untargeted attacks is one of the most recognized methods. Theoretically, the predicted labels of untargeted attacks should be unpredictable and uniformly-distributed overall false classes. However, we find that the naturally imbalanced inter-class semantic similarity makes those hard-class pairs to become the virtual targets of each other. This study investigates the impact of such closely-coupled classes on adversarial attacks and develops a self-paced reweighting strategy in adversarial training accordingly. Specifically, we propose to upweight hard-class pair loss in model optimization, which prompts learning discriminative features from hard classes. We further incorporate a term to quantify hard-class pair consistency in adversarial training, which greatly boost model robustness. Extensive experiments show that the proposed adversarial training method achieves superior robustness performance over state-of-the-art defenses against a wide range of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2210.15068",
    "authors": [
      "Pengyue Hou",
      "Jie Han",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15093",
    "title": "Predicting Visual Attention and Distraction During Visual Search Using  Convolutional Neural Networks",
    "abstract": "Most studies in computational modeling of visual attention encompass task-free observation of images. Free-viewing saliency considers limited scenarios of daily life. Most visual activities are goal-oriented and demand a great amount of top-down attention control. Visual search task demands more top-down control of attention, compared to free-viewing. In this paper, we present two approaches to model visual attention and distraction of observers during visual search. Our first approach adapts a light-weight free-viewing saliency model to predict eye fixation density maps of human observers over pixels of search images, using a two-stream convolutional encoder-decoder network, trained and evaluated on COCO-Search18 dataset. This method predicts which locations are more distracting when searching for a particular target. Our network achieves good results on standard saliency metrics (AUC-Judd=0.95, AUC-Borji=0.85, sAUC=0.84, NSS=4.64, KLD=0.93, CC=0.72, SIM=0.54, and IG=2.59). Our second approach is object-based and predicts the distractor and target objects during visual search. Distractors are all objects except the target that observers fixate on during search. This method uses a Mask-RCNN segmentation network pre-trained on MS-COCO and fine-tuned on COCO-Search18 dataset. We release our segmentation annotations of targets and distractors in COCO-Search18 for three target categories: bottle, bowl, and car. The average scores over the three categories are: F1-score=0.64, MAP(iou:0.5)=0.57, MAR(iou:0.5)=0.73. Our implementation code in Tensorflow is publicly available at https://github.com/ManooshSamiei/Distraction-Visual-Search . ",
    "url": "https://arxiv.org/abs/2210.15093",
    "authors": [
      "Manoosh Samiei",
      "James J. Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.15111",
    "title": "MEET: Mobility-Enhanced Edge inTelligence for Smart and Green 6G  Networks",
    "abstract": "Edge intelligence is an emerging paradigm for real-time training and inference at the wireless edge, thus enabling mission-critical applications. Accordingly, base stations (BSs) and edge servers (ESs) need to be densely deployed, leading to huge deployment and operation costs, in particular the energy costs. In this article, we propose a new framework called Mobility-Enhanced Edge inTelligence (MEET), which exploits the sensing, communication, computing, and self-powering capabilities of intelligent connected vehicles for the smart and green 6G networks. Specifically, the operators can incorporate infrastructural vehicles as movable BSs or ESs, and schedule them in a more flexible way to align with the communication and computation traffic fluctuations. Meanwhile, the remaining compute resources of opportunistic vehicles are exploited for edge training and inference, where mobility can further enhance edge intelligence by bringing more compute resources, communication opportunities, and diverse data. In this way, the deployment and operation costs are spread over the vastly available vehicles, so that the edge intelligence is realized cost-effectively and sustainably. Furthermore, these vehicles can be either powered by renewable energy to reduce carbon emissions, or charged more flexibly during off-peak hours to cut electricity bills. ",
    "url": "https://arxiv.org/abs/2210.15111",
    "authors": [
      "Yuxuan Sun",
      "Bowen Xie",
      "Sheng Zhou",
      "Zhisheng Niu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15120",
    "title": "Federated Graph Representation Learning using Self-Supervision",
    "abstract": "Federated graph representation learning (FedGRL) brings the benefits of distributed training to graph structured data while simultaneously addressing some privacy and compliance concerns related to data curation. However, several interesting real-world graph data characteristics viz. label deficiency and downstream task heterogeneity are not taken into consideration in current FedGRL setups. In this paper, we consider a realistic and novel problem setting, wherein cross-silo clients have access to vast amounts of unlabeled data with limited or no labeled data and additionally have diverse downstream class label domains. We then propose a novel FedGRL formulation based on model interpolation where we aim to learn a shared global model that is optimized collaboratively using a self-supervised objective and gets downstream task supervision through local client models. We provide a specific instantiation of our general formulation using BGRL a SoTA self-supervised graph representation learning method and we empirically verify its effectiveness through realistic cross-slio datasets: (1) we adapt the Twitch Gamer Network which naturally simulates a cross-geo scenario and show that our formulation can provide consistent and avg. 6.1% gains over traditional supervised federated learning objectives and on avg. 1.7% gains compared to individual client specific self-supervised training and (2) we construct and introduce a new cross-silo dataset called Amazon Co-purchase Networks that have both the characteristics of the motivated problem setting. And, we witness on avg. 11.5% gains over traditional supervised federated learning and on avg. 1.9% gains over individually trained self-supervised models. Both experimental results point to the effectiveness of our proposed formulation. Finally, both our novel problem setting and dataset contributions provide new avenues for the research in FedGRL. ",
    "url": "https://arxiv.org/abs/2210.15120",
    "authors": [
      "Susheel Suresh",
      "Danny Godbout",
      "Arko Mukherjee",
      "Mayank Shrivastava",
      "Jennifer Neville",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15125",
    "title": "ViT-CAT: Parallel Vision Transformers with Cross Attention Fusion for  Popularity Prediction in MEC Networks",
    "abstract": "Mobile Edge Caching (MEC) is a revolutionary technology for the Sixth Generation (6G) of wireless networks with the promise to significantly reduce users' latency via offering storage capacities at the edge of the network. The efficiency of the MEC network, however, critically depends on its ability to dynamically predict/update the storage of caching nodes with the top-K popular contents. Conventional statistical caching schemes are not robust to the time-variant nature of the underlying pattern of content requests, resulting in a surge of interest in using Deep Neural Networks (DNNs) for time-series popularity prediction in MEC networks. However, existing DNN models within the context of MEC fail to simultaneously capture both temporal correlations of historical request patterns and the dependencies between multiple contents. This necessitates an urgent quest to develop and design a new and innovative popularity prediction architecture to tackle this critical challenge. The paper addresses this gap by proposing a novel hybrid caching framework based on the attention mechanism. Referred to as the parallel Vision Transformers with Cross Attention (ViT-CAT) Fusion, the proposed architecture consists of two parallel ViT networks, one for collecting temporal correlation, and the other for capturing dependencies between different contents. Followed by a Cross Attention (CA) module as the Fusion Center (FC), the proposed ViT-CAT is capable of learning the mutual information between temporal and spatial correlations, as well, resulting in improving the classification accuracy, and decreasing the model's complexity about 8 times. Based on the simulation results, the proposed ViT-CAT architecture outperforms its counterparts across the classification accuracy, complexity, and cache-hit ratio. ",
    "url": "https://arxiv.org/abs/2210.15125",
    "authors": [
      "Zohreh HajiAkhondi-Meybodi",
      "Arash Mohammadi",
      "Ming Hou",
      "Jamshid Abouei",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.15131",
    "title": "Towards High-Quality Neural TTS for Low-Resource Languages by Learning  Compact Speech Representations",
    "abstract": "This paper aims to enhance low-resource TTS by reducing training data requirements using compact speech representations. A Multi-Stage Multi-Codebook (MSMC) VQ-GAN is trained to learn the representation, MSMCR, and decode it to waveforms. Subsequently, we train the multi-stage predictor to predict MSMCRs from the text for TTS synthesis. Moreover, we optimize the training strategy by leveraging more audio to learn MSMCRs better for low-resource languages. It selects audio from other languages using speaker similarity metric to augment the training set, and applies transfer learning to improve training quality. In MOS tests, the proposed system significantly outperforms FastSpeech and VITS in standard and low-resource scenarios, showing lower data requirements. The proposed training strategy effectively enhances MSMCRs on waveform reconstruction. It improves TTS performance further, which wins 77% votes in the preference test for the low-resource TTS with only 15 minutes of paired data. ",
    "url": "https://arxiv.org/abs/2210.15131",
    "authors": [
      "Haohan Guo",
      "Fenglong Xie",
      "Xixin Wu",
      "Hui Lu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15136",
    "title": "3D Shape Knowledge Graph for Cross-domain and Cross-modal 3D Shape  Retrieval",
    "abstract": "With the development of 3D modeling and fabrication, 3D shape retrieval has become a hot topic. In recent years, several strategies have been put forth to address this retrieval issue. However, it is difficult for them to handle cross-modal 3D shape retrieval because of the natural differences between modalities. In this paper, we propose an innovative concept, namely, geometric words, which is regarded as the basic element to represent any 3D or 2D entity by combination, and assisted by which, we can simultaneously handle cross-domain or cross-modal retrieval problems. First, to construct the knowledge graph, we utilize the geometric word as the node, and then use the category of the 3D shape as well as the attribute of the geometry to bridge the nodes. Second, based on the knowledge graph, we provide a unique way for learning each entity's embedding. Finally, we propose an effective similarity measure to handle the cross-domain and cross-modal 3D shape retrieval. Specifically, every 3D or 2D entity could locate its geometric terms in the 3D knowledge graph, which serve as a link between cross-domain and cross-modal data. Thus, our approach can achieve the cross-domain and cross-modal 3D shape retrieval at the same time. We evaluated our proposed method on the ModelNet40 dataset and ShapeNetCore55 dataset for both the 3D shape retrieval task and cross-domain 3D shape retrieval task. The classic cross-modal dataset (MI3DOR) is utilized to evaluate cross-modal 3D shape retrieval. Experimental results and comparisons with state-of-the-art methods illustrate the superiority of our approach. ",
    "url": "https://arxiv.org/abs/2210.15136",
    "authors": [
      "Weizhi Nie",
      "Rihao Chang",
      "Tong Hao",
      "Anan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15137",
    "title": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "abstract": "Generative Adversarial Networks (GANs) typically suffer from overfitting when limited training data is available. To facilitate GAN training, current methods propose to use data-specific augmentation techniques. Despite the effectiveness, it is difficult for these methods to scale to practical applications. In this work, we present ScoreMix, a novel and scalable data augmentation approach for various image synthesis tasks. We first produce augmented samples using the convex combinations of the real samples. Then, we optimize the augmented samples by minimizing the norms of the data scores, i.e., the gradients of the log-density functions. This procedure enforces the augmented samples close to the data manifold. To estimate the scores, we train a deep estimation network with multi-scale score matching. For different image synthesis tasks, we train the score estimation network using different data. We do not require the tuning of the hyperparameters or modifications to the network architecture. The ScoreMix method effectively increases the diversity of data and reduces the overfitting problem. Moreover, it can be easily incorporated into existing GAN models with minor modifications. Experimental results on numerous tasks demonstrate that GAN models equipped with the ScoreMix method achieve significant improvements. ",
    "url": "https://arxiv.org/abs/2210.15137",
    "authors": [
      "Jie Cao",
      "Mandi Luo",
      "Junchi Yu",
      "Ming-Hsuan Yang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15152",
    "title": "Robust output regulation of linear system subject to modeled and  unmodeled uncertainty",
    "abstract": "In this paper, a novel robust output regulation control framework is proposed for the system subject to noise, modeled disturbance and unmodeled disturbance to seek tracking performance and robustness simultaneously. The output regulation scheme is utilized in the framework to track the reference in the presence of modeled disturbance, and the effect of unmodeled disturbance is reduced by an $\\mathcal{H}_\\infty$ compensator. The Kalman filter can be also introduced in the stabilization loop to deal with the white noise. Furthermore, the tracking error in the presence/absence of noise and disturbance is estimated. The effectiveness and performance of our proposed control framework is verified in the numerical example by applying in the Furuta Inverted Pendulum system. ",
    "url": "https://arxiv.org/abs/2210.15152",
    "authors": [
      "Zhicheng Zhang",
      "Zhiqiang Zuo",
      "Xiang Chen",
      "Ying Tan",
      "Yijing Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15156",
    "title": "Towards Complex Backgrounds: A Unified Difference-Aware Decoder for  Binary Segmentation",
    "abstract": "Binary segmentation is used to distinguish objects of interest from background, and is an active area of convolutional encoder-decoder network research. The current decoders are designed for specific objects based on the common backbones as the encoders, but cannot deal with complex backgrounds. Inspired by the way human eyes detect objects of interest, a new unified dual-branch decoder paradigm named the difference-aware decoder is proposed in this paper to explore the difference between the foreground and the background and separate the objects of interest in optical images. The difference-aware decoder imitates the human eye in three stages using the multi-level features output by the encoder. In Stage A, the first branch decoder of the difference-aware decoder is used to obtain a guide map. The highest-level features are enhanced with a novel field expansion module and a dual residual attention module, and are combined with the lowest-level features to obtain the guide map. In Stage B, the other branch decoder adopts a middle feature fusion module to make trade-offs between textural details and semantic information and generate background-aware features. In Stage C, the proposed difference-aware extractor, consisting of a difference guidance model and a difference enhancement module, fuses the guide map from Stage A and the background-aware features from Stage B, to enlarge the differences between the foreground and the background and output a final detection result. The results demonstrate that the difference-aware decoder can achieve a higher accuracy than the other state-of-the-art binary segmentation methods for these tasks. ",
    "url": "https://arxiv.org/abs/2210.15156",
    "authors": [
      "Jiepan Li",
      "Wei He",
      "Hongyan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15160",
    "title": "Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection",
    "abstract": "Expressions and facial action units (AUs) are two levels of facial behavior descriptors. Expression auxiliary information has been widely used to improve the AU detection performance. However, most existing expression representations can only describe pre-determined discrete categories (e.g., Angry, Disgust, Happy, Sad, etc.) and cannot capture subtle expression transformations like AUs. In this paper, we propose a novel fine-grained \\textsl{Global Expression representation Encoder} to capture subtle and continuous facial movements, to promote AU detection. To obtain such a global expression representation, we propose to train an expression embedding model on a large-scale expression dataset according to global expression similarity. Moreover, considering the local definition of AUs, it is essential to extract local AU features. Therefore, we design a \\textsl{Local AU Features Module} to generate local facial features for each AU. Specifically, it consists of an AU feature map extractor and a corresponding AU mask extractor. First, the two extractors transform the global expression representation into AU feature maps and masks, respectively. Then, AU feature maps and their corresponding AU masks are multiplied to generate AU masked features focusing on local facial region. Finally, the AU masked features are fed into an AU classifier for judging the AU occurrence. Extensive experiment results demonstrate the superiority of our proposed method. Our method validly outperforms previous works and achieves state-of-the-art performances on widely-used face datasets, including BP4D, DISFA, and BP4D+. ",
    "url": "https://arxiv.org/abs/2210.15160",
    "authors": [
      "Rudong An",
      "Wei Zhang",
      "Hao Zeng",
      "Wei Chen",
      "Zhigang Deng",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15176",
    "title": "Domain Adaptive Object Detection for Autonomous Driving under Foggy  Weather",
    "abstract": "Most object detection methods for autonomous driving usually assume a consistent feature distribution between training and testing data, which is not always the case when weathers differ significantly. The object detection model trained under clear weather might not be effective enough in foggy weather because of the domain gap. This paper proposes a novel domain adaptive object detection framework for autonomous driving under foggy weather. Our method leverages both image-level and object-level adaptation to diminish the domain discrepancy in image style and object appearance. To further enhance the model's capabilities under challenging samples, we also come up with a new adversarial gradient reversal layer to perform adversarial mining for the hard examples together with domain adaptation. Moreover, we propose to generate an auxiliary domain by data augmentation to enforce a new domain-level metric regularization. Experimental results on public benchmarks show the effectiveness and accuracy of the proposed method. The code is available at https://github.com/jinlong17/DA-Detect. ",
    "url": "https://arxiv.org/abs/2210.15176",
    "authors": [
      "Jinlong Li",
      "Runsheng Xu",
      "Jin Ma",
      "Qin Zou",
      "Jiaqi Ma",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15178",
    "title": "Anonymized Histograms in Intermediate Privacy Models",
    "abstract": "We study the problem of privately computing the anonymized histogram (a.k.a. unattributed histogram), which is defined as the histogram without item labels. Previous works have provided algorithms with $\\ell_1$- and $\\ell_2^2$-errors of $O_\\varepsilon(\\sqrt{n})$ in the central model of differential privacy (DP). In this work, we provide an algorithm with a nearly matching error guarantee of $\\tilde{O}_\\varepsilon(\\sqrt{n})$ in the shuffle DP and pan-private models. Our algorithm is very simple: it just post-processes the discrete Laplace-noised histogram! Using this algorithm as a subroutine, we show applications in privately estimating symmetric properties of distributions such as entropy, support coverage, and support size. ",
    "url": "https://arxiv.org/abs/2210.15178",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15180",
    "title": "Disentangled and Robust Representation Learning for Bragging  Classification in Social Media",
    "abstract": "Researching bragging behavior on social media arouses interest of computational (socio) linguists. However, existing bragging classification datasets suffer from a serious data imbalance issue. Because labeling a data-balance dataset is expensive, most methods introduce external knowledge to improve model learning. Nevertheless, such methods inevitably introduce noise and non-relevance information from external knowledge. To overcome the drawback, we propose a novel bragging classification method with disentangle-based representation augmentation and domain-aware adversarial strategy. Specifically, model learns to disentangle and reconstruct representation and generate augmented features via disentangle-based representation augmentation. Moreover, domain-aware adversarial strategy aims to constrain domain of augmented features to improve their robustness. Experimental results demonstrate that our method achieves state-of-the-art performance compared to other methods. ",
    "url": "https://arxiv.org/abs/2210.15180",
    "authors": [
      "Xiang Li",
      "Yucheng Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15187",
    "title": "Learning Joint Representation of Human Motion and Language",
    "abstract": "In this work, we present MoLang (a Motion-Language connecting model) for learning joint representation of human motion and language, leveraging both unpaired and paired datasets of motion and language modalities. To this end, we propose a motion-language model with contrastive learning, empowering our model to learn better generalizable representations of the human motion domain. Empirical results show that our model learns strong representations of human motion data through navigating language modality. Our proposed method is able to perform both action recognition and motion retrieval tasks with a single model where it outperforms state-of-the-art approaches on a number of action recognition benchmarks. ",
    "url": "https://arxiv.org/abs/2210.15187",
    "authors": [
      "Jihoon Kim",
      "Youngjae Yu",
      "Seungyoun Shin",
      "Taehyun Byun",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15189",
    "title": "Partially Oblivious Neural Network Inference",
    "abstract": "Oblivious inference is the task of outsourcing a ML model, like neural-networks, without disclosing critical and sensitive information, like the model's parameters. One of the most prominent solutions for secure oblivious inference is based on a powerful cryptographic tools, like Homomorphic Encryption (HE) and/or multi-party computation (MPC). Even though the implementation of oblivious inference systems schemes has impressively improved the last decade, there are still significant limitations on the ML models that they can practically implement. Especially when both the ML model and the input data's confidentiality must be protected. In this paper, we introduce the notion of partially oblivious inference. We empirically show that for neural network models, like CNNs, some information leakage can be acceptable. We therefore propose a novel trade-off between security and efficiency. In our research, we investigate the impact on security and inference runtime performance from the CNN model's weights partial leakage. We experimentally demonstrate that in a CIFAR-10 network we can leak up to $80\\%$ of the model's weights with practically no security impact, while the necessary HE-mutliplications are performed four times faster. ",
    "url": "https://arxiv.org/abs/2210.15189",
    "authors": [
      "Panagiotis Rizomiliotis",
      "Christos Diou",
      "Aikaterini Triakosia",
      "Ilias Kyrannas",
      "Konstantinos Tserpes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15198",
    "title": "Watermarking for Out-of-distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection aims to identify OOD data based on representations extracted from well-trained deep models. However, existing methods largely ignore the reprogramming property of deep models and thus may not fully unleash their intrinsic strength: without modifying parameters of a well-trained deep model, we can reprogram this model for a new purpose via data-level manipulation (e.g., adding a specific feature perturbation to the data). This property motivates us to reprogram a classification model to excel at OOD detection (a new task), and thus we propose a general methodology named watermarking in this paper. Specifically, we learn a unified pattern that is superimposed onto features of original data, and the model's detection capability is largely boosted after watermarking. Extensive experiments verify the effectiveness of watermarking, demonstrating the significance of the reprogramming property of deep models in OOD detection. ",
    "url": "https://arxiv.org/abs/2210.15198",
    "authors": [
      "Qizhou Wang",
      "Feng Liu",
      "Yonggang Zhang",
      "Jing Zhang",
      "Chen Gong",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.15199",
    "title": "Characterising the Robustness of Reinforcement Learning for Continuous  Control using Disturbance Injection",
    "abstract": "In this study, we leverage the deliberate and systematic fault-injection capabilities of an open-source benchmark suite to perform a series of experiments on state-of-the-art deep and robust reinforcement learning algorithms. We aim to benchmark robustness in the context of continuous action spaces -- crucial for deployment in robot control. We find that robustness is more prominent for action disturbances than it is for disturbances to observations and dynamics. We also observe that state-of-the-art approaches that are not explicitly designed to improve robustness perform at a level comparable to that achieved by those that are. Our study and results are intended to provide insight into the current state of safe and robust reinforcement learning and a foundation for the advancement of the field, in particular, for deployment in robotic systems. ",
    "url": "https://arxiv.org/abs/2210.15199",
    "authors": [
      "Catherine R. Glossop",
      "Jacopo Panerati",
      "Amrit Krishnan",
      "Zhaocong Yuan",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15201",
    "title": "Multi-view Contrastive Learning with Additive Margin for Adaptive  Nasopharyngeal Carcinoma Radiotherapy Prediction",
    "abstract": "The prediction of adaptive radiation therapy (ART) prior to radiation therapy (RT) for nasopharyngeal carcinoma (NPC) patients is important to reduce toxicity and prolong the survival of patients. Currently, due to the complex tumor micro-environment, a single type of high-resolution image can provide only limited information. Meanwhile, the traditional softmax-based loss is insufficient for quantifying the discriminative power of a model. To overcome these challenges, we propose a supervised multi-view contrastive learning method with an additive margin (MMCon). For each patient, four medical images are considered to form multi-view positive pairs, which can provide additional information and enhance the representation of medical images. In addition, the embedding space is learned by means of contrastive learning. NPC samples from the same patient or with similar labels will remain close in the embedding space, while NPC samples with different labels will be far apart. To improve the discriminative ability of the loss function, we incorporate a margin into the contrastive learning. Experimental result show this new learning objective can be used to find an embedding space that exhibits superior discrimination ability for NPC images. ",
    "url": "https://arxiv.org/abs/2210.15201",
    "authors": [
      "Jiabao Sheng",
      "Yuanpeng Zhang",
      "Jing Cai",
      "Sai-Kit Lam",
      "Zhe Li",
      "Jiang Zhang",
      "Xinzhi Teng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15205",
    "title": "Torque Controlled Locomotion of a Biped Robot with Link Flexibility",
    "abstract": "When a big and heavy robot moves, it exerts large forces on the environment and on its own structure, its angular momentum can varysubstantially, and even the robot's structure can deform if there is a mechanical weakness. Under these conditions, standard locomotion controllers can fail easily. In this article, we propose a complete control scheme to work with heavy robots in torque control. The full centroidal dynamics is used to generate walking gaits online, link deflections are taken into account to estimate the robot posture and all postural instructions are designed to avoid conflicting with each other, improving balance. These choices reduce model and control errors, allowing our centroidal stabilizer to compensate for the remaining residual errors. The stabilizer and motion generator are designed together to ensure feasibility under the assumption of bounded errors. We deploy this scheme to control the locomotion of the humanoid robot Talos, whose hip links flex when walking. It allows us to reach steps of 35~cm, for an average speed of 25~cm/sec, which is among the best performances so far for torque-controlled electric robots. ",
    "url": "https://arxiv.org/abs/2210.15205",
    "authors": [
      "Nahuel A Villa",
      "Pierre Fernbach",
      "Maximilien Naveau",
      "Guilhem Saurel",
      "Ewen Dantec",
      "Nicolas Mansard",
      "Olivier Stasse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15212",
    "title": "COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with  Contrastive and Distributionally Robust Learning",
    "abstract": "We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to improve the generalization ability of dense retrieval by combating the distribution shifts between source training tasks and target scenarios. To mitigate the impact of document differences, COCO-DR continues pretraining the language model on the target corpora to adapt the model to target distributions via COtinuous COtrastive learning. To prepare for unseen target queries, COCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to reweight samples from different source query clusters for improving model robustness over rare queries during fine-tuning. COCO-DR achieves superior average performance on BEIR, the zero-shot retrieval benchmark. At BERT Base scale, COCO-DR Base outperforms other ZeroDR models with 60x larger size. At BERT Large scale, COCO-DR Large outperforms the giant GPT-3 embedding model which has 500x more parameters. Our analysis show the correlation between COCO-DR's effectiveness in combating distribution shifts and improving zero-shot accuracy. Our code and model can be found at \\url{https://github.com/OpenMatch/COCO-DR}. ",
    "url": "https://arxiv.org/abs/2210.15212",
    "authors": [
      "Yue Yu",
      "Chenyan Xiong",
      "Si Sun",
      "Chao Zhang",
      "Arnold Overwijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15220",
    "title": "End-to-End Pareto Set Prediction with Graph Neural Networks for  Multi-objective Facility Location",
    "abstract": "The facility location problems (FLPs) are a typical class of NP-hard combinatorial optimization problems, which are widely seen in the supply chain and logistics. Many mathematical and heuristic algorithms have been developed for optimizing the FLP. In addition to the transportation cost, there are usually multiple conflicting objectives in realistic applications. It is therefore desirable to design algorithms that find a set of Pareto solutions efficiently without enormous search cost. In this paper, we consider the multi-objective facility location problem (MO-FLP) that simultaneously minimizes the overall cost and maximizes the system reliability. We develop a learning-based approach to predicting the distribution probability of the entire Pareto set for a given problem. To this end, the MO-FLP is modeled as a bipartite graph optimization problem and two graph neural networks are constructed to learn the implicit graph representation on nodes and edges. The network outputs are then converted into the probability distribution of the Pareto set, from which a set of non-dominated solutions can be sampled non-autoregressively. Experimental results on MO-FLP instances of different scales show that the proposed approach achieves a comparable performance to a widely used multi-objective evolutionary algorithm in terms of the solution quality while significantly reducing the computational cost for search. ",
    "url": "https://arxiv.org/abs/2210.15220",
    "authors": [
      "Shiqing Liu",
      "Xueming Yan",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.15221",
    "title": "TASA: Deceiving Question Answering Models by Twin Answer Sentences  Attack",
    "abstract": "We present Twin Answer Sentences Attack (TASA), an adversarial attack method for question answering (QA) models that produces fluent and grammatical adversarial contexts while maintaining gold answers. Despite phenomenal progress on general adversarial attacks, few works have investigated the vulnerability and attack specifically for QA models. In this work, we first explore the biases in the existing models and discover that they mainly rely on keyword matching between the question and context, and ignore the relevant contextual relations for answer prediction. Based on two biases above, TASA attacks the target model in two folds: (1) lowering the model's confidence on the gold answer with a perturbed answer sentence; (2) misguiding the model towards a wrong answer with a distracting answer sentence. Equipped with designed beam search and filtering methods, TASA can generate more effective attacks than existing textual attack methods while sustaining the quality of contexts, in extensive experiments on five QA datasets and human evaluations. ",
    "url": "https://arxiv.org/abs/2210.15221",
    "authors": [
      "Yu Cao",
      "Dianqi Li",
      "Meng Fang",
      "Tianyi Zhou",
      "Jun Gao",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15224",
    "title": "The Effect of Normalization for Bi-directional Amharic-English Neural  Machine Translation",
    "abstract": "Machine translation (MT) is one of the main tasks in natural language processing whose objective is to translate texts automatically from one natural language to another. Nowadays, using deep neural networks for MT tasks has received great attention. These networks require lots of data to learn abstract representations of the input and store it in continuous vectors. This paper presents the first relatively large-scale Amharic-English parallel sentence dataset. Using these compiled data, we build bi-directional Amharic-English translation models by fine-tuning the existing Facebook M2M100 pre-trained model achieving a BLEU score of 37.79 in Amharic-English 32.74 in English-Amharic translation. Additionally, we explore the effects of Amharic homophone normalization on the machine translation task. The results show that the normalization of Amharic homophone characters increases the performance of Amharic-English machine translation in both directions. ",
    "url": "https://arxiv.org/abs/2210.15224",
    "authors": [
      "Tadesse Destaw Belay",
      "Atnafu Lambebo Tonja",
      "Olga Kolesnikova",
      "Seid Muhie Yimam",
      "Abinew Ali Ayele",
      "Silesh Bogale Haile",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15226",
    "title": "Iterative pseudo-forced alignment by acoustic CTC loss for  self-supervised ASR domain adaptation",
    "abstract": "High-quality data labeling from specific domains is costly and human time-consuming. In this work, we propose a self-supervised domain adaptation method, based upon an iterative pseudo-forced alignment algorithm. The produced alignments are employed to customize an end-to-end Automatic Speech Recognition (ASR) and iteratively refined. The algorithm is fed with frame-wise character posteriors produced by a seed ASR, trained with out-of-domain data, and optimized throughout a Connectionist Temporal Classification (CTC) loss. The alignments are computed iteratively upon a corpus of broadcast TV. The process is repeated by reducing the quantity of text to be aligned or expanding the alignment window until finding the best possible audio-text alignment. The starting timestamps, or temporal anchors, are produced uniquely based on the confidence score of the last aligned utterance. This score is computed with the paths of the CTC-alignment matrix. With this methodology, no human-revised text references are required. Alignments from long audio files with low-quality transcriptions, like TV captions, are filtered out by confidence score and ready for further ASR adaptation. The obtained results, on both the Spanish RTVE2022 and CommonVoice databases, underpin the feasibility of using CTC-based systems to perform: highly accurate audio-text alignments, domain adaptation and semi-supervised training of end-to-end ASR. ",
    "url": "https://arxiv.org/abs/2210.15226",
    "authors": [
      "Fernando L\u00f3pez",
      "Jordi Luque"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15247",
    "title": "A few-shot learning approach with domain adaptation for personalized  real-life stress detection in close relationships",
    "abstract": "We design a metric learning approach that aims to address computational challenges that yield from modeling human outcomes from ambulatory real-life data. The proposed metric learning is based on a Siamese neural network (SNN) that learns the relative difference between pairs of samples from a target user and non-target users, thus being able to address the scarcity of labelled data from the target. The SNN further minimizes the Wasserstein distance of the learned embeddings between target and non-target users, thus mitigating the distribution mismatch between the two. Finally, given the fact that the base rate of focal behaviors is different per user, the proposed method approximates the focal base rate based on labelled samples that lay closest to the target, based on which further minimizes the Wasserstein distance. Our method is exemplified for the purpose of hourly stress classification using real-life multimodal data from 72 dating couples. Results in few-shot and one-shot learning experiments indicate that proposed formulation benefits stress classification and can help mitigate the aforementioned challenges. ",
    "url": "https://arxiv.org/abs/2210.15247",
    "authors": [
      "Kexin Feng",
      "Jacqueline B. Duong",
      "Kayla E. Carta",
      "Sierra Walters",
      "Gayla Margolin",
      "Adela C. Timmons",
      "Theodora Chaspari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.15248",
    "title": "Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI",
    "abstract": "With the advance of natural language inference (NLI), a rising demand for NLI is to handle scientific texts. Existing methods depend on pre-trained models (PTM) which lack domain-specific knowledge. To tackle this drawback, we introduce a scientific knowledge graph to generalize PTM to scientific domain. However, existing knowledge graph construction approaches suffer from some drawbacks, i.e., expensive labeled data, failure to apply in other domains, long inference time and difficulty extending to large corpora. Therefore, we propose an unsupervised knowledge graph construction method to build a scientific knowledge graph (SKG) without any labeled data. Moreover, to alleviate noise effect from SKG and complement knowledge in sentences better, we propose an event-centric knowledge infusion method to integrate external knowledge into each event that is a fine-grained semantic unit in sentences. Experimental results show that our method achieves state-of-the-art performance and the effectiveness and reliability of SKG. ",
    "url": "https://arxiv.org/abs/2210.15248",
    "authors": [
      "Chenglin Wang",
      "Yucheng Zhou",
      "Guodong Long",
      "Xiaodong Wang",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15261",
    "title": "A knowledge-driven vowel-based approach of depression classification  from speech using data augmentation",
    "abstract": "We propose a novel explainable machine learning (ML) model that identifies depression from speech, by modeling the temporal dependencies across utterances and utilizing the spectrotemporal information at the vowel level. Our method first models the variable-length utterances at the local-level into a fixed-size vowel-based embedding using a convolutional neural network with a spatial pyramid pooling layer (\"vowel CNN\"). Following that, the depression is classified at the global-level from a group of vowel CNN embeddings that serve as the input of another 1D CNN (\"depression CNN\"). Different data augmentation methods are designed for both the training of vowel CNN and depression CNN. We investigate the performance of the proposed system at various temporal granularities when modeling short, medium, and long analysis windows, corresponding to 10, 21, and 42 utterances, respectively. The proposed method reaches comparable performance with previous state-of-the-art approaches and depicts explainable properties with respect to the depression outcome. The findings from this work may benefit clinicians by providing additional intuitions during joint human-ML decision-making tasks. ",
    "url": "https://arxiv.org/abs/2210.15261",
    "authors": [
      "Kexin Feng",
      "Theodora Chaspari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15279",
    "title": "On the Approximation and Complexity of Deep Neural Networks to Invariant  Functions",
    "abstract": "Recent years have witnessed a hot wave of deep neural networks in various domains; however, it is not yet well understood theoretically. A theoretical characterization of deep neural networks should point out their approximation ability and complexity, i.e., showing which architecture and size are sufficient to handle the concerned tasks. This work takes one step on this direction by theoretically studying the approximation and complexity of deep neural networks to invariant functions. We first prove that the invariant functions can be universally approximated by deep neural networks. Then we show that a broad range of invariant functions can be asymptotically approximated by various types of neural network models that includes the complex-valued neural networks, convolutional neural networks, and Bayesian neural networks using a polynomial number of parameters or optimization iterations. We also provide a feasible application that connects the parameter estimation and forecasting of high-resolution signals with our theoretical conclusions. The empirical results obtained on simulation experiments demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2210.15279",
    "authors": [
      "Gao Zhang",
      "Jin-Hui Wu",
      "Shao-Qun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15283",
    "title": "On Out-of-Distribution Detection for Audio with Deep Nearest Neighbors",
    "abstract": "Out-of-distribution (OOD) detection is concerned with identifying data points that do not belong to the same distribution as the model's training data. For the safe deployment of predictive models in a real-world environment, it is critical to avoid making confident predictions on OOD inputs as it can lead to potentially dangerous consequences. However, OOD detection largely remains an under-explored area in the audio (and speech) domain. This is despite the fact that audio is a central modality for many tasks, such as speaker diarization, automatic speech recognition, and sound event detection. To address this, we propose to leverage feature-space of the model with deep k-nearest neighbors to detect OOD samples. We show that this simple and flexible method effectively detects OOD inputs across a broad category of audio (and speech) datasets. Specifically, it improves the false positive rate (FPR@TPR95) by 17% and the AUROC score by 7% than other prior techniques. ",
    "url": "https://arxiv.org/abs/2210.15283",
    "authors": [
      "Zaharah Bukhsh",
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15285",
    "title": "SAN: a robust end-to-end ASR model architecture",
    "abstract": "In this paper, we propose a novel Siamese Adversarial Network (SAN) architecture for automatic speech recognition, which aims at solving the difficulty of fuzzy audio recognition. Specifically, SAN constructs two sub-networks to differentiate the audio feature input and then introduces a loss to unify the output distribution of these sub-networks. Adversarial learning enables the network to capture more essential acoustic features and helps the models achieve better performance when encountering fuzzy audio input. We conduct numerical experiments with the SAN model on several datasets for the automatic speech recognition task. All experimental results show that the siamese adversarial nets significantly reduce the character error rate (CER). Specifically, we achieve a new state of art 4.37 CER without language model on the AISHELL-1 dataset, which leads to around 5% relative CER reduction. To reveal the generality of the siamese adversarial net, we also conduct experiments on the phoneme recognition task, which also shows the superiority of the siamese adversarial network. ",
    "url": "https://arxiv.org/abs/2210.15285",
    "authors": [
      "Zeping Min",
      "Qian Ge",
      "Guanhua Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15291",
    "title": "Isometric 3D Adversarial Examples in the Physical World",
    "abstract": "3D deep learning models are shown to be as vulnerable to adversarial examples as 2D models. However, existing attack methods are still far from stealthy and suffer from severe performance degradation in the physical world. Although 3D data is highly structured, it is difficult to bound the perturbations with simple metrics in the Euclidean space. In this paper, we propose a novel $\\epsilon$-isometric ($\\epsilon$-ISO) attack to generate natural and robust 3D adversarial examples in the physical world by considering the geometric properties of 3D objects and the invariance to physical transformations. For naturalness, we constrain the adversarial example to be $\\epsilon$-isometric to the original one by adopting the Gaussian curvature as a surrogate metric guaranteed by a theoretical analysis. For invariance to physical transformations, we propose a maxima over transformation (MaxOT) method that actively searches for the most harmful transformations rather than random ones to make the generated adversarial example more robust in the physical world. Experiments on typical point cloud recognition models validate that our approach can significantly improve the attack success rate and naturalness of the generated 3D adversarial examples than the state-of-the-art attack methods. ",
    "url": "https://arxiv.org/abs/2210.15291",
    "authors": [
      "Yibo Miao",
      "Yinpeng Dong",
      "Jun Zhu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15300",
    "title": "Leveraging Computer Vision Application in Visual Arts: A Case Study on  the Use of Residual Neural Network to Classify and Analyze Baroque Paintings",
    "abstract": "With the increasing availability of large digitized fine art collections, automated analysis and classification of paintings is becoming an interesting area of research. However, due to domain specificity, implicit subjectivity, and pervasive nuances that vaguely separate art movements, analyzing art using machine learning techniques poses significant challenges. Residual networks, or variants thereof, are one the most popular tools for image classification tasks, which can extract relevant features for well-defined classes. In this case study, we focus on the classification of a selected painting 'Portrait of the Painter Charles Bruni' by Johann Kupetzky and the analysis of the performance of the proposed classifier. We show that the features extracted during residual network training can be useful for image retrieval within search systems in online art collections. ",
    "url": "https://arxiv.org/abs/2210.15300",
    "authors": [
      "Daniel Kvak"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15304",
    "title": "Explaining the Explainers in Graph Neural Networks: a Comparative Study",
    "abstract": "Following a fast initial breakthrough in graph based learning, Graph Neural Networks (GNNs) have reached a widespread application in many science and engineering fields, prompting the need for methods to understand their decision process. GNN explainers have started to emerge in recent years, with a multitude of methods both novel or adapted from other domains. To sort out this plethora of alternative approaches, several studies have benchmarked the performance of different explainers in terms of various explainability metrics. However, these earlier works make no attempts at providing insights into why different GNN architectures are more or less explainable, or which explainer should be preferred in a given setting. In this survey, we fill these gaps by devising a systematic experimental study, which tests ten explainers on eight representative architectures trained on six carefully designed graph and node classification datasets. With our results we provide key insights on the choice and applicability of GNN explainers, we isolate key components that make them usable and successful and provide recommendations on how to avoid common interpretation pitfalls. We conclude by highlighting open questions and directions of possible future research. ",
    "url": "https://arxiv.org/abs/2210.15304",
    "authors": [
      "Antonio Longa",
      "Steve Azzolin",
      "Gabriele Santin",
      "Giulia Cencetti",
      "Pietro Li\u00f2",
      "Bruno Lepri",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15305",
    "title": "Deformable Temporal Convolutional Networks for Monaural Noisy  Reverberant Speech Separation",
    "abstract": "Speech separation models are used for isolating individual speakers in many speech processing applications. Deep learning models have been shown to lead to state-of-the-art (SOTA) results on a number of speech separation benchmarks. One such class of models known as temporal convolutional networks (TCNs) has shown promising results for speech separation tasks. A limitation of these models is that they have a fixed receptive field (RF). Recent research in speech dereverberation has shown that the optimal RF of a TCN varies with the reverberation characteristics of the speech signal. In this work deformable convolution is proposed as a solution to allow TCN models to have dynamic RFs that can adapt to various reverberation times for reverberant speech separation. The proposed models are capable of achieving an 11.1 dB average scale-invariant signal-to-distortion ratio (SISDR) improvement over the input signal on the WHAMR benchmark. A relatively small deformable TCN model of 1.3M parameters is proposed which gives comparable separation performance to larger and more computationally complex models. ",
    "url": "https://arxiv.org/abs/2210.15305",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15315",
    "title": "Noise in the Clouds: Influence of Network Performance Variability on  Application Scalability",
    "abstract": "Cloud computing represents an appealing opportunity for cost-effective deployment of HPC workloads on the best-fitting hardware. However, although cloud and on-premise HPC systems offer similar computational resources, their network architecture and performance may differ significantly. For example, these systems use fundamentally different network transport and routing protocols, which may introduce network noise that can eventually limit the application scaling. This work analyzes network performance, scalability, and cost of running HPC workloads on cloud systems. First, we consider latency, bandwidth, and collective communication patterns in detailed small-scale measurements, and then we simulate network performance at a larger scale. We validate our approach on four popular cloud providers and three on-premise HPC systems, showing that network (and also OS) noise can significantly impact performance and cost both at small and large scale. ",
    "url": "https://arxiv.org/abs/2210.15315",
    "authors": [
      "Daniele De Sensi",
      "Tiziano De Matteis",
      "Konstantin Taranov",
      "Salvatore Di Girolamo",
      "Tobias Rahn",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.15316",
    "title": "MSF3DDETR: Multi-Sensor Fusion 3D Detection Transformer for Autonomous  Driving",
    "abstract": "3D object detection is a significant task for autonomous driving. Recently with the progress of vision transformers, the 2D object detection problem is being treated with the set-to-set loss. Inspired by these approaches on 2D object detection and an approach for multi-view 3D object detection DETR3D, we propose MSF3DDETR: Multi-Sensor Fusion 3D Detection Transformer architecture to fuse image and LiDAR features to improve the detection accuracy. Our end-to-end single-stage, anchor-free and NMS-free network takes in multi-view images and LiDAR point clouds and predicts 3D bounding boxes. Firstly, we link the object queries learnt from data to the image and LiDAR features using a novel MSF3DDETR cross-attention block. Secondly, the object queries interacts with each other in multi-head self-attention block. Finally, MSF3DDETR block is repeated for $L$ number of times to refine the object queries. The MSF3DDETR network is trained end-to-end on the nuScenes dataset using Hungarian algorithm based bipartite matching and set-to-set loss inspired by DETR. We present both quantitative and qualitative results which are competitive to the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2210.15316",
    "authors": [
      "Gopi Krishna Erabati",
      "Helder Araujo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15318",
    "title": "Efficient and Effective Augmentation Strategy for Adversarial Training",
    "abstract": "Adversarial training of Deep Neural Networks is known to be significantly more data-hungry when compared to standard training. Furthermore, complex data augmentations such as AutoAugment, which have led to substantial gains in standard training of image classifiers, have not been successful with Adversarial Training. We first explain this contrasting behavior by viewing augmentation during training as a problem of domain generalization, and further propose Diverse Augmentation-based Joint Adversarial Training (DAJAT) to use data augmentations effectively in adversarial training. We aim to handle the conflicting goals of enhancing the diversity of the training dataset and training with data that is close to the test distribution by using a combination of simple and complex augmentations with separate batch normalization layers during training. We further utilize the popular Jensen-Shannon divergence loss to encourage the joint learning of the diverse augmentations, thereby allowing simple augmentations to guide the learning of complex ones. Lastly, to improve the computational efficiency of the proposed method, we propose and utilize a two-step defense, Ascending Constraint Adversarial Training (ACAT), that uses an increasing epsilon schedule and weight-space smoothing to prevent gradient masking. The proposed method DAJAT achieves substantially better robustness-accuracy trade-off when compared to existing methods on the RobustBench Leaderboard on ResNet-18 and WideResNet-34-10. The code for implementing DAJAT is available here: https://github.com/val-iisc/DAJAT. ",
    "url": "https://arxiv.org/abs/2210.15318",
    "authors": [
      "Sravanti Addepalli",
      "Samyak Jain",
      "R.Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15353",
    "title": "Learning Discrete Directed Acyclic Graphs via Backpropagation",
    "abstract": "Recently continuous relaxations have been proposed in order to learn Directed Acyclic Graphs (DAGs) from data by backpropagation, instead of using combinatorial optimization. However, a number of techniques for fully discrete backpropagation could instead be applied. In this paper, we explore that direction and propose DAG-DB, a framework for learning DAGs by Discrete Backpropagation. Based on the architecture of Implicit Maximum Likelihood Estimation [I-MLE, arXiv:2106.01798], DAG-DB adopts a probabilistic approach to the problem, sampling binary adjacency matrices from an implicit probability distribution. DAG-DB learns a parameter for the distribution from the loss incurred by each sample, performing competitively using either of two fully discrete backpropagation techniques, namely I-MLE and Straight-Through Estimation. ",
    "url": "https://arxiv.org/abs/2210.15353",
    "authors": [
      "Andrew J. Wren",
      "Pasquale Minervini",
      "Luca Franceschi",
      "Valentina Zantedeschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15358",
    "title": "Leveraging knowledge graphs to update scientific word embeddings using  latent semantic imputation",
    "abstract": "The most interesting words in scientific texts will often be novel or rare. This presents a challenge for scientific word embedding models to determine quality embedding vectors for useful terms that are infrequent or newly emerging. We demonstrate how \\gls{lsi} can address this problem by imputing embeddings for domain-specific words from up-to-date knowledge graphs while otherwise preserving the original word embedding model. We use the MeSH knowledge graph to impute embedding vectors for biomedical terminology without retraining and evaluate the resulting embedding model on a domain-specific word-pair similarity task. We show that LSI can produce reliable embedding vectors for rare and OOV terms in the biomedical domain. ",
    "url": "https://arxiv.org/abs/2210.15358",
    "authors": [
      "Jason Hoelscher-Obermaier",
      "Edward Stevinson",
      "Valentin Stauber",
      "Ivaylo Zhelev",
      "Victor Botev",
      "Ronin Wu",
      "Jeremy Minton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15359",
    "title": "Exploiting modality-invariant feature for robust multimodal emotion  recognition with missing modalities",
    "abstract": "Multimodal emotion recognition leverages complementary information across modalities to gain performance. However, we cannot guarantee that the data of all modalities are always present in practice. In the studies to predict the missing data across modalities, the inherent difference between heterogeneous modalities, namely the modality gap, presents a challenge. To address this, we propose to use invariant features for a missing modality imagination network (IF-MMIN) which includes two novel mechanisms: 1) an invariant feature learning strategy that is based on the central moment discrepancy (CMD) distance under the full-modality scenario; 2) an invariant feature based imagination module (IF-IM) to alleviate the modality gap during the missing modalities prediction, thus improving the robustness of multimodal joint representation. Comprehensive experiments on the benchmark dataset IEMOCAP demonstrate that the proposed model outperforms all baselines and invariantly improves the overall emotion recognition performance under uncertain missing-modality conditions. We release the code at: https://github.com/ZhuoYulang/IF-MMIN. ",
    "url": "https://arxiv.org/abs/2210.15359",
    "authors": [
      "Haolin Zuo",
      "Rui Liu",
      "Jinming Zhao",
      "Guanglai Gao",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15362",
    "title": "A Novel Approach for Neuromorphic Vision Data Compression based on Deep  Belief Network",
    "abstract": "A neuromorphic camera is an image sensor that emulates the human eyes capturing only changes in local brightness levels. They are widely known as event cameras, silicon retinas or dynamic vision sensors (DVS). DVS records asynchronous per-pixel brightness changes, resulting in a stream of events that encode the brightness change's time, location, and polarity. DVS consumes little power and can capture a wider dynamic range with no motion blur and higher temporal resolution than conventional frame-based cameras. Although this method of event capture results in a lower bit rate than traditional video capture, it is further compressible. This paper proposes a novel deep learning-based compression scheme for event data. Using a deep belief network (DBN), the high dimensional event data is reduced into a latent representation and later encoded using an entropy-based coding technique. The proposed scheme is among the first to incorporate deep learning for event compression. It achieves a high compression ratio while maintaining good reconstruction quality outperforming state-of-the-art event data coders and other lossless benchmark techniques. ",
    "url": "https://arxiv.org/abs/2210.15362",
    "authors": [
      "Sally Khaidem",
      "Mansi Sharma",
      "Abhipraay Nevatia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15365",
    "title": "Li3DeTr: A LiDAR based 3D Detection Transformer",
    "abstract": "Inspired by recent advances in vision transformers for object detection, we propose Li3DeTr, an end-to-end LiDAR based 3D Detection Transformer for autonomous driving, that inputs LiDAR point clouds and regresses 3D bounding boxes. The LiDAR local and global features are encoded using sparse convolution and multi-scale deformable attention respectively. In the decoder head, firstly, in the novel Li3DeTr cross-attention block, we link the LiDAR global features to 3D predictions leveraging the sparse set of object queries learnt from the data. Secondly, the object query interactions are formulated using multi-head self-attention. Finally, the decoder layer is repeated $L_{dec}$ number of times to refine the object queries. Inspired by DETR, we employ set-to-set loss to train the Li3DeTr network. Without bells and whistles, the Li3DeTr network achieves 61.3% mAP and 67.6% NDS surpassing the state-of-the-art methods with non-maximum suppression (NMS) on the nuScenes dataset and it also achieves competitive performance on the KITTI dataset. We also employ knowledge distillation (KD) using a teacher and student model that slightly improves the performance of our network. ",
    "url": "https://arxiv.org/abs/2210.15365",
    "authors": [
      "Gopi Krishna Erabati",
      "Helder Araujo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15370",
    "title": "CasNet: Investigating Channel Robustness for Speech Separation",
    "abstract": "Recording channel mismatch between training and testing conditions has been shown to be a serious problem for speech separation. This situation greatly reduces the separation performance, and cannot meet the requirement of daily use. In this study, inheriting the use of our previously constructed TAT-2mix corpus, we address the channel mismatch problem by proposing a channel-aware audio separation network (CasNet), a deep learning framework for end-to-end time-domain speech separation. CasNet is implemented on top of TasNet. Channel embedding (characterizing channel information in a mixture of multiple utterances) generated by Channel Encoder is introduced into the separation module by the FiLM technique. Through two training strategies, we explore two roles that channel embedding may play: 1) a real-life noise disturbance, making the model more robust, or 2) a guide, instructing the separation model to retain the desired channel information. Experimental results on TAT-2mix show that CasNet trained with both training strategies outperforms the TasNet baseline, which does not use channel embeddings. ",
    "url": "https://arxiv.org/abs/2210.15370",
    "authors": [
      "Fan-Lin Wang",
      "Yao-Fei Cheng",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15374",
    "title": "2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth  Estimation",
    "abstract": "Stereo correspondence matching is an essential part of the multi-step stereo depth estimation process. This paper revisits the depth estimation problem, avoiding the explicit stereo matching step using a simple two-tower convolutional neural network. The proposed algorithm is entitled as 2T-UNet. The idea behind 2T-UNet is to replace cost volume construction with twin convolution towers. These towers have an allowance for different weights between them. Additionally, the input for twin encoders in 2T-UNet are different compared to the existing stereo methods. Generally, a stereo network takes a right and left image pair as input to determine the scene geometry. However, in the 2T-UNet model, the right stereo image is taken as one input and the left stereo image along with its monocular depth clue information, is taken as the other input. Depth clues provide complementary suggestions that help enhance the quality of predicted scene geometry. The 2T-UNet surpasses state-of-the-art monocular and stereo depth estimation methods on the challenging Scene flow dataset, both quantitatively and qualitatively. The architecture performs incredibly well on complex natural scenes, highlighting its usefulness for various real-time applications. Pretrained weights and code will be made readily available. ",
    "url": "https://arxiv.org/abs/2210.15374",
    "authors": [
      "Rohit Choudhary",
      "Mansi Sharma",
      "Rithvik Anil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15375",
    "title": "Grasping Causality for the Explanation of Criticality for Automated  Driving",
    "abstract": "The verification and validation of automated driving systems at SAE levels 4 and 5 is a multi-faceted challenge for which classical statistical considerations become infeasible. For this, contemporary approaches suggest a decomposition into scenario classes combined with statistical analysis thereof regarding the emergence of criticality. Unfortunately, these associational approaches may yield spurious inferences, or worse, fail to recognize the causalities leading to critical scenarios, which are, in turn, prerequisite for the development and safeguarding of automated driving systems. As to incorporate causal knowledge within these processes, this work introduces a formalization of causal queries whose answers facilitate a causal understanding of safety-relevant influencing factors for automated driving. This formalized causal knowledge can be used to specify and implement abstract safety principles that provably reduce the criticality associated with these influencing factors. Based on Judea Pearl's causal theory, we define a causal relation as a causal structure together with a context, both related to a domain ontology, where the focus lies on modeling the effect of such influencing factors on criticality as measured by a suitable metric. As to assess modeling quality, we suggest various quantities and evaluate them on a small example. As availability and quality of data are imperative for validly estimating answers to the causal queries, we also discuss requirements on real-world and synthetic data acquisition. We thereby contribute to establishing causal considerations at the heart of the safety processes that are urgently needed as to ensure the safe operation of automated driving systems. ",
    "url": "https://arxiv.org/abs/2210.15375",
    "authors": [
      "Tjark Koopmann",
      "Christian Neurohr",
      "Lina Putze",
      "Lukas Westhofen",
      "Roman Gansch",
      "Ahmad Adee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.15377",
    "title": "Structuring User-Generated Content on Social Media with Multimodal  Aspect-Based Sentiment Analysis",
    "abstract": "People post their opinions and experiences on social media, yielding rich databases of end users' sentiments. This paper shows to what extent machine learning can analyze and structure these databases. An automated data analysis pipeline is deployed to provide insights into user-generated content for researchers in other domains. First, the domain expert can select an image and a term of interest. Then, the pipeline uses image retrieval to find all images showing similar contents and applies aspect-based sentiment analysis to outline users' opinions about the selected term. As part of an interdisciplinary project between architecture and computer science researchers, an empirical study of Hamburg's Elbphilharmonie was conveyed on 300 thousand posts from the platform Flickr with the hashtag 'hamburg'. Image retrieval methods generated a subset of slightly more than 1.5 thousand images displaying the Elbphilharmonie. We found that these posts mainly convey a neutral or positive sentiment towards it. With this pipeline, we suggest a new big data analysis method that offers new insights into end-users opinions, e.g., for architecture domain experts. ",
    "url": "https://arxiv.org/abs/2210.15377",
    "authors": [
      "Miriam Ansch\u00fctz",
      "Tobias Eder",
      "Georg Groh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15387",
    "title": "Automatic Severity Assessment of Dysarthric speech by using  Self-supervised Model with Multi-task Learning",
    "abstract": "Automatic assessment of dysarthric speech is essential for sustained treatments and rehabilitation. However, obtaining atypical speech is challenging, often leading to data scarcity issues. To tackle the problem, we propose a novel automatic severity assessment method for dysarthric speech, using the self-supervised model in conjunction with multi-task learning. Wav2vec 2.0 XLS-R is jointly trained for two different tasks: severity level classification and an auxilary automatic speech recognition (ASR). For the baseline experiments, we employ hand-crafted features such as eGeMaps and linguistic features, and SVM, MLP, and XGBoost classifiers. Explored on the Korean dysarthric speech QoLT database, our model outperforms the traditional baseline methods, with a relative percentage increase of 4.79% for classification accuracy. In addition, the proposed model surpasses the model trained without ASR head, achieving 10.09% relative percentage improvements. Furthermore, we present how multi-task learning affects the severity classification performance by analyzing the latent representations and regularization effect. ",
    "url": "https://arxiv.org/abs/2210.15387",
    "authors": [
      "Eun Jung Yeo",
      "Kwanghee Choi",
      "Sunhee Kim",
      "Minhwa Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15392",
    "title": "LeNo: Adversarial Robust Salient Object Detection Networks with  Learnable Noise",
    "abstract": "Pixel-wise predction with deep neural network has become an effective paradigm for salient object detection (SOD) and achieved remakable performance. However, very few SOD models are robust against adversarial attacks which are visually imperceptible for human visual attention. The previous work robust salient object detection against adversarial attacks (ROSA) shuffles the pre-segmented superpixels and then refines the coarse saliency map by the densely connected CRF. Different from ROSA that rely on various pre- and post-processings, this paper proposes a light-weight Learnble Noise (LeNo) to against adversarial attacks for SOD models. LeNo preserves accuracy of SOD models on both adversarial and clean images, as well as inference speed. In general, LeNo consists of a simple shallow noise and noise estimation that embedded in the encoder and decoder of arbitrary SOD networks respectively. Inspired by the center prior of human visual attention mechanism, we initialize the shallow noise with a cross-shaped gaussian distribution for better defense against adversarial attacks. Instead of adding additional network components for post-processing, the proposed noise estimation modifies only one channel of the decoder. With the deeply-supervised noise-decoupled training on state-of-the-art RGB and RGB-D SOD networks, LeNo outperforms previous works not only on adversarial images but also clean images, which contributes stronger robustness for SOD. ",
    "url": "https://arxiv.org/abs/2210.15392",
    "authors": [
      "He Tang",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15398",
    "title": "Make More of Your Data: Minimal Effort Data Augmentation for Automatic  Speech Recognition and Translation",
    "abstract": "Data augmentation is a technique to generate new training data based on existing data. We evaluate the simple and cost-effective method of concatenating the original data examples to build new training instances. Continued training with such augmented data is able to improve off-the-shelf Transformer and Conformer models that were optimized on the original data only. We demonstrate considerable improvements on the LibriSpeech-960h test sets (WER 2.83 and 6.87 for test-clean and test-other), which carry over to models combined with shallow fusion (WER 2.55 and 6.27). Our method of continued training also leads to improvements of up to 0.9 WER on the ASR part of CoVoST-2 for four non English languages, and we observe that the gains are highly dependent on the size of the original training data. We compare different concatenation strategies and found that our method does not need speaker information to achieve its improvements. Finally, we demonstrate on two datasets that our methods also works for speech translation tasks. ",
    "url": "https://arxiv.org/abs/2210.15398",
    "authors": [
      "Tsz Kin Lam",
      "Shigehiko Schamoni",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15401",
    "title": "Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "abstract": "Video-based remote physiological measurement aims to estimate remote photoplethysmography (rPPG) signals from human face videos and then measure multiple vital signs (e.g. heart rate, respiration frequency) from rPPG signals. Recent approaches achieve it by training deep neural networks, which normally require abundant face videos and synchronously recorded photoplethysmography (PPG) signals for supervision. However, the collection of these annotated corpora is uneasy in practice. In this paper, we introduce a novel frequency-inspired self-supervised framework that learns to estimate rPPG signals from face videos without the need of ground truth PPG signals. Given a video sample, we first augment it into multiple positive/negative samples which contain similar/dissimilar signal frequencies to the original one. Specifically, positive samples are generated using spatial augmentation. Negative samples are generated via a learnable frequency augmentation module, which performs non-linear signal frequency transformation on the input without excessively changing its visual appearance. Next, we introduce a local rPPG expert aggregation module to estimate rPPG signals from augmented samples. It encodes complementary pulsation information from different face regions and aggregate them into one rPPG prediction. Finally, we propose a series of frequency-inspired losses, i.e. frequency contrastive loss, frequency ratio consistency loss, and cross-video frequency agreement loss, for the optimization of estimated rPPG signals from multiple augmented video samples and across temporally neighboring video samples. We conduct rPPG-based heart rate, heart rate variability and respiration frequency estimation on four standard benchmarks. The experimental results demonstrate that our method improves the state of the art by a large margin. ",
    "url": "https://arxiv.org/abs/2210.15401",
    "authors": [
      "Zijie Yue",
      "Miaojing Shi",
      "Shuai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15415",
    "title": "Exact Gradient Computation for Spiking Neural Networks Through Forward  Propagation",
    "abstract": "Spiking neural networks (SNN) have recently emerged as alternatives to traditional neural networks, owing to energy efficiency benefits and capacity to better capture biological neuronal mechanisms. However, the classic backpropagation algorithm for training traditional networks has been notoriously difficult to apply to SNN due to the hard-thresholding and discontinuities at spike times. Therefore, a large majority of prior work believes exact gradients for SNN w.r.t. their weights do not exist and has focused on approximation methods to produce surrogate gradients. In this paper, (1) by applying the implicit function theorem to SNN at the discrete spike times, we prove that, albeit being non-differentiable in time, SNNs have well-defined gradients w.r.t. their weights, and (2) we propose a novel training algorithm, called \\emph{forward propagation} (FP), that computes exact gradients for SNN. FP exploits the causality structure between the spikes and allows us to parallelize computation forward in time. It can be used with other algorithms that simulate the forward pass, and it also provides insights on why other related algorithms such as Hebbian learning and also recently-proposed surrogate gradient methods may perform well. ",
    "url": "https://arxiv.org/abs/2210.15415",
    "authors": [
      "Jane H. Lee",
      "Saeid Haghighatshoar",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.15417",
    "title": "Dynamic Survival Transformers for Causal Inference with Electronic  Health Records",
    "abstract": "In medicine, researchers often seek to infer the effects of a given treatment on patients' outcomes. However, the standard methods for causal survival analysis make simplistic assumptions about the data-generating process and cannot capture complex interactions among patient covariates. We introduce the Dynamic Survival Transformer (DynST), a deep survival model that trains on electronic health records (EHRs). Unlike previous transformers used in survival analysis, DynST can make use of time-varying information to predict evolving survival probabilities. We derive a semi-synthetic EHR dataset from MIMIC-III to show that DynST can accurately estimate the causal effect of a treatment intervention on restricted mean survival time (RMST). We demonstrate that DynST achieves better predictive and causal estimation than two alternative models. ",
    "url": "https://arxiv.org/abs/2210.15417",
    "authors": [
      "Prayag Chatha",
      "Yixin Wang",
      "Zhenke Wu",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.15427",
    "title": "Are You Stealing My Model? Sample Correlation for Fingerprinting Deep  Neural Networks",
    "abstract": "An off-the-shelf model as a commercial service could be stolen by model stealing attacks, posing great threats to the rights of the model owner. Model fingerprinting aims to verify whether a suspect model is stolen from the victim model, which gains more and more attention nowadays. Previous methods always leverage the transferable adversarial examples as the model fingerprint, which is sensitive to adversarial defense or transfer learning scenarios. To address this issue, we consider the pairwise relationship between samples instead and propose a novel yet simple model stealing detection method based on SAmple Correlation (SAC). Specifically, we present SAC-w that selects wrongly classified normal samples as model inputs and calculates the mean correlation among their model outputs. To reduce the training time, we further develop SAC-m that selects CutMix Augmented samples as model inputs, without the need for training the surrogate models or generating adversarial examples. Extensive results validate that SAC successfully defends against various model stealing attacks, even including adversarial training or transfer learning, and detects the stolen models with the best performance in terms of AUC across different datasets and model architectures. The codes are available at https://github.com/guanjiyang/SAC. ",
    "url": "https://arxiv.org/abs/2210.15427",
    "authors": [
      "Jiyang Guan",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15429",
    "title": "Multi-view Representation Learning from Malware to Defend Against  Adversarial Variants",
    "abstract": "Deep learning-based adversarial malware detectors have yielded promising results in detecting never-before-seen malware executables without relying on expensive dynamic behavior analysis and sandbox. Despite their abilities, these detectors have been shown to be vulnerable to adversarial malware variants - meticulously modified, functionality-preserving versions of original malware executables generated by machine learning. Due to the nature of these adversarial modifications, these adversarial methods often use a \\textit{single view} of malware executables (i.e., the binary/hexadecimal view) to generate adversarial malware variants. This provides an opportunity for the defenders (i.e., malware detectors) to detect the adversarial variants by utilizing more than one view of a malware file (e.g., source code view in addition to the binary view). The rationale behind this idea is that while the adversary focuses on the binary view, certain characteristics of the malware file in the source code view remain untouched which leads to the detection of the adversarial malware variants. To capitalize on this opportunity, we propose Adversarially Robust Multiview Malware Defense (ARMD), a novel multi-view learning framework to improve the robustness of DL-based malware detectors against adversarial variants. Our experiments on three renowned open-source deep learning-based malware detectors across six common malware categories show that ARMD is able to improve the adversarial robustness by up to seven times on these malware detectors. ",
    "url": "https://arxiv.org/abs/2210.15429",
    "authors": [
      "James Lee Hu",
      "Mohammadreza Ebrahimi",
      "Weifeng Li",
      "Xin Li",
      "Hsinchun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15446",
    "title": "LP-BFGS attack: An adversarial attack based on the Hessian with limited  pixels",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks. Most white-box attacks are based on the gradient of models to the input. Since the computation and memory budget, adversarial attacks based on the Hessian information are not paid enough attention. In this work, we study the attack performance and computation cost of the attack method based on the Hessian with a limited perturbation pixel number. Specifically, we propose the Limited Pixel BFGS (LP-BFGS) attack method by incorporating the BFGS algorithm. Some pixels are selected as perturbation pixels by the Integrated Gradient algorithm, which are regarded as optimization variables of the LP-BFGS attack. Experimental results across different networks and datasets with various perturbation pixel numbers demonstrate our approach has a comparable attack with an acceptable computation compared with existing solutions. ",
    "url": "https://arxiv.org/abs/2210.15446",
    "authors": [
      "Jiebao Zhang",
      "Wenhua Qian",
      "Rencan Nie",
      "Jinde Cao",
      "Dan Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15449",
    "title": "Conditional Goal-oriented Trajectory Prediction for Interacting Vehicles  with Vectorized Representation",
    "abstract": "This paper aims to tackle the interactive behavior prediction task, and proposes a novel Conditional Goal-oriented Trajectory Prediction (CGTP) framework to jointly generate scene-compliant trajectories of two interacting agents. Our CGTP framework is an end to end and interpretable model, including three main stages: context encoding, goal interactive prediction and trajectory interactive prediction. First, a Goals-of-Interest Network (GoINet) is designed to extract the interactive features between agent-to-agent and agent-to-goals using a graph-based vectorized representation. Further, the Conditional Goal Prediction Network (CGPNet) focuses on goal interactive prediction via a combined form of marginal and conditional goal predictors. Finally, the Goaloriented Trajectory Forecasting Network (GTFNet) is proposed to implement trajectory interactive prediction via the conditional goal-oriented predictors, with the predicted future states of the other interacting agent taken as inputs. In addition, a new goal interactive loss is developed to better learn the joint probability distribution over goal candidates between two interacting agents. In the end, the proposed method is conducted on Argoverse motion forecasting dataset, In-house cut-in dataset, and Waymo open motion dataset. The comparative results demonstrate the superior performance of our proposed CGTP model than the mainstream prediction methods. ",
    "url": "https://arxiv.org/abs/2210.15449",
    "authors": [
      "Ding Li",
      "Qichao Zhang",
      "Shuai Lu",
      "Yifeng Pan",
      "Dongbin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15469",
    "title": "Learning Failure-Inducing Models for Testing Software-Defined Networks",
    "abstract": "Software-defined networks (SDN) enable flexible and effective communication systems, e.g., data centers, that are managed by centralized software controllers. However, such a controller can undermine the underlying communication network of an SDN-based system and thus must be carefully tested. When an SDN-based system fails, in order to address such a failure, engineers need to precisely understand the conditions under which it occurs. In this paper, we introduce a machine learning-guided fuzzing method, named FuzzSDN, aiming at both (1) generating effective test data leading to failures in SDN-based systems and (2) learning accurate failure-inducing models that characterize conditions under which such system fails. This is done in a synergistic manner where models guide test generation and the latter also aims at improving the models. To our knowledge, FuzzSDN is the first attempt to simultaneously address these two objectives for SDNs. We evaluate FuzzSDN by applying it to systems controlled by two open-source SDN controllers. Further, we compare FuzzSDN with two state-of-the-art methods for fuzzing SDNs and two baselines (i.e., simple extensions of these two existing methods) for learning failure-inducing models. Our results show that (1) compared to the state-of-the-art methods, FuzzSDN generates at least 12 times more failures, within the same time budget, with a controller that is fairly robust to fuzzing and (2) our failure-inducing models have, on average, a precision of 98% and a recall of 86%, significantly outperforming the baselines. ",
    "url": "https://arxiv.org/abs/2210.15469",
    "authors": [
      "Rapha\u00ebl Ollando",
      "Seung Yeob Shin",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.15491",
    "title": "GaitMixer: skeleton-based gait representation learning via wide-spectrum  multi-axial mixer",
    "abstract": "Most existing gait recognition methods are appearance-based, which rely on the silhouettes extracted from the video data of human walking activities. The less-investigated skeleton-based gait recognition methods directly learn the gait dynamics from 2D/3D human skeleton sequences, which are theoretically more robust solutions in the presence of appearance changes caused by clothes, hairstyles, and carrying objects. However, the performance of skeleton-based solutions is still largely behind the appearance-based ones. This paper aims to close such performance gap by proposing a novel network model, GaitMixer, to learn more discriminative gait representation from skeleton sequence data. In particular, GaitMixer follows a heterogeneous multi-axial mixer architecture, which exploits the spatial self-attention mixer followed by the temporal large-kernel convolution mixer to learn rich multi-frequency signals in the gait feature maps. Experiments on the widely used gait database, CASIA-B, demonstrate that GaitMixer outperforms the previous SOTA skeleton-based methods by a large margin while achieving a competitive performance compared with the representative appearance-based solutions. Code will be available at https://github.com/exitudio/gaitmixer ",
    "url": "https://arxiv.org/abs/2210.15491",
    "authors": [
      "Ekkasit Pinyoanuntapong",
      "Ayman Ali",
      "Pu Wang",
      "Minwoo Lee",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15495",
    "title": "Leveraging Wikidata's edit history in knowledge graph refinement tasks",
    "abstract": "Knowledge graphs have been adopted in many diverse fields for a variety of purposes. Most of those applications rely on valid and complete data to deliver their results, pressing the need to improve the quality of knowledge graphs. A number of solutions have been proposed to that end, ranging from rule-based approaches to the use of probabilistic methods, but there is an element that has not been considered yet: the edit history of the graph. In the case of collaborative knowledge graphs (e.g., Wikidata), those edits represent the process in which the community reaches some kind of fuzzy and distributed consensus over the information that best represents each entity, and can hold potentially interesting information to be used by knowledge graph refinement methods. In this paper, we explore the use of edit history information from Wikidata to improve the performance of type prediction methods. To do that, we have first built a JSON dataset containing the edit history of every instance from the 100 most important classes in Wikidata. This edit history information is then explored and analyzed, with a focus on its potential applicability in knowledge graph refinement tasks. Finally, we propose and evaluate two new methods to leverage this edit history information in knowledge graph embedding models for type prediction tasks. Our results show an improvement in one of the proposed methods against current approaches, showing the potential of using edit information in knowledge graph refinement tasks and opening new promising research lines within the field. ",
    "url": "https://arxiv.org/abs/2210.15495",
    "authors": [
      "Alejandro Gonzalez-Hevia",
      "Daniel Gayo-Avello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.15504",
    "title": "Perception-aware Tag Placement Planning for Robust Localization of UAVs  in Indoor Construction Environments",
    "abstract": "Tag-based visual-inertial localization is a lightweight method for enabling autonomous data collection missions of low-cost unmanned aerial vehicles (UAVs) in indoor construction environments. However, finding the optimal tag configuration (i.e., number, size, and location) on dynamic construction sites remains challenging. This paper proposes a perception-aware genetic algorithm-based tag placement planner (PGA-TaPP) to determine the optimal tag configuration using 4D-BIM, considering the project progress, safety requirements, and UAV's localizability. The proposed method provides a 4D plan for tag placement by maximizing the localizability in user-specified regions of interest (ROIs) while limiting the installation costs. Localizability is quantified using the Fisher information matrix (FIM) and encapsulated in navigable grids. The experimental results show the effectiveness of our method in finding an optimal 4D tag placement plan for the robust localization of UAVs on under-construction indoor sites. ",
    "url": "https://arxiv.org/abs/2210.15504",
    "authors": [
      "Navid Kayhani",
      "Angela Schoellig",
      "Brenda McCabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15505",
    "title": "Investigating the Origins of Fractality Based on Two Novel Fractal  Network Models",
    "abstract": "Numerous network models have been investigated to gain insights into the origins of fractality. In this work, we introduce two novel network models, to better understand the growing mechanism and structural characteristics of fractal networks. The Repulsion Based Fractal Model (RBFM) is built on the well-known Song-Havlin-Makse (SHM) model, but in RBFM repulsion is always present among a specific group of nodes. The model resolves the contradiction between the SHM model and the Hub Attraction Dynamical Growth model, by showing that repulsion is the characteristic that induces fractality. The Lattice Small-world Transition Model (LSwTM) was motivated by the fact that repulsion directly influences the node distances. Through LSwTM we study the fractal-small-world transition. The model illustrates the transition on a fixed number of nodes and edges using a preferential-attachment-based edge rewiring process. It shows that a small average distance works against fractal scaling, and also demonstrates that fractality is not a dichotomous property, continuous transition can be observed between the pure fractal and non-fractal characteristics. ",
    "url": "https://arxiv.org/abs/2210.15505",
    "authors": [
      "Enik\u0151 Zakar-Poly\u00e1k",
      "Marcell Nagy",
      "Roland Molontay"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.15510",
    "title": "Fusion-based Few-Shot Morphing Attack Detection and Fingerprinting",
    "abstract": "The vulnerability of face recognition systems to morphing attacks has posed a serious security threat due to the wide adoption of face biometrics in the real world. Most existing morphing attack detection (MAD) methods require a large amount of training data and have only been tested on a few predefined attack models. The lack of good generalization properties, especially in view of the growing interest in developing novel morphing attacks, is a critical limitation with existing MAD research. To address this issue, we propose to extend MAD from supervised learning to few-shot learning and from binary detection to multiclass fingerprinting in this paper. Our technical contributions include: 1) We propose a fusion-based few-shot learning (FSL) method to learn discriminative features that can generalize to unseen morphing attack types from predefined presentation attacks; 2) The proposed FSL based on the fusion of the PRNU model and Noiseprint network is extended from binary MAD to multiclass morphing attack fingerprinting (MAF). 3) We have collected a large-scale database, which contains five face datasets and eight different morphing algorithms, to benchmark the proposed few-shot MAF (FS-MAF) method. Extensive experimental results show the outstanding performance of our fusion-based FS-MAF. The code and data will be publicly available at https://github.com/nz0001na/mad maf. ",
    "url": "https://arxiv.org/abs/2210.15510",
    "authors": [
      "Na Zhang",
      "Shan Jia",
      "Siwei Lyu",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15514",
    "title": "Point-Voxel Adaptive Feature Abstraction for Robust Point Cloud  Classification",
    "abstract": "Great progress has been made in point cloud classification with learning-based methods. However, complex scene and sensor inaccuracy in real-world application make point cloud data suffer from corruptions, such as occlusion, noise and outliers. In this work, we propose Point-Voxel based Adaptive (PV-Ada) feature abstraction for robust point cloud classification under various corruptions. Specifically, the proposed framework iteratively voxelize the point cloud and extract point-voxel feature with shared local encoding and Transformer. Then, adaptive max-pooling is proposed to robustly aggregate the point cloud feature for classification. Experiments on ModelNet-C dataset demonstrate that PV-Ada outperforms the state-of-the-art methods. In particular, we rank the $2^{nd}$ place in ModelNet-C classification track of PointCloud-C Challenge 2022, with Overall Accuracy (OA) being 0.865. Code will be available at https://github.com/zhulf0804/PV-Ada. ",
    "url": "https://arxiv.org/abs/2210.15514",
    "authors": [
      "Lifa Zhu",
      "Changwei Lin",
      "Cheng Zheng",
      "Ninghua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15527",
    "title": "Exploiting Features and Logits in Heterogeneous Federated Learning",
    "abstract": "Due to the rapid growth of IoT and artificial intelligence, deploying neural networks on IoT devices is becoming increasingly crucial for edge intelligence. Federated learning (FL) facilitates the management of edge devices to collaboratively train a shared model while maintaining training data local and private. However, a general assumption in FL is that all edge devices are trained on the same machine learning model, which may be impractical considering diverse device capabilities. For instance, less capable devices may slow down the updating process because they struggle to handle large models appropriate for ordinary devices. In this paper, we propose a novel data-free FL method that supports heterogeneous client models by managing features and logits, called Felo; and its extension with a conditional VAE deployed in the server, called Velo. Felo averages the mid-level features and logits from the clients at the server based on their class labels to provide the average features and logits, which are utilized for further training the client models. Unlike Felo, the server has a conditional VAE in Velo, which is used for training mid-level features and generating synthetic features according to the labels. The clients optimize their models based on the synthetic features and the average logits. We conduct experiments on two datasets and show satisfactory performances of our methods compared with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.15527",
    "authors": [
      "Yun-Hin Chan",
      "Edith C.-H. Ngai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15529",
    "title": "Learning Location from Shared Elevation Profiles in Fitness Apps: A  Privacy Perspective",
    "abstract": "The extensive use of smartphones and wearable devices has facilitated many useful applications. For example, with Global Positioning System (GPS)-equipped smart and wearable devices, many applications can gather, process, and share rich metadata, such as geolocation, trajectories, elevation, and time. For example, fitness applications, such as Runkeeper and Strava, utilize the information for activity tracking and have recently witnessed a boom in popularity. Those fitness tracker applications have their own web platforms and allow users to share activities on such platforms or even with other social network platforms. To preserve the privacy of users while allowing sharing, several of those platforms may allow users to disclose partial information, such as the elevation profile for an activity, which supposedly would not leak the location of the users. In this work, and as a cautionary tale, we create a proof of concept where we examine the extent to which elevation profiles can be used to predict the location of users. To tackle this problem, we devise three plausible threat settings under which the city or borough of the targets can be predicted. Those threat settings define the amount of information available to the adversary to launch the prediction attacks. Establishing that simple features of elevation profiles, e.g., spectral features, are insufficient, we devise both natural language processing (NLP)-inspired text-like representation and computer vision-inspired image-like representation of elevation profiles, and we convert the problem at hand into text and image classification problem. We use both traditional machine learning- and deep learning-based techniques and achieve a prediction success rate ranging from 59.59\\% to 99.80\\%. The findings are alarming, highlighting that sharing elevation information may have significant location privacy risks. ",
    "url": "https://arxiv.org/abs/2210.15529",
    "authors": [
      "Ulku Meteriz-Yildiran",
      "Necip Fazil Yildiran",
      "Joongheon Kim",
      "David Mohaisen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15533",
    "title": "Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural  Vocoder",
    "abstract": "Our previous work, the unified source-filter GAN (uSFGAN) vocoder, introduced a novel architecture based on the source-filter theory into the parallel waveform generative adversarial network to achieve high voice quality and pitch controllability. However, the high temporal resolution inputs result in high computation costs. Although the HiFi-GAN vocoder achieves fast high-fidelity voice generation thanks to the efficient upsampling-based generator architecture, the pitch controllability is severely limited. To realize a fast and pitch-controllable high-fidelity neural vocoder, we introduce the source-filter theory into HiFi-GAN by hierarchically conditioning the resonance filtering network on a well-estimated source excitation information. According to the experimental results, our proposed method outperforms HiFi-GAN and uSFGAN on a singing voice generation in voice quality and synthesis speed on a single CPU. Furthermore, unlike the uSFGAN vocoder, the proposed method can be easily adopted/integrated in real-time applications and end-to-end systems. ",
    "url": "https://arxiv.org/abs/2210.15533",
    "authors": [
      "Reo Yoneyama",
      "Yi-Chiao Wu",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15559",
    "title": "Robust Monocular Localization of Drones by Adapting Domain Maps to Depth  Prediction Inaccuracies",
    "abstract": "We present a novel monocular localization framework by jointly training deep learning-based depth prediction and Bayesian filtering-based pose reasoning. The proposed cross-modal framework significantly outperforms deep learning-only predictions with respect to model scalability and tolerance to environmental variations. Specifically, we show little-to-no degradation of pose accuracy even with extremely poor depth estimates from a lightweight depth predictor. Our framework also maintains high pose accuracy in extreme lighting variations compared to standard deep learning, even without explicit domain adaptation. By openly representing the map and intermediate feature maps (such as depth estimates), our framework also allows for faster updates and reusing intermediate predictions for other tasks, such as obstacle avoidance, resulting in much higher resource efficiency. ",
    "url": "https://arxiv.org/abs/2210.15559",
    "authors": [
      "Priyesh Shukla",
      "Sureshkumar S.",
      "Alex C. Stutts",
      "Sathya Ravi",
      "Theja Tulabandhula",
      "Amit R. Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.15567",
    "title": "Training Graph Neural Networks on Growing Stochastic Graphs",
    "abstract": "Graph Neural Networks (GNNs) rely on graph convolutions to exploit meaningful patterns in networked data. Based on matrix multiplications, convolutions incur in high computational costs leading to scalability limitations in practice. To overcome these limitations, proposed methods rely on training GNNs in smaller number of nodes, and then transferring the GNN to larger graphs. Even though these methods are able to bound the difference between the output of the GNN with different number of nodes, they do not provide guarantees against the optimal GNN on the very large graph. In this paper, we propose to learn GNNs on very large graphs by leveraging the limit object of a sequence of growing graphs, the graphon. We propose to grow the size of the graph as we train, and we show that our proposed methodology -- learning by transference -- converges to a neighborhood of a first order stationary point on the graphon data. A numerical experiment validates our proposed approach. ",
    "url": "https://arxiv.org/abs/2210.15567",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15575",
    "title": "A Graph Is More Than Its Nodes: Towards Structured Uncertainty-Aware  Learning on Graphs",
    "abstract": "Current graph neural networks (GNNs) that tackle node classification on graphs tend to only focus on nodewise scores and are solely evaluated by nodewise metrics. This limits uncertainty estimation on graphs since nodewise marginals do not fully characterize the joint distribution given the graph structure. In this work, we propose novel edgewise metrics, namely the edgewise expected calibration error (ECE) and the agree/disagree ECEs, which provide criteria for uncertainty estimation on graphs beyond the nodewise setting. Our experiments demonstrate that the proposed edgewise metrics can complement the nodewise results and yield additional insights. Moreover, we show that GNN models which consider the structured prediction problem on graphs tend to have better uncertainty estimations, which illustrates the benefit of going beyond the nodewise setting. ",
    "url": "https://arxiv.org/abs/2210.15575",
    "authors": [
      "Hans Hao-Hsun Hsu",
      "Yuesong Shen",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15578",
    "title": "GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs",
    "abstract": "Embedding knowledge graphs (KGs) for multi-hop logical reasoning is a challenging problem due to massive and complicated structures in many KGs. Recently, many promising works projected entities and queries into a geometric space to efficiently find answers. However, it remains challenging to model the negation and union operator. The negation operator has no strict boundaries, which generates overlapped embeddings and leads to obtaining ambiguous answers. An additional limitation is that the union operator is non-closure, which undermines the model to handle a series of union operators. To address these problems, we propose a novel probabilistic embedding model, namely Gamma Embeddings (GammaE), for encoding entities and queries to answer different types of FOL queries on KGs. We utilize the linear property and strong boundary support of the Gamma distribution to capture more features of entities and queries, which dramatically reduces model uncertainty. Furthermore, GammaE implements the Gamma mixture method to design the closed union operator. The performance of GammaE is validated on three large logical query datasets. Experimental results show that GammaE significantly outperforms state-of-the-art models on public benchmarks. ",
    "url": "https://arxiv.org/abs/2210.15578",
    "authors": [
      "Dong Yang",
      "Peijun Qing",
      "Yang Li",
      "Haonan Lu",
      "Xiaodong Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.15581",
    "title": "An arbitrary-order discrete rot-rot complex on polygonal meshes with  application to a quad-rot problem",
    "abstract": "In this work, following the discrete de Rham (DDR) approach, we develop a discrete counterpart of a two-dimensional de Rham complex with enhanced regularity. The proposed construction supports general polygonal meshes and arbitrary approximation orders. We establish exactness on a contractible domain for both the versions of the complex with and without boundary conditions and, for the former, prove a complete set of Poincar\\'e-type inequalities. The discrete complex is then used to derive a novel discretisation method for a quad-rot problem which, unlike other schemes in the literature, does not require the forcing term to be prepared. We carry out complete stability and convergence analyses for the proposed scheme and provide numerical validation of the results. ",
    "url": "https://arxiv.org/abs/2210.15581",
    "authors": [
      "Daniele A. Di Pietro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.15586",
    "title": "Joint Multi-Person Body Detection and Orientation Estimation via One  Unified Embedding",
    "abstract": "Human body orientation estimation (HBOE) is widely applied into various applications, including robotics, surveillance, pedestrian analysis and autonomous driving. Although many approaches have been addressing the HBOE problem from specific under-controlled scenes to challenging in-the-wild environments, they assume human instances are already detected and take a well cropped sub-image as the input. This setting is less efficient and prone to errors in real application, such as crowds of people. In the paper, we propose a single-stage end-to-end trainable framework for tackling the HBOE problem with multi-persons. By integrating the prediction of bounding boxes and direction angles in one embedding, our method can jointly estimate the location and orientation of all bodies in one image directly. Our key idea is to integrate the HBOE task into the multi-scale anchor channel predictions of persons for concurrently benefiting from engaged intermediate features. Therefore, our approach can naturally adapt to difficult instances involving low resolution and occlusion as in object detection. We validated the efficiency and effectiveness of our method in the recently presented benchmark MEBOW with extensive experiments. Besides, we completed ambiguous instances ignored by the MEBOW dataset, and provided corresponding weak body-orientation labels to keep the integrity and consistency of it for supporting studies toward multi-persons. Our work is available at \\url{https://github.com/hnuzhy/JointBDOE}. ",
    "url": "https://arxiv.org/abs/2210.15586",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Jiaxin Si",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15614",
    "title": "Private and Reliable Neural Network Inference",
    "abstract": "Reliable neural networks (NNs) provide important inference-time reliability guarantees such as fairness and robustness. Complementarily, privacy-preserving NN inference protects the privacy of client data. So far these two emerging areas have been largely disconnected, yet their combination will be increasingly important. In this work, we present the first system which enables privacy-preserving inference on reliable NNs. Our key idea is to design efficient fully homomorphic encryption (FHE) counterparts for the core algorithmic building blocks of randomized smoothing, a state-of-the-art technique for obtaining reliable models. The lack of required control flow in FHE makes this a demanding task, as na\\\"ive solutions lead to unacceptable runtime. We employ these building blocks to enable privacy-preserving NN inference with robustness and fairness guarantees in a system called Phoenix. Experimentally, we demonstrate that Phoenix achieves its goals without incurring prohibitive latencies. To our knowledge, this is the first work which bridges the areas of client data privacy and reliability guarantees for NNs. ",
    "url": "https://arxiv.org/abs/2210.15614",
    "authors": [
      "Nikola Jovanovi\u0107",
      "Marc Fischer",
      "Samuel Steffen",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.15616",
    "title": "Cross-Domain Neural Entity Linking",
    "abstract": "Entity Linking is the task of matching a mention to an entity in a given knowledge base (KB). It contributes to annotating a massive amount of documents existing on the Web to harness new facts about their matched entities. However, existing Entity Linking systems focus on developing models that are typically domain-dependent and robust only to a particular knowledge base on which they have been trained. The performance is not as adequate when being evaluated on documents and knowledge bases from different domains. Approaches based on pre-trained language models, such as Wu et al. (2020), attempt to solve the problem using a zero-shot setup, illustrating some potential when evaluated on a general-domain KB. Nevertheless, the performance is not equivalent when evaluated on a domain-specific KB. To allow for more accurate Entity Linking across different domains, we propose our framework: Cross-Domain Neural Entity Linking (CDNEL). Our objective is to have a single system that enables simultaneous linking to both the general-domain KB and the domain-specific KB. CDNEL works by learning a joint representation space for these knowledge bases from different domains. It is evaluated using the external Entity Linking dataset (Zeshel) constructed by Logeswaran et al. (2019) and the Reddit dataset collected by Botzer et al. (2021), to compare our proposed method with the state-of-the-art results. The proposed framework uses different types of datasets for fine-tuning, resulting in different model variants of CDNEL. When evaluated on four domains included in the Zeshel dataset, these variants achieve an average precision gain of 9%. ",
    "url": "https://arxiv.org/abs/2210.15616",
    "authors": [
      "Hassan Soliman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15621",
    "title": "Class Based Thresholding in Early Exit Semantic Segmentation Networks",
    "abstract": "We propose Class Based Thresholding (CBT) to reduce the computational cost of early exit semantic segmentation models while preserving the mean intersection over union (mIoU) performance. A key idea of CBT is to exploit the naturally-occurring neural collapse phenomenon. Specifically, by calculating the mean prediction probabilities of each class in the training set, CBT assigns different masking threshold values to each class, so that the computation can be terminated sooner for pixels belonging to easy-to-predict classes. We show the effectiveness of CBT on Cityscapes and ADE20K datasets. CBT can reduce the computational cost by $23\\%$ compared to the previous state-of-the-art early exit models. ",
    "url": "https://arxiv.org/abs/2210.15621",
    "authors": [
      "Alperen G\u00f6rmez",
      "Erdem Koyuncu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15623",
    "title": "Neural Networks with Quantization Constraints",
    "abstract": "Enabling low precision implementations of deep learning models, without considerable performance degradation, is necessary in resource and latency constrained settings. Moreover, exploiting the differences in sensitivity to quantization across layers can allow mixed precision implementations to achieve a considerably better computation performance trade-off. However, backpropagating through the quantization operation requires introducing gradient approximations, and choosing which layers to quantize is challenging for modern architectures due to the large search space. In this work, we present a constrained learning approach to quantization aware training. We formulate low precision supervised learning as a constrained optimization problem, and show that despite its non-convexity, the resulting problem is strongly dual and does away with gradient estimations. Furthermore, we show that dual variables indicate the sensitivity of the objective with respect to constraint perturbations. We demonstrate that the proposed approach exhibits competitive performance in image classification tasks, and leverage the sensitivity result to apply layer selective quantization based on the value of dual variables, leading to considerable performance improvements. ",
    "url": "https://arxiv.org/abs/2210.15623",
    "authors": [
      "Ignacio Hounie",
      "Juan Elenter",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15645",
    "title": "Dragoman: Efficiently Evaluating Declarative Mapping Languages over  Frameworks for Knowledge Graph Creation",
    "abstract": "In recent years, there have been valuable efforts and contributions to make the process of RDF knowledge graph creation traceable and transparent; extending and applying declarative mapping languages is an example. One challenging step is the traceability of procedures that aim to overcome interoperability issues, a.k.a. data-level integration. In most pipelines, data integration is performed by ad-hoc programs, preventing traceability and reusability. However, formal frameworks provided by function-based declarative mapping languages such as FunUL and RML+FnO empower expressiveness. Data-level integration can be defined as functions and integrated as part of the mappings performing schema-level integration. However, combining functions with the mappings introduces a new source of complexity that can considerably impact the required number of resources and execution time. We tackle the problem of efficiently executing mappings with functions and formalize the transformation of them into function-free mappings. These transformations are the basis of an optimization process that aims to perform an eager evaluation of function-based mapping rules. These techniques are implemented in a framework named Dragoman. We demonstrate the correctness of the transformations while ensuring that the function-free data integration processes are equivalent to the original one. The effectiveness of Dragoman is empirically evaluated in 230 testbeds composed of various types of functions integrated with mapping rules of different complexity. The outcomes suggest that evaluating function-free mapping rules reduces execution time in complex knowledge graph creation pipelines composed of large data sources and multiple types of mapping rules. The savings can be up to 75%, suggesting that eagerly executing functions in mapping rules enable making these pipelines applicable and scalable in real-world settings. ",
    "url": "https://arxiv.org/abs/2210.15645",
    "authors": [
      "Samaneh Jozashoori",
      "Enrique Iglesias",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Other Computer Science (cs.OH)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.15651",
    "title": "Learning Single-Index Models with Shallow Neural Networks",
    "abstract": "Single-index models are a class of functions given by an unknown univariate ``link'' function applied to an unknown one-dimensional projection of the input. These models are particularly relevant in high dimension, when the data might present low-dimensional structure that learning algorithms should adapt to. While several statistical aspects of this model, such as the sample complexity of recovering the relevant (one-dimensional) subspace, are well-understood, they rely on tailored algorithms that exploit the specific structure of the target function. In this work, we introduce a natural class of shallow neural networks and study its ability to learn single-index models via gradient flow. More precisely, we consider shallow networks in which biases of the neurons are frozen at random initialization. We show that the corresponding optimization landscape is benign, which in turn leads to generalization guarantees that match the near-optimal sample complexity of dedicated semi-parametric methods. ",
    "url": "https://arxiv.org/abs/2210.15651",
    "authors": [
      "Alberto Bietti",
      "Joan Bruna",
      "Clayton Sanford",
      "Min Jae Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15657",
    "title": "Detecting fake accounts through Generative Adversarial Network in online  social media",
    "abstract": "Nowadays, online social media has become an inseparable part of human life, also this phenomenon is being used by individuals to send messages and share files via videos and images. Twitter, Instagram, and Facebook are well-known samples of these networks. One of the main challenges of privacy for users in these networks is anomalies in security. Anomalies in online social networks can be attributed to illegal behavior, such deviance is done by malicious people like account forgers, online fraudsters, etc. This paper proposed a new method to identify fake user accounts by calculating the similarity measures among users, applying the Generative Adversarial Network (GAN) algorithm over the Twitter dataset. The results of the proposed method showed, accuracy was able to reach 98.1% for classifying and detecting fake user accounts. ",
    "url": "https://arxiv.org/abs/2210.15657",
    "authors": [
      "Jinus Bordbar",
      "Mohammadreza Mohammadrezaie",
      "Saman Ardalan",
      "Mohammad Ebrahim Shiri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14961",
    "title": "A Neural Network Based Automated IFT-20 Sensory Neuron Classifier for  Caenorhabditis elegans",
    "abstract": "Determining neuronal identity in imaging data is an essential task in neuroscience, facilitating the comparison of neural activity across organisms. Cross-organism comparison, in turn, enables a wide variety of research including whole-brain analysis of functional networks and linking the activity of specific neurons to behavior or environmental stimuli. The recent development of three-dimensional, pan-neuronal imaging with single-cell resolution within Caenorhabditis elegans has brought neuron identification, tracking, and activity monitoring all within reach. The nematode C. elegans is often used as a model organism to study neuronal activity due to factors such as its transparency and well-understood nervous system. The principal barrier to high-accuracy neuron identification is that in adult C. elegans, the position of neuronal cell bodies is not stereotyped. Existing approaches to address this issue use genetically encoded markers as an additional identifying feature. For example, the NeuroPAL strain uses multicolored fluorescent reporters. However, this approach has limited use due to the negative effects of excessive genetic modification. In this study, I propose an alternative neuronal identification technique using only single-color fluorescent images. I designed a novel neural network based classifier that automatically labels sensory neurons using an iterative, landmark-based neuron identification process inspired by the manual annotation procedures that humans employ. This design labels sensory neurons in C. elegans with 91.61% accuracy. ",
    "url": "https://arxiv.org/abs/2210.14961",
    "authors": [
      "Arvind Seshan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14974",
    "title": "SINCO: A Novel structural regularizer for image compression using  implicit neural representations",
    "abstract": "Implicit neural representations (INR) have been recently proposed as deep learning (DL) based solutions for image compression. An image can be compressed by training an INR model with fewer weights than the number of image pixels to map the coordinates of the image to corresponding pixel values. While traditional training approaches for INRs are based on enforcing pixel-wise image consistency, we propose to further improve image quality by using a new structural regularizer. We present structural regularization for INR compression (SINCO) as a novel INR method for image compression. SINCO imposes structural consistency of the compressed images to the groundtruth by using a segmentation network to penalize the discrepancy of segmentation masks predicted from compressed images. We validate SINCO on brain MRI images by showing that it can achieve better performance than some recent INR methods. ",
    "url": "https://arxiv.org/abs/2210.14974",
    "authors": [
      "Harry Gao",
      "Weijie Gan",
      "Zhixin Sun",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14982",
    "title": "LinearCoFold and LinearCoPartition: Linear-Time Algorithms for Secondary  Structure Prediction of Interacting RNA molecules",
    "abstract": "Many ncRNAs function through RNA-RNA interactions. Fast and reliable RNA structure prediction with consideration of RNA-RNA interaction is useful. Some existing tools are less accurate due to omitting the competing of intermolecular and intramolecular base pairs, or focus more on predicting the binding region rather than predicting the complete secondary structure of two interacting strands. Vienna RNAcofold, which reduces the problem into the classical single sequence folding by concatenating two strands, scales in cubic time against the combined sequence length, and is slow for long sequences. To address these issues, we present LinearCoFold, which predicts the complete minimum free energy structure of two strands in linear runtime, and LinearCoPartition, which calculates the cofolding partition function and base pairing probabilities in linear runtime. LinearCoFold and LinearCoPartition follows the concatenation strategy of RNAcofold, but are orders of magnitude faster than RNAcofold. For example, on a sequence pair with combined length of 26,190 nt, LinearCoFold is 86.8x faster than RNAcofold MFE mode (0.6 minutes vs. 52.1 minutes), and LinearCoPartition is 642.3x faster than RNAcofold partition function mode (1.8 minutes vs. 1156.2 minutes). Different from the local algorithms, LinearCoFold and LinearCoPartition are global cofolding algorithms without restriction on base pair length. Surprisingly, LinearCoFold and LinearCoPartition's predictions have higher PPV and sensitivity of intermolecular base pairs. Furthermore, we apply LinearCoFold to predict the RNA-RNA interaction between SARS-CoV-2 gRNA and human U4 snRNA, which has been experimentally studied, and observe that LinearCoFold's prediction correlates better to the wet lab results. ",
    "url": "https://arxiv.org/abs/2210.14982",
    "authors": [
      "He Zhang",
      "Sizhen Li",
      "Liang Zhang",
      "David H. Mathews",
      "Liang Huang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Data Structures and Algorithms (cs.DS)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.15044",
    "title": "Generative modeling of the enteric nervous system employing point  pattern analysis and graph construction",
    "abstract": "We describe a generative network model of the architecture of the enteric nervous system (ENS) in the colon employing data from images of human and mouse tissue samples obtained through confocal microscopy. Our models combine spatial point pattern analysis with graph generation to characterize the spatial and topological properties of the ganglia (clusters of neurons and glial cells), the inter-ganglionic connections, and the neuronal organization within the ganglia. We employ a hybrid hardcore-Strauss process for spatial patterns and a planar random graph generation for constructing the spatially embedded network. We show that our generative model may be helpful in both basic and translational studies, and it is sufficiently expressive to model the ENS architecture of individuals who vary in age and health status. Increased understanding of the ENS connectome will enable the use of neuromodulation strategies in treatment and clarify anatomic diagnostic criteria for people with bowel motility disorders. ",
    "url": "https://arxiv.org/abs/2210.15044",
    "authors": [
      "Abida Sanjana Shemonti",
      "Joshua D. Eisenberg",
      "Robert O. Heuckeroth",
      "Marthe J. Howard",
      "Alex Pothen",
      "Bartek Rajwa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2210.15058",
    "title": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "abstract": "In this work we introduce a convolution operation over the tangent bundle of Riemannian manifolds exploiting the Connection Laplacian operator. We use the convolution to define tangent bundle filters and tangent bundle neural networks (TNNs), novel continuous architectures operating on tangent bundle signals, i.e. vector fields over manifolds. We discretize TNNs both in space and time domains, showing that their discrete counterpart is a principled variant of the recently introduced Sheaf Neural Networks. We formally prove that this discrete architecture converges to the underlying continuous TNN. We numerically evaluate the effectiveness of the proposed architecture on a denoising task of a tangent vector field over the unit 2-sphere. ",
    "url": "https://arxiv.org/abs/2210.15058",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15073",
    "title": "Architecture representations for quantum convolutional neural networks",
    "abstract": "The Quantum Convolutional Neural Network (QCNN) is a quantum circuit model inspired by the architecture of Convolutional Neural Networks (CNNs). The success of CNNs is largely due to its ability to learn high level features from raw data rather than requiring manual feature design. Neural Architecture Search (NAS) continues this trend by learning network architecture, alleviating the need for its manual construction and have been able to generate state of the art models automatically. Search space design is a crucial step in NAS and there is currently no formal framework through which it can be achieved for QCNNs. In this work we provide such a framework by utilizing techniques from NAS to create an architectural representation for QCNNs that facilitate search space design and automatic model generation. This is done by specifying primitive operations, such as convolutions and pooling, in such a way that they can be dynamically stacked on top of each other to form different architectures. This way, QCNN search spaces can be created by controlling the sequence and hyperparameters of stacked primitives, allowing the capture of different design motifs. We show this by generating QCNNs that belong to a popular family of parametric quantum circuits, those resembling reverse binary trees. We then benchmark this family of models on a music genre classification dataset, GTZAN. Showing that alternating architecture impact model performance more than other modelling components such as choice of unitary ansatz and data encoding, resulting in a way to improve model performance without increasing its complexity. Finally we provide an open source python package that enable dynamic QCNN creation by system or hand, based off the work presented in this paper, facilitating search space design. ",
    "url": "https://arxiv.org/abs/2210.15073",
    "authors": [
      "Matt Lourens",
      "Ilya Sinayskiy",
      "Daniel K. Park",
      "Carsten Blank",
      "Francesco Petruccione"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15076",
    "title": "Tur\u00e1n graphs with bounded matching number",
    "abstract": "We determine the maximum possible number of edges of a graph with $n$ vertices, matching number at most $s$ and clique number at most $k$ for all admissible values of the parameters. ",
    "url": "https://arxiv.org/abs/2210.15076",
    "authors": [
      "Noga Alon",
      "Peter Frankl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.15083",
    "title": "Deep Learning is Provably Robust to Symmetric Label Noise",
    "abstract": "Deep neural networks (DNNs) are capable of perfectly fitting the training data, including memorizing noisy data. It is commonly believed that memorization hurts generalization. Therefore, many recent works propose mitigation strategies to avoid noisy data or correct memorization. In this work, we step back and ask the question: Can deep learning be robust against massive label noise without any mitigation? We provide an affirmative answer for the case of symmetric label noise: We find that certain DNNs, including under-parameterized and over-parameterized models, can tolerate massive symmetric label noise up to the information-theoretic threshold. By appealing to classical statistical theory and universal consistency of DNNs, we prove that for multiclass classification, $L_1$-consistent DNN classifiers trained under symmetric label noise can achieve Bayes optimality asymptotically if the label noise probability is less than $\\frac{K-1}{K}$, where $K \\ge 2$ is the number of classes. Our results show that for symmetric label noise, no mitigation is necessary for $L_1$-consistent estimators. We conjecture that for general label noise, mitigation strategies that make use of the noisy data will outperform those that ignore the noisy data. ",
    "url": "https://arxiv.org/abs/2210.15083",
    "authors": [
      "Carey E. Priebe",
      "Ningyuan Huang",
      "Soledad Villar",
      "Cong Mu",
      "Li Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15148",
    "title": "Ranking Edges by their Impact on the Spectral Complexity of Information  Diffusion over Networks",
    "abstract": "Despite the numerous ways now available to quantify which parts or subsystems of a network are most important, there remains a lack of centrality measures that are related to the complexity of information flows and are derived directly from entropy measures. Here, we introduce a ranking of edges based on how each edge's removal would change a system's von Neumann entropy (VNE), which is a spectral-entropy measure that has been adapted from quantum information theory to quantify the complexity of information dynamics over networks. We show that a direct calculation of such rankings is computationally inefficient (or unfeasible) for large networks: e.g.\\ the scaling is $\\mathcal{O}(N^3)$ per edge for networks with $N$ nodes. To overcome this limitation, we employ spectral perturbation theory to estimate VNE perturbations and derive an approximate edge-ranking algorithm that is accurate and fast to compute, scaling as $\\mathcal{O}(N)$ per edge. Focusing on a form of VNE that is associated with a transport operator $e^{-\\beta{ L}}$, where ${ L}$ is a graph Laplacian matrix and $\\beta>0$ is a diffusion timescale parameter, we apply this approach to diverse applications including a network encoding polarized voting patterns of the 117th U.S. Senate, a multimodal transportation system including roads and metro lines in London, and a multiplex brain network encoding correlated human brain activity. Our experiments highlight situations where the edges that are considered to be most important for information diffusion complexity can dramatically change as one considers short, intermediate and long timescales $\\beta$ for diffusion. ",
    "url": "https://arxiv.org/abs/2210.15148",
    "authors": [
      "Jeremy Kazimer",
      "Manlio de Domenico",
      "Peter J. Mucha",
      "Dane Taylor"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2210.15149",
    "title": "Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study",
    "abstract": "Despite high global prevalence of hepatic steatosis, no automated diagnostics demonstrated generalizability in detecting steatosis on multiple heterogeneous populations. In this retrospective study, we externally validated a fully automated artificial intelligence (AI) system to detect hepatic steatosis. 1,014 non-contrast enhanced chest computed tomography (CT) scans were collected from eight distinct datasets: LIDC-IDRI, NSCLC-Lung1, RIDER, VESSEL12, RICORD-1A, RICORD-1B, COVID-19-Italy, and COVID-19-China. This three-step AI workflow consists of the following: (i) 3D liver segmentation - a 3D U-Net deep learning model developed for liver segmentation and applied externally without retraining. (ii) liver attenuation measurements by three automatic methods: AI on regions of interest (AI-ROI), AI-3D, and AI-2D; (iii) hepatic steatosis detection. The deep-learning segmentation achieved a mean dice coefficient of 0.957. AI-ROI attenuation measurements showed no significant differences compared to expert measurements (P > 0.05), but AI-3D and AI-2D were significantly different from the expert (P < 0.001). The area under the curve (AUC) of steatosis classification for AI-ROI, AI-3D, and AI-2D are 0.921 (95% CI: 0.883 - 0.959), 0.939 (95% CI: 0.903 - 0.973), and 0.894 (95% CI: 0.850 - 0.938) respectively. If adopted for universal detection, this deep learning system could potentially allow early non-invasive, non-pharmacological preventative interventions for hepatic steatosis. 1,014 expert-annotated liver segmentations of CT images can be downloaded here: https://drive.google.com/drive/folders/1-g_zJeAaZXYXGqL1OeF6pUjr6KB0igJX. ",
    "url": "https://arxiv.org/abs/2210.15149",
    "authors": [
      "Zhongyi Zhang",
      "Guixia Li",
      "Ziqiang Wang",
      "Feng Xia",
      "Ning Zhao",
      "Huibin Nie",
      "Zezhong Ye",
      "Joshua Lin",
      "Yiyi Hui",
      "Xiangchun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15193",
    "title": "A framework of distributionally robust possibilistic optimization",
    "abstract": "In this paper, an optimization problem with uncertain constraint coefficients is considered. Possibility theory is used to model the uncertainty. Namely, a joint possibility distribution in constraint coefficient realizations, called scenarios, is specified. This possibility distribution induces a necessity measure in scenario set, which in turn describes an ambiguity set of probability distributions in scenario set. The distributionally robust approach is then used to convert the imprecise constraints into deterministic equivalents. Namely, the left-hand side of an imprecise constraint is evaluated by using a risk measure with respect to the worst probability distribution that can occur. In this paper, the Conditional Value at Risk is used as the risk measure, which generalizes the strict robust and expected value approaches, commonly used in literature. A general framework for solving such a class of problems is described. Some cases which can be solved in polynomial time are identified. ",
    "url": "https://arxiv.org/abs/2210.15193",
    "authors": [
      "Romain Guillaume",
      "Adam Kasperski",
      "Pawel Zielinski"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.15196",
    "title": "HRTF Field: Unifying Measured HRTF Magnitude Representation with Neural  Fields",
    "abstract": "Head-related transfer functions (HRTFs) are a set of functions of frequency describing the spatial filtering effect of the outer ear (i.e., torso, head, and pinnae) onto sound sources at different azimuth and elevation angles. They are widely used in spatial audio rendering. While the azimuth and elevation angles are intrinsically continuous, measured HRTFs in existing datasets employ different spatial sampling schemes, making it difficult to model HRTFs across datasets. In this work, we propose to use neural fields, a differentiable representation of functions through neural networks, to model HRTFs with arbitrary spatial sampling schemes. Such representation is unified across datasets with different spatial sampling schemes and HRTFs for arbitrary azimuth and elevation angles can be derived from this representation. We further introduce a generative model named HRTF field to learn a latent space of the HRTF neural fields. We demonstrate promising performance on HRTF interpolation and generation tasks and point out potential future work. ",
    "url": "https://arxiv.org/abs/2210.15196",
    "authors": [
      "You Zhang",
      "Yuxiang Wang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15258",
    "title": "Forecasting Graph Signals with Recursive MIMO Graph Filters",
    "abstract": "Forecasting time series on graphs is a fundamental problem in graph signal processing. When each entity of the network carries a vector of values for each time stamp instead of a scalar one, existing approaches resort to the use of product graphs to combine this multidimensional information, at the expense of creating a larger graph. In this paper, we show the limitations of such approaches, and propose extensions to tackle them. Then, we propose a recursive multiple-input multiple-output graph filter which encompasses many already existing models in the literature while being more flexible. Numerical simulations on a real world data set show the effectiveness of the proposed models. ",
    "url": "https://arxiv.org/abs/2210.15258",
    "authors": [
      "Jelmer van der Hoeven",
      "Alberto Natali",
      "Geert Leus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15277",
    "title": "Implications of sparsity and high triangle density for graph  representation learning",
    "abstract": "Recent work has shown that sparse graphs containing many triangles cannot be reproduced using a finite-dimensional representation of the nodes, in which link probabilities are inner products. Here, we show that such graphs can be reproduced using an infinite-dimensional inner product model, where the node representations lie on a low-dimensional manifold. Recovering a global representation of the manifold is impossible in a sparse regime. However, we can zoom in on local neighbourhoods, where a lower-dimensional representation is possible. As our constructions allow the points to be uniformly distributed on the manifold, we find evidence against the common perception that triangles imply community structure. ",
    "url": "https://arxiv.org/abs/2210.15277",
    "authors": [
      "Hannah Sansford",
      "Alexander Modell",
      "Nick Whiteley",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15286",
    "title": "Interplay between exogenous triggers and endogenous behavioral changes  in contagion processes on social networks",
    "abstract": "In recent years, statistical physics' methodologies have proven extremely successful in offering insights into the mechanisms that govern social interactions. However, the question of whether these models are able to capture trends observed in real-world datasets is hardly addressed in the current literature. With this work we aim at bridging the gap between theoretical modeling and validation with data. In particular, we propose a model for opinion dynamics on a social network in the presence of external triggers, framing the interpretation of the model in the context of misbehavior spreading. We divide our population in aware, unaware and zealot/educated agents. Individuals change their status according to two competing dynamics, referred to as behavioral dynamics and broadcasting. The former accounts for information spreading through contact among individuals whereas broadcasting plays the role of an external agent, modeling the effect of mainstream media outlets. Through both simulations and analytical computations we find that the stationary distribution of the fraction of unaware agents in the system undergoes a phase transition when an all-to-all approximation is considered. Surprisingly, such a phase transition disappears in the presence of a minimum fraction of educated agents. Finally, we validate our model using data collected from the public discussion on Twitter, including millions of posts, about the potential adverse effects of the AstraZeneca vaccine against COVID-19. We show that the intervention of external agents, as accounted for in our model, is able to reproduce some key features that are found in this real-world dataset. ",
    "url": "https://arxiv.org/abs/2210.15286",
    "authors": [
      "Clara Eminente",
      "Oriol Artime",
      "Manlio De Domenico"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.15297",
    "title": "Spatio-Temporal Hybrid Fusion of CAE and SWIn Transformers for Lung  Cancer Malignancy Prediction",
    "abstract": "The paper proposes a novel hybrid discovery Radiomics framework that simultaneously integrates temporal and spatial features extracted from non-thin chest Computed Tomography (CT) slices to predict Lung Adenocarcinoma (LUAC) malignancy with minimum expert involvement. Lung cancer is the leading cause of mortality from cancer worldwide and has various histologic types, among which LUAC has recently been the most prevalent. LUACs are classified as pre-invasive, minimally invasive, and invasive adenocarcinomas. Timely and accurate knowledge of the lung nodules malignancy leads to a proper treatment plan and reduces the risk of unnecessary or late surgeries. Currently, chest CT scan is the primary imaging modality to assess and predict the invasiveness of LUACs. However, the radiologists' analysis based on CT images is subjective and suffers from a low accuracy compared to the ground truth pathological reviews provided after surgical resections. The proposed hybrid framework, referred to as the CAET-SWin, consists of two parallel paths: (i) The Convolutional Auto-Encoder (CAE) Transformer path that extracts and captures informative features related to inter-slice relations via a modified Transformer architecture, and; (ii) The Shifted Window (SWin) Transformer path, which is a hierarchical vision transformer that extracts nodules' related spatial features from a volumetric CT scan. Extracted temporal (from the CAET-path) and spatial (from the Swin path) are then fused through a fusion path to classify LUACs. Experimental results on our in-house dataset of 114 pathologically proven Sub-Solid Nodules (SSNs) demonstrate that the CAET-SWin significantly improves reliability of the invasiveness prediction task while achieving an accuracy of 82.65%, sensitivity of 83.66%, and specificity of 81.66% using 10-fold cross-validation. ",
    "url": "https://arxiv.org/abs/2210.15297",
    "authors": [
      "Sadaf Khademi",
      "Shahin Heidarian",
      "Parnian Afshar",
      "Farnoosh Naderkhani",
      "Anastasia Oikonomou",
      "Konstantinos Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15324",
    "title": "Robust Data2vec: Noise-robust Speech Representation Learning for ASR by  Combining Regression and Improved Contrastive Learning",
    "abstract": "Self-supervised pre-training methods based on contrastive learning or regression tasks can utilize more unlabeled data to improve the performance of automatic speech recognition (ASR). However, the robustness impact of combining the two pre-training tasks and constructing different negative samples for contrastive learning still remains unclear. In this paper, we propose a noise-robust data2vec for self-supervised speech representation learning by jointly optimizing the contrastive learning and regression tasks in the pre-training stage. Furthermore, we present two improved methods to facilitate contrastive learning. More specifically, we first propose to construct patch-based non-semantic negative samples to boost the noise robustness of the pre-training model, which is achieved by dividing the features into patches at different sizes (i.e., so-called negative samples). Second, by analyzing the distribution of positive and negative samples, we propose to remove the easily distinguishable negative samples to improve the discriminative capacity for pre-training models. Experimental results on the CHiME-4 dataset show that our method is able to improve the performance of the pre-trained model in noisy scenarios. We find that joint training of the contrastive learning and regression tasks can avoid the model collapse to some extent compared to only training the regression task. ",
    "url": "https://arxiv.org/abs/2210.15324",
    "authors": [
      "Qiu-Shi Zhu",
      "Long Zhou",
      "Jie Zhang",
      "Shu-Jie Liu",
      "Yu-Chen Hu",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15325",
    "title": "Geodesic packing in graphs",
    "abstract": "Given a graph $G$, a geodesic packing in $G$ is a set of vertex-disjoint maximal geodesics, and the geodesic packing number of $G$, ${\\gpack}(G)$, is the maximum cardinality of a geodesic packing in $G$. It is proved that the decision version of the geodesic packing number is NP-complete. We also consider the geodesic transversal number, ${\\gt}(G)$, which is the minimum cardinality of a set of vertices that hit all maximal geodesics in $G$. While $\\gt(G)\\ge \\gpack(G)$ in every graph $G$, the quotient ${\\rm gt}(G)/{\\rm gpack}(G)$ is investigated. By using the rook's graph, it is proved that there does not exist a constant $C < 3$ such that $\\frac{{\\rm gt}(G)}{{\\rm gpack}(G)}\\le C$ would hold for all graphs $G$. If $T$ is a tree, then it is proved that ${\\rm gpack}(T) = {\\rm gt}(T)$, and a linear algorithm for determining ${\\rm gpack}(T)$ is derived. The geodesic packing number is also determined for the strong product of paths. ",
    "url": "https://arxiv.org/abs/2210.15325",
    "authors": [
      "Paul Manuel",
      "Bostjan Bresar",
      "Sandi Klavzar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2210.15336",
    "title": "Multi-class Detection of Pathological Speech with Latent Features: How  does it perform on unseen data?",
    "abstract": "The detection of pathologies from speech features is usually defined as a binary classification task with one class representing a specific pathology and the other class representing healthy speech. In this work, we train neural networks, large margin classifiers, and tree boosting machines to distinguish between four different pathologies: Parkinson's disease, laryngeal cancer, cleft lip and palate, and oral squamous cell carcinoma. We demonstrate that latent representations extracted at different layers of a pre-trained wav2vec 2.0 system can be effectively used to classify these types of pathological voices. We evaluate the robustness of our classifiers by adding room impulse responses to the test data and by applying them to unseen speech corpora. Our approach achieves unweighted average F1-Scores between 74.1% and 96.4%, depending on the model and the noise conditions used. The systems generalize and perform well on unseen data of healthy speakers sampled from a variety of different sources. ",
    "url": "https://arxiv.org/abs/2210.15336",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Franziska Braun",
      "Sebastian P. Bayerl",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15340",
    "title": "Sample-Specific Root Causal Inference with Latent Variables",
    "abstract": "Root causal analysis seeks to identify the set of initial perturbations that induce an unwanted outcome. In prior work, we defined sample-specific root causes of disease using exogenous error terms that predict a diagnosis in a structural equation model. We rigorously quantified predictivity using Shapley values. However, the associated algorithms for inferring root causes assume no latent confounding. We relax this assumption by permitting confounding among the predictors. We then introduce a corresponding procedure called Extract Errors with Latents (EEL) for recovering the error terms up to contamination by vertices on certain paths under the linear non-Gaussian acyclic model. EEL also identifies the smallest sets of dependent errors for fast computation of the Shapley values. The algorithm bypasses the hard problem of estimating the underlying causal graph in both cases. Experiments highlight the superior accuracy and robustness of EEL relative to its predecessors. ",
    "url": "https://arxiv.org/abs/2210.15340",
    "authors": [
      "Eric V. Strobl",
      "Thomas A. Lasko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.15366",
    "title": "Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification",
    "abstract": "Most existing deep learning-based acoustic scene classification (ASC) approaches directly utilize representations extracted from spectrograms to identify target scenes. However, these approaches pay little attention to the audio events occurring in the scene despite they provide crucial semantic information. This paper conducts the first study to investigate whether real-life acoustic scenes can be reliably recognized based only on the features that describe a limited number of audio events. To model the task-specific relationships between coarse-grained acoustic scenes and fine-grained audio events, we propose an event relational graph representation learning (ERGL) framework for ASC. Specifically, the ERGL learns a graph representation of an acoustic scene from the input audio, where the embedding of each event is treated as a node, while the relationship cues derived from each pair of event embeddings are described by a learned multi-dimensional edge feature. Experiments on a polyphonic acoustic scene dataset show that the proposed ERGL achieves competitive performance on ASC by using only a limited number of embeddings of audio events without any data augmentations. The validity of the proposed ERGL framework proves the feasibility of recognizing diverse acoustic scenes based on the event relational graph. Our code is available on project homepage (https://github.com/Yuanbo2020/ERGL). ",
    "url": "https://arxiv.org/abs/2210.15366",
    "authors": [
      "Yuanbo Hou",
      "Siyang Song",
      "Chuang Yu",
      "Yuxin Song",
      "Wenwu Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15385",
    "title": "Self-Supervised Training of Speaker Encoder with Multi-Modal Diverse  Positive Pairs",
    "abstract": "We study a novel neural architecture and its training strategies of speaker encoder for speaker recognition without using any identity labels. The speaker encoder is trained to extract a fixed-size speaker embedding from a spoken utterance of various length. Contrastive learning is a typical self-supervised learning technique. However, the quality of the speaker encoder depends very much on the sampling strategy of positive and negative pairs. It is common that we sample a positive pair of segments from the same utterance. Unfortunately, such poor-man's positive pairs (PPP) lack necessary diversity for the training of a robust encoder. In this work, we propose a multi-modal contrastive learning technique with novel sampling strategies. By cross-referencing between speech and face data, we study a method that finds diverse positive pairs (DPP) for contrastive learning, thus improving the robustness of the speaker encoder. We train the speaker encoder on the VoxCeleb2 dataset without any speaker labels, and achieve an equal error rate (EER) of 2.89\\%, 3.17\\% and 6.27\\% under the proposed progressive clustering strategy, and an EER of 1.44\\%, 1.77\\% and 3.27\\% under the two-stage learning strategy with pseudo labels, on the three test sets of VoxCeleb1. This novel solution outperforms the state-of-the-art self-supervised learning methods by a large margin, at the same time, achieves comparable results with the supervised learning counterpart. We also evaluate our self-supervised learning technique on LRS2 and LRW datasets, where the speaker information is unknown. All experiments suggest that the proposed neural architecture and sampling strategies are robust across datasets. ",
    "url": "https://arxiv.org/abs/2210.15385",
    "authors": [
      "Ruijie Tao",
      "Kong Aik Lee",
      "Rohan Kumar Das",
      "Ville Hautam\u00e4ki",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.15425",
    "title": "HEiMDaL: Highly Efficient Method for Detection and Localization of  wake-words",
    "abstract": "Streaming keyword spotting is a widely used solution for activating voice assistants. Deep Neural Networks with Hidden Markov Model (DNN-HMM) based methods have proven to be efficient and widely adopted in this space, primarily because of the ability to detect and identify the start and end of the wake-up word at low compute cost. However, such hybrid systems suffer from loss metric mismatch when the DNN and HMM are trained independently. Sequence discriminative training cannot fully mitigate the loss-metric mismatch due to the inherent Markovian style of the operation. We propose an low footprint CNN model, called HEiMDaL, to detect and localize keywords in streaming conditions. We introduce an alignment-based classification loss to detect the occurrence of the keyword along with an offset loss to predict the start of the keyword. HEiMDaL shows 73% reduction in detection metrics along with equivalent localization accuracy and with the same memory footprint as existing DNN-HMM style models for a given wake-word. ",
    "url": "https://arxiv.org/abs/2210.15425",
    "authors": [
      "Arnav Kundu",
      "Mohammad Samragh Razlighi",
      "Minsik Cho",
      "Priyanka Padmanabhan",
      "Devang Naik"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15428",
    "title": "Time-Domain Based Embeddings for Spoofed Audio Representation",
    "abstract": "Anti-spoofing is the task of speech authentication. That is, identifying genuine human speech compared to spoofed speech. The main focus of this paper is to suggest new representations for genuine and spoofed speech, based on the probability mass function (PMF) estimation of the audio waveforms' amplitude. We introduce a new feature extraction method for speech audio signals: unlike traditional methods, our method is based on direct processing of time-domain audio samples. The PMF is utilized by designing a feature extractor based on different PMF distances and similarity measures. As an additional step, we used filter-bank preprocessing, which significantly affects the discriminative characteristics of the features and facilitates convenient visualization of possible clustering of spoofing attacks. Furthermore, we use diffusion maps to reveal the underlying manifold on which the data lies. The suggested embeddings allow the use of simple linear separators to achieve decent performance. In addition, we present a convenient way to visualize the data, which helps to assess the efficiency of different spoofing techniques. The experimental results show the potential of using multi-channel PMF based features for the anti-spoofing task, in addition to the benefits of using diffusion maps both as an analysis tool and as an embedding tool. ",
    "url": "https://arxiv.org/abs/2210.15428",
    "authors": [
      "Matan Karo",
      "Arie Yeredor",
      "Itshak Lapidot"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15439",
    "title": "Learning versus Refutation in Noninteractive Local Differential Privacy",
    "abstract": "We study two basic statistical tasks in non-interactive local differential privacy (LDP): learning and refutation. Learning requires finding a concept that best fits an unknown target function (from labelled samples drawn from a distribution), whereas refutation requires distinguishing between data distributions that are well-correlated with some concept in the class, versus distributions where the labels are random. Our main result is a complete characterization of the sample complexity of agnostic PAC learning for non-interactive LDP protocols. We show that the optimal sample complexity for any concept class is captured by the approximate $\\gamma_2$~norm of a natural matrix associated with the class. Combined with previous work [Edmonds, Nikolov and Ullman, 2019] this gives an equivalence between learning and refutation in the agnostic setting. ",
    "url": "https://arxiv.org/abs/2210.15439",
    "authors": [
      "Alexander Edmonds",
      "Aleksandar Nikolov",
      "Toniann Pitassi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15539",
    "title": "Deep Convolutional Neural Networks for Multi-Target Tracking: A Transfer  Learning Approach",
    "abstract": "Multi-target tracking (MTT) is a traditional signal processing task, where the goal is to estimate the states of an unknown number of moving targets from noisy sensor measurements. In this paper, we revisit MTT from a deep learning perspective and propose convolutional neural network (CNN) architectures to tackle it. We represent the target states and sensor measurements as images. Thereby we recast the problem as a image-to-image prediction task for which we train a fully convolutional model. This architecture is motivated by a novel theoretical bound on the transferability error of CNN. The proposed CNN architecture outperforms a GM-PHD filter on the MTT task with 10 targets. The CNN performance transfers without re-training to a larger MTT task with 250 targets with only a $13\\%$ increase in average OSPA. ",
    "url": "https://arxiv.org/abs/2210.15539",
    "authors": [
      "Damian Owerko",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro",
      "Donald J. Bucci Jr",
      "Jennifer Bondarchuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15571",
    "title": "Full-scale Deeply Supervised Attention Network for Segmenting COVID-19  Lesions",
    "abstract": "Automated delineation of COVID-19 lesions from lung CT scans aids the diagnosis and prognosis for patients. The asymmetric shapes and positioning of the infected regions make the task extremely difficult. Capturing information at multiple scales will assist in deciphering features, at global and local levels, to encompass lesions of variable size and texture. We introduce the Full-scale Deeply Supervised Attention Network (FuDSA-Net), for efficient segmentation of corona-infected lung areas in CT images. The model considers activation responses from all levels of the encoding path, encompassing multi-scalar features acquired at different levels of the network. This helps segment target regions (lesions) of varying shape, size and contrast. Incorporation of the entire gamut of multi-scalar characteristics into the novel attention mechanism helps prioritize the selection of activation responses and locations containing useful information. Determining robust and discriminatory features along the decoder path is facilitated with deep supervision. Connections in the decoder arm are remodeled to handle the issue of vanishing gradient. As observed from the experimental results, FuDSA-Net surpasses other state-of-the-art architectures; especially, when it comes to characterizing complicated geometries of the lesions. ",
    "url": "https://arxiv.org/abs/2210.15571",
    "authors": [
      "Pallabi Dutta",
      "Sushmita Mitra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15631",
    "title": "Exploring Effective Distillation of Self-Supervised Speech Models for  Automatic Speech Recognition",
    "abstract": "Recent years have witnessed great strides in self-supervised learning (SSL) on the speech processing. The SSL model is normally pre-trained on a great variety of unlabelled data and a large model size is preferred to increase the modeling capacity. However, this might limit its potential applications due to the expensive computation and memory costs introduced by the oversize model. Miniaturization for SSL models has become an important research direction of practical value. To this end, we explore the effective distillation of HuBERT-based SSL models for automatic speech recognition (ASR). First, in order to establish a strong baseline, a comprehensive study on different student model structures is conducted. On top of this, as a supplement to the regression loss widely adopted in previous works, a discriminative loss is introduced for HuBERT to enhance the distillation performance, especially in low-resource scenarios. In addition, we design a simple and effective algorithm to distill the front-end input from waveform to Fbank feature, resulting in 17% parameter reduction and doubling inference speed, at marginal performance degradation. ",
    "url": "https://arxiv.org/abs/2210.15631",
    "authors": [
      "Yujin Wang",
      "Changli Tang",
      "Ziyang Ma",
      "Zhisheng Zheng",
      "Xie Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1810.00226",
    "title": "Toward single particle reconstruction without particle picking: Breaking  the detection limit",
    "abstract": " Comments: Older citations to this paper refer to version arXiv:1810.00226v1, parts of which now appear in: Tamir Bendory, Nicolas Boumal, William Leeb, Eitan Levin, and Amit Singer. \"Multi-target detection with application to cryo-electron microscopy.\" Inverse Problems 35, no. 10 (2019): 104003 ",
    "url": "https://arxiv.org/abs/1810.00226",
    "authors": [
      "Tamir Bendory",
      "Nicolas Boumal",
      "William Leeb",
      "Eitan Levin",
      "Amit Singer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2008.09682",
    "title": "DecoMine: A Compilation-Based Graph Pattern Mining System with Pattern  Decomposition",
    "abstract": " Title: DecoMine: A Compilation-Based Graph Pattern Mining System with Pattern  Decomposition ",
    "url": "https://arxiv.org/abs/2008.09682",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2010.06154",
    "title": "An Analysis of Robustness of Non-Lipschitz Networks",
    "abstract": " Comments: 42 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2010.06154",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Dravyansh Sharma",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.09091",
    "title": "Colourings of $(m, n)$-coloured mixed graphs",
    "abstract": " Comments: 7 pages, no figures ",
    "url": "https://arxiv.org/abs/2010.09091",
    "authors": [
      "Gary MacGillivray",
      "Shahla Nasserasr",
      "Feiran Yang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2011.01455",
    "title": "Distributed Machine Learning with Strategic Network Design: A  Game-Theoretic Perspective",
    "abstract": " Comments: 13 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2011.01455",
    "authors": [
      "Shutian Liu",
      "Tao Li",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2011.05466",
    "title": "Incorporating Causal Effects into Deep Learning Predictions on EHR Data",
    "abstract": " Comments: 10 pages, 8 figures, in process of SDM ",
    "url": "https://arxiv.org/abs/2011.05466",
    "authors": [
      "Jia Li",
      "Haoyu Yang",
      "Xiaowei Jia",
      "Vipin Kumar",
      "Michael Steinbach",
      "Gyorgy Simon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.03789",
    "title": "Khuzdul: Efficient and Scalable Distributed Graph Pattern Mining Engine",
    "abstract": " Title: Khuzdul: Efficient and Scalable Distributed Graph Pattern Mining Engine ",
    "url": "https://arxiv.org/abs/2105.03789",
    "authors": [
      "Jingji Chen",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2105.07703",
    "title": "The effect of algorithmic bias and network structure on coexistence,  consensus, and polarization of opinions",
    "abstract": " Title: The effect of algorithmic bias and network structure on coexistence,  consensus, and polarization of opinions ",
    "url": "https://arxiv.org/abs/2105.07703",
    "authors": [
      "Antonio F. Peralta",
      "Matteo Neri",
      "J\u00e1nos Kert\u00e9sz",
      "Gerardo I\u00f1iguez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.09249",
    "title": "Self-Supervised Aggregation of Diverse Experts for Test-Agnostic  Long-Tailed Recognition",
    "abstract": " Comments: NeurIPS 2022. Source code: this https URL ",
    "url": "https://arxiv.org/abs/2107.09249",
    "authors": [
      "Yifan Zhang",
      "Bryan Hooi",
      "Lanqing Hong",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.01005",
    "title": "Cerberus: Query-driven Scalable Vulnerability Detection in OAuth Service  Provider Implementations",
    "abstract": " Comments: ACM Conference on Computer and Communications Security (CCS 2022) ",
    "url": "https://arxiv.org/abs/2110.01005",
    "authors": [
      "Tamjid Al Rahat",
      "Yu Feng",
      "Yuan Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.05668",
    "title": "NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks",
    "abstract": " Comments: NeurIPS 2022 Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2110.05668",
    "authors": [
      "Renbo Tu",
      "Nicholas Roberts",
      "Mikhail Khodak",
      "Junhong Shen",
      "Frederic Sala",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03016",
    "title": "Graph neural network initialisation of quantum approximate optimisation",
    "abstract": " Comments: 12 pages, 8 Figures - publised version ",
    "url": "https://arxiv.org/abs/2111.03016",
    "authors": [
      "Nishant Jain",
      "Brian Coyle",
      "Elham Kashefi",
      "Niraj Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01502",
    "title": "Dimensions of Motion: Monocular Prediction through Flow Subspaces",
    "abstract": " Comments: Project page at this https URL ",
    "url": "https://arxiv.org/abs/2112.01502",
    "authors": [
      "Richard Strong Bowen",
      "Richard Tucker",
      "Ramin Zabih",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.02475",
    "title": "Deep Domain Adversarial Adaptation for Photon-efficient Imaging",
    "abstract": " Title: Deep Domain Adversarial Adaptation for Photon-efficient Imaging ",
    "url": "https://arxiv.org/abs/2201.02475",
    "authors": [
      "Yiwei Chen",
      "Gongxin Yao",
      "Yong Liu",
      "Hongye Su",
      "Xiaomin Hu",
      "Yu Pan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03139",
    "title": "Differentially Private Generative Adversarial Networks with Model  Inversion",
    "abstract": " Comments: Best Student Paper Award of 13th IEEE International Workshop on Information Forensics and Security (WIFS 2021), Montpellier, France ",
    "url": "https://arxiv.org/abs/2201.03139",
    "authors": [
      "Dongjie Chen",
      "Sen-ching Samson Cheung",
      "Chen-Nee Chuah",
      "Sally Ozonoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.04124",
    "title": "A Mini-Block Fisher Method for Deep Neural Networks",
    "abstract": " Title: A Mini-Block Fisher Method for Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2202.04124",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.05100",
    "title": "Adaptively Exploiting d-Separators with Causal Bandits",
    "abstract": " Comments: 29 pages, 3 figures. Camera ready version ",
    "url": "https://arxiv.org/abs/2202.05100",
    "authors": [
      "Blair Bilodeau",
      "Linbo Wang",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00871",
    "title": "Dense Voxel Fusion for 3D Object Detection",
    "abstract": " Comments: Accepted in WACV 2023 ",
    "url": "https://arxiv.org/abs/2203.00871",
    "authors": [
      "Anas Mahmoud",
      "Jordan S. K. Hu",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07709",
    "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision  Avoidance in Complex Scenes",
    "abstract": " Comments: accepted by IROS2022 ",
    "url": "https://arxiv.org/abs/2203.07709",
    "authors": [
      "Shuaijun Wang",
      "Rui Gao",
      "Ruihua Han",
      "Shengduo Chen",
      "Chengyang Li",
      "Qi Hao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15277",
    "title": "Decomposed Temporal Dynamic CNN: Efficient Time-Adaptive Network for  Text-Independent Speaker Verification Explained with Speaker Activation Map",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2203.15277",
    "authors": [
      "Seong-Hu Kim",
      "Hyeonuk Nam",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.07667",
    "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language  Models",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.07667",
    "authors": [
      "Weiyan Shi",
      "Ryan Shea",
      "Si Chen",
      "Chiyuan Zhang",
      "Ruoxi Jia",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.01493",
    "title": "On the uncertainty principle of neural networks",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2205.01493",
    "authors": [
      "Jun-Jie Zhang",
      "Dong-Xiao Zhang",
      "Jian-Nan Chen",
      "Long-Gang Pang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2205.10643",
    "title": "Self-Supervised Speech Representation Learning: A Review",
    "abstract": " Title: Self-Supervised Speech Representation Learning: A Review ",
    "url": "https://arxiv.org/abs/2205.10643",
    "authors": [
      "Abdelrahman Mohamed",
      "Hung-yi Lee",
      "Lasse Borgholt",
      "Jakob D. Havtorn",
      "Joakim Edin",
      "Christian Igel",
      "Katrin Kirchhoff",
      "Shang-Wen Li",
      "Karen Livescu",
      "Lars Maal\u00f8e",
      "Tara N. Sainath",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.15680",
    "title": "Simulation-Based Inference with Waldo: Confidence Regions by Leveraging  Prediction Algorithms or Posterior Estimators for Inverse Problems",
    "abstract": " Comments: 15 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2205.15680",
    "authors": [
      "Luca Masserano",
      "Tommaso Dorigo",
      "Rafael Izbicki",
      "Mikael Kuusela",
      "Ann B. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00746",
    "title": "Residual Multiplicative Filter Networks for Multiscale Reconstruction",
    "abstract": " Comments: NeurIPS 2022, Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.00746",
    "authors": [
      "Shayan Shekarforoush",
      "David B. Lindell",
      "David J. Fleet",
      "Marcus A. Brubaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05764",
    "title": "Mining Multi-Label Samples from Single Positive Labels",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.05764",
    "authors": [
      "Youngin Cho",
      "Daejin Kim",
      "Mohammad Azam Khan",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14284",
    "title": "Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs",
    "abstract": " Title: Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs ",
    "url": "https://arxiv.org/abs/2206.14284",
    "authors": [
      "Florian Krach",
      "Marc N\u00fcbel",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2207.00210",
    "title": "Neural Parameterization for Dynamic Human Head Editing",
    "abstract": " Comments: 15 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2207.00210",
    "authors": [
      "Li Ma",
      "Xiaoyu Li",
      "Jing Liao",
      "Xuan Wang",
      "Qi Zhang",
      "Jue Wang",
      "Pedro Sander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2208.01036",
    "title": "Face-to-Face Contrastive Learning for Social Intelligence  Question-Answering",
    "abstract": " Title: Face-to-Face Contrastive Learning for Social Intelligence  Question-Answering ",
    "url": "https://arxiv.org/abs/2208.01036",
    "authors": [
      "Alex Wilf",
      "Martin Q. Ma",
      "Paul Pu Liang",
      "Amir Zadeh",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.02252",
    "title": "GROWN+UP: A Graph Representation Of a Webpage Network Utilizing  Pre-training",
    "abstract": " Comments: Submitted to CIKM '22 ",
    "url": "https://arxiv.org/abs/2208.02252",
    "authors": [
      "Benedict Yeoh",
      "Huijuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.03941",
    "title": "A high-resolution dynamical view on momentum methods for  over-parameterized neural networks",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2208.03941",
    "authors": [
      "Xin Liu",
      "Wei Tao",
      "Jun Wang",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2208.04433",
    "title": "Peer Prediction for Learning Agents",
    "abstract": " Comments: 34 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2208.04433",
    "authors": [
      "Shi Feng",
      "Fang-Yi Yu",
      "Yiling Chen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2208.10607",
    "title": "Individual Tree Detection in Large-Scale Urban Environments using  High-Resolution Multispectral Imagery",
    "abstract": " Title: Individual Tree Detection in Large-Scale Urban Environments using  High-Resolution Multispectral Imagery ",
    "url": "https://arxiv.org/abs/2208.10607",
    "authors": [
      "Jonathan Ventura",
      "Camille Pawlak",
      "Milo Honsberger",
      "Cameron Gonsalves",
      "Julian Rice",
      "Natalie L.R. Love",
      "Skyler Han",
      "Viet Nguyen",
      "Keilana Sugano",
      "Jacqueline Doremus",
      "G. Andrew Fricker",
      "Jenn Yost",
      "Matt Ritter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.12025",
    "title": "Integrating Statistical and Machine Learning Approaches to Identify  Receptive Field Structure in Neural Populations",
    "abstract": " Title: Integrating Statistical and Machine Learning Approaches to Identify  Receptive Field Structure in Neural Populations ",
    "url": "https://arxiv.org/abs/2208.12025",
    "authors": [
      "Mehrad Sarmashghi",
      "Shantanu P. Jadhav",
      "Uri T. Eden"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.14923",
    "title": "Few-Shot Learning for Clinical Natural Language Processing Using Siamese  Neural Networks",
    "abstract": " Title: Few-Shot Learning for Clinical Natural Language Processing Using Siamese  Neural Networks ",
    "url": "https://arxiv.org/abs/2208.14923",
    "authors": [
      "David Oniani",
      "Sonish Sivarajkumar",
      "Yanshan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.01766",
    "title": "Exploring the Verifiability of Code Generated by GitHub Copilot",
    "abstract": " Comments: HATRA workshop at SPLASH 2022 ",
    "url": "https://arxiv.org/abs/2209.01766",
    "authors": [
      "Dakota Wong",
      "Austin Kothig",
      "Patrick Lam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2209.12702",
    "title": "End-to-End Lyrics Recognition with Self-supervised Learning",
    "abstract": " Comments: 4 pages, 2 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2209.12702",
    "authors": [
      "Xiangyu Zhang",
      "Shuyue Stella Li",
      "Zhanhong He",
      "Roberto Togneri",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2209.15214",
    "title": "Construction and Applications of Billion-Scale Pre-trained Multimodal  Business Knowledge Graph",
    "abstract": " Comments: OpenBG. Work in Progress ",
    "url": "https://arxiv.org/abs/2209.15214",
    "authors": [
      "Shumin Deng",
      "Chengming Wang",
      "Zhoubo Li",
      "Ningyu Zhang",
      "Zelin Dai",
      "Hehong Chen",
      "Feiyu Xiong",
      "Ming Yan",
      "Qiang Chen",
      "Mosha Chen",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Bryan Hooi",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01787",
    "title": "Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean  Function Perspective",
    "abstract": " Comments: 37 pages; to appear in NeurIPS 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2210.01787",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.03221",
    "title": "PQLM -- Multilingual Decentralized Portable Quantum Language Model for  Privacy Protection",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.03221",
    "authors": [
      "Shuyue Stella Li",
      "Xiangyu Zhang",
      "Shu Zhou",
      "Hongchao Shu",
      "Ruixing Liang",
      "Hexin Liu",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.05311",
    "title": "CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection",
    "abstract": " Title: CD-FSOD: A Benchmark for Cross-domain Few-shot Object Detection ",
    "url": "https://arxiv.org/abs/2210.05311",
    "authors": [
      "Wuti Xiong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07323",
    "title": "HuBERT-TR: Reviving Turkish Automatic Speech Recognition with  Self-supervised Speech Representation Learning",
    "abstract": " Comments: Submitted to ICASSP2023 ",
    "url": "https://arxiv.org/abs/2210.07323",
    "authors": [
      "Ali Safaya",
      "Engin Erzin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": " Comments: updated affiliations; improved references ",
    "url": "https://arxiv.org/abs/2210.08219",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08629",
    "title": "A Note On $\\ell$-Rauzy Graphs for the Infinite Fibonacci Word",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2210.08629",
    "authors": [
      "Rajavel Praveen M",
      "Rama R"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.10570",
    "title": "Spoofed training data for speech spoofing countermeasure can be  efficiently created using neural vocoders",
    "abstract": " Comments: ICASSP 2023 submission ",
    "url": "https://arxiv.org/abs/2210.10570",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.12415",
    "title": "ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation",
    "abstract": " Title: ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation ",
    "url": "https://arxiv.org/abs/2210.12415",
    "authors": [
      "Zhiying Xu",
      "Jiafan Xu",
      "Hongding Peng",
      "Wei Wang",
      "Xiaoliang Wang",
      "Haoran Wan",
      "Haipeng Dai",
      "Yixu Xu",
      "Hao Cheng",
      "Kun Wang",
      "Guihai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.12548",
    "title": "JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network  for Multi-contrast MRI",
    "abstract": " Title: JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network  for Multi-contrast MRI ",
    "url": "https://arxiv.org/abs/2210.12548",
    "authors": [
      "Lin Zhao",
      "Xiao Chen",
      "Eric Z. Chen",
      "Yikang Liu",
      "Dinggang Shen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13206",
    "title": "Post-Selection Confidence Bounds for Prediction Performance",
    "abstract": " Comments: Changed title, changed layout of figures, added a number to equation 4, added more info to figure captions, added keywords ",
    "url": "https://arxiv.org/abs/2210.13206",
    "authors": [
      "Pascal Rink",
      "Werner Brannath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13318",
    "title": "Time-Domain Speech Enhancement for Robust Automatic Speech Recognition",
    "abstract": " Comments: The co-authors have not approved the current submission ",
    "url": "https://arxiv.org/abs/2210.13318",
    "authors": [
      "Yufeng Yang",
      "Ashutosh Pandey",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14016",
    "title": "Shortest Edit Path Crossover: A Theory-driven Solution to the  Permutation Problem in Evolutionary Neural Architecture Search",
    "abstract": " Comments: 17 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2210.14016",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14164",
    "title": "Model-Free Prediction of Adversarial Drop Points in 3D Point Clouds",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2210.14164",
    "authors": [
      "Hanieh Naderi",
      "Chinthaka Dinesh",
      "Ivan V. Bajic",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14226",
    "title": "FedClassAvg: Local Representation Learning for Personalized Federated  Learning on Heterogeneous Neural Networks",
    "abstract": " Comments: Accepted to ICPP 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2210.14226",
    "authors": [
      "Jaehee Jang",
      "Heonseok Ha",
      "Dahuin Jung",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14404",
    "title": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "abstract": " Title: Adaptive Test-Time Defense with the Manifold Hypothesis ",
    "url": "https://arxiv.org/abs/2210.14404",
    "authors": [
      "Zhaoyuan Yang",
      "Zhiwei Xu",
      "Jing Zhang",
      "Richard Hartley",
      "Peter Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14509",
    "title": "Parallel Gated Neural Network With Attention Mechanism For Speech  Enhancement",
    "abstract": " Comments: 5 pages, 6 figures, references added ",
    "url": "https://arxiv.org/abs/2210.14509",
    "authors": [
      "Jianqiao Cui",
      "Stefan Bleeck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14576",
    "title": "Uncertainty Sentence Sampling by Virtual Adversarial Perturbation",
    "abstract": " Title: Uncertainty Sentence Sampling by Virtual Adversarial Perturbation ",
    "url": "https://arxiv.org/abs/2210.14576",
    "authors": [
      "Hanshan Zhang",
      "Zhen Zhang",
      "Hongfei Jiang",
      "Yang Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14633",
    "title": "Graph Filter Transfer via Probability Density Ratio Weighting",
    "abstract": " Comments: 5 pages, submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.14633",
    "authors": [
      "Koki Yamada"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14862",
    "title": "Visual Semantic Parsing: From Images to Abstract Meaning Representation",
    "abstract": " Comments: published in CoNLL 2022 ",
    "url": "https://arxiv.org/abs/2210.14862",
    "authors": [
      "Mohamed Ashraf Abdelsalam",
      "Zhan Shi",
      "Federico Fancellu",
      "Kalliopi Basioti",
      "Dhaivat J. Bhatt",
      "Vladimir Pavlovic",
      "Afsaneh Fazly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]