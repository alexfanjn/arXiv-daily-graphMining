[
  {
    "id": "arXiv:2210.03734",
    "title": "T2CI-GAN: Text to Compressed Image generation using Generative  Adversarial Network",
    "abstract": "The problem of generating textual descriptions for the visual data has gained research attention in the recent years. In contrast to that the problem of generating visual data from textual descriptions is still very challenging, because it requires the combination of both Natural Language Processing (NLP) and Computer Vision techniques. The existing methods utilize the Generative Adversarial Networks (GANs) and generate the uncompressed images from textual description. However, in practice, most of the visual data are processed and transmitted in the compressed representation. Hence, the proposed work attempts to generate the visual data directly in the compressed representation form using Deep Convolutional GANs (DCGANs) to achieve the storage and computational efficiency. We propose GAN models for compressed image generation from text. The first model is directly trained with JPEG compressed DCT images (compressed domain) to generate the compressed images from text descriptions. The second model is trained with RGB images (pixel domain) to generate JPEG compressed DCT representation from text descriptions. The proposed models are tested on an open source benchmark dataset Oxford-102 Flower images using both RGB and JPEG compressed versions, and accomplished the state-of-the-art performance in the JPEG compressed domain. The code will be publicly released at GitHub after acceptance of paper. ",
    "url": "https://arxiv.org/abs/2210.03734",
    "authors": [
      "Bulla Rajesh",
      "Nandakishore Dusa",
      "Mohammed Javed",
      "Shiv Ram Dubey",
      "P. Nagabhushan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.03746",
    "title": "A deep learning approach to solve forward differential problems on  graphs",
    "abstract": "We propose a novel deep learning (DL) approach to solve one-dimensional non-linear elliptic, parabolic, and hyperbolic problems on graphs. A system of physics-informed neural network (PINN) models is used to solve the differential equations, by assigning each PINN model to a specific edge of the graph. Kirkhoff-Neumann (KN) nodal conditions are imposed in a weak form by adding a penalization term to the training loss function. Through the penalization term that imposes the KN conditions, PINN models associated with edges that share a node coordinate with each other to ensure continuity of the solution and of its directional derivatives computed along the respective edges. Using individual PINN models for each edge of the graph allows our approach to fulfill necessary requirements for parallelization by enabling different PINN models to be trained on distributed compute resources. Numerical results show that the system of PINN models accurately approximate the solutions of the differential problems across the entire graph for a broad set of graph topologies. ",
    "url": "https://arxiv.org/abs/2210.03746",
    "authors": [
      "Yuanyuan Zhao",
      "Massimiliano Lupo Pasini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.03768",
    "title": "xDBTagger: Explainable Natural Language Interface to Databases Using  Keyword Mappings and Schema Graph",
    "abstract": "Translating natural language queries (NLQ) into structured query language (SQL) in interfaces to relational databases is a challenging task that has been widely studied by researchers from both the database and natural language processing communities. Numerous works have been proposed to attack the natural language interfaces to databases (NLIDB) problem either as a conventional pipeline-based or an end-to-end deep-learning-based solution. Nevertheless, regardless of the approach preferred, such solutions exhibit black-box nature, which makes it difficult for potential users targeted by these systems to comprehend the decisions made to produce the translated SQL. To this end, we propose xDBTagger, an explainable hybrid translation pipeline that explains the decisions made along the way to the user both textually and visually. We also evaluate xDBTagger quantitatively in three real-world relational databases. The evaluation results indicate that in addition to being fully interpretable, xDBTagger is effective in terms of accuracy and translates the queries more efficiently compared to other state-of-the-art pipeline-based systems up to 10000 times. ",
    "url": "https://arxiv.org/abs/2210.03768",
    "authors": [
      "Arif Usta",
      "Akifhan Karakayali",
      "\u00d6zg\u00fcr Ulusoy"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.03773",
    "title": "In What Ways Are Deep Neural Networks Invariant and How Should We  Measure This?",
    "abstract": "It is often said that a deep learning model is \"invariant\" to some specific type of transformation. However, what is meant by this statement strongly depends on the context in which it is made. In this paper we explore the nature of invariance and equivariance of deep learning models with the goal of better understanding the ways in which they actually capture these concepts on a formal level. We introduce a family of invariance and equivariance metrics that allows us to quantify these properties in a way that disentangles them from other metrics such as loss or accuracy. We use our metrics to better understand the two most popular methods used to build invariance into networks: data augmentation and equivariant layers. We draw a range of conclusions about invariance and equivariance in deep learning models, ranging from whether initializing a model with pretrained weights has an effect on a trained model's invariance, to the extent to which invariance learned via training can generalize to out-of-distribution data. ",
    "url": "https://arxiv.org/abs/2210.03773",
    "authors": [
      "Henry Kvinge",
      "Tegan H. Emerson",
      "Grayson Jorgenson",
      "Scott Vasquez",
      "Timothy Doster",
      "Jesse D. Lew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03794",
    "title": "SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained  Models",
    "abstract": "Vision-language models such as CLIP are pretrained on large volumes of internet sourced image and text pairs, and have been shown to sometimes exhibit impressive zero- and low-shot image classification performance. However, due to their size, fine-tuning these models on new datasets can be prohibitively expensive, both in terms of the supervision and compute required. To combat this, a series of light-weight adaptation methods have been proposed to efficiently adapt such models when limited supervision is available. In this work, we show that while effective on internet-style datasets, even those remedies under-deliver on classification tasks with images that differ significantly from those commonly found online. To address this issue, we present a new approach called SVL-Adapter that combines the complementary strengths of both vision-language pretraining and self-supervised representation learning. We report an average classification accuracy improvement of 10% in the low-shot setting when compared to existing methods, on a set of challenging visual classification tasks. Further, we present a fully automatic way of selecting an important blending hyperparameter for our model that does not require any held-out labeled validation data. Code for our project is available here: https://github.com/omipan/svl_adapter. ",
    "url": "https://arxiv.org/abs/2210.03794",
    "authors": [
      "Omiros Pantazis",
      "Gabriel Brostow",
      "Kate Jones",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03820",
    "title": "The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks",
    "abstract": "In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with homogeneous activations, even those with biases, residual connections, and normalization layers, while structured enough to enable geometric analysis of its gradient dynamics. Using this analysis, we generalize the existing results of maximum-margin bias for homogeneous networks to this richer class of models. We find that gradient flow implicitly favors a subset of the parameters, unlike in the case of a homogeneous model where all parameters are treated equally. We demonstrate through simple examples how this strong favoritism toward minimizing an asymmetric norm can degrade the robustness of quasi-homogeneous models. On the other hand, we conjecture that this norm-minimization discards, when possible, unnecessary higher-order parameters, reducing the model to a sparser parameterization. Lastly, by applying our theorem to sufficiently expressive neural networks with normalization layers, we reveal a universal mechanism behind the empirical phenomenon of Neural Collapse. ",
    "url": "https://arxiv.org/abs/2210.03820",
    "authors": [
      "Daniel Kunin",
      "Atsushi Yamamura",
      "Chao Ma",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.03825",
    "title": "See, Plan, Predict: Language-guided Cognitive Planning with Video  Prediction",
    "abstract": "Cognitive planning is the structural decomposition of complex tasks into a sequence of future behaviors. In the computational setting, performing cognitive planning entails grounding plans and concepts in one or more modalities in order to leverage them for low level control. Since real-world tasks are often described in natural language, we devise a cognitive planning algorithm via language-guided video prediction. Current video prediction models do not support conditioning on natural language instructions. Therefore, we propose a new video prediction architecture which leverages the power of pre-trained transformers.The network is endowed with the ability to ground concepts based on natural language input with generalization to unseen objects. We demonstrate the effectiveness of this approach on a new simulation dataset, where each task is defined by a high-level action described in natural language. Our experiments compare our method again stone video generation baseline without planning or action grounding and showcase significant improvements. Our ablation studies highlight an improved generalization to unseen objects that natural language embeddings offer to concept grounding ability, as well as the importance of planning towards visual \"imagination\" of a task. ",
    "url": "https://arxiv.org/abs/2210.03825",
    "authors": [
      "Maria Attarian",
      "Advaya Gupta",
      "Ziyi Zhou",
      "Wei Yu",
      "Igor Gilitschenski",
      "Animesh Garg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.03828",
    "title": "Sampling-Based Decomposition Algorithms for Arbitrary Tensor Networks",
    "abstract": "We show how to develop sampling-based alternating least squares (ALS) algorithms for decomposition of tensors into any tensor network (TN) format. Provided the TN format satisfies certain mild assumptions, resulting algorithms will have input sublinear per-iteration cost. Unlike most previous works on sampling-based ALS methods for tensor decomposition, the sampling in our framework is done according to the exact leverage score distribution of the design matrices in the ALS subproblems. We implement and test two tensor decomposition algorithms that use our sampling framework in a feature extraction experiment where we compare them against a number of other decomposition algorithms. ",
    "url": "https://arxiv.org/abs/2210.03828",
    "authors": [
      "Osman Asif Malik",
      "Vivek Bharadwaj",
      "Riley Murray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03829",
    "title": "Early Detection of Bark Beetle Attack Using Remote Sensing and Machine  Learning: A Review",
    "abstract": "Bark beetle outbreaks can result in a devastating impact on forest ecosystem processes, biodiversity, forest structure and function, and economies. Accurate and timely detection of bark beetle infestations is crucial to mitigate further damage, develop proactive forest management activities, and minimize economic losses. Incorporating remote sensing (RS) data with machine learning (ML) (or deep learning (DL)) can provide a great alternative to the current approaches that rely on aerial surveys and field surveys, which are impractical over vast geographical regions. This paper provides a comprehensive review of past and current advances in the early detection of bark beetle-induced tree mortality from three key perspectives: bark beetle & host interactions, RS, and ML/DL. We parse recent literature according to bark beetle species & attack phases, host trees, study regions, imagery platforms & sensors, spectral/spatial/temporal resolutions, spectral signatures, spectral vegetation indices (SVIs), ML approaches, learning schemes, task categories, models, algorithms, classes/clusters, features, and DL networks & architectures. This review focuses on challenging early detection, discussing current challenges and potential solutions. Our literature survey suggests that the performance of current ML methods is limited (less than 80%) and depends on various factors, including imagery sensors & resolutions, acquisition dates, and employed features & algorithms/networks. A more promising result from DL networks and then the random forest (RF) algorithm highlighted the potential to detect subtle changes in visible, thermal, and short-wave infrared (SWIR) spectral regions. ",
    "url": "https://arxiv.org/abs/2210.03829",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03839",
    "title": "Edge deletion to tree-like graph classes",
    "abstract": "For a fixed property (graph class) $\\Pi$, given a graph $G$ and an integer $k$, the $\\Pi$-deletion problem consists in deciding if we can turn $G$ into a graph with the property $\\Pi$ by deleting at most $k$ edges of $G$. The $\\Pi$-deletion problem is known to be NP-hard for most of the well-studied graph classes (such as chordal, interval, bipartite, planar, comparability and permutation graphs, among others), with the notable exception of trees. Motivated by this fact, in this work we study the deletion problem for some classes close to trees. We obtain NP-hardness results for several classes of sparse graphs, for which we prove that deletion is hard even when the input is a bipartite graph. In addition, we give sufficient structural conditions for the graph class $\\Pi$ for NP-hardness. In the case of deletion to cactus, we show that the problem becomes tractable when the input is chordal, and we give polynomial-time algorithms for quasi-threshold graphs. ",
    "url": "https://arxiv.org/abs/2210.03839",
    "authors": [
      "Ivo Koch",
      "Nina Pardal",
      "Vinicius Fernandes dos Santos"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2210.03853",
    "title": "Revisiting Self-Supervised Contrastive Learning for Facial Expression  Recognition",
    "abstract": "The success of most advanced facial expression recognition works relies heavily on large-scale annotated datasets. However, it poses great challenges in acquiring clean and consistent annotations for facial expression datasets. On the other hand, self-supervised contrastive learning has gained great popularity due to its simple yet effective instance discrimination training strategy, which can potentially circumvent the annotation issue. Nevertheless, there remain inherent disadvantages of instance-level discrimination, which are even more challenging when faced with complicated facial representations. In this paper, we revisit the use of self-supervised contrastive learning and explore three core strategies to enforce expression-specific representations and to minimize the interference from other facial attributes, such as identity and face styling. Experimental results show that our proposed method outperforms the current state-of-the-art self-supervised learning methods, in terms of both categorical and dimensional facial expression recognition tasks. ",
    "url": "https://arxiv.org/abs/2210.03853",
    "authors": [
      "Yuxuan Shu",
      "Xiao Gu",
      "Guang-Zhong Yang",
      "Benny Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03861",
    "title": "Towards Light Weight Object Detection System",
    "abstract": "Transformers are a popular choice for classification tasks and as backbones for object detection tasks. However, their high latency brings challenges in their adaptation to lightweight object detection systems. We present an approximation of the self-attention layers used in the transformer architecture. This approximation reduces the latency of the classification system while incurring minimal loss in accuracy. We also present a method that uses a transformer encoder layer for multi-resolution feature fusion. This feature fusion improves the accuracy of the state-of-the-art lightweight object detection system without significantly increasing the number of parameters. Finally, we provide an abstraction for the transformer architecture called Generalized Transformer (gFormer) that can guide the design of novel transformer-like architectures. ",
    "url": "https://arxiv.org/abs/2210.03861",
    "authors": [
      "Dharma KC",
      "Venkata Ravi Kiran Dayana",
      "Meng-Lin Wu",
      "Venkateswara Rao Cherukuri",
      "Hau Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03881",
    "title": "Fourier Neural Solver for large sparse linear algebraic systems",
    "abstract": "Large sparse linear algebraic systems can be found in a variety of scientific and engineering fields, and many scientists strive to solve them in an efficient and robust manner. In this paper, we propose an interpretable neural solver, the Fourier Neural Solver (FNS), to address them. FNS is based on deep learning and Fast Fourier transform. Because the error between the iterative solution and the ground truth involves a wide range of frequency modes, FNS combines a stationary iterative method and frequency space correction to eliminate different components of the error. Local Fourier analysis reveals that the FNS can pick up on the error components in frequency space that are challenging to eliminate with stationary methods. Numerical experiments on the anisotropy diffusion equation, convection-diffusion equation, and Helmholtz equation show that FNS is more efficient and more robust than the state-of-the-art neural solver. ",
    "url": "https://arxiv.org/abs/2210.03881",
    "authors": [
      "Chen Cui",
      "Kai Jiang",
      "Yun Liu",
      "Shi Shu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.03883",
    "title": "Rethinking the Detection Head Configuration for Traffic Object Detection",
    "abstract": "Multi-scale detection plays an important role in object detection models. However, researchers usually feel blank on how to reasonably configure detection heads combining multi-scale features at different input resolutions. We find that there are different matching relationships between the object distribution and the detection head at different input resolutions. Based on the instructive findings, we propose a lightweight traffic object detection network based on matching between detection head and object distribution, termed as MHD-Net. It consists of three main parts. The first is the detection head and object distribution matching strategy, which guides the rational configuration of detection head, so as to leverage multi-scale features to effectively detect objects at vastly different scales. The second is the cross-scale detection head configuration guideline, which instructs to replace multiple detection heads with only two detection heads possessing of rich feature representations to achieve an excellent balance between detection accuracy, model parameters, FLOPs and detection speed. The third is the receptive field enlargement method, which combines the dilated convolution module with shallow features of backbone to further improve the detection accuracy at the cost of increasing model parameters very slightly. The proposed model achieves more competitive performance than other models on BDD100K dataset and our proposed ETFOD-v2 dataset. The code will be available. ",
    "url": "https://arxiv.org/abs/2210.03883",
    "authors": [
      "Yi Shi",
      "Jiang Wu",
      "Shixuan Zhao",
      "Gangyao Gao",
      "Tao Deng",
      "Hongmei Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.03894",
    "title": "GRANITE: A Graph Neural Network Model for Basic Block Throughput  Estimation",
    "abstract": "Analytical hardware performance models yield swift estimation of desired hardware performance metrics. However, developing these analytical models for modern processors with sophisticated microarchitectures is an extremely laborious task and requires a firm understanding of target microarchitecture's internal structure. In this paper, we introduce GRANITE, a new machine learning model that estimates the throughput of basic blocks across different microarchitectures. GRANITE uses a graph representation of basic blocks that captures both structural and data dependencies between instructions. This representation is processed using a graph neural network that takes advantage of the relational information captured in the graph and learns a rich neural representation of the basic block that allows more precise throughput estimation. Our results establish a new state-of-the-art for basic block performance estimation with an average test error of 6.9% across a wide range of basic blocks and microarchitectures for the x86-64 target. Compared to recent work, this reduced the error by 1.7% while improving training and inference throughput by approximately 3.0x. In addition, we propose the use of multi-task learning with independent multi-layer feed forward decoder networks. Our results show that this technique further improves precision of all learned models while significantly reducing per-microarchitecture training costs. We perform an extensive set of ablation studies and comparisons with prior work, concluding a set of methods to achieve high accuracy for basic block performance estimation. ",
    "url": "https://arxiv.org/abs/2210.03894",
    "authors": [
      "Ondrej Sykora",
      "Phitchaya Mangpo Phothilimthana",
      "Charith Mendis",
      "Amir Yazdanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.03895",
    "title": "ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial  Viewpoints",
    "abstract": "Recent studies have demonstrated that visual recognition models lack robustness to distribution shift. However, current work mainly considers model robustness to 2D image transformations, leaving viewpoint changes in the 3D world less explored. In general, viewpoint changes are prevalent in various real-world applications (e.g., autonomous driving), making it imperative to evaluate viewpoint robustness. In this paper, we propose a novel method called ViewFool to find adversarial viewpoints that mislead visual recognition models. By encoding real-world objects as neural radiance fields (NeRF), ViewFool characterizes a distribution of diverse adversarial viewpoints under an entropic regularizer, which helps to handle the fluctuations of the real camera pose and mitigate the reality gap between the real objects and their neural representations. Experiments validate that the common image classifiers are extremely vulnerable to the generated adversarial viewpoints, which also exhibit high cross-model transferability. Based on ViewFool, we introduce ImageNet-V, a new out-of-distribution dataset for benchmarking viewpoint robustness of image classifiers. Evaluation results on 40 classifiers with diverse architectures, objective functions, and data augmentations reveal a significant drop in model performance when tested on ImageNet-V, which provides a possibility to leverage ViewFool as an effective data augmentation strategy to improve viewpoint robustness. ",
    "url": "https://arxiv.org/abs/2210.03895",
    "authors": [
      "Yinpeng Dong",
      "Shouwei Ruan",
      "Hang Su",
      "Caixin Kang",
      "Xingxing Wei",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.03899",
    "title": "Multi-Scale Wavelet Transformer for Face Forgery Detection",
    "abstract": "Currently, many face forgery detection methods aggregate spatial and frequency features to enhance the generalization ability and gain promising performance under the cross-dataset scenario. However, these methods only leverage one level frequency information which limits their expressive ability. To overcome these limitations, we propose a multi-scale wavelet transformer framework for face forgery detection. Specifically, to take full advantage of the multi-scale and multi-frequency wavelet representation, we gradually aggregate the multi-scale wavelet representation at different stages of the backbone network. To better fuse the frequency feature with the spatial features, frequency-based spatial attention is designed to guide the spatial feature extractor to concentrate more on forgery traces. Meanwhile, cross-modality attention is proposed to fuse the frequency features with the spatial features. These two attention modules are calculated through a unified transformer block for efficiency. A wide variety of experiments demonstrate that the proposed method is efficient and effective for both within and cross datasets. ",
    "url": "https://arxiv.org/abs/2210.03899",
    "authors": [
      "Jie Liu",
      "Jingjing Wang",
      "Peng Zhang",
      "Chunmao Wang",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03900",
    "title": "Bottleneck Analysis of Dynamic Graph Neural Network Inference on CPU and  GPU",
    "abstract": "Dynamic graph neural network (DGNN) is becoming increasingly popular because of its widespread use in capturing dynamic features in the real world. A variety of dynamic graph neural networks designed from algorithmic perspectives have succeeded in incorporating temporal information into graph processing. Despite the promising algorithmic performance, deploying DGNNs on hardware presents additional challenges due to the model complexity, diversity, and the nature of the time dependency. Meanwhile, the differences between DGNNs and static graph neural networks make hardware-related optimizations for static graph neural networks unsuitable for DGNNs. In this paper, we select eight prevailing DGNNs with different characteristics and profile them on both CPU and GPU. The profiling results are summarized and analyzed, providing in-depth insights into the bottlenecks of DGNNs on hardware and identifying potential optimization opportunities for future DGNN acceleration. Followed by a comprehensive survey, we provide a detailed analysis of DGNN performance bottlenecks on hardware, including temporal data dependency, workload imbalance, data movement, and GPU warm-up. We suggest several optimizations from both software and hardware perspectives. This paper is the first to provide an in-depth analysis of the hardware performance of DGNN Code is available at https://github.com/sharc-lab/DGNN_analysis. ",
    "url": "https://arxiv.org/abs/2210.03900",
    "authors": [
      "Hanqiu Chen",
      "Yahya Alhinai",
      "Yihan Jiang",
      "Eunjee Na",
      "Cong Hao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03901",
    "title": "A fairness assessment of mobility-based COVID-19 case prediction models",
    "abstract": "In light of the outbreak of COVID-19, analyzing and measuring human mobility has become increasingly important. A wide range of studies have explored spatiotemporal trends over time, examined associations with other variables, evaluated non-pharmacologic interventions (NPIs), and predicted or simulated COVID-19 spread using mobility data. Despite the benefits of publicly available mobility data, a key question remains unanswered: are models using mobility data performing equitably across demographic groups? We hypothesize that bias in the mobility data used to train the predictive models might lead to unfairly less accurate predictions for certain demographic groups. To test our hypothesis, we applied two mobility-based COVID infection prediction models at the county level in the United States using SafeGraph data, and correlated model performance with sociodemographic traits. Findings revealed that there is a systematic bias in models performance toward certain demographic characteristics. Specifically, the models tend to favor large, highly educated, wealthy, young, urban, and non-black-dominated counties. We hypothesize that the mobility data currently used by many predictive models tends to capture less information about older, poorer, non-white, and less educated regions, which in turn negatively impacts the accuracy of the COVID-19 prediction in these regions. Ultimately, this study points to the need of improved data collection and sampling approaches that allow for an accurate representation of the mobility patterns across demographic groups. ",
    "url": "https://arxiv.org/abs/2210.03901",
    "authors": [
      "Abdolmajid Erfani",
      "Vanessa Frias-Martinez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.03907",
    "title": "Learning the Network of Graphs for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have achieved great success in many scenarios with graph-structured data. However, in many real applications, there are three issues when applying GNNs: graphs are unknown, nodes have noisy features, and graphs contain noisy connections. Aiming at solving these problems, we propose a new graph neural network named as GL-GNN. Our model includes multiple sub-modules, each sub-module selects important data features and learn the corresponding key relation graph of data samples when graphs are unknown. GL-GNN further obtains the network of graphs by learning the network of sub-modules. The learned graphs are further fused using an aggregation method over the network of graphs. Our model solves the first issue by simultaneously learning multiple relation graphs of data samples as well as a relation network of graphs, and solves the second and the third issue by selecting important data features as well as important data sample relations. We compare our method with 14 baseline methods on seven datasets when the graph is unknown and 11 baseline methods on two datasets when the graph is known. The results show that our method achieves better accuracies than the baseline methods and is capable of selecting important features and graph edges from the dataset. Our code will be publicly available at \\url{https://github.com/Looomo/GL-GNN}. ",
    "url": "https://arxiv.org/abs/2210.03907",
    "authors": [
      "Yixiang Shan",
      "Jielong Yang",
      "Xing Liu",
      "Yixing Gao",
      "Hechang Chen",
      "Shuzhi Sam Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03919",
    "title": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "abstract": "Recently introduced Contrastive Language-Image Pre-Training (CLIP) bridges images and text by embedding them into a joint latent space. This opens the door to ample literature that aims to manipulate an input image by providing a textual explanation. However, due to the discrepancy between image and text embeddings in the joint space, using text embeddings as the optimization target often introduces undesired artifacts in the resulting images. Disentanglement, interpretability, and controllability are also hard to guarantee for manipulation. To alleviate these problems, we propose to define corpus subspaces spanned by relevant prompts to capture specific image characteristics. We introduce CLIP Projection-Augmentation Embedding (PAE) as an optimization target to improve the performance of text-guided image manipulation. Our method is a simple and general paradigm that can be easily computed and adapted, and smoothly incorporated into any CLIP-based image manipulation algorithm. To demonstrate the effectiveness of our method, we conduct several theoretical and empirical studies. As a case study, we utilize the method for text-guided semantic face editing. We quantitatively and qualitatively demonstrate that PAE facilitates a more disentangled, interpretable, and controllable image manipulation with state-of-the-art quality and accuracy. ",
    "url": "https://arxiv.org/abs/2210.03919",
    "authors": [
      "Chenliang Zhou",
      "Fancheng Zhong",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03930",
    "title": "Hierarchical Graph Transformer with Adaptive Node Sampling",
    "abstract": "The Transformer architecture has achieved remarkable success in a number of domains including natural language processing and computer vision. However, when it comes to graph-structured data, transformers have not achieved competitive performance, especially on large graphs. In this paper, we identify the main deficiencies of current graph transformers:(1) Existing node sampling strategies in Graph Transformers are agnostic to the graph characteristics and the training process. (2) Most sampling strategies only focus on local neighbors and neglect the long-range dependencies in the graph. We conduct experimental investigations on synthetic datasets to show that existing sampling strategies are sub-optimal. To tackle the aforementioned problems, we formulate the optimization strategies of node sampling in Graph Transformer as an adversary bandit problem, where the rewards are related to the attention weights and can vary in the training procedure. Meanwhile, we propose a hierarchical attention scheme with graph coarsening to capture the long-range interactions while reducing computational complexity. Finally, we conduct extensive experiments on real-world datasets to demonstrate the superiority of our method over existing graph transformers and popular GNNs. ",
    "url": "https://arxiv.org/abs/2210.03930",
    "authors": [
      "Zaixi Zhang",
      "Qi Liu",
      "Qingyong Hu",
      "Chee-Kong Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03942",
    "title": "Point Cloud Upsampling via Cascaded Refinement Network",
    "abstract": "Point cloud upsampling focuses on generating a dense, uniform and proximity-to-surface point set. Most previous approaches accomplish these objectives by carefully designing a single-stage network, which makes it still challenging to generate a high-fidelity point distribution. Instead, upsampling point cloud in a coarse-to-fine manner is a decent solution. However, existing coarse-to-fine upsampling methods require extra training strategies, which are complicated and time-consuming during the training. In this paper, we propose a simple yet effective cascaded refinement network, consisting of three generation stages that have the same network architecture but achieve different objectives. Specifically, the first two upsampling stages generate the dense but coarse points progressively, while the last refinement stage further adjust the coarse points to a better position. To mitigate the learning conflicts between multiple stages and decrease the difficulty of regressing new points, we encourage each stage to predict the point offsets with respect to the input shape. In this manner, the proposed cascaded refinement network can be easily optimized without extra learning strategies. Moreover, we design a transformer-based feature extraction module to learn the informative global and local shape context. In inference phase, we can dynamically adjust the model efficiency and effectiveness, depending on the available computational resources. Extensive experiments on both synthetic and real-scanned datasets demonstrate that the proposed approach outperforms the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.03942",
    "authors": [
      "Hang Du",
      "Xuejun Yan",
      "Jingjing Wang",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03949",
    "title": "ConstGCN: Constrained Transmission-based Graph Convolutional Networks  for Document-level Relation Extraction",
    "abstract": "Document-level relation extraction with graph neural networks faces a fundamental graph construction gap between training and inference - the golden graph structure only available during training, which causes that most methods adopt heuristic or syntactic rules to construct a prior graph as a pseudo proxy. In this paper, we propose $\\textbf{ConstGCN}$, a novel graph convolutional network which performs knowledge-based information propagation between entities along with all specific relation spaces without any prior graph construction. Specifically, it updates the entity representation by aggregating information from all other entities along with each relation space, thus modeling the relation-aware spatial information. To control the information flow passing through the indeterminate relation spaces, we propose to constrain the propagation using transmitting scores learned from the Noise Contrastive Estimation between fact triples. Experimental results show that our method outperforms the previous state-of-the-art (SOTA) approaches on the DocRE dataset. ",
    "url": "https://arxiv.org/abs/2210.03949",
    "authors": [
      "Ji Qi",
      "Bin Xu",
      "Kaisheng Zeng",
      "Jinxin Liu",
      "Jifan Yu",
      "Qi Gao",
      "Juanzi Li",
      "Lei Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.03952",
    "title": "Detaching and Boosting: Dual Engine for Scale-Invariant Self-Supervised  Monocular Depth Estimation",
    "abstract": "Monocular depth estimation (MDE) in the self-supervised scenario has emerged as a promising method as it refrains from the requirement of ground truth depth. Despite continuous efforts, MDE is still sensitive to scale changes especially when all the training samples are from one single camera. Meanwhile, it deteriorates further since camera movement results in heavy coupling between the predicted depth and the scale change. In this paper, we present a scale-invariant approach for self-supervised MDE, in which scale-sensitive features (SSFs) are detached away while scale-invariant features (SIFs) are boosted further. To be specific, a simple but effective data augmentation by imitating the camera zooming process is proposed to detach SSFs, making the model robust to scale changes. Besides, a dynamic cross-attention module is designed to boost SIFs by fusing multi-scale cross-attention features adaptively. Extensive experiments on the KITTI dataset demonstrate that the detaching and boosting strategies are mutually complementary in MDE and our approach achieves new State-of-The-Art performance against existing works from 0.097 to 0.090 w.r.t absolute relative error. The code will be made public soon. ",
    "url": "https://arxiv.org/abs/2210.03952",
    "authors": [
      "Peizhe Jiang",
      "Wei Yang",
      "Xiaoqing Ye",
      "Xiao Tan",
      "Meng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03956",
    "title": "Robust Graph Structure Learning over Images via Multiple Statistical  Tests",
    "abstract": "Graph structure learning aims to learn connectivity in a graph from data. It is particularly important for many computer vision related tasks since no explicit graph structure is available for images for most cases. A natural way to construct a graph among images is to treat each image as a node and assign pairwise image similarities as weights to corresponding edges. It is well known that pairwise similarities between images are sensitive to the noise in feature representations, leading to unreliable graph structures. We address this problem from the viewpoint of statistical tests. By viewing the feature vector of each node as an independent sample, the decision of whether creating an edge between two nodes based on their similarity in feature representation can be thought as a ${\\it single}$ statistical test. To improve the robustness in the decision of creating an edge, multiple samples are drawn and integrated by ${\\it multiple}$ statistical tests to generate a more reliable similarity measure, consequentially more reliable graph structure. The corresponding elegant matrix form named $\\mathcal{B}\\textbf{-Attention}$ is designed for efficiency. The effectiveness of multiple tests for graph structure learning is verified both theoretically and empirically on multiple clustering and ReID benchmark datasets. Source codes are available at https://github.com/Thomas-wyh/B-Attention. ",
    "url": "https://arxiv.org/abs/2210.03956",
    "authors": [
      "Yaohua Wang",
      "FangYi Zhang",
      "Ming Lin",
      "Senzhang Wang",
      "Xiuyu Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03963",
    "title": "SDA: Simple Discrete Augmentation for Contrastive Sentence  Representation Learning",
    "abstract": "Contrastive learning methods achieve state-of-the-art results in unsupervised sentence representation learning. Although playing essential roles in contrastive learning, data augmentation methods applied on sentences have not been fully explored. Current SOTA method SimCSE utilizes a simple dropout mechanism as continuous augmentation which outperforms discrete augmentations such as cropping, word deletion and synonym replacement. To understand the underlying rationales, we revisit existing approaches and attempt to hypothesize the desiderata of reasonable data augmentation methods: balance of semantic consistency and expression diversity. Based on the hypothesis, we propose three simple yet effective discrete sentence augmentation methods, i.e., punctuation insertion, affirmative auxiliary and double negation. The punctuation marks, auxiliaries and negative words act as minimal noises in lexical level to produce diverse sentence expressions. Unlike traditional augmentation methods which randomly modify the sentence, our augmentation rules are well designed for generating semantically consistent and grammatically correct sentences. We conduct extensive experiments on both English and Chinese semantic textual similarity datasets. The results show the robustness and effectiveness of the proposed methods. ",
    "url": "https://arxiv.org/abs/2210.03963",
    "authors": [
      "Zhenyu Mao",
      "Dongsheng Zhu",
      "Jinghui Lu",
      "Rui Zhao",
      "Fei Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.03970",
    "title": "KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text  Classification",
    "abstract": "Medical text learning has recently emerged as a promising area to improve healthcare due to the wide adoption of electronic health record (EHR) systems. The complexity of the medical text such as diverse length, mixed text types, and full of medical jargon, poses a great challenge for developing effective deep learning models. BERT has presented state-of-the-art results in many NLP tasks, such as text classification and question answering. However, the standalone BERT model cannot deal with the complexity of the medical text, especially the lengthy clinical notes. Herein, we develop a new model called KG-MTT-BERT (Knowledge Graph Enhanced Multi-Type Text BERT) by extending the BERT model for long and multi-type text with the integration of the medical knowledge graph. Our model can outperform all baselines and other state-of-the-art models in diagnosis-related group (DRG) classification, which requires comprehensive medical text for accurate classification. We also demonstrated that our model can effectively handle multi-type text and the integration of medical knowledge graph can significantly improve the performance. ",
    "url": "https://arxiv.org/abs/2210.03970",
    "authors": [
      "Yong He",
      "Cheng Wang",
      "Shun Zhang",
      "Nan Li",
      "Zhaorong Li",
      "Zhenyu Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03974",
    "title": "FBNet: Feedback Network for Point Cloud Completion",
    "abstract": "The rapid development of point cloud learning has driven point cloud completion into a new era. However, the information flows of most existing completion methods are solely feedforward, and high-level information is rarely reused to improve low-level feature learning. To this end, we propose a novel Feedback Network (FBNet) for point cloud completion, in which present features are efficiently refined by rerouting subsequent fine-grained ones. Firstly, partial inputs are fed to a Hierarchical Graph-based Network (HGNet) to generate coarse shapes. Then, we cascade several Feedback-Aware Completion (FBAC) Blocks and unfold them across time recurrently. Feedback connections between two adjacent time steps exploit fine-grained features to improve present shape generations. The main challenge of building feedback connections is the dimension mismatching between present and subsequent features. To address this, the elaborately designed point Cross Transformer exploits efficient information from feedback features via cross attention strategy and then refines present features with the enhanced feedback features. Quantitative and qualitative experiments on several datasets demonstrate the superiority of proposed FBNet compared to state-of-the-art methods on point completion task. ",
    "url": "https://arxiv.org/abs/2210.03974",
    "authors": [
      "Xuejun Yan",
      "Hongyu Yan",
      "Jingjing Wang",
      "Hang Du",
      "Zhihong Wu",
      "Di Xie",
      "Shiliang Pu",
      "Li Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03980",
    "title": "Distilling Causal Effect from Miscellaneous Other-Class for Continual  Named Entity Recognition",
    "abstract": "Continual Learning for Named Entity Recognition (CL-NER) aims to learn a growing number of entity types over time from a stream of data. However, simply learning Other-Class in the same way as new entity types amplifies the catastrophic forgetting and leads to a substantial performance drop. The main cause behind this is that Other-Class samples usually contain old entity types, and the old knowledge in these Other-Class samples is not preserved properly. Thanks to the causal inference, we identify that the forgetting is caused by the missing causal effect from the old data. To this end, we propose a unified causal framework to retrieve the causality from both new entity types and Other-Class. Furthermore, we apply curriculum learning to mitigate the impact of label noise and introduce a self-adaptive weight for balancing the causal effects between new entity types and Other-Class. Experimental results on three benchmark datasets show that our method outperforms the state-of-the-art method by a large margin. Moreover, our method can be combined with the existing state-of-the-art methods to improve the performance in CL-NER ",
    "url": "https://arxiv.org/abs/2210.03980",
    "authors": [
      "Junhao Zheng",
      "Zhanxian Liang",
      "Haibin Chen",
      "Qianli Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03990",
    "title": "Weisfeiler--Lehman goes Dynamic: An Analysis of the Expressive Power of  Graph Neural Networks for Attributed and Dynamic Graphs",
    "abstract": "Graph Neural Networks (GNNs) are a large class of relational models for graph processing. Recent theoretical studies on the expressive power of GNNs have focused on two issues. On the one hand, it has been proven that GNNs are as powerful as the Weisfeiler-Lehman test (1-WL) in their ability to distinguish graphs. Moreover, it has been shown that the equivalence enforced by 1-WL equals unfolding equivalence. On the other hand, GNNs turned out to be universal approximators on graphs modulo the constraints enforced by 1-WL/unfolding equivalence. However, these results only apply to Static Undirected Homogeneous Graphs with node attributes. In contrast, real-life applications often involve a variety of graph properties, such as, e.g., dynamics or node and edge attributes. In this paper, we conduct a theoretical analysis of the expressive power of GNNs for these two graph types that are particularly of interest. Dynamic graphs are widely used in modern applications, and its theoretical analysis requires new approaches. The attributed type acts as a standard form for all graph types since it has been shown that all graph types can be transformed without loss to Static Undirected Homogeneous Graphs with attributes on nodes and edges (SAUHG). The study considers generic GNN models and proposes appropriate 1-WL tests for those domains. Then, the results on the expressive power of GNNs are extended by proving that GNNs have the same capability as the 1-WL test in distinguishing dynamic and attributed graphs, the 1-WL equivalence equals unfolding equivalence and that GNNs are universal approximators modulo 1-WL/unfolding equivalence. Moreover, the proof of the approximation capability holds for SAUHGs, which include most of those used in practical applications, and it is constructive in nature allowing to deduce hints on the architecture of GNNs that can achieve the desired accuracy. ",
    "url": "https://arxiv.org/abs/2210.03990",
    "authors": [
      "Silvia Beddar-Wiesing",
      "Giuseppe Alessio D'Inverno",
      "Caterina Graziani",
      "Veronica Lachi",
      "Alice Moallemy-Oureh",
      "Franco Scarselli",
      "Josephine Maria Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03994",
    "title": "Relational Message Passing for Fully Inductive Knowledge Graph  Completion",
    "abstract": "In knowledge graph completion (KGC), predicting triples involving emerging entities and/or relations, which are unseen when the KG embeddings are learned, has become a critical challenge. Subgraph reasoning with message passing is a promising and popular solution. Some recent methods have achieved good performance, but they (i) usually can only predict triples involving unseen entities alone, failing to address more realistic fully inductive situations with both unseen entities and unseen relations, and (ii) often conduct message passing over the entities with the relation patterns not fully utilized. In this study, we propose a new method named RMPI which uses a novel Relational Message Passing network for fully Inductive KGC. It passes messages directly between relations to make full use of the relation patterns for subgraph reasoning with new techniques on graph transformation, graph pruning, relation-aware neighborhood attention, addressing empty subgraphs, etc., and can utilize the relation semantics defined in the ontological schema of KG. Extensive evaluation on multiple benchmarks has shown the effectiveness of techniques involved in RMPI and its better performance compared with the existing methods that support fully inductive KGC. RMPI is also comparable to the state-of-the-art partially inductive KGC methods with very promising results achieved. Our codes and data are available at https://github.com/zjukg/RMPI. ",
    "url": "https://arxiv.org/abs/2210.03994",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Wen Zhang",
      "Jeff Z. Pan",
      "Mingyang Chen",
      "Huajun Chen",
      "Song Jiang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03998",
    "title": "Towards the Detection of Malicious Java Packages",
    "abstract": "Open-source software supply chain attacks aim at infecting downstream users by poisoning open-source packages. The common way of consuming such artifacts is through package repositories and the development of vetting strategies to detect such attacks is ongoing research. Despite its popularity, the Java ecosystem is the less explored one in the context of supply chain attacks. In this paper we present indicators of malicious behavior that can be observed statically through the analysis of Java bytecode. Then we evaluate how such indicators and their combinations perform when detecting malicious code injections. We do so by injecting three malicious payloads taken from real-world examples into the Top-10 most popular Java libraries from libraries.io. We found that the analysis of strings in the constant pool and of sensitive APIs in the bytecode instructions aid in the task of detecting malicious Java packages by significantly reducing the information, thus, making also manual triage possible. ",
    "url": "https://arxiv.org/abs/2210.03998",
    "authors": [
      "Piergiorgio Ladisa",
      "Henrik Plate",
      "Matias Martinez",
      "Olivier Barais",
      "Serena Elisa Ponta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04006",
    "title": "(Fusionformer):Exploiting the Joint Motion Synergy with Fusion Network  Based On Transformer for 3D Human Pose Estimation",
    "abstract": "For the current 3D human pose estimation task, in order to improve the efficiency of pose sequence output, we try to further improve the prediction stability in low input video frame scenarios.Many previous methods lack the understanding of local joint information.\\cite{9878888}considers the temporal relationship of a single joint in this work.However, we found that there is a certain predictive correlation between the trajectories of different joints in time.Therefore, our proposed \\textbf{Fusionformer} method introduces a self-trajectory module and a cross-trajectory module based on the spatio-temporal module.After that, the global spatio-temporal features and local joint trajectory features are fused through a linear network in a parallel manner.To eliminate the influence of bad 2D poses on 3D projections, finally we also introduce a pose refinement network to balance the consistency of 3D projections.In addition, we evaluate the proposed method on two benchmark datasets (Human3.6M, MPI-INF-3DHP). Comparing our method with the baseline method poseformer, the results show an improvement of 2.4\\% MPJPE and 4.3\\% P-MPJPE on the Human3.6M dataset, respectively. ",
    "url": "https://arxiv.org/abs/2210.04006",
    "authors": [
      "Xinwei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04014",
    "title": "AdaptivePose++: A Powerful Single-Stage Network for Multi-Person Pose  Regression",
    "abstract": "Multi-person pose estimation generally follows top-down and bottom-up paradigms. Both of them use an extra stage ($\\boldsymbol{e.g.,}$ human detection in top-down paradigm or grouping process in bottom-up paradigm) to build the relationship between the human instance and corresponding keypoints, thus leading to the high computation cost and redundant two-stage pipeline. To address the above issue, we propose to represent the human parts as adaptive points and introduce a fine-grained body representation method. The novel body representation is able to sufficiently encode the diverse pose information and effectively model the relationship between the human instance and corresponding keypoints in a single-forward pass. With the proposed body representation, we further deliver a compact single-stage multi-person pose regression network, termed as AdaptivePose. During inference, our proposed network only needs a single-step decode operation to form the multi-person pose without complex post-processes and refinements. We employ AdaptivePose for both 2D/3D multi-person pose estimation tasks to verify the effectiveness of AdaptivePose. Without any bells and whistles, we achieve the most competitive performance on MS COCO and CrowdPose in terms of accuracy and speed. Furthermore, the outstanding performance on MuCo-3DHP and MuPoTS-3D further demonstrates the effectiveness and generalizability on 3D scenes. Code is available at https://github.com/buptxyb666/AdaptivePose. ",
    "url": "https://arxiv.org/abs/2210.04014",
    "authors": [
      "Yabo Xiao",
      "Xiaojuan Wang",
      "Dongdong Yu",
      "Kai Su",
      "Lei Jin",
      "Mei Song",
      "Shuicheng Yan",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04017",
    "title": "Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous  Driving via Semantic Masked World Model",
    "abstract": "End-to-end autonomous driving provides a feasible way to automatically maximize overall driving system performance by directly mapping the raw pixels from a front-facing camera to control signals. Recent advanced methods construct a latent world model to map the high dimensional observations into compact latent space. However, the latent states embedded by the world model proposed in previous works may contain a large amount of task-irrelevant information, resulting in low sampling efficiency and poor robustness to input perturbations. Meanwhile, the training data distribution is usually unbalanced, and the learned policy is hard to cope with the corner cases during the driving process. To solve the above challenges, we present a semantic masked recurrent world model (SEM2), which introduces a latent filter to extract key task-relevant features and reconstruct a semantic mask via the filtered features, and is trained with a multi-source data sampler, which aggregates common data and multiple corner case data in a single batch, to balance the data distribution. Extensive experiments on CARLA show that our method outperforms the state-of-the-art approaches in terms of sample efficiency and robustness to input permutations. ",
    "url": "https://arxiv.org/abs/2210.04017",
    "authors": [
      "Zeyu Gao",
      "Yao Mu",
      "Ruoyan Shen",
      "Chen Chen",
      "Yangang Ren",
      "Jianyu Chen",
      "Shengbo Eben Li",
      "Ping Luo",
      "Yanfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04022",
    "title": "A Computational Study on the Site and Power Assignment Problem in  Wireless Networks",
    "abstract": "In this work, we address the wireless network design problem, i.e., the problem of configuring a set of transmitters to provide service coverage to a set of receivers. It is well-known that natural formulations of this problem are sources of numerical instabilities and make the optimal resolution challenging for state-of-the-art solvers, even in small-sized instances. We tackle this limitation from a computational perspective by suggesting two implementation procedures capable of speeding the resolution of the instances of this problem. The first one consists of the employment of an extremely effective branching rule for a compact reformulation of this problem. The second one is the use of presolve operations to manage numerical instability. The approaches are validated using LTE instances kindly provided by Fondazione Ugo Bordoni. The proposed implementation techniques have proved capable of significantly accelerating the resolution of the problem, beating the performance of a standard resolution. ",
    "url": "https://arxiv.org/abs/2210.04022",
    "authors": [
      "Pasquale Avella",
      "Alice Calamita",
      "Laura Palagi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.04052",
    "title": "FedDef: Robust Federated Learning-based Network Intrusion Detection  Systems Against Gradient Leakage",
    "abstract": "Deep learning methods have been widely applied to anomaly-based network intrusion detection systems (NIDS) to detect malicious traffic. To expand the usage scenarios of DL-based methods, the federated learning (FL) framework allows intelligent techniques to jointly train a model by multiple individuals on the basis of respecting individual data privacy. However, it has not yet been systematically evaluated how robust FL-based NIDSs are against existing privacy attacks under existing defenses. To address this issue, in this paper we propose two privacy evaluation metrics designed for FL-based NIDSs, including leveraging two reconstruction attacks to recover the training data to obtain the privacy score for traffic features, followed by Generative Adversarial Network (GAN) based attack that generates adversarial examples with the reconstructed benign traffic to evaluate evasion rate against other NIDSs. We conduct experiments to show that existing defenses provide little protection that the corresponding adversarial traffic can even evade the SOTA NIDS Kitsune. To build a more robust FL-based NIDS, we further propose a novel optimization-based input perturbation defense strategy with theoretical guarantee that achieves both high utility by minimizing the gradient distance and strong privacy protection by maximizing the input distance. We experimentally evaluate four existing defenses on four datasets and show that our defense outperforms all the baselines with strong privacy guarantee while maintaining model accuracy loss within 3% under optimal parameter combination. ",
    "url": "https://arxiv.org/abs/2210.04052",
    "authors": [
      "Jiahui Chen",
      "Yi Zhao",
      "Qi Li",
      "Ke Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04062",
    "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code  Representation Learning",
    "abstract": "Speech is the surface form of a finite set of phonetic units, which can be represented by discrete codes. We propose the Code BERT (CoBERT) approach for self-supervised speech representation learning. The idea is to convert an utterance to a sequence of discrete codes, and perform code representation learning, where we predict the code representations based on a masked view of the original speech input. Unlike the prior self-distillation approaches of which the teacher and the student are of the same modality, our target model predicts representations from a different modality. CoBERT outperforms the most recent state-of-the-art performance on the ASR task and brings significant improvements on the SUPERB speech translation (ST) task. ",
    "url": "https://arxiv.org/abs/2210.04062",
    "authors": [
      "Chutong Meng",
      "Junyi Ao",
      "Tom Ko",
      "Mingxuan Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.04066",
    "title": "Drowsiness detection in drivers with a smartwatch",
    "abstract": "The main objective of this work is to detect early if a driver shows symptoms of sleepiness that indicate that he/she is falling asleep and, in that case, generate an alert to wake him/her up. To solve this problem, an application has been designed that collects various parameters, through a smartwatch while driving. First, the application detects the driving action. Then, it collects information about the most significant physiological variables of a person while driving. On the other hand, given the high level of sensitivity of the data managed in the designed application, in this work special attention has been paid to the security of the implementation. The proposed solution improves road safety, reducing the number of accidents caused by drowsiness while driving. ",
    "url": "https://arxiv.org/abs/2210.04066",
    "authors": [
      "Sonia D\u00edaz-Santos",
      "Pino Caballero-Gil"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04074",
    "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection of  Events",
    "abstract": "Natural language often describes events in different granularities, such that more coarse-grained (goal) events can often be decomposed into fine-grained sequences of (step) events. A critical but overlooked challenge in understanding an event process lies in the fact that the step events are not equally important to the central goal. In this paper, we seek to fill this gap by studying how well current models can understand the essentiality of different step events towards a goal event. As discussed by cognitive studies, such an ability enables the machine to mimic human's commonsense reasoning about preconditions and necessary efforts of daily-life tasks. Our work contributes with a high-quality corpus of (goal, step) pairs from a community guideline website WikiHow, where the steps are manually annotated with their essentiality w.r.t. the goal. The high IAA indicates that humans have a consistent understanding of the events. Despite evaluating various statistical and massive pre-trained NLU models, we observe that existing SOTA models all perform drastically behind humans, indicating the need for future investigation of this crucial yet challenging task. ",
    "url": "https://arxiv.org/abs/2210.04074",
    "authors": [
      "Hongming Zhang",
      "Yueguan Wang",
      "Yuqian Deng",
      "Haoyu Wang",
      "Muhao Chen",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04076",
    "title": "Robustness of Unsupervised Representation Learning without Labels",
    "abstract": "Unsupervised representation learning leverages large unlabeled datasets and is competitive with supervised learning. But non-robust encoders may affect downstream task robustness. Recently, robust representation encoders have become of interest. Still, all prior work evaluates robustness using a downstream classification task. Instead, we propose a family of unsupervised robustness measures, which are model- and task-agnostic and label-free. We benchmark state-of-the-art representation encoders and show that none dominates the rest. We offer unsupervised extensions to the FGSM and PGD attacks. When used in adversarial training, they improve most unsupervised robustness measures, including certified robustness. We validate our results against a linear probe and show that, for MOCOv2, adversarial training results in 3 times higher certified accuracy, a 2-fold decrease in impersonation attack success rate and considerable improvements in certified robustness. ",
    "url": "https://arxiv.org/abs/2210.04076",
    "authors": [
      "Aleksandar Petrov",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04083",
    "title": "Unified Probabilistic Neural Architecture and Weight Ensembling Improves  Model Robustness",
    "abstract": "Robust machine learning models with accurately calibrated uncertainties are crucial for safety-critical applications. Probabilistic machine learning and especially the Bayesian formalism provide a systematic framework to incorporate robustness through the distributional estimates and reason about uncertainty. Recent works have shown that approximate inference approaches that take the weight space uncertainty of neural networks to generate ensemble prediction are the state-of-the-art. However, architecture choices have mostly been ad hoc, which essentially ignores the epistemic uncertainty from the architecture space. To this end, we propose a Unified probabilistic architecture and weight ensembling Neural Architecture Search (UraeNAS) that leverages advances in probabilistic neural architecture search and approximate Bayesian inference to generate ensembles form the joint distribution of neural network architectures and weights. The proposed approach showed a significant improvement both with in-distribution (0.86% in accuracy, 42% in ECE) CIFAR-10 and out-of-distribution (2.43% in accuracy, 30% in ECE) CIFAR-10-C compared to the baseline deterministic approach. ",
    "url": "https://arxiv.org/abs/2210.04083",
    "authors": [
      "Sumegha Premchandar",
      "Sandeep Madireddy",
      "Sanket Jantre",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04085",
    "title": "Dual Pyramid Generative Adversarial Networks for Semantic Image  Synthesis",
    "abstract": "The goal of semantic image synthesis is to generate photo-realistic images from semantic label maps. It is highly relevant for tasks like content generation and image editing. Current state-of-the-art approaches, however, still struggle to generate realistic objects in images at various scales. In particular, small objects tend to fade away and large objects are often generated as collages of patches. In order to address this issue, we propose a Dual Pyramid Generative Adversarial Network (DP-GAN) that learns the conditioning of spatially-adaptive normalization blocks at all scales jointly, such that scale information is bi-directionally used, and it unifies supervision at different scales. Our qualitative and quantitative results show that the proposed approach generates images where small and large objects look more realistic compared to images generated by state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.04085",
    "authors": [
      "Shijie Li",
      "Ming-Ming Cheng",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04087",
    "title": "Symmetry Subgroup Defense Against Adversarial Attacks",
    "abstract": "Adversarial attacks and defenses disregard the lack of invariance of convolutional neural networks (CNNs), that is, the inability of CNNs to classify samples and their symmetric transformations the same. The lack of invariance of CNNs with respect to symmetry transformations is detrimental when classifying transformed original samples but not necessarily detrimental when classifying transformed adversarial samples. For original images, the lack of invariance means that symmetrically transformed original samples are classified differently from their correct labels. However, for adversarial images, the lack of invariance means that symmetrically transformed adversarial images are classified differently from their incorrect adversarial labels. Might the CNN lack of invariance revert symmetrically transformed adversarial samples to the correct classification? This paper answers this question affirmatively for a threat model that ranges from zero-knowledge adversaries to perfect-knowledge adversaries. We base our defense against perfect-knowledge adversaries on devising a Klein four symmetry subgroup that incorporates an additional artificial symmetry of pixel intensity inversion. The closure property of the subgroup not only provides a framework for the accuracy evaluation but also confines the transformations that an adaptive, perfect-knowledge adversary can apply. We find that by using only symmetry defense, no adversarial samples, and by changing nothing in the model architecture and parameters, we can defend against white-box PGD adversarial attacks, surpassing the PGD adversarial training defense by up to ~50% even against a perfect-knowledge adversary for ImageNet. The proposed defense also maintains and surpasses the classification accuracy for non-adversarial samples. ",
    "url": "https://arxiv.org/abs/2210.04087",
    "authors": [
      "Blerta Lindqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04095",
    "title": "How do you go where? Improving next location prediction by learning  travel mode information using transformers",
    "abstract": "Predicting the next visited location of an individual is a key problem in human mobility analysis, as it is required for the personalization and optimization of sustainable transport options. Here, we propose a transformer decoder-based neural network to predict the next location an individual will visit based on historical locations, time, and travel modes, which are behaviour dimensions often overlooked in previous work. In particular, the prediction of the next travel mode is designed as an auxiliary task to help guide the network's learning. For evaluation, we apply this approach to two large-scale and long-term GPS tracking datasets involving more than 600 individuals. Our experiments show that the proposed method significantly outperforms other state-of-the-art next location prediction methods by a large margin (8.05% and 5.60% relative increase in F1-score for the two datasets, respectively). We conduct an extensive ablation study that quantifies the influence of considering temporal features, travel mode information, and the auxiliary task on the prediction results. Moreover, we experimentally determine the performance upper bound when including the next mode prediction in our model. Finally, our analysis indicates that the performance of location prediction varies significantly with the chosen next travel mode by the individual. These results show potential for a more systematic consideration of additional dimensions of travel behaviour in human mobility prediction tasks. The source code of our model and experiments is available at https://github.com/mie-lab/location-mode-prediction. ",
    "url": "https://arxiv.org/abs/2210.04095",
    "authors": [
      "Ye Hong",
      "Henry Martin",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.04104",
    "title": "Training Deep Learning Algorithms on Synthetic Forest Images for Tree  Detection",
    "abstract": "Vision-based segmentation in forested environments is a key functionality for autonomous forestry operations such as tree felling and forwarding. Deep learning algorithms demonstrate promising results to perform visual tasks such as object detection. However, the supervised learning process of these algorithms requires annotations from a large diversity of images. In this work, we propose to use simulated forest environments to automatically generate 43 k realistic synthetic images with pixel-level annotations, and use it to train deep learning algorithms for tree detection. This allows us to address the following questions: i) what kind of performance should we expect from deep learning in harsh synthetic forest environments, ii) which annotations are the most important for training, and iii) what modality should be used between RGB and depth. We also report the promising transfer learning capability of features learned on our synthetic dataset by directly predicting bounding box, segmentation masks and keypoints on real images. Code available on GitHub (https://github.com/norlab-ulaval/PercepTreeV1). ",
    "url": "https://arxiv.org/abs/2210.04104",
    "authors": [
      "Vincent Grondin",
      "Fran\u00e7ois Pomerleau",
      "Philippe Gigu\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04114",
    "title": "Towards Real-Time Temporal Graph Learning",
    "abstract": "In recent years, graph representation learning has gained significant popularity, which aims to generate node embeddings that capture features of graphs. One of the methods to achieve this is employing a technique called random walks that captures node sequences in a graph and then learns embeddings for each node using a natural language processing technique called Word2Vec. These embeddings are then used for deep learning on graph data for classification tasks, such as link prediction or node classification. Prior work operates on pre-collected temporal graph data and is not designed to handle updates on a graph in real-time. Real world graphs change dynamically and their entire temporal updates are not available upfront. In this paper, we propose an end-to-end graph learning pipeline that performs temporal graph construction, creates low-dimensional node embeddings, and trains multi-layer neural network models in an online setting. The training of the neural network models is identified as the main performance bottleneck as it performs repeated matrix operations on many sequentially connected low-dimensional kernels. We propose to unlock fine-grain parallelism in these low-dimensional kernels to boost performance of model training. ",
    "url": "https://arxiv.org/abs/2210.04114",
    "authors": [
      "Deniz Gurevin",
      "Mohsin Shan",
      "Tong Geng",
      "Weiwen Jiang",
      "Caiwen Ding",
      "Omer Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04124",
    "title": "Generalized energy and gradient flow via graph framelets",
    "abstract": "In this work, we provide a theoretical understanding of the framelet-based graph neural networks through the perspective of energy gradient flow. By viewing the framelet-based models as discretized gradient flows of some energy, we show it can induce both low-frequency and high-frequency-dominated dynamics, via the separate weight matrices for different frequency components. This substantiates its good empirical performance on both homophilic and heterophilic graphs. We then propose a generalized energy via framelet decomposition and show its gradient flow leads to a novel graph neural network, which includes many existing models as special cases. We then explain how the proposed model generally leads to more flexible dynamics, thus potentially enhancing the representation power of graph neural networks. ",
    "url": "https://arxiv.org/abs/2210.04124",
    "authors": [
      "Andi Han",
      "Dai Shi",
      "Zhiqi Shao",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04127",
    "title": "Towards Efficient Neural Scene Graphs by Learning Consistency Fields",
    "abstract": "Neural Radiance Fields (NeRF) achieves photo-realistic image rendering from novel views, and the Neural Scene Graphs (NSG) \\cite{ost2021neural} extends it to dynamic scenes (video) with multiple objects. Nevertheless, computationally heavy ray marching for every image frame becomes a huge burden. In this paper, taking advantage of significant redundancy across adjacent frames in videos, we propose a feature-reusing framework. From the first try of naively reusing the NSG features, however, we learn that it is crucial to disentangle object-intrinsic properties consistent across frames from transient ones. Our proposed method, \\textit{Consistency-Field-based NSG (CF-NSG)}, reformulates neural radiance fields to additionally consider \\textit{consistency fields}. With disentangled representations, CF-NSG takes full advantage of the feature-reusing scheme and performs an extended degree of scene manipulation in a more controllable manner. We empirically verify that CF-NSG greatly improves the inference efficiency by using 85\\% less queries than NSG without notable degradation in rendering quality. Code will be available at: https://github.com/ldynx/CF-NSG ",
    "url": "https://arxiv.org/abs/2210.04127",
    "authors": [
      "Yeji Song",
      "Chaerin Kong",
      "Seoyoung Lee",
      "Nojun Kwak",
      "Joonseok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04145",
    "title": "Fine-grained Anomaly Detection in Sequential Data via Counterfactual  Explanations",
    "abstract": "Anomaly detection in sequential data has been studied for a long time because of its potential in various applications, such as detecting abnormal system behaviors from log data. Although many approaches can achieve good performance on anomalous sequence detection, how to identify the anomalous entries in sequences is still challenging due to a lack of information at the entry-level. In this work, we propose a novel framework called CFDet for fine-grained anomalous entry detection. CFDet leverages the idea of interpretable machine learning. Given a sequence that is detected as anomalous, we can consider anomalous entry detection as an interpretable machine learning task because identifying anomalous entries in the sequence is to provide an interpretation to the detection result. We make use of the deep support vector data description (Deep SVDD) approach to detect anomalous sequences and propose a novel counterfactual interpretation-based approach to identify anomalous entries in the sequences. Experimental results on three datasets show that CFDet can correctly detect anomalous entries. ",
    "url": "https://arxiv.org/abs/2210.04145",
    "authors": [
      "He Cheng",
      "Depeng Xu",
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04152",
    "title": "A Contextual Bandit Approach for Value-oriented Prediction Interval  Forecasting",
    "abstract": "Prediction interval (PI) is an effective tool to quantify uncertainty and usually serves as an input to downstream robust optimization. Traditional approaches focus on improving the quality of PI in the view of statistical scores and assume the improvement in quality will lead to a higher value in the power systems operation. However, such an assumption cannot always hold in practice. In this paper, we propose a value-oriented PI forecasting approach, which aims at reducing operational costs in downstream operations. For that, it is required to issue PIs with the guidance of operational costs in robust optimization, which is addressed within the contextual bandit framework here. Concretely, the agent is used to select the optimal quantile proportion, while the environment reveals the costs in operations as rewards to the agent. As such, the agent can learn the policy of quantile proportion selection for minimizing the operational cost. The numerical study regarding a two-timescale operation of a virtual power plant verifies the superiority of the proposed approach in terms of operational value. And it is especially evident in the context of extensive penetration of wind power. ",
    "url": "https://arxiv.org/abs/2210.04152",
    "authors": [
      "Yufan Zhang",
      "Honglin Wen",
      "Qiuwei Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.04153",
    "title": "Stimulative Training of Residual Networks: A Social Psychology  Perspective of Loafing",
    "abstract": "Residual networks have shown great success and become indispensable in today's deep models. In this work, we aim to re-investigate the training process of residual networks from a novel social psychology perspective of loafing, and further propose a new training strategy to strengthen the performance of residual networks. As residual networks can be viewed as ensembles of relatively shallow networks (i.e., \\textit{unraveled view}) in prior works, we also start from such view and consider that the final performance of a residual network is co-determined by a group of sub-networks. Inspired by the social loafing problem of social psychology, we find that residual networks invariably suffer from similar problem, where sub-networks in a residual network are prone to exert less effort when working as part of the group compared to working alone. We define this previously overlooked problem as \\textit{network loafing}. As social loafing will ultimately cause the low individual productivity and the reduced overall performance, network loafing will also hinder the performance of a given residual network and its sub-networks. Referring to the solutions of social psychology, we propose \\textit{stimulative training}, which randomly samples a residual sub-network and calculates the KL-divergence loss between the sampled sub-network and the given residual network, to act as extra supervision for sub-networks and make the overall goal consistent. Comprehensive empirical results and theoretical analyses verify that stimulative training can well handle the loafing problem, and improve the performance of a residual network by improving the performance of its sub-networks. The code is available at https://github.com/Sunshine-Ye/NIPS22-ST . ",
    "url": "https://arxiv.org/abs/2210.04153",
    "authors": [
      "Peng Ye",
      "Shengji Tang",
      "Baopu Li",
      "Tao Chen",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04154",
    "title": "Self-supervised Video Representation Learning with Motion-Aware Masked  Autoencoders",
    "abstract": "Masked autoencoders (MAEs) have emerged recently as art self-supervised spatiotemporal representation learners. Inheriting from the image counterparts, however, existing video MAEs still focus largely on static appearance learning whilst are limited in learning dynamic temporal information hence less effective for video downstream tasks. To resolve this drawback, in this work we present a motion-aware variant -- MotionMAE. Apart from learning to reconstruct individual masked patches of video frames, our model is designed to additionally predict the corresponding motion structure information over time. This motion information is available at the temporal difference of nearby frames. As a result, our model can extract effectively both static appearance and dynamic motion spontaneously, leading to superior spatiotemporal representation learning capability. Extensive experiments show that our MotionMAE outperforms significantly both supervised learning baseline and state-of-the-art MAE alternatives, under both domain-specific and domain-generic pretraining-then-finetuning settings. In particular, when using ViT-B as the backbone our MotionMAE surpasses the prior art model by a margin of 1.2% on Something-Something V2 and 3.2% on UCF101 in domain-specific pretraining setting. Encouragingly, it also surpasses the competing MAEs by a large margin of over 3% on the challenging video object segmentation task. The code is available at https://github.com/happy-hsy/MotionMAE. ",
    "url": "https://arxiv.org/abs/2210.04154",
    "authors": [
      "Haosen Yang",
      "Deng Huang",
      "Bin Wen",
      "Jiannan Wu",
      "Hongxun Yao",
      "Yi Jiang",
      "Xiatian Zhu",
      "Zehuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04165",
    "title": "Neural Extended Kalman Filters for Learning and Predicting Dynamics of  Structural Systems",
    "abstract": "Accurate structural response prediction forms a main driver for structural health monitoring and control applications. This often requires the proposed model to adequately capture the underlying dynamics of complex structural systems. In this work, we utilize a learnable Extended Kalman Filter (EKF), named the Neural Extended Kalman Filter (Neural EKF) throughout this paper, for learning the latent evolution dynamics of complex physical systems. The Neural EKF is a generalized version of the conventional EKF, where the modeling of process dynamics and sensory observations can be parameterized by neural networks, therefore learned by end-to-end training. The method is implemented under the variational inference framework with the EKF conducting inference from sensing measurements. Typically, conventional variational inference models are parameterized by neural networks independent of the latent dynamics models. This characteristic makes the inference and reconstruction accuracy weakly based on the dynamics models and renders the associated training inadequate. We here show how the structure imposed by the Neural EKF is beneficial to the learning process. We demonstrate the efficacy of the framework on both simulated and real-world monitoring datasets, with the results indicating significant predictive capabilities of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2210.04165",
    "authors": [
      "Wei Liu",
      "Zhilu Lai",
      "Kiran Bacsa",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04175",
    "title": "Safety Verification for Neural Networks Based on Set-boundary Analysis",
    "abstract": "Neural networks (NNs) are increasingly applied in safety-critical systems such as autonomous vehicles. However, they are fragile and are often ill-behaved. Consequently, their behaviors should undergo rigorous guarantees before deployment in practice. In this paper we propose a set-boundary reachability method to investigate the safety verification problem of NNs from a topological perspective. Given an NN with an input set and a safe set, the safety verification problem is to determine whether all outputs of the NN resulting from the input set fall within the safe set. In our method, the homeomorphism property of NNs is mainly exploited, which establishes a relationship mapping boundaries to boundaries. The exploitation of this property facilitates reachability computations via extracting subsets of the input set rather than the entire input set, thus controlling the wrapping effect in reachability analysis and facilitating the reduction of computation burdens for safety verification. The homeomorphism property exists in some widely used NNs such as invertible NNs. Notable representations are invertible residual networks (i-ResNets) and Neural ordinary differential equations (Neural ODEs). For these NNs, our set-boundary reachability method only needs to perform reachability analysis on the boundary of the input set. For NNs which do not feature this property with respect to the input set, we explore subsets of the input set for establishing the local homeomorphism property, and then abandon these subsets for reachability computations. Finally, some examples demonstrate the performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.04175",
    "authors": [
      "Zhen Liang",
      "Dejin Ren",
      "Wanwei Liu",
      "Ji Wang",
      "Wenjing Yang",
      "Bai Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.04183",
    "title": "MAMO: Masked Multimodal Modeling for Fine-Grained Vision-Language  Representation Learning",
    "abstract": "Multimodal representation learning has shown promising improvements on various vision-language tasks. Most existing methods excel at building global-level alignment between vision and language while lacking effective fine-grained image-text interaction. In this paper, we propose a jointly masked multimodal modeling method to learn fine-grained multimodal representations. Our method performs joint masking on image-text input and integrates both implicit and explicit targets for the masked signals to recover. The implicit target provides a unified and debiased objective for vision and language, where the model predicts latent multimodal representations of the unmasked input. The explicit target further enriches the multimodal representations by recovering high-level and semantically meaningful information: momentum visual features of image patches and concepts of word tokens. Through such a masked modeling process, our model not only learns fine-grained multimodal interaction, but also avoids the semantic gap between high-level representations and low- or mid-level prediction targets (e.g. image pixels), thus producing semantically rich multimodal representations that perform well on both zero-shot and fine-tuned settings. Our pre-trained model (named MAMO) achieves state-of-the-art performance on various downstream vision-language tasks, including image-text retrieval, visual question answering, visual reasoning, and weakly-supervised visual grounding. ",
    "url": "https://arxiv.org/abs/2210.04183",
    "authors": [
      "Zijia Zhao",
      "Longteng Guo",
      "Xingjian He",
      "Shuai Shao",
      "Zehuan Yuan",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.04195",
    "title": "Online Training Through Time for Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are promising brain-inspired energy-efficient models. Recent progress in training methods has enabled successful deep SNNs on large-scale tasks with low latency. Particularly, backpropagation through time (BPTT) with surrogate gradients (SG) is popularly used to achieve high performance in a very small number of time steps. However, it is at the cost of large memory consumption for training, lack of theoretical clarity for optimization, and inconsistency with the online property of biological learning and rules on neuromorphic hardware. Other works connect spike representations of SNNs with equivalent artificial neural network formulation and train SNNs by gradients from equivalent mappings to ensure descent directions. But they fail to achieve low latency and are also not online. In this work, we propose online training through time (OTTT) for SNNs, which is derived from BPTT to enable forward-in-time learning by tracking presynaptic activities and leveraging instantaneous loss and gradients. Meanwhile, we theoretically analyze and prove that gradients of OTTT can provide a similar descent direction for optimization as gradients based on spike representations under both feedforward and recurrent conditions. OTTT only requires constant training memory costs agnostic to time steps, avoiding the significant memory costs of BPTT for GPU training. Furthermore, the update rule of OTTT is in the form of three-factor Hebbian learning, which could pave a path for online on-chip learning. With OTTT, it is the first time that two mainstream supervised SNN training methods, BPTT with SG and spike representation-based training, are connected, and meanwhile in a biologically plausible form. Experiments on CIFAR-10, CIFAR-100, ImageNet, and CIFAR10-DVS demonstrate the superior performance of our method on large-scale static and neuromorphic datasets in small time steps. ",
    "url": "https://arxiv.org/abs/2210.04195",
    "authors": [
      "Mingqing Xiao",
      "Qingyan Meng",
      "Zongpeng Zhang",
      "Di He",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04200",
    "title": "Boosting Out-of-distribution Detection with Typical Features",
    "abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the reliability and safety of deep neural networks in real-world scenarios. Different from most previous OOD detection methods that focus on designing OOD scores or introducing diverse outlier examples to retrain the model, we delve into the obstacle factors in OOD detection from the perspective of typicality and regard the feature's high-probability region of the deep model as the feature's typical set. We propose to rectify the feature into its typical set and calculate the OOD score with the typical features to achieve reliable uncertainty estimation. The feature rectification can be conducted as a {plug-and-play} module with various OOD scores. We evaluate the superiority of our method on both the commonly used benchmark (CIFAR) and the more challenging high-resolution benchmark with large label space (ImageNet). Notably, our approach outperforms state-of-the-art methods by up to 5.11$\\%$ in the average FPR95 on the ImageNet benchmark. ",
    "url": "https://arxiv.org/abs/2210.04200",
    "authors": [
      "Yao Zhu",
      "YueFeng Chen",
      "Chuanlong Xie",
      "Xiaodan Li",
      "Rong Zhang",
      "Hui Xue",
      "Xiang Tian",
      "bolun zheng",
      "Yaowu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04213",
    "title": "Towards Understanding and Boosting Adversarial Transferability from a  Distribution Perspective",
    "abstract": "Transferable adversarial attacks against Deep neural networks (DNNs) have received broad attention in recent years. An adversarial example can be crafted by a surrogate model and then attack the unknown target model successfully, which brings a severe threat to DNNs. The exact underlying reasons for the transferability are still not completely understood. Previous work mostly explores the causes from the model perspective, e.g., decision boundary, model architecture, and model capacity. adversarial attacks against Deep neural networks (DNNs) have received broad attention in recent years. An adversarial example can be crafted by a surrogate model and then attack the unknown target model successfully, which brings a severe threat to DNNs. The exact underlying reasons for the transferability are still not completely understood. Previous work mostly explores the causes from the model perspective. Here, we investigate the transferability from the data distribution perspective and hypothesize that pushing the image away from its original distribution can enhance the adversarial transferability. To be specific, moving the image out of its original distribution makes different models hardly classify the image correctly, which benefits the untargeted attack, and dragging the image into the target distribution misleads the models to classify the image as the target class, which benefits the targeted attack. Towards this end, we propose a novel method that crafts adversarial examples by manipulating the distribution of the image. We conduct comprehensive transferable attacks against multiple DNNs to demonstrate the effectiveness of the proposed method. Our method can significantly improve the transferability of the crafted attacks and achieves state-of-the-art performance in both untargeted and targeted scenarios, surpassing the previous best method by up to 40$\\%$ in some cases. ",
    "url": "https://arxiv.org/abs/2210.04213",
    "authors": [
      "Yao Zhu",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Kejiang Chen",
      "Yuan He",
      "Xiang Tian",
      "Bolun Zheng",
      "Yaowu Chen",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04214",
    "title": "Data augmentation for NeRF: a geometric consistent solution based on  view morphing",
    "abstract": "NeRF aims to learn a continuous neural scene representation by using a finite set of input images taken from different viewpoints. The fewer the number of viewpoints, the higher the likelihood of overfitting on them. This paper mitigates such limitation by presenting a novel data augmentation approach to generate geometrically consistent image transitions between viewpoints using view morphing. View morphing is a highly versatile technique that does not requires any prior knowledge about the 3D scene because it is based on general principles of projective geometry. A key novelty of our method is to use the very same depths predicted by NeRF to generate the image transitions that are then added to NeRF training. We experimentally show that this procedure enables NeRF to improve the quality of its synthesised novel views in the case of datasets with few training viewpoints. We improve PSNR up to 1.8dB and 10.5dB when eight and four views are used for training, respectively. To the best of our knowledge, this is the first data augmentation strategy for NeRF that explicitly synthesises additional new input images to improve the model generalisation. ",
    "url": "https://arxiv.org/abs/2210.04214",
    "authors": [
      "Matteo Bortolon",
      "Alessio Del Bue",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.04217",
    "title": "Estimating Neural Reflectance Field from Radiance Field using Tree  Structures",
    "abstract": "We present a new method for estimating the Neural Reflectance Field (NReF) of an object from a set of posed multi-view images under unknown lighting. NReF represents 3D geometry and appearance of objects in a disentangled manner, and are hard to be estimated from images only. Our method solves this problem by exploiting the Neural Radiance Field (NeRF) as a proxy representation, from which we perform further decomposition. A high-quality NeRF decomposition relies on good geometry information extraction as well as good prior terms to properly resolve ambiguities between different components. To extract high-quality geometry information from radiance fields, we re-design a new ray-casting based method for surface point extraction. To efficiently compute and apply prior terms, we convert different prior terms into different type of filter operations on the surface extracted from radiance field. We then employ two type of auxiliary data structures, namely Gaussian KD-tree and octree, to support fast querying of surface points and efficient computation of surface filters during training. Based on this, we design a multi-stage decomposition optimization pipeline for estimating neural reflectance field from neural radiance fields. Extensive experiments show our method outperforms other state-of-the-art methods on different data, and enable high-quality free-view relighting as well as material editing tasks. ",
    "url": "https://arxiv.org/abs/2210.04217",
    "authors": [
      "Xiu Li",
      "Xiao Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04220",
    "title": "Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect  Category Detection",
    "abstract": "Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of aspect-based sentiment analysis, which aims to detect aspect categories accurately with limited training instances. Recently, dominant works use the prototypical network to accomplish this task, and employ the attention mechanism to extract keywords of aspect category from the sentences to produce the prototype for each aspect. However, they still suffer from serious noise problems: (1) due to lack of sufficient supervised data, the previous methods easily catch noisy words irrelevant to the current aspect category, which largely affects the quality of the generated prototype; (2) the semantically-close aspect categories usually generate similar prototypes, which are mutually noisy and confuse the classifier seriously. In this paper, we resort to the label information of each aspect to tackle the above problems, along with proposing a novel Label-Driven Denoising Framework (LDF). Extensive experimental results show that our framework achieves better performance than other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.04220",
    "authors": [
      "Fei Zhao",
      "Yuchen Shen",
      "Zhen Wu",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04227",
    "title": "Dual-distribution discrepancy with self-supervised refinement for  anomaly detection in medical images",
    "abstract": "Medical anomaly detection is a crucial yet challenging task aiming at recognizing abnormal images to assist diagnosis. Due to the high-cost annotations of abnormal images, most methods utilize only known normal images during training and identify samples not conforming to the normal profile as anomalies in the testing phase. A large number of readily available unlabeled images containing anomalies are thus ignored in the training phase, restricting their performance. To solve this problem, we propose the Dual-distribution Discrepancy for Anomaly Detection (DDAD), utilizing both known normal images and unlabeled images. Two modules are designed to model the normative distribution of normal images and the unknown distribution of both normal and unlabeled images, respectively, using ensembles of reconstruction networks. Subsequently, intra-discrepancy of the normative distribution module, and inter-discrepancy between the two modules are designed as anomaly scores. Furthermore, an Anormal Score Refinement Net (ASR-Net) trained via self-supervised learning is proposed to refine the two anomaly scores. For evaluation, five medical datasets including chest X-rays, brain MRIs and retinal fundus images are organized as benchmarks. Experiments on these benchmarks demonstrate our method achieves significant gains and outperforms state-of-the-art methods. Code and organized benchmarks will be available at https://github.com/caiyu6666/DDAD-ASR ",
    "url": "https://arxiv.org/abs/2210.04227",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04229",
    "title": "Learning on the Edge: Online Learning with Stochastic Feedback Graphs",
    "abstract": "The framework of feedback graphs is a generalization of sequential decision-making with bandit or full information feedback. In this work, we study an extension where the directed feedback graph is stochastic, following a distribution similar to the classical Erd\\H{o}s-R\\'enyi model. Specifically, in each round every edge in the graph is either realized or not with a distinct probability for each edge. We prove nearly optimal regret bounds of order $\\min\\bigl\\{\\min_{\\varepsilon} \\sqrt{(\\alpha_\\varepsilon/\\varepsilon) T},\\, \\min_{\\varepsilon} (\\delta_\\varepsilon/\\varepsilon)^{1/3} T^{2/3}\\bigr\\}$ (ignoring logarithmic factors), where $\\alpha_{\\varepsilon}$ and $\\delta_{\\varepsilon}$ are graph-theoretic quantities measured on the support of the stochastic feedback graph $\\mathcal{G}$ with edge probabilities thresholded at $\\varepsilon$. Our result, which holds without any preliminary knowledge about $\\mathcal{G}$, requires the learner to observe only the realized out-neighborhood of the chosen action. When the learner is allowed to observe the realization of the entire graph (but only the losses in the out-neighborhood of the chosen action), we derive a more efficient algorithm featuring a dependence on weighted versions of the independence and weak domination numbers that exhibits improved bounds for some special cases. ",
    "url": "https://arxiv.org/abs/2210.04229",
    "authors": [
      "Emmanuel Esposito",
      "Federico Fusco",
      "Dirk van der Hoeven",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.04232",
    "title": "Revealing Patient-Reported Experiences in Healthcare from Social Media  using the DAPMAV Framework",
    "abstract": "Understanding patient experience in healthcare is increasingly important and desired by medical professionals in a patient-centred care approach. Healthcare discourse on social media presents an opportunity to gain a unique perspective on patient-reported experiences, complementing traditional survey data. These social media reports often appear as first-hand accounts of patients' journeys through the healthcare system, whose details extend beyond the confines of structured surveys and at a far larger scale than focus groups. However, in contrast with the vast presence of patient-experience data on social media and the potential benefits the data offers, it attracts comparatively little research attention due to the technical proficiency required for text analysis. In this paper, we introduce the Design-Acquire-Process-Model-Analyse-Visualise (DAPMAV) framework to equip non-technical domain experts with a structured approach that will enable them to capture patient-reported experiences from social media data. We apply this framework in a case study on prostate cancer data from /r/ProstateCancer, demonstrate the framework's value in capturing specific aspects of patient concern (such as sexual dysfunction), provide an overview of the discourse, and show narrative and emotional progression through these stories. We anticipate this framework to apply to a wide variety of areas in healthcare, including capturing and differentiating experiences across minority groups, geographic boundaries, and types of illnesses. ",
    "url": "https://arxiv.org/abs/2210.04232",
    "authors": [
      "Curtis Murray",
      "Lewis Mitchell",
      "Jonathan Tuke",
      "Mark Mackay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04233",
    "title": "Robustifying the Multi-Scale Representation of Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) recently emerged as a new paradigm for object representation from multi-view (MV) images. Yet, it cannot handle multi-scale (MS) images and camera pose estimation errors, which generally is the case with multi-view images captured from a day-to-day commodity camera. Although recently proposed Mip-NeRF could handle multi-scale imaging problems with NeRF, it cannot handle camera pose estimation error. On the other hand, the newly proposed BARF can solve the camera pose problem with NeRF but fails if the images are multi-scale in nature. This paper presents a robust multi-scale neural radiance fields representation approach to simultaneously overcome both real-world imaging issues. Our method handles multi-scale imaging effects and camera-pose estimation problems with NeRF-inspired approaches by leveraging the fundamentals of scene rigidity. To reduce unpleasant aliasing artifacts due to multi-scale images in the ray space, we leverage Mip-NeRF multi-scale representation. For joint estimation of robust camera pose, we propose graph-neural network-based multiple motion averaging in the neural volume rendering framework. We demonstrate, with examples, that for an accurate neural representation of an object from day-to-day acquired multi-view images, it is crucial to have precise camera-pose estimates. Without considering robustness measures in the camera pose estimation, modeling for multi-scale aliasing artifacts via conical frustum can be counterproductive. We present extensive experiments on the benchmark datasets to demonstrate that our approach provides better results than the recent NeRF-inspired approaches for such realistic settings. ",
    "url": "https://arxiv.org/abs/2210.04233",
    "authors": [
      "Nishant Jain",
      "Suryansh Kumar",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04236",
    "title": "Fusing Event-based Camera and Radar for SLAM Using Spiking Neural  Networks with Continual STDP Learning",
    "abstract": "This work proposes a first-of-its-kind SLAM architecture fusing an event-based camera and a Frequency Modulated Continuous Wave (FMCW) radar for drone navigation. Each sensor is processed by a bio-inspired Spiking Neural Network (SNN) with continual Spike-Timing-Dependent Plasticity (STDP) learning, as observed in the brain. In contrast to most learning-based SLAM systems%, which a) require the acquisition of a representative dataset of the environment in which navigation must be performed and b) require an off-line training phase, our method does not require any offline training phase, but rather the SNN continuously learns features from the input data on the fly via STDP. At the same time, the SNN outputs are used as feature descriptors for loop closure detection and map correction. We conduct numerous experiments to benchmark our system against state-of-the-art RGB methods and we demonstrate the robustness of our DVS-Radar SLAM approach under strong lighting variations. ",
    "url": "https://arxiv.org/abs/2210.04236",
    "authors": [
      "Ali Safa",
      "Tim Verbelen",
      "Ilja Ocket",
      "Andr\u00e9 Bourdoux",
      "Hichem Sahli",
      "Francky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.04244",
    "title": "Text detection and recognition based on a lensless imaging system",
    "abstract": "Lensless cameras are characterized by several advantages (e.g., miniaturization, ease of manufacture, and low cost) as compared with conventional cameras. However, they have not been extensively employed due to their poor image clarity and low image resolution, especially for tasks that have high requirements on image quality and details such as text detection and text recognition. To address the problem, a framework of deep-learning-based pipeline structure was built to recognize text with three steps from raw data captured by employing lensless cameras. This pipeline structure consisted of the lensless imaging model U-Net, the text detection model connectionist text proposal network (CTPN), and the text recognition model convolutional recurrent neural network (CRNN). Compared with the method focusing only on image reconstruction, UNet in the pipeline was able to supplement the imaging details by enhancing factors related to character categories in the reconstruction process, so the textual information can be more effectively detected and recognized by CTPN and CRNN with fewer artifacts and high-clarity reconstructed lensless images. By performing experiments on datasets of different complexities, the applicability to text detection and recognition on lensless cameras was verified. This study reasonably demonstrates text detection and recognition tasks in the lensless camera system,and develops a basic method for novel applications. ",
    "url": "https://arxiv.org/abs/2210.04244",
    "authors": [
      "Yinger Zhang",
      "Zhouyi Wu",
      "Peiying Lin",
      "Yuting Wu",
      "Lusong Wei",
      "Zhengjie Huang",
      "Jiangtao Huangfu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04246",
    "title": "Improve Transformer Pre-Training with Decoupled Directional Relative  Position Encoding and Representation Differentiations",
    "abstract": "In this work, we revisit the Transformer-based pre-trained language models and identify two problems that may limit the expressiveness of the model. Firstly, existing relative position encoding models (e.g., T5 and DEBERTA) confuse two heterogeneous information: relative distance and direction. It may make the model unable to capture the associative semantics of the same direction or the same distance, which in turn affects the performance of downstream tasks. Secondly, we notice the pre-trained BERT with Mask Language Modeling (MLM) pre-training objective outputs similar token representations and attention weights of different heads, which may impose difficulties in capturing discriminative semantic representations. Motivated by the above investigation, we propose two novel techniques to improve pre-trained language models: Decoupled Directional Relative Position (DDRP) encoding and MTH pre-training objective. DDRP decouples the relative distance features and the directional features in classical relative position encoding for better position information understanding. MTH designs two novel auxiliary losses besides MLM to enlarge the dissimilarities between (a) last hidden states of different tokens, and (b) attention weights of different heads, alleviating homogenization and anisotropic problem in representation learning for better optimization. Extensive experiments and ablation studies on GLUE benchmark demonstrate the effectiveness of our proposed methods. ",
    "url": "https://arxiv.org/abs/2210.04246",
    "authors": [
      "Haojie Zhang",
      "Mingfei Liang",
      "Ruobing Xie",
      "Zhenlong Sun",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04255",
    "title": "Unsupervised Cross-Modality Domain Adaptation for Vestibular Schwannoma  Segmentation and Koos Grade Prediction based on Semi-Supervised Contrastive  Learning",
    "abstract": "Domain adaptation has been widely adopted to transfer styles across multi-vendors and multi-centers, as well as to complement the missing modalities. In this challenge, we proposed an unsupervised domain adaptation framework for cross-modality vestibular schwannoma (VS) and cochlea segmentation and Koos grade prediction. We learn the shared representation from both ceT1 and hrT2 images and recover another modality from the latent representation, and we also utilize proxy tasks of VS segmentation and brain parcellation to restrict the consistency of image structures in domain adaptation. After generating missing modalities, the nnU-Net model is utilized for VS and cochlea segmentation, while a semi-supervised contrastive learning pre-train approach is employed to improve the model performance for Koos grade prediction. On CrossMoDA validation phase Leaderboard, our method received rank 4 in task1 with a mean Dice score of 0.8394 and rank 2 in task2 with Macro-Average Mean Square Error of 0.3941. Our code is available at https://github.com/fiy2W/cmda2022.superpolymerization. ",
    "url": "https://arxiv.org/abs/2210.04255",
    "authors": [
      "Luyi Han",
      "Yunzhi Huang",
      "Tao Tan",
      "Ritse Mann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04260",
    "title": "Coresets for Wasserstein Distributionally Robust Optimization Problems",
    "abstract": "Wasserstein distributionally robust optimization (\\textsf{WDRO}) is a popular model to enhance the robustness of machine learning with ambiguous data. However, the complexity of \\textsf{WDRO} can be prohibitive in practice since solving its ``minimax'' formulation requires a great amount of computation. Recently, several fast \\textsf{WDRO} training algorithms for some specific machine learning tasks (e.g., logistic regression) have been developed. However, the research on designing efficient algorithms for general large-scale \\textsf{WDRO}s is still quite limited, to the best of our knowledge. \\textit{Coreset} is an important tool for compressing large dataset, and thus it has been widely applied to reduce the computational complexities for many optimization problems. In this paper, we introduce a unified framework to construct the $\\epsilon$-coreset for the general \\textsf{WDRO} problems. Though it is challenging to obtain a conventional coreset for \\textsf{WDRO} due to the uncertainty issue of ambiguous data, we show that we can compute a ``dual coreset'' by using the strong duality property of \\textsf{WDRO}. Also, the error introduced by the dual coreset can be theoretically guaranteed for the original \\textsf{WDRO} objective. To construct the dual coreset, we propose a novel grid sampling approach that is particularly suitable for the dual formulation of \\textsf{WDRO}. Finally, we implement our coreset approach and illustrate its effectiveness for several \\textsf{WDRO} problems in the experiments. ",
    "url": "https://arxiv.org/abs/2210.04260",
    "authors": [
      "Ruomin Huang",
      "Jiawei Huang",
      "Wenjie Liu",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04264",
    "title": "CAGroup3D: Class-Aware Grouping for 3D Object Detection on Point Clouds",
    "abstract": "We present a novel two-stage fully sparse convolutional 3D object detection framework, named CAGroup3D. Our proposed method first generates some high-quality 3D proposals by leveraging the class-aware local group strategy on the object surface voxels with the same semantic predictions, which considers semantic consistency and diverse locality abandoned in previous bottom-up approaches. Then, to recover the features of missed voxels due to incorrect voxel-wise segmentation, we build a fully sparse convolutional RoI pooling module to directly aggregate fine-grained spatial information from backbone for further proposal refinement. It is memory-and-computation efficient and can better encode the geometry-specific features of each 3D proposal. Our model achieves state-of-the-art 3D detection performance with remarkable gains of +\\textit{3.6\\%} on ScanNet V2 and +\\textit{2.6}\\% on SUN RGB-D in term of mAP@0.25. Code will be available at https://github.com/Haiyang-W/CAGroup3D. ",
    "url": "https://arxiv.org/abs/2210.04264",
    "authors": [
      "Haiyang Wang",
      "Lihe Ding",
      "Shaocong Dong",
      "Shaoshuai Shi",
      "Aoxue Li",
      "Jianan Li",
      "Zhenguo Li",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04267",
    "title": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "abstract": "Pre-training large neural language models, such as BERT, has led to impressive gains on many natural language processing (NLP) tasks. Although this method has proven to be effective for many domains, it might not always provide desirable benefits. In this paper we study the effects of hateful pre-training on low resource hate speech classification tasks. While previous studies on English language have emphasized its importance, we aim to to augment their observations with some non-obvious insights. We evaluate different variations of tweet based BERT models pre-trained on hateful, non-hateful and mixed subsets of 40M tweet dataset. This evaluation is carried for Indian languages Hindi and Marathi. This paper is an empirical evidence that hateful pre-training is not the best pre-training option for hate speech detection. We show that pre-training on non-hateful text from target domain provides similar or better results. Further, we introduce HindTweetBERT and MahaTweetBERT, the first publicly available BERT models pre-trained on Hindi and Marathi tweets respectively. We show that they provide state-of-the-art performance on hate speech classification tasks. We also release a gold hate speech evaluation benchmark HateEval-Hi and HateEval-Mr consisting of manually labeled 2000 tweets each. ",
    "url": "https://arxiv.org/abs/2210.04267",
    "authors": [
      "Shantanu Patankar",
      "Omkar Gokhale",
      "Aditya Kane",
      "Tanmay Chavan",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04271",
    "title": "Sketched Multi-view Subspace Learning for Hyperspectral Anomalous Change  Detection",
    "abstract": "In recent years, multi-view subspace learning has been garnering increasing attention. It aims to capture the inner relationships of the data that are collected from multiple sources by learning a unified representation. In this way, comprehensive information from multiple views is shared and preserved for the generalization processes. As a special branch of temporal series hyperspectral image (HSI) processing, the anomalous change detection task focuses on detecting very small changes among different temporal images. However, when the volume of datasets is very large or the classes are relatively comprehensive, existing methods may fail to find those changes between the scenes, and end up with terrible detection results. In this paper, inspired by the sketched representation and multi-view subspace learning, a sketched multi-view subspace learning (SMSL) model is proposed for HSI anomalous change detection. The proposed model preserves major information from the image pairs and improves computational complexity by using a sketched representation matrix. Furthermore, the differences between scenes are extracted by utilizing the specific regularizer of the self-representation matrices. To evaluate the detection effectiveness of the proposed SMSL model, experiments are conducted on a benchmark hyperspectral remote sensing dataset and a natural hyperspectral dataset, and compared with other state-of-the art approaches. ",
    "url": "https://arxiv.org/abs/2210.04271",
    "authors": [
      "Shizhen Chang",
      "Michael Kopp",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04297",
    "title": "Optimal Control for Platooning in Vehicular Networks",
    "abstract": "Truck platooning has recently gained attention as the automotive industry develops toward autonomous driving systems and vehicular networks. Recent research in this area has focused on the aerodynamics, network stability, and longitudinal control of platoons. However, the system aspects (e.g., platoon coordination) are still not well explored. This paper studies a platooning coordination problem that decides whether or not trucks waiting at an initial location (station) should wait for a platoon to arrive in order to leave. Arrivals of trucks at the station and platoons by the station are independent, and Bernoulli distributed. We use the theory of Markov decision processes to formulate the dispatching control problem and derive the optimal policy to govern the dispatching of trucks with platoons. It is shown that the policy that minimizes the dispatching control at the station is a threshold policy. Numerical results for the average cost case are presented. They are consistent with the theoretical ones. ",
    "url": "https://arxiv.org/abs/2210.04297",
    "authors": [
      "Thiago S. Gomides",
      "Evangelos Kranakis",
      "Ioannis Lambadaris",
      "Yannis Viniotis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.04303",
    "title": "Are All Vision Models Created Equal? A Study of the Open-Loop to  Closed-Loop Causality Gap",
    "abstract": "There is an ever-growing zoo of modern neural network models that can efficiently learn end-to-end control from visual observations. These advanced deep models, ranging from convolutional to patch-based networks, have been extensively tested on offline image classification and regression tasks. In this paper, we study these vision architectures with respect to the open-loop to closed-loop causality gap, i.e., offline training followed by an online closed-loop deployment. This causality gap typically emerges in robotics applications such as autonomous driving, where a network is trained to imitate the control commands of a human. In this setting, two situations arise: 1) Closed-loop testing in-distribution, where the test environment shares properties with those of offline training data. 2) Closed-loop testing under distribution shifts and out-of-distribution. Contrary to recently reported results, we show that under proper training guidelines, all vision models perform indistinguishably well on in-distribution deployment, resolving the causality gap. In situation 2, We observe that the causality gap disrupts performance regardless of the choice of the model architecture. Our results imply that the causality gap can be solved in situation one with our proposed training guideline with any modern network architecture, whereas achieving out-of-distribution generalization (situation two) requires further investigations, for instance, on data diversity rather than the model architecture. ",
    "url": "https://arxiv.org/abs/2210.04303",
    "authors": [
      "Mathias Lechner",
      "Ramin Hasani",
      "Alexander Amini",
      "Tsun-Hsuan Wang",
      "Thomas A. Henzinger",
      "Daniela Rus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04311",
    "title": "Pruning Adversarially Robust Neural Networks without Adversarial  Examples",
    "abstract": "Adversarial pruning compresses models while preserving robustness. Current methods require access to adversarial examples during pruning. This significantly hampers training efficiency. Moreover, as new adversarial attacks and training methods develop at a rapid rate, adversarial pruning methods need to be modified accordingly to keep up. In this work, we propose a novel framework to prune a previously trained robust neural network while maintaining adversarial robustness, without further generating adversarial examples. We leverage concurrent self-distillation and pruning to preserve knowledge in the original model as well as regularizing the pruned model via the Hilbert-Schmidt Information Bottleneck. We comprehensively evaluate our proposed framework and show its superior performance in terms of both adversarial robustness and efficiency when pruning architectures trained on the MNIST, CIFAR-10, and CIFAR-100 datasets against five state-of-the-art attacks. Code is available at https://github.com/neu-spiral/PwoA/. ",
    "url": "https://arxiv.org/abs/2210.04311",
    "authors": [
      "Tong Jian",
      "Zifeng Wang",
      "Yanzhi Wang",
      "Jennifer Dy",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04337",
    "title": "Quantifying Social Biases Using Templates is Unreliable",
    "abstract": "Recently, there has been an increase in efforts to understand how large language models (LLMs) propagate and amplify social biases. Several works have utilized templates for fairness evaluation, which allow researchers to quantify social biases in the absence of test sets with protected attribute labels. While template evaluation can be a convenient and helpful diagnostic tool to understand model deficiencies, it often uses a simplistic and limited set of templates. In this paper, we study whether bias measurements are sensitive to the choice of templates used for benchmarking. Specifically, we investigate the instability of bias measurements by manually modifying templates proposed in previous works in a semantically-preserving manner and measuring bias across these modifications. We find that bias values and resulting conclusions vary considerably across template modifications on four tasks, ranging from an 81% reduction (NLI) to a 162% increase (MLM) in (task-specific) bias measurements. Our results indicate that quantifying fairness in LLMs, as done in current practice, can be brittle and needs to be approached with more care and caution. ",
    "url": "https://arxiv.org/abs/2210.04337",
    "authors": [
      "Preethi Seshadri",
      "Pouya Pezeshkpour",
      "Sameer Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04338",
    "title": "A Method for Computing Inverse Parametric PDE Problems with  Random-Weight Neural Networks",
    "abstract": "We present a method for computing the inverse parameters and the solution field to inverse parametric PDEs based on randomized neural networks. This extends the local extreme learning machine technique originally developed for forward PDEs to inverse problems. We develop three algorithms for training the neural network to solve the inverse PDE problem. The first algorithm (NLLSQ) determines the inverse parameters and the trainable network parameters all together by the nonlinear least squares method with perturbations (NLLSQ-perturb). The second algorithm (VarPro-F1) eliminates the inverse parameters from the overall problem by variable projection to attain a reduced problem about the trainable network parameters only. It solves the reduced problem first by the NLLSQ-perturb algorithm for the trainable network parameters, and then computes the inverse parameters by the linear least squares method. The third algorithm (VarPro-F2) eliminates the trainable network parameters from the overall problem by variable projection to attain a reduced problem about the inverse parameters only. It solves the reduced problem for the inverse parameters first, and then computes the trainable network parameters afterwards. VarPro-F1 and VarPro-F2 are reciprocal to each other in a sense. The presented method produces accurate results for inverse PDE problems, as shown by the numerical examples herein. For noise-free data, the errors for the inverse parameters and the solution field decrease exponentially as the number of collocation points or the number of trainable network parameters increases, and can reach a level close to the machine accuracy. For noisy data, the accuracy degrades compared with the case of noise-free data, but the method remains quite accurate. The presented method has been compared with the physics-informed neural network method. ",
    "url": "https://arxiv.org/abs/2210.04338",
    "authors": [
      "Suchuan Dong",
      "Yiran Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2210.04349",
    "title": "Nonlinear Sufficient Dimension Reduction with a Stochastic Neural  Network",
    "abstract": "Sufficient dimension reduction is a powerful tool to extract core information hidden in the high-dimensional data and has potentially many important applications in machine learning tasks. However, the existing nonlinear sufficient dimension reduction methods often lack the scalability necessary for dealing with large-scale data. We propose a new type of stochastic neural network under a rigorous probabilistic framework and show that it can be used for sufficient dimension reduction for large-scale data. The proposed stochastic neural network is trained using an adaptive stochastic gradient Markov chain Monte Carlo algorithm, whose convergence is rigorously studied in the paper as well. Through extensive experiments on real-world classification and regression problems, we show that the proposed method compares favorably with the existing state-of-the-art sufficient dimension reduction methods and is computationally more efficient for large-scale data. ",
    "url": "https://arxiv.org/abs/2210.04349",
    "authors": [
      "Siqi Liang",
      "Yan Sun",
      "Faming Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04367",
    "title": "Unsupervised RGB-to-Thermal Domain Adaptation via Multi-Domain Attention  Network",
    "abstract": "This work presents a new method for unsupervised thermal image classification and semantic segmentation by transferring knowledge from the RGB domain using a multi-domain attention network. Our method does not require any thermal annotations or co-registered RGB-thermal pairs, enabling robots to perform visual tasks at night and in adverse weather conditions without incurring additional costs of data labeling and registration. Current unsupervised domain adaptation methods look to align global images or features across domains. However, when the domain shift is significantly larger for cross-modal data, not all features can be transferred. We solve this problem by using a shared backbone network that promotes generalization, and domain-specific attention that reduces negative transfer by attending to domain-invariant and easily-transferable features. Our approach outperforms the state-of-the-art RGB-to-thermal adaptation method in classification benchmarks, and is successfully applied to thermal river scene segmentation using only synthetic RGB images. Our code is made publicly available at https://github.com/ganlumomo/thermal-uda-attention. ",
    "url": "https://arxiv.org/abs/2210.04367",
    "authors": [
      "Lu Gan",
      "Connor Lee",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04370",
    "title": "Propagation Stability Concepts for Network Synchronization Processes",
    "abstract": "A notion of disturbance propagation stability is defined for dynamical network processes, in terms of decrescence of an input-output energy metric along cutsets away from the disturbance source. A characterization of the disturbance propagation notion is developed for a canonical model for synchronization of linearly-coupled homogeneous subsystems. Specifically, propagation stability is equivalenced with the frequency response of a certain local closed-loop model, which is defined from the subsystem model and local network connections, being sub-unity gain. For the case where the subsystem is single-input single-output (SISO), a further simplification in terms of the subsystem's open loop Nyquist plot is obtained. An extension of the disturbance propagation stability concept toward imperviousness of subnetworks to disturbances is briefly developed, and an example focused on networks with planar subsystems is considered. ",
    "url": "https://arxiv.org/abs/2210.04370",
    "authors": [
      "Sandip Roy",
      "Subir Sarker",
      "Mengran Xue"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.04373",
    "title": "Contrastive Representation Learning for Conversational Question  Answering over Knowledge Graphs",
    "abstract": "This paper addresses the task of conversational question answering (ConvQA) over knowledge graphs (KGs). The majority of existing ConvQA methods rely on full supervision signals with a strict assumption of the availability of gold logical forms of queries to extract answers from the KG. However, creating such a gold logical form is not viable for each potential question in a real-world scenario. Hence, in the case of missing gold logical forms, the existing information retrieval-based approaches use weak supervision via heuristics or reinforcement learning, formulating ConvQA as a KG path ranking problem. Despite missing gold logical forms, an abundance of conversational contexts, such as entire dialog history with fluent responses and domain information, can be incorporated to effectively reach the correct KG path. This work proposes a contrastive representation learning-based approach to rank KG paths effectively. Our approach solves two key challenges. Firstly, it allows weak supervision-based learning that omits the necessity of gold annotations. Second, it incorporates the conversational context (entire dialog history and domain information) to jointly learn its homogeneous representation with KG paths to improve contrastive representations for effective path ranking. We evaluate our approach on standard datasets for ConvQA, on which it significantly outperforms existing baselines on all domains and overall. Specifically, in some cases, the Mean Reciprocal Rank (MRR) and Hit@5 ranking metrics improve by absolute 10 and 18 points, respectively, compared to the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2210.04373",
    "authors": [
      "Endri Kacupaj",
      "Kuldeep Singh",
      "Maria Maleshkova",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04404",
    "title": "Modeling and Mining Multi-Aspect Graphs With Scalable Streaming Tensor  Decomposition",
    "abstract": "Graphs emerge in almost every real-world application domain, ranging from online social networks all the way to health data and movie viewership patterns. Typically, such real-world graphs are big and dynamic, in the sense that they evolve over time. Furthermore, graphs usually contain multi-aspect information i.e. in a social network, we can have the \"means of communication\" between nodes, such as who messages whom, who calls whom, and who comments on whose timeline and so on. How can we model and mine useful patterns, such as communities of nodes in that graph, from such multi-aspect graphs? How can we identify dynamic patterns in those graphs, and how can we deal with streaming data, when the volume of data to be processed is very large? In order to answer those questions, in this thesis, we propose novel tensor-based methods for mining static and dynamic multi-aspect graphs. In general, a tensor is a higher-order generalization of a matrix that can represent high-dimensional multi-aspect data such as time-evolving networks, collaboration networks, and spatio-temporal data like Electroencephalography (EEG) brain measurements. The thesis is organized in two synergistic thrusts: First, we focus on static multi-aspect graphs, where the goal is to identify coherent communities and patterns between nodes by leveraging the tensor structure in the data. Second, as our graphs evolve dynamically, we focus on handling such streaming updates in the data without having to re-compute the decomposition, but incrementally update the existing results. ",
    "url": "https://arxiv.org/abs/2210.04404",
    "authors": [
      "Ekta Gujral"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04406",
    "title": "Predicting Blossom Date of Cherry Tree With Support Vector Machine and  Recurrent Neural Network",
    "abstract": "Our project probes the relationship between temperatures and the blossom date of cherry trees. Through modeling, future flowering will become predictive, helping the public plan travels and avoid pollen season. To predict the date when the cherry trees will blossom exactly could be viewed as a multiclass classification problem, so we applied the multi-class Support Vector Classifier (SVC) and Recurrent Neural Network (RNN), particularly Long Short-term Memory (LSTM), to formulate the problem. In the end, we evaluate and compare the performance of these approaches to find out which one might be more applicable in reality. ",
    "url": "https://arxiv.org/abs/2210.04406",
    "authors": [
      "Hongyi Zheng",
      "Yanyu Chen",
      "Zihan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04427",
    "title": "Asymmetric Temperature Scaling Makes Larger Networks Teach Well Again",
    "abstract": "Knowledge Distillation (KD) aims at transferring the knowledge of a well-performed neural network (the {\\it teacher}) to a weaker one (the {\\it student}). A peculiar phenomenon is that a more accurate model doesn't necessarily teach better, and temperature adjustment can neither alleviate the mismatched capacity. To explain this, we decompose the efficacy of KD into three parts: {\\it correct guidance}, {\\it smooth regularization}, and {\\it class discriminability}. The last term describes the distinctness of {\\it wrong class probabilities} that the teacher provides in KD. Complex teachers tend to be over-confident and traditional temperature scaling limits the efficacy of {\\it class discriminability}, resulting in less discriminative wrong class probabilities. Therefore, we propose {\\it Asymmetric Temperature Scaling (ATS)}, which separately applies a higher/lower temperature to the correct/wrong class. ATS enlarges the variance of wrong class probabilities in the teacher's label and makes the students grasp the absolute affinities of wrong classes to the target class as discriminative as possible. Both theoretical analysis and extensive experimental results demonstrate the effectiveness of ATS. The demo developed in Mindspore is available at \\url{https://gitee.com/lxcnju/ats-mindspore}. ",
    "url": "https://arxiv.org/abs/2210.04427",
    "authors": [
      "Xin-Chun Li",
      "Wen-Shu Fan",
      "Shaoming Song",
      "Yinchuan Li",
      "Bingshuai Li",
      "Yunfeng Shao",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04434",
    "title": "Improving Code Review with GitHub Issue Tracking",
    "abstract": "Software quality is an important problem for technology companies, since it substantially impacts the efficiency, usefulness, and maintainability of the final product; hence, code review is a must-do activity for software developers. During the code review process, senior engineers monitor other developers' work to spot possible problems and enforce coding standards. One of the most widely used open-source software platforms, GitHub, attracts millions of developers who use it to store their projects. This study aims to analyze code quality on GitHub from the standpoint of code reviews. We examined the code review process using GitHub's Issues Tracker, which allows team members to evaluate, discuss, and share their opinions on the proposed code before it is approved. Based on our analysis, we present a novel approach for improving the code review process by promoting regularity and community involvement. ",
    "url": "https://arxiv.org/abs/2210.04434",
    "authors": [
      "Abduljaleel Al-Rubaye",
      "Gita Sukthankar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.04442",
    "title": "Towards Training Graph Neural Networks with Node-Level Differential  Privacy",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in mining graph-structured data. Despite the superior performance of GNNs in learning graph representations, serious privacy concerns have been raised for the trained models which could expose the sensitive information of graphs. We conduct the first formal study of training GNN models to ensure utility while satisfying the rigorous node-level differential privacy considering the private information of both node features and edges. We adopt the training framework utilizing personalized PageRank to decouple the message-passing process from feature aggregation during training GNN models and propose differentially private PageRank algorithms to protect graph topology information formally. Furthermore, we analyze the privacy degradation caused by the sampling process dependent on the differentially private PageRank results during model training and propose a differentially private GNN (DPGNN) algorithm to further protect node features and achieve rigorous node-level differential privacy. Extensive experiments on real-world graph datasets demonstrate the effectiveness of the proposed algorithms for providing node-level differential privacy while preserving good model utility. ",
    "url": "https://arxiv.org/abs/2210.04442",
    "authors": [
      "Qiuchen Zhang",
      "Jing Ma",
      "Jian Lou",
      "Carl Yang",
      "Li Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04447",
    "title": "CrowdChecked: Detecting Previously Fact-Checked Claims in Social Media",
    "abstract": "While there has been substantial progress in developing systems to automate fact-checking, they still lack credibility in the eyes of the users. Thus, an interesting approach has emerged: to perform automatic fact-checking by verifying whether an input claim has been previously fact-checked by professional fact-checkers and to return back an article that explains their decision. This is a sensible approach as people trust manual fact-checking, and as many claims are repeated multiple times. Yet, a major issue when building such systems is the small number of known tweet--verifying article pairs available for training. Here, we aim to bridge this gap by making use of crowd fact-checking, i.e., mining claims in social media for which users have responded with a link to a fact-checking article. In particular, we mine a large-scale collection of 330,000 tweets paired with a corresponding fact-checking article. We further propose an end-to-end framework to learn from this noisy data based on modified self-adaptive training, in a distant supervision scenario. Our experiments on the CLEF'21 CheckThat! test set show improvements over the state of the art by two points absolute. Our code and datasets are available at https://github.com/mhardalov/crowdchecked-claims ",
    "url": "https://arxiv.org/abs/2210.04447",
    "authors": [
      "Momchil Hardalov",
      "Anton Chernyavskiy",
      "Ivan Koychev",
      "Dmitry Ilvovsky",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.04485",
    "title": "A Memory Transformer Network for Incremental Learning",
    "abstract": "We study class-incremental learning, a training setup in which new classes of data are observed over time for the model to learn from. Despite the straightforward problem formulation, the naive application of classification models to class-incremental learning results in the \"catastrophic forgetting\" of previously seen classes. One of the most successful existing methods has been the use of a memory of exemplars, which overcomes the issue of catastrophic forgetting by saving a subset of past data into a memory bank and utilizing it to prevent forgetting when training future tasks. In our paper, we propose to enhance the utilization of this memory bank: we not only use it as a source of additional training data like existing works but also integrate it in the prediction process explicitly.Our method, the Memory Transformer Network (MTN), learns how to combine and aggregate the information from the nearest neighbors in the memory with a transformer to make more accurate predictions. We conduct extensive experiments and ablations to evaluate our approach. We show that MTN achieves state-of-the-art performance on the challenging ImageNet-1k and Google-Landmarks-1k incremental learning benchmarks. ",
    "url": "https://arxiv.org/abs/2210.04485",
    "authors": [
      "Ahmet Iscen",
      "Thomas Bird",
      "Mathilde Caron",
      "Alireza Fathi",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04490",
    "title": "Semantic Framework based Query Generation for Temporal Question  Answering over Knowledge Graphs",
    "abstract": "Answering factual questions with temporal intent over knowledge graphs (temporal KGQA) attracts rising attention in recent years. In the generation of temporal queries, existing KGQA methods ignore the fact that some intrinsic connections between events can make them temporally related, which may limit their capability. We systematically analyze the possible interpretation of temporal constraints and conclude the interpretation structures as the Semantic Framework of Temporal Constraints, SF-TCons. Based on the semantic framework, we propose a temporal question answering method, SF-TQA, which generates query graphs by exploring the relevant facts of mentioned entities, where the exploring process is restricted by SF-TCons. Our evaluations show that SF-TQA significantly outperforms existing methods on two benchmarks over different knowledge graphs. ",
    "url": "https://arxiv.org/abs/2210.04490",
    "authors": [
      "Weantao Ding",
      "Hao Chen",
      "Huayu Li",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04497",
    "title": "Learning Robust Representations for Continual Relation Extraction via  Adversarial Class Augmentation",
    "abstract": "Continual relation extraction (CRE) aims to continually learn new relations from a class-incremental data stream. CRE model usually suffers from catastrophic forgetting problem, i.e., the performance of old relations seriously degrades when the model learns new relations. Most previous work attributes catastrophic forgetting to the corruption of the learned representations as new relations come, with an implicit assumption that the CRE models have adequately learned the old relations. In this paper, through empirical studies we argue that this assumption may not hold, and an important reason for catastrophic forgetting is that the learned representations do not have good robustness against the appearance of analogous relations in the subsequent learning process. To address this issue, we encourage the model to learn more precise and robust representations through a simple yet effective adversarial class augmentation mechanism (ACA), which is easy to implement and model-agnostic. Experimental results show that ACA can consistently improve the performance of state-of-the-art CRE models on two popular benchmarks. ",
    "url": "https://arxiv.org/abs/2210.04497",
    "authors": [
      "Peiyi Wang",
      "Yifan Song",
      "Tianyu Liu",
      "Binghuai Lin",
      "Yunbo Cao",
      "Sujian Li",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04505",
    "title": "A Survey on Heterogeneous Federated Learning",
    "abstract": "Federated learning (FL) has been proposed to protect data privacy and virtually assemble the isolated data silos by cooperatively training models among organizations without breaching privacy and security. However, FL faces heterogeneity from various aspects, including data space, statistical, and system heterogeneity. For example, collaborative organizations without conflict of interest often come from different areas and have heterogeneous data from different feature spaces. Participants may also want to train heterogeneous personalized local models due to non-IID and imbalanced data distribution and various resource-constrained devices. Therefore, heterogeneous FL is proposed to address the problem of heterogeneity in FL. In this survey, we comprehensively investigate the domain of heterogeneous FL in terms of data space, statistical, system, and model heterogeneity. We first give an overview of FL, including its definition and categorization. Then, We propose a precise taxonomy of heterogeneous FL settings for each type of heterogeneity according to the problem setting and learning objective. We also investigate the transfer learning methodologies to tackle the heterogeneity in FL. We further present the applications of heterogeneous FL. Finally, we highlight the challenges and opportunities and envision promising future research directions toward new framework design and trustworthy approaches. ",
    "url": "https://arxiv.org/abs/2210.04505",
    "authors": [
      "Dashan Gao",
      "Xin Yao",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04514",
    "title": "Self-Supervised 3D Human Pose Estimation in Static Video Via Neural  Rendering",
    "abstract": "Inferring 3D human pose from 2D images is a challenging and long-standing problem in the field of computer vision with many applications including motion capture, virtual reality, surveillance or gait analysis for sports and medicine. We present preliminary results for a method to estimate 3D pose from 2D video containing a single person and a static background without the need for any manual landmark annotations. We achieve this by formulating a simple yet effective self-supervision task: our model is required to reconstruct a random frame of a video given a frame from another timepoint and a rendered image of a transformed human shape template. Crucially for optimisation, our ray casting based rendering pipeline is fully differentiable, enabling end to end training solely based on the reconstruction task. ",
    "url": "https://arxiv.org/abs/2210.04514",
    "authors": [
      "Luca Schmidtke",
      "Benjamin Hou",
      "Athanasios Vlontzos",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.04525",
    "title": "SelfMix: Robust Learning Against Textual Label Noise with Self-Mixup  Training",
    "abstract": "The conventional success of textual classification relies on annotated data, and the new paradigm of pre-trained language models (PLMs) still requires a few labeled data for downstream tasks. However, in real-world applications, label noise inevitably exists in training data, damaging the effectiveness, robustness, and generalization of the models constructed on such data. Recently, remarkable achievements have been made to mitigate this dilemma in visual data, while only a few explore textual data. To fill this gap, we present SelfMix, a simple yet effective method, to handle label noise in text classification tasks. SelfMix uses the Gaussian Mixture Model to separate samples and leverages semi-supervised learning. Unlike previous works requiring multiple models, our method utilizes the dropout mechanism on a single model to reduce the confirmation bias in self-training and introduces a textual-level mixup training strategy. Experimental results on three text classification benchmarks with different types of text show that the performance of our proposed method outperforms these strong baselines designed for both textual and visual data under different noise ratios and noise types. Our anonymous code is available at \\url{https://github.com/noise-learning/SelfMix}. ",
    "url": "https://arxiv.org/abs/2210.04525",
    "authors": [
      "Dan Qiao",
      "Chenchen Dai",
      "Yuyang Ding",
      "Juntao Li",
      "Qiang Chen",
      "Wenliang Chen",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04532",
    "title": "Training Spiking Neural Networks with Local Tandem Learning",
    "abstract": "Spiking neural networks (SNNs) are shown to be more biologically plausible and energy efficient over their predecessors. However, there is a lack of an efficient and generalized training method for deep SNNs, especially for deployment on analog computing substrates. In this paper, we put forward a generalized learning rule, termed Local Tandem Learning (LTL). The LTL rule follows the teacher-student learning approach by mimicking the intermediate feature representations of a pre-trained ANN. By decoupling the learning of network layers and leveraging highly informative supervisor signals, we demonstrate rapid network convergence within five training epochs on the CIFAR-10 dataset while having low computational complexity. Our experimental results have also shown that the SNNs thus trained can achieve comparable accuracies to their teacher ANNs on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets. Moreover, the proposed LTL rule is hardware friendly. It can be easily implemented on-chip to perform fast parameter calibration and provide robustness against the notorious device non-ideality issues. It, therefore, opens up a myriad of opportunities for training and deployment of SNN on ultra-low-power mixed-signal neuromorphic computing chips.10 ",
    "url": "https://arxiv.org/abs/2210.04532",
    "authors": [
      "Qu Yang",
      "Jibin Wu",
      "Malu Zhang",
      "Yansong Chua",
      "Xinchao Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.04536",
    "title": "Fully discrete Heterogeneous Multiscale Method for parabolic problems  with multiple spatial and temporal scales",
    "abstract": "The aim of this work is the numerical homogenization of a parabolic problem with several time and spatial scales using the heterogeneous multiscale method. We replace the actual cell problem with an alternate one, using Dirichlet boundary and initial values instead of periodic boundary and time conditions. Further, we give a detailed a priori error analysis of the fully discretized, i.e., in space and time for both the macroscopic and the cell problem, method. Numerical experiments illustrate the theoretical convergence rates. ",
    "url": "https://arxiv.org/abs/2210.04536",
    "authors": [
      "Daniel Eckhardt",
      "Barbara Verf\u00fcrth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.04545",
    "title": "Automatic Evaluation and Analysis of Idioms in Neural Machine  Translation",
    "abstract": "A major open problem in neural machine translation (NMT) is the translation of idiomatic expressions, such as \"under the weather\". The meaning of these expressions is not composed by the meaning of their constituent words, and NMT models tend to translate them literally (i.e., word-by-word), which leads to confusing and nonsensical translations. Research on idioms in NMT is limited and obstructed by the absence of automatic methods for quantifying these errors. In this work, first, we propose a novel metric for automatically measuring the frequency of literal translation errors without human involvement. Equipped with this metric, we present controlled translation experiments with models trained in different conditions (with/without the test-set idioms) and across a wide range of (global and targeted) metrics and test sets. We explore the role of monolingual pretraining and find that it yields substantial targeted improvements, even without observing any translation examples of the test-set idioms. In our analysis, we probe the role of idiom context. We find that the randomly initialized models are more local or \"myopic\" as they are relatively unaffected by variations of the idiom context, unlike the pretrained ones. ",
    "url": "https://arxiv.org/abs/2210.04545",
    "authors": [
      "Christos Baziotis",
      "Prashant Mathur",
      "Eva Hasler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04553",
    "title": "SiNeRF: Sinusoidal Neural Radiance Fields for Joint Pose Estimation and  Scene Reconstruction",
    "abstract": "NeRFmm is the Neural Radiance Fields (NeRF) that deal with Joint Optimization tasks, i.e., reconstructing real-world scenes and registering camera parameters simultaneously. Despite NeRFmm producing precise scene synthesis and pose estimations, it still struggles to outperform the full-annotated baseline on challenging scenes. In this work, we identify that there exists a systematic sub-optimality in joint optimization and further identify multiple potential sources for it. To diminish the impacts of potential sources, we propose Sinusoidal Neural Radiance Fields (SiNeRF) that leverage sinusoidal activations for radiance mapping and a novel Mixed Region Sampling (MRS) for selecting ray batch efficiently. Quantitative and qualitative results show that compared to NeRFmm, SiNeRF achieves comprehensive significant improvements in image synthesis quality and pose estimation accuracy. Codes are available at https://github.com/yitongx/sinerf. ",
    "url": "https://arxiv.org/abs/2210.04553",
    "authors": [
      "Yitong Xia",
      "Hao Tang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04555",
    "title": "Everything is Varied: The Surprising Impact of Individual Variation on  ML Robustness in Medicine",
    "abstract": "In medical settings, Individual Variation (IV) refers to variation that is due not to population differences or errors, but rather to within-subject variation, that is the intrinsic and characteristic patterns of variation pertaining to a given instance or the measurement process. While taking into account IV has been deemed critical for proper analysis of medical data, this source of uncertainty and its impact on robustness have so far been neglected in Machine Learning (ML). To fill this gap, we look at how IV affects ML performance and generalization and how its impact can be mitigated. Specifically, we provide a methodological contribution to formalize the problem of IV in the statistical learning framework and, through an experiment based on one of the largest real-world laboratory medicine datasets for the problem of COVID-19 diagnosis, we show that: 1) common state-of-the-art ML models are severely impacted by the presence of IV in data; and 2) advanced learning strategies, based on data augmentation and data imprecisiation, and proper study designs can be effective at improving robustness to IV. Our findings demonstrate the critical relevance of correctly accounting for IV to enable safe deployment of ML in clinical settings. ",
    "url": "https://arxiv.org/abs/2210.04555",
    "authors": [
      "Andra Campagner",
      "Lorenzo Famiglini",
      "Anna Carobene",
      "Federico Cabitza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04561",
    "title": "A Comprehensive Survey of Data Augmentation in Visual Reinforcement  Learning",
    "abstract": "Visual reinforcement learning (RL), which makes decisions directly from high-dimensional visual inputs, has demonstrated significant potential in various domains. However, deploying visual RL techniques in the real world remains challenging due to their low sample efficiency and large generalization gaps. To tackle these obstacles, data augmentation (DA) has become a widely used technique in visual RL for acquiring sample-efficient and generalizable policies by diversifying the training data. This survey aims to provide a timely and essential review of DA techniques in visual RL in recognition of the thriving development in this field. In particular, we propose a unified framework for analyzing visual RL and understanding the role of DA in it. We then present a principled taxonomy of the existing augmentation techniques used in visual RL and conduct an in-depth discussion on how to better leverage augmented data in different scenarios. Moreover, we report a systematic empirical evaluation of DA-based techniques in visual RL and conclude by highlighting the directions for future research. As the first comprehensive survey of DA in visual RL, this work is expected to offer valuable guidance to this emerging field. ",
    "url": "https://arxiv.org/abs/2210.04561",
    "authors": [
      "Guozheng Ma",
      "Zhen Wang",
      "Zhecheng Yuan",
      "Xueqian Wang",
      "Bo Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04562",
    "title": "Using Detection, Tracking and Prediction in Visual SLAM to Achieve  Real-time Semantic Mapping of Dynamic Scenarios",
    "abstract": "In this paper, we propose a lightweight system, RDS-SLAM, based on ORB-SLAM2, which can accurately estimate poses and build semantic maps at object level for dynamic scenarios in real time using only one commonly used Intel Core i7 CPU. In RDS-SLAM, three major improvements, as well as major architectural modifications, are proposed to overcome the limitations of ORB-SLAM2. Firstly, it adopts a lightweight object detection neural network in key frames. Secondly, an efficient tracking and prediction mechanism is embedded into the system to remove the feature points belonging to movable objects in all incoming frames. Thirdly, a semantic octree map is built by probabilistic fusion of detection and tracking results, which enables a robot to maintain a semantic description at object level for potential interactions in dynamic scenarios. We evaluate RDS-SLAM in TUM RGB-D dataset, and experimental results show that RDS-SLAM can run with 30.3 ms per frame in dynamic scenarios using only an Intel Core i7 CPU, and achieves comparable accuracy compared with the state-of-the-art SLAM systems which heavily rely on both Intel Core i7 CPUs and powerful GPUs. ",
    "url": "https://arxiv.org/abs/2210.04562",
    "authors": [
      "Xingyu Chen",
      "Jianru Xue",
      "Jianwu Fang",
      "Yuxin Pan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04563",
    "title": "Towards Robust Visual Question Answering: Making the Most of Biased  Samples via Contrastive Learning",
    "abstract": "Models for Visual Question Answering (VQA) often rely on the spurious correlations, i.e., the language priors, that appear in the biased samples of training set, which make them brittle against the out-of-distribution (OOD) test data. Recent methods have achieved promising progress in overcoming this problem by reducing the impact of biased samples on model training. However, these models reveal a trade-off that the improvements on OOD data severely sacrifice the performance on the in-distribution (ID) data (which is dominated by the biased samples). Therefore, we propose a novel contrastive learning approach, MMBS, for building robust VQA models by Making the Most of Biased Samples. Specifically, we construct positive samples for contrastive learning by eliminating the information related to spurious correlation from the original training samples and explore several strategies to use the constructed positive samples for training. Instead of undermining the importance of biased samples in model training, our approach precisely exploits the biased samples for unbiased information that contributes to reasoning. The proposed method is compatible with various VQA backbones. We validate our contributions by achieving competitive performance on the OOD dataset VQA-CP v2 while preserving robust performance on the ID dataset VQA v2. ",
    "url": "https://arxiv.org/abs/2210.04563",
    "authors": [
      "Qingyi Si",
      "Yuanxin Liu",
      "Fandong Meng",
      "Zheng Lin",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04567",
    "title": "BoundaryFace: A mining framework with noise label self-correction for  Face Recognition",
    "abstract": "Face recognition has made tremendous progress in recent years due to the advances in loss functions and the explosive growth in training sets size. A properly designed loss is seen as key to extract discriminative features for classification. Several margin-based losses have been proposed as alternatives of softmax loss in face recognition. However, two issues remain to consider: 1) They overlook the importance of hard sample mining for discriminative learning. 2) Label noise ubiquitously exists in large-scale datasets, which can seriously damage the model's performance. In this paper, starting from the perspective of decision boundary, we propose a novel mining framework that focuses on the relationship between a sample's ground truth class center and its nearest negative class center. Specifically, a closed-set noise label self-correction module is put forward, making this framework work well on datasets containing a lot of label noise. The proposed method consistently outperforms SOTA methods in various face recognition benchmarks. Training code has been released at https://github.com/SWJTU-3DVision/BoundaryFace. ",
    "url": "https://arxiv.org/abs/2210.04567",
    "authors": [
      "Shijie Wu",
      "Xun Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04569",
    "title": "Systematic Evaluation and User Study of Privacy of Default Apps in  Apple's Mobile Ecosystem",
    "abstract": "Users need to configure default apps when they first start using their devices. The privacy configurations of the default apps do not always match what users think they have initially enabled. We first systematically evaluated the privacy configurations of default apps. We discovered serious issues with the documentation of the default apps. Based on these findings, we explored users' experiences with an interview study (N=15). Our findings from both studies show that: the instructions of setting privacy configurations of default apps are vague and lack required steps; users were unable to disable default apps from accessing their personal information; users assumed they were being tracked by some default apps; default apps may cause tensions in family relationships because of information sharing. Our results illuminate on the privacy and security implications of configuring the privacy of default apps and how users perceive and understand the mobile ecosystem. ",
    "url": "https://arxiv.org/abs/2210.04569",
    "authors": [
      "Amel Bourdoucen",
      "Janne Lindqvist"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04570",
    "title": "The Eyecandies Dataset for Unsupervised Multimodal Anomaly Detection and  Localization",
    "abstract": "We present Eyecandies, a novel synthetic dataset for unsupervised anomaly detection and localization. Photo-realistic images of procedurally generated candies are rendered in a controlled environment under multiple lightning conditions, also providing depth and normal maps in an industrial conveyor scenario. We make available anomaly-free samples for model training and validation, while anomalous instances with precise ground-truth annotations are provided only in the test set. The dataset comprises ten classes of candies, each showing different challenges, such as complex textures, self-occlusions and specularities. Furthermore, we achieve large intra-class variation by randomly drawing key parameters of a procedural rendering pipeline, which enables the creation of an arbitrary number of instances with photo-realistic appearance. Likewise, anomalies are injected into the rendering graph and pixel-wise annotations are automatically generated, overcoming human-biases and possible inconsistencies. We believe this dataset may encourage the exploration of original approaches to solve the anomaly detection task, e.g. by combining color, depth and normal maps, as they are not provided by most of the existing datasets. Indeed, in order to demonstrate how exploiting additional information may actually lead to higher detection performance, we show the results obtained by training a deep convolutional autoencoder to reconstruct different combinations of inputs. ",
    "url": "https://arxiv.org/abs/2210.04570",
    "authors": [
      "Luca Bonfiglioli",
      "Marco Toschi",
      "Davide Silvestri",
      "Nicola Fioraio",
      "Daniele De Gregorio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04574",
    "title": "ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object  Detection",
    "abstract": "Deep neural networks tend to reciprocate the bias of their training dataset. In object detection, the bias exists in the form of various imbalances such as class, background-foreground, and object size. In this paper, we denote size of an object as the number of pixels it covers in an image and size imbalance as the over-representation of certain sizes of objects in a dataset. We aim to address the problem of size imbalance in drone-based aerial image datasets. Existing methods for solving size imbalance are based on architectural changes that utilize multiple scales of images or feature maps for detecting objects of different sizes. We, on the other hand, propose a novel ARchitectUre-agnostic BAlanced Loss (ARUBA) that can be applied as a plugin on top of any object detection model. It follows a neighborhood-driven approach inspired by the ordinality of object size. We evaluate the effectiveness of our approach through comprehensive experiments on aerial datasets such as HRSC2016, DOTAv1.0, DOTAv1.5 and VisDrone and obtain consistent improvement in performance. ",
    "url": "https://arxiv.org/abs/2210.04574",
    "authors": [
      "Rebbapragada V C Sairam",
      "Monish Keswani",
      "Uttaran Sinha",
      "Nishit Shah",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04578",
    "title": "Is your noise correction noisy? PLS: Robustness to label noise with two  stage detection",
    "abstract": "Designing robust algorithms capable of training accurate neural networks on uncurated datasets from the web has been the subject of much research as it reduces the need for time consuming human labor. The focus of many previous research contributions has been on the detection of different types of label noise; however, this paper proposes to improve the correction accuracy of noisy samples once they have been detected. In many state-of-the-art contributions, a two phase approach is adopted where the noisy samples are detected before guessing a corrected pseudo-label in a semi-supervised fashion. The guessed pseudo-labels are then used in the supervised objective without ensuring that the label guess is likely to be correct. This can lead to confirmation bias, which reduces the noise robustness. Here we propose the pseudo-loss, a simple metric that we find to be strongly correlated with pseudo-label correctness on noisy samples. Using the pseudo-loss, we dynamically down weight under-confident pseudo-labels throughout training to avoid confirmation bias and improve the network accuracy. We additionally propose to use a confidence guided contrastive objective that learns robust representation on an interpolated objective between class bound (supervised) for confidently corrected samples and unsupervised representation for under-confident label corrections. Experiments demonstrate the state-of-the-art performance of our Pseudo-Loss Selection (PLS) algorithm on a variety of benchmark datasets including curated data synthetically corrupted with in-distribution and out-of-distribution noise, and two real world web noise datasets. Our experiments are fully reproducible [github coming soon] ",
    "url": "https://arxiv.org/abs/2210.04578",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Tarun Kirshna",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04590",
    "title": "The Small Solution Hypothesis for MAPF on Directed Graphs Is True",
    "abstract": "The determination of the computational complexity of multi-agent pathfinding on directed graphs has been an open problem for many years. Only recently, it has been established that the problem is NP-hard. Further, it has been proved that it is in NP, provided the short solution hypothesis for strongly connected digraphs holds. In this paper, it is shown that this hypothesis is indeed true. ",
    "url": "https://arxiv.org/abs/2210.04590",
    "authors": [
      "Bernhard Nebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.04591",
    "title": "Universal Adversarial Perturbations: Efficiency on a small image dataset",
    "abstract": "Although neural networks perform very well on the image classification task, they are still vulnerable to adversarial perturbations that can fool a neural network without visibly changing an input image. A paper has shown the existence of Universal Adversarial Perturbations which when added to any image will fool the neural network with a very high probability. In this paper we will try to reproduce the experience of the Universal Adversarial Perturbations paper, but on a smaller neural network architecture and training set, in order to be able to study the efficiency of the computed perturbation. ",
    "url": "https://arxiv.org/abs/2210.04591",
    "authors": [
      "Waris Radji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04604",
    "title": "Actor-Critic Network for O-RAN Resource Allocation: xApp Design,  Deployment, and Analysis",
    "abstract": "Open Radio Access Network (O-RAN) has introduced an emerging RAN architecture that enables openness, intelligence, and automated control. The RAN Intelligent Controller (RIC) provides the platform to design and deploy RAN controllers. xApps are the applications which will take this responsibility by leveraging machine learning (ML) algorithms and acting in near-real time. Despite the opportunities provided by this new architecture, the progress of practical artificial intelligence (AI)-based solutions for network control and automation has been slow. This is mostly because of the lack of an endto-end solution for designing, deploying, and testing AI-based xApps fully executable in real O-RAN network. In this paper we introduce an end-to-end O-RAN design and evaluation procedure and provide a detailed discussion of developing a Reinforcement Learning (RL) based xApp by using two different RL approaches and considering the latest released O-RAN architecture and interfaces. ",
    "url": "https://arxiv.org/abs/2210.04604",
    "authors": [
      "Mohammadreza Kouchaki",
      "Vuk Marojevic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.04614",
    "title": "Joint Multi-grained Popularity-aware Graph Convolution Collaborative  Filtering for Recommendation",
    "abstract": "Graph Convolution Networks (GCNs), with their efficient ability to capture high-order connectivity in graphs, have been widely applied in recommender systems. Stacking multiple neighbor aggregation is the major operation in GCNs. It implicitly captures popularity features because the number of neighbor nodes reflects the popularity of a node. However, existing GCN-based methods ignore a universal problem: users' sensitivity to item popularity is differentiated, but the neighbor aggregations in GCNs actually fix this sensitivity through Graph Laplacian Normalization, leading to suboptimal personalization. In this work, we propose to model multi-grained popularity features and jointly learn them together with high-order connectivity, to match the differentiation of user preferences exhibited in popularity features. Specifically, we develop a Joint Multi-grained Popularity-aware Graph Convolution Collaborative Filtering model, short for JMP-GCF, which uses a popularity-aware embedding generation to construct multi-grained popularity features, and uses the idea of joint learning to capture the signals within and between different granularities of popularity features that are relevant for modeling user preferences. Additionally, we propose a multistage stacked training strategy to speed up model convergence. We conduct extensive experiments on three public datasets to show the state-of-the-art performance of JMP-GCF. ",
    "url": "https://arxiv.org/abs/2210.04614",
    "authors": [
      "Kang Liu",
      "Feng Xue",
      "Xiangnan He",
      "Dan Guo",
      "Richang Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.04625",
    "title": "Robustness Certification of Visual Perception Models via Camera Motion  Smoothing",
    "abstract": "A vast literature shows that the learning-based visual perception model is sensitive to adversarial noises but few works consider the robustness of robotic perception models under widely-existing camera motion perturbations. To this end, we study the robustness of the visual perception model under camera motion perturbations to investigate the influence of camera motion on robotic perception. Specifically, we propose a motion smoothing technique for arbitrary image classification models, whose robustness under camera motion perturbations could be certified. The proposed robustness certification framework based on camera motion smoothing provides tight and scalable robustness guarantees for visual perception modules so that they are applicable to wide robotic applications. As far as we are aware, this is the first work to provide the robustness certification for the deep perception module against camera motions, which improves the trustworthiness of robotic perception. A realistic indoor robotic dataset with the dense point cloud map for the entire room, MetaRoom, is introduced for the challenging certifiable robust perception task. We conduct extensive experiments to validate the certification approach via motion smoothing against camera motion perturbations. Our framework guarantees the certified accuracy of 81.7% against camera translation perturbation along depth direction within -0.1m ` 0.1m. We also validate the effectiveness of our method on the real-world robot by conducting hardware experiment on the robotic arm with an eye-in-hand camera. The code is available on https://github.com/HanjiangHu/camera-motion-smoothing. ",
    "url": "https://arxiv.org/abs/2210.04625",
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Linyi Li",
      "Jiacheng Zhu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04631",
    "title": "A Prospective Analysis of Security Vulnerabilities within Link  Traversal-Based Query Processing (Extended Version)",
    "abstract": "The societal and economical consequences surrounding Big Data-driven platforms have increased the call for decentralized solutions. However, retrieving and querying data in more decentralized environments requires fundamentally different approaches, whose properties are not yet well understood. Link Traversal-based Query Processing (LTQP) is a technique for querying over decentralized data networks, in which a client-side query engine discovers data by traversing links between documents. Since decentralized environments are potentially unsafe due to their non-centrally controlled nature, there is a need for client-side LTQP query engines to be resistant against security threats aimed at the query engine's host machine or the query initiator's personal data. As such, we have performed an analysis of potential security vulnerabilities of LTQP. This article provides an overview of security threats in related domains, which are used as inspiration for the identification of 10 LTQP security threats. Each threat is explained, together with an example, and one or more avenues for mitigations are proposed. We conclude with several concrete recommendations for LTQP query engine developers and data publishers as a first step to mitigate some of these issues. With this work, we start filling the unknowns for enabling querying over decentralized environments. Aside from future work on security, wider research is needed to uncover missing building blocks for enabling true decentralization. ",
    "url": "https://arxiv.org/abs/2210.04631",
    "authors": [
      "Ruben Taelman",
      "Ruben Verborgh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.04633",
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models  for Programming Language Attend Code Structure",
    "abstract": "Code pre-trained models (CodePTMs) have recently demonstrated significant success in code intelligence. To interpret these models, some probing methods have been applied. However, these methods fail to consider the inherent characteristics of codes. In this paper, to address the problem, we propose a novel probing method CAT-probing to quantitatively interpret how CodePTMs attend code structure. We first denoise the input code sequences based on the token types pre-defined by the compilers to filter those tokens whose attention scores are too small. After that, we define a new metric CAT-score to measure the commonality between the token-level attention scores generated in CodePTMs and the pair-wise distances between corresponding AST nodes. The higher the CAT-score, the stronger ability of CodePTMs to capture code structure. We conduct extensive experiments to integrate CAT-probing with representative CodePTMs for different programming languages. Experimental results show the effectiveness of CAT-probing in CodePTM interpretation. Our codes and data are publicly available at https://github.com/nchen909/CodeAttention. ",
    "url": "https://arxiv.org/abs/2210.04633",
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.04637",
    "title": "Association Graph Learning for Multi-Task Classification with Category  Shifts",
    "abstract": "In this paper, we focus on multi-task classification, where related classification tasks share the same label space and are learned simultaneously. In particular, we tackle a new setting, which is more realistic than currently addressed in the literature, where categories shift from training to test data. Hence, individual tasks do not contain complete training data for the categories in the test set. To generalize to such test data, it is crucial for individual tasks to leverage knowledge from related tasks. To this end, we propose learning an association graph to transfer knowledge among tasks for missing classes. We construct the association graph with nodes representing tasks, classes and instances, and encode the relationships among the nodes in the edges to guide their mutual knowledge transfer. By message passing on the association graph, our model enhances the categorical information of each instance, making it more discriminative. To avoid spurious correlations between task and class nodes in the graph, we introduce an assignment entropy maximization that encourages each class node to balance its edge weights. This enables all tasks to fully utilize the categorical information from related tasks. An extensive evaluation on three general benchmarks and a medical dataset for skin lesion classification reveals that our method consistently performs better than representative baselines. ",
    "url": "https://arxiv.org/abs/2210.04637",
    "authors": [
      "Jiayi Shen",
      "Zehao Xiao",
      "Xiantong Zhen",
      "Cees G. M. Snoek",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04643",
    "title": "Critical Learning Periods for Multisensory Integration in Deep Networks",
    "abstract": "We show that the ability of a neural network to integrate information from diverse sources hinges critically on being exposed to properly correlated signals during the early phases of training. Interfering with the learning process during this initial stage can permanently impair the development of a skill, both in artificial and biological systems where the phenomenon is known as critical learning period. We show that critical periods arise from the complex and unstable early transient dynamics, which are decisive of final performance of the trained system and their learned representations. This evidence challenges the view, engendered by analysis of wide and shallow networks, that early learning dynamics of neural networks are simple, akin to those of a linear model. Indeed, we show that even deep linear networks exhibit critical learning periods for multi-source integration, while shallow networks do not. To better understand how the internal representations change according to disturbances or sensory deficits, we introduce a new measure of source sensitivity, which allows us to track the inhibition and integration of sources during training. Our analysis of inhibition suggests cross-source reconstruction as a natural auxiliary training objective, and indeed we show that architectures trained with cross-sensor reconstruction objectives are remarkably more resilient to critical periods. Our findings suggest that the recent success in self-supervised multi-modal training compared to previous supervised efforts may be in part due to more robust learning dynamics and not solely due to better architectures and/or more data. ",
    "url": "https://arxiv.org/abs/2210.04643",
    "authors": [
      "Michael Kleinman",
      "Alessandro Achille",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.04665",
    "title": "Towards Developing and Analysing Metric-Based Software Defect Severity  Prediction Model",
    "abstract": "In a critical software system, the testers have to spend an enormous amount of time and effort to maintain the software due to the continuous occurrence of defects. Among such defects, some severe defects may adversely affect the software. To reduce the time and effort of a tester, many machine learning models have been proposed in the literature, which use the documented defect reports to automatically predict the severity of the defective software modules. In contrast to the traditional approaches, in this work we propose a metric-based software defect severity prediction (SDSP) model that uses a self-training semi-supervised learning approach to classify the severity of the defective software modules. The approach is constructed on a mixture of unlabelled and labelled defect severity data. The self-training works on the basis of a decision tree classifier to assign the pseudo-class labels to the unlabelled instances. The predictions are promising since the self-training successfully assigns the suitable class labels to the unlabelled instances. On the other hand, numerous research studies have covered proposing prediction approaches as well as the methodological aspects of defect severity prediction models, the gap in estimating project attributes from the prediction model remains unresolved. To bridge the gap, we propose five project specific measures such as the Risk-Factor (RF), the Percent of Saved Budget (PSB), the Loss in the Saved Budget (LSB), the Remaining Service Time (RST) and Gratuitous Service Time (GST) to capture project outcomes from the predictions. Similar to the traditional measures, these measures are also calculated from the observed confusion matrix. These measures are used to analyse the impact that the prediction model has on the software project. ",
    "url": "https://arxiv.org/abs/2210.04665",
    "authors": [
      "Umamaheswara Sharma B",
      "Ravichandra Sadam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.04672",
    "title": "Exploiting map information for self-supervised learning in motion  forecasting",
    "abstract": "Inspired by recent developments regarding the application of self-supervised learning (SSL), we devise an auxiliary task for trajectory prediction that takes advantage of map-only information such as graph connectivity with the intent of improving map comprehension and generalization. We apply this auxiliary task through two frameworks - multitasking and pretraining. In either framework we observe significant improvement of our baseline in metrics such as $\\mathrm{minFDE}_6$ (as much as 20.3%) and $\\mathrm{MissRate}_6$ (as much as 33.3%), as well as a richer comprehension of map features demonstrated by different training configurations. The results obtained were consistent in all three data sets used for experiments: Argoverse, Interaction and NuScenes. We also submit our new pretrained model's results to the Interaction challenge and achieve $\\textit{1st}$ place with respect to $\\mathrm{minFDE}_6$ and $\\mathrm{minADE}_6$. ",
    "url": "https://arxiv.org/abs/2210.04672",
    "authors": [
      "Caio Azevedo",
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04686",
    "title": "Utilizing Explainable AI for improving the Performance of Neural  Networks",
    "abstract": "Nowadays, deep neural networks are widely used in a variety of fields that have a direct impact on society. Although those models typically show outstanding performance, they have been used for a long time as black boxes. To address this, Explainable Artificial Intelligence (XAI) has been developing as a field that aims to improve the transparency of the model and increase their trustworthiness. We propose a retraining pipeline that consistently improves the model predictions starting from XAI and utilizing state-of-the-art techniques. To do that, we use the XAI results, namely SHapley Additive exPlanations (SHAP) values, to give specific training weights to the data samples. This leads to an improved training of the model and, consequently, better performance. In order to benchmark our method, we evaluate it on both real-life and public datasets. First, we perform the method on a radar-based people counting scenario. Afterward, we test it on the CIFAR-10, a public Computer Vision dataset. Experiments using the SHAP-based retraining approach achieve a 4% more accuracy w.r.t. the standard equal weight retraining for people counting tasks. Moreover, on the CIFAR-10, our SHAP-based weighting strategy ends up with a 3% accuracy rate than the training procedure with equal weighted samples. ",
    "url": "https://arxiv.org/abs/2210.04686",
    "authors": [
      "Huawei Sun",
      "Lorenzo Servadei",
      "Hao Feng",
      "Michael Stephan",
      "Robert Wille",
      "Avik Santra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.04699",
    "title": "FedBA: Non-IID Federated Learning Framework in UAV Networks",
    "abstract": "With the development and progress of science and technology, the Internet of Things(IoT) has gradually entered people's lives, bringing great convenience to our lives and improving people's work efficiency. Specifically, the IoT can replace humans in jobs that they cannot perform. As a new type of IoT vehicle, the current status and trend of research on Unmanned Aerial Vehicle(UAV) is gratifying, and the development prospect is very promising. However, privacy and communication are still very serious issues in drone applications. This is because most drones still use centralized cloud-based data processing, which may lead to leakage of data collected by drones. At the same time, the large amount of data collected by drones may incur greater communication overhead when transferred to the cloud. Federated learning as a means of privacy protection can effectively solve the above two problems. However, federated learning when applied to UAV networks also needs to consider the heterogeneity of data, which is caused by regional differences in UAV regulation. In response, this paper proposes a new algorithm FedBA to optimize the global model and solves the data heterogeneity problem. In addition, we apply the algorithm to some real datasets, and the experimental results show that the algorithm outperforms other algorithms and improves the accuracy of the local model for UAVs. ",
    "url": "https://arxiv.org/abs/2210.04699",
    "authors": [
      "Pei Li",
      "Zhijun Liu",
      "Luyi Chang",
      "Jialiang Peng",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04700",
    "title": "Bio-inspired Algorithms in the Optimisation of Wireless Sensor Networks",
    "abstract": "WSN are a growing technology in industrial and personal use fields. The Quality of Service (QoS) of WSN is associated to the architecture of WSN nodes and network design. In this work, the composition of the nodes and network is analysed. The success of WSN is related to the maximisation of the lifetime and coverage of the device, allied to the minimisation of energy consumption and number of nodes, guaranteeing a good network connectivity and high transmission. The most common WSN issues are presented and reviewed. The most suitable optimisation technique is Multi-objective (MOO) which is exemplified in this work from complex multi-objective functions which include several WSN problems. The second part of this review focus on bio-inspired algorithms in WSN optimisation: Genetic Algorithms (GA), Particles Swarm Optimisation (PSO) and Ant Colony Optimisation (ACO). Other less common methods are also present and related to WSN issues. ",
    "url": "https://arxiv.org/abs/2210.04700",
    "authors": [
      "Joana Matos",
      "Carine M. Rebello",
      "Erbet A. Costa",
      "Luana P. Queiroz",
      "Maria Joao B. Regufe",
      "Idelfonso B.R. Nogueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.04733",
    "title": "A Privacy Preserving IoT Data Marketplace Using IOTA Smart Contracts",
    "abstract": "In recent years, the volume of data generated by IoT devices has increased dramatically. Using this data can improve decision-making in the public and private sectors and increase productivity. Many attempts have been made to enhance and adapt businesses to exploit this IoT data. Among these, IoT data trading is the most popular approach. To this end, ongoing projects are currently focused on developing decentralized data marketplaces for IoT using blockchain and cryptocurrencies. Here we explore how a decentralized data marketplace could be created using IOTA tangle and IOTA smart contract chains (SC chains). We also consider the advantages of such architecture in terms of cost, scalability, and privacy over current designs and introduce the various elements it should have. ",
    "url": "https://arxiv.org/abs/2210.04733",
    "authors": [
      "Hadi Farahani",
      "Hamid Reza Shahriari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04735",
    "title": "Edge Device Deployment of Multi-Tasking Network for Self-Driving  Operations",
    "abstract": "A safe and robust autonomous driving system relies on accurate perception of the environment for application-oriented scenarios. This paper proposes deployment of the three most crucial tasks (i.e., object detection, drivable area segmentation and lane detection tasks) on embedded system for self-driving operations. To achieve this research objective, multi-tasking network is utilized with a simple encoder-decoder architecture. Comprehensive and extensive comparisons for two models based on different backbone networks are performed. All training experiments are performed on server while Nvidia Jetson Xavier NX is chosen as deployment device. ",
    "url": "https://arxiv.org/abs/2210.04735",
    "authors": [
      "Shokhrukh Miraliev",
      "Shakhboz Abdigapporov",
      "Jumabek Alikhanov",
      "Vijay Kakani",
      "Hakil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04742",
    "title": "Over-the-Air Split Machine Learning in Wireless MIMO Networks",
    "abstract": "In split machine learning (ML), different partitions of a neural network (NN) are executed by different computing nodes, requiring a large amount of communication cost. To ease communication burden, over-the-air computation (OAC) can efficiently implement all or part of the computation at the same time of communication. Based on the proposed system, the system implementation over wireless network is introduced and we provide the problem formulation. In particular, we show that the inter-layer connection in a NN of any size can be mathematically decomposed into a set of linear precoding and combining transformations over MIMO channels. Therefore, the precoding matrix at the transmitter and the combining matrix at the receiver of each MIMO link, as well as the channel matrix itself, can jointly serve as a fully connected layer of the NN. The generalization of the proposed scheme to the conventional NNs is also introduced. Finally, we extend the proposed scheme to the widely used convolutional neural networks and demonstrate its effectiveness under both the static and quasi-static memory channel conditions with comprehensive simulations. In such a split ML system, the precoding and combining matrices are regarded as trainable parameters, while MIMO channel matrix is regarded as unknown (implicit) parameters. ",
    "url": "https://arxiv.org/abs/2210.04742",
    "authors": [
      "Yuzhi Yang",
      "Zhaoyang Zhang",
      "Yuqing Tian",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Caijun Zhong",
      "Kai-Kit Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04763",
    "title": "On the Forward Invariance of Neural ODEs",
    "abstract": "To ensure robust and trustworthy decision-making, it is highly desirable to enforce constraints over a neural network's parameters and its inputs automatically by back-propagating output specifications. This way, we can guarantee that the network makes reliable decisions under perturbations. Here, we propose a new method for achieving a class of specification guarantees for neural Ordinary Differentiable Equations (ODEs) by using invariance set propagation. An invariance of a neural ODE is defined as an output specification, such as to satisfy mathematical formulae, physical laws, and system safety. We use control barrier functions to specify the invariance of a neural ODE on the output layer and propagate it back to the input layer. Through the invariance backpropagation, we map output specifications onto constraints on the neural ODE parameters or its input. The satisfaction of the corresponding constraints implies the satisfaction of output specifications. This allows us to achieve output specification guarantees by changing the input or parameters while maximally preserving the model performance. We demonstrate the invariance propagation on a comprehensive series of representation learning tasks, including spiral curve regression, autoregressive modeling of joint physical dynamics, convexity portrait of a function, and safe neural control of collision avoidance for autonomous vehicles. ",
    "url": "https://arxiv.org/abs/2210.04763",
    "authors": [
      "Wei Xiao",
      "Tsun-Hsuan Wang",
      "Ramin Hasani",
      "Mathias Lechner",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.04766",
    "title": "Hierarchical Learning in Euclidean Neural Networks",
    "abstract": "Equivariant machine learning methods have shown wide success at 3D learning applications in recent years. These models explicitly build in the reflection, translation and rotation symmetries of Euclidean space and have facilitated large advances in accuracy and data efficiency for a range of applications in the physical sciences. An outstanding question for equivariant models is why they achieve such larger-than-expected advances in these applications. To probe this question, we examine the role of higher order (non-scalar) features in Euclidean Neural Networks (\\texttt{e3nn}). We focus on the previously studied application of \\texttt{e3nn} to the problem of electron density prediction, which allows for a variety of non-scalar outputs, and examine whether the nature of the output (scalar $l=0$, vector $l=1$, or higher order $l>1$) is relevant to the effectiveness of non-scalar hidden features in the network. Further, we examine the behavior of non-scalar features throughout training, finding a natural hierarchy of features by $l$, reminiscent of a multipole expansion. We aim for our work to ultimately inform design principles and choices of domain applications for {\\tt e3nn} networks. ",
    "url": "https://arxiv.org/abs/2210.04766",
    "authors": [
      "Joshua A. Rackers",
      "Pranav Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2210.04772",
    "title": "An Ontology for Defect Detection in Metal Additive Manufacturing",
    "abstract": "A key challenge for Industry 4.0 applications is to develop control systems for automated manufacturing services that are capable of addressing both data integration and semantic interoperability issues, as well as monitoring and decision making tasks. To address such an issue in advanced manufacturing systems, principled knowledge representation approaches based on formal ontologies have been proposed as a foundation to information management and maintenance in presence of heterogeneous data sources. In addition, ontologies provide reasoning and querying capabilities to aid domain experts and end users in the context of constraint validation and decision making. Finally, ontology-based approaches to advanced manufacturing services can support the explainability and interpretability of the behaviour of monitoring, control, and simulation systems that are based on black-box machine learning algorithms. In this work, we provide a novel ontology for the classification of process-induced defects known from the metal additive manufacturing literature. Together with a formal representation of the characterising features and sources of defects, we integrate our knowledge base with state-of-the-art ontologies in the field. Our knowledge base aims at enhancing the modelling capabilities of additive manufacturing ontologies by adding further defect analysis terminology and diagnostic inference features. ",
    "url": "https://arxiv.org/abs/2210.04772",
    "authors": [
      "Massimo Carraturo",
      "Andrea Mazzullo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.04782",
    "title": "Robustification of Multilingual Language Models to Real-world Noise with  Robust Contrastive Pretraining",
    "abstract": "Advances in neural modeling have achieved state-of-the-art (SOTA) results on public natural language processing (NLP) benchmarks, at times surpassing human performance. However, there is a gap between public benchmarks and real-world applications where noise such as typos or grammatical mistakes is abundant, resulting in degraded performance. Unfortunately, works that assess the robustness of neural models on noisy data and suggest improvements are limited to the English language. Upon analyzing noise in different languages, we observe that noise types vary across languages and thus require their own investigation. Thus, to benchmark the performance of pretrained multilingual models, we construct noisy datasets covering five languages and four NLP tasks. We see a gap in performance between clean and noisy data. After investigating ways to boost the zero-shot cross-lingual robustness of multilingual pretrained models, we propose Robust Contrastive Pretraining (RCP). RCP combines data augmentation with a contrastive loss term at the pretraining stage and achieves large improvements on noisy (& original test data) across two sentence-level classification (+3.2%) and two sequence-labeling (+10 F1-score) multilingual tasks. ",
    "url": "https://arxiv.org/abs/2210.04782",
    "authors": [
      "Asa Cooper Stickland",
      "Sailik Sengupta",
      "Jason Krone",
      "Saab Mansour",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04791",
    "title": "Tango or Square Dance? How Tightly Should we Integrate Network  Functionality in Browsers?",
    "abstract": "The question at which layer network functionality is presented or abstracted remains a research challenge. Traditionally, network functionality was either placed into the core network, middleboxes, or into the operating system -- but recent developments have expanded the design space to directly introduce functionality into the application (and in particular into the browser) as a way to expose it to the user. Given the context of emerging path-aware networking technology, an interesting question arises: which layer should handle the new features? We argue that the browser is becoming a powerful platform for network innovation, where even user-driven properties can be implemented in an OS-agnostic fashion. We demonstrate the feasibility of geo-fenced browsing using a prototype browser extension, realized by the SCION path-aware networking architecture, without introducing any significant performance overheads. ",
    "url": "https://arxiv.org/abs/2210.04791",
    "authors": [
      "Alex Davidson",
      "Matthias Frei",
      "Marten Gartner",
      "Hamed Haddadi",
      "Jordi Subir\u00e0 Nieto",
      "Adrian Perrig",
      "Philipp Winter",
      "Fran\u00e7ois Wirz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.04802",
    "title": "SimSCOOD: Systematic Analysis of Out-of-Distribution Behavior of Source  Code Models",
    "abstract": "While large code datasets have become available in recent years, acquiring representative training data with full coverage of general code distribution remains challenging due to the compositional nature of code and the complexity of software. This leads to the out-of-distribution (OOD) issues with unexpected model inference behaviors that have not been systematically studied yet. We contribute the first systematic approach that simulates various OOD scenarios along different dimensions of data properties and investigates the model behaviors in such scenarios. Our extensive studies on six state-of-the-art models for three code generation tasks expose several failure modes caused by the out-of-distribution issues. It thereby provides insights and sheds light for future research in terms of generalization, robustness, and inductive biases of source code models. ",
    "url": "https://arxiv.org/abs/2210.04802",
    "authors": [
      "Hossein Hajipour",
      "Ning Yu",
      "Cristian-Alexandru Staicu",
      "Mario Fritz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.04803",
    "title": "Using Whole Slide Image Representations from Self-Supervised Contrastive  Learning for Melanoma Concordance Regression",
    "abstract": "Although melanoma occurs more rarely than several other skin cancers, patients' long term survival rate is extremely low if the diagnosis is missed. Diagnosis is complicated by a high discordance rate among pathologists when distinguishing between melanoma and benign melanocytic lesions. A tool that provides potential concordance information to healthcare providers could help inform diagnostic, prognostic, and therapeutic decision-making for challenging melanoma cases. We present a melanoma concordance regression deep learning model capable of predicting the concordance rate of invasive melanoma or melanoma in-situ from digitized Whole Slide Images (WSIs). The salient features corresponding to melanoma concordance were learned in a self-supervised manner with the contrastive learning method, SimCLR. We trained a SimCLR feature extractor with 83,356 WSI tiles randomly sampled from 10,895 specimens originating from four distinct pathology labs. We trained a separate melanoma concordance regression model on 990 specimens with available concordance ground truth annotations from three pathology labs and tested the model on 211 specimens. We achieved a Root Mean Squared Error (RMSE) of 0.28 +/- 0.01 on the test set. We also investigated the performance of using the predicted concordance rate as a malignancy classifier, and achieved a precision and recall of 0.85 +/- 0.05 and 0.61 +/- 0.06, respectively, on the test set. These results are an important first step for building an artificial intelligence (AI) system capable of predicting the results of consulting a panel of experts and delivering a score based on the degree to which the experts would agree on a particular diagnosis. Such a system could be used to suggest additional testing or other action such as ordering additional stains or genetic tests. ",
    "url": "https://arxiv.org/abs/2210.04803",
    "authors": [
      "Sean Grullon",
      "Vaughn Spurrier",
      "Jiayi Zhao",
      "Corey Chivers",
      "Yang Jiang",
      "Kiran Motaparthi",
      "Michael Bonham",
      "Julianna Ianni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.04813",
    "title": "Stochastic Robustness Interval for Motion Planning with Signal Temporal  Logic",
    "abstract": "In this work, we present a novel robustness measure for continuous-time stochastic trajectories with respect to Signal Temporal Logic (STL) specifications. We show the soundness of the measure and develop a monitor for reasoning about partial trajectories. Using this monitor, we introduce an STL sampling-based motion planning algorithm for robots under uncertainty. Given a minimum robustness requirement, this algorithm finds satisfying motion plans; alternatively, the algorithm also optimizes for the measure. We prove probabilistic completeness and asymptotic optimality, and demonstrate the effectiveness of our approach on several case studies. ",
    "url": "https://arxiv.org/abs/2210.04813",
    "authors": [
      "Roland B. Ilyes",
      "Qi Heng Ho",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.04816",
    "title": "Ensemble Learning using Transformers and Convolutional Networks for  Masked Face Recognition",
    "abstract": "Wearing a face mask is one of the adjustments we had to follow to reduce the spread of the coronavirus. Having our faces covered by masks constantly has driven the need to understand and investigate how this behavior affects the recognition capability of face recognition systems. Current face recognition systems have extremely high accuracy when dealing with unconstrained general face recognition cases but do not generalize well with occluded masked faces. In this work, we propose a system for masked face recognition. The proposed system comprises two Convolutional Neural Network (CNN) models and two Transformer models. The CNN models have been fine-tuned on FaceNet pre-trained model. We ensemble the predictions of the four models using the majority voting technique to identify the person with the mask. The proposed system has been evaluated on a synthetically masked LFW dataset created in this work. The best accuracy is obtained using the ensembled models with an accuracy of 92%. This recognition rate outperformed the accuracy of other models and it shows the correctness and robustness of the proposed model for recognizing masked faces. The code and data are available at https://github.com/Hamzah-Luqman/MFR ",
    "url": "https://arxiv.org/abs/2210.04816",
    "authors": [
      "Mohammed R. Al-Sinan",
      "Aseel F. Haneef",
      "Hamzah Luqman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04817",
    "title": "Do you pay for Privacy in Online learning?",
    "abstract": "Online learning, in the mistake bound model, is one of the most fundamental concepts in learning theory. Differential privacy, instead, is the most widely used statistical concept of privacy in the machine learning community. It is thus clear that defining learning problems that are online differentially privately learnable is of great interest. In this paper, we pose the question on if the two problems are equivalent from a learning perspective, i.e., is privacy for free in the online learning framework? ",
    "url": "https://arxiv.org/abs/2210.04817",
    "authors": [
      "Amartya Sanyal",
      "Giorgia Ramponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04820",
    "title": "Long N-step Surrogate Stage Reward to Reduce Variances of Deep  Reinforcement Learning in Complex Problems",
    "abstract": "High variances in reinforcement learning have shown impeding successful convergence and hurting task performance. As reward signal plays an important role in learning behavior, multi-step methods have been considered to mitigate the problem, and are believed to be more effective than single step methods. However, there is a lack of comprehensive and systematic study on this important aspect to demonstrate the effectiveness of multi-step methods in solving highly complex continuous control problems. In this study, we introduce a new long $N$-step surrogate stage (LNSS) reward approach to effectively account for complex environment dynamics while previous methods are usually feasible for limited number of steps. The LNSS method is simple, low computational cost, and applicable to value based or policy gradient reinforcement learning. We systematically evaluate LNSS in OpenAI Gym and DeepMind Control Suite to address some complex benchmark environments that have been challenging to obtain good results by DRL in general. We demonstrate performance improvement in terms of total reward, convergence speed, and coefficient of variation (CV) by LNSS. We also provide analytical insights on how LNSS exponentially reduces the upper bound on the variances of Q value from a respective single step method ",
    "url": "https://arxiv.org/abs/2210.04820",
    "authors": [
      "Junmin Zhong",
      "Ruofan Wu",
      "Jennie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04828",
    "title": "Assessing Neural Referential Form Selectors on a Realistic Multilingual  Dataset",
    "abstract": "Previous work on Neural Referring Expression Generation (REG) all uses WebNLG, an English dataset that has been shown to reflect a very limited range of referring expression (RE) use. To tackle this issue, we build a dataset based on the OntoNotes corpus that contains a broader range of RE use in both English and Chinese (a language that uses zero pronouns). We build neural Referential Form Selection (RFS) models accordingly, assess them on the dataset and conduct probing experiments. The experiments suggest that, compared to WebNLG, OntoNotes is better for assessing REG/RFS models. We compare English and Chinese RFS and confirm that, in line with linguistic theories, Chinese RFS depends more on discourse context than English. ",
    "url": "https://arxiv.org/abs/2210.04828",
    "authors": [
      "Guanyi Chen",
      "Fahime Same",
      "Kees van Deemter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04845",
    "title": "FS-DETR: Few-Shot DEtection TRansformer with prompting and without  re-training",
    "abstract": "This paper is on Few-Shot Object Detection (FSOD), where given a few templates (examples) depicting a novel class (not seen during training), the goal is to detect all of its occurrences within a set of images. From a practical perspective, an FSOD system must fulfil the following desiderata: (a) it must be used as is, without requiring any fine-tuning at test time, (b) it must be able to process an arbitrary number of novel objects concurrently while supporting an arbitrary number of examples from each class and (c) it must achieve accuracy comparable to a closed system. While there are (relatively) few systems that support (a), to our knowledge, there is no system supporting (b) and (c). In this work, we make the following contributions: We introduce, for the first time, a simple, yet powerful, few-shot detection transformer (FS-DETR) that can address both desiderata (a) and (b). Our system builds upon the DETR framework, extending it based on two key ideas: (1) feed the provided visual templates of the novel classes as visual prompts during test time, and (2) ``stamp'' these prompts with pseudo-class embeddings, which are then predicted at the output of the decoder. Importantly, we show that our system is not only more flexible than existing methods, but also, making a step towards satisfying desideratum (c), it is more accurate, matching and outperforming the current state-of-the-art on the most well-established benchmarks (PASCAL VOC & MSCOCO) for FSOD. Code will be made available. ",
    "url": "https://arxiv.org/abs/2210.04845",
    "authors": [
      "Adrian Bulat",
      "Ricardo Guerrero",
      "Brais Martinez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04852",
    "title": "Learning Real-world Autonomous Navigation by Self-Supervised Environment  Synthesis",
    "abstract": "Machine learning approaches have recently enabled autonomous navigation for mobile robots in a data-driven manner. Since most existing learning-based navigation systems are trained with data generated in artificially created training environments, during real-world deployment at scale, it is inevitable that robots will encounter unseen scenarios, which are out of the training distribution and therefore lead to poor real-world performance. On the other hand, directly training in the real world is generally unsafe and inefficient. To address this issue, we introduce Self-supervised Environment Synthesis (SES), in which, after real-world deployment with safety and efficiency requirements, autonomous mobile robots can utilize experience from the real-world deployment, reconstruct navigation scenarios, and synthesize representative training environments in simulation. Training in these synthesized environments leads to improved future performance in the real world. The effectiveness of SES at synthesizing representative simulation environments and improving real-world navigation performance is evaluated via a large-scale deployment in a high-fidelity, realistic simulator and a small-scale deployment on a physical robot. ",
    "url": "https://arxiv.org/abs/2210.04852",
    "authors": [
      "Zifan Xu",
      "Anirudh Nair",
      "Xuesu Xiao",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.04868",
    "title": "Deep object detection for waterbird monitoring using aerial imagery",
    "abstract": "Monitoring of colonial waterbird nesting islands is essential to tracking waterbird population trends, which are used for evaluating ecosystem health and informing conservation management decisions. Recently, unmanned aerial vehicles, or drones, have emerged as a viable technology to precisely monitor waterbird colonies. However, manually counting waterbirds from hundreds, or potentially thousands, of aerial images is both difficult and time-consuming. In this work, we present a deep learning pipeline that can be used to precisely detect, count, and monitor waterbirds using aerial imagery collected by a commercial drone. By utilizing convolutional neural network-based object detectors, we show that we can detect 16 classes of waterbird species that are commonly found in colonial nesting islands along the Texas coast. Our experiments using Faster R-CNN and RetinaNet object detectors give mean interpolated average precision scores of 67.9% and 63.1% respectively. ",
    "url": "https://arxiv.org/abs/2210.04868",
    "authors": [
      "Krish Kabra",
      "Alexander Xiong",
      "Wenbin Li",
      "Minxuan Luo",
      "William Lu",
      "Raul Garcia",
      "Dhananjay Vijay",
      "Jiahui Yu",
      "Maojie Tang",
      "Tianjiao Yu",
      "Hank Arnold",
      "Anna Vallery",
      "Richard Gibbons",
      "Arko Barman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04870",
    "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge  Graph Link Prediction",
    "abstract": "Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel schema-augmented multi-level contrastive learning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2210.04870",
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Qianqian Xie",
      "Wenjie Xu",
      "Hua Wang",
      "Min Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04886",
    "title": "Revisiting adapters with adversarial training",
    "abstract": "While adversarial training is generally used as a defense mechanism, recent works show that it can also act as a regularizer. By co-training a neural network on clean and adversarial inputs, it is possible to improve classification accuracy on the clean, non-adversarial inputs. We demonstrate that, contrary to previous findings, it is not necessary to separate batch statistics when co-training on clean and adversarial inputs, and that it is sufficient to use adapters with few domain-specific parameters for each type of input. We establish that using the classification token of a Vision Transformer (ViT) as an adapter is enough to match the classification performance of dual normalization layers, while using significantly less additional parameters. First, we improve upon the top-1 accuracy of a non-adversarially trained ViT-B16 model by +1.12% on ImageNet (reaching 83.76% top-1 accuracy). Second, and more importantly, we show that training with adapters enables model soups through linear combinations of the clean and adversarial tokens. These model soups, which we call adversarial model soups, allow us to trade-off between clean and robust accuracy without sacrificing efficiency. Finally, we show that we can easily adapt the resulting models in the face of distribution shifts. Our ViT-B16 obtains top-1 accuracies on ImageNet variants that are on average +4.00% better than those obtained with Masked Autoencoders. ",
    "url": "https://arxiv.org/abs/2210.04886",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Francesco Croce",
      "Sven Gowal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": "Accurate segmentation of mandibular canals in lower jaws is important in dental implantology, in which the implant position and dimensions are currently determined manually from 3D CT images by medical experts to avoid damaging the mandibular nerve inside the canal. In this paper, we propose a novel dual-stage deep learning based scheme for automatic detection of mandibular canal. Particularly, we first we enhance the CBCT scans by employing the novel histogram-based dynamic windowing scheme which improves the visibility of mandibular canals. After enhancement, we design 3D deeply supervised attention U-Net architecture for localize the volume of interest (VOI) which contains the mandibular canals (i.e., left and right canals). Finally, we employed the multi-scale input residual U-Net architecture (MS-R-UNet) to accurately segment the mandibular canals. The proposed method has been rigorously evaluated on 500 scans and results demonstrate that our technique out performs the existing state-of-the-art methods in term of segmentation performance as well as robustness. ",
    "url": "https://arxiv.org/abs/2210.03739",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03743",
    "title": "Single Image Super-Resolution Based on Capsule Neural Networks",
    "abstract": "Single image super-resolution (SISR) is the process of obtaining one high-resolution version of a low-resolution image by increasing the number of pixels per unit area. This method has been actively investigated by the research community, due to the wide variety of real-world problems where it can be applied, from aerial and satellite imaging to compressed image and video enhancement. Despite the improvements achieved by deep learning in the field, the vast majority of the used networks are based on traditional convolutions, with the solutions focusing on going deeper and/or wider, and innovations coming from jointly employing successful concepts from other fields. In this work, we decided to step up from the traditional convolutions and adopt the concept of capsules. Since their overwhelming results both in image classification and segmentation problems, we question how suitable they are for SISR. We also verify that different solutions share most of their configurations, and argue that this trend leads to fewer explorations of network varieties. During our experiments, we check various strategies to improve results, ranging from new and different loss functions to changes in the capsule layers. Our network achieved good results with fewer convolutional-based layers, showing that capsules might be a concept worth applying in the image super-resolution problem. ",
    "url": "https://arxiv.org/abs/2210.03743",
    "authors": [
      "George Corr\u00eaa de Ara\u00fajo",
      "Helio Pedrini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03745",
    "title": "ProGReST: Prototypical Graph Regression Soft Trees for Molecular  Property Prediction",
    "abstract": "In this work, we propose the novel Prototypical Graph Regression Self-explainable Trees (ProGReST) model, which combines prototype learning, soft decision trees, and Graph Neural Networks. In contrast to other works, our model can be used to address various challenging tasks, including compound property prediction. In ProGReST, the rationale is obtained along with prediction due to the model's built-in interpretability. Additionally, we introduce a new graph prototype projection to accelerate model training. Finally, we evaluate PRoGReST on a wide range of chemical datasets for molecular property prediction and perform in-depth analysis with chemical experts to evaluate obtained interpretations. Our method achieves competitive results against state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.03745",
    "authors": [
      "Dawid Rymarczyk",
      "Daniel Dobrowolski",
      "Tomasz Danel"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03762",
    "title": "Trustworthiness of Laser-Induced Breakdown Spectroscopy Predictions via  Simulation-based Synthetic Data Augmentation and Multitask Learning",
    "abstract": "We consider quantitative analyses of spectral data using laser-induced breakdown spectroscopy. We address the small size of training data available, and the validation of the predictions during inference on unknown data. For the purpose, we build robust calibration models using deep convolutional multitask learning architectures to predict the concentration of the analyte, alongside additional spectral information as auxiliary outputs. These secondary predictions can be used to validate the trustworthiness of the model by taking advantage of the mutual dependencies of the parameters of the multitask neural networks. Due to the experimental lack of training samples, we introduce a simulation-based data augmentation process to synthesise an arbitrary number of spectra, statistically representative of the experimental data. Given the nature of the deep learning model, no dimensionality reduction or data selection processes are required. The procedure is an end-to-end pipeline including the process of synthetic data augmentation, the construction of a suitable robust, homoscedastic, deep learning model, and the validation of its predictions. In the article, we compare the performance of the multitask model with traditional univariate and multivariate analyses, to highlight the separate contributions of each element introduced in the process. ",
    "url": "https://arxiv.org/abs/2210.03762",
    "authors": [
      "Riccardo Finotello",
      "Daniel L'Hermite",
      "Celine Qu\u00e9r\u00e9",
      "Benjamin Rouge",
      "Mohamed Tamaazousti",
      "Jean-Baptiste Sirven"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03779",
    "title": "MRI-based classification of IDH mutation and 1p/19q codeletion status of  gliomas using a 2.5D hybrid multi-task convolutional neural network",
    "abstract": "Isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion status are important prognostic markers for glioma. Currently, they are determined using invasive procedures. Our goal was to develop artificial intelligence-based methods to non-invasively determine these molecular alterations from MRI. For this purpose, pre-operative MRI scans of 2648 patients with gliomas (grade II-IV) were collected from Washington University School of Medicine (WUSM; n = 835) and publicly available datasets viz. Brain Tumor Segmentation (BraTS; n = 378), LGG 1p/19q (n = 159), Ivy Glioblastoma Atlas Project (Ivy GAP; n = 41), The Cancer Genome Atlas (TCGA; n = 461), and the Erasmus Glioma Database (EGD; n = 774). A 2.5D hybrid convolutional neural network was proposed to simultaneously localize the tumor and classify its molecular status by leveraging imaging features from MR scans and prior knowledge features from clinical records and tumor location. The models were tested on one internal (TCGA) and two external (WUSM and EGD) test sets. For IDH, the best-performing model achieved areas under the receiver operating characteristic (AUROC) of 0.925, 0.874, 0.933 and areas under the precision-recall curves (AUPRC) of 0.899, 0.702, 0.853 on the internal, WUSM, and EGD test sets, respectively. For 1p/19q, the best model achieved AUROCs of 0.782, 0.754, 0.842, and AUPRCs of 0.588, 0.713, 0.782, on those three data-splits, respectively. The high accuracy of the model on unseen data showcases its generalization capabilities and suggests its potential to perform a 'virtual biopsy' for tailoring treatment planning and overall clinical management of gliomas. ",
    "url": "https://arxiv.org/abs/2210.03779",
    "authors": [
      "Satrajit Chakrabarty",
      "Pamela LaMontagne",
      "Joshua Shimony",
      "Daniel S. Marcus",
      "Aristeidis Sotiras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2210.03837",
    "title": "Self-Supervised Deep Equilibrium Models for Inverse Problems with  Theoretical Guarantees",
    "abstract": "Deep equilibrium models (DEQ) have emerged as a powerful alternative to deep unfolding (DU) for image reconstruction. DEQ models-implicit neural networks with effectively infinite number of layers-were shown to achieve state-of-the-art image reconstruction without the memory complexity associated with DU. While the performance of DEQ has been widely investigated, the existing work has primarily focused on the settings where groundtruth data is available for training. We present self-supervised deep equilibrium model (SelfDEQ) as the first self-supervised reconstruction framework for training model-based implicit networks from undersampled and noisy MRI measurements. Our theoretical results show that SelfDEQ can compensate for unbalanced sampling across multiple acquisitions and match the performance of fully supervised DEQ. Our numerical results on in-vivo MRI data show that SelfDEQ leads to state-of-the-art performance using only undersampled and noisy training data. ",
    "url": "https://arxiv.org/abs/2210.03837",
    "authors": [
      "Weijie Gan",
      "Chunwei Ying",
      "Parna Eshraghi",
      "Tongyao Wang",
      "Cihat Eldeniz",
      "Yuyang Hu",
      "Jiaming Liu",
      "Yasheng Chen",
      "Hongyu An",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03882",
    "title": "Investigation of Applying Quantum Neural Network of Early-Stage Breast  Cancer Detection",
    "abstract": "Due to the heavy burden on medical institutes and computer-aided image diagnostics (CAD) have been gaining importance in diagnostic medicine to aid the medical staff to attain better service for the patients. Breast cancer is a fatal disease that can be treated successfully if it is detected early. Quantum neural network (QNN) has been introduced by many researchers around the world and presented recently by research corporations such as Microsoft, Google, and IBM. In this paper, we are trying to answer the question of: whether can the QNN be an effective method for mass-scale early breast cancer detection. This paper is dedicated to drawing a baseline for examining QNN, and the results showed a promising opportunity to use it for mass-scale screening using a fully functional quantum computer. ",
    "url": "https://arxiv.org/abs/2210.03882",
    "authors": [
      "Musaddiq Al Ali",
      "Amjad Y. Sahib",
      "Muazez Al Ali"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Information Theory (cs.IT)",
      "Quantum Algebra (math.QA)"
    ]
  },
  {
    "id": "arXiv:2210.03888",
    "title": "Accelerated and Deep Expectation Maximization for One-Bit MIMO-OFDM  Detection",
    "abstract": "In this paper we study the expectation maximization (EM) technique for one-bit MIMO-OFDM detection (OMOD). Arising from the recent interest in massive MIMO with one-bit analog-to-digital converters, OMOD is a massive-scale problem. EM is an iterative method that can exploit the OFDM structure to process the problem in a per-iteration efficient fashion. In this study we analyze the convergence rate of EM for a class of approximate maximum-likelihood OMOD formulations, or, in a broader sense, a class of problems involving regression from quantized data. We show how the SNR and channel conditions can have an impact on the convergence rate. We do so by making a connection between the EM and the proximal gradient methods in the context of OMOD. This connection also gives us insight to build new accelerated and/or inexact EM schemes. The accelerated scheme has faster convergence in theory, and the inexact scheme provides us with the flexibility to implement EM more efficiently, with convergence guarantee. Furthermore we develop a deep EM algorithm, wherein we take the structure of our inexact EM algorithm and apply deep unfolding to train an efficient structured deep net. Simulation results show that our accelerated exact/inexact EM algorithms run much faster than their standard EM counterparts, and that the deep EM algorithm gives promising detection and runtime performances. ",
    "url": "https://arxiv.org/abs/2210.03888",
    "authors": [
      "Mingjie Shao",
      "Wing-Kin Ma",
      "Junbin Liu",
      "Zihao Huang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.03911",
    "title": "Signal Detection in MIMO Systems with Hardware Imperfections: Message  Passing on Neural Networks",
    "abstract": "In this paper, we investigate signal detection in multiple-input-multiple-output (MIMO) communication systems with hardware impairments, such as power amplifier nonlinearity and in-phase/quadrature imbalance. To deal with the complex combined effects of hardware imperfections, neural network (NN) techniques, in particular deep neural networks (DNNs), have been studied to directly compensate for the impact of hardware impairments. However, it is difficult to train a DNN with limited pilot signals, hindering its practical applications. In this work, we investigate how to achieve efficient Bayesian signal detection in MIMO systems with hardware imperfections. Characterizing combined hardware imperfections often leads to complicated signal models, making Bayesian signal detection challenging. To address this issue, we first train an NN to \"model\" the MIMO system with hardware imperfections and then perform Bayesian inference based on the trained NN. Modelling the MIMO system with NN enables the design of NN architectures based on the signal flow of the MIMO system, minimizing the number of NN layers and parameters, which is crucial to achieving efficient training with limited pilot signals. We then represent the trained NN with a factor graph, and design an efficient message passing based Bayesian signal detector, leveraging the unitary approximate message passing (UAMP) algorithm. The implementation of a turbo receiver with the proposed Bayesian detector is also investigated. Extensive simulation results demonstrate that the proposed technique delivers remarkably better performance than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.03911",
    "authors": [
      "Dawei Gao",
      "Qinghua Guo",
      "Guisheng Liao",
      "Yonina C. Eldar",
      "Yonghui Li",
      "Yanguang Yu",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04011",
    "title": "Compartmental limit of discrete Bass models on networks",
    "abstract": "We introduce a new method for proving the convergence and the rate of convergence of discrete Bass models on various networks to their respective compartmental Bass models, as the population size $M$ becomes infinite. In this method, the full set of master equations is reduced to a smaller system of equations, which is closed and exact. The reduced finite system is embedded into an infinite system, and the convergence of that system to the infinite limit system is proved using standard ODE estimates. Finally, an ansatz provides an exact closure of the infinite limit system, which reduces that system to the compartmental model. Using this method, we show that when the network is complete and homogeneous, the discrete Bass model converges to the original 1969 compartmental Bass model, at the rate of $1/M$. When the network is circular, however, the compartmental limit is different, and the rate of convergence is exponential in $M$. In the case of a heterogeneous network that consists of $K$ homogeneous groups, the limit is given by a heterogeneous compartmental Bass model, and the rate of convergence is $1/M$. Using this compartmental model, we show that when the heterogeneity in the external and internal influence parameters among the $K$ groups is positively monotonically related, heterogeneity slows down the diffusion. ",
    "url": "https://arxiv.org/abs/2210.04011",
    "authors": [
      "Gadi Fibich",
      "Amit Golan",
      "Steve Schochet"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.04122",
    "title": "Inferring Line-of-Sight Velocities and Doppler Widths from Stokes  Profiles of GST/NIRIS Using Stacked Deep Neural Networks",
    "abstract": "Obtaining high-quality magnetic and velocity fields through Stokes inversion is crucial in solar physics. In this paper, we present a new deep learning method, named Stacked Deep Neural Networks (SDNN), for inferring line-of-sight (LOS) velocities and Doppler widths from Stokes profiles collected by the Near InfraRed Imaging Spectropolarimeter (NIRIS) on the 1.6 m Goode Solar Telescope (GST) at the Big Bear Solar Observatory (BBSO). The training data of SDNN is prepared by a Milne-Eddington (ME) inversion code used by BBSO. We quantitatively assess SDNN, comparing its inversion results with those obtained by the ME inversion code and related machine learning (ML) algorithms such as multiple support vector regression, multilayer perceptrons and a pixel-level convolutional neural network. Major findings from our experimental study are summarized as follows. First, the SDNN-inferred LOS velocities are highly correlated to the ME-calculated ones with the Pearson product-moment correlation coefficient being close to 0.9 on average. Second, SDNN is faster, while producing smoother and cleaner LOS velocity and Doppler width maps, than the ME inversion code. Third, the maps produced by SDNN are closer to ME's maps than those from the related ML algorithms, demonstrating the better learning capability of SDNN than the ML algorithms. Finally, comparison between the inversion results of ME and SDNN based on GST/NIRIS and those from the Helioseismic and Magnetic Imager on board the Solar Dynamics Observatory in flare-prolific active region NOAA 12673 is presented. We also discuss extensions of SDNN for inferring vector magnetic fields with empirical evaluation. ",
    "url": "https://arxiv.org/abs/2210.04122",
    "authors": [
      "Haodi Jiang",
      "Qin Li",
      "Yan Xu",
      "Wynne Hsu",
      "Kwangsu Ahn",
      "Wenda Cao",
      "Jason T. L. Wang",
      "Haimin Wang"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04168",
    "title": "Galaxy Spin Classification I: Z-wise vs S-wise Spirals With Chirality  Equivariant Residual Network",
    "abstract": "The angular momentum of galaxies (galaxy spin) contains rich information about the initial condition of the Universe, yet it is challenging to efficiently measure the spin direction for the tremendous amount of galaxies that are being mapped by the ongoing and forthcoming cosmological surveys. We present a machine learning based classifier for the Z-wise vs S-wise spirals, which can help to break the degeneracy in the galaxy spin direction measurement. The proposed Chirality Equivariant Residual Network (CE-ResNet) is manifestly equivariant under a reflection of the input image, which guarantees that there is no inherent asymmetry between the Z-wise and S-wise probability estimators. We train the model with Sloan Digital Sky Survey (SDSS) images, with the training labels given by the Galaxy Zoo 1 (GZ1) project. A combination of data augmentation tricks are used during the training, making the model more robust to be applied to other surveys. We find a $\\sim\\!30\\%$ increase of both types of spirals when Dark Energy Spectroscopic Instrument (DESI) images are used for classification, due to the better imaging quality of DESI. We verify that the $\\sim\\!7\\sigma$ difference between the numbers of Z-wise and S-wise spirals is due to human bias, since the discrepancy drops to $<\\!1.8\\sigma$ with our CE-ResNet classification results. We discuss the potential systematics that are relevant to the future cosmological applications. ",
    "url": "https://arxiv.org/abs/2210.04168",
    "authors": [
      "He Jia",
      "Hong-Ming Zhu",
      "Ue-Li Pen"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04172",
    "title": "A Transformer-based deep neural network model for SSVEP classification",
    "abstract": "Steady-state visual evoked potential (SSVEP) is one of the most commonly used control signal in the brain-computer interface (BCI) systems. However, the conventional spatial filtering methods for SSVEP classification highly depend on the subject-specific calibration data. The need for the methods that can alleviate the demand for the calibration data become urgent. In recent years, developing the methods that can work in inter-subject classification scenario has become a promising new direction. As the popular deep learning model nowadays, Transformer has excellent performance and has been used in EEG signal classification tasks. Therefore, in this study, we propose a deep learning model for SSVEP classification based on Transformer structure in inter-subject classification scenario, termed as SSVEPformer, which is the first application of the transformer to the classification of SSVEP. Inspired by previous studies, the model adopts the frequency spectrum of SSVEP data as input, and explores the spectral and spatial domain information for classification. Furthermore, to fully utilize the harmonic information, an extended SSVEPformer based on the filter bank technology (FB-SSVEPformer) is proposed to further improve the classification performance. Experiments were conducted using two open datasets (Dataset 1: 10 subjects, 12-class task; Dataset 2: 35 subjects, 40-class task) in the inter-subject classification scenario. The experimental results show that the proposed models could achieve better results in terms of classification accuracy and information transfer rate, compared with other baseline methods. The proposed model validates the feasibility of deep learning models based on Transformer structure for SSVEP classification task, and could serve as a potential model to alleviate the calibration procedure in the practical application of SSVEP-based BCI systems. ",
    "url": "https://arxiv.org/abs/2210.04172",
    "authors": [
      "Jianbo Chen",
      "Yangsong Zhang",
      "Yudong Pan",
      "Peng Xu",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04188",
    "title": "Invertible Rescaling Network and Its Extensions",
    "abstract": "Image rescaling is a commonly used bidirectional operation, which first downscales high-resolution images to fit various display screens or to be storage- and bandwidth-friendly, and afterward upscales the corresponding low-resolution images to recover the original resolution or the details in the zoom-in images. However, the non-injective downscaling mapping discards high-frequency contents, leading to the ill-posed problem for the inverse restoration task. This can be abstracted as a general image degradation-restoration problem with information loss. In this work, we propose a novel invertible framework to handle this general problem, which models the bidirectional degradation and restoration from a new perspective, i.e. invertible bijective transformation. The invertibility enables the framework to model the information loss of pre-degradation in the form of distribution, which could mitigate the ill-posed problem during post-restoration. To be specific, we develop invertible models to generate valid degraded images and meanwhile transform the distribution of lost contents to the fixed distribution of a latent variable during the forward degradation. Then restoration is made tractable by applying the inverse transformation on the generated degraded image together with a randomly-drawn latent variable. We start from image rescaling and instantiate the model as Invertible Rescaling Network (IRN), which can be easily extended to the similar decolorization-colorization task. We further propose to combine the invertible framework with existing degradation methods such as image compression for wider applications. Experimental results demonstrate the significant improvement of our model over existing methods in terms of both quantitative and qualitative evaluations of upscaling and colorizing reconstruction from downscaled and decolorized images, and rate-distortion of image compression. ",
    "url": "https://arxiv.org/abs/2210.04188",
    "authors": [
      "Mingqing Xiao",
      "Shuxin Zheng",
      "Chang Liu",
      "Zhouchen Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04193",
    "title": "Quasi-Monolithic Graph Neural Network for Fluid-Structure Interaction",
    "abstract": "Using convolutional neural networks, deep learning-based reduced-order models have demonstrated great potential in accelerating the simulations of coupled fluid-structure systems for downstream optimization and control tasks. However, these networks have to operate on a uniform Cartesian grid due to the inherent restriction of convolutions, leading to difficulties in extracting fine physical details along a fluid-structure interface without excessive computational burden. In this work, we present a quasi-monolithic graph neural network framework for the reduced-order modelling of fluid-structure interaction systems. With the aid of an arbitrary Lagrangian-Eulerian formulation, the mesh and fluid states are evolved temporally with two sub-networks. The movement of the mesh is reduced to the evolution of several coefficients via proper orthogonal decomposition, and these coefficients are propagated through time via a multi-layer perceptron. A graph neural network is employed to predict the evolution of the fluid state based on the state of the whole system. The structural state is implicitly modelled by the movement of the mesh on the fluid-structure boundary; hence it makes the proposed data-driven methodology quasi-monolithic. The effectiveness of the proposed quasi-monolithic graph neural network architecture is assessed on a prototypical fluid-structure system of the flow around an elastically-mounted cylinder. We use the full-order flow snapshots and displacements as target physical data to learn and infer coupled fluid-structure dynamics. The proposed framework tracks the interface description and provides the state predictions during roll-out with acceptable accuracy. We also directly extract the lift and drag forces from the predicted fluid and mesh states, in contrast to existing convolution-based architectures. ",
    "url": "https://arxiv.org/abs/2210.04193",
    "authors": [
      "Rui Gao",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04198",
    "title": "Super-Resolution by Predicting Offsets: An Ultra-Efficient  Super-Resolution Network for Rasterized Images",
    "abstract": "Rendering high-resolution (HR) graphics brings substantial computational costs. Efficient graphics super-resolution (SR) methods may achieve HR rendering with small computing resources and have attracted extensive research interests in industry and research communities. We present a new method for real-time SR for computer graphics, namely Super-Resolution by Predicting Offsets (SRPO). Our algorithm divides the image into two parts for processing, i.e., sharp edges and flatter areas. For edges, different from the previous SR methods that take the anti-aliased images as inputs, our proposed SRPO takes advantage of the characteristics of rasterized images to conduct SR on the rasterized images. To complement the residual between HR and low-resolution (LR) rasterized images, we train an ultra-efficient network to predict the offset maps to move the appropriate surrounding pixels to the new positions. For flat areas, we found simple interpolation methods can already generate reasonable output. We finally use a guided fusion operation to integrate the sharp edges generated by the network and flat areas by the interpolation method to get the final SR image. The proposed network only contains 8,434 parameters and can be accelerated by network quantization. Extensive experiments show that the proposed SRPO can achieve superior visual effects at a smaller computational cost than the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.04198",
    "authors": [
      "Jinjin Gu",
      "Haoming Cai",
      "Chenyu Dong",
      "Ruofan Zhang",
      "Yulun Zhang",
      "Wenming Yang",
      "Chun Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04222",
    "title": "Correlative Information Maximization Based Biologically Plausible Neural  Networks for Correlated Source Separation",
    "abstract": "The brain effortlessly extracts latent causes of stimuli, but how it does this at the network level remains unknown. Most prior attempts at this problem proposed neural networks that implement independent component analysis which works under the limitation that latent causes are mutually independent. Here, we relax this limitation and propose a biologically plausible neural network that extracts correlated latent sources by exploiting information about their domains. To derive this network, we choose maximum correlative information transfer from inputs to outputs as the separation objective under the constraint that the outputs are restricted to their presumed sets. The online formulation of this optimization problem naturally leads to neural networks with local learning rules. Our framework incorporates infinitely many source domain choices and flexibly models complex latent structures. Choices of simplex or polytopic source domains result in networks with piecewise-linear activation functions. We provide numerical examples to demonstrate the superior correlated source separation capability for both synthetic and natural sources. ",
    "url": "https://arxiv.org/abs/2210.04222",
    "authors": [
      "Bariscan Bozkurt",
      "Ates Isfendiyaroglu",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04248",
    "title": "Residual Neural Networks for the Prediction of Planetary Collision  Outcomes",
    "abstract": "Fast and accurate treatment of collisions in the context of modern N-body planet formation simulations remains a challenging task due to inherently complex collision processes. We aim to tackle this problem with machine learning (ML), in particular via residual neural networks. Our model is motivated by the underlying physical processes of the data-generating process and allows for flexible prediction of post-collision states. We demonstrate that our model outperforms commonly used collision handling methods such as perfect inelastic merging and feed-forward neural networks in both prediction accuracy and out-of-distribution generalization. Our model outperforms the current state of the art in 20/24 experiments. We provide a dataset that consists of 10164 Smooth Particle Hydrodynamics (SPH) simulations of pairwise planetary collisions. The dataset is specifically suited for ML research to improve computational aspects for collision treatment and for studying planetary collisions in general. We formulate the ML task as a multi-task regression problem, allowing simple, yet efficient training of ML models for collision treatment in an end-to-end manner. Our models can be easily integrated into existing N-body frameworks and can be used within our chosen parameter space of initial conditions, i.e. where similar-sized collisions during late-stage terrestrial planet formation typically occur. ",
    "url": "https://arxiv.org/abs/2210.04248",
    "authors": [
      "Philip M. Winter",
      "Christoph Burger",
      "Sebastian Lehner",
      "Johannes Kofler",
      "Thomas I. Maindl",
      "Christoph M. Sch\u00e4fer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04285",
    "title": "Improved Abdominal Multi-Organ Segmentation via 3D Boundary-Constrained  Deep Neural Networks",
    "abstract": "Quantitative assessment of the abdominal region from clinically acquired CT scans requires the simultaneous segmentation of abdominal organs. Thanks to the availability of high-performance computational resources, deep learning-based methods have resulted in state-of-the-art performance for the segmentation of 3D abdominal CT scans. However, the complex characterization of organs with fuzzy boundaries prevents the deep learning methods from accurately segmenting these anatomical organs. Specifically, the voxels on the boundary of organs are more vulnerable to misprediction due to the highly-varying intensity of inter-organ boundaries. This paper investigates the possibility of improving the abdominal image segmentation performance of the existing 3D encoder-decoder networks by leveraging organ-boundary prediction as a complementary task. To address the problem of abdominal multi-organ segmentation, we train the 3D encoder-decoder network to simultaneously segment the abdominal organs and their corresponding boundaries in CT scans via multi-task learning. The network is trained end-to-end using a loss function that combines two task-specific losses, i.e., complete organ segmentation loss and boundary prediction loss. We explore two different network topologies based on the extent of weights shared between the two tasks within a unified multi-task framework. To evaluate the utilization of complementary boundary prediction task in improving the abdominal multi-organ segmentation, we use three state-of-the-art encoder-decoder networks: 3D UNet, 3D UNet++, and 3D Attention-UNet. The effectiveness of utilizing the organs' boundary information for abdominal multi-organ segmentation is evaluated on two publically available abdominal CT datasets. A maximum relative improvement of 3.5% and 3.6% is observed in Mean Dice Score for Pancreas-CT and BTCV datasets, respectively. ",
    "url": "https://arxiv.org/abs/2210.04285",
    "authors": [
      "Samra Irshad",
      "Douglas P.S. Gomes",
      "Seong Tae Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04318",
    "title": "Prediction interval for neural network models using weighted asymmetric  loss functions",
    "abstract": "We develop a novel and simple method to produce prediction intervals (PIs) for fitting and forecasting exercises. It finds the lower and upper bound of the intervals by minimising a weighted asymmetric loss function, where the weight depends on the width of the interval. We give a short mathematical proof. As a corollary of our proof, we find PIs for values restricted to a parameterised function and argue why the method works for predicting PIs of dependent variables. The results of applying the method on a neural network deployed in a real-world forecasting task prove the validity of its practical implementation in complex machine learning setups. ",
    "url": "https://arxiv.org/abs/2210.04318",
    "authors": [
      "Milo Grillo",
      "Agnieszka Werpachowska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04334",
    "title": "QuTE: decentralized multiple testing on sensor networks with false  discovery rate control",
    "abstract": "This paper designs methods for decentralized multiple hypothesis testing on graphs that are equipped with provable guarantees on the false discovery rate (FDR). We consider the setting where distinct agents reside on the nodes of an undirected graph, and each agent possesses p-values corresponding to one or more hypotheses local to its node. Each agent must individually decide whether to reject one or more of its local hypotheses by only communicating with its neighbors, with the joint aim that the global FDR over the entire graph must be controlled at a predefined level. We propose a simple decentralized family of Query-Test-Exchange (QuTE) algorithms and prove that they can control FDR under independence or positive dependence of the p-values. Our algorithm reduces to the Benjamini-Hochberg (BH) algorithm when after graph-diameter rounds of communication, and to the Bonferroni procedure when no communication has occurred or the graph is empty. To avoid communicating real-valued p-values, we develop a quantized BH procedure, and extend it to a quantized QuTE procedure. QuTE works seamlessly in streaming data settings, where anytime-valid p-values may be continually updated at each node. Last, QuTE is robust to arbitrary dropping of packets, or a graph that changes at every step, making it particularly suitable to mobile sensor networks involving drones or other multi-agent systems. We study the power of our procedure using a simulation suite of different levels of connectivity and communication on a variety of graph structures, and also provide an illustrative real-world example. ",
    "url": "https://arxiv.org/abs/2210.04334",
    "authors": [
      "Aaditya Ramdas",
      "Jianbo Chen",
      "Martin J. Wainwright",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.04339",
    "title": "Seller-buyer networks in NFT art are driven by preferential ties",
    "abstract": "Non-Fungible Tokens (NFTs) have recently surged to mainstream attention by allowing the exchange of digital assets via blockchains. NFTs have also been adopted by artists to sell digital art. One of the promises of NFTs is broadening participation to the arts market, a traditionally closed and opaque system, to sustain a wider and more diverse set of artists and collectors. A key sign of this effect would be the disappearance or at least reduction in importance of seller-buyer preferential ties, whereby the success of an artist is strongly dependent on the patronage of a single collector. We investigate NFT art seller-buyer networks considering several galleries and a large set of nearly 40,000 sales for over 230M USD in total volume. We find that NFT art is a highly concentrated market driven by few successful sellers and even fewer systematic buyers. High concentration is present in both the number of sales and, even more strongly, in their priced volume. Furthermore, we show that, while a broader-participation market was present in the early phase of NFT art adoption, preferential ties have dominated during market growth, peak and recent decline. We consistently find that the top buyer accounts on average for over 80% of buys for a given seller. Similar trends apply to buyers and their top seller. We conclude that NFT art constitutes, at the present, a highly concentrated market driven by preferential seller-buyer ties. ",
    "url": "https://arxiv.org/abs/2210.04339",
    "authors": [
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.04371",
    "title": "A Detailed Study of Interpretability of Deep Neural Network based Top  Taggers",
    "abstract": "Recent developments in the methods of explainable AI (xAI) methods allow us to explore the inner workings of deep neural networks (DNNs), revealing crucial information about input-output relationships and realizing how data connects with machine learning models. In this paper we explore interpretability of DNN models designed for identifying jets coming from top quark decay in the high energy proton-proton collisions at the Large Hadron Collider (LHC). We review a subset of existing such top tagger models and explore different quantitative methods to identify which features play the most important roles in identifying the top jets. We also investigate how and why feature importance varies across different xAI metrics, how feature correlations impact their explainability, and how latent space representations encode information as well as correlate with physically meaningful quantities. Our studies uncover some major pitfalls of existing xAI methods and illustrate how they can be overcome to obtain consistent and meaningful interpretation of these models. We additionally illustrate the activity of hidden layers as Neural Activation Pattern (NAP) diagrams and demonstrate how they can be used to understand how DNNs relay information across the layers and how this understanding can help us to make such models significantly simpler by allowing effective model reoptimization and hyperparameter tuning. While the primary focus of this work remains a detailed study of interpretability of DNN-based top tagger models, it also features state-of-the art performance obtained from modified implementation of existing networks. ",
    "url": "https://arxiv.org/abs/2210.04371",
    "authors": [
      "Ayush Khot",
      "Mark S. Neubauer",
      "Avik Roy"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04389",
    "title": "DeepMed: Semiparametric Causal Mediation Analysis with Debiased Deep  Learning",
    "abstract": "Causal mediation analysis can unpack the black box of causality and is therefore a powerful tool for disentangling causal pathways in biomedical and social sciences, and also for evaluating machine learning fairness. To reduce bias for estimating Natural Direct and Indirect Effects in mediation analysis, we propose a new method called DeepMed that uses deep neural networks (DNNs) to cross-fit the infinite-dimensional nuisance functions in the efficient influence functions. We obtain novel theoretical results that our DeepMed method (1) can achieve semiparametric efficiency bound without imposing sparsity constraints on the DNN architecture and (2) can adapt to certain low dimensional structures of the nuisance functions, significantly advancing the existing literature on DNN-based semiparametric causal inference. Extensive synthetic experiments are conducted to support our findings and also expose the gap between theory and practice. As a proof of concept, we apply DeepMed to analyze two real datasets on machine learning fairness and reach conclusions consistent with previous findings. ",
    "url": "https://arxiv.org/abs/2210.04389",
    "authors": [
      "Siqi Xu",
      "Lin Liu",
      "Zhonghua Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.04431",
    "title": "Scientific Machine Learning for Modeling and Simulating Complex Fluids",
    "abstract": "The formulation of rheological constitutive equations -- models that relate internal stresses and deformations in complex fluids -- is a critical step in the engineering of systems involving soft materials. While data-driven models provide accessible alternatives to expensive first-principles models and less accurate empirical models in many engineering disciplines, the development of similar models for complex fluids has lagged. The diversity of techniques for characterizing non-Newtonian fluid dynamics creates a challenge for classical machine learning approaches, which require uniformly structured training data. Consequently, early machine learning constitutive equations have not been portable between different deformation protocols or mechanical observables. Here, we present a data-driven framework that resolves such issues, allowing rheologists to construct learnable models that incorporate essential physical information, while remaining agnostic to details regarding particular experimental protocols or flow kinematics. These scientific machine learning models incorporate a universal approximator within a materially objective tensorial constitutive framework. By construction, these models respect physical constraints, such as frame-invariance and tensor symmetry, required by continuum mechanics. We demonstrate that this framework facilitates the rapid discovery of accurate constitutive equations from limited data, and that the learned models may be used to describe more kinematically complex flows. This inherent flexibility admits the application of these 'digital fluid twins' to a range of material systems and engineering problems. We illustrate this flexibility by deploying a trained model within a multidimensional computational fluid dynamics simulation -- a task that is not achievable using any previously developed data-driven rheological equation of state. ",
    "url": "https://arxiv.org/abs/2210.04431",
    "authors": [
      "Kyle R. Lennon",
      "Gareth H. McKinley",
      "James W. Swan"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04621",
    "title": "Calibrating AI Models for Few-Shot Demodulation via Conformal Prediction",
    "abstract": "AI tools can be useful to address model deficits in the design of communication systems. However, conventional learning-based AI algorithms yield poorly calibrated decisions, unabling to quantify their outputs uncertainty. While Bayesian learning can enhance calibration by capturing epistemic uncertainty caused by limited data availability, formal calibration guarantees only hold under strong assumptions about the ground-truth, unknown, data generation mechanism. We propose to leverage the conformal prediction framework to obtain data-driven set predictions whose calibration properties hold irrespective of the data distribution. Specifically, we investigate the design of baseband demodulators in the presence of hard-to-model nonlinearities such as hardware imperfections, and propose set-based demodulators based on conformal prediction. Numerical results confirm the theoretical validity of the proposed demodulators, and bring insights into their average prediction set size efficiency. ",
    "url": "https://arxiv.org/abs/2210.04621",
    "authors": [
      "Kfir M. Cohen",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.04629",
    "title": "Investigation of inverse design of multilayer thin-films with  conditional invertible Neural Networks",
    "abstract": "The task of designing optical multilayer thin-films regarding a given target is currently solved using gradient-based optimization in conjunction with methods that can introduce additional thin-film layers. Recently, Deep Learning and Reinforcement Learning have been been introduced to the task of designing thin-films with great success, however a trained network is usually only able to become proficient for a single target and must be retrained if the optical targets are varied. In this work, we apply conditional Invertible Neural Networks (cINN) to inversely designing multilayer thin-films given an optical target. Since the cINN learns the energy landscape of all thin-film configurations within the training dataset, we show that cINNs can generate a stochastic ensemble of proposals for thin-film configurations that that are reasonably close to the desired target depending only on random variables. By refining the proposed configurations further by a local optimization, we show that the generated thin-films reach the target with significantly greater precision than comparable state-of-the art approaches. Furthermore, we tested the generative capabilities on samples which are outside the training data distribution and found that the cINN was able to predict thin-films for out-of-distribution targets, too. The results suggest that in order to improve the generative design of thin-films, it is instructive to use established and new machine learning methods in conjunction in order to obtain the most favorable results. ",
    "url": "https://arxiv.org/abs/2210.04629",
    "authors": [
      "Alexander Luce",
      "Ali Mahdavi",
      "Heribert Wankerl",
      "Florian Marquardt"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04649",
    "title": "Locally irregular edge-coloring of subcubic graphs",
    "abstract": "A graph is {\\em locally irregular} if no two adjacent vertices have the same degree. A {\\em locally irregular edge-coloring} of a graph $G$ is such an (improper) edge-coloring that the edges of any fixed color induce a locally irregular graph. Among the graphs admitting a locally irregular edge-coloring, i.e., {\\em decomposable graphs}, only one is known to require $4$ colors, while for all the others it is believed that $3$ colors suffice. In this paper, we prove that decomposable claw-free graphs with maximum degree $3$, all cycle permutation graphs, and all generalized Petersen graphs admit a locally irregular edge-coloring with at most $3$ colors. We also discuss when $2$ colors suffice for a locally irregular edge-coloring of cubic graphs and present an infinite family of cubic graphs of girth $4$ which require $3$ colors. ",
    "url": "https://arxiv.org/abs/2210.04649",
    "authors": [
      "Borut Lu\u017ear",
      "M\u00e1ria Macekov\u00e1",
      "Simona Rindo\u0161ov\u00e1",
      "Roman Sot\u00e1k",
      "Katar\u00edna Srokov\u00e1",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.04653",
    "title": "Rejecting noise in Baikal-GVD data with neural networks",
    "abstract": "Baikal-GVD is a large ($\\sim$ 1 km$^3$) underwater neutrino telescope installed in the fresh waters of Lake Baikal. The deep lake water environment is pervaded by background light, which produces detectable signals in the Baikal-GVD photosensors. We introduce a neural network for an efficient separation of these noise hits from the signal ones, stemming from the propagation of relativistic particles through the detector. The neural network has a U-net like architecture and employs temporal (causal) structure of events. On Monte-Carlo simulated data, it reaches 99% signal purity (precision) and 98% survival efficiency (recall). The benefits of using neural network for data analysis are discussed, and other possible architectures of neural networks, including graph based, are examined. ",
    "url": "https://arxiv.org/abs/2210.04653",
    "authors": [
      "I. Kharuk",
      "G. Rubtsov",
      "G. Safronov"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04669",
    "title": "Spanning trees of smallest maximum degree in subdivisions of graphs",
    "abstract": "\\newcommand{\\subdG}[1][G]{#1^\\star} Given a graph $G$ and a positive integer $k$, we study the question whether $G^\\star$ has a spanning tree of maximum degree at most $k$ where $G^\\star$ is the graph that is obtained from $G$ by subdividing every edge once. Using matroid intersection, we obtain a polynomial algorithm for this problem and a characterization of its positive instances. We use this characterization to show that $G^\\star$ has a spanning tree of bounded maximum degree if $G$ is contained in some particular graph class. We study the class of 3-connected graphs which are embeddable in a fixed surface and the class of $(p-1)$-connected $K_p$-minor-free graphs for a fixed integer $p$. We also give tightness examples for most of these classes. ",
    "url": "https://arxiv.org/abs/2210.04669",
    "authors": [
      "Christoph Brause",
      "Jochen Harant",
      "Florian H\u00f6rsch",
      "Samuel Mohr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.04797",
    "title": "DeepVol: Volatility Forecasting from High-Frequency Data with Dilated  Causal Convolutions",
    "abstract": "Volatility forecasts play a central role among equity risk measures. Besides traditional statistical models, modern forecasting techniques, based on machine learning, can readily be employed when treating volatility as a univariate, daily time-series. However, econometric studies have shown that increasing the number of daily observations with high-frequency intraday data helps to improve predictions. In this work, we propose DeepVol, a model based on Dilated Causal Convolutions to forecast day-ahead volatility by using high-frequency data. We show that the dilated convolutional filters are ideally suited to extract relevant information from intraday financial data, thereby naturally mimicking (via a data-driven approach) the econometric models which incorporate realised measures of volatility into the forecast. This allows us to take advantage of the abundance of intraday observations, helping us to avoid the limitations of models that use daily data, such as model misspecification or manually designed handcrafted features, whose devise involves optimising the trade-off between accuracy and computational efficiency and makes models prone to lack of adaptation into changing circumstances. In our analysis, we use two years of intraday data from NASDAQ-100 to evaluate DeepVol's performance. The reported empirical results suggest that the proposed deep learning-based approach learns global features from high-frequency data, achieving more accurate predictions than traditional methodologies, yielding to more appropriate risk measures. ",
    "url": "https://arxiv.org/abs/2210.04797",
    "authors": [
      "Fernando Moreno-Pino",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2210.04872",
    "title": "Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models",
    "abstract": "We introduce Sequential Neural Posterior Score Estimation (SNPSE) and Sequential Neural Likelihood Score Estimation (SNLSE), two new score-based methods for Bayesian inference in simulator-based models. Our methods, inspired by the success of score-based methods in generative modelling, leverage conditional score-based diffusion models to generate samples from the posterior distribution of interest. These models can be trained using one of two possible objective functions, one of which approximates the score of the intractable likelihood, while the other directly estimates the score of the posterior. We embed these models into a sequential training procedure, which guides simulations using the current approximation of the posterior at the observation of interest, thereby reducing the simulation cost. We validate our methods, as well as their amortised, non-sequential variants, on several numerical examples, demonstrating comparable or superior performance to existing state-of-the-art methods such as Sequential Neural Posterior Estimation (SNPE) and Sequential Neural Likelihood Estimation (SNLE). ",
    "url": "https://arxiv.org/abs/2210.04872",
    "authors": [
      "Louis Sharrock",
      "Jack Simons",
      "Song Liu",
      "Mark Beaumont"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1906.11443",
    "title": "Region Refinement Network for Salient Object Detection",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/1906.11443",
    "authors": [
      "Zhuotao Tian",
      "Hengshuang Zhao",
      "Michelle Shu",
      "Jiaze Wang",
      "Ruiyu Li",
      "Xiaoyong Shen",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1908.06504",
    "title": "Graphs with large total angular resolution",
    "abstract": " Comments: Some parts appeared in the Proceedings of the 27th International Symposium on Graph Drawing and Network Visualization (GD 2019) ",
    "url": "https://arxiv.org/abs/1908.06504",
    "authors": [
      "Oswin Aichholzer",
      "Matias Korman",
      "Yoshio Okamoto",
      "Irene Parada",
      "Daniel Perz",
      "Andr\u00e9 van Renssen",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:1909.08549",
    "title": "Knowledge representation and diagnostic inference using Bayesian  networks in the medical discourse",
    "abstract": " Title: Knowledge representation and diagnostic inference using Bayesian  networks in the medical discourse ",
    "url": "https://arxiv.org/abs/1909.08549",
    "authors": [
      "Sebastian Fl\u00fcgge",
      "Sandra Zimmer",
      "Uwe Petersohn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2008.04980",
    "title": "Robust Output Feedback MPC with Reduced Conservatism under Ellipsoidal  Uncertainty",
    "abstract": " Comments: Accepted at CDC 2022 ",
    "url": "https://arxiv.org/abs/2008.04980",
    "authors": [
      "Tianchen Ji",
      "Junyi Geng",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2008.06952",
    "title": "A Functional Perspective on Learning Symmetric Functions with Neural  Networks",
    "abstract": " Comments: Accepted to ICML 2021 ",
    "url": "https://arxiv.org/abs/2008.06952",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.13356",
    "title": "A Unified Mixture-View Framework for Unsupervised Representation  Learning",
    "abstract": " Comments: BMVC 2022 ",
    "url": "https://arxiv.org/abs/2011.13356",
    "authors": [
      "Xiangxiang Chu",
      "Xiaohang Zhan",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.06746",
    "title": "Periocular Embedding Learning with Consistent Knowledge Distillation  from Face",
    "abstract": " Comments: Submitted to IEEE TIP. The first two authors have contributed equally ",
    "url": "https://arxiv.org/abs/2012.06746",
    "authors": [
      "Yoon Gyo Jung",
      "Jaewoo Park",
      "Cheng Yaw Low",
      "Jacky Chen Long Chai",
      "Leslie Ching Ow Tiong",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.00654",
    "title": "DPIVE: A Regionalized Location Obfuscation Scheme with Personalized  Privacy Levels",
    "abstract": " Comments: 26 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2102.00654",
    "authors": [
      "Shun Zhang",
      "Pengfei Lan",
      "Benfei Duan",
      "Zhili Chen",
      "Hong Zhong",
      "Neal N. Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2102.03509",
    "title": "Robust normalizing flows using Bernstein-type polynomials",
    "abstract": " Title: Robust normalizing flows using Bernstein-type polynomials ",
    "url": "https://arxiv.org/abs/2102.03509",
    "authors": [
      "Sameera Ramasinghe",
      "Kasun Fernando",
      "Salman Khan",
      "Nick Barnes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.05013",
    "title": "Spherical Message Passing for 3D Molecular Graphs",
    "abstract": " Comments: The paper has been accepted by ICLR 2022. You can also cite the conference version ",
    "url": "https://arxiv.org/abs/2102.05013",
    "authors": [
      "Yi Liu",
      "Limei Wang",
      "Meng Liu",
      "Xuan Zhang",
      "Bora Oztekin",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.14029",
    "title": "Causal Inference Under Unmeasured Confounding With Negative Controls: A  Minimax Learning Approach",
    "abstract": " Title: Causal Inference Under Unmeasured Confounding With Negative Controls: A  Minimax Learning Approach ",
    "url": "https://arxiv.org/abs/2103.14029",
    "authors": [
      "Nathan Kallus",
      "Xiaojie Mao",
      "Masatoshi Uehara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2105.13508",
    "title": "Reduced Complexity Neural Network Equalizers for Two-dimensional  Magnetic Recording",
    "abstract": " Comments: This paper has been accepted for publication in IEEE Transactions on Magnetics. Part of this paper was presented in the 33rd magnetic recording conference (TMRC) 2022, on August 29, 2022 ",
    "url": "https://arxiv.org/abs/2105.13508",
    "authors": [
      "Ahmed Aboutaleb",
      "Nitin Nangare"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.02780",
    "title": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy",
    "abstract": " Title: Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy ",
    "url": "https://arxiv.org/abs/2107.02780",
    "authors": [
      "Anish Agarwal",
      "Rahul Singh"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.08574",
    "title": "A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues",
    "abstract": " Title: A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues ",
    "url": "https://arxiv.org/abs/2107.08574",
    "authors": [
      "Mohamed Abdelhack",
      "Jiaming Zhang",
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Daniel Felsky",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.04398",
    "title": "The Role of Masks in Mitigating Viral Spread on Networks",
    "abstract": " Title: The Role of Masks in Mitigating Viral Spread on Networks ",
    "url": "https://arxiv.org/abs/2110.04398",
    "authors": [
      "Yurun Tian",
      "Anirudh Sridhar",
      "Chai Wah Wu",
      "Simon A. Levin",
      "Kathleen M. Carley",
      "H.Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.03543",
    "title": "Empirical analysis of representation learning and exploration in neural  kernel bandits",
    "abstract": " Comments: Extended version. Added a major experiment comparing NK distribution w.r.t. exploration and exploitation. Submitted to ICLR 2023 ",
    "url": "https://arxiv.org/abs/2111.03543",
    "authors": [
      "Michal Lisicki",
      "Arash Afkanpour",
      "Graham W. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.07495",
    "title": "Distribution-Free Model for Community Detection",
    "abstract": " Comments: 21 pages, 9 figures, 1 table, comments are welcome ",
    "url": "https://arxiv.org/abs/2111.07495",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.11398",
    "title": "Why Do Self-Supervised Models Transfer? Investigating the Impact of  Invariance on Downstream Tasks",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2111.11398",
    "authors": [
      "Linus Ericsson",
      "Henry Gouk",
      "Timothy M. Hospedales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13420",
    "title": "Confounder Identification-free Causal Visual Feature Learning",
    "abstract": " Comments: 21 pages ",
    "url": "https://arxiv.org/abs/2111.13420",
    "authors": [
      "Xin Li",
      "Zhizheng Zhang",
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12310",
    "title": "Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art",
    "abstract": " Title: Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art ",
    "url": "https://arxiv.org/abs/2112.12310",
    "authors": [
      "Xiang Ling",
      "Lingfei Wu",
      "Jiangyu Zhang",
      "Zhenqing Qu",
      "Wei Deng",
      "Xiang Chen",
      "Yaguan Qian",
      "Chunming Wu",
      "Shouling Ji",
      "Tianyue Luo",
      "Jingzheng Wu",
      "Yanjun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.02084",
    "title": "Active Terminal Identification, Channel Estimation, and Signal Detection  for Grant-Free NOMA-OTFS in LEO Satellite Internet-of-Things",
    "abstract": " Comments: 20 pages, 9 figures, accepted by IEEE Transactions on Wireless Communications ",
    "url": "https://arxiv.org/abs/2201.02084",
    "authors": [
      "Xingyu Zhou",
      "Keke Ying",
      "Zhen Gao",
      "Yongpeng Wu",
      "Zhenyu Xiao",
      "Symeon Chatzinotas",
      "Jinhong Yuan",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.06225",
    "title": "Interactive Contrastive Learning for Self-supervised Entity Alignment",
    "abstract": " Comments: Accepted by CIKM 2022 ",
    "url": "https://arxiv.org/abs/2201.06225",
    "authors": [
      "Kaisheng Zeng",
      "Zhenhao Dong",
      "Lei Hou",
      "Yixin Cao",
      "Minghao Hu",
      "Jifan Yu",
      "Xin Lv",
      "Juanzi Li",
      "Ling Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.07984",
    "title": "AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees",
    "abstract": " Title: AstBERT: Enabling Language Model for Financial Code Understanding with  Abstract Syntax Trees ",
    "url": "https://arxiv.org/abs/2201.07984",
    "authors": [
      "Rong Liang",
      "Tiehua Zhang",
      "Yujie Lu",
      "Yuze Liu",
      "Zhen Huang",
      "Xin Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13329",
    "title": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.13329",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Hongxin Wei",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.02976",
    "title": "Measuring and Reducing Model Update Regression in Structured Prediction  for NLP",
    "abstract": " Comments: NeurIPS2022 ",
    "url": "https://arxiv.org/abs/2202.02976",
    "authors": [
      "Deng Cai",
      "Elman Mansimov",
      "Yi-An Lai",
      "Yixuan Su",
      "Lei Shu",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.02989",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03738",
    "title": "Conflict-free incidence coloring of outer-1-planar graphs",
    "abstract": " Comments: This paper is acccepted for publication in Acta Mathematicae Applicatae Sinica (English Series) under the current title as a reviewer suggested ",
    "url": "https://arxiv.org/abs/2202.03738",
    "authors": [
      "Mengke Qi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.05211",
    "title": "Behavior-Semantic Scenery Description (BSSD) of Road Networks for  Automated Driving",
    "abstract": " Comments: 13 pages, 3 figures, 3 tables, submitted to IEEE Access ",
    "url": "https://arxiv.org/abs/2202.05211",
    "authors": [
      "Moritz Lippert",
      "Felix Glatzki",
      "Hermann Winner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.06503",
    "title": "Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos",
    "abstract": " Title: Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos ",
    "url": "https://arxiv.org/abs/2202.06503",
    "authors": [
      "Congqi Cao",
      "Xin Zhang",
      "Shizhou Zhang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10030",
    "title": "Nonnegative-Constrained Joint Collaborative Representation with Union  Dictionary for Hyperspectral Anomaly Detection",
    "abstract": " Title: Nonnegative-Constrained Joint Collaborative Representation with Union  Dictionary for Hyperspectral Anomaly Detection ",
    "url": "https://arxiv.org/abs/2203.10030",
    "authors": [
      "Shizhen Chang",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10465",
    "title": "Inspection-L: Self-Supervised GNN Node Embeddings for Money Laundering  Detection in Bitcoin",
    "abstract": " Title: Inspection-L: Self-Supervised GNN Node Embeddings for Money Laundering  Detection in Bitcoin ",
    "url": "https://arxiv.org/abs/2203.10465",
    "authors": [
      "Wai Weng Lo",
      "Gayan K. Kulatilleke",
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2203.14619",
    "title": "Data-driven micromobility network planning for demand and safety",
    "abstract": " Comments: Main text: 16 pages, 5 figures, SI: 12 pages, 9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2203.14619",
    "authors": [
      "Pietro Folco",
      "Laetitia Gauvin",
      "Michele Tizzoni",
      "Michael Szell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2203.15335",
    "title": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "abstract": " Title: Iranian Modal Music (Dastgah) detection using deep neural networks ",
    "url": "https://arxiv.org/abs/2203.15335",
    "authors": [
      "Danial Ebrat",
      "Farzad Didehvar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.00903",
    "title": "Safety Verification of Neural Feedback Systems Based on Constrained  Zonotopes",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2204.00903",
    "authors": [
      "Yuhao Zhang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.04875",
    "title": "Learning to Induce Causal Structure",
    "abstract": " Title: Learning to Induce Causal Structure ",
    "url": "https://arxiv.org/abs/2204.04875",
    "authors": [
      "Nan Rosemary Ke",
      "Silvia Chiappa",
      "Jane Wang",
      "Anirudh Goyal",
      "Jorg Bornschein",
      "Melanie Rey",
      "Theophane Weber",
      "Matthew Botvinic",
      "Michael Mozer",
      "Danilo Jimenez Rezende"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.00160",
    "title": "Elucidating Meta-Structures of Noisy Labels in Semantic Segmentation by  Deep Neural Networks",
    "abstract": " Title: Elucidating Meta-Structures of Noisy Labels in Semantic Segmentation by  Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2205.00160",
    "authors": [
      "Yaoru Luo",
      "Guole Liu",
      "Yuanhao Guo",
      "Ge Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.00305",
    "title": "AdapterBias: Parameter-efficient Token-dependent Representation Shift  for Adapters in NLP Tasks",
    "abstract": " Comments: Findings of NAACL 2022 ",
    "url": "https://arxiv.org/abs/2205.00305",
    "authors": [
      "Chin-Lun Fu",
      "Zih-Ching Chen",
      "Yun-Ru Lee",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.05177",
    "title": "ConfLab: A Data Collection Concept, Dataset, and Benchmark for Machine  Analysis of Free-Standing Social Interactions in the Wild",
    "abstract": " Comments: In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks (NeurIPS D&B) ",
    "url": "https://arxiv.org/abs/2205.05177",
    "authors": [
      "Chirag Raman",
      "Jose Vargas-Quiros",
      "Stephanie Tan",
      "Ashraful Islam",
      "Ekin Gedik",
      "Hayley Hung"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09332",
    "title": "Accelerated Training of Physics-Informed Neural Networks (PINNs) using  Meshless Discretizations",
    "abstract": " Comments: Accepted at the 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.09332",
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10636",
    "title": "AutoLink: Self-supervised Learning of Human Skeletons and Object  Outlines by Linking Keypoints",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.10636",
    "authors": [
      "Xingzhe He",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10683",
    "title": "Scalable and Efficient Training of Large Convolutional Neural Networks  with Differential Privacy",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.10683",
    "authors": [
      "Zhiqi Bu",
      "Jialin Mao",
      "Shiyun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10920",
    "title": "Test-Time Robust Personalization for Federated Learning",
    "abstract": " Comments: LJ and TL contribute equally ",
    "url": "https://arxiv.org/abs/2205.10920",
    "authors": [
      "Liangze Jiang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12156",
    "title": "Not too little, not too much: a theoretical analysis of graph  (over)smoothing",
    "abstract": " Title: Not too little, not too much: a theoretical analysis of graph  (over)smoothing ",
    "url": "https://arxiv.org/abs/2205.12156",
    "authors": [
      "Nicolas Keriven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12850",
    "title": "A Universal Error Measure for Input Predictions Applied to Online Graph  Problems",
    "abstract": " Comments: To appear in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.12850",
    "authors": [
      "Giulia Bernardini",
      "Alexander Lindermayr",
      "Alberto Marchetti-Spaccamela",
      "Nicole Megow",
      "Leen Stougie",
      "Michelle Sweering"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13479",
    "title": "Learning to Reconstruct Missing Data from Spatiotemporal Graphs with  Sparse Observations",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13479",
    "authors": [
      "Ivan Marisca",
      "Andrea Cini",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13679",
    "title": "SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching",
    "abstract": " Title: SeedGNN: Graph Neural Networks for Supervised Seeded Graph Matching ",
    "url": "https://arxiv.org/abs/2205.13679",
    "authors": [
      "Liren Yu",
      "Jiaming Xu",
      "Xiaojun Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.15117",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15288",
    "title": "Self-Supervised Visual Representation Learning with Semantic Grouping",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.15288",
    "authors": [
      "Xin Wen",
      "Bingchen Zhao",
      "Anlin Zheng",
      "Xiangyu Zhang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00416",
    "title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.00416",
    "authors": [
      "Amir Feder",
      "Guy Horowitz",
      "Yoav Wald",
      "Roi Reichart",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.01201",
    "title": "REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual  Question Answering",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01201",
    "authors": [
      "Yuanze Lin",
      "Yujia Xie",
      "Dongdong Chen",
      "Yichong Xu",
      "Chenguang Zhu",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02016",
    "title": "Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network?",
    "abstract": " Title: Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network? ",
    "url": "https://arxiv.org/abs/2206.02016",
    "authors": [
      "Chuwei Wang",
      "Shanda Li",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.02369",
    "title": "Learning to Break the Loop: Analyzing and Mitigating Repetitions for  Neural Text Generation",
    "abstract": " Comments: Accepted by NeurIPS 2022. Code is released at this https URL ",
    "url": "https://arxiv.org/abs/2206.02369",
    "authors": [
      "Jin Xu",
      "Xiaojiang Liu",
      "Jianhao Yan",
      "Deng Cai",
      "Huayang Li",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.03287",
    "title": "NeMF: Neural Motion Fields for Kinematic Animation",
    "abstract": " Comments: Accepted to NeurIPS 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.03287",
    "authors": [
      "Chengan He",
      "Jun Saito",
      "James Zachary",
      "Holly Rushmeier",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": " Title: EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks ",
    "url": "https://arxiv.org/abs/2206.03491",
    "authors": [
      "Adrien Raison",
      "Pascal Bourdon",
      "David Helbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07594",
    "title": "Robust and Sparse Estimation of Linear Regression Coefficients with  Heavy-tailed Noises and Covariates",
    "abstract": " Comments: Some mistakes are corrected, and one assumption is added to the main theorem ",
    "url": "https://arxiv.org/abs/2206.07594",
    "authors": [
      "Takeyuki Sasai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07824",
    "title": "Large-Scale Differentiable Causal Discovery of Factor Graphs",
    "abstract": " Comments: 33 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2206.07824",
    "authors": [
      "Romain Lopez",
      "Jan-Christian H\u00fctter",
      "Jonathan K. Pritchard",
      "Aviv Regev"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2206.10991",
    "title": "Graph Neural Networks as Gradient Flows: understanding graph  convolutions via energy",
    "abstract": " Comments: First two authors equal contribution; 39 pages ",
    "url": "https://arxiv.org/abs/2206.10991",
    "authors": [
      "Francesco Di Giovanni",
      "James Rowbottom",
      "Benjamin P. Chamberlain",
      "Thomas Markovich",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.12839",
    "title": "Repository-Level Prompt Generation for Large Language Models of Code",
    "abstract": " Title: Repository-Level Prompt Generation for Large Language Models of Code ",
    "url": "https://arxiv.org/abs/2206.12839",
    "authors": [
      "Disha Shrivastava",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.13594",
    "title": "Cyber Network Resilience against Self-Propagating Malware Attacks",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2206.13594",
    "authors": [
      "Alesia Chernikova",
      "Nicol\u00f2 Gozzi",
      "Simona Boboila",
      "Priyanka Angadi",
      "John Loughner",
      "Matthew Wilden",
      "Nicola Perra",
      "Tina Eliassi-Rad",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.14604",
    "title": "Mining Seasonal Temporal Patterns in Big Time Series",
    "abstract": " Title: Mining Seasonal Temporal Patterns in Big Time Series ",
    "url": "https://arxiv.org/abs/2206.14604",
    "authors": [
      "Van Long Ho",
      "Nguyen Ho",
      "Torben Bach Pedersen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2206.15374",
    "title": "Verification and search algorithms for causal DAGs",
    "abstract": " Title: Verification and search algorithms for causal DAGs ",
    "url": "https://arxiv.org/abs/2206.15374",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15474",
    "title": "Forecasting Future World Events with Neural Networks",
    "abstract": " Comments: NeurIPS 2022; our dataset is available at this https URL ",
    "url": "https://arxiv.org/abs/2206.15474",
    "authors": [
      "Andy Zou",
      "Tristan Xiao",
      "Ryan Jia",
      "Joe Kwon",
      "Mantas Mazeika",
      "Richard Li",
      "Dawn Song",
      "Jacob Steinhardt",
      "Owain Evans",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.01472",
    "title": "Deep Contrastive One-Class Time Series Anomaly Detection",
    "abstract": " Title: Deep Contrastive One-Class Time Series Anomaly Detection ",
    "url": "https://arxiv.org/abs/2207.01472",
    "authors": [
      "Rui Wang",
      "Chongwei Liu",
      "Xudong Mou",
      "Kai Gao",
      "Xiaohui Guo",
      "Pin Liu",
      "Tianyu Wo",
      "Xudong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03337",
    "title": "Factorizing Knowledge in Neural Networks",
    "abstract": " Comments: ECCV2022 Camera Ready Version ",
    "url": "https://arxiv.org/abs/2207.03337",
    "authors": [
      "Xingyi Yang",
      "Jingwen Ye",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05372",
    "title": "Diversity-aware social robots meet people: beyond context-aware embodied  AI",
    "abstract": " Comments: The article has been presented during the Roundtable \"AI in holistic care and healing practices: the caring encounter beyond COVID-19\", Anthropology, AI and the Future of Human Society, 6-10 June 2022, Royal Anthropological Institute ",
    "url": "https://arxiv.org/abs/2207.05372",
    "authors": [
      "Carmine Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05899",
    "title": "Neural Topological Ordering for Computation Graphs",
    "abstract": " Comments: To appear in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.05899",
    "authors": [
      "Mukul Gagrani",
      "Corrado Rainone",
      "Yang Yang",
      "Harris Teague",
      "Wonseok Jeon",
      "Herke Van Hoof",
      "Weiliang Will Zeng",
      "Piero Zappi",
      "Christopher Lott",
      "Roberto Bondesan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07719",
    "title": "Temporal Forward-Backward Consistency, Not Residual Error, Measures the  Prediction Accuracy of Extended Dynamic Mode Decomposition",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2207.07719",
    "authors": [
      "Masih Haseli",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2207.10075",
    "title": "Is an Object-Centric Video Representation Beneficial for Transfer?",
    "abstract": " Comments: Accepted to ACCV 2022 ",
    "url": "https://arxiv.org/abs/2207.10075",
    "authors": [
      "Chuhan Zhang",
      "Ankush Gupta",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.13799",
    "title": "Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods",
    "abstract": " Title: Network polarization, filter bubbles, and echo chambers: An annotated  review of measures and reduction methods ",
    "url": "https://arxiv.org/abs/2207.13799",
    "authors": [
      "Ruben Interian",
      "Ruslan G. Marzo",
      "Isela Mendoza",
      "Celso C. Ribeiro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.05767",
    "title": "Distributionally Robust Model-Based Offline Reinforcement Learning with  Near-Optimal Sample Complexity",
    "abstract": " Title: Distributionally Robust Model-Based Offline Reinforcement Learning with  Near-Optimal Sample Complexity ",
    "url": "https://arxiv.org/abs/2208.05767",
    "authors": [
      "Laixi Shi",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.07498",
    "title": "Universal Solutions of Feedforward ReLU Networks for Interpolations",
    "abstract": " Comments: v2:minor revision; v3:proposition 5 modified ",
    "url": "https://arxiv.org/abs/2208.07498",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.09821",
    "title": "On The Robustness of Channel Allocation in Joint Radar And Communication  Systems: An Auction Approach",
    "abstract": " Title: On The Robustness of Channel Allocation in Joint Radar And Communication  Systems: An Auction Approach ",
    "url": "https://arxiv.org/abs/2208.09821",
    "authors": [
      "Ismail Lotfi",
      "Hongyang Du",
      "Dusit Niyato",
      "Sumei Sun",
      "Dong In Kim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2208.10627",
    "title": "Targeted Advertising on Social Networks Using Online Variational Tensor  Regression",
    "abstract": " Comments: 18 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.10627",
    "authors": [
      "Tsuyoshi Id\u00e9",
      "Keerthiram Murugesan",
      "Djallel Bouneffouf",
      "Naoki Abe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11727",
    "title": "Hyperparameter Optimization for Unsupervised Outlier Detection",
    "abstract": " Title: Hyperparameter Optimization for Unsupervised Outlier Detection ",
    "url": "https://arxiv.org/abs/2208.11727",
    "authors": [
      "Yue Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11985",
    "title": "Learning to Prune Instances of Steiner Tree Problem in Graphs",
    "abstract": " Title: Learning to Prune Instances of Steiner Tree Problem in Graphs ",
    "url": "https://arxiv.org/abs/2208.11985",
    "authors": [
      "Jiwei Zhang",
      "Deepak Ajwani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12880",
    "title": "Neuromorphic Visual Scene Understanding with Resonator Networks",
    "abstract": " Comments: 15 pages, 6 figures, minor changes ",
    "url": "https://arxiv.org/abs/2208.12880",
    "authors": [
      "Alpha Renner",
      "Lazar Supic",
      "Andreea Danielescu",
      "Giacomo Indiveri",
      "Bruno A. Olshausen",
      "Yulia Sandamirskaya",
      "Friedrich T. Sommer",
      "E. Paxon Frady"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.02000",
    "title": "Neuromorphic Visual Odometry with Resonator Networks",
    "abstract": " Comments: 14 pages, 5 figures, minor changes ",
    "url": "https://arxiv.org/abs/2209.02000",
    "authors": [
      "Alpha Renner",
      "Lazar Supic",
      "Andreea Danielescu",
      "Giacomo Indiveri",
      "E. Paxon Frady",
      "Friedrich T. Sommer",
      "Yulia Sandamirskaya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.03042",
    "title": "Graph Neural Networks for Low-Energy Event Classification &  Reconstruction in IceCube",
    "abstract": " Comments: Prepared for submission to JINST ",
    "url": "https://arxiv.org/abs/2209.03042",
    "authors": [
      "R. Abbasi",
      "M. Ackermann",
      "J. Adams",
      "N. Aggarwal",
      "J. A. Aguilar",
      "M. Ahlers",
      "M. Ahrens",
      "J.M. Alameddine",
      "A. A. Alves Jr.",
      "N. M. Amin",
      "K. Andeen",
      "T. Anderson",
      "G. Anton",
      "C. Arg\u00fcelles",
      "Y. Ashida",
      "S. Athanasiadou",
      "S. Axani",
      "X. Bai",
      "A. Balagopal V.",
      "M. Baricevic",
      "S. W. Barwick",
      "V. Basu",
      "R. Bay",
      "J. J. Beatty",
      "K.-H. Becker",
      "J. Becker Tjus",
      "J. Beise",
      "C. Bellenghi",
      "S. Benda",
      "S. BenZvi",
      "D. Berley",
      "E. Bernardini",
      "D. Z. Besson",
      "G. Binder",
      "D. Bindig",
      "E. Blaufuss",
      "S. Blot",
      "F. Bontempo",
      "J. Y. Book",
      "J. Borowka",
      "C. Boscolo Meneguolo",
      "S. B\u00f6ser",
      "O. Botner",
      "J. B\u00f6ttcher",
      "E. Bourbeau",
      "J. Braun",
      "B. Brinson",
      "J. Brostean-Kaiser",
      "R. T. Burley",
      "R. S. Busse",
      "M. A. Campana",
      "E. G. Carnie-Bronca",
      "C. Chen",
      "Z. Chen",
      "D. Chirkin",
      "K. Choi",
      "B. A. Clark",
      "L. Classen",
      "A. Coleman",
      "G. H. Collin",
      "A. Connolly",
      "J. M. Conrad"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2209.04154",
    "title": "SUPER-Rec: SUrrounding Position-Enhanced Representation for  Recommendation",
    "abstract": " Comments: There was a testing environment issue so it is required to re-conduct the model evaluation ",
    "url": "https://arxiv.org/abs/2209.04154",
    "authors": [
      "Taejun Lim",
      "Siqu Long",
      "Josiah Poon",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.04445",
    "title": "Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection",
    "abstract": " Title: Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection ",
    "url": "https://arxiv.org/abs/2209.04445",
    "authors": [
      "Vijay Srinivas Tida Sai Venkatesh Chilukoti",
      "Sonya Hsu",
      "Xiali Hei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.04561",
    "title": "Deep Baseline Network for Time Series Modeling and Anomaly Detection",
    "abstract": " Title: Deep Baseline Network for Time Series Modeling and Anomaly Detection ",
    "url": "https://arxiv.org/abs/2209.04561",
    "authors": [
      "Cheng Ge",
      "Xi Chen",
      "Ming Wang",
      "Jin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.05722",
    "title": "GrASPE: Graph based Multimodal Fusion for Robot Navigation in  Unstructured Outdoor Environments",
    "abstract": " Title: GrASPE: Graph based Multimodal Fusion for Robot Navigation in  Unstructured Outdoor Environments ",
    "url": "https://arxiv.org/abs/2209.05722",
    "authors": [
      "Kasun Weerakoon",
      "Adarsh Jagan Sathyamoorthy",
      "Jing Liang",
      "Tianrui Guan",
      "Utsav Patel",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.06353",
    "title": "Label Refinement Network from Synthetic Error Augmentation for Medical  Image Segmentation",
    "abstract": " Title: Label Refinement Network from Synthetic Error Augmentation for Medical  Image Segmentation ",
    "url": "https://arxiv.org/abs/2209.06353",
    "authors": [
      "Shuai Chen",
      "Antonio Garcia-Uceda",
      "Jiahang Su",
      "Gijs van Tulder",
      "Lennard Wolff",
      "Theo van Walsum",
      "Marleen de Bruijne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": " Title: Sketch of a novel approach to a neural model ",
    "url": "https://arxiv.org/abs/2209.06865",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2209.07924",
    "title": "GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks",
    "abstract": " Title: GNNInterpreter: A Probabilistic Generative Model-Level Explanation for  Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.07924",
    "authors": [
      "Xiaoqi Wang",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08902",
    "title": "Improving Fake News Detection of Influential Domain via Domain- and  Instance-Level Transfer",
    "abstract": " Comments: Accepted by COLING 2022. The 29th International Conference on Computational Linguistics, Gyeongju, Republic of Korea ",
    "url": "https://arxiv.org/abs/2209.08902",
    "authors": [
      "Qiong Nan",
      "Danding Wang",
      "Yongchun Zhu",
      "Qiang Sheng",
      "Yuhui Shi",
      "Juan Cao",
      "Jintao Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08932",
    "title": "OPR-Miner: Order-preserving rule mining for time series",
    "abstract": " Title: OPR-Miner: Order-preserving rule mining for time series ",
    "url": "https://arxiv.org/abs/2209.08932",
    "authors": [
      "Youxi Wu",
      "Xiaoqian Zhao",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Philippe Fournier-Viger",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2209.11924",
    "title": "Interventional Causal Representation Learning",
    "abstract": " Title: Interventional Causal Representation Learning ",
    "url": "https://arxiv.org/abs/2209.11924",
    "authors": [
      "Kartik Ahuja",
      "Yixin Wang",
      "Divyat Mahajan",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14065",
    "title": "LL-GNN: Low Latency Graph Neural Networks on FPGAs for Particle  Detectors",
    "abstract": " Comments: 13 pages and 12 figures ",
    "url": "https://arxiv.org/abs/2209.14065",
    "authors": [
      "Zhiqiang Que",
      "Hongxiang Fan",
      "Marcus Loo",
      "Michaela Blott",
      "Maurizio Pierini",
      "Alexander D Tapper",
      "Wayne Luk"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2209.14826",
    "title": "Towards Lightweight Black-Box Attacks against Deep Neural Networks",
    "abstract": " Title: Towards Lightweight Black-Box Attacks against Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2209.14826",
    "authors": [
      "Chenghao Sun",
      "Yonggang Zhang",
      "Wan Chaoqun",
      "Qizhou Wang",
      "Ya Li",
      "Tongliang Liu",
      "Bo Han",
      "Xinmei Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00383",
    "title": "Conditions for minimally tough graphs",
    "abstract": " Title: Conditions for minimally tough graphs ",
    "url": "https://arxiv.org/abs/2210.00383",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Blas Fern\u00e1ndez",
      "Gyula Y. Katona",
      "Martin Milani\u010d",
      "Kitti Varga"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.00453",
    "title": "Neural Graphical Models",
    "abstract": " Title: Neural Graphical Models ",
    "url": "https://arxiv.org/abs/2210.00453",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00538",
    "title": "Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation",
    "abstract": " Title: Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation ",
    "url": "https://arxiv.org/abs/2210.00538",
    "authors": [
      "Yuecen Wei",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Jia Wu",
      "Jinyan Wang",
      "Xianxian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00802",
    "title": "DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm",
    "abstract": " Title: DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm ",
    "url": "https://arxiv.org/abs/2210.00802",
    "authors": [
      "Kyriakos Schwarz",
      "Alicia Pliego-Mendieta",
      "Lara Planas-Paz",
      "Chantal Pauli",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.02040",
    "title": "GT-GAN: General Purpose Time Series Synthesis with Generative  Adversarial Networks",
    "abstract": " Comments: NeurIPs 2022 ",
    "url": "https://arxiv.org/abs/2210.02040",
    "authors": [
      "Jinsung Jeon",
      "Jeonghak Kim",
      "Haryong Song",
      "Seunghyeon Cho",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02192",
    "title": "Are All Losses Created Equal: A Neural Collapse Perspective",
    "abstract": " Comments: 32 page, 10 figures, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.02192",
    "authors": [
      "Jinxin Zhou",
      "Chong You",
      "Xiao Li",
      "Kangning Liu",
      "Sheng Liu",
      "Qing Qu",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02933",
    "title": "Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question  Answering",
    "abstract": " Comments: Findings of EMNLP2022 ",
    "url": "https://arxiv.org/abs/2210.02933",
    "authors": [
      "Mingxuan Ju",
      "Wenhao Yu",
      "Tong Zhao",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03093",
    "title": "Edge-Varying Fourier Graph Networks for Multivariate Time Series  Forecasting",
    "abstract": " Title: Edge-Varying Fourier Graph Networks for Multivariate Time Series  Forecasting ",
    "url": "https://arxiv.org/abs/2210.03093",
    "authors": [
      "Kun Yi",
      "Qi Zhang",
      "Liang Hu",
      "Hui He",
      "Ning An",
      "LongBing Cao",
      "ZhenDong Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03150",
    "title": "Towards Out-of-Distribution Adversarial Robustness",
    "abstract": " Comments: Under review ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.03150",
    "authors": [
      "Adam Ibrahim",
      "Charles Guille-Escuret",
      "Ioannis Mitliagkas",
      "Irina Rish",
      "David Krueger",
      "Pouya Bashivan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03526",
    "title": "A Unified Hard-Constraint Framework for Solving Geometrically Complex  PDEs",
    "abstract": " Comments: 10 pages, 5 figures, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.03526",
    "authors": [
      "Songming Liu",
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03675",
    "title": "Koopman Neural Forecaster for Time Series with Temporal Distribution  Shifts",
    "abstract": " Title: Koopman Neural Forecaster for Time Series with Temporal Distribution  Shifts ",
    "url": "https://arxiv.org/abs/2210.03675",
    "authors": [
      "Rui Wang",
      "Yihe Dong",
      "Sercan \u00d6. Arik",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]