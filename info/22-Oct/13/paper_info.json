[
  {
    "id": "arXiv:2210.05671",
    "title": "iMedBot: A Web-based Intelligent Agent for Healthcare Related Prediction  and Deep Learning",
    "abstract": "Background: Breast cancer is a multifactorial disease, genetic and environmental factors will affect its incidence probability. Breast cancer metastasis is one of the main cause of breast cancer related deaths reported by the American Cancer Society (ACS). Method: the iMedBot is a web application that we developed using the python Flask web framework and deployed on Amazon Web Services. It contains a frontend and a backend. The backend is supported by a python program we developed using the python Keras and scikit-learn packages, which can be used to learn deep feedforward neural network (DFNN) models. Result: the iMedBot can provide two main services: 1. it can predict 5-, 10-, or 15-year breast cancer metastasis based on a set of clinical information provided by a user. The prediction is done by using a set of DFNN models that were pretrained, and 2. It can train DFNN models for a user using user-provided dataset. The model trained will be evaluated using AUC and both the AUC value and the AUC ROC curve will be provided. Conclusion: The iMedBot web application provides a user-friendly interface for user-agent interaction in conducting personalized prediction and model training. It is an initial attempt to convert results of deep learning research into an online tool that may stir further research interests in this direction. Keywords: Deep learning, Breast Cancer, Web application, Model training. ",
    "url": "https://arxiv.org/abs/2210.05671",
    "authors": [
      "Chuhan Xu",
      "Xia Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.05674",
    "title": "Unsupervised detection of structural damage using Variational  Autoencoder and a One-Class Support Vector Machine",
    "abstract": "In recent years, Artificial Neural Networks (ANNs) have been introduced in Structural Health Monitoring (SHM) systems. An unsupervised method with a data-driven approach allows the ANN training on data acquired from an undamaged structural condition to detect structural damages. In standard approaches, after the training stage, a decision rule is manually defined to detect anomalous data. However, this process could be made automatic using machine learning methods, whom performances are maximised using hyperparameter optimization techniques. The paper proposes an unsupervised method with a data-driven approach to detect structural anomalies. The methodology consists of: (i) a Variational Autoencoder (VAE) to approximate undamaged data distribution and (ii) a One-Class Support Vector Machine (OC-SVM) to discriminate different health conditions using damage sensitive features extracted from VAE's signal reconstruction. The method is applied to a scale steel structure that was tested in nine damage's scenarios by IASC-ASCE Structural Health Monitoring Task Group. ",
    "url": "https://arxiv.org/abs/2210.05674",
    "authors": [
      "Andrea Pollastro",
      "Giusiana Testa",
      "Antonio Bilotta",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05676",
    "title": "Towards Consistency and Complementarity: A Multiview Graph Information  Bottleneck Approach",
    "abstract": "The empirical studies of Graph Neural Networks (GNNs) broadly take the original node feature and adjacency relationship as singleview input, ignoring the rich information of multiple graph views. To circumvent this issue, the multiview graph analysis framework has been developed to fuse graph information across views. How to model and integrate shared (i.e. consistency) and view-specific (i.e. complementarity) information is a key issue in multiview graph analysis. In this paper, we propose a novel Multiview Variational Graph Information Bottleneck (MVGIB) principle to maximize the agreement for common representations and the disagreement for view-specific representations. Under this principle, we formulate the common and view-specific information bottleneck objectives across multiviews by using constraints from mutual information. However, these objectives are hard to directly optimize since the mutual information is computationally intractable. To tackle this challenge, we derive variational lower and upper bounds of mutual information terms, and then instead optimize variational bounds to find the approximate solutions for the information objectives. Extensive experiments on graph benchmark datasets demonstrate the superior effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.05676",
    "authors": [
      "Xiaolong Fan",
      "Maoguo Gong",
      "Yue Wu",
      "Mingyang Zhang",
      "Hao Li",
      "Xiangming Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05715",
    "title": "Relational Embeddings for Language Independent Stance Detection",
    "abstract": "The large majority of the research performed on stance detection has been focused on developing more or less sophisticated text classification systems, even when many benchmarks are based on social network data such as Twitter. This paper aims to take on the stance detection task by placing the emphasis not so much on the text itself but on the interaction data available on social networks. More specifically, we propose a new method to leverage social information such as friends and retweets by generating relational embeddings, namely, dense vector representations of interaction pairs. Our method can be applied to any language and target without any manual tuning. Our experiments on seven publicly available datasets and four different languages show that combining our relational embeddings with textual methods helps to substantially improve performance, obtaining best results for six out of seven evaluation settings, outperforming strong baselines based on large pre-trained language models. ",
    "url": "https://arxiv.org/abs/2210.05715",
    "authors": [
      "Joseba Fernandez de Landa",
      "Rodrigo Agerri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05735",
    "title": "TetGAN: A Convolutional Neural Network for Tetrahedral Mesh Generation",
    "abstract": "We present TetGAN, a convolutional neural network designed to generate tetrahedral meshes. We represent shapes using an irregular tetrahedral grid which encodes an occupancy and displacement field. Our formulation enables defining tetrahedral convolution, pooling, and upsampling operations to synthesize explicit mesh connectivity with variable topological genus. The proposed neural network layers learn deep features over each tetrahedron and learn to extract patterns within spatial regions across multiple scales. We illustrate the capabilities of our technique to encode tetrahedral meshes into a semantically meaningful latent-space which can be used for shape editing and synthesis. Our project page is at https://threedle.github.io/tetGAN/. ",
    "url": "https://arxiv.org/abs/2210.05735",
    "authors": [
      "William Gao",
      "April Wang",
      "Gal Metzer",
      "Raymond A. Yeh",
      "Rana Hanocka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05741",
    "title": "Road Slope Prediction and Vehicle Dynamics Control for Autonomous  Vehicles",
    "abstract": "Autonomous vehicles can enhance overall performance and implement safety measures in ways that are impossible with conventional automobiles. These functions are executed through vehicle control systems, which have been the subject of considerable research. Autonomous cars have a distinct advantage as they possess various perception sensors that can predict road surface conditions and other phenomena ahead of time. Many modern automotive control systems treat the road slope as a constant and do not account for changes in the road profile in their vehicle models. As a result, vehicle states may be miscalculated, which, in the worst-case scenario, may result in accidents. This is particularly true for high center-of-gravity vehicles like trailers and delivery trucks. With the help of perception sensors in autonomous vehicles, a road slope estimation system can be developed to aid these control systems in making informed decisions regarding the vehicle's state. The current review is divided into three logical steps that can be discussed in the following manner: the first section describes and reviews the individual steps for developing a road slope estimation system. The second one provides a detailed review of previous investigations that implemented different methods that employ this prediction system to improve overall vehicle performance. Finally, a roll control system is presented as an innovative idea that builds on the whole discussion. A rollover prevention system with prediction abilities is presented because (1) it proves to be a critical safety feature, especially for heavy vehicles like buses, trucks, delivery trailers, etc., and (2) not enough research has been conducted on technologies that integrate a roll stability controller with a slope estimation system. ",
    "url": "https://arxiv.org/abs/2210.05741",
    "authors": [
      "Gautam Shetty",
      "Sabir Hossain",
      "Chuan Hu",
      "Xianke Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.05742",
    "title": "Curved Representation Space of Vision Transformers",
    "abstract": "Neural networks with self-attention (a.k.a. Transformers) like ViT and Swin have emerged as a better alternative to traditional convolutional neural networks (CNNs) for computer vision tasks. However, our understanding of how the new architecture works is still limited. In this paper, we focus on the phenomenon that Transformers show higher robustness against corruptions than CNNs, while not being overconfident (in fact, we find Transformers are actually underconfident). This is contrary to the intuition that robustness increases with confidence. We resolve this contradiction by investigating how the output of the penultimate layer moves in the representation space as the input data moves within a small area. In particular, we show the following. (1) While CNNs exhibit fairly linear relationship between the input and output movements, Transformers show nonlinear relationship for some data. For those data, the output of Transformers moves in a curved trajectory as the input moves linearly. (2) When a data is located in a curved region, it is hard to move it out of the decision region since the output moves along a curved trajectory instead of a straight line to the decision boundary, resulting in high robustness of Transformers. (3) If a data is slightly modified to jump out of the curved region, the movements afterwards become linear and the output goes to the decision boundary directly. Thus, Transformers can be attacked easily after a small random jump and the perturbation in the final attacked data remains imperceptible, i.e., there does exist a decision boundary near the data. This also explains the underconfident prediction of Transformers. (4) The curved regions in the representation space start to form at an early training stage and grow throughout the training course. Some data are trapped in the regions, obstructing Transformers from reducing the training loss. ",
    "url": "https://arxiv.org/abs/2210.05742",
    "authors": [
      "Juyeop Kim",
      "Junha Park",
      "Songkuk Kim",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05751",
    "title": "Toward Sustainable Continual Learning: Detection and Knowledge  Repurposing of Similar Tasks",
    "abstract": "Most existing works on continual learning (CL) focus on overcoming the catastrophic forgetting (CF) problem, with dynamic models and replay methods performing exceptionally well. However, since current works tend to assume exclusivity or dissimilarity among learning tasks, these methods require constantly accumulating task-specific knowledge in memory for each task. This results in the eventual prohibitive expansion of the knowledge repository if we consider learning from a long sequence of tasks. In this work, we introduce a paradigm where the continual learner gets a sequence of mixed similar and dissimilar tasks. We propose a new continual learning framework that uses a task similarity detection function that does not require additional learning, with which we analyze whether there is a specific task in the past that is similar to the current task. We can then reuse previous task knowledge to slow down parameter expansion, ensuring that the CL system expands the knowledge repository sublinearly to the number of learned tasks. Our experiments show that the proposed framework performs competitively on widely used computer vision benchmarks such as CIFAR10, CIFAR100, and EMNIST. ",
    "url": "https://arxiv.org/abs/2210.05751",
    "authors": [
      "Sijia Wang",
      "Yoojin Choi",
      "Junya Chen",
      "Mostafa El-Khamy",
      "Ricardo Henao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05769",
    "title": "Vote'n'Rank: Revision of Benchmarking with Social Choice Theory",
    "abstract": "The development of state-of-the-art systems in different applied areas of machine learning (ML) is driven by benchmarks, which have shaped the paradigm of evaluating generalisation capabilities from multiple perspectives. Although the paradigm is shifting towards more fine-grained evaluation across diverse tasks, the delicate question of how to aggregate the performances has received particular interest in the community. In general, benchmarks follow the unspoken utilitarian principles, where the systems are ranked based on their mean average score over task-specific metrics. Such aggregation procedure has been viewed as a sub-optimal evaluation protocol, which may have created the illusion of progress. This paper proposes Vote'n'Rank, a framework for ranking systems in multi-task benchmarks under the principles of the social choice theory. We demonstrate that our approach can be efficiently utilised to draw new insights on benchmarking in several ML sub-fields and identify the best-performing systems in research and development case studies. The Vote'n'Rank's procedures are more robust than the mean average while being able to handle missing performance scores and determine conditions under which the system becomes the winner. ",
    "url": "https://arxiv.org/abs/2210.05769",
    "authors": [
      "Mark Rofin",
      "Vladislav Mikhailov",
      "Mikhail Florinskiy",
      "Andrey Kravchenko",
      "Elena Tutubalina",
      "Tatiana Shavrina",
      "Daniel Karabekyan",
      "Ekaterina Artemova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05788",
    "title": "A Note on Reachability and Distance Oracles for Transmission Graphs",
    "abstract": "Let $P$ be a set of $n$ points in the plane, where each point $p\\in P$ has a transmission radius $r(p)>0$. The transmission graph defined by $P$ and the given radii, denoted by $\\mathcal{G}_{\\mathrm{tr}}(P)$, is the directed graph whose nodes are the points in $P$ and that contains the arcs $(p,q)$ such that $|pq|\\leq r(p)$. An and Oh [Algorithmica 2022] presented a reachability oracle for transmission graphs. Their oracle uses $O(n^{5/3})$ storage and, given two query points $s,t\\in P$, can decide in $O(n^{2/3})$ time if there is a path from $s$ to $t$ in $\\mathcal{G}_{\\mathrm{tr}}(P)$. We show that the clique-based separators introduced by De Berg \\emph{et al.} [SICOMP 2020] can be used to improve the storage of the oracle to $O(n\\sqrt{n})$ and the query time to $O(\\sqrt{n})$. Our oracle can be extended to approximate distance queries: we can construct, for a given parameter $\\varepsilon>0$, an oracle that uses $O((n/\\varepsilon)\\sqrt{n}\\log n)$ storage and that can report in $O((\\sqrt{n}/\\varepsilon)\\log n)$ time a value $d_{\\mathrm{hop}}^*(s,t)$ satisfying $d_{\\mathrm{hop}}(s,t) \\leq d_{\\mathrm{hop}}^*(s,t) < (1+\\varepsilon)\\cdot d_{\\mathrm{hop}}(s,t) + 1$, where $d_{\\mathrm{hop}}(s,t)$ is the hop-distance from $s$ to $t$. We also show how to extend the oracle to so-called continuous queries, where the target point $t$ can be any point in the plane. To obtain an efficient preprocessing algorithm, we show that a clique-based separator of a set~$F$ of convex fat objects in $\\Bbb{R}^d$ can be constructed in $O(n\\log n)$ time. ",
    "url": "https://arxiv.org/abs/2210.05788",
    "authors": [
      "Mark de Berg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2210.05794",
    "title": "Robustify Transformers with Robust Kernel Density Estimation",
    "abstract": "Recent advances in Transformer architecture have empowered its empirical success in various tasks across different domains. However, existing works mainly focus on improving the standard accuracy and computational cost, without considering the robustness of contaminated samples. Existing work has shown that the self-attention mechanism, which is the center of the Transformer architecture, can be viewed as a non-parametric estimator based on the well-known kernel density estimation (KDE). This motivates us to leverage the robust kernel density estimation (RKDE) in the self-attention mechanism, to alleviate the issue of the contamination of data by down-weighting the weight of bad samples in the estimation process. The modified self-attention mechanism can be incorporated into different Transformer variants. Empirical results on language modeling and image classification tasks demonstrate the effectiveness of this approach. ",
    "url": "https://arxiv.org/abs/2210.05794",
    "authors": [
      "Xing Han",
      "Tongzheng Ren",
      "Tan Minh Nguyen",
      "Khai Nguyen",
      "Joydeep Ghosh",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05801",
    "title": "Linkless Link Prediction via Relational Distillation",
    "abstract": "Graph Neural Networks (GNNs) have been widely used on graph data and have shown exceptional performance in the task of link prediction. Despite their effectiveness, GNNs often suffer from high latency due to non-trivial neighborhood data dependency in practical deployments. To address this issue, researchers have proposed methods based on knowledge distillation (KD) to transfer the knowledge from teacher GNNs to student MLPs, which are known to be efficient even with industrial scale data, and have shown promising results on node classification. Nonetheless, using KD to accelerate link prediction is still unexplored. In this work, we start with exploring two direct analogs of traditional KD for link prediction, i.e., predicted logit-based matching and node representation-based matching. Upon observing direct KD analogs do not perform well for link prediction, we propose a relational KD framework, Linkless Link Prediction (LLP). Unlike simple KD methods that match independent link logits or node representations, LLP distills relational knowledge that is centered around each (anchor) node to the student MLP. Specifically, we propose two matching strategies that complement each other: rank-based matching and distribution-based matching. Extensive experiments demonstrate that LLP boosts the link prediction performance of MLPs with significant margins, and even outperforms the teacher GNNs on 6 out of 9 benchmarks. LLP also achieves a 776.37x speedup in link prediction inference compared to GNNs on the large scale OGB-Citation2 dataset. ",
    "url": "https://arxiv.org/abs/2210.05801",
    "authors": [
      "Zhichun Guo",
      "William Shiao",
      "Shichang Zhang",
      "Yozen Liu",
      "Nitesh Chawla",
      "Neil Shah",
      "Tong Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05810",
    "title": "Continuous conditional video synthesis by neural processes",
    "abstract": "We propose a unified model for multiple conditional video synthesis tasks, including video prediction and video frame interpolation. We show that conditional video synthesis can be formulated as a neural process, which maps input spatio-temporal coordinates to target pixel values given context spatio-temporal coordinates and pixels values. Specifically, we feed an implicit neural representations of coordinates into a Transformer-based non-autoregressive conditional video synthesis model. Our task-specific models outperform previous work for video interpolation on multiple datasets and reach a competitive performance with the state-of-the-art models for video prediction. Importantly, the model is able to interpolate or predict with an arbitrary high frame rate, i.e., continuous synthesis. Our source code is available at \\url{https://github.com/NPVS/NPVS}. ",
    "url": "https://arxiv.org/abs/2210.05810",
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05831",
    "title": "Social-Group-Agnostic Word Embedding Debiasing via the Stereotype  Content Model",
    "abstract": "Existing word embedding debiasing methods require social-group-specific word pairs (e.g., \"man\"-\"woman\") for each social attribute (e.g., gender), which cannot be used to mitigate bias for other social groups, making these methods impractical or costly to incorporate understudied social groups in debiasing. We propose that the Stereotype Content Model (SCM), a theoretical framework developed in social psychology for understanding the content of stereotypes, which structures stereotype content along two psychological dimensions - \"warmth\" and \"competence\" - can help debiasing efforts to become social-group-agnostic by capturing the underlying connection between bias and stereotypes. Using only pairs of terms for warmth (e.g., \"genuine\"-\"fake\") and competence (e.g.,\"smart\"-\"stupid\"), we perform debiasing with established methods and find that, across gender, race, and age, SCM-based debiasing performs comparably to group-specific debiasing ",
    "url": "https://arxiv.org/abs/2210.05831",
    "authors": [
      "Ali Omrani",
      "Brendan Kennedy",
      "Mohammad Atari",
      "Morteza Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05833",
    "title": "Parameter estimation of the homodyned K distribution based on neural  networks and trainable fractional-order moments",
    "abstract": "Homodyned K (HK) distribution has been widely used to describe the scattering phenomena arising in various research fields, such as ultrasound imaging or optics. In this work, we propose a machine learning based approach to the estimation of the HK distribution parameters. We develop neural networks that can estimate the HK distribution parameters based on the signal-to-noise ratio, skewness and kurtosis calculated using fractional-order moments. Compared to the previous approaches, we consider the orders of the moments as trainable variables that can be optimized along with the network weights using the back-propagation algorithm. Networks are trained based on samples generated from the HK distribution. Obtained results demonstrate that the proposed method can be used to accurately estimate the HK distribution parameters. ",
    "url": "https://arxiv.org/abs/2210.05833",
    "authors": [
      "Michal Byra",
      "Ziemowit Klimonda",
      "Piotr Jarosik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2210.05834",
    "title": "Effectiveness of the Recent Advances in Capsule Networks",
    "abstract": "Convolutional neural networks (CNNs) have revolutionized the field of deep neural networks. However, recent research has shown that CNNs fail to generalize under various conditions and hence the idea of capsules was introduced in 2011, though the real surge of research started from 2017. In this paper, we present an overview of the recent advances in capsule architecture and routing mechanisms. In addition, we find that the relative focus in recent literature is on modifying routing procedure or architecture as a whole but the study of other finer components, specifically, squash function is wanting. Thus, we also present some new insights regarding the effect of squash functions in performance of the capsule networks. Finally, we conclude by discussing and proposing possible opportunities in the field of capsule networks. ",
    "url": "https://arxiv.org/abs/2210.05834",
    "authors": [
      "Nidhin Harilal",
      "Rohan Patil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05847",
    "title": "Experimental Evaluation of Baselines for Forecasting Social Media  Timeseries",
    "abstract": "Forecasting social media activity can be of practical use in many scenarios, from understanding trends, such as which topics are likely to engage more users in the coming week, to identifying unusual behavior, such as coordinated information operations or PumpNDump efforts. To evaluate a new approach to forecasting, it is important to have baselines against which to assess performance gains. We experimentally evaluate the performance of four baselines for forecasting activity in several social media datasets that record discussions related to three different geo-political contexts synchronously taking place on two different platforms, Twitter and YouTube. Experiments are done over hourly time periods. Our evaluation identifies the baselines which are most accurate for particular metrics and thus provide guidance for future work in social media modeling. ",
    "url": "https://arxiv.org/abs/2210.05847",
    "authors": [
      "Kin Wai Ng",
      "Frederick Mubang",
      "Lawrence O. Hall",
      "John Skvoretz",
      "Adriana Iamnitchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.05874",
    "title": "Multi-Content Time-Series Popularity Prediction with Multiple-Model  Transformers in MEC Networks",
    "abstract": "Coded/uncoded content placement in Mobile Edge Caching (MEC) has evolved as an efficient solution to meet the significant growth of global mobile data traffic by boosting the content diversity in the storage of caching nodes. To meet the dynamic nature of the historical request pattern of multimedia contents, the main focus of recent researches has been shifted to develop data-driven and real-time caching schemes. In this regard and with the assumption that users' preferences remain unchanged over a short horizon, the Top-K popular contents are identified as the output of the learning model. Most existing datadriven popularity prediction models, however, are not suitable for the coded/uncoded content placement frameworks. On the one hand, in coded/uncoded content placement, in addition to classifying contents into two groups, i.e., popular and nonpopular, the probability of content request is required to identify which content should be stored partially/completely, where this information is not provided by existing data-driven popularity prediction models. On the other hand, the assumption that users' preferences remain unchanged over a short horizon only works for content with a smooth request pattern. To tackle these challenges, we develop a Multiple-model (hybrid) Transformer-based Edge Caching (MTEC) framework with higher generalization ability, suitable for various types of content with different time-varying behavior, that can be adapted with coded/uncoded content placement frameworks. Simulation results corroborate the effectiveness of the proposed MTEC caching framework in comparison to its counterparts in terms of the cache-hit ratio, classification accuracy, and the transferred byte volume. ",
    "url": "https://arxiv.org/abs/2210.05874",
    "authors": [
      "Zohreh HajiAkhondi-Meybodi",
      "Arash Mohammadi",
      "Ming Hou",
      "Elahe Rahimian",
      "Shahin Heidarian",
      "Jamshid Abouei",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.05876",
    "title": "Statistical Modeling of Soft Error Influence on Neural Networks",
    "abstract": "Soft errors in large VLSI circuits pose dramatic influence on computing- and memory-intensive neural network (NN) processing. Understanding the influence of soft errors on NNs is critical to protect against soft errors for reliable NN processing. Prior work mainly rely on fault simulation to analyze the influence of soft errors on NN processing. They are accurate but usually specific to limited configurations of errors and NN models due to the prohibitively slow simulation speed especially for large NN models and datasets. With the observation that the influence of soft errors propagates across a large number of neurons and accumulates as well, we propose to characterize the soft error induced data disturbance on each neuron with normal distribution model according to central limit theorem and develop a series of statistical models to analyze the behavior of NN models under soft errors in general. The statistical models reveal not only the correlation between soft errors and NN model accuracy, but also how NN parameters such as quantization and architecture affect the reliability of NNs. The proposed models are compared with fault simulation and verified comprehensively. In addition, we observe that the statistical models that characterize the soft error influence can also be utilized to predict fault simulation results in many cases and we explore the use of the proposed statistical models to accelerate fault simulations of NNs. According to our experiments, the accelerated fault simulation shows almost two orders of magnitude speedup with negligible simulation accuracy loss over the baseline fault simulations. ",
    "url": "https://arxiv.org/abs/2210.05876",
    "authors": [
      "Haitong Huang",
      "Xinghua Xue",
      "Cheng Liu",
      "Ying Wang",
      "Tao Luo",
      "Long Cheng",
      "Huawei Li",
      "Xiaowei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.05881",
    "title": "Deterioration Prediction using Time-Series of Three Vital Signs and  Current Clinical Features Amongst COVID-19 Patients",
    "abstract": "Unrecognized patient deterioration can lead to high morbidity and mortality. Most existing deterioration prediction models require a large number of clinical information, typically collected in hospital settings, such as medical images or comprehensive laboratory tests. This is infeasible for telehealth solutions and highlights a gap in deterioration prediction models that are based on minimal data, which can be recorded at a large scale in any clinic, nursing home, or even at the patient's home. In this study, we propose and develop a prognostic model that predicts if a patient will experience deterioration in the forthcoming 3-24 hours. The model sequentially processes routine triadic vital signs: (a) oxygen saturation, (b) heart rate, and (c) temperature. The model is also provided with basic patient information, including sex, age, vaccination status, vaccination date, and status of obesity, hypertension, or diabetes. We train and evaluate the model using data collected from 37,006 COVID-19 patients at NYU Langone Health in New York, USA. The model achieves an area under the receiver operating characteristic curve (AUROC) of 0.808-0.880 for 3-24 hour deterioration prediction. We also conduct occlusion experiments to evaluate the importance of each input feature, where the results reveal the significance of continuously monitoring the variations of the vital signs. Our results show the prospect of accurate deterioration forecast using a minimum feature set that can be relatively easily obtained using wearable devices and self-reported patient information. ",
    "url": "https://arxiv.org/abs/2210.05881",
    "authors": [
      "Sarmad Mehrdad",
      "Farah E. Shamout",
      "Yao Wang",
      "S. Farokh Atashzar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.05883",
    "title": "AD-DROP: Attribution-Driven Dropout for Robust Language Model  Fine-Tuning",
    "abstract": "Fine-tuning large pre-trained language models on downstream tasks is apt to suffer from overfitting when limited training data is available. While dropout proves to be an effective antidote by randomly dropping a proportion of units, existing research has not examined its effect on the self-attention mechanism. In this paper, we investigate this problem through self-attention attribution and find that dropping attention positions with low attribution scores can accelerate training and increase the risk of overfitting. Motivated by this observation, we propose Attribution-Driven Dropout (AD-DROP), which randomly discards some high-attribution positions to encourage the model to make predictions by relying more on low-attribution positions to reduce overfitting. We also develop a cross-tuning strategy to alternate fine-tuning and AD-DROP to avoid dropping high-attribution positions excessively. Extensive experiments on various benchmarks show that AD-DROP yields consistent improvements over baselines. Analysis further confirms that AD-DROP serves as a strategic regularizer to prevent overfitting during fine-tuning. ",
    "url": "https://arxiv.org/abs/2210.05883",
    "authors": [
      "Tao Yang",
      "Jinghao Deng",
      "Xiaojun Quan",
      "Qifan Wang",
      "Shaoliang Nie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05889",
    "title": "Building Heterogeneous Cloud System for Machine Learning Inference",
    "abstract": "Online inference is becoming a key service product for many businesses, deployed in cloud platforms to meet customer demands. Despite their revenue-generation capability, these services need to operate under tight Quality-of-Service (QoS) and cost budget constraints. This paper introduces KAIROS, a novel runtime framework that maximizes the query throughput while meeting QoS target and a cost budget. KAIROS designs and implements novel techniques to build a pool of heterogeneous compute hardware without online exploration overhead, and distribute inference queries optimally at runtime. Our evaluation using industry-grade deep learning (DL) models shows that KAIROS yields up to 2X the throughput of an optimal homogeneous solution, and outperforms state-of-the-art schemes by up to 70\\%, despite advantageous implementations of the competing schemes to ignore their exploration overhead. ",
    "url": "https://arxiv.org/abs/2210.05889",
    "authors": [
      "Baolin Li",
      "Siddharth Samsi",
      "Vijay Gadepally",
      "Devesh Tiwari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05896",
    "title": "Common Corruption Robustness of Point Cloud Detectors: Benchmark and  Enhancement",
    "abstract": "Object detection through LiDAR-based point cloud has recently been important in autonomous driving. Although achieving high accuracy on public benchmarks, the state-of-the-art detectors may still go wrong and cause a heavy loss due to the widespread corruptions in the real world like rain, snow, sensor noise, etc. Nevertheless, there is a lack of a large-scale dataset covering diverse scenes and realistic corruption types with different severities to develop practical and robust point cloud detectors, which is challenging due to the heavy collection costs. To alleviate the challenge and start the first step for robust point cloud detection, we propose the physical-aware simulation methods to generate degraded point clouds under different real-world common corruptions. Then, for the first attempt, we construct a benchmark based on the physical-aware common corruptions for point cloud detectors, which contains a total of 1,122,150 examples covering 7,481 scenes, 25 common corruption types, and 6 severities. With such a novel benchmark, we conduct extensive empirical studies on 8 state-of-the-art detectors that contain 6 different detection frameworks. Thus we get several insight observations revealing the vulnerabilities of the detectors and indicating the enhancement directions. Moreover, we further study the effectiveness of existing robustness enhancement methods based on data augmentation and data denoising. The benchmark can potentially be a new platform for evaluating point cloud detectors, opening a door for developing novel robustness enhancement methods. ",
    "url": "https://arxiv.org/abs/2210.05896",
    "authors": [
      "Shuangzhi Li",
      "Zhijie Wang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Xingyu Li",
      "Lei Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.05901",
    "title": "Zero-Shot Prompting for Implicit Intent Prediction and Recommendation  with Commonsense Reasoning",
    "abstract": "Intelligent virtual assistants are currently designed to perform tasks or services explicitly mentioned by users, so multiple related domains or tasks need to be performed one by one through a long conversation with many explicit intents. Instead, human assistants are capable of reasoning (multiple) implicit intents based on user utterances via commonsense knowledge, reducing complex interactions and improving practicality. Therefore, this paper proposes a framework of multi-domain dialogue systems, which can automatically infer implicit intents based on user utterances and then perform zero-shot prompting using a large pre-trained language model to trigger suitable single task-oriented bots. The proposed framework is demonstrated effective to realize implicit intents and recommend associated bots in a zero-shot manner. ",
    "url": "https://arxiv.org/abs/2210.05901",
    "authors": [
      "Hui-Chi Kuo",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05912",
    "title": "PSNet: Parallel Symmetric Network for Video Salient Object Detection",
    "abstract": "For the video salient object detection (VSOD) task, how to excavate the information from the appearance modality and the motion modality has always been a topic of great concern. The two-stream structure, including an RGB appearance stream and an optical flow motion stream, has been widely used as a typical pipeline for VSOD tasks, but the existing methods usually only use motion features to unidirectionally guide appearance features or adaptively but blindly fuse two modality features. However, these methods underperform in diverse scenarios due to the uncomprehensive and unspecific learning schemes. In this paper, following a more secure modeling philosophy, we deeply investigate the importance of appearance modality and motion modality in a more comprehensive way and propose a VSOD network with up and down parallel symmetry, named PSNet. Two parallel branches with different dominant modalities are set to achieve complete video saliency decoding with the cooperation of the Gather Diffusion Reinforcement (GDR) module and Cross-modality Refinement and Complement (CRC) module. Finally, we use the Importance Perception Fusion (IPF) module to fuse the features from two parallel branches according to their different importance in different scenarios. Experiments on four dataset benchmarks demonstrate that our method achieves desirable and competitive performance. ",
    "url": "https://arxiv.org/abs/2210.05912",
    "authors": [
      "Runmin Cong",
      "Weiyu Song",
      "Jianjun Lei",
      "Guanghui Yue",
      "Yao Zhao",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05920",
    "title": "Boosting Graph Neural Networks via Adaptive Knowledge Distillation",
    "abstract": "Graph neural networks (GNNs) have shown remarkable performance on diverse graph mining tasks. Although different GNNs can be unified as the same message passing framework, they learn complementary knowledge from the same graph. Knowledge distillation (KD) is developed to combine the diverse knowledge from multiple models. It transfers knowledge from high-capacity teachers to a lightweight student. However, to avoid oversmoothing, GNNs are often shallow, which deviates from the setting of KD. In this context, we revisit KD by separating its benefits from model compression and emphasizing its power of transferring knowledge. To this end, we need to tackle two challenges: how to transfer knowledge from compact teachers to a student with the same capacity; and, how to exploit student GNN's own strength to learn knowledge. In this paper, we propose a novel adaptive KD framework, called BGNN, which sequentially transfers knowledge from multiple GNNs into a student GNN. We also introduce an adaptive temperature module and a weight boosting module. These modules guide the student to the appropriate knowledge for effective learning. Extensive experiments have demonstrated the effectiveness of BGNN. In particular, we achieve up to 3.05% improvement for node classification and 7.67% improvement for graph classification over vanilla GNNs. ",
    "url": "https://arxiv.org/abs/2210.05920",
    "authors": [
      "Zhichun Guo",
      "Chunhui Zhang",
      "Yujie Fan",
      "Yijun Tian",
      "Chuxu Zhang",
      "Nitesh Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05921",
    "title": "Step out of KG: Knowledge Graph Completion via Knowledgeable Retrieval  and Reading Comprehension",
    "abstract": "Knowledge graphs, as the cornerstone of many AI applications, usually face serious incompleteness problems. In recent years, there have been many efforts to study automatic knowledge graph completion (KGC), most of which use existing knowledge to infer new knowledge. However, in our experiments, we find that not all relations can be obtained by inference, which constrains the performance of existing models. To alleviate this problem, we propose a new model based on information retrieval and reading comprehension, namely IR4KGC. Specifically, we pre-train a knowledge-based information retrieval module that can retrieve documents related to the triples to be completed. Then, the retrieved documents are handed over to the reading comprehension module to generate the predicted answers. In experiments, we find that our model can well solve relations that cannot be inferred from existing knowledge, and achieve good results on KGC datasets. ",
    "url": "https://arxiv.org/abs/2210.05921",
    "authors": [
      "Xin Lv",
      "Yankai Lin",
      "Zijun Yao",
      "Kaisheng Zeng",
      "Jiajie Zhang",
      "Lei Hou",
      "Juanzi Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05923",
    "title": "Solving combinational optimization problems with evolutionary  single-pixel imaging",
    "abstract": "Single-pixel imaging (SPI) is a novel optical imaging technique by replacing the pixelated sensor array in a conventional camera with a single-pixel detector. In previous works, SPI is usually used for capturing object images or performing image processing tasks. In this work, we propose a SPI scheme for processing other types of data in addition to images. An Ising machine model is implemented optically with SPI for solving combinational optimization problems including number partition and graph maximum cut. Simulated and experimental results show that our proposed scheme can optimize the Hamiltonian function with evolutionary illumination patterns. ",
    "url": "https://arxiv.org/abs/2210.05923",
    "authors": [
      "Wei Huang",
      "Jiaxiang Li",
      "Shuming Jiao",
      "Zibang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2210.05927",
    "title": "Efficient Adversarial Training without Attacking: Worst-Case-Aware  Robust Reinforcement Learning",
    "abstract": "Recent studies reveal that a well-trained deep reinforcement learning (RL) policy can be particularly vulnerable to adversarial perturbations on input observations. Therefore, it is crucial to train RL agents that are robust against any attacks with a bounded budget. Existing robust training methods in deep RL either treat correlated steps separately, ignoring the robustness of long-term rewards, or train the agents and RL-based attacker together, doubling the computational burden and sample complexity of the training process. In this work, we propose a strong and efficient robust training framework for RL, named Worst-case-aware Robust RL (WocaR-RL) that directly estimates and optimizes the worst-case reward of a policy under bounded l_p attacks without requiring extra samples for learning an attacker. Experiments on multiple environments show that WocaR-RL achieves state-of-the-art performance under various strong attacks, and obtains significantly higher training efficiency than prior state-of-the-art robust training methods. The code of this work is available at https://github.com/umd-huang-lab/WocaR-RL. ",
    "url": "https://arxiv.org/abs/2210.05927",
    "authors": [
      "Yongyuan Liang",
      "Yanchao Sun",
      "Ruijie Zheng",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05929",
    "title": "Few-shot Backdoor Attacks via Neural Tangent Kernels",
    "abstract": "In a backdoor attack, an attacker injects corrupted examples into the training set. The goal of the attacker is to cause the final trained model to predict the attacker's desired target label when a predefined trigger is added to test inputs. Central to these attacks is the trade-off between the success rate of the attack and the number of corrupted training examples injected. We pose this attack as a novel bilevel optimization problem: construct strong poison examples that maximize the attack success rate of the trained model. We use neural tangent kernels to approximate the training dynamics of the model being attacked and automatically learn strong poison examples. We experiment on subclasses of CIFAR-10 and ImageNet with WideResNet-34 and ConvNeXt architectures on periodic and patch trigger attacks and show that NTBA-designed poisoned examples achieve, for example, an attack success rate of 90% with ten times smaller number of poison examples injected compared to the baseline. We provided an interpretation of the NTBA-designed attacks using the analysis of kernel linear regression. We further demonstrate a vulnerability in overparametrized deep neural networks, which is revealed by the shape of the neural tangent kernel. ",
    "url": "https://arxiv.org/abs/2210.05929",
    "authors": [
      "Jonathan Hayase",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05938",
    "title": "Robust Models are less Over-Confident",
    "abstract": "Despite the success of convolutional neural networks (CNNs) in many academic benchmarks for computer vision tasks, their application in the real-world is still facing fundamental challenges. One of these open problems is the inherent lack of robustness, unveiled by the striking effectiveness of adversarial attacks. Current attack methods are able to manipulate the network's prediction by adding specific but small amounts of noise to the input. In turn, adversarial training (AT) aims to achieve robustness against such attacks and ideally a better model generalization ability by including adversarial samples in the trainingset. However, an in-depth analysis of the resulting robust models beyond adversarial robustness is still pending. In this paper, we empirically analyze a variety of adversarially trained models that achieve high robust accuracies when facing state-of-the-art attacks and we show that AT has an interesting side-effect: it leads to models that are significantly less overconfident with their decisions, even on clean data than non-robust models. Further, our analysis of robust models shows that not only AT but also the model's building blocks (like activation functions and pooling) have a strong influence on the models' prediction confidences. Data & Project website: https://github.com/GeJulia/robustness_confidences_evaluation ",
    "url": "https://arxiv.org/abs/2210.05938",
    "authors": [
      "Julia Grabinski",
      "Paul Gavrikov",
      "Janis Keuper",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05944",
    "title": "Dynamic Clustering Network for Unsupervised Semantic Segmentation",
    "abstract": "Recently, the ability of self-supervised Vision Transformer (ViT) to represent pixel-level semantic relationships promotes the development of unsupervised dense prediction tasks. In this work, we investigate transferring self-supervised ViT to unsupervised semantic segmentation task. According to the analysis that the pixel-level representations of self-supervised ViT within a single image achieve good intra-class compactness and inter-class discrimination, we propose the Dynamic Clustering Network (DCN) to dynamically infer the underlying cluster centers for different images. By training with the proposed modularity loss, the DCN learns to project a set of prototypes to cluster centers for pixel representations in each image and assign pixels to different clusters, resulting on dividing each image to class-agnostic regions. For achieving unsupervised semantic segmentation task, we treat it as a region classification problem. Based on the regions produced by the DCN, we explore different ways to extract region-level representations and classify them in an unsupervised manner. We demonstrate the effectiveness of the proposed method trough experiments on unsupervised semantic segmentation, and achieve state-of-the-art performance on PASCAL VOC 2012 unsupervised semantic segmentation task. ",
    "url": "https://arxiv.org/abs/2210.05944",
    "authors": [
      "Kehan Li",
      "Zhennan Wang",
      "Zesen Cheng",
      "Runyi Yu",
      "Yian Zhao",
      "Guoli Song",
      "Li Yuan",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05947",
    "title": "Adaptive Dual Channel Convolution Hypergraph Representation Learning for  Technological Intellectual Property",
    "abstract": "In the age of big data, the demand for hidden information mining in technological intellectual property is increasing in discrete countries. Definitely, a considerable number of graph learning algorithms for technological intellectual property have been proposed. The goal is to model the technological intellectual property entities and their relationships through the graph structure and use the neural network algorithm to extract the hidden structure information in the graph. However, most of the existing graph learning algorithms merely focus on the information mining of binary relations in technological intellectual property, ignoring the higherorder information hidden in non-binary relations. Therefore, a hypergraph neural network model based on dual channel convolution is proposed. For the hypergraph constructed from technological intellectual property data, the hypergraph channel and the line expanded graph channel of the hypergraph are used to learn the hypergraph, and the attention mechanism is introduced to adaptively fuse the output representations of the two channels. The proposed model outperforms the existing approaches on a variety of datasets. ",
    "url": "https://arxiv.org/abs/2210.05947",
    "authors": [
      "Yuxin Liu",
      "Yawen Li",
      "Yingxia Shao",
      "Zeli Guan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05956",
    "title": "Towards Theoretically Inspired Neural Initialization Optimization",
    "abstract": "Automated machine learning has been widely explored to reduce human efforts in designing neural architectures and looking for proper hyperparameters. In the domain of neural initialization, however, similar automated techniques have rarely been studied. Most existing initialization methods are handcrafted and highly dependent on specific architectures. In this paper, we propose a differentiable quantity, named GradCosine, with theoretical insights to evaluate the initial state of a neural network. Specifically, GradCosine is the cosine similarity of sample-wise gradients with respect to the initialized parameters. By analyzing the sample-wise optimization landscape, we show that both the training and test performance of a network can be improved by maximizing GradCosine under gradient norm constraint. Based on this observation, we further propose the neural initialization optimization (NIO) algorithm. Generalized from the sample-wise analysis into the real batch setting, NIO is able to automatically look for a better initialization with negligible cost compared with the training time. With NIO, we improve the classification performance of a variety of neural architectures on CIFAR-10, CIFAR-100, and ImageNet. Moreover, we find that our method can even help to train large vision Transformer architecture without warmup. ",
    "url": "https://arxiv.org/abs/2210.05956",
    "authors": [
      "Yibo Yang",
      "Hong Wang",
      "Haobo Yuan",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05958",
    "title": "Bridging the Gap Between Vision Transformers and Convolutional Neural  Networks on Small Datasets",
    "abstract": "There still remains an extreme performance gap between Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs) when training from scratch on small datasets, which is concluded to the lack of inductive bias. In this paper, we further consider this problem and point out two weaknesses of ViTs in inductive biases, that is, the spatial relevance and diverse channel representation. First, on spatial aspect, objects are locally compact and relevant, thus fine-grained feature needs to be extracted from a token and its neighbors. While the lack of data hinders ViTs to attend the spatial relevance. Second, on channel aspect, representation exhibits diversity on different channels. But the scarce data can not enable ViTs to learn strong enough representation for accurate recognition. To this end, we propose Dynamic Hybrid Vision Transformer (DHVT) as the solution to enhance the two inductive biases. On spatial aspect, we adopt a hybrid structure, in which convolution is integrated into patch embedding and multi-layer perceptron module, forcing the model to capture the token features as well as their neighboring features. On channel aspect, we introduce a dynamic feature aggregation module in MLP and a brand new \"head token\" design in multi-head self-attention module to help re-calibrate channel representation and make different channel group representation interacts with each other. The fusion of weak channel representation forms a strong enough representation for classification. With this design, we successfully eliminate the performance gap between CNNs and ViTs, and our DHVT achieves a series of state-of-the-art performance with a lightweight model, 85.68% on CIFAR-100 with 22.8M parameters, 82.3% on ImageNet-1K with 24.0M parameters. Code is available at https://github.com/ArieSeirack/DHVT. ",
    "url": "https://arxiv.org/abs/2210.05958",
    "authors": [
      "Zhiying Lu",
      "Hongtao Xie",
      "Chuanbin Liu",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05959",
    "title": "JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional  Networks",
    "abstract": "Graph Convolutional Network (GCN) has exhibited strong empirical performance in many real-world applications. The vast majority of existing works on GCN primarily focus on the accuracy while ignoring how confident or uncertain a GCN is with respect to its predictions. Despite being a cornerstone of trustworthy graph mining, uncertainty quantification on GCN has not been well studied and the scarce existing efforts either fail to provide deterministic quantification or have to change the training procedure of GCN by introducing additional parameters or architectures. In this paper, we propose the first frequentist-based approach named JuryGCN in quantifying the uncertainty of GCN, where the key idea is to quantify the uncertainty of a node as the width of confidence interval by a jackknife estimator. Moreover, we leverage the influence functions to estimate the change in GCN parameters without re-training to scale up the computation. The proposed JuryGCN is capable of quantifying uncertainty deterministically without modifying the GCN architecture or introducing additional parameters. We perform extensive experimental evaluation on real-world datasets in the tasks of both active learning and semi-supervised node classification, which demonstrate the efficacy of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.05959",
    "authors": [
      "Jian Kang",
      "Qinghai Zhou",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.05968",
    "title": "Boosting the Transferability of Adversarial Attacks with Reverse  Adversarial Perturbation",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples, which can produce erroneous predictions by injecting imperceptible perturbations. In this work, we study the transferability of adversarial examples, which is significant due to its threat to real-world applications where model architecture or parameters are usually unknown. Many existing works reveal that the adversarial examples are likely to overfit the surrogate model that they are generated from, limiting its transfer attack performance against different target models. To mitigate the overfitting of the surrogate model, we propose a novel attack method, dubbed reverse adversarial perturbation (RAP). Specifically, instead of minimizing the loss of a single adversarial point, we advocate seeking adversarial example located at a region with unified low loss value, by injecting the worst-case perturbation (the reverse adversarial perturbation) for each step of the optimization procedure. The adversarial attack with RAP is formulated as a min-max bi-level optimization problem. By integrating RAP into the iterative process for attacks, our method can find more stable adversarial examples which are less sensitive to the changes of decision boundary, mitigating the overfitting of the surrogate model. Comprehensive experimental comparisons demonstrate that RAP can significantly boost adversarial transferability. Furthermore, RAP can be naturally combined with many existing black-box attack techniques, to further boost the transferability. When attacking a real-world image recognition system, Google Cloud Vision API, we obtain 22% performance improvement of targeted attacks over the compared method. Our codes are available at https://github.com/SCLBD/Transfer_attack_RAP. ",
    "url": "https://arxiv.org/abs/2210.05968",
    "authors": [
      "Zeyu Qin",
      "Yanbo Fan",
      "Yi Liu",
      "Li Shen",
      "Yong Zhang",
      "Jue Wang",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05974",
    "title": "Clustering Embedding Tables, Without First Learning Them",
    "abstract": "To work with categorical features, machine learning systems employ embedding tables. These tables can become exceedingly large in modern recommendation systems, necessitating the development of new methods for fitting them in memory, even during training. Some of the most successful methods for table compression are Product- and Residual Vector Quantization (Gray & Neuhoff, 1998). These methods replace table rows with references to k-means clustered \"codewords.\" Unfortunately, this means they must first know the table before compressing it, so they can only save memory during inference, not training. Recent work has used hashing-based approaches to minimize memory usage during training, but the compression obtained is inferior to that obtained by \"post-training\" quantization. We show that the best of both worlds may be obtained by combining techniques based on hashing and clustering. By first training a hashing-based \"sketch\", then clustering it, and then training the clustered quantization, our method achieves compression ratios close to those of post-training quantization with the training time memory reductions of hashing-based methods. We show experimentally that our method provides better compression and/or accuracy that previous methods, and we prove that our method always converges to the optimal embedding table for least-squares training. ",
    "url": "https://arxiv.org/abs/2210.05974",
    "authors": [
      "Henry Ling-Hei Tsang",
      "Thomas Dybdahl Ahle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.05976",
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion  Prediction",
    "abstract": "Stochastic human motion prediction aims to forecast multiple plausible future motions given a single pose sequence from the past. Most previous works focus on designing elaborate losses to improve the accuracy, while the diversity is typically characterized by randomly sampling a set of latent variables from the latent prior, which is then decoded into possible motions. This joint training of sampling and decoding, however, suffers from posterior collapse as the learned latent variables tend to be ignored by a strong decoder, leading to limited diversity. Alternatively, inspired by the diffusion process in nonequilibrium thermodynamics, we propose MotionDiff, a diffusion probabilistic model to treat the kinematics of human joints as heated particles, which will diffuse from original states to a noise distribution. This process offers a natural way to obtain the \"whitened\" latents without any trainable parameters, and human motion prediction can be regarded as the reverse diffusion process that converts the noise distribution into realistic future motions conditioned on the observed sequence. Specifically, MotionDiff consists of two parts: a spatial-temporal transformer-based diffusion network to generate diverse yet plausible motions, and a graph convolutional network to further refine the outputs. Experimental results on two datasets demonstrate that our model yields the competitive performance in terms of both accuracy and diversity. ",
    "url": "https://arxiv.org/abs/2210.05976",
    "authors": [
      "Dong Wei",
      "Huaijiang Sun",
      "Bin Li",
      "Jianfeng Lu",
      "Weiqing Li",
      "Xiaoning Sun",
      "Shengxiang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05990",
    "title": "GGViT:Multistream Vision Transformer Network in Face2Face Facial  Reenactment Detection",
    "abstract": "Detecting manipulated facial images and videos on social networks has been an urgent problem to be solved. The compression of videos on social media has destroyed some pixel details that could be used to detect forgeries. Hence, it is crucial to detect manipulated faces in videos of different quality. We propose a new multi-stream network architecture named GGViT, which utilizes global information to improve the generalization of the model. The embedding of the whole face extracted by ViT will guide each stream network. Through a large number of experiments, we have proved that our proposed model achieves state-of-the-art classification accuracy on FF++ dataset, and has been greatly improved on scenarios of different compression rates. The accuracy of Raw/C23, Raw/C40 and C23/C40 was increased by 24.34%, 15.08% and 10.14% respectively. ",
    "url": "https://arxiv.org/abs/2210.05990",
    "authors": [
      "Haotian Wu",
      "Peipei Wang",
      "Xin Wang",
      "Ji Xiang",
      "Rui Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05992",
    "title": "Fast Convergence to Unanimity in Dense Erd\u0151s-R\u00e9nyi Graphs",
    "abstract": "Majority dynamics on the binomial Erd\\H{o}s-R\\'enyi graph $\\mathsf{G}(n,p)$ with $p=\\lambda/\\sqrt{n}$ is studied. In this process, each vertex has a state in $\\{0,1\\}$ and at each round, every vertex adopts the state of the majority of its neighbors, retaining its state in the case of a tie. It was conjectured by Benjamini et al. and proved by Fountoulakis et al. that this process reaches unanimity with high probability in at most four rounds. By adding some extra randomness and allowing the underlying graph to be drawn anew in each communication round, we improve on their result and prove that this process reaches consensus in only three communication rounds with probability approaching $1$ as $n$ grows to infinity. We also provide a converse result, showing that three rounds are not only sufficient, but also necessary. ",
    "url": "https://arxiv.org/abs/2210.05992",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.06002",
    "title": "Face Super-Resolution with Progressive Embedding of Multi-scale Face  Priors",
    "abstract": "The face super-resolution (FSR) task is to reconstruct high-resolution face images from low-resolution inputs. Recent works have achieved success on this task by utilizing facial priors such as facial landmarks. Most existing methods pay more attention to global shape and structure information, but less to local texture information, which makes them cannot recover local details well. In this paper, we propose a novel recurrent convolutional network based framework for face super-resolution, which progressively introduces both global shape and local texture information. We take full advantage of the intermediate outputs of the recurrent network, and landmarks information and facial action units (AUs) information are extracted in the output of the first and second steps respectively, rather than low-resolution input. Moreover, we introduced AU classification results as a novel quantitative metric for facial details restoration. Extensive experiments show that our proposed method significantly outperforms state-of-the-art FSR methods in terms of image quality and facial details restoration. ",
    "url": "https://arxiv.org/abs/2210.06002",
    "authors": [
      "Chenggong Zhang",
      "Zhilei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06005",
    "title": "Generative Adversarial Nets: Can we generate a new dataset based on only  one training set?",
    "abstract": "A generative adversarial network (GAN) is a class of machine learning frameworks designed by Goodfellow et al. in 2014. In the GAN framework, the generative model is pitted against an adversary: a discriminative model that learns to determine whether a sample is from the model distribution or the data distribution. GAN generates new samples from the same distribution as the training set. In this work, we aim to generate a new dataset that has a different distribution from the training set. In addition, the Jensen-Shannon divergence between the distributions of the generative and training datasets can be controlled by some target $\\delta \\in [0, 1]$. Our work is motivated by applications in generating new kinds of rice that have similar characteristics as good rice. ",
    "url": "https://arxiv.org/abs/2210.06005",
    "authors": [
      "Lan V. Truong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.06006",
    "title": "BEV Lane Det: Fast Lane Detection on BEV Ground",
    "abstract": "Recently, 3D lane detection has been an actively developing area in autonomous driving which is the key to routing the vehicle. This work proposes a deployment-oriented monocular 3D lane detector with only naive CNN and FC layers. This detector achieved state-of-the-art results on the Apollo 3D Lane Synthetic dataset and OpenLane real-world dataset with 96 FPS runtime speed. We conduct three techniques in our detector: (1) Virtual Camera eliminates the difference in poses of cameras mounted on different vehicles. (2) Spatial Feature Pyramid Transform as a light-weighed image-view to bird-eye view transformer can utilize scales of image-view featmaps. (3) Yolo Style Lane Representation makes a good balance between bird-eye view resolution and runtime speed. Meanwhile, it can reduce the inefficiency caused by the class imbalance due to the sparsity of the lane detection task during training. Combining these three techniques, we obtained a 58.4% F1-score on the OpenLane dataset, which is a 10.6% improvement over the baseline. On the Apollo dataset, we achieved an F1-score of 96.9%, which is 4% points of supremacy over the best on the leaderboard. The source code will release soon. ",
    "url": "https://arxiv.org/abs/2210.06006",
    "authors": [
      "Ruihao Wang",
      "Jian Qin",
      "Kaiying Li",
      "Dong Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06008",
    "title": "BoxMask: Revisiting Bounding Box Supervision for Video Object Detection",
    "abstract": "We present a new, simple yet effective approach to uplift video object detection. We observe that prior works operate on instance-level feature aggregation that imminently neglects the refined pixel-level representation, resulting in confusion among objects sharing similar appearance or motion characteristics. To address this limitation, we propose BoxMask, which effectively learns discriminative representations by incorporating class-aware pixel-level information. We simply consider bounding box-level annotations as a coarse mask for each object to supervise our method. The proposed module can be effortlessly integrated into any region-based detector to boost detection. Extensive experiments on ImageNet VID and EPIC KITCHENS datasets demonstrate consistent and significant improvement when we plug our BoxMask module into numerous recent state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.06008",
    "authors": [
      "Khurram Azeem Hashmi",
      "Alain Pagani",
      "Didier Stricker",
      "Muhammamd Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06010",
    "title": "Simulating Spreading of Multiple Interacting Processes in Complex  Networks",
    "abstract": "Investigating the interaction between spreading processes in complex networks is one of the most important challenges in network science. However, whether we would like to know how the information campaign will affect virus spreading or how the advertising campaign of the new iPhone will affect the sales of Samsung phones, we need an environment that will allow us to evaluate under what conditions our spreading campaign will be effective. Network Diffusion is a Python package that should help do that. In this paper, we introduce its operating principle and main functionalities, including simple examples of simulations that can be performed using it. ",
    "url": "https://arxiv.org/abs/2210.06010",
    "authors": [
      "Micha\u0142 Czuba",
      "Piotr Br\u00f3dka"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.06012",
    "title": "Phantom -- An RL-driven framework for agent-based modeling of complex  economic systems and markets",
    "abstract": "Agent based modeling (ABM) is a computational approach to modeling complex systems by specifying the behavior of autonomous decision-making components or agents in the system and allowing the system dynamics to emerge from their interactions. Recent advances in the field of Multi-agent reinforcement learning (MARL) have made it feasible to learn the equilibrium of complex environments where multiple agents learn at the same time - opening up the possibility of building ABMs where agent behaviors are learned and system dynamics can be analyzed. However, most ABM frameworks are not RL-native, in that they do not offer concepts and interfaces that are compatible with the use of MARL to learn agent behaviors. In this paper, we introduce a new framework, Phantom, to bridge the gap between ABM and MARL. Phantom is an RL-driven framework for agent-based modeling of complex multi-agent systems such as economic systems and markets. To enable this, the framework provides tools to specify the ABM in MARL-compatible terms - including features to encode dynamic partial observability, agent utility / reward functions, heterogeneity in agent preferences or types, and constraints on the order in which agents can act (e.g. Stackelberg games, or complex turn-taking environments). In this paper, we present these features, their design rationale and show how they were used to model and simulate Over-The-Counter (OTC) markets. ",
    "url": "https://arxiv.org/abs/2210.06012",
    "authors": [
      "Leo Ardon",
      "Jared Vann",
      "Deepeka Garg",
      "Tom Spooner",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.06015",
    "title": "Energy Consumption-Aware Tabular Benchmarks for Neural Architecture  Search",
    "abstract": "The demand for large-scale computational resources for Neural Architecture Search (NAS) has been lessened by tabular benchmarks for NAS. Evaluating NAS strategies is now possible on extensive search spaces and at a moderate computational cost. But so far, NAS has mainly focused on maximising performance on some hold-out validation/test set. However, energy consumption is a partially conflicting objective that should not be neglected. We hypothesise that constraining NAS to include the energy consumption of training the models could reveal a sub-space of undiscovered architectures that are more computationally efficient with a smaller carbon footprint. To support the hypothesis, an existing tabular benchmark for NAS is augmented with the energy consumption of each architecture. We then perform multi-objective optimisation that includes energy consumption as an additional objective. We demonstrate the usefulness of multi-objective NAS for uncovering the trade-off between performance and energy consumption as well as for finding more energy-efficient architectures. The updated tabular benchmark, EC-NAS-Bench, is open-sourced to encourage the further exploration of energy consumption-aware NAS. ",
    "url": "https://arxiv.org/abs/2210.06015",
    "authors": [
      "Pedram Bakhtiarifard",
      "Christian Igel",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06028",
    "title": "VL4Pose: Active Learning Through Out-Of-Distribution Detection For Pose  Estimation",
    "abstract": "Advances in computing have enabled widespread access to pose estimation, creating new sources of data streams. Unlike mock set-ups for data collection, tapping into these data streams through on-device active learning allows us to directly sample from the real world to improve the spread of the training distribution. However, on-device computing power is limited, implying that any candidate active learning algorithm should have a low compute footprint while also being reliable. Although multiple algorithms cater to pose estimation, they either use extensive compute to power state-of-the-art results or are not competitive in low-resource settings. We address this limitation with VL4Pose (Visual Likelihood For Pose Estimation), a first principles approach for active learning through out-of-distribution detection. We begin with a simple premise: pose estimators often predict incoherent poses for out-of-distribution samples. Hence, can we identify a distribution of poses the model has been trained on, to identify incoherent poses the model is unsure of? Our solution involves modelling the pose through a simple parametric Bayesian network trained via maximum likelihood estimation. Therefore, poses incurring a low likelihood within our framework are out-of-distribution samples making them suitable candidates for annotation. We also observe two useful side-outcomes: VL4Pose in-principle yields better uncertainty estimates by unifying joint and pose level ambiguity, as well as the unintentional but welcome ability of VL4Pose to perform pose refinement in limited scenarios. We perform qualitative and quantitative experiments on three datasets: MPII, LSP and ICVL, spanning human and hand pose estimation. Finally, we note that VL4Pose is simple, computationally inexpensive and competitive, making it suitable for challenging tasks such as on-device active learning. ",
    "url": "https://arxiv.org/abs/2210.06028",
    "authors": [
      "Megh Shukla",
      "Roshan Roy",
      "Pankaj Singh",
      "Shuaib Ahmed",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06040",
    "title": "Question Answering Over Biological Knowledge Graph via Amazon Alexa",
    "abstract": "Structured and unstructured data and facts about drugs, genes, protein, viruses, and their mechanism are spread across a huge number of scientific articles. These articles are a large-scale knowledge source and can have a huge impact on disseminating knowledge about the mechanisms of certain biological processes. A knowledge graph (KG) can be constructed by integrating such facts and data and be used for data integration, exploration, and federated queries. However, exploration and querying large-scale KGs is tedious for certain groups of users due to a lack of knowledge about underlying data assets or semantic technologies. A question-answering (QA) system allows the answer of natural language questions over KGs automatically using triples contained in a KG. Recently, the use and adaption of digital assistants are getting wider owing to their capability at enabling users to voice commands to control smart systems or devices. This paper is about using Amazon Alexa's voice-enabled interface for QA over KGs. As a proof-of-concept, we use the well-known DisgeNET KG, which contains knowledge covering 1.13 million gene-disease associations between 21,671 genes and 30,170 diseases, disorders, and clinical or abnormal human phenotypes. Our study shows how Alex could be of help to find facts about certain biological entities from large-scale knowledge bases. ",
    "url": "https://arxiv.org/abs/2210.06040",
    "authors": [
      "Md. Rezaul Karim",
      "Hussain Ali",
      "Prinon Das",
      "Mohamed Abdelwaheb",
      "Stefan Decker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.06044",
    "title": "Multi-Granularity Cross-modal Alignment for Generalized Medical Visual  Representation Learning",
    "abstract": "Learning medical visual representations directly from paired radiology reports has become an emerging topic in representation learning. However, existing medical image-text joint learning methods are limited by instance or local supervision analysis, ignoring disease-level semantic correspondences. In this paper, we present a novel Multi-Granularity Cross-modal Alignment (MGCA) framework for generalized medical visual representation learning by harnessing the naturally exhibited semantic correspondences between medical image and radiology reports at three different levels, i.e., pathological region-level, instance-level, and disease-level. Specifically, we first incorporate the instance-wise alignment module by maximizing the agreement between image-report pairs. Further, for token-wise alignment, we introduce a bidirectional cross-attention strategy to explicitly learn the matching between fine-grained visual tokens and text tokens, followed by contrastive learning to align them. More important, to leverage the high-level inter-subject relationship semantic (e.g., disease) correspondences, we design a novel cross-modal disease-level alignment paradigm to enforce the cross-modal cluster assignment consistency. Extensive experimental results on seven downstream medical image datasets covering image classification, object detection, and semantic segmentation tasks demonstrate the stable and superior performance of our framework. ",
    "url": "https://arxiv.org/abs/2210.06044",
    "authors": [
      "Fuying Wang",
      "Yuyin Zhou",
      "Shujun Wang",
      "Varut Vardhanabhuti",
      "Lequan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06066",
    "title": "On the Optimality of Coded Caching With Heterogeneous User Profiles",
    "abstract": "In this paper, we consider a coded caching scenario where users have heterogeneous interests. Taking into consideration the system model originally proposed by Wang and Peleato, for which the end-receiving users are divided into groups according to their file preferences, we develop a novel information-theoretic converse on the optimal worst-case communication load under uncoded cache placement. Interestingly, the developed converse bound, jointly with one of the coded schemes proposed by Wang and Peleato, allows us to characterize the optimal worst-case communication load under uncoded prefetching within a constant multiplicative gap of $2$. Although we restrict the caching policy to be uncoded, our work improves the previously known order optimality results for the considered caching problem. ",
    "url": "https://arxiv.org/abs/2210.06066",
    "authors": [
      "Federico Brunero",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.06068",
    "title": "Using Massive Multilingual Pre-Trained Language Models Towards Real  Zero-Shot Neural Machine Translation in Clinical Domain",
    "abstract": "Massively multilingual pre-trained language models (MMPLMs) are developed in recent years demonstrating superpowers and the pre-knowledge they acquire for downstream tasks. In this work, we investigate whether MMPLMs can be applied to zero-shot machine translation (MT) toward entirely new language pairs and new domains. We carry out an experimental investigation using Meta-AI's MMPLMs \"wmt21-dense-24-wide-en-X and X-en (WMT21fb)\" which were pre-trained on 7 language pairs and 14 translation directions including English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and opposite direction. We fine-tune these MMPLMs towards English-Spanish language pair which did not exist at all in their original pre-trained corpora both implicitly and explicitly. We prepare carefully aligned clinical domain data for this fine-tuning, which is different from their original mixed domain knowledge as well. Our experimental result shows that the fine-tuning is very successful using just 250k well-aligned in-domain EN-ES pairs/sentences for three sub-task translation tests: clinical cases, clinical terms, and ontology concepts. It achieves very close evaluation scores to another MMPLM NLLB from Meta-AI, which included Spanish as a high-resource setting in the pre-training. To the best of our knowledge, this is the first work on using MMPLMs towards real zero-shot NMT successfully for totally unseen languages during pre-training, and also the first in clinical domain for such a study. ",
    "url": "https://arxiv.org/abs/2210.06068",
    "authors": [
      "Lifeng Han",
      "Gleb Erofeev",
      "Irina Sorokina",
      "Serge Gladkoff",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06077",
    "title": "Double Bubble, Toil and Trouble: Enhancing Certified Robustness through  Transitivity",
    "abstract": "In response to subtle adversarial examples flipping classifications of neural network models, recent research has promoted certified robustness as a solution. There, invariance of predictions to all norm-bounded attacks is achieved through randomised smoothing of network inputs. Today's state-of-the-art certifications make optimal use of the class output scores at the input instance under test: no better radius of certification (under the $L_2$ norm) is possible given only these score. However, it is an open question as to whether such lower bounds can be improved using local information around the instance under test. In this work, we demonstrate how today's \"optimal\" certificates can be improved by exploiting both the transitivity of certifications, and the geometry of the input space, giving rise to what we term Geometrically-Informed Certified Robustness. By considering the smallest distance to points on the boundary of a set of certifications this approach improves certifications for more than $80\\%$ of Tiny-Imagenet instances, yielding an on average $5 \\%$ increase in the associated certification. When incorporating training time processes that enhance the certified radius, our technique shows even more promising results, with a uniform $4$ percentage point increase in the achieved certified radius. ",
    "url": "https://arxiv.org/abs/2210.06077",
    "authors": [
      "Andrew C. Cullen",
      "Paul Montague",
      "Shijie Liu",
      "Sarah M. Erfani",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06088",
    "title": "Annihilation of Spurious Minima in Two-Layer ReLU Networks",
    "abstract": "We study the optimization problem associated with fitting two-layer ReLU neural networks with respect to the squared loss, where labels are generated by a target network. Use is made of the rich symmetry structure to develop a novel set of tools for studying the mechanism by which over-parameterization annihilates spurious minima. Sharp analytic estimates are obtained for the loss and the Hessian spectrum at different minima, and it is proved that adding neurons can turn symmetric spurious minima into saddles; minima of lesser symmetry require more neurons. Using Cauchy's interlacing theorem, we prove the existence of descent directions in certain subspaces arising from the symmetry structure of the loss function. This analytic approach uses techniques, new to the field, from algebraic geometry, representation theory and symmetry breaking, and confirms rigorously the effectiveness of over-parameterization in making the associated loss landscape accessible to gradient-based methods. For a fixed number of neurons and inputs, the spectral results remain true under symmetry breaking perturbation of the target. ",
    "url": "https://arxiv.org/abs/2210.06088",
    "authors": [
      "Yossi Arjevani",
      "Michael Field"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.06089",
    "title": "When are Local Queries Useful for Robust Learning?",
    "abstract": "Distributional assumptions have been shown to be necessary for the robust learnability of concept classes when considering the exact-in-the-ball robust risk and access to random examples by Gourdeau et al. (2019). In this paper, we study learning models where the learner is given more power through the use of local queries, and give the first distribution-free algorithms that perform robust empirical risk minimization (ERM) for this notion of robustness. The first learning model we consider uses local membership queries (LMQ), where the learner can query the label of points near the training sample. We show that, under the uniform distribution, LMQs do not increase the robustness threshold of conjunctions and any superclass, e.g., decision lists and halfspaces. Faced with this negative result, we introduce the local equivalence query (LEQ) oracle, which returns whether the hypothesis and target concept agree in the perturbation region around a point in the training sample, as well as a counterexample if it exists. We show a separation result: on one hand, if the query radius $\\lambda$ is strictly smaller than the adversary's perturbation budget $\\rho$, then distribution-free robust learning is impossible for a wide variety of concept classes; on the other hand, the setting $\\lambda=\\rho$ allows us to develop robust ERM algorithms. We then bound the query complexity of these algorithms based on online learning guarantees and further improve these bounds for the special case of conjunctions. We finish by giving robust learning algorithms for halfspaces with margins on both $\\{0,1\\}^n$ and $\\mathbb{R}^n$. ",
    "url": "https://arxiv.org/abs/2210.06089",
    "authors": [
      "Pascale Gourdeau",
      "Varun Kanade",
      "Marta Kwiatkowska",
      "James Worrell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06096",
    "title": "M$^3$Video: Masked Motion Modeling for Self-Supervised Video  Representation Learning",
    "abstract": "We study self-supervised video representation learning that seeks to learn video features from unlabeled videos, which is widely used for video analysis as labeling videos is labor-intensive. Current methods often mask some video regions and then train a model to reconstruct spatial information in these regions (e.g., original pixels). However, the model is easy to reconstruct this information by considering content in a single frame. As a result, it may neglect to learn the interactions between frames, which are critical for video analysis. In this paper, we present a new self-supervised learning task, called Masked Motion Modeling (M$^3$Video), for learning representation by enforcing the model to predict the motion of moving objects in the masked regions. To generate motion targets for this task, we track the objects using optical flow. The motion targets consist of position transitions and shape changes of the tracked objects, thus the model has to consider multiple frames comprehensively. Besides, to help the model capture fine-grained motion details, we enforce the model to predict trajectory motion targets in high temporal resolution based on a video in low temporal resolution. After pre-training using our M$^3$Video task, the model is able to anticipate fine-grained motion details even taking a sparsely sampled video as input. We conduct extensive experiments on four benchmark datasets. Remarkably, when doing pre-training with 400 epochs, we improve the accuracy from 67.6\\% to 69.2\\% and from 78.8\\% to 79.7\\% on Something-Something V2 and Kinetics-400 datasets, respectively. ",
    "url": "https://arxiv.org/abs/2210.06096",
    "authors": [
      "Xinyu Sun",
      "Peihao Chen",
      "Liangwei Chen",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06105",
    "title": "SpecRNet: Towards Faster and More Accessible Audio DeepFake Detection",
    "abstract": "Audio DeepFakes are utterances generated with the use of deep neural networks. They are highly misleading and pose a threat due to use in fake news, impersonation, or extortion. In this work, we focus on increasing accessibility to the audio DeepFake detection methods by providing SpecRNet, a neural network architecture characterized by a quick inference time and low computational requirements. Our benchmark shows that SpecRNet, requiring up to about 40% less time to process an audio sample, provides performance comparable to LCNN architecture - one of the best audio DeepFake detection models. Such a method can not only be used by online multimedia services to verify a large bulk of content uploaded daily but also, thanks to its low requirements, by average citizens to evaluate materials on their devices. In addition, we provide benchmarks in three unique settings that confirm the correctness of our model. They reflect scenarios of low-resource datasets, detection on short utterances and limited attacks benchmark in which we take a closer look at the influence of particular attacks on given architectures. ",
    "url": "https://arxiv.org/abs/2210.06105",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.06106",
    "title": "DiPA: Diverse and Probabilistically Accurate Interactive Prediction",
    "abstract": "Accurate prediction is important for operating an autonomous vehicle in interactive scenarios. Previous interactive predictors have used closest-mode evaluations, which test if one of a set of predictions covers the ground-truth, but not if additional unlikely predictions are made. The presence of unlikely predictions can interfere with planning, by indicating conflict with the ego plan when it is not likely to occur. Closest-mode evaluations are not sufficient for showing a predictor is useful, an effective predictor also needs to accurately estimate mode probabilities, and to be evaluated using probabilistic measures. These two evaluation approaches, eg. predicted-mode RMS and minADE/FDE, are analogous to precision and recall in binary classification, and there is a challenging trade-off between prediction strategies for each. We present DiPA, a method for producing diverse predictions while also capturing accurate probabilistic estimates. DiPA uses a flexible representation that captures interactions in widely varying road topologies, and uses a novel training regime for a Gaussian Mixture Model that supports diversity of predicted modes, along with accurate spatial distribution and mode probability estimates. DiPA achieves state-of-the-art performance on INTERACTION and NGSIM, and improves over a baseline (MFP) when both closest-mode and probabilistic evaluations are used at the same time. ",
    "url": "https://arxiv.org/abs/2210.06106",
    "authors": [
      "Anthony Knittel",
      "Majd Hawasly",
      "Stefano V. Albrecht",
      "John Redford",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06118",
    "title": "Towards Mining Creative Thinking Patterns from Educational Data",
    "abstract": "Creativity, i.e., the process of generating and developing fresh and original ideas or products that are useful or effective, is a valuable skill in a variety of domains. Creativity is called an essential 21st-century skill that should be taught in schools. The use of educational technology to promote creativity is an active study field, as evidenced by several studies linking creativity in the classroom to beneficial learning outcomes. Despite the burgeoning body of research on adaptive technology for education, mining creative thinking patterns from educational data remains a challenging task. In this paper, to address this challenge, we put the first step towards formalizing educational knowledge by constructing a domain-specific Knowledge Base to identify essential concepts, facts, and assumptions in identifying creative patterns. We then introduce a pipeline to contextualize the raw educational data, such as assessments and class activities. Finally, we present a rule-based approach to learning from the Knowledge Base, and facilitate mining creative thinking patterns from contextualized data and knowledge. We evaluate our approach with real-world datasets and highlight how the proposed pipeline can help instructors understand creative thinking patterns from students' activities and assessment tasks. ",
    "url": "https://arxiv.org/abs/2210.06118",
    "authors": [
      "Nasrin Shabani"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06121",
    "title": "Specializing Scope Graph Resolution Queries: Extended Edition",
    "abstract": "To warrant programmer productivity, type checker results should be correct and available quickly. Correctness can be provided when a type checker implementation corresponds to a declarative type system specification. Statix is a type system specification language which achieves this by automatically deriving type checker implementations from declarative typing rules. A key feature of Statix is that it uses scope graphs for declarative specification of name resolution. However, compared to hand-written type checkers, type checkers derived from Statix specifications have sub-optimal run time performance. In this paper, we identify and resolve a performance bottleneck in the Statix solver, namely part of the name resolution algorithm, using partial evaluation. To this end, we introduce a tailored procedural intermediate query resolution language, and provide a specializer that translates declarative queries to this language. Evaluating this specializer by comparing type checking run time performance on three benchmarks (Apache Commons CSV, IO, and Lang3), shows that our specializer improves query resolution time up to 7.7x, which reduces the total type checking run time by 38 - 48%. ",
    "url": "https://arxiv.org/abs/2210.06121",
    "authors": [
      "Aron Zwaan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.06126",
    "title": "Regularized Graph Structure Learning with Semantic Knowledge for  Multi-variates Time-Series Forecasting",
    "abstract": "Multivariate time-series forecasting is a critical task for many applications, and graph time-series network is widely studied due to its capability to capture the spatial-temporal correlation simultaneously. However, most existing works focus more on learning with the explicit prior graph structure, while ignoring potential information from the implicit graph structure, yielding incomplete structure modeling. Some recent works attempt to learn the intrinsic or implicit graph structure directly while lacking a way to combine explicit prior structure with implicit structure together. In this paper, we propose Regularized Graph Structure Learning (RGSL) model to incorporate both explicit prior structure and implicit structure together, and learn the forecasting deep networks along with the graph structure. RGSL consists of two innovative modules. First, we derive an implicit dense similarity matrix through node embedding, and learn the sparse graph structure using the Regularized Graph Generation (RGG) based on the Gumbel Softmax trick. Second, we propose a Laplacian Matrix Mixed-up Module (LM3) to fuse the explicit graph and implicit graph together. We conduct experiments on three real-word datasets. Results show that the proposed RGSL model outperforms existing graph forecasting algorithms with a notable margin, while learning meaningful graph structure simultaneously. Our code and models are made publicly available at https://github.com/alipay/RGSL.git. ",
    "url": "https://arxiv.org/abs/2210.06126",
    "authors": [
      "Hongyuan Yu",
      "Ting Li",
      "Weichen Yu",
      "Jianguo Li",
      "Yan Huang",
      "Liang Wang",
      "Alex Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06138",
    "title": "Improved Data Augmentation for Translation Suggestion",
    "abstract": "Translation suggestion (TS) models are used to automatically provide alternative suggestions for incorrect spans in sentences generated by machine translation. This paper introduces the system used in our submission to the WMT'22 Translation Suggestion shared task. Our system is based on the ensemble of different translation architectures, including Transformer, SA-Transformer, and DynamicConv. We use three strategies to construct synthetic data from parallel corpora to compensate for the lack of supervised data. In addition, we introduce a multi-phase pre-training strategy, adding an additional pre-training phase with in-domain data. We rank second and third on the English-German and English-Chinese bidirectional tasks, respectively. ",
    "url": "https://arxiv.org/abs/2210.06138",
    "authors": [
      "Hongxiao Zhang",
      "Siyu Lai",
      "Songming Zhang",
      "Hui Huang",
      "Yufeng Chen",
      "Jinan Xu",
      "Jian Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06163",
    "title": "Privacy of federated QR decomposition using additive secure multiparty  computation",
    "abstract": "Federated learning (FL) is a privacy-aware data mining strategy keeping the private data on the owners' machine and thereby confidential. The clients compute local models and send them to an aggregator which computes a global model. In hybrid FL, the local parameters are additionally masked using secure aggregation, such that only the global aggregated statistics become available in clear text, not the client specific updates. Federated QR decomposition has not been studied extensively in the context of cross-silo federated learning. In this article, we investigate the suitability of three QR decomposition algorithms for cross-silo FL and suggest a privacy-aware QR decomposition scheme based on the Gram-Schmidt algorithm which does not blatantly leak raw data. We apply the algorithm to compute linear regression in a federated manner. ",
    "url": "https://arxiv.org/abs/2210.06163",
    "authors": [
      "Anne Hartebrodt",
      "Richard R\u00f6ttger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06177",
    "title": "VCSE: Time-Domain Visual-Contextual Speaker Extraction Network",
    "abstract": "Speaker extraction seeks to extract the target speech in a multi-talker scenario given an auxiliary reference. Such reference can be auditory, i.e., a pre-recorded speech, visual, i.e., lip movements, or contextual, i.e., phonetic sequence. References in different modalities provide distinct and complementary information that could be fused to form top-down attention on the target speaker. Previous studies have introduced visual and contextual modalities in a single model. In this paper, we propose a two-stage time-domain visual-contextual speaker extraction network named VCSE, which incorporates visual and self-enrolled contextual cues stage by stage to take full advantage of every modality. In the first stage, we pre-extract a target speech with visual cues and estimate the underlying phonetic sequence. In the second stage, we refine the pre-extracted target speech with the self-enrolled contextual cues. Experimental results on the real-world Lip Reading Sentences 3 (LRS3) database demonstrate that our proposed VCSE network consistently outperforms other state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2210.06177",
    "authors": [
      "Junjie Li",
      "Meng Ge",
      "Zexu Pan",
      "Longbiao Wang",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.06183",
    "title": "Transfer Learning on Heterogeneous Feature Spaces for Treatment Effects  Estimation",
    "abstract": "Consider the problem of improving the estimation of conditional average treatment effects (CATE) for a target domain of interest by leveraging related information from a source domain with a different feature space. This heterogeneous transfer learning problem for CATE estimation is ubiquitous in areas such as healthcare where we may wish to evaluate the effectiveness of a treatment for a new patient population for which different clinical covariates and limited data are available. In this paper, we address this problem by introducing several building blocks that use representation learning to handle the heterogeneous feature spaces and a flexible multi-task architecture with shared and private layers to transfer information between potential outcome functions across domains. Then, we show how these building blocks can be used to recover transfer learning equivalents of the standard CATE learners. On a new semi-synthetic data simulation benchmark for heterogeneous transfer learning we not only demonstrate performance improvements of our heterogeneous transfer causal effect learners across datasets, but also provide insights into the differences between these learners from a transfer perspective. ",
    "url": "https://arxiv.org/abs/2210.06183",
    "authors": [
      "Ioana Bica",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.06186",
    "title": "Gotcha: A Challenge-Response System for Real-Time Deepfake Detection",
    "abstract": "The integrity of online video interactions is threatened by the widespread rise of AI-enabled high-quality deepfakes that are now deployable in real-time. This paper presents Gotcha, a real-time deepfake detection system for live video interactions. The core principle underlying Gotcha is the presentation of a specially chosen cascade of both active and passive challenges to video conference participants. Active challenges include inducing changes in face occlusion, face expression, view angle, and ambiance; passive challenges include digital manipulation of the webcam feed. The challenges are designed to target vulnerabilities in the structure of modern deepfake generators and create perceptible artifacts for the human eye while inducing robust signals for ML-based automatic deepfake detectors. We present a comprehensive taxonomy of a large set of challenge tasks, which reveals a natural hierarchy among different challenges. Our system leverages this hierarchy by cascading progressively more demanding challenges to a suspected deepfake. We evaluate our system on a novel dataset of live users emulating deepfakes and show that our system provides consistent, measurable degradation of deepfake quality, showcasing its promise for robust real-time deepfake detection when deployed in the wild. ",
    "url": "https://arxiv.org/abs/2210.06186",
    "authors": [
      "Govind Mittal",
      "Jiraphon Yenphraphai",
      "Chinmay Hegde",
      "Nasir Memon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06188",
    "title": "Anomaly Detection using Generative Models and Sum-Product Networks in  Mammography Scans",
    "abstract": "Unsupervised anomaly detection models which are trained solely by healthy data, have gained importance in the recent years, as the annotation of medical data is a tedious task. Autoencoders and generative adversarial networks are the standard anomaly detection methods that are utilized to learn the data distribution. However, they fall short when it comes to inference and evaluation of the likelihood of test samples. We propose a novel combination of generative models and a probabilistic graphical model. After encoding image samples by autoencoders, the distribution of data is modeled by Random and Tensorized Sum-Product Networks ensuring exact and efficient inference at test time. We evaluate different autoencoder architectures in combination with Random and Tensorized Sum-Product Networks on mammography images using patch-wise processing and observe superior performance over utilizing the models standalone and state-of-the-art in anomaly detection for medical data. ",
    "url": "https://arxiv.org/abs/2210.06188",
    "authors": [
      "Marc Dietrichstein",
      "David Major",
      "Maria Wimmer",
      "Dimitrios Lenis",
      "Philip Winter",
      "Astrid Berg",
      "Theresa Neubauer",
      "Katja B\u00fchler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06192",
    "title": "Pose-Guided Graph Convolutional Networks for Skeleton-Based Action  Recognition",
    "abstract": "Graph convolutional networks (GCNs), which can model the human body skeletons as spatial and temporal graphs, have shown remarkable potential in skeleton-based action recognition. However, in the existing GCN-based methods, graph-structured representation of the human skeleton makes it difficult to be fused with other modalities, especially in the early stages. This may limit their scalability and performance in action recognition tasks. In addition, the pose information, which naturally contains informative and discriminative clues for action recognition, is rarely explored together with skeleton data in existing methods. In this work, we propose pose-guided GCN (PG-GCN), a multi-modal framework for high-performance human action recognition. In particular, a multi-stream network is constructed to simultaneously explore the robust features from both the pose and skeleton data, while a dynamic attention module is designed for early-stage feature fusion. The core idea of this module is to utilize a trainable graph to aggregate features from the skeleton stream with that of the pose stream, which leads to a network with more robust feature representation ability. Extensive experiments show that the proposed PG-GCN can achieve state-of-the-art performance on the NTU RGB+D 60 and NTU RGB+D 120 datasets. ",
    "url": "https://arxiv.org/abs/2210.06192",
    "authors": [
      "Han Chen",
      "Yifan Jiang",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.06201",
    "title": "Diffusion Models for Causal Discovery via Topological Ordering",
    "abstract": "Discovering causal relations from observational data becomes possible with additional assumptions such as considering the functional relations to be constrained as nonlinear with additive noise. In this case, the Hessian of the data log-likelihood can be used for finding leaf nodes in a causal graph. Topological ordering approaches for causal discovery exploit this by performing graph discovery in two steps, first sequentially identifying nodes in reverse order of depth (topological ordering), and secondly pruning the potential relations. This is more efficient since the search is performed over a permutation rather than a graph space. However, existing computational methods for obtaining the Hessian still do not scale as the number of variables and the number of samples are increased. Therefore, inspired by recent innovations in diffusion probabilistic models (DPMs), we propose DiffAN, a topological ordering algorithm that leverages DPMs. Further, we introduce theory for updating the learned Hessian without re-training the neural network, and we show that computing with a subset of samples gives an accurate approximation of the ordering, which allows scaling to datasets with more samples and variables. We show empirically that our method scales exceptionally well to datasets with up to $500$ nodes and up to $10^5$ samples while still performing on par over small datasets with state-of-the-art causal discovery methods. Implementation is available at https://github.com/vios-s/DiffAN . ",
    "url": "https://arxiv.org/abs/2210.06201",
    "authors": [
      "Pedro Sanchez",
      "Xiao Liu",
      "Alison Q O'Neil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06223",
    "title": "Latency-aware Spatial-wise Dynamic Networks",
    "abstract": "Spatial-wise dynamic convolution has become a promising approach to improving the inference efficiency of deep networks. By allocating more computation to the most informative pixels, such an adaptive inference paradigm reduces the spatial redundancy in image features and saves a considerable amount of unnecessary computation. However, the theoretical efficiency achieved by previous methods can hardly translate into a realistic speedup, especially on the multi-core processors (e.g. GPUs). The key challenge is that the existing literature has only focused on designing algorithms with minimal computation, ignoring the fact that the practical latency can also be influenced by scheduling strategies and hardware properties. To bridge the gap between theoretical computation and practical efficiency, we propose a latency-aware spatial-wise dynamic network (LASNet), which performs coarse-grained spatially adaptive inference under the guidance of a novel latency prediction model. The latency prediction model can efficiently estimate the inference latency of dynamic networks by simultaneously considering algorithms, scheduling strategies, and hardware properties. We use the latency predictor to guide both the algorithm design and the scheduling optimization on various hardware platforms. Experiments on image classification, object detection and instance segmentation demonstrate that the proposed framework significantly improves the practical inference efficiency of deep networks. For example, the average latency of a ResNet-101 on the ImageNet validation set could be reduced by 36% and 46% on a server GPU (Nvidia Tesla-V100) and an edge device (Nvidia Jetson TX2 GPU) respectively without sacrificing the accuracy. Code is available at https://github.com/LeapLabTHU/LASNet. ",
    "url": "https://arxiv.org/abs/2210.06223",
    "authors": [
      "Yizeng Han",
      "Zhihang Yuan",
      "Yifan Pu",
      "Chenhao Xue",
      "Shiji Song",
      "Guangyu Sun",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06225",
    "title": "On the Generalizability of ECG-based Stress Detection Models",
    "abstract": "Stress is prevalent in many aspects of everyday life including work, healthcare, and social interactions. Many works have studied handcrafted features from various bio-signals that are indicators of stress. Recently, deep learning models have also been proposed to detect stress. Typically, stress models are trained and validated on the same dataset, often involving one stressful scenario. However, it is not practical to collect stress data for every scenario. So, it is crucial to study the generalizability of these models and determine to what extent they can be used in other scenarios. In this paper, we explore the generalization capabilities of Electrocardiogram (ECG)-based deep learning models and models based on handcrafted ECG features, i.e., Heart Rate Variability (HRV) features. To this end, we train three HRV models and two deep learning models that use ECG signals as input. We use ECG signals from two popular stress datasets - WESAD and SWELL-KW - differing in terms of stressors and recording devices. First, we evaluate the models using leave-one-subject-out (LOSO) cross-validation using training and validation samples from the same dataset. Next, we perform a cross-dataset validation of the models, that is, LOSO models trained on the WESAD dataset are validated using SWELL-KW samples and vice versa. While deep learning models achieve the best results on the same dataset, models based on HRV features considerably outperform them on data from a different dataset. This trend is observed for all the models on both datasets. Therefore, HRV models are a better choice for stress recognition in applications that are different from the dataset scenario. To the best of our knowledge, this is the first work to compare the cross-dataset generalizability between ECG-based deep learning models and HRV models. ",
    "url": "https://arxiv.org/abs/2210.06225",
    "authors": [
      "Pooja Prajod",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06240",
    "title": "Explore Contextual Information for 3D Scene Graph Generation",
    "abstract": "3D scene graph generation (SGG) has been of high interest in computer vision. Although the accuracy of 3D SGG on coarse classification and single relation label has been gradually improved, the performance of existing works is still far from being perfect for fine-grained and multi-label situations. In this paper, we propose a framework fully exploring contextual information for the 3D SGG task, which attempts to satisfy the requirements of fine-grained entity class, multiple relation labels, and high accuracy simultaneously. Our proposed approach is composed of a Graph Feature Extraction module and a Graph Contextual Reasoning module, achieving appropriate information-redundancy feature extraction, structured organization, and hierarchical inferring. Our approach achieves superior or competitive performance over previous methods on the 3DSSG dataset, especially on the relationship prediction sub-task. ",
    "url": "https://arxiv.org/abs/2210.06240",
    "authors": [
      "Yuanyuan Liu",
      "Chengjiang Long",
      "Zhaoxuan Zhang",
      "Bokai Liu",
      "Qiang Zhang",
      "Baocai Yin",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06242",
    "title": "Entity Aware Negative Sampling with Auxiliary Loss of False Negative  Prediction for Knowledge Graph Embedding",
    "abstract": "Knowledge graph (KG) embedding is widely used in many downstream applications using KGs. Generally, since KGs contain only ground truth triples, it is necessary to construct arbitrary negative samples for representation learning of KGs. Recently, various methods for sampling high-quality negatives have been studied because the quality of negative triples has great effect on KG embedding. In this paper, we propose a novel method called Entity Aware Negative Sampling (EANS), which is able to sample negative entities resemble to positive one by adopting Gaussian distribution to the aligned entity index space. Additionally, we introduce auxiliary loss for false negative prediction that can alleviate the impact of the sampled false negative triples. The proposed method can generate high-quality negative samples regardless of negative sample size and effectively mitigate the influence of false negative samples. The experimental results on standard benchmarks show that our EANS outperforms existing the state-of-the-art methods of negative sampling on several knowledge graph embedding models. Moreover, the proposed method achieves competitive performance even when the number of negative samples is limited to only one. ",
    "url": "https://arxiv.org/abs/2210.06242",
    "authors": [
      "Sang-Hyun Je"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06272",
    "title": "Deep Koopman Representation of Nonlinear Time Varying Systems",
    "abstract": "A data-driven method is developed to approximate an nonlinear time-varying system (NTVS) by a linear time-varying system (LTVS), based on Koopman Operator and deep neural networks. Analysis on the approximation error in system states of the proposed method is investigated. It is further shown by simulation on a simple NTVS that the resulted LTVS approximate the NTVS very well with small approximation errors in states. Furthermore, simulations on a cartpole further show that optimal controller developed based on the achieved LTVS works very well to control the original NTVS. ",
    "url": "https://arxiv.org/abs/2210.06272",
    "authors": [
      "Wenjian Hao",
      "Bowen Huang",
      "Wei Pan",
      "Di Wu",
      "Shaoshuai Mou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.06281",
    "title": "TwiRGCN: Temporally Weighted Graph Convolution for Question Answering  over Temporal Knowledge Graphs",
    "abstract": "Recent years have witnessed much interest in temporal reasoning over knowledge graphs (KG) for complex question answering (QA), but there remains a substantial gap in human capabilities. We explore how to generalize relational graph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose a novel, intuitive and interpretable scheme to modulate the messages passed through a KG edge during convolution, based on the relevance of its associated time period to the question. We also introduce a gating device to predict if the answer to a complex temporal question is likely to be a KG entity or time and use this prediction to guide our scoring mechanism. We evaluate the resulting system, which we call TwiRGCN, on TimeQuestions, a recently released, challenging dataset for multi-hop complex temporal QA. We show that TwiRGCN significantly outperforms state-of-the-art systems on this dataset across diverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage points for the most difficult ordinal and implicit question types. ",
    "url": "https://arxiv.org/abs/2210.06281",
    "authors": [
      "Aditya Sharma",
      "Apoorv Saxena",
      "Chitrank Gupta",
      "Seyed Mehran Kazemi",
      "Partha Talukdar",
      "Soumen Chakrabarti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06282",
    "title": "Towards Generalized and Explainable Long-Range Context Representation  for Dialogue Systems",
    "abstract": "Context representation is crucial to both dialogue understanding and generation. Recently, the most popular method for dialog context representation is to concatenate the last-$k$ previous utterances as context and use a large transformer-based model to generate the next response. However, this method may not be ideal for conversations containing long-range dependencies. In this work, we propose DialoGX, a novel encoder-decoder based framework for conversational response generation with a generalized and explainable context representation that can look beyond the last-$k$ utterances. Hence the method is adaptive to conversations with long-range dependencies. Our proposed solution is based on two key ideas: a) computing a dynamic representation of the entire context, and b) finding the previous utterances that are relevant for generating the next response. Instead of last-$k$ utterances, DialoGX uses the concatenation of the dynamic context vector and encoding of the most relevant utterances as input which enables it to represent conversations of any length in a compact and generalized fashion. We conduct our experiments on DailyDialog, a popular open-domain chit-chat dataset. DialoGX achieves comparable performance with the state-of-the-art models on the automated metrics. We also justify our context representation through the lens of psycholinguistics and show that the relevance score of previous utterances agrees well with human cognition which makes DialoGX explainable as well. ",
    "url": "https://arxiv.org/abs/2210.06282",
    "authors": [
      "Suvodip Dey",
      "Maunendra Sankar Desarkar",
      "P. K. Srijith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06284",
    "title": "Visual Prompting for Adversarial Robustness",
    "abstract": "In this work, we leverage visual prompting (VP) to improve adversarial robustness of a fixed, pre-trained model at testing time. Compared to conventional adversarial defenses, VP allows us to design universal (i.e., data-agnostic) input prompting templates, which have plug-and-play capabilities at testing time to achieve desired model performance without introducing much computation overhead. Although VP has been successfully applied to improving model generalization, it remains elusive whether and how it can be used to defend against adversarial attacks. We investigate this problem and show that the vanilla VP approach is not effective in adversarial defense since a universal input prompt lacks the capacity for robust learning against sample-specific adversarial perturbations. To circumvent it, we propose a new VP method, termed Class-wise Adversarial Visual Prompting (C-AVP), to generate class-wise visual prompts so as to not only leverage the strengths of ensemble prompts but also optimize their interrelations to improve model robustness. Our experiments show that C-AVP outperforms the conventional VP method, with 2.1X standard accuracy gain and 2X robust accuracy gain. Compared to classical test-time defenses, C-AVP also yields a 42X inference time speedup. ",
    "url": "https://arxiv.org/abs/2210.06284",
    "authors": [
      "Aochuan Chen",
      "Peter Lorenz",
      "Yuguang Yao",
      "Pin-Yu Chen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06289",
    "title": "An Efficient and Robust Object-Level Cooperative Perception Framework  for Connected and Automated Driving",
    "abstract": "Cooperative perception is challenging for connected and automated driving because of the real-time requirements and bandwidth limitation, especially when the vehicle location and pose information are inaccurate. We propose an efficient object-level cooperative perception framework, in which data of the 3D bounding boxes, location, and pose are broadcast and received between the connected vehicles, then fused at the object level. Two Iterative Closest Point (ICP) and Optimal Transport theory-based matching algorithms are developed to maximize the total correlations between the 3D bounding boxes jointly detected by the vehicles. Experiment results show that it only takes 5ms to associate objects from different vehicles for each frame, and robust performance is achieved for different levels of location and heading errors. Meanwhile, the proposed framework outperforms the state-of-the-art benchmark methods when location or pose errors occur. ",
    "url": "https://arxiv.org/abs/2210.06289",
    "authors": [
      "Zhiying Song",
      "Fuxi Wen",
      "Hailiang Zhang",
      "Jun Li"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06302",
    "title": "Maximum entropy exploration in contextual bandits with neural networks  and energy based models",
    "abstract": "Contextual bandits can solve a huge range of real-world problems. However, current popular algorithms to solve them either rely on linear models, or unreliable uncertainty estimation in non-linear models, which are required to deal with the exploration-exploitation trade-off. Inspired by theories of human cognition, we introduce novel techniques that use maximum entropy exploration, relying on neural networks to find optimal policies in settings with both continuous and discrete action spaces. We present two classes of models, one with neural networks as reward estimators, and the other with energy based models, which model the probability of obtaining an optimal reward given an action. We evaluate the performance of these models in static and dynamic contextual bandit simulation environments. We show that both techniques outperform well-known standard algorithms, where energy based models have the best overall performance. This provides practitioners with new techniques that perform well in static and dynamic settings, and are particularly well suited to non-linear scenarios with continuous action spaces. ",
    "url": "https://arxiv.org/abs/2210.06302",
    "authors": [
      "Adam Elwood",
      "Marco Leonardi",
      "Ashraf Mohamed",
      "Alessandro Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06312",
    "title": "Changing the Representation: Examining Language Representation for  Neural Sign Language Production",
    "abstract": "Neural Sign Language Production (SLP) aims to automatically translate from spoken language sentences to sign language videos. Historically the SLP task has been broken into two steps; Firstly, translating from a spoken language sentence to a gloss sequence and secondly, producing a sign language video given a sequence of glosses. In this paper we apply Natural Language Processing techniques to the first step of the SLP pipeline. We use language models such as BERT and Word2Vec to create better sentence level embeddings, and apply several tokenization techniques, demonstrating how these improve performance on the low resource translation task of Text to Gloss. We introduce Text to HamNoSys (T2H) translation, and show the advantages of using a phonetic representation for sign language translation rather than a sign level gloss representation. Furthermore, we use HamNoSys to extract the hand shape of a sign and use this as additional supervision during training, further increasing the performance on T2H. Assembling best practise, we achieve a BLEU-4 score of 26.99 on the MineDGS dataset and 25.09 on PHOENIX14T, two new state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2210.06312",
    "authors": [
      "Harry Walsh",
      "Ben Saunders",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06331",
    "title": "RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims  on Social Media",
    "abstract": "We present Reddit Health Online Talk (RedHOT), a corpus of 22,000 richly annotated social media posts from Reddit spanning 24 health conditions. Annotations include demarcations of spans corresponding to medical claims, personal experiences, and questions. We collect additional granular annotations on identified claims. Specifically, we mark snippets that describe patient Populations, Interventions, and Outcomes (PIO elements) within these. Using this corpus, we introduce the task of retrieving trustworthy evidence relevant to a given claim made on social media. We propose a new method to automatically derive (noisy) supervision for this task which we use to train a dense retrieval model; this outperforms baseline models. Manual evaluation of retrieval results performed by medical doctors indicate that while our system performance is promising, there is considerable room for improvement. Collected annotations (and scripts to assemble the dataset), are available at https://github.com/sominw/redhot. ",
    "url": "https://arxiv.org/abs/2210.06331",
    "authors": [
      "Somin Wadhwa",
      "Vivek Khetan",
      "Silvio Amir",
      "Byron Wallace"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06341",
    "title": "TaskMix: Data Augmentation for Meta-Learning of Spoken Intent  Understanding",
    "abstract": "Meta-Learning has emerged as a research direction to better transfer knowledge from related tasks to unseen but related tasks. However, Meta-Learning requires many training tasks to learn representations that transfer well to unseen tasks; otherwise, it leads to overfitting, and the performance degenerates to worse than Multi-task Learning. We show that a state-of-the-art data augmentation method worsens this problem of overfitting when the task diversity is low. We propose a simple method, TaskMix, which synthesizes new tasks by linearly interpolating existing tasks. We compare TaskMix against many baselines on an in-house multilingual intent classification dataset of N-Best ASR hypotheses derived from real-life human-machine telephony utterances and two datasets derived from MTOP. We show that TaskMix outperforms baselines, alleviates overfitting when task diversity is low, and does not degrade performance even when it is high. ",
    "url": "https://arxiv.org/abs/2210.06341",
    "authors": [
      "Surya Kant Sahu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.06346",
    "title": "Predicting the clinical citation count of biomedical papers using  multilayer perceptron neural network",
    "abstract": "The number of clinical citations received from clinical guidelines or clinical trials has been considered as one of the most appropriate indicators for quantifying the clinical impact of biomedical papers. Therefore, the early prediction of the clinical citation count of biomedical papers is critical to scientific activities in biomedicine, such as research evaluation, resource allocation, and clinical translation. In this study, we designed a four-layer multilayer perceptron neural network (MPNN) model to predict the clinical citation count of biomedical papers in the future by using 9,822,620 biomedical papers published from 1985 to 2005. We extracted ninety-one paper features from three dimensions as the input of the model, including twenty-one features in the paper dimension, thirty-five in the reference dimension, and thirty-five in the citing paper dimension. In each dimension, the features can be classified into three categories, i.e., the citation-related features, the clinical translation-related features, and the topic-related features. Besides, in the paper dimension, we also considered the features that have previously been demonstrated to be related to the citation counts of research papers. The results showed that the proposed MPNN model outperformed the other five baseline models, and the features in the reference dimension were the most important. ",
    "url": "https://arxiv.org/abs/2210.06346",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Qikai Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06350",
    "title": "CTL++: Evaluating Generalization on Never-Seen Compositional Patterns of  Known Functions, and Compatibility of Neural Representations",
    "abstract": "Well-designed diagnostic tasks have played a key role in studying the failure of neural nets (NNs) to generalize systematically. Famous examples include SCAN and Compositional Table Lookup (CTL). Here we introduce CTL++, a new diagnostic dataset based on compositions of unary symbolic functions. While the original CTL is used to test length generalization or productivity, CTL++ is designed to test systematicity of NNs, that is, their capability to generalize to unseen compositions of known functions. CTL++ splits functions into groups and tests performance on group elements composed in a way not seen during training. We show that recent CTL-solving Transformer variants fail on CTL++. The simplicity of the task design allows for fine-grained control of task difficulty, as well as many insightful analyses. For example, we measure how much overlap between groups is needed by tested NNs for learning to compose. We also visualize how learned symbol representations in outputs of functions from different groups are compatible in case of success but not in case of failure. These results provide insights into failure cases reported on more complex compositions in the natural language domain. Our code is public. ",
    "url": "https://arxiv.org/abs/2210.06350",
    "authors": [
      "R\u00f3bert Csord\u00e1s",
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.06361",
    "title": "MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection",
    "abstract": "Recent research about camouflaged object detection (COD) aims to segment highly concealed objects hidden in complex surroundings. The tiny, fuzzy camouflaged objects result in visually indistinguishable properties. However, current single-view COD detectors are sensitive to background distractors. Therefore, blurred boundaries and variable shapes of the camouflaged objects are challenging to be fully captured with a single-view detector. To overcome these obstacles, we propose a behavior-inspired framework, called Multi-view Feature Fusion Network (MFFN), which mimics the human behaviors of finding indistinct objects in images, i.e., observing from multiple angles, distances, perspectives. Specifically, the key idea behind it is to generate multiple ways of observation (multi-view) by data augmentation and apply them as inputs. MFFN captures critical edge and semantic information by comparing and fusing extracted multi-view features. In addition, our MFFN exploits the dependence and interaction between views by the designed hierarchical view and channel integration modules. Furthermore, our methods leverage the complementary information between different views through a two-stage attention module called Co-attention of Multi-view (CAMV). And we designed a local-overall module called Channel Fusion Unit (CFU) to explore the channel-wise contextual clues of diverse feature maps in an iterative manner. The experiment results show that our method performs favorably against existing state-of-the-art methods via training with the same data. The code will be available at https: //github.com/dwardzheng/MFFN_COD. ",
    "url": "https://arxiv.org/abs/2210.06361",
    "authors": [
      "Dehua Zheng",
      "Xiaochen Zheng",
      "Laurence T. Yang",
      "Yuan Gao",
      "Chenlu Zhu",
      "Yiheng Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06363",
    "title": "On Extremal Rates of Storage over Graphs",
    "abstract": "A storage code over a graph maps $K$ independent source symbols, each of $L_w$ bits, to $N$ coded symbols, each of $L_v$ bits, such that each coded symbol is stored in a node of the graph and each edge of the graph is associated with one source symbol. From a pair of nodes connected by an edge, the source symbol that is associated with the edge can be decoded. The ratio $L_w/L_v$ is called the symbol rate of a storage code and the highest symbol rate is called the capacity. We show that the three highest capacity values of storage codes over graphs are $2, 3/2, 4/3$. We characterize all graphs over which the storage code capacity is $2$ and $3/2$, and for capacity value of $4/3$, necessary condition and sufficient condition (that do not match) on the graphs are given. ",
    "url": "https://arxiv.org/abs/2210.06363",
    "authors": [
      "Zhou Li",
      "Hua Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.06373",
    "title": "Learning Multi-resolution Functional Maps with Spectral Attention for  Robust Shape Matching",
    "abstract": "In this work, we present a novel non-rigid shape matching framework based on multi-resolution functional maps with spectral attention. Existing functional map learning methods all rely on the critical choice of the spectral resolution hyperparameter, which can severely affect the overall accuracy or lead to overfitting, if not chosen carefully. In this paper, we show that spectral resolution tuning can be alleviated by introducing spectral attention. Our framework is applicable in both supervised and unsupervised settings, and we show that it is possible to train the network so that it can adapt the spectral resolution, depending on the given shape input. More specifically, we propose to compute multi-resolution functional maps that characterize correspondence across a range of spectral resolutions, and introduce a spectral attention network that helps to combine this representation into a single coherent final correspondence. Our approach is not only accurate with near-isometric input, for which a high spectral resolution is typically preferred, but also robust and able to produce reasonable matching even in the presence of significant non-isometric distortion, which poses great challenges to existing methods. We demonstrate the superior performance of our approach through experiments on a suite of challenging near-isometric and non-isometric shape matching benchmarks. ",
    "url": "https://arxiv.org/abs/2210.06373",
    "authors": [
      "Lei Li",
      "Nicolas Donati",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.06386",
    "title": "Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper  Directly-Trained Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatio-temporal information to directly train SNNs by backpropagation. However, the binary and non-differentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level firing (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormant-suppressed residual network (spiking DS-ResNet). MLF enables more efficient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efficiently perform identity mapping of discrete spikes, as well as provide a more suitable connection for gradient propagation in deep SNNs. With the proposed method, our model achieves superior performances on a non-neuromorphic dataset and two neuromorphic datasets with much fewer trainable parameters and demonstrates the great ability to combat the gradient vanishing and degradation problem in deep SNNs. ",
    "url": "https://arxiv.org/abs/2210.06386",
    "authors": [
      "Lang Feng",
      "Qianhui Liu",
      "Huajin Tang",
      "De Ma",
      "Gang Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06391",
    "title": "What Makes Graph Neural Networks Miscalibrated?",
    "abstract": "Given the importance of getting calibrated predictions and reliable uncertainty estimations, various post-hoc calibration methods have been developed for neural networks on standard multi-class classification tasks. However, these methods are not well suited for calibrating graph neural networks (GNNs), which presents unique challenges such as accounting for the graph structure and the graph-induced correlations between the nodes. In this work, we conduct a systematic study on the calibration qualities of GNN node predictions. In particular, we identify five factors which influence the calibration of GNNs: general under-confident tendency, diversity of nodewise predictive distributions, distance to training nodes, relative confidence level, and neighborhood similarity. Furthermore, based on the insights from this study, we design a novel calibration method named Graph Attention Temperature Scaling (GATS), which is tailored for calibrating graph neural networks. GATS incorporates designs that address all the identified influential factors and produces nodewise temperature scaling using an attention-based architecture. GATS is accuracy-preserving, data-efficient, and expressive at the same time. Our experiments empirically verify the effectiveness of GATS, demonstrating that it can consistently achieve state-of-the-art calibration results on various graph datasets for different GNN backbones. ",
    "url": "https://arxiv.org/abs/2210.06391",
    "authors": [
      "Hans Hao-Hsun Hsu",
      "Yuesong Shen",
      "Christian Tomani",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06393",
    "title": "Application Scheduling with Multiplexed Sensing of Monitoring Points in  Multi-purpose IoT Wireless Sensor Networks",
    "abstract": "Wireless sensor networks (WSNs) have many applications and are an essential part of IoT systems. The primary functionality of a WSN is gathering data from specific points that are covered with sensor nodes and transmitting the collected data to remote units for further processing. In IoT use cases, a WSN infrastructure may need to be shared by many applications, which requires scheduling those applications to time-share the node and network resources. In this paper, we investigate the problem of application scheduling in WSN infrastructures. We focus on the scenarios where applications request a set of monitoring points to be sensed in the region a WSN spans and propose a shared-data approach utilizing multiplexed sensing of monitoring points requested by multiple applications, which reduces sensing and communication load on the network. We also propose a genetic algorithm called GABAS, and three greedy algorithms for scheduling applications onto a WSN infrastructure considering different criteria. We performed extensive simulation experiments to evaluate our algorithms and compare them to some standard scheduling methods. The results show that our proposed methods perform much better than the standard scheduling methods in terms of makespan, turnaround time, waiting time, and successful execution rate metrics. We also observed that our genetic algorithm is very effective in scheduling applications with respect to these metrics. ",
    "url": "https://arxiv.org/abs/2210.06393",
    "authors": [
      "Mustafa Can \u00c7avdar",
      "Ibrahim Korpeoglu",
      "\u00d6zg\u00fcr Ulusoy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.06397",
    "title": "Star Anagram Detection and Classification",
    "abstract": "A star anagram is a rearrangement of the letters of one word to produce another word where no letter retains its original neighbors. These maximally shuffled anagrams are rare, comprising only about 5.7% of anagrams in English. They can also be depicted as unicursal polygons with varying forms, including the eponymous stars. We develop automated methods for detecting stars among other anagrams and for classifying them based on their polygon's degree of both rotational and reflective symmetry. Next, we explore several properties of star anagrams including proofs for two results about the edge lengths of perfect, i.e., maximally symmetric, stars leveraging perhaps surprising connections to modular arithmetic and the celebrated Chinese Remainder Theorem. Finally, we conduct an exhaustive search of English for star anagrams and provide numerical results about their clustering into common shapes along with examples of geometrically noteworthy stars. ",
    "url": "https://arxiv.org/abs/2210.06397",
    "authors": [
      "Jason Parker",
      "Dan Barker"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2210.06404",
    "title": "Graph Neural Network Surrogate for seismic reliability analysis of  highway bridge system",
    "abstract": "Rapid reliability assessment of transportation networks can enhance preparedness, risk mitigation and response management procedures related to these systems. Network reliability approaches commonly consider network-level responses, and due to computational cost do not consider the more detailed node-level responses. In this paper, we propose a rapid seismic reliability assessment approach for bridge networks based on graph neural networks, where node-level connectivities, between points of interest and other nodes, are quantified under probabilistic bridge conditions and earthquake events. Via numerical experiments on transportation systems in California, we demonstrate the accuracy, computational efficiency and robustness of the proposed approach compared to the Monte Carlo approach. ",
    "url": "https://arxiv.org/abs/2210.06404",
    "authors": [
      "Tong Liu",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06417",
    "title": "BiaScope: Visual Unfairness Diagnosis for Graph Embeddings",
    "abstract": "The issue of bias (i.e., systematic unfairness) in machine learning models has recently attracted the attention of both researchers and practitioners. For the graph mining community in particular, an important goal toward algorithmic fairness is to detect and mitigate bias incorporated into graph embeddings since they are commonly used in human-centered applications, e.g., social-media recommendations. However, simple analytical methods for detecting bias typically involve aggregate statistics which do not reveal the sources of unfairness. Instead, visual methods can provide a holistic fairness characterization of graph embeddings and help uncover the causes of observed bias. In this work, we present BiaScope, an interactive visualization tool that supports end-to-end visual unfairness diagnosis for graph embeddings. The tool is the product of a design study in collaboration with domain experts. It allows the user to (i) visually compare two embeddings with respect to fairness, (ii) locate nodes or graph communities that are unfairly embedded, and (iii) understand the source of bias by interactively linking the relevant embedding subspace with the corresponding graph topology. Experts' feedback confirms that our tool is effective at detecting and diagnosing unfairness. Thus, we envision our tool both as a companion for researchers in designing their algorithms as well as a guide for practitioners who use off-the-shelf graph embeddings. ",
    "url": "https://arxiv.org/abs/2210.06417",
    "authors": [
      "Agapi Rissaki",
      "Bruno Scarone",
      "David Liu",
      "Aditeya Pandey",
      "Brennan Klein",
      "Tina Eliassi-Rad",
      "Michelle A. Borkin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.06418",
    "title": "Relational Graph Convolutional Neural Networks for Multihop Reasoning: A  Comparative Study",
    "abstract": "Multihop Question Answering is a complex Natural Language Processing task that requires multiple steps of reasoning to find the correct answer to a given question. Previous research has explored the use of models based on Graph Neural Networks for tackling this task. Various architectures have been proposed, including Relational Graph Convolutional Networks (RGCN). For these many node types and relations between them have been introduced, such as simple entity co-occurrences, modelling coreferences, or \"reasoning paths\" from questions to answers via intermediary entities. Nevertheless, a thoughtful analysis on which relations, node types, embeddings and architecture are the most beneficial for this task is still missing. In this paper we explore a number of RGCN-based Multihop QA models, graph relations, and node embeddings, and empirically explore the influence of each on Multihop QA performance on the WikiHop dataset. ",
    "url": "https://arxiv.org/abs/2210.06418",
    "authors": [
      "Ieva Stali\u016bnait\u0117",
      "Philip John Gorinski",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06428",
    "title": "Trap and Replace: Defending Backdoor Attacks by Trapping Them into an  Easy-to-Replace Subnetwork",
    "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks. Previous works have shown it extremely challenging to unlearn the undesired backdoor behavior from the network, since the entire network can be affected by the backdoor samples. In this paper, we propose a brand-new backdoor defense strategy, which makes it much easier to remove the harmful influence of backdoor samples from the model. Our defense strategy, \\emph{Trap and Replace}, consists of two stages. In the first stage, we bait and trap the backdoors in a small and easy-to-replace subnetwork. Specifically, we add an auxiliary image reconstruction head on top of the stem network shared with a light-weighted classification head. The intuition is that the auxiliary image reconstruction task encourages the stem network to keep sufficient low-level visual features that are hard to learn but semantically correct, instead of overfitting to the easy-to-learn but semantically incorrect backdoor correlations. As a result, when trained on backdoored datasets, the backdoors are easily baited towards the unprotected classification head, since it is much more vulnerable than the shared stem, leaving the stem network hardly poisoned. In the second stage, we replace the poisoned light-weighted classification head with an untainted one, by re-training it from scratch only on a small holdout dataset with clean samples, while fixing the stem network. As a result, both the stem and the classification head in the final network are hardly affected by backdoor training samples. We evaluate our method against ten different backdoor attacks. Our method outperforms previous state-of-the-art methods by up to $20.57\\%$, $9.80\\%$, and $13.72\\%$ attack success rate and on-average $3.14\\%$, $1.80\\%$, and $1.21\\%$ clean classification accuracy on CIFAR10, GTSRB, and ImageNet-12, respectively. Code is available online. ",
    "url": "https://arxiv.org/abs/2210.06428",
    "authors": [
      "Haotao Wang",
      "Junyuan Hong",
      "Aston Zhang",
      "Jiayu Zhou",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06433",
    "title": "Self-supervised video pretraining yields strong image representations",
    "abstract": "Videos contain far more information than still images and hold the potential for learning rich representations of the visual world. Yet, pretraining on image datasets has remained the dominant paradigm for learning representations that capture spatial information, and previous attempts at video pretraining have fallen short on image understanding tasks. In this work we revisit self-supervised learning of image representations from the dynamic evolution of video frames. To that end, we propose a dataset curation procedure that addresses the domain mismatch between video and image datasets, and develop a contrastive learning framework which handles the complex transformations present in natural videos. This simple paradigm for distilling knowledge from videos to image representations, called VITO, performs surprisingly well on a variety of image-based transfer learning tasks. For the first time, our video-pretrained model closes the gap with ImageNet pretraining on semantic segmentation on PASCAL and ADE20K and object detection on COCO and LVIS, suggesting that video-pretraining could become the new default for learning image representations. ",
    "url": "https://arxiv.org/abs/2210.06433",
    "authors": [
      "Nikhil Parthasarathy",
      "S. M. Ali Eslami",
      "Jo\u00e3o Carreira",
      "Olivier J. H\u00e9naff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06464",
    "title": "Predictive Querying for Autoregressive Neural Sequence Models",
    "abstract": "In reasoning about sequential events it is natural to pose probabilistic queries such as \"when will event A occur next\" or \"what is the probability of A occurring before B\", with applications in areas such as user modeling, medicine, and finance. However, with machine learning shifting towards neural autoregressive models such as RNNs and transformers, probabilistic querying has been largely restricted to simple cases such as next-event prediction. This is in part due to the fact that future querying involves marginalization over large path spaces, which is not straightforward to do efficiently in such models. In this paper we introduce a general typology for predictive queries in neural autoregressive sequence models and show that such queries can be systematically represented by sets of elementary building blocks. We leverage this typology to develop new query estimation methods based on beam search, importance sampling, and hybrids. Across four large-scale sequence datasets from different application domains, as well as for the GPT-2 language model, we demonstrate the ability to make query answering tractable for arbitrary queries in exponentially-large predictive path-spaces, and find clear differences in cost-accuracy tradeoffs between search and sampling methods. ",
    "url": "https://arxiv.org/abs/2210.06464",
    "authors": [
      "Alex Boyd",
      "Sam Showalter",
      "Stephan Mandt",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06466",
    "title": "Prompt Generation Networks for Efficient Adaptation of Frozen Vision  Transformers",
    "abstract": "Large-scale pretrained models, especially those trained from vision-language data have demonstrated the tremendous value that can be gained from both larger training datasets and models. Thus, in order to benefit from these developments, there is renewed interest in transfer learning and adapting models from large-scale general pretraining to particular downstream tasks. However, the continuously increasing size of the models means that even the classic approach of finetuning is becoming infeasible for all but big institutions. Prompt leaning has emerged as a flexible way to adapt models by solely learning additional inputs to a model that is kept frozen, but so far performances remained inferior to finetuning. To address this, we propose the Prompt Generation Network (PGN) that generates input-dependent prompts by sampling from a learned library of tokens. We show the PGN is effective in adapting pretrained models to various new datasets. It surpasses previous prompt-learning methods by a large margin and even fullfinetuning on 5 out of 12 datasets while requiring 100x less parameters. PGN can even be used for training and inferring on multiple datasets simultaneously and learns to allocate tokens between domains. Given these findings, we conclude that PGN is a viable and scalable approach for downstream adaptation of frozen models. Code is available at https://github.com/jochemloedeman/PGN. ",
    "url": "https://arxiv.org/abs/2210.06466",
    "authors": [
      "Jochem Loedeman",
      "Maarten C. Stol",
      "Tengda Han",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05686",
    "title": "Neural Importance Sampling for Rapid and Reliable Gravitational-Wave  Inference",
    "abstract": "We combine amortized neural posterior estimation with importance sampling for fast and accurate gravitational-wave inference. We first generate a rapid proposal for the Bayesian posterior using neural networks, and then attach importance weights based on the underlying likelihood and prior. This provides (1) a corrected posterior free from network inaccuracies, (2) a performance diagnostic (the sample efficiency) for assessing the proposal and identifying failure cases, and (3) an unbiased estimate of the Bayesian evidence. By establishing this independent verification and correction mechanism we address some of the most frequent criticisms against deep learning for scientific inference. We carry out a large study analyzing 42 binary black hole mergers observed by LIGO and Virgo with the SEOBNRv4PHM and IMRPhenomXPHM waveform models. This shows a median sample efficiency of $\\approx 10\\%$ (two orders-of-magnitude better than standard samplers) as well as a ten-fold reduction in the statistical uncertainty in the log evidence. Given these advantages, we expect a significant impact on gravitational-wave inference, and for this approach to serve as a paradigm for harnessing deep learning methods in scientific applications. ",
    "url": "https://arxiv.org/abs/2210.05686",
    "authors": [
      "Maximilian Dax",
      "Stephen R. Green",
      "Jonathan Gair",
      "Michael P\u00fcrrer",
      "Jonas Wildberger",
      "Jakob H. Macke",
      "Alessandra Buonanno",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05710",
    "title": "Predictive Event Segmentation and Representation with Neural Networks: A  Self-Supervised Model Assessed by Psychological Experiments",
    "abstract": "People segment complex, ever-changing and continuous experience into basic, stable and discrete spatio-temporal experience units, called events. Event segmentation literature investigates the mechanisms that allow people to extract events. Event segmentation theory points out that people predict ongoing activities and observe prediction error signals to find event boundaries that keep events apart. In this study, we investigated the mechanism giving rise to this ability by a computational model and accompanying psychological experiments. Inspired from event segmentation theory and predictive processing, we introduced a self-supervised model of event segmentation. This model consists of neural networks that predict the sensory signal in the next time-step to represent different events, and a cognitive model that regulates these networks on the basis of their prediction errors. In order to verify the ability of our model in segmenting events, learning them during passive observation, and representing them in its internal representational space, we prepared a video that depicts human behaviors represented by point-light displays. We compared event segmentation behaviors of participants and our model with this video in two hierarchical event segmentation levels. By using point-biserial correlation technique, we demonstrated that event segmentation decisions of our model correlated with the responses of participants. Moreover, by approximating representation space of participants by a similarity-based technique, we showed that our model formed a similar representation space with those of participants. The result suggests that our model that tracks the prediction error signals can produce human-like event boundaries and event representations. Finally, we discussed our contribution to the literature of event cognition and our understanding of how event segmentation is implemented in the brain. ",
    "url": "https://arxiv.org/abs/2210.05710",
    "authors": [
      "Hamit Basgol",
      "Inci Ayhan",
      "Emre Ugur"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05713",
    "title": "Explainable fMRI-based Brain Decoding via Spatial Temporal-pyramid Graph  Convolutional Network",
    "abstract": "Brain decoding, aiming to identify the brain states using neural activity, is important for cognitive neuroscience and neural engineering. However, existing machine learning methods for fMRI-based brain decoding either suffer from low classification performance or poor explainability. Here, we address this issue by proposing a biologically inspired architecture, Spatial Temporal-pyramid Graph Convolutional Network (STpGCN), to capture the spatial-temporal graph representation of functional brain activities. By designing multi-scale spatial-temporal pathways and bottom-up pathways that mimic the information process and temporal integration in the brain, STpGCN is capable of explicitly utilizing the multi-scale temporal dependency of brain activities via graph, thereby achieving high brain decoding performance. Additionally, we propose a sensitivity analysis method called BrainNetX to better explain the decoding results by automatically annotating task-related brain regions from the brain-network standpoint. We conduct extensive experiments on fMRI data under 23 cognitive tasks from Human Connectome Project (HCP) S1200. The results show that STpGCN significantly improves brain decoding performance compared to competing baseline models; BrainNetX successfully annotates task-relevant brain regions. Post hoc analysis based on these regions further validates that the hierarchical structure in STpGCN significantly contributes to the explainability, robustness and generalization of the model. Our methods not only provide insights into information representation in the brain under multiple cognitive tasks but also indicate a bright future for fMRI-based brain decoding. ",
    "url": "https://arxiv.org/abs/2210.05713",
    "authors": [
      "Ziyuan Ye",
      "Youzhi Qu",
      "Zhichao Liang",
      "Mo Wang",
      "Quanying Liu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.05746",
    "title": "On RKHS Choices for Assessing Graph Generators via Kernel Stein  Statistics",
    "abstract": "Score-based kernelised Stein discrepancy (KSD) tests have emerged as a powerful tool for the goodness of fit tests, especially in high dimensions; however, the test performance may depend on the choice of kernels in an underlying reproducing kernel Hilbert space (RKHS). Here we assess the effect of RKHS choice for KSD tests of random networks models, developed for exponential random graph models (ERGMs) in Xu and Reinert (2021)and for synthetic graph generators in Xu and Reinert (2022). We investigate the power performance and the computational runtime of the test in different scenarios, including both dense and sparse graph regimes. Experimental results on kernel performance for model assessment tasks are shown and discussed on synthetic and real-world network applications. ",
    "url": "https://arxiv.org/abs/2210.05746",
    "authors": [
      "Moritz Weckbecker",
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05821",
    "title": "Short-term prediction of stream turbidity using surrogate data and a  meta-model approach",
    "abstract": "Many water-quality monitoring programs aim to measure turbidity to help guide effective management of waterways and catchments, yet distributing turbidity sensors throughout networks is typically cost prohibitive. To this end, we built and compared the ability of dynamic regression (ARIMA), long short-term memory neural nets (LSTM), and generalized additive models (GAM) to forecast stream turbidity one step ahead, using surrogate data from relatively low-cost in-situ sensors and publicly available databases. We iteratively trialled combinations of four surrogate covariates (rainfall, water level, air temperature and total global solar exposure) selecting a final model for each type that minimised the corrected Akaike Information Criterion. Cross-validation using a rolling time-window indicated that ARIMA, which included the rainfall and water-level covariates only, produced the most accurate predictions, followed closely by GAM, which included all four covariates. We constructed a meta-model, trained on time-series features of turbidity, to take advantage of the strengths of each model over different time points and predict the best model (that with the lowest forecast error one-step prior) for each time step. The meta-model outperformed all other models, indicating that this methodology can yield high accuracy and may be a viable alternative to using measurements sourced directly from turbidity-sensors where costs prohibit their deployment and maintenance, and when predicting turbidity across the short term. Our findings also indicated that temperature and light-associated variables, for example underwater illuminance, may hold promise as cost-effective, high-frequency surrogates of turbidity, especially when combined with other covariates, like rainfall, that are typically measured at coarse levels of spatial resolution. ",
    "url": "https://arxiv.org/abs/2210.05821",
    "authors": [
      "Bhargav Rele",
      "Caleb Hogan",
      "Sevvandi Kandanaarachchi",
      "Catherine Leigh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.05841",
    "title": "Towards Optimal Primary- and Secondary-control Design for Networks with  Generators and Inverters",
    "abstract": "For power grids predominantly featuring large synchronous generators (SGs), there exists a significant body of work bridging optimization and control tasks. A generic workflow in such efforts entails: characterizing the steady state of control algorithms and SG dynamics; assessing the optimality of the resulting operating point with respect to an optimal dispatch task; and prescribing control parameters to ensure that (under reasonable ambient perturbations) the considered control nudges the system steady state to optimality. Well studied instances of the aforementioned approach include designing: i) automatic generation control (AGC) participation factors to ensure economic optimality, and ii) governor frequency-droop slopes to ensure power sharing. Recognizing that future power grids will feature a diverse mix of SGs and inverter-based resources (IBRs) with varying control structures, this work examines the different steps of the optimization-control workflow for this context. Considering a representative model of active power-frequency dynamics of IBRs and SGs, a characterization of steady state is put forth (with and without secondary frequency control). Conditions on active-power droop slopes and AGC participation factors are then derived to ascertain desired power sharing and ensure economically optimal operation under varying power demands. ",
    "url": "https://arxiv.org/abs/2210.05841",
    "authors": [
      "Manish K. Singh",
      "D. Venkatramanan",
      "Sairaj Dhople"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.05843",
    "title": "Cross-dataset COVID-19 Transfer Learning with Cough Detection, Cough  Segmentation, and Data Augmentation",
    "abstract": "This paper addresses issues on cough-based COVID-19 detection. We propose a cross-dataset transfer learning approach to improve the performance of COVID-19 detection by incorporating cough detection, cough segmentation, and data augmentation. The first aimed at removing non-cough signals and cough signals with low probability. The second aimed at segregating several coughs in a waveform into individual coughs. The third aimed at increasing the number of samples for the deep learning model. These three processing blocks are important as our finding revealed a large margin of improvement relative to the baseline methods without these blocks. An ablation study is conducted to optimize hyperparameters and it was found that alpha mixup is an important factor among others in improving the model performance via this augmentation method. A summary of this study with previous studies on the same evaluation set was given to gain insights into different methods of cough-based COVID-19 detection. ",
    "url": "https://arxiv.org/abs/2210.05843",
    "authors": [
      "Bagus Tris Atmaja",
      "Zanjabila",
      "Suyanto",
      "Akira Sasou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.05880",
    "title": "Pathology Steered Stratification Network for Subtype Identification in  Alzheimer's Disease",
    "abstract": "Alzheimer's disease (AD) is a heterogeneous, multifactorial neurodegenerative disorder characterized by beta-amyloid, pathologic tau, and neurodegeneration. The massive heterogeneity between neurobiological examinations and clinical assessment is the current biggest challenge in the early diagnosis of Alzheimer's disease, urging for a comprehensive stratification of the aging population that is defined by reliable neurobiological biomarkers and closely associated with clinical outcomes. However, existing statistical inference approaches in neuroimaging studies of AD subtype identification fail to take into account the neuropathological domain knowledge, which could lead to ill-posed results that are sometimes inconsistent with neurological principles. To fill this knowledge gap, we propose a novel pathology steered stratification network (PSSN) that integrates mainstream AD pathology with multimodal longitudinal neuroimaging data to categorize the aging population. By combining theory-based biological modeling and data-driven deep learning, this cross-disciplinary approach can not only generate long-term biomarker prediction consistent with the end-state of individuals but also stratifies subjects into fine-grained subtypes with distinct neurological underpinnings, where ag-ing brains within the same subtype share com-mon biological behaviors that emerge as similar trajectories of cognitive decline. Our stratification outperforms K-means and SuStaIn in both inter-cluster heterogeneity and intra-cluster homogeneity of various clinical scores. Importantly, we identify six subtypes spanning AD spectrum, where each subtype exhibits a distinctive biomarker pattern that is consistent with its clinical outcome. A disease evolutionary graph is further provided by quantifying subtype transition probabilities, which may assist pre-symptomatic diagnosis and guide therapeutic treatments. ",
    "url": "https://arxiv.org/abs/2210.05880",
    "authors": [
      "Enze Xu",
      "Jingwen Zhang",
      "Jiadi Li",
      "Defu Yang",
      "Guorong Wu",
      "Minghan Chen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05946",
    "title": "Self-Supervised Equivariant Regularization Reconciles Multiple Instance  Learning: Joint Referable Diabetic Retinopathy Classification and Lesion  Segmentation",
    "abstract": "Lesion appearance is a crucial clue for medical providers to distinguish referable diabetic retinopathy (rDR) from non-referable DR. Most existing large-scale DR datasets contain only image-level labels rather than pixel-based annotations. This motivates us to develop algorithms to classify rDR and segment lesions via image-level labels. This paper leverages self-supervised equivariant learning and attention-based multi-instance learning (MIL) to tackle this problem. MIL is an effective strategy to differentiate positive and negative instances, helping us discard background regions (negative instances) while localizing lesion regions (positive ones). However, MIL only provides coarse lesion localization and cannot distinguish lesions located across adjacent patches. Conversely, a self-supervised equivariant attention mechanism (SEAM) generates a segmentation-level class activation map (CAM) that can guide patch extraction of lesions more accurately. Our work aims at integrating both methods to improve rDR classification accuracy. We conduct extensive validation experiments on the Eyepacs dataset, achieving an area under the receiver operating characteristic curve (AU ROC) of 0.958, outperforming current state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2210.05946",
    "authors": [
      "Wenhui Zhu",
      "Peijie Qiu",
      "Natasha Lepore",
      "Oana M. Dumitrascu",
      "Yalin Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.05979",
    "title": "Adversarial Speaker-Consistency Learning Using Untranscribed Speech Data  for Zero-Shot Multi-Speaker Text-to-Speech",
    "abstract": "Several recently proposed text-to-speech (TTS) models achieved to generate the speech samples with the human-level quality in the single-speaker and multi-speaker TTS scenarios with a set of pre-defined speakers. However, synthesizing a new speaker's voice with a single reference audio, commonly known as zero-shot multi-speaker text-to-speech (ZSM-TTS), is still a very challenging task. The main challenge of ZSM-TTS is the speaker domain shift problem upon the speech generation of a new speaker. To mitigate this problem, we propose adversarial speaker-consistency learning (ASCL). The proposed method first generates an additional speech of a query speaker using the external untranscribed datasets at each training iteration. Then, the model learns to consistently generate the speech sample of the same speaker as the corresponding speaker embedding vector by employing an adversarial learning scheme. The experimental results show that the proposed method is effective compared to the baseline in terms of the quality and speaker similarity in ZSM-TTS. ",
    "url": "https://arxiv.org/abs/2210.05979",
    "authors": [
      "Byoung Jin Choi",
      "Myeonghun Jeong",
      "Minchan Kim",
      "Sung Hwan Mun",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.05988",
    "title": "CLEEGN: A Convolutional Neural Network for Plug-and-Play Automatic EEG  Reconstruction",
    "abstract": "Human electroencephalography (EEG) is a brain monitoring modality that senses cortical neuroelectrophysiological activity in high-temporal resolution. One of the greatest challenges posed in applications of EEG is the unstable signal quality susceptible to inevitable artifacts during recordings. To date, most existing techniques for EEG artifact removal and reconstruction are applicable to offline analysis solely, or require individualized training data to facilitate online reconstruction. We have proposed CLEEGN, a novel convolutional neural network for plug-and-play automatic EEG reconstruction. CLEEGN is based on a subject-independent pre-trained model using existing data and can operate on a new user without any further calibration. The performance of CLEEGN was validated using multiple evaluations including waveform observation, reconstruction error assessment, and decoding accuracy on well-studied labeled datasets. The results of simulated online validation suggest that, even without any calibration, CLEEGN can largely preserve inherent brain activity and outperforms leading online/offline artifact removal methods in the decoding accuracy of reconstructed EEG data. In addition, visualization of model parameters and latent features exhibit the model behavior and reveal explainable insights related to existing knowledge of neuroscience. We foresee pervasive applications of CLEEGN in prospective works of online plug-and-play EEG decoding and analysis. ",
    "url": "https://arxiv.org/abs/2210.05988",
    "authors": [
      "Pin-Hua Lai",
      "Wei-Chun Yang",
      "Hsiang-Chieh Tsou",
      "Chun-Shu Wei"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.06069",
    "title": "E3Bind: An End-to-End Equivariant Network for Protein-Ligand Docking",
    "abstract": "In silico prediction of the ligand binding pose to a given protein target is a crucial but challenging task in drug discovery. This work focuses on blind flexible selfdocking, where we aim to predict the positions, orientations and conformations of docked molecules. Traditional physics-based methods usually suffer from inaccurate scoring functions and high inference cost. Recently, data-driven methods based on deep learning techniques are attracting growing interest thanks to their efficiency during inference and promising performance. These methods usually either adopt a two-stage approach by first predicting the distances between proteins and ligands and then generating the final coordinates based on the predicted distances, or directly predicting the global roto-translation of ligands. In this paper, we take a different route. Inspired by the resounding success of AlphaFold2 for protein structure prediction, we propose E3Bind, an end-to-end equivariant network that iteratively updates the ligand pose. E3Bind models the protein-ligand interaction through careful consideration of the geometric constraints in docking and the local context of the binding site. Experiments on standard benchmark datasets demonstrate the superior performance of our end-to-end trainable model compared to traditional and recently-proposed deep learning methods. ",
    "url": "https://arxiv.org/abs/2210.06069",
    "authors": [
      "Yangtian Zhang",
      "Huiyu Cai",
      "Chence Shi",
      "Bozitao Zhong",
      "Jian Tang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06140",
    "title": "Differentially Private Bootstrap: New Privacy Analysis and Inference  Strategies",
    "abstract": "Differential private (DP) mechanisms protect individual-level information by introducing randomness into the statistical analysis procedure. While there are now many DP tools for various statistical problems, there is still a lack of general techniques to understand the sampling distribution of a DP estimator, which is crucial for uncertainty quantification in statistical inference. We analyze a DP bootstrap procedure that releases multiple private bootstrap estimates to infer the sampling distribution and construct confidence intervals. Our privacy analysis includes new results on the privacy cost of a single DP bootstrap estimate applicable to incorporate arbitrary DP mechanisms and identifies some misuses of the bootstrap in the existing literature. We show that the release of $B$ DP bootstrap estimates from mechanisms satisfying $(\\mu/\\sqrt{(2-2/\\mathrm{e})B})$-Gaussian DP asymptotically satisfies $\\mu$-Gaussian DP as $B$ goes to infinity. We also develop a statistical procedure based on the DP bootstrap estimates to correctly infer the sampling distribution using techniques related to the deconvolution of probability measures, an approach which is novel in analyzing DP procedures. From our density estimate, we construct confidence intervals and compare them to existing methods through simulations and real-world experiments using the 2016 Canada Census Public Use Microdata. The coverage of our private confidence intervals achieves the nominal confidence level, while other methods fail to meet this guarantee. ",
    "url": "https://arxiv.org/abs/2210.06140",
    "authors": [
      "Zhanyu Wang",
      "Guang Cheng",
      "Jordan Awan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06170",
    "title": "Contrastive Neural Ratio Estimation",
    "abstract": "Likelihood-to-evidence ratio estimation is usually cast as either a binary (NRE-A) or a multiclass (NRE-B) classification task. In contrast to the binary classification framework, the current formulation of the multiclass version has an intrinsic and unknown bias term, making otherwise informative diagnostics unreliable. We propose a multiclass framework free from the bias inherent to NRE-B at optimum, leaving us in the position to run diagnostics that practitioners depend on. It also recovers NRE-A in one corner case and NRE-B in the limiting case. For fair comparison, we benchmark the behavior of all algorithms in both familiar and novel training regimes: when jointly drawn data is unlimited, when data is fixed but prior draws are unlimited, and in the commonplace fixed data and parameters setting. Our investigations reveal that the highest performing models are distant from the competitors (NRE-A, NRE-B) in hyperparameter space. We make a recommendation for hyperparameters distinct from the previous models. We suggest a bound on the mutual information as a performance metric for simulation-based inference methods, without the need for posterior samples, and provide experimental results. ",
    "url": "https://arxiv.org/abs/2210.06170",
    "authors": [
      "Benjamin Kurt Miller",
      "Christoph Weniger",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ]
  },
  {
    "id": "arXiv:2210.06175",
    "title": "Exploring Efficient-tuning Methods in Self-supervised Speech Models",
    "abstract": "In this study, we aim to explore efficient tuning methods for speech self-supervised learning. Recent studies show that self-supervised learning (SSL) can learn powerful representations for different speech tasks. However, fine-tuning pre-trained models for each downstream task is parameter-inefficient since SSL models are notoriously large with millions of parameters. Adapters are lightweight modules commonly used in NLP to solve this problem. In downstream tasks, the parameters of SSL models are frozen, and only the adapters are trained. Given the lack of studies generally exploring the effectiveness of adapters for self-supervised speech tasks, we intend to fill this gap by adding various adapter modules in pre-trained speech SSL models. We show that the performance parity can be achieved with over 90% parameter reduction, and discussed the pros and cons of efficient tuning techniques. This is the first comprehensive investigation of various adapter types across speech tasks. ",
    "url": "https://arxiv.org/abs/2210.06175",
    "authors": [
      "Zih-Ching Chen",
      "Chin-Lun Fu",
      "Chih-Ying Liu",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.06179",
    "title": "Convolutional Neural Network-Based Image Watermarking using Discrete  Wavelet Transform",
    "abstract": "As the Internet becomes more popular, digital images are used and transferred more frequently. Although this phenomenon facilitates easy access to information, it also creates security concerns and violates intellectual property rights by allowing illegal use, copying, and digital content theft. Using watermarks (WMs) in digital images is one of the most common ways to maintain security. Watermarking is proving and declaring ownership of an image by adding a digital watermark to the original image. Watermarks can be either text or an image placed overtly or covertly in an image and are expected to be challenging to remove. This paper proposes a combination of convolutional neural networks (CNNs) and wavelet transforms to obtain a watermarking network for embedding and extracting watermarks. The network is independent of the host image resolution, can accept all kinds of watermarks, and has only 11 CNN layers while keeping performance. Two terms measure performance; the similarity between the extracted watermark and the original one and the similarity between the host image and the watermarked one. ",
    "url": "https://arxiv.org/abs/2210.06179",
    "authors": [
      "Alireza Tavakoli",
      "Zahra Honjani",
      "Hedieh Sajedi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06285",
    "title": "Smart Cup: An impedance sensing based fluid intake monitoring system for  beverages classification and freshness detection",
    "abstract": "This paper presents a novel beverage intake monitoring system that can accurately recognize beverage kinds and freshness. By mounting carbon electrodes on the commercial cup, the system measures the electrochemical impedance spectrum of the fluid in the cup. We studied the frequency sensitivity of the electrochemical impedance spectrum regarding distinct beverages and the importance of features like amplitude, phase, and real and imaginary components for beverage classification. The results show that features from a low-frequency domain (100 Hz to 1000 Hz) provide more meaningful information for beverage classification than the higher frequency domain. Twenty beverages, including carbonated drinks and juices, were classified with nearly perfect accuracy using a supervised machine learning approach. The same performance was also observed in the freshness recognition, where four different kinds of milk and fruit juice were studied. ",
    "url": "https://arxiv.org/abs/2210.06285",
    "authors": [
      "Mengxi Liu",
      "Sizhen Bian",
      "Bo Zhou",
      "Agnes Gr\u00fcnerbl",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06286",
    "title": "Self-supervised Learning for Label-Efficient Sleep Stage Classification:  A Comprehensive Evaluation",
    "abstract": "The past few years have witnessed a remarkable advance in deep learning for EEG-based sleep stage classification (SSC). However, the success of these models is attributed to possessing a massive amount of labeled data for training, limiting their applicability in real-world scenarios. In such scenarios, sleep labs can generate a massive amount of data, but labeling these data can be expensive and time-consuming. Recently, the self-supervised learning (SSL) paradigm has shined as one of the most successful techniques to overcome the scarcity of labeled data. In this paper, we evaluate the efficacy of SSL to boost the performance of existing SSC models in the few-labels regime. We conduct a thorough study on three SSC datasets, and we find that fine-tuning the pretrained SSC models with only 5% of labeled data can achieve competitive performance to the supervised training with full labels. Moreover, self-supervised pretraining helps SSC models to be more robust to data imbalance and domain shift problems. The code is publicly available at \\url{https://github.com/emadeldeen24/eval_ssl_ssc}. ",
    "url": "https://arxiv.org/abs/2210.06286",
    "authors": [
      "Emadeldeen Eldele",
      "Mohamed Ragab",
      "Zhenghua Chen",
      "Min Wu",
      "Chee-Keong Kwoh",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06287",
    "title": "An Energy-Efficient Spiking Neural Network for Finger Velocity Decoding  for Implantable Brain-Machine Interface",
    "abstract": "Brain-machine interfaces (BMIs) are promising for motor rehabilitation and mobility augmentation. High-accuracy and low-power algorithms are required to achieve implantable BMI systems. In this paper, we propose a novel spiking neural network (SNN) decoder for implantable BMI regression tasks. The SNN is trained with enhanced spatio-temporal backpropagation to fully leverage its ability in handling temporal problems. The proposed SNN decoder achieves the same level of correlation coefficient as the state-of-the-art ANN decoder in offline finger velocity decoding tasks, while it requires only 6.8% of the computation operations and 9.4% of the memory access. ",
    "url": "https://arxiv.org/abs/2210.06287",
    "authors": [
      "Jiawei Liao",
      "Lars Widmer",
      "Xiaying Wang",
      "Alfio Di Mauro",
      "Samuel R. Nason-Tomaszewski",
      "Cynthia A. Chestek",
      "Luca Benini",
      "Taekwang Jang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06292",
    "title": "A review on Epileptic Seizure Detection using Machine Learning",
    "abstract": "Epilepsy is a neurological brain disorder which life threatening and gives rise to recurrent seizures that are unprovoked. It occurs due to the abnormal chemical changes in our brain. Over the course of many years, studies have been conducted to support automatic diagnosis of epileptic seizures for the ease of clinicians. For that, several studies entail the use of machine learning methods for the early prediction of epileptic seizures. Mainly, feature extraction methods have been used to extract the right features from the EEG data generated by the EEG machine and then various machine learning classifiers are used for the classification process. This study provides a systematic literature review of feature selection process as well as the classification performance. This study was limited to the finding of most used feature extraction methods and the classifiers used for accurate classification of normal to epileptic seizures. The existing literature was examined from well-known repositories such as MPDI, IEEEXplore, Wiley, Elsevier, ACM, Springerlink and others. Furthermore, a taxonomy was created that recapitulates the state-of-the-art used solutions for this problem. We also studied the nature of different benchmark and unbiased datasets and gave a rigorous analysis of the working of classifiers. Finally, we concluded the research by presenting the gaps, challenges and opportunities which can further help researchers in prediction of epileptic seizure ",
    "url": "https://arxiv.org/abs/2210.06292",
    "authors": [
      "Muhammad Shoaib Farooq",
      "Aimen Zulfiqar",
      "Shamyla Riaz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06293",
    "title": "Two-stream Network for ECG Signal Classification",
    "abstract": "Electrocardiogram (ECG), a technique for medical monitoring of cardiac activity, is an important method for identifying cardiovascular disease. However, analyzing the increasing quantity of ECG data consumes a lot of medical resources. This paper explores an effective algorithm for automatic classifications of multi-classes of heartbeat types based on ECG. Most neural network based methods target the individual heartbeats, ignoring the secrets embedded in the temporal sequence. And the ECG signal has temporal variation and unique individual characteristics, which means that the same type of ECG signal varies among patients under different physical conditions. A two-stream architecture is used in this paper and presents an enhanced version of ECG recognition based on this. The architecture achieves classification of holistic ECG signal and individual heartbeat and incorporates identified and temporal stream networks. Identified networks are used to extract features of individual heartbeats, while temporal networks aim to extract temporal correlations between heartbeats. Results on the MIT-BIH Arrhythmia Database demonstrate that the proposed algorithm performs an accuracy of 99.38\\%. In addition, the proposed algorithm reaches an 88.07\\% positive accuracy on massive data in real life, showing that the proposed algorithm can efficiently categorize different classes of heartbeat with high diagnostic performance. ",
    "url": "https://arxiv.org/abs/2210.06293",
    "authors": [
      "Xinyao Hou",
      "Shengmei Qin",
      "Jianbo Su"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06294",
    "title": "Indoor Localization with Robust Global Channel Charting: A  Time-Distance-Based Approach",
    "abstract": "Fingerprinting-based positioning significantly improves the indoor localization performance in non-line-of-sight-dominated areas. However, its deployment and maintenance is cost-intensive as it needs ground-truth reference systems for both the initial training and the adaption to environmental changes. In contrast, channel charting (CC) works without explicit reference information and only requires the spatial correlations of channel state information (CSI). While CC has shown promising results in modelling the geometry of the radio environment, a deeper insight into CC for localization using multi-anchor large-bandwidth measurements is still pending. We contribute a novel distance metric for time-synchronized single-input/single-output CSIs that approaches a linear correlation to the Euclidean distance. This allows to learn the environment's global geometry without annotations. To efficiently optimize the global channel chart we approximate the metric with a Siamese neural network. This enables full CC-assisted fingerprinting and positioning only using a linear transformation from the chart to the real-world coordinates. We compare our approach to the state-of-the-art of CC on two different real-world data sets recorded with a 5G and UWB radio setup. Our approach outperforms others with localization accuracies of 0.69m for the UWB and 1.4m for the 5G setup. We show that CC-assisted fingerprinting enables highly accurate localization and reduces (or eliminates) the need for annotated training data. ",
    "url": "https://arxiv.org/abs/2210.06294",
    "authors": [
      "Maximilian Stahlke",
      "George Yammine",
      "Tobias Feigl",
      "Bjoern M. Eskofier",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06297",
    "title": "Multimodality Multi-Lead ECG Arrhythmia Classification using  Self-Supervised Learning",
    "abstract": "Electrocardiogram (ECG) signal is one of the most effective sources of information mainly employed for the diagnosis and prediction of cardiovascular diseases (CVDs) connected with the abnormalities in heart rhythm. Clearly, single modality ECG (i.e. time series) cannot convey its complete characteristics, thus, exploiting both time and time-frequency modalities in the form of time-series data and spectrogram is needed. Leveraging the cutting-edge self-supervised learning (SSL) technique on unlabeled data, we propose SSL-based multimodality ECG classification. Our proposed network follows SSL learning paradigm and consists of two modules corresponding to pre-stream task, and down-stream task, respectively. In the SSL-pre-stream task, we utilize self-knowledge distillation (KD) techniques with no labeled data, on various transformations and in both time and frequency domains. In the down-stream task, which is trained on labeled data, we propose a gate fusion mechanism to fuse information from multimodality.To evaluate the effectiveness of our approach, ten-fold cross validation on the 12-lead PhysioNet 2020 dataset has been conducted. ",
    "url": "https://arxiv.org/abs/2210.06297",
    "authors": [
      "Thinh Phan",
      "Duc Le",
      "Patel Brijesh",
      "Donald Adjeroh",
      "Jingxian Wu",
      "Morten Olgaard Jensen",
      "Ngan Le"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06298",
    "title": "Cross Task Neural Architecture Search for EEG Signal Classifications",
    "abstract": "Electroencephalograms (EEGs) are brain dynamics measured outside the brain, which have been widely utilized in non-invasive brain-computer interface applications. Recently, various neural network approaches have been proposed to improve the accuracy of EEG signal recognition. However, these approaches severely rely on manually designed network structures for different tasks which generally are not sharing the same empirical design cross-task-wise. In this paper, we propose a cross-task neural architecture search (CTNAS-EEG) framework for EEG signal recognition, which can automatically design the network structure across tasks and improve the recognition accuracy of EEG signals. Specifically, a compatible search space for cross-task searching and an efficient constrained searching method is proposed to overcome challenges brought by EEG signals. By unifying structure search on different EEG tasks, this work is the first to explore and analyze the searched structure difference cross-task-wise. Moreover, by introducing architecture search, this work is the first to analyze model performance by customizing model structure for each human subject. Detailed experimental results suggest that the proposed CTNAS-EEG could reach state-of-the-art performance on different EEG tasks, such as Motor Imagery (MI) and Emotion recognition. Extensive experiments and detailed analysis are provided as a good reference for follow-up researchers. ",
    "url": "https://arxiv.org/abs/2210.06298",
    "authors": [
      "Yiqun Duan",
      "Zhen Wang",
      "Yi Li",
      "Jianhang Tang",
      "Yu-Kai Wang",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06303",
    "title": "Dynamic neuronal networks efficiently achieve classification in robotic  interactions with real-world objects",
    "abstract": "Biological cortical networks are potentially fully recurrent networks without any distinct output layer, where recognition may instead rely on the distribution of activity across its neurons. Because such biological networks can have rich dynamics, they are well-designed to cope with dynamical interactions of the types that occur in nature, while traditional machine learning networks may struggle to make sense of such data. Here we connected a simple model neuronal network (based on the 'linear summation neuron model' featuring biologically realistic dynamics (LSM), consisting of 10 of excitatory and 10 inhibitory neurons, randomly connected) to a robot finger with multiple types of force sensors when interacting with materials of different levels of compliance. Scope: to explore the performance of the network on classification accuracy. Therefore, we compared the performance of the network output with principal component analysis of statistical features of the sensory data as well as its mechanical properties. Remarkably, even though the LSM was a very small and untrained network, and merely designed to provide rich internal network dynamics while the neuron model itself was highly simplified, we found that the LSM outperformed these other statistical approaches in terms of accuracy. ",
    "url": "https://arxiv.org/abs/2210.06303",
    "authors": [
      "Pakorn Uttayopas",
      "Xiaoxiao Cheng",
      "Udaya Bhaskar Rongala",
      "Henrik jorntell",
      "Etienne Burdet"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06335",
    "title": "A deep learning network with differentiable dynamic programming for  retina OCT surface segmentation",
    "abstract": "Multiple-surface segmentation in Optical Coherence Tomography (OCT) images is a challenge problem, further complicated by the frequent presence of weak image boundaries. Recently, many deep learning (DL) based methods have been developed for this task and yield remarkable performance. Unfortunately, due to the scarcity of training data in medical imaging, it is challenging for DL networks to learn the global structure of the target surfaces, including surface smoothness. To bridge this gap, this study proposes to seamlessly unify a U-Net for feature learning with a constrained differentiable dynamic programming module to achieve an end-to-end learning for retina OCT surface segmentation to explicitly enforce surface smoothness. It effectively utilizes the feedback from the downstream model optimization module to guide feature learning, yielding a better enforcement of global structures of the target surfaces. Experiments on Duke AMD (age-related macular degeneration) and JHU MS (multiple sclerosis) OCT datasets for retinal layer segmentation demonstrated very promising segmentation accuracy. ",
    "url": "https://arxiv.org/abs/2210.06335",
    "authors": [
      "Hui Xie",
      "Weiyu Xu",
      "Xiaodong Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06362",
    "title": "A Comparative Study on 1.5T-3T MRI Conversion through Deep Neural  Network Models",
    "abstract": "In this paper, we explore the capabilities of a number of deep neural network models in generating whole-brain 3T-like MR images from clinical 1.5T MRIs. The models include a fully convolutional network (FCN) method and three state-of-the-art super-resolution solutions, ESPCN [26], SRGAN [17] and PRSR [7]. The FCN solution, U-Convert-Net, carries out mapping of 1.5T-to-3T slices through a U-Net-like architecture, with 3D neighborhood information integrated through a multi-view ensemble. The pros and cons of the models, as well the associated evaluation metrics, are measured with experiments and discussed in depth. To the best of our knowledge, this study is the first work to evaluate multiple deep learning solutions for whole-brain MRI conversion, as well as the first attempt to utilize FCN/U-Net-like structure for this purpose. ",
    "url": "https://arxiv.org/abs/2210.06362",
    "authors": [
      "Binhua Liao",
      "Yani Chen",
      "Zhewei Wang",
      "Charles D. Smith",
      "Jundong Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06382",
    "title": "An Ensemble Teacher-Student Learning Approach with Poisson Sub-sampling  to Differential Privacy Preserving Speech Recognition",
    "abstract": "We propose an ensemble learning framework with Poisson sub-sampling to effectively train a collection of teacher models to issue some differential privacy (DP) guarantee for training data. Through boosting under DP, a student model derived from the training data suffers little model degradation from the models trained with no privacy protection. Our proposed solution leverages upon two mechanisms, namely: (i) a privacy budget amplification via Poisson sub-sampling to train a target prediction model that requires less noise to achieve a same level of privacy budget, and (ii) a combination of the sub-sampling technique and an ensemble teacher-student learning framework that introduces DP-preserving noise at the output of the teacher models and transfers DP-preserving properties via noisy labels. Privacy-preserving student models are then trained with the noisy labels to learn the knowledge with DP-protection from the teacher model ensemble. Experimental evidences on spoken command recognition and continuous speech recognition of Mandarin speech show that our proposed framework greatly outperforms existing DP-preserving algorithms in both speech processing tasks. ",
    "url": "https://arxiv.org/abs/2210.06382",
    "authors": [
      "Chao-Han Huck Yang",
      "Jun Qi",
      "Sabato Marco Siniscalchi",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:1902.03223",
    "title": "Robust Streaming PCA",
    "abstract": " Comments: The authors are ordered alphabetically. 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/1902.03223",
    "authors": [
      "Daniel Bienstock",
      "Minchan Jeong",
      "Apurv Shukla",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1907.00380",
    "title": "Dimension is polynomial in height for posets with planar cover graphs",
    "abstract": " Title: Dimension is polynomial in height for posets with planar cover graphs ",
    "url": "https://arxiv.org/abs/1907.00380",
    "authors": [
      "Jakub Kozik",
      "Piotr Micek",
      "William T. Trotter"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1910.03365",
    "title": "A Penalized Inequality-Constrained Approach for Robust Beamforming with  DoF Limitation",
    "abstract": " Comments: Accepted by Signal Processing ",
    "url": "https://arxiv.org/abs/1910.03365",
    "authors": [
      "Wenqiang Pu",
      "Jinjun Xiao",
      "Tao Zhang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2005.06156",
    "title": "Super-resolution and Robust Sparse Continuous Fourier Transform in Any  Constant Dimension: Nearly Linear Time and Sample Complexity",
    "abstract": " Comments: SODA 2023 ",
    "url": "https://arxiv.org/abs/2005.06156",
    "authors": [
      "Yaonan Jin",
      "Daogao Liu",
      "Zhao Song"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2007.12107",
    "title": "Few-Shot Object Detection and Viewpoint Estimation for Objects in the  Wild",
    "abstract": " Comments: Accepted by TPAMI, add experimental results and additional ablation studies ",
    "url": "https://arxiv.org/abs/2007.12107",
    "authors": [
      "Yang Xiao",
      "Vincent Lepetit",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2009.05683",
    "title": "MACE: A Flexible Framework for Membership Privacy Estimation in  Generative Models",
    "abstract": " Title: MACE: A Flexible Framework for Membership Privacy Estimation in  Generative Models ",
    "url": "https://arxiv.org/abs/2009.05683",
    "authors": [
      "Yixi Xu",
      "Sumit Mukherjee",
      "Xiyang Liu",
      "Shruti Tople",
      "Rahul Dodhia",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.05624",
    "title": "Self-Adjusting Population Sizes for Non-Elitist Evolutionary Algorithms:  Why Success Rates Matter",
    "abstract": " Comments: This is an extended version of a paper that appeared in the Proceedings of the Genetic and Evolutionary Computation Conference (GECCO 2021) ",
    "url": "https://arxiv.org/abs/2104.05624",
    "authors": [
      "Mario Alejandro Hevia Fajardo",
      "Dirk Sudholt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2106.08068",
    "title": "An Analytical Theory of Curriculum Learning in Teacher-Student Networks",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.08068",
    "authors": [
      "Luca Saglietti",
      "Stefano Sarao Mannelli",
      "Andrew Saxe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.13681",
    "title": "Rate-Independent Computation in Continuous Chemical Reaction Networks",
    "abstract": " Comments: preliminary version appeared in ITCS 2014: this http URL ",
    "url": "https://arxiv.org/abs/2107.13681",
    "authors": [
      "Ho-Lin Chen",
      "David Doty",
      "David Soloveichik",
      "Wyatt Reeves"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2109.08844",
    "title": "Near-Minimax Optimal Estimation With Shallow ReLU Neural Networks",
    "abstract": " Comments: IEEE Transactions on Information Theory (in press) ",
    "url": "https://arxiv.org/abs/2109.08844",
    "authors": [
      "Rahul Parhi",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.00060",
    "title": "Automating Internet of Things Network Traffic Collection with Robotic  Arm Interactions",
    "abstract": " Comments: 10 pages, 5 figures, 3 tables; revised version for publication ",
    "url": "https://arxiv.org/abs/2110.00060",
    "authors": [
      "Xi Jiang",
      "Noah Apthorpe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.14392",
    "title": "TaylorSwiftNet: Taylor Driven Temporal Modeling for Swift Future Frame  Prediction",
    "abstract": " Comments: BMVC 2022 ",
    "url": "https://arxiv.org/abs/2110.14392",
    "authors": [
      "Saber Pourheydari",
      "Emad Bahrami",
      "Mohsen Fayyaz",
      "Gianpiero Francesca",
      "Mehdi Noroozi",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.11994",
    "title": "Degree-preserving graph dynamics -- a versatile process to construct  random networks",
    "abstract": " Comments: 21 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2111.11994",
    "authors": [
      "P\u00e9ter L. Erd\u0151s",
      "Shubha R. Kharel",
      "Tam\u00e1s R. Mezei",
      "Zolt\u00e1n Toroczkai"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2112.12299",
    "title": "A Robust Initialization of Residual Blocks for Effective ResNet Training  without Batch Normalization",
    "abstract": " Comments: 16 pages (4 pages of supplementary material), 9 figures, 2 table ",
    "url": "https://arxiv.org/abs/2112.12299",
    "authors": [
      "Enrico Civitelli",
      "Alessio Sortino",
      "Matteo Lapucci",
      "Francesco Bagattini",
      "Giulio Galvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.13593",
    "title": "Multi-modal Attention Network for Stock Movements Prediction",
    "abstract": " Comments: The AAAI-22 Workshop on Knowledge Discovery from Unstructured Data in Financial Services (KDF 2022) ",
    "url": "https://arxiv.org/abs/2112.13593",
    "authors": [
      "Shwai He",
      "Shi Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Trading and Market Microstructure (q-fin.TR)"
    ]
  },
  {
    "id": "arXiv:2201.04122",
    "title": "In Defense of the Unitary Scalarization for Deep Multi-Task Learning",
    "abstract": " Comments: NeurIPS 2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2201.04122",
    "authors": [
      "Vitaly Kurin",
      "Alessandro De Palma",
      "Ilya Kostrikov",
      "Shimon Whiteson",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05021",
    "title": "Robustness against Read Committed for Transaction Templates with  Functional Constraints",
    "abstract": " Comments: 49 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2201.05021",
    "authors": [
      "Brecht Vandevoort",
      "Bas Ketsman",
      "Christoph Koch",
      "Frank Neven"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2201.09636",
    "title": "Neural Implicit Surface Evolution using Differential Equations",
    "abstract": " Title: Neural Implicit Surface Evolution using Differential Equations ",
    "url": "https://arxiv.org/abs/2201.09636",
    "authors": [
      "Tiago Novello",
      "Vinicius da Silva",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Helio Lopes",
      "Luiz Velho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.09785",
    "title": "Unifying and Boosting Gradient-Based Training-Free Neural Architecture  Search",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.09785",
    "authors": [
      "Yao Shu",
      "Zhongxiang Dai",
      "Zhaoxuan Wu",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12032",
    "title": "Neural Approximation of Graph Topological Features",
    "abstract": " Comments: Accepted in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.12032",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13180",
    "title": "Learning on Arbitrary Graph Topologies via Predictive Coding",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2201.13180",
    "authors": [
      "Tommaso Salvatori",
      "Luca Pinchetti",
      "Beren Millidge",
      "Yuhang Song",
      "Tianyi Bao",
      "Rafal Bogacz",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02363",
    "title": "Meta-Reinforcement Learning with Self-Modifying Networks",
    "abstract": " Comments: Published at Neurips 2022 ",
    "url": "https://arxiv.org/abs/2202.02363",
    "authors": [
      "Mathieu Chalvidal",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2202.02365",
    "title": "MariusGNN: Resource-Efficient Out-of-Core Training of Graph Neural  Networks",
    "abstract": " Title: MariusGNN: Resource-Efficient Out-of-Core Training of Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2202.02365",
    "authors": [
      "Roger Waleffe",
      "Jason Mohoney",
      "Theodoros Rekatsinas",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2202.08087",
    "title": "Extended Unconstrained Features Model for Exploring Deep Neural Collapse",
    "abstract": " Comments: ICML 2022. Relaxed Theorem 4.2 and clarified proofs ",
    "url": "https://arxiv.org/abs/2202.08087",
    "authors": [
      "Tom Tirer",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08266",
    "title": "Open-Ended Reinforcement Learning with Neural Reward Functions",
    "abstract": " Title: Open-Ended Reinforcement Learning with Neural Reward Functions ",
    "url": "https://arxiv.org/abs/2202.08266",
    "authors": [
      "Robert Meier",
      "Asier Mujika"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.09081",
    "title": "Inducing Neural Collapse in Imbalanced Learning: Do We Really Need a  Learnable Classifier at the End of Deep Neural Network?",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2203.09081",
    "authors": [
      "Yibo Yang",
      "Shixiang Chen",
      "Xiangtai Li",
      "Liang Xie",
      "Zhouchen Lin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09940",
    "title": "Alleviating Adversarial Attacks on Variational Autoencoders with MCMC",
    "abstract": " Title: Alleviating Adversarial Attacks on Variational Autoencoders with MCMC ",
    "url": "https://arxiv.org/abs/2203.09940",
    "authors": [
      "Anna Kuzina",
      "Max Welling",
      "Jakub M. Tomczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13313",
    "title": "Deep learning for laboratory earthquake prediction and autoregressive  forecasting of fault zone stress",
    "abstract": " Comments: Published in this https URL ",
    "url": "https://arxiv.org/abs/2203.13313",
    "authors": [
      "Laura Laurenti",
      "Elisa Tinti",
      "Fabio Galasso",
      "Luca Franco",
      "Chris Marone"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04061",
    "title": "\"Am I Private and If So, how Many?\" -- Using Risk Communication Formats  for Making Differential Privacy Understandable",
    "abstract": " Comments: Accepted at ACM Conference on Computer and Communications Security (CCS) 2022 ",
    "url": "https://arxiv.org/abs/2204.04061",
    "authors": [
      "Daniel Franzen",
      "Saskia Nu\u00f1ez von Voigt",
      "Peter S\u00f6rries",
      "Florian Tschorsch",
      "Claudia M\u00fcller-Birn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.04218",
    "title": "Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes  for Medical Image Super-Resolution",
    "abstract": " Comments: Accepted at WACV 2023 (main paper + supplementary) ",
    "url": "https://arxiv.org/abs/2204.04218",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Nicolae-Catalin Ristea",
      "Nicolae Verga",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.08241",
    "title": "GNN-encoder: Learning a Dual-encoder Architecture via Graph Neural  Networks for Dense Passage Retrieval",
    "abstract": " Comments: Findings of EMNLP2022 ",
    "url": "https://arxiv.org/abs/2204.08241",
    "authors": [
      "Jiduan Liu",
      "Jiahao Liu",
      "Yang Yang",
      "Jingang Wang",
      "Wei Wu",
      "Dongyan Zhao",
      "Rui Yan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.09179",
    "title": "On the Representation Collapse of Sparse Mixture of Experts",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2204.09179",
    "authors": [
      "Zewen Chi",
      "Li Dong",
      "Shaohan Huang",
      "Damai Dai",
      "Shuming Ma",
      "Barun Patra",
      "Saksham Singhal",
      "Payal Bajaj",
      "Xia Song",
      "Xian-Ling Mao",
      "Heyan Huang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.11144",
    "title": "Competitive Physics Informed Networks",
    "abstract": " Title: Competitive Physics Informed Networks ",
    "url": "https://arxiv.org/abs/2204.11144",
    "authors": [
      "Qi Zeng",
      "Yash Kothari",
      "Spencer H. Bryngelson",
      "Florian Sch\u00e4fer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2205.01666",
    "title": "DANBO: Disentangled Articulated Neural Body Representations via Graph  Neural Networks",
    "abstract": " Comments: ECCV 2022. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2205.01666",
    "authors": [
      "Shih-Yang Su",
      "Timur Bagautdinov",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.03017",
    "title": "Generative Adversarial Neural Operators",
    "abstract": " Comments: Transactions on Machine Learning Research 2022 ",
    "url": "https://arxiv.org/abs/2205.03017",
    "authors": [
      "Md Ashiqur Rahman",
      "Manuel A. Florez",
      "Anima Anandkumar",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.09435",
    "title": "Adversarial random forests for density estimation and generative  modelling",
    "abstract": " Comments: 19 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2205.09435",
    "authors": [
      "David S. Watson",
      "Kristin Blesch",
      "Jan Kapar",
      "Marvin N. Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2205.09589",
    "title": "Learning Energy Networks with Generalized Fenchel-Young Losses",
    "abstract": " Title: Learning Energy Networks with Generalized Fenchel-Young Losses ",
    "url": "https://arxiv.org/abs/2205.09589",
    "authors": [
      "Mathieu Blondel",
      "Felipe Llinares-L\u00f3pez",
      "Robert Dadashi",
      "L\u00e9onard Hussenot",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10130",
    "title": "Spiking Neural Operators for Scientific Machine Learning",
    "abstract": " Comments: 16 pages, 6 figures and 4 tables ",
    "url": "https://arxiv.org/abs/2205.10130",
    "authors": [
      "Adar Kahana",
      "Qian Zhang",
      "Leonard Gleyzer",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11610",
    "title": "uGLAD: Sparse graph recovery by optimizing deep unrolled networks",
    "abstract": " Title: uGLAD: Sparse graph recovery by optimizing deep unrolled networks ",
    "url": "https://arxiv.org/abs/2205.11610",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska",
      "Robin Abraham",
      "Xinshi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.11782",
    "title": "Fine-grained Poisoning Attack to Local Differential Privacy Protocols  for Mean and Variance Estimation",
    "abstract": " Title: Fine-grained Poisoning Attack to Local Differential Privacy Protocols  for Mean and Variance Estimation ",
    "url": "https://arxiv.org/abs/2205.11782",
    "authors": [
      "Xiaoguang Li",
      "Ninghui Li",
      "Wenhai Sun",
      "Neil Zhenqiang Gong",
      "Hui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.12454",
    "title": "Recipe for a General, Powerful, Scalable Graph Transformer",
    "abstract": " Comments: In Proceedings of NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.12454",
    "authors": [
      "Ladislav Ramp\u00e1\u0161ek",
      "Mikhail Galkin",
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Guy Wolf",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13503",
    "title": "Multi-layer State Evolution Under Random Convolutional Design",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13503",
    "authors": [
      "Max Daniels",
      "C\u00e9dric Gerbelot",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.13532",
    "title": "Selective Classification Via Neural Network Training Dynamics",
    "abstract": " Title: Selective Classification Via Neural Network Training Dynamics ",
    "url": "https://arxiv.org/abs/2205.13532",
    "authors": [
      "Stephan Rabanser",
      "Anvith Thudi",
      "Kimia Hamidieh",
      "Adam Dziedzic",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14014",
    "title": "What Dense Graph Do You Need for Self-Attention?",
    "abstract": " Comments: Accepted by ICML 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.14014",
    "authors": [
      "Yuxin Wang",
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14140",
    "title": "CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model  Behavior",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.14140",
    "authors": [
      "Eldar David Abraham",
      "Karel D'Oosterlinck",
      "Amir Feder",
      "Yair Ori Gat",
      "Atticus Geiger",
      "Christopher Potts",
      "Roi Reichart",
      "Zhengxuan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.15286",
    "title": "Robust and accelerated single-spike spiking neural network training with  applicability to challenging temporal tasks",
    "abstract": " Comments: 18 pages, 6 figures, under review at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2205.15286",
    "authors": [
      "Luke Taylor",
      "Andrew King",
      "Nicol Harper"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.00257",
    "title": "CoNSoLe: Convex Neural Symbolic Learning",
    "abstract": " Comments: 18 pages, 5 figures, conference for NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.00257",
    "authors": [
      "Haoran Li",
      "Yang Weng",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.00665",
    "title": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface  Reconstruction",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.00665",
    "authors": [
      "Zehao Yu",
      "Songyou Peng",
      "Michael Niemeyer",
      "Torsten Sattler",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02675",
    "title": "Effects of Safety State Augmentation on Safe Exploration",
    "abstract": " Comments: Published in Neurips 2022 ",
    "url": "https://arxiv.org/abs/2206.02675",
    "authors": [
      "Aivar Sootla",
      "Alexander I. Cowen-Rivers",
      "Jun Wang",
      "Haitham Bou Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.04910",
    "title": "NAGphormer: A Tokenized Graph Transformer for Node Classification in  Large Graphs",
    "abstract": " Title: NAGphormer: A Tokenized Graph Transformer for Node Classification in  Large Graphs ",
    "url": "https://arxiv.org/abs/2206.04910",
    "authors": [
      "Jinsong Chen",
      "Kaiyuan Gao",
      "Gaichao Li",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.06922",
    "title": "Object Scene Representation Transformer",
    "abstract": " Comments: Accepted at NeurIPS '22. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.06922",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Daniel Duckworth",
      "Aravindh Mahendran",
      "Sjoerd van Steenkiste",
      "Filip Paveti\u0107",
      "Mario Lu\u010di\u0107",
      "Leonidas J. Guibas",
      "Klaus Greff",
      "Thomas Kipf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11541",
    "title": "A Neuromorphic Vision-Based Measurement for Robust Relative Localization  in Future Space Exploration Missions",
    "abstract": " Title: A Neuromorphic Vision-Based Measurement for Robust Relative Localization  in Future Space Exploration Missions ",
    "url": "https://arxiv.org/abs/2206.11541",
    "authors": [
      "Mohammed Salah",
      "Mohammed Chehadah",
      "Muhammed Humais",
      "Mohammed Wahbah",
      "Abdulla Ayyad",
      "Rana Azzam",
      "Lakmal Seneviratne",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12314",
    "title": "Learning sparse features can lead to overfitting in neural networks",
    "abstract": " Title: Learning sparse features can lead to overfitting in neural networks ",
    "url": "https://arxiv.org/abs/2206.12314",
    "authors": [
      "Leonardo Petrini",
      "Francesco Cagnetta",
      "Eric Vanden-Eijnden",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02803",
    "title": "Delving into Sequential Patches for Deepfake Detection",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.02803",
    "authors": [
      "Jiazhi Guan",
      "Hang Zhou",
      "Zhibin Hong",
      "Errui Ding",
      "Jingdong Wang",
      "Chengbin Quan",
      "Youjian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04396",
    "title": "Scalable and Privacy-enhanced Graph Generative Model for Graph Neural  Networks",
    "abstract": " Title: Scalable and Privacy-enhanced Graph Generative Model for Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2207.04396",
    "authors": [
      "Minji Yoon",
      "Yue Wu",
      "John Palowitch",
      "Bryan Perozzi",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.06456",
    "title": "Graph Neural Network Bandits",
    "abstract": " Comments: Accepted to Neurips2022, 37 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2207.06456",
    "authors": [
      "Parnian Kassraie",
      "Andreas Krause",
      "Ilija Bogunovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.07783",
    "title": "Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection",
    "abstract": " Comments: ECCV 2022 camera ready (Supplementary videos: on ECVA soon). This paper supersedes arXiv:2112.01479 ",
    "url": "https://arxiv.org/abs/2207.07783",
    "authors": [
      "Kyle Min",
      "Sourya Roy",
      "Subarna Tripathi",
      "Tanaya Guha",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.13877",
    "title": "p-Adic Statistical Field Theory and Deep Belief Networks",
    "abstract": " Comments: Some additional typos were corrected ",
    "url": "https://arxiv.org/abs/2207.13877",
    "authors": [
      "W. A. Z\u00fa\u00f1iga-Galindo"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.14742",
    "title": "Graph Neural Networks for Channel Decoding",
    "abstract": " Comments: Source code is available online this https URL ",
    "url": "https://arxiv.org/abs/2207.14742",
    "authors": [
      "Sebastian Cammerer",
      "Jakob Hoydis",
      "Fay\u00e7al A\u00eft Aoudia",
      "Alexander Keller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00789",
    "title": "Self-supervised learning with rotation-invariant kernels",
    "abstract": " Title: Self-supervised learning with rotation-invariant kernels ",
    "url": "https://arxiv.org/abs/2208.00789",
    "authors": [
      "L\u00e9on Zheng",
      "Gilles Puy",
      "Elisa Riccietti",
      "Patrick P\u00e9rez",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.02433",
    "title": "Simulation and application of COVID-19 compartment model using  physics-informed neural network",
    "abstract": " Title: Simulation and application of COVID-19 compartment model using  physics-informed neural network ",
    "url": "https://arxiv.org/abs/2208.02433",
    "authors": [
      "Jinhuan Ke",
      "Jiahao Ma",
      "Xiyu Yin",
      "Robin Singh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2208.04950",
    "title": "BabyNet: A Lightweight Network for Infant Reaching Action Recognition in  Unconstrained Environments to Support Future Pediatric Rehabilitation  Applications",
    "abstract": " Comments: Accepted to RO-MAN 2021 ",
    "url": "https://arxiv.org/abs/2208.04950",
    "authors": [
      "Amel Dechemi",
      "Vikarn Bhakri",
      "Ipsita Sahin",
      "Arjun Modi",
      "Julya Mestas",
      "Pamodya Peiris",
      "Dannya Enriquez Barrundia",
      "Elena Kokkoni",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.05117",
    "title": "NOTE: Robust Continual Test-time Adaptation Against Temporal Correlation",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2208.05117",
    "authors": [
      "Taesik Gong",
      "Jongheon Jeong",
      "Taewon Kim",
      "Yewon Kim",
      "Jinwoo Shin",
      "Sung-Ju Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06195",
    "title": "Category-Level Pose Retrieval with Contrastive Features Learnt with  Occlusion Augmentation",
    "abstract": " Comments: 29 pages, 16 Figures, 14 tables, BMVC 2022 ",
    "url": "https://arxiv.org/abs/2208.06195",
    "authors": [
      "Georgios Kouros",
      "Shubham Shrivastava",
      "C\u00e9dric Picron",
      "Sushruth Nagesh",
      "Punarjay Chakravarty",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.08012",
    "title": "Disentangled Speaker Representation Learning via Mutual Information  Minimization",
    "abstract": " Comments: Accepted by APSIPA ASC 2022. Camera-ready. 8 pages, 4 figures, and 1 table ",
    "url": "https://arxiv.org/abs/2208.08012",
    "authors": [
      "Sung Hwan Mun",
      "Min Hyun Han",
      "Minchan Kim",
      "Dongjune Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2208.13066",
    "title": "SA: Sliding attack for synthetic speech detection with resistance to  clipping and self-splicing",
    "abstract": " Comments: Updated description and formula ",
    "url": "https://arxiv.org/abs/2208.13066",
    "authors": [
      "Deng JiaCheng",
      "Dong Li",
      "Yan Diqun",
      "Wang Rangding",
      "Zeng Jiaming"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.13701",
    "title": "Empirical Gateaux Derivatives for Causal Inference",
    "abstract": " Comments: Comments welcome; conference version accepted at Neurips 2022 ",
    "url": "https://arxiv.org/abs/2208.13701",
    "authors": [
      "Michael I. Jordan",
      "Yixin Wang",
      "Angela Zhou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.05471",
    "title": "PATE: Property, Amenities, Traffic and Emotions Coming Together for Real  Estate Price Prediction",
    "abstract": " Comments: Accepted by IEEE DSAA 2022. 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2209.05471",
    "authors": [
      "Yaping Zhao",
      "Ramgopal Ravi",
      "Shuhui Shi",
      "Zhongrui Wang",
      "Edmund Y. Lam",
      "Jichang Zhao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2209.07413",
    "title": "EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring",
    "abstract": " Title: EZNAS: Evolving Zero Cost Proxies For Neural Architecture Scoring ",
    "url": "https://arxiv.org/abs/2209.07413",
    "authors": [
      "Yash Akhauri",
      "J. Pablo Munoz",
      "Nilesh Jain",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.08514",
    "title": "Imbalanced Node Processing Method in Graph Neural Network Classification  Task",
    "abstract": " Comments: Insufficient experiments, will continue to study in depth ",
    "url": "https://arxiv.org/abs/2209.08514",
    "authors": [
      "Min Liu",
      "Siwen Jin",
      "Luo Jin",
      "Shuohan Wang",
      "Yu Fang",
      "Yuliang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12362",
    "title": "Multi-dataset Training of Transformers for Robust Action Recognition",
    "abstract": " Comments: Accepted by NeurIPS 2022. Camera-ready. Code and models are available at this https URL ",
    "url": "https://arxiv.org/abs/2209.12362",
    "authors": [
      "Junwei Liang",
      "Enwei Zhang",
      "Jun Zhang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.13507",
    "title": "CrossDTR: Cross-view and Depth-guided Transformers for 3D Object  Detection",
    "abstract": " Title: CrossDTR: Cross-view and Depth-guided Transformers for 3D Object  Detection ",
    "url": "https://arxiv.org/abs/2209.13507",
    "authors": [
      "Ching-Yu Tseng",
      "Yi-Rong Chen",
      "Hsin-Ying Lee",
      "Tsung-Han Wu",
      "Wen-Chin Chen",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14369",
    "title": "Social Search: retrieving information in Online Social Platforms -- A  Survey",
    "abstract": " Title: Social Search: retrieving information in Online Social Platforms -- A  Survey ",
    "url": "https://arxiv.org/abs/2209.14369",
    "authors": [
      "Maddalena Amendola",
      "Andrea Passarella",
      "Raffaele Perego"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.15190",
    "title": "Neural Integral Equations",
    "abstract": " Comments: 10 + 12 pages, 12 figures and 7 tables. Comments are welcome! v2: One reference has been fixed. Codes will be made public after the peer-review process ",
    "url": "https://arxiv.org/abs/2209.15190",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Josue Ortega Caro",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.00453",
    "title": "Neural Graphical Models",
    "abstract": " Title: Neural Graphical Models ",
    "url": "https://arxiv.org/abs/2210.00453",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02191",
    "title": "On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks",
    "abstract": " Title: On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2210.02191",
    "authors": [
      "Huimin Zeng",
      "Zhenrui Yue",
      "Yang Zhang",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02713",
    "title": "On Optimal Learning Under Targeted Data Poisoning",
    "abstract": " Title: On Optimal Learning Under Targeted Data Poisoning ",
    "url": "https://arxiv.org/abs/2210.02713",
    "authors": [
      "Steve Hanneke",
      "Amin Karbasi",
      "Mohammad Mahmoody",
      "Idan Mehalel",
      "Shay Moran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.04074",
    "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection of  Events",
    "abstract": " Title: Are All Steps Equally Important? Benchmarking Essentiality Detection of  Events ",
    "url": "https://arxiv.org/abs/2210.04074",
    "authors": [
      "Hongming Zhang",
      "Yueguan Wang",
      "Yuqian Deng",
      "Haoyu Wang",
      "Muhao Chen",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04114",
    "title": "Towards Real-Time Temporal Graph Learning",
    "abstract": " Title: Towards Real-Time Temporal Graph Learning ",
    "url": "https://arxiv.org/abs/2210.04114",
    "authors": [
      "Deniz Gurevin",
      "Mohsin Shan",
      "Tong Geng",
      "Weiwen Jiang",
      "Caiwen Ding",
      "Omer Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04318",
    "title": "Prediction intervals for neural network models using weighted asymmetric  loss functions",
    "abstract": " Comments: 14 pages, 4 figures, not submitted for conference yet as of 09-10-2022 ",
    "url": "https://arxiv.org/abs/2210.04318",
    "authors": [
      "Milo Grillo",
      "Agnieszka Werpachowska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04633",
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models  for Programming Language Attend Code Structure",
    "abstract": " Comments: To appear in EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.04633",
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.04828",
    "title": "Assessing Neural Referential Form Selectors on a Realistic Multilingual  Dataset",
    "abstract": " Comments: Eval4NLP workshop ",
    "url": "https://arxiv.org/abs/2210.04828",
    "authors": [
      "Guanyi Chen",
      "Fahime Same",
      "Kees van Deemter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05152",
    "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "abstract": " Comments: 22 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.05152",
    "authors": [
      "Dan Zhang",
      "Rui Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05236",
    "title": "Planning Assembly Sequence with Graph Transformer",
    "abstract": " Comments: Submitted to ICRA2023 ",
    "url": "https://arxiv.org/abs/2210.05236",
    "authors": [
      "Lin Ma",
      "Jiangtao Gong",
      "Hao Xu",
      "Hao Chen",
      "Hao Zhao",
      "Wenbing Huang",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05287",
    "title": "Revisiting and Advancing Chinese Natural Language Understanding with  Accelerated Heterogeneous Knowledge Pre-training",
    "abstract": " Comments: EMNLP 2022 industry track ",
    "url": "https://arxiv.org/abs/2210.05287",
    "authors": [
      "Taolin Zhang",
      "Junwei Dong",
      "Jianing Wang",
      "Chengyu Wang",
      "Ang Wang",
      "Yinghui Liu",
      "Jun Huang",
      "Yong Li",
      "Xiaofeng He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05567",
    "title": "Global Spectral Filter Memory Network for Video Object Segmentation",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2210.05567",
    "authors": [
      "Yong Liu",
      "Ran Yu",
      "Jiahao Wang",
      "Xinyuan Zhao",
      "Yitong Wang",
      "Yansong Tang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05574",
    "title": "Motion Aware Self-Supervision for Generic Event Boundary Detection",
    "abstract": " Comments: Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2210.05574",
    "authors": [
      "Ayush K. Rai",
      "Tarun Krishna",
      "Julia Dietlmeier",
      "Kevin McGuinness",
      "Alan F. Smeaton",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]