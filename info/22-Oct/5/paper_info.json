[
  {
    "id": "arXiv:2210.01126",
    "title": "Wheel Impact Test by Deep Learning: Prediction of Location and Magnitude  of Maximum Stress",
    "abstract": "The impact performance of the wheel during wheel development must be ensured through a wheel impact test for vehicle safety. However, manufacturing and testing a real wheel take a significant amount of time and money because developing an optimal wheel design requires numerous iterative processes of modifying the wheel design and verifying the safety performance. Accordingly, the actual wheel impact test has been replaced by computer simulations, such as Finite Element Analysis (FEA), but it still requires high computational costs for modeling and analysis. Moreover, FEA experts are needed. This study presents an aluminum road wheel impact performance prediction model based on deep learning that replaces the computationally expensive and time-consuming 3D FEA. For this purpose, 2D disk-view wheel image data, 3D wheel voxel data, and barrier mass value used for wheel impact test are utilized as the inputs to predict the magnitude of maximum von Mises stress, corresponding location, and the stress distribution of 2D disk-view. The wheel impact performance prediction model can replace the impact test in the early wheel development stage by predicting the impact performance in real time and can be used without domain knowledge. The time required for the wheel development process can be shortened through this mechanism. ",
    "url": "https://arxiv.org/abs/2210.01126",
    "authors": [
      "Seungyeon Shin",
      "Ah-hyeon Jin",
      "Soyoung Yoo",
      "Sunghee Lee",
      "ChangGon Kim",
      "Sungpil Heo",
      "Namwoo Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01166",
    "title": "NARF22: Neural Articulated Radiance Fields for Configuration-Aware  Rendering",
    "abstract": "Articulated objects pose a unique challenge for robotic perception and manipulation. Their increased number of degrees-of-freedom makes tasks such as localization computationally difficult, while also making the process of real-world dataset collection unscalable. With the aim of addressing these scalability issues, we propose Neural Articulated Radiance Fields (NARF22), a pipeline which uses a fully-differentiable, configuration-parameterized Neural Radiance Field (NeRF) as a means of providing high quality renderings of articulated objects. NARF22 requires no explicit knowledge of the object structure at inference time. We propose a two-stage parts-based training mechanism which allows the object rendering models to generalize well across the configuration space even if the underlying training data has as few as one configuration represented. We demonstrate the efficacy of NARF22 by training configurable renderers on a real-world articulated tool dataset collected via a Fetch mobile manipulation robot. We show the applicability of the model to gradient-based inference methods through a configuration estimation and 6 degree-of-freedom pose refinement task. The project webpage is available at: https://progress.eecs.umich.edu/projects/narf/. ",
    "url": "https://arxiv.org/abs/2210.01166",
    "authors": [
      "Stanley Lewis",
      "Jana Pavlasek",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01171",
    "title": "TPGNN: Learning High-order Information in Dynamic Graphs via Temporal  Propagation",
    "abstract": "Temporal graph is an abstraction for modeling dynamic systems that consist of evolving interaction elements. In this paper, we aim to solve an important yet neglected problem -- how to learn information from high-order neighbors in temporal graphs? -- to enhance the informativeness and discriminativeness for the learned node representations. We argue that when learning high-order information from temporal graphs, we encounter two challenges, i.e., computational inefficiency and over-smoothing, that cannot be solved by conventional techniques applied on static graphs. To remedy these deficiencies, we propose a temporal propagation-based graph neural network, namely TPGNN. To be specific, the model consists of two distinct components, i.e., propagator and node-wise encoder. The propagator is leveraged to propagate messages from the anchor node to its temporal neighbors within $k$-hop, and then simultaneously update the state of neighborhoods, which enables efficient computation, especially for a deep model. In addition, to prevent over-smoothing, the model compels the messages from $n$-hop neighbors to update the $n$-hop memory vector preserved on the anchor. The node-wise encoder adopts transformer architecture to learn node representations by explicitly learning the importance of memory vectors preserved on the node itself, that is, implicitly modeling the importance of messages from neighbors at different layers, thus mitigating the over-smoothing. Since the encoding process will not query temporal neighbors, we can dramatically save time consumption in inference. Extensive experiments on temporal link prediction and node classification demonstrate the superiority of TPGNN over state-of-the-art baselines in efficiency and robustness. ",
    "url": "https://arxiv.org/abs/2210.01171",
    "authors": [
      "Zehong Wang",
      "Qi Li",
      "Donghua Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.01185",
    "title": "ContraGen: Effective Contrastive Learning For Causal Language Model",
    "abstract": "Despite exciting progress in large-scale language generation, the expressiveness of its representations is severely limited by the \\textit{anisotropy} issue where the hidden representations are distributed into a narrow cone in the vector space. To address this issue, we present ContraGen, a novel contrastive learning framework to improve the representation with better uniformity and discrimination. We assess ContraGen on a wide range of downstream tasks in natural and programming languages. We show that ContraGen can effectively enhance both uniformity and discrimination of the representations and lead to the desired improvement on various language understanding tasks where discriminative representations are crucial for attaining good performance. Specifically, we attain $44\\%$ relative improvement on the Semantic Textual Similarity tasks and $34\\%$ on Code-to-Code Search tasks. Furthermore, by improving the expressiveness of the representations, ContraGen also boosts the source code generation capability with $9\\%$ relative improvement on execution accuracy on the HumanEval benchmark. ",
    "url": "https://arxiv.org/abs/2210.01185",
    "authors": [
      "Nihal Jain",
      "Dejiao Zhang",
      "Wasi Uddin Ahmad",
      "Zijian Wang",
      "Feng Nan",
      "Xiaopeng Li",
      "Ming Tan",
      "Ramesh Nallapati",
      "Baishakhi Ray",
      "Parminder Bhatia",
      "Xiaofei Ma",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01191",
    "title": "Extending Compositional Attention Networks for Social Reasoning in  Videos",
    "abstract": "We propose a novel deep architecture for the task of reasoning about social interactions in videos. We leverage the multi-step reasoning capabilities of Compositional Attention Networks (MAC), and propose a multimodal extension (MAC-X). MAC-X is based on a recurrent cell that performs iterative mid-level fusion of input modalities (visual, auditory, text) over multiple reasoning steps, by use of a temporal attention mechanism. We then combine MAC-X with LSTMs for temporal input processing in an end-to-end architecture. Our ablation studies show that the proposed MAC-X architecture can effectively leverage multimodal input cues using mid-level fusion mechanisms. We apply MAC-X to the task of Social Video Question Answering in the Social IQ dataset and obtain a 2.5% absolute improvement in terms of binary accuracy over the current state-of-the-art. ",
    "url": "https://arxiv.org/abs/2210.01191",
    "authors": [
      "Christina Sartzetaki",
      "Georgios Paraskevopoulos",
      "Alexandros Potamianos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01213",
    "title": "Robust Active Distillation",
    "abstract": "Distilling knowledge from a large teacher model to a lightweight one is a widely successful approach for generating compact, powerful models in the semi-supervised learning setting where a limited amount of labeled data is available. In large-scale applications, however, the teacher tends to provide a large number of incorrect soft-labels that impairs student performance. The sheer size of the teacher additionally constrains the number of soft-labels that can be queried due to prohibitive computational and/or financial costs. The difficulty in achieving simultaneous \\emph{efficiency} (i.e., minimizing soft-label queries) and \\emph{robustness} (i.e., avoiding student inaccuracies due to incorrect labels) hurts the widespread application of knowledge distillation to many modern tasks. In this paper, we present a parameter-free approach with provable guarantees to query the soft-labels of points that are simultaneously informative and correctly labeled by the teacher. At the core of our work lies a game-theoretic formulation that explicitly considers the inherent trade-off between the informativeness and correctness of input instances. We establish bounds on the expected performance of our approach that hold even in worst-case distillation instances. We present empirical evaluations on popular benchmarks that demonstrate the improved distillation performance enabled by our work relative to that of state-of-the-art active learning and active distillation methods. ",
    "url": "https://arxiv.org/abs/2210.01213",
    "authors": [
      "Cenk Baykal",
      "Khoa Trinh",
      "Fotis Iliopoulos",
      "Gaurav Menghani",
      "Erik Vee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01217",
    "title": "One-shot Detail Retouching with Patch Space Neural Field based  Transformation Blending",
    "abstract": "Photo retouching is a difficult task for novice users as it requires expert knowledge and advanced tools. Photographers often spend a great deal of time generating high-quality retouched photos with intricate details. In this paper, we introduce a one-shot learning based technique to automatically retouch details of an input image based on just a single pair of before and after example images. Our approach provides accurate and generalizable detail edit transfer to new images. We achieve these by proposing a new representation for image to image maps. Specifically, we propose neural field based transformation blending in the patch space for defining patch to patch transformations for each frequency band. This parametrization of the map with anchor transformations and associated weights, and spatio-spectral localized patches, allows us to capture details well while staying generalizable. We evaluate our technique both on known ground truth filtes and artist retouching edits. Our method accurately transfers complex detail retouching edits. ",
    "url": "https://arxiv.org/abs/2210.01217",
    "authors": [
      "Fazilet Gokbudak",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.01238",
    "title": "Towards Performance Portable Programming for Distributed Heterogeneous  Systems",
    "abstract": "Hardware heterogeneity is here to stay for high-performance computing. Large-scale systems are currently equipped with multiple GPU accelerators per compute node and are expected to incorporate more specialized hardware in the future. This shift in the computing ecosystem offers many opportunities for performance improvement; however, it also increases the complexity of programming for such architectures. This work introduces a runtime framework that enables effortless programming for heterogeneous systems while efficiently utilizing hardware resources. The framework is integrated within a distributed and scalable runtime system to facilitate performance portability across heterogeneous nodes. Along with the design, this paper describes the implementation and optimizations performed, achieving up to 300% improvement in a shared memory benchmark and up to 10 times in distributed device communication. Preliminary results indicate that our software incurs low overhead and achieves 40% improvement in a distributed Jacobi proxy application while hiding the idiosyncrasies of the hardware. ",
    "url": "https://arxiv.org/abs/2210.01238",
    "authors": [
      "Polykarpos Thomadakis",
      "Nikos Chrisochoides"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.01244",
    "title": "Event-based Temporally Dense Optical Flow Estimation with Sequential  Neural Networks",
    "abstract": "Prior works on event-based optical flow estimation have investigated several gradient-based learning methods to train neural networks for predicting optical flow. However, they do not utilize the fast data rate of event data streams and rely on a spatio-temporal representation constructed from a collection of events over a fixed period of time (often between two grayscale frames). As a result, optical flow is only evaluated at a frequency much lower than the rate data is produced by an event-based camera, leading to a temporally sparse optical flow estimation. To predict temporally dense optical flow, we cast the problem as a sequential learning task and propose a training methodology to train sequential networks for continuous prediction on an event stream. We propose two types of networks: one focused on performance and another focused on compute efficiency. We first train long-short term memory networks (LSTMs) on the DSEC dataset and demonstrated 10x temporally dense optical flow estimation over existing flow estimation approaches. The additional benefit of having a memory to draw long temporal correlations back in time results in a 19.7% improvement in flow prediction accuracy of LSTMs over similar networks with no memory elements. We subsequently show that the inherent recurrence of spiking neural networks (SNNs) enables them to learn and estimate temporally dense optical flow with 31.8% lesser parameters than LSTM, but with a slightly increased error. This demonstrates potential for energy-efficient implementation of fast optical flow prediction using SNNs. ",
    "url": "https://arxiv.org/abs/2210.01244",
    "authors": [
      "Wachirawit Ponghiran",
      "Chamika Mihiranga Liyanagedera",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.01245",
    "title": "Random orthogonal additive filters: a solution to the  vanishing/exploding gradient of deep neural networks",
    "abstract": "Since the recognition in the early nineties of the vanishing/exploding (V/E) gradient issue plaguing the training of neural networks (NNs), significant efforts have been exerted to overcome this obstacle. However, a clear solution to the V/E issue remained elusive so far. In this manuscript a new architecture of NN is proposed, designed to mathematically prevent the V/E issue to occur. The pursuit of approximate dynamical isometry, i.e. parameter configurations where the singular values of the input-output Jacobian are tightly distributed around 1, leads to the derivation of a NN's architecture that shares common traits with the popular Residual Network model. Instead of skipping connections between layers, the idea is to filter the previous activations orthogonally and add them to the nonlinear activations of the next layer, realising a convex combination between them. Remarkably, the impossibility for the gradient updates to either vanish or explode is demonstrated with analytical bounds that hold even in the infinite depth case. The effectiveness of this method is empirically proved by means of training via backpropagation an extremely deep multilayer perceptron of 50k layers, and an Elman NN to learn long-term dependencies in the input of 10k time steps in the past. Compared with other architectures specifically devised to deal with the V/E problem, e.g. LSTMs for recurrent NNs, the proposed model is way simpler yet more effective. Surprisingly, a single layer vanilla RNN can be enhanced to reach state of the art performance, while converging super fast; for instance on the psMNIST task, it is possible to get test accuracy of over 94% in the first epoch, and over 98% after just 10 epochs. ",
    "url": "https://arxiv.org/abs/2210.01245",
    "authors": [
      "Andrea Ceni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.01249",
    "title": "LOPR: Latent Occupancy PRediction using Generative Models",
    "abstract": "Environment prediction frameworks are essential for autonomous vehicles to facilitate safe maneuvers in a dynamic environment. Previous approaches have used occupancy grid maps as a bird's eye-view representation of the scene and optimized the prediction architectures directly in pixel space. Although these methods have had some success in spatiotemporal prediction, they are, at times, hindered by unrealistic and incorrect predictions. We postulate that the quality and realism of the forecasted occupancy grids can be improved with the use of generative models. We propose a framework that decomposes occupancy grid prediction into task-independent low-dimensional representation learning and task-dependent prediction in the latent space. We demonstrate that our approach achieves state-of-the-art performance on the real-world autonomous driving dataset, NuScenes. ",
    "url": "https://arxiv.org/abs/2210.01249",
    "authors": [
      "Bernard Lange",
      "Masha Itkina",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01257",
    "title": "Convolutional networks inherit frequency sensitivity from image  statistics",
    "abstract": "It is widely acknowledged that trained convolutional neural networks (CNNs) have different levels of sensitivity to signals of different frequency. In particular, a number of empirical studies have documented CNNs sensitivity to low-frequency signals. In this work we show with theory and experiments that this observed sensitivity is a consequence of the frequency distribution of natural images, which is known to have most of its power concentrated in low-to-mid frequencies. Our theoretical analysis relies on representations of the layers of a CNN in frequency space, an idea that has previously been used to accelerate computations and study implicit bias of network training algorithms, but to the best of our knowledge has not been applied in the domain of model robustness. ",
    "url": "https://arxiv.org/abs/2210.01257",
    "authors": [
      "Charles Godfrey",
      "Elise Bishoff",
      "Myles Mckay",
      "Davis Brown",
      "Grayson Jorgenson",
      "Henry Kvinge",
      "Eleanor Byler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01258",
    "title": "Understanding Prior Bias and Choice Paralysis in Transformer-based  Language Representation Models through Four Experimental Probes",
    "abstract": "Recent work on transformer-based neural networks has led to impressive advances on multiple-choice natural language understanding (NLU) problems, such as Question Answering (QA) and abductive reasoning. Despite these advances, there is limited work still on understanding whether these models respond to perturbed multiple-choice instances in a sufficiently robust manner that would allow them to be trusted in real-world situations. We present four confusion probes, inspired by similar phenomena first identified in the behavioral science community, to test for problems such as prior bias and choice paralysis. Experimentally, we probe a widely used transformer-based multiple-choice NLU system using four established benchmark datasets. Here we show that the model exhibits significant prior bias and to a lesser, but still highly significant degree, choice paralysis, in addition to other problems. Our results suggest that stronger testing protocols and additional benchmarks may be necessary before the language models are used in front-facing systems or decision making with real world consequences. ",
    "url": "https://arxiv.org/abs/2210.01258",
    "authors": [
      "Ke Shen",
      "Mayank Kejriwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01260",
    "title": "Enriching Vulnerability Reports Through Automated and Augmented  Description Summarization",
    "abstract": "Security incidents and data breaches are increasing rapidly, and only a fraction of them is being reported. Public vulnerability databases, e.g., national vulnerability database (NVD) and common vulnerability and exposure (CVE), have been leading the effort in documenting vulnerabilities and sharing them to aid defenses. Both are known for many issues, including brief vulnerability descriptions. Those descriptions play an important role in communicating the vulnerability information to security analysts in order to develop the appropriate countermeasure. Many resources provide additional information about vulnerabilities, however, they are not utilized to boost public repositories. In this paper, we devise a pipeline to augment vulnerability description through third party reference (hyperlink) scrapping. To normalize the description, we build a natural language summarization pipeline utilizing a pretrained language model that is fine-tuned using labeled instances and evaluate its performance against both human evaluation (golden standard) and computational metrics, showing initial promising results in terms of summary fluency, completeness, correctness, and understanding. ",
    "url": "https://arxiv.org/abs/2210.01260",
    "authors": [
      "Hattan Althebeiti",
      "David Mohaisen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01274",
    "title": "Random Weight Factorization Improves the Training of Continuous Neural  Representations",
    "abstract": "Continuous neural representations have recently emerged as a powerful and flexible alternative to classical discretized representations of signals. However, training them to capture fine details in multi-scale signals is difficult and computationally expensive. Here we propose random weight factorization as a simple drop-in replacement for parameterizing and initializing conventional linear layers in coordinate-based multi-layer perceptrons (MLPs) that significantly accelerates and improves their training. We show how this factorization alters the underlying loss landscape and effectively enables each neuron in the network to learn using its own self-adaptive learning rate. This not only helps with mitigating spectral bias, but also allows networks to quickly recover from poor initializations and reach better local minima. We demonstrate how random weight factorization can be leveraged to improve the training of neural representations on a variety of tasks, including image regression, shape representation, computed tomography, inverse rendering, solving partial differential equations, and learning operators between function spaces. ",
    "url": "https://arxiv.org/abs/2210.01274",
    "authors": [
      "Sifan Wang",
      "Hanwen Wang",
      "Jacob H. Seidman",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01288",
    "title": "Strength-Adaptive Adversarial Training",
    "abstract": "Adversarial training (AT) is proved to reliably improve network's robustness against adversarial data. However, current AT with a pre-specified perturbation budget has limitations in learning a robust network. Firstly, applying a pre-specified perturbation budget on networks of various model capacities will yield divergent degree of robustness disparity between natural and robust accuracies, which deviates from robust network's desideratum. Secondly, the attack strength of adversarial training data constrained by the pre-specified perturbation budget fails to upgrade as the growth of network robustness, which leads to robust overfitting and further degrades the adversarial robustness. To overcome these limitations, we propose \\emph{Strength-Adaptive Adversarial Training} (SAAT). Specifically, the adversary employs an adversarial loss constraint to generate adversarial training data. Under this constraint, the perturbation budget will be adaptively adjusted according to the training state of adversarial data, which can effectively avoid robust overfitting. Besides, SAAT explicitly constrains the attack strength of training data through the adversarial loss, which manipulates model capacity scheduling during training, and thereby can flexibly control the degree of robustness disparity and adjust the tradeoff between natural accuracy and robustness. Extensive experiments show that our proposal boosts the robustness of adversarial training. ",
    "url": "https://arxiv.org/abs/2210.01288",
    "authors": [
      "Chaojian Yu",
      "Dawei Zhou",
      "Li Shen",
      "Jun Yu",
      "Bo Han",
      "Mingming Gong",
      "Nannan Wang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01297",
    "title": "Privacy-Preserving Link Prediction",
    "abstract": "Consider two data holders, ABC and XYZ, with graph data (e.g., social networks, e-commerce, telecommunication, and bio-informatics). ABC can see that node A is linked to node B, and XYZ can see node B is linked to node C. Node B is the common neighbour of A and C but neither network can discover this fact on their own. In this paper, we provide a two party computation that ABC and XYZ can run to discover the common neighbours in the union of their graph data, however neither party has to reveal their plaintext graph to the other. Based on private set intersection, we implement our solution, provide measurements, and quantify partial leaks of privacy. We also propose a heavyweight solution that leaks zero information based on additively homomorphic encryption. ",
    "url": "https://arxiv.org/abs/2210.01297",
    "authors": [
      "Didem Demirag",
      "Mina Namazi",
      "Erman Ayday",
      "Jeremy Clark"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01301",
    "title": "GIDN: A Lightweight Graph Inception Diffusion Network for High-efficient  Link Prediction",
    "abstract": "In this paper, we propose a Graph Inception Diffusion Networks(GIDN) model. This model generalizes graph diffusion in different feature spaces, and uses the inception module to avoid the large amount of computations caused by complex network structures. We evaluate GIDN model on Open Graph Benchmark(OGB) datasets, reached an 11% higher performance than AGDN on ogbl-collab dataset. ",
    "url": "https://arxiv.org/abs/2210.01301",
    "authors": [
      "Zixiao Wang",
      "Yuluo Guo",
      "Jin Zhao",
      "Yu Zhang",
      "Hui Yu",
      "Xiaofei Liao",
      "Hai Jin",
      "Biao Wang",
      "Ting Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.01302",
    "title": "Nuisances via Negativa: Adjusting for Spurious Correlations via Data  Augmentation",
    "abstract": "There exist features that are related to the label in the same way across different settings for that task; these are semantic features or semantics. Features with varying relationships to the label are nuisances. For example, in detecting cows from natural images, the shape of the head is a semantic and because images of cows often have grass backgrounds but only in certain settings, the background is a nuisance. Relationships between a nuisance and the label are unstable across settings and, consequently, models that exploit nuisance-label relationships face performance degradation when these relationships change. Direct knowledge of a nuisance helps build models that are robust to such changes, but knowledge of a nuisance requires extra annotations beyond the label and the covariates. In this paper, we develop an alternative way to produce robust models by data augmentation. These data augmentations corrupt semantic information to produce models that identify and adjust for where nuisances drive predictions. We study semantic corruptions in powering different robust-modeling methods for multiple out-of distribution (OOD) tasks like classifying waterbirds, natural language inference, and detecting Cardiomegaly in chest X-rays. ",
    "url": "https://arxiv.org/abs/2210.01302",
    "authors": [
      "Aahlad Puli",
      "Nitish Joshi",
      "He He",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01307",
    "title": "Beam Management in Ultra-dense mmWave Network via Federated  Reinforcement Learning: An Intelligent and Secure Approach",
    "abstract": "Deploying ultra-dense networks that operate on millimeter wave (mmWave) band is a promising way to address the tremendous growth on mobile data traffic. However, one key challenge of ultra-dense mmWave network (UDmmN) is beam management due to the high propagation delay, limited beam coverage as well as numerous beams and users. In this paper, a novel systematic beam control scheme is presented to tackle the beam management problem which is difficult due to the nonconvex objective function. We employ double deep Q-network (DDQN) under a federated learning (FL) framework to address the above optimization problem, and thereby fulfilling adaptive and intelligent beam management in UDmmN. In the proposed beam management scheme based on FL (BMFL), the non-rawdata aggregation can theoretically protect user privacy while reducing handoff cost. Moreover, we propose to adopt a data cleaning technique in the local model training for BMFL, with the aim to further strengthen the privacy protection of users while improving the learning convergence speed. Simulation results demonstrate the performance gain of our proposed scheme. ",
    "url": "https://arxiv.org/abs/2210.01307",
    "authors": [
      "Qing Xue",
      "Yi-Jing Liu",
      "Yao Sun",
      "Jian Wang",
      "Li Yan",
      "Gang Feng",
      "Shaodan Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01315",
    "title": "Concurrent build direction, part segmentation, and topology optimization  for additive manufacturing using neural networks",
    "abstract": "We propose a neural network-based approach to topology optimization that aims to reduce the use of support structures in additive manufacturing. Our approach uses a network architecture that allows the simultaneous determination of an optimized: (1) part segmentation, (2) the topology of each part, and (3) the build direction of each part that collectively minimize the amount of support structure. Through training, the network learns a material density and segment classification in the continuous 3D space. Given a problem domain with prescribed load and displacement boundary conditions, the neural network takes as input 3D coordinates of the voxelized domain as training samples and outputs a continuous density field. Since the neural network for topology optimization learns the density distribution field, analytical solutions to the density gradient can be obtained from the input-output relationship of the neural network. We demonstrate our approach on several compliance minimization problems with volume fraction constraints, where support volume minimization is added as an additional criterion to the objective function. We show that simultaneous optimization of part segmentation along with the topology and print angle optimization further reduces the support structure, compared to a combined print angle and topology optimization without segmentation. ",
    "url": "https://arxiv.org/abs/2210.01315",
    "authors": [
      "Hongrui Chen",
      "Aditya Joglekar",
      "Kate S. Whitefoot",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01325",
    "title": "Automated Medical Device Display Reading Using Deep Learning Object  Detection",
    "abstract": "Telemedicine and mobile health applications, especially during the quarantine imposed by the covid-19 pandemic, led to an increase on the need of transferring health monitor readings from patients to specialists. Considering that most home medical devices use seven-segment displays, an automatic display reading algorithm should provide a more reliable tool for remote health care. This work proposes an end-to-end method for detection and reading seven-segment displays from medical devices based on deep learning object detection models. Two state of the art model families, EfficientDet and EfficientDet-lite, previously trained with the MS-COCO dataset, were fine-tuned on a dataset comprised by medical devices photos taken with mobile digital cameras, to simulate real case applications. Evaluation of the trained model show high efficiency, where all models achieved more than 98% of detection precision and more than 98% classification accuracy, with model EfficientDet-lite1 showing 100% detection precision and 100% correct digit classification for a test set of 104 images and 438 digits. ",
    "url": "https://arxiv.org/abs/2210.01325",
    "authors": [
      "Lucas P. Moreira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01338",
    "title": "Learning to Collocate Visual-Linguistic Neural Modules for Image  Captioning",
    "abstract": "Humans tend to decompose a sentence into different parts like \\textsc{sth do sth at someplace} and then fill each part with certain content. Inspired by this, we follow the \\textit{principle of modular design} to propose a novel image captioner: learning to Collocate Visual-Linguistic Neural Modules (CVLNM). Unlike the \\re{widely used} neural module networks in VQA, where the language (\\ie, question) is fully observable, \\re{the task of collocating visual-linguistic modules is more challenging.} This is because the language is only partially observable, for which we need to dynamically collocate the modules during the process of image captioning. To sum up, we make the following technical contributions to design and train our CVLNM: 1) \\textit{distinguishable module design} -- \\re{four modules in the encoder} including one linguistic module for function words and three visual modules for different content words (\\ie, noun, adjective, and verb) and another linguistic one in the decoder for commonsense reasoning, 2) a self-attention based \\textit{module controller} for robustifying the visual reasoning, 3) a part-of-speech based \\textit{syntax loss} imposed on the module controller for further regularizing the training of our CVLNM. Extensive experiments on the MS-COCO dataset show that our CVLNM is more effective, \\eg, achieving a new state-of-the-art 129.5 CIDEr-D, and more robust, \\eg, being less likely to overfit to dataset bias and suffering less when fewer training samples are available. Codes are available at \\url{https://github.com/GCYZSL/CVLMN} ",
    "url": "https://arxiv.org/abs/2210.01338",
    "authors": [
      "Xu Yang",
      "Hanwang Zhang",
      "Chongyang Gao",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01346",
    "title": "ImmFusion: Robust mmWave-RGB Fusion for 3D Human Body Reconstruction in  All Weather Conditions",
    "abstract": "3D human reconstruction from RGB images achieves decent results in good weather conditions but degrades dramatically in rough weather. Complementary, mmWave radars have been employed to reconstruct 3D human joints and meshes in rough weather. However, combining RGB and mmWave signals for robust all-weather 3D human reconstruction is still an open challenge, given the sparse nature of mmWave and the vulnerability of RGB images. In this paper, we present ImmFusion, the first mmWave-RGB fusion solution to reconstruct 3D human bodies in all weather conditions robustly. Specifically, our ImmFusion consists of image and point backbones for token feature extraction and a Transformer module for token fusion. The image and point backbones refine global and local features from original data, and the Fusion Transformer Module aims for effective information fusion of two modalities by dynamically selecting informative tokens. Extensive experiments on a large-scale dataset, mmBody, captured in various environments demonstrate that ImmFusion can efficiently utilize the information of two modalities to achieve a robust 3D human body reconstruction in all weather conditions. In addition, our method's accuracy is significantly superior to that of state-of-the-art Transformer-based LiDAR-camera fusion methods. ",
    "url": "https://arxiv.org/abs/2210.01346",
    "authors": [
      "Anjun Chen",
      "Xiangyu Wang",
      "Kun Shi",
      "Shaohao Zhu",
      "Yingfeng Chen",
      "Bin Fang",
      "Jiming Chen",
      "Yuchi Huo",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01348",
    "title": "Fast Saturating Gate for Learning Long Time Scales with Recurrent Neural  Networks",
    "abstract": "Gate functions in recurrent models, such as an LSTM and GRU, play a central role in learning various time scales in modeling time series data by using a bounded activation function. However, it is difficult to train gates to capture extremely long time scales due to gradient vanishing of the bounded function for large inputs, which is known as the saturation problem. We closely analyze the relation between saturation of the gate function and efficiency of the training. We prove that the gradient vanishing of the gate function can be mitigated by accelerating the convergence of the saturating function, i.e., making the output of the function converge to 0 or 1 faster. Based on the analysis results, we propose a gate function called fast gate that has a doubly exponential convergence rate with respect to inputs by simple function composition. We empirically show that our method outperforms previous methods in accuracy and computational efficiency on benchmark tasks involving extremely long time scales. ",
    "url": "https://arxiv.org/abs/2210.01348",
    "authors": [
      "Kentaro Ohno",
      "Sekitoshi Kanai",
      "Yasutoshi Ida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.01360",
    "title": "Learning an Invertible Output Mapping Can Mitigate Simplicity Bias in  Neural Networks",
    "abstract": "Deep Neural Networks are known to be brittle to even minor distribution shifts compared to the training distribution. While one line of work has demonstrated that Simplicity Bias (SB) of DNNs - bias towards learning only the simplest features - is a key reason for this brittleness, another recent line of work has surprisingly found that diverse/ complex features are indeed learned by the backbone, and their brittleness is due to the linear classification head relying primarily on the simplest features. To bridge the gap between these two lines of work, we first hypothesize and verify that while SB may not altogether preclude learning complex features, it amplifies simpler features over complex ones. Namely, simple features are replicated several times in the learned representations while complex features might not be replicated. This phenomenon, we term Feature Replication Hypothesis, coupled with the Implicit Bias of SGD to converge to maximum margin solutions in the feature space, leads the models to rely mostly on the simple features for classification. To mitigate this bias, we propose Feature Reconstruction Regularizer (FRR) to ensure that the learned features can be reconstructed back from the logits. The use of {\\em FRR} in linear layer training (FRR-L) encourages the use of more diverse features for classification. We further propose to finetune the full network by freezing the weights of the linear layer trained using FRR-L, to refine the learned features, making them more suitable for classification. Using this simple solution, we demonstrate up to 15% gains in OOD accuracy on the recently introduced semi-synthetic datasets with extreme distribution shifts. Moreover, we demonstrate noteworthy gains over existing SOTA methods on the standard OOD benchmark DomainBed as well. ",
    "url": "https://arxiv.org/abs/2210.01360",
    "authors": [
      "Sravanti Addepalli",
      "Anshul Nasery",
      "R. Venkatesh Babu",
      "Praneeth Netrapalli",
      "Prateek Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01363",
    "title": "Connecting Surrogate Safety Measures to Crash Probablity via Causal  Probabilistic Time Series Prediction",
    "abstract": "Surrogate safety measures can provide fast and pro-active safety analysis and give insights on the pre-crash process and crash failure mechanism by studying near misses. However, validating surrogate safety measures by connecting them to crashes is still an open question. This paper proposed a method to connect surrogate safety measures to crash probability using probabilistic time series prediction. The method used sequences of speed, acceleration and time-to-collision to estimate the probability density functions of those variables with transformer masked autoregressive flow (transformer-MAF). The autoregressive structure mimicked the causal relationship between condition, action and crash outcome and the probability density functions are used to calculate the conditional action probability, crash probability and conditional crash probability. The predicted sequence is accurate and the estimated probability is reasonable under both traffic conflict context and normal interaction context and the conditional crash probability shows the effectiveness of evasive action to avoid crashes in a counterfactual experiment. ",
    "url": "https://arxiv.org/abs/2210.01363",
    "authors": [
      "Jiajian Lu",
      "Offer Grembek",
      "Mark Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01365",
    "title": "Communication in Immersive Social Virtual Reality: A Systematic Review  of 10 Years' Studies",
    "abstract": "As virtual reality (VR) technologies have improved in the past decade, more research has investigated how they could support more effective communication in various contexts to improve collaboration and social connectedness. However, there was no literature to summarize the uniqueness VR provided and put forward guidance for designing social VR applications for better communication. To understand how VR has been designed and used to facilitate communication in different contexts, we conducted a systematic review of the studies investigating communication in social VR in the past ten years by following the PRISMA guidelines. We highlight current practices and challenges and identify research opportunities to improve the design of social VR to better support communication and make social VR more accessible. ",
    "url": "https://arxiv.org/abs/2210.01365",
    "authors": [
      "Xiaoying Wei",
      "Xiaofu Jin",
      "Mingming Fan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.01368",
    "title": "RAP: Risk-Aware Prediction for Robust Planning",
    "abstract": "Robust planning in interactive scenarios requires predicting the uncertain future to make risk-aware decisions. Unfortunately, due to long-tail safety-critical events, the risk is often under-estimated by finite-sampling approximations of probabilistic motion forecasts. This can lead to overconfident and unsafe robot behavior, even with robust planners. Instead of assuming full prediction coverage that robust planners require, we propose to make prediction itself risk-aware. We introduce a new prediction objective to learn a risk-biased distribution over trajectories, so that risk evaluation simplifies to an expected cost estimation under this biased distribution. This reduces the sample complexity of the risk estimation during online planning, which is needed for safe real-time performance. Evaluation results in a didactic simulation environment and on a real-world dataset demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2210.01368",
    "authors": [
      "Haruki Nishimura",
      "Jean Mercat",
      "Blake Wulfe",
      "Rowan McAllister",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01376",
    "title": "Improved High-Probability Regret for Adversarial Bandits with  Time-Varying Feedback Graphs",
    "abstract": "We study high-probability regret bounds for adversarial $K$-armed bandits with time-varying feedback graphs over $T$ rounds. For general strongly observable graphs, we develop an algorithm that achieves the optimal regret $\\widetilde{\\mathcal{O}}((\\sum_{t=1}^T\\alpha_t)^{1/2}+\\max_{t\\in[T]}\\alpha_t)$ with high probability, where $\\alpha_t$ is the independence number of the feedback graph at round $t$. Compared to the best existing result [Neu, 2015] which only considers graphs with self-loops for all nodes, our result not only holds more generally, but importantly also removes any $\\text{poly}(K)$ dependence that can be prohibitively large for applications such as contextual bandits. Furthermore, we also develop the first algorithm that achieves the optimal high-probability regret bound for weakly observable graphs, which even improves the best expected regret bound of [Alon et al., 2015] by removing the $\\mathcal{O}(\\sqrt{KT})$ term with a refined analysis. Our algorithms are based on the online mirror descent framework, but importantly with an innovative combination of several techniques. Notably, while earlier works use optimistic biased loss estimators for achieving high-probability bounds, we find it important to use a pessimistic one for nodes without self-loop in a strongly observable graph. ",
    "url": "https://arxiv.org/abs/2210.01376",
    "authors": [
      "Haipeng Luo",
      "Hanghang Tong",
      "Mengxiao Zhang",
      "Yuheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01384",
    "title": "Toward Edge-Efficient Dense Predictions with Synergistic Multi-Task  Neural Architecture Search",
    "abstract": "In this work, we propose a novel and scalable solution to address the challenges of developing efficient dense predictions on edge platforms. Our first key insight is that MultiTask Learning (MTL) and hardware-aware Neural Architecture Search (NAS) can work in synergy to greatly benefit on-device Dense Predictions (DP). Empirical results reveal that the joint learning of the two paradigms is surprisingly effective at improving DP accuracy, achieving superior performance over both the transfer learning of single-task NAS and prior state-of-the-art approaches in MTL, all with just 1/10th of the computation. To the best of our knowledge, our framework, named EDNAS, is the first to successfully leverage the synergistic relationship of NAS and MTL for DP. Our second key insight is that the standard depth training for multi-task DP can cause significant instability and noise to MTL evaluation. Instead, we propose JAReD, an improved, easy-to-adopt Joint Absolute-Relative Depth loss, that reduces up to 88% of the undesired noise while simultaneously boosting accuracy. We conduct extensive evaluations on standard datasets, benchmark against strong baselines and state-of-the-art approaches, as well as provide an analysis of the discovered optimal architectures. ",
    "url": "https://arxiv.org/abs/2210.01384",
    "authors": [
      "Thanh Vu",
      "Yanqi Zhou",
      "Chunfeng Wen",
      "Yueqi Li",
      "Jan-Michael Frahm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01391",
    "title": "Bridged Transformer for Vision and Point Cloud 3D Object Detection",
    "abstract": "3D object detection is a crucial research topic in computer vision, which usually uses 3D point clouds as input in conventional setups. Recently, there is a trend of leveraging multiple sources of input data, such as complementing the 3D point cloud with 2D images that often have richer color and fewer noises. However, due to the heterogeneous geometrics of the 2D and 3D representations, it prevents us from applying off-the-shelf neural networks to achieve multimodal fusion. To that end, we propose Bridged Transformer (BrT), an end-to-end architecture for 3D object detection. BrT is simple and effective, which learns to identify 3D and 2D object bounding boxes from both points and image patches. A key element of BrT lies in the utilization of object queries for bridging 3D and 2D spaces, which unifies different sources of data representations in Transformer. We adopt a form of feature aggregation realized by point-to-patch projections which further strengthen the correlations between images and points. Moreover, BrT works seamlessly for fusing the point cloud with multi-view images. We experimentally show that BrT surpasses state-of-the-art methods on SUN RGB-D and ScanNetV2 datasets. ",
    "url": "https://arxiv.org/abs/2210.01391",
    "authors": [
      "Yikai Wang",
      "TengQi Ye",
      "Lele Cao",
      "Wenbing Huang",
      "Fuchun Sun",
      "Fengxiang He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01421",
    "title": "Learning of Dynamical Systems under Adversarial Attacks -- Null Space  Property Perspective",
    "abstract": "We study the identification of a linear time-invariant dynamical system affected by large-and-sparse disturbances modeling adversarial attacks or faults. Under the assumption that the states are measurable, we develop necessary and sufficient conditions for the recovery of the system matrices by solving a constrained lasso-type optimization problem. In addition, we provide an upper bound on the estimation error whenever the disturbance sequence is a combination of small noise values and large adversarial values. Our results depend on the null space property that has been widely used in the lasso literature, and we investigate under what conditions this property holds for linear time-invariant dynamical systems. Lastly, we further study the conditions for a specific probabilistic model and support the results with numerical experiments. ",
    "url": "https://arxiv.org/abs/2210.01421",
    "authors": [
      "Han Feng",
      "Baturalp Yalcin",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2210.01426",
    "title": "Continuous Monte Carlo Graph Search",
    "abstract": "In many complex sequential decision making tasks, online planning is crucial for high-performance. For efficient online planning, Monte Carlo Tree Search (MCTS) employs a principled mechanism for trading off between exploration and exploitation. MCTS outperforms comparison methods in various discrete decision making domains such as Go, Chess, and Shogi. Following, extensions of MCTS to continuous domains have been proposed. However, the inherent high branching factor and the resulting explosion of search tree size is limiting existing methods. To solve this problem, this paper proposes Continuous Monte Carlo Graph Search (CMCGS), a novel extension of MCTS to online planning in environments with continuous state and action spaces. CMCGS takes advantage of the insight that, during planning, sharing the same action policy between several states can yield high performance. To implement this idea, at each time step CMCGS clusters similar states into a limited number of stochastic action bandit nodes, which produce a layered graph instead of an MCTS search tree. Experimental evaluation with limited sample budgets shows that CMCGS outperforms comparison methods in several complex continuous DeepMind Control Suite benchmarks and a 2D navigation task. ",
    "url": "https://arxiv.org/abs/2210.01426",
    "authors": [
      "Amin Babadi",
      "Yi Zhao",
      "Juho Kannala",
      "Alexander Ilin",
      "Joni Pajarinen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01437",
    "title": "Shielding Federated Learning: Mitigating Byzantine Attacks with Less  Constraints",
    "abstract": "Federated learning is a newly emerging distributed learning framework that facilitates the collaborative training of a shared global model among distributed participants with their privacy preserved. However, federated learning systems are vulnerable to Byzantine attacks from malicious participants, who can upload carefully crafted local model updates to degrade the quality of the global model and even leave a backdoor. While this problem has received significant attention recently, current defensive schemes heavily rely on various assumptions, such as a fixed Byzantine model, availability of participants' local data, minority attackers, IID data distribution, etc. To relax those constraints, this paper presents Robust-FL, the first prediction-based Byzantine-robust federated learning scheme where none of the assumptions is leveraged. The core idea of the Robust-FL is exploiting historical global model to construct an estimator based on which the local models will be filtered through similarity detection. We then cluster local models to adaptively adjust the acceptable differences between the local models and the estimator such that Byzantine users can be identified. Extensive experiments over different datasets show that our approach achieves the following advantages simultaneously: (i) independence of participants' local data, (ii) tolerance of majority attackers, (iii) generalization to variable Byzantine model. ",
    "url": "https://arxiv.org/abs/2210.01437",
    "authors": [
      "Minghui Li",
      "Wei Wan",
      "Jianrong Lu",
      "Shengshan Hu",
      "Junyu Shi",
      "Leo Yu Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.01447",
    "title": "A Novel Light Field Coding Scheme Based on Deep Belief Network and  Weighted Binary Images for Additive Layered Displays",
    "abstract": "Light field display caters to the viewer's immersive experience by providing binocular depth sensation and motion parallax. Glasses-free tensor light field display is becoming a prominent area of research in auto-stereoscopic display technology. Stacking light attenuating layers is one of the approaches to implement a light field display with a good depth of field, wide viewing angles and high resolution. This paper presents a compact and efficient representation of light field data based on scalable compression of the binary represented image layers suitable for additive layered display using a Deep Belief Network (DBN). The proposed scheme learns and optimizes the additive layer patterns using a convolutional neural network (CNN). Weighted binary images represent the optimized patterns, reducing the file size and introducing scalable encoding. The DBN further compresses the weighted binary patterns into a latent space representation followed by encoding the latent data using an h.254 codec. The proposed scheme is compared with benchmark codecs such as h.264 and h.265 and achieved competitive performance on light field data. ",
    "url": "https://arxiv.org/abs/2210.01447",
    "authors": [
      "Sally Khaidem",
      "Mansi Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.01448",
    "title": "Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with  Hierarchical Neural Embeddings",
    "abstract": "Automatic synthesis of realistic co-speech gestures is an increasingly important yet challenging task in artificial embodied agent creation. Previous systems mainly focus on generating gestures in an end-to-end manner, which leads to difficulties in mining the clear rhythm and semantics due to the complex yet subtle harmony between speech and gestures. We present a novel co-speech gesture synthesis method that achieves convincing results both on the rhythm and semantics. For the rhythm, our system contains a robust rhythm-based segmentation pipeline to ensure the temporal coherence between the vocalization and gestures explicitly. For the gesture semantics, we devise a mechanism to effectively disentangle both low- and high-level neural embeddings of speech and motion based on linguistic theory. The high-level embedding corresponds to semantics, while the low-level embedding relates to subtle variations. Lastly, we build correspondence between the hierarchical embeddings of the speech and the motion, resulting in rhythm- and semantics-aware gesture synthesis. Evaluations with existing objective metrics, a newly proposed rhythmic metric, and human feedback show that our method outperforms state-of-the-art systems by a clear margin. ",
    "url": "https://arxiv.org/abs/2210.01448",
    "authors": [
      "Tenglong Ao",
      "Qingzhe Gao",
      "Yuke Lou",
      "Baoquan Chen",
      "Libin Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.01451",
    "title": "Certified Data Removal in Sum-Product Networks",
    "abstract": "Data protection regulations like the GDPR or the California Consumer Privacy Act give users more control over the data that is collected about them. Deleting the collected data is often insufficient to guarantee data privacy since it is often used to train machine learning models, which can expose information about the training data. Thus, a guarantee that a trained model does not expose information about its training data is additionally needed. In this paper, we present UnlearnSPN -- an algorithm that removes the influence of single data points from a trained sum-product network and thereby allows fulfilling data privacy requirements on demand. ",
    "url": "https://arxiv.org/abs/2210.01451",
    "authors": [
      "Alexander Becker",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01482",
    "title": "Transformer-based Subject Entity Detection in Wikipedia Listings",
    "abstract": "In tasks like question answering or text summarisation, it is essential to have background knowledge about the relevant entities. The information about entities - in particular, about long-tail or emerging entities - in publicly available knowledge graphs like DBpedia or CaLiGraph is far from complete. In this paper, we present an approach that exploits the semi-structured nature of listings (like enumerations and tables) to identify the main entities of the listing items (i.e., of entries and rows). These entities, which we call subject entities, can be used to increase the coverage of knowledge graphs. Our approach uses a transformer network to identify subject entities at the token-level and surpasses an existing approach in terms of performance while being bound by fewer limitations. Due to a flexible input format, it is applicable to any kind of listing and is, unlike prior work, not dependent on entity boundaries as input. We demonstrate our approach by applying it to the complete Wikipedia corpus and extracting 40 million mentions of subject entities with an estimated precision of 71% and recall of 77%. The results are incorporated in the most recent version of CaLiGraph. ",
    "url": "https://arxiv.org/abs/2210.01482",
    "authors": [
      "Nicolas Heist",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.01489",
    "title": "Generative Models and Learning Algorithms for Core-Periphery Structured  Graphs",
    "abstract": "We consider core-periphery structured graphs, which are graphs with a group of densely and sparsely connected nodes, respectively, referred to as core and periphery nodes. The so-called core score of a node is related to the likelihood of it being a core node. In this paper, we focus on learning the core scores of a graph from its node attributes and connectivity structure. To this end, we propose two classes of probabilistic graphical models: affine and nonlinear. First, we describe affine generative models to model the dependence of node attributes on its core scores, which determine the graph structure. Next, we discuss nonlinear generative models in which the partial correlations of node attributes influence the graph structure through latent core scores. We develop algorithms for inferring the model parameters and core scores of a graph when both the graph structure and node attributes are available. When only the node attributes of graphs are available, we jointly learn a core-periphery structured graph and its core scores. We provide results from numerical experiments on several synthetic and real-world datasets to demonstrate the efficacy of the developed models and algorithms. ",
    "url": "https://arxiv.org/abs/2210.01489",
    "authors": [
      "Sravanthi Gurugubelli",
      "Sundeep Prabhakar Chepuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01500",
    "title": "Enhancing Spatiotemporal Prediction Model using Modular Design and  Beyond",
    "abstract": "Predictive learning uses a known state to generate a future state over a period of time. It is a challenging task to predict spatiotemporal sequence because the spatiotemporal sequence varies both in time and space. The mainstream method is to model spatial and temporal structures at the same time using RNN-based or transformer-based architecture, and then generates future data by using learned experience in the way of auto-regressive. The method of learning spatial and temporal features simultaneously brings a lot of parameters to the model, which makes the model difficult to be convergent. In this paper, a modular design is proposed, which decomposes spatiotemporal sequence model into two modules: a spatial encoder-decoder and a predictor. These two modules can extract spatial features and predict future data respectively. The spatial encoder-decoder maps the data into a latent embedding space and generates data from the latent space while the predictor forecasts future embedding from past. By applying the design to the current research and performing experiments on KTH-Action and MovingMNIST datasets, we both improve computational performance and obtain state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2210.01500",
    "authors": [
      "Haoyu Pan",
      "Hao Wu",
      "Tan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01504",
    "title": "Knowledge Unlearning for Mitigating Privacy Risks in Language Models",
    "abstract": "Pretrained Language Models (LMs) memorize a vast amount of knowledge during initial pretraining, including information that may violate the privacy of personal lives and identities. Previous work addressing privacy issues for language models has mostly focused on data preprocessing and differential privacy methods, both requiring re-training the underlying LM. We propose knowledge unlearning as an alternative method to reduce privacy risks for LMs post hoc. We show that simply applying the unlikelihood training objective to target token sequences is effective at forgetting them with little to no degradation of general language modeling performances; it sometimes even substantially improves the underlying LM with just a few iterations. We also find that sequential unlearning is better than trying to unlearn all the data at once and that unlearning is highly dependent on which kind of data (domain) is forgotten. By showing comparisons with a previous data preprocessing method known to mitigate privacy risks for LMs, we show that unlearning can give a stronger empirical privacy guarantee in scenarios where the data vulnerable to extraction attacks are known a priori while being orders of magnitude more computationally efficient. We release the code and dataset needed to replicate our results at https://github.com/joeljang/knowledge-unlearning . ",
    "url": "https://arxiv.org/abs/2210.01504",
    "authors": [
      "Joel Jang",
      "Dongkeun Yoon",
      "Sohee Yang",
      "Sungmin Cha",
      "Moontae Lee",
      "Lajanugen Logeswaran",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01506",
    "title": "How deep convolutional neural networks lose spatial information with  training",
    "abstract": "A central question of machine learning is how deep nets manage to learn tasks in high dimensions. An appealing hypothesis is that they achieve this feat by building a representation of the data where information irrelevant to the task is lost. For image datasets, this view is supported by the observation that after (and not before) training, the neural representation becomes less and less sensitive to diffeomorphisms acting on images as the signal propagates through the net. This loss of sensitivity correlates with performance, and surprisingly correlates with a gain of sensitivity to white noise acquired during training. These facts are unexplained, and as we demonstrate still hold when white noise is added to the images of the training set. Here, we (i) show empirically for various architectures that stability to image diffeomorphisms is achieved by spatial pooling in the first half of the net, and by channel pooling in the second half, (ii) introduce a scale-detection task for a simple model of data where pooling is learned during training, which captures all empirical observations above and (iii) compute in this model how stability to diffeomorphisms and noise scale with depth. The scalings are found to depend on the presence of strides in the net architecture. We find that the increased sensitivity to noise is due to the perturbing noise piling up during pooling, after being rectified by ReLU units. ",
    "url": "https://arxiv.org/abs/2210.01506",
    "authors": [
      "Umberto M. Tomasini",
      "Leonardo Petrini",
      "Francesco Cagnetta",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01548",
    "title": "Neural Implicit Surface Reconstruction from Noisy Camera Observations",
    "abstract": "Representing 3D objects and scenes with neural radiance fields has become very popular over the last years. Recently, surface-based representations have been proposed, that allow to reconstruct 3D objects from simple photographs. However, most current techniques require an accurate camera calibration, i.e. camera parameters corresponding to each image, which is often a difficult task to do in real-life situations. To this end, we propose a method for learning 3D surfaces from noisy camera parameters. We show that we can learn camera parameters together with learning the surface representation, and demonstrate good quality 3D surface reconstruction even with noisy camera observations. ",
    "url": "https://arxiv.org/abs/2210.01548",
    "authors": [
      "Sarthak Gupta",
      "Patrik Huber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01549",
    "title": "Diffusion Models for Graphs Benefit From Discrete State Spaces",
    "abstract": "Denoising diffusion probabilistic models and score matching models have proven to be very powerful for generative tasks. While these approaches have also been applied to the generation of discrete graphs, they have, so far, relied on continuous Gaussian perturbations. Instead, in this work, we suggest using discrete noise for the forward Markov process. This ensures that in every intermediate step the graph remains discrete. Compared to the previous approach, our experimental results on four datasets and multiple architectures show that using a discrete noising process results in higher quality generated samples indicated with an average MMDs reduced by a factor of 1.5. Furthermore, the number of denoising steps is reduced from 1000 to 32 steps leading to a 30 times faster sampling procedure. ",
    "url": "https://arxiv.org/abs/2210.01549",
    "authors": [
      "Kilian Konstantin Haefeli",
      "Karolis Martinkus",
      "Nathana\u00ebl Perraudin",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01558",
    "title": "GaIA: Graphical Information Gain based Attention Network for Weakly  Supervised Point Cloud Semantic Segmentation",
    "abstract": "While point cloud semantic segmentation is a significant task in 3D scene understanding, this task demands a time-consuming process of fully annotating labels. To address this problem, recent studies adopt a weakly supervised learning approach under the sparse annotation. Different from the existing studies, this study aims to reduce the epistemic uncertainty measured by the entropy for a precise semantic segmentation. We propose the graphical information gain based attention network called GaIA, which alleviates the entropy of each point based on the reliable information. The graphical information gain discriminates the reliable point by employing relative entropy between target point and its neighborhoods. We further introduce anchor-based additive angular margin loss, ArcPoint. The ArcPoint optimizes the unlabeled points containing high entropy towards semantically similar classes of the labeled points on hypersphere space. Experimental results on S3DIS and ScanNet-v2 datasets demonstrate our framework outperforms the existing weakly supervised methods. We have released GaIA at https://github.com/Karel911/GaIA. ",
    "url": "https://arxiv.org/abs/2210.01558",
    "authors": [
      "Min Seok Lee",
      "Seok Woo Yang",
      "Sung Won Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01561",
    "title": "Causal Intervention-based Prompt Debiasing for Event Argument Extraction",
    "abstract": "Prompt-based methods have become increasingly popular among information extraction tasks, especially in low-data scenarios. By formatting a finetune task into a pre-training objective, prompt-based methods resolve the data scarce problem effectively. However, seldom do previous research investigate the discrepancy among different prompt formulating strategies. In this work, we compare two kinds of prompts, name-based prompt and ontology-base prompt, and reveal how ontology-base prompt methods exceed its counterpart in zero-shot event argument extraction (EAE) . Furthermore, we analyse the potential risk in ontology-base prompts via a causal view and propose a debias method by causal intervention. Experiments on two benchmarks demonstrate that modified by our debias method, the baseline model becomes both more effective and robust, with significant improvement in the resistance to adversarial attacks. ",
    "url": "https://arxiv.org/abs/2210.01561",
    "authors": [
      "Jiaju Lin",
      "Jie Zhou",
      "Qin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01571",
    "title": "VICRegL: Self-Supervised Learning of Local Visual Features",
    "abstract": "Most recent self-supervised methods for learning image representations focus on either producing a global feature with invariance properties, or producing a set of local features. The former works best for classification tasks while the latter is best for detection and segmentation tasks. This paper explores the fundamental trade-off between learning local and global features. A new method called VICRegL is proposed that learns good global and local features simultaneously, yielding excellent performance on detection and segmentation tasks while maintaining good performance on classification tasks. Concretely, two identical branches of a standard convolutional net architecture are fed two differently distorted versions of the same image. The VICReg criterion is applied to pairs of global feature vectors. Simultaneously, the VICReg criterion is applied to pairs of local feature vectors occurring before the last pooling layer. Two local feature vectors are attracted to each other if their l2-distance is below a threshold or if their relative locations are consistent with a known geometric transformation between the two input images. We demonstrate strong performance on linear classification and segmentation transfer tasks. Code and pretrained models are publicly available at: https://github.com/facebookresearch/VICRegL ",
    "url": "https://arxiv.org/abs/2210.01571",
    "authors": [
      "Adrien Bardes",
      "Jean Ponce",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01612",
    "title": "PlaneDepth: Plane-Based Self-Supervised Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation refers to training a monocular depth estimation (MDE) network using only RGB images to overcome the difficulty of collecting dense ground truth depth. Many previous works addressed this problem using depth classification or depth regression. However, depth classification tends to fall into local minima due to the bilinear interpolation search on the target view. Depth classification overcomes this problem using pre-divided depth bins, but those depth candidates lead to discontinuities in the final depth result, and using the same probability for weighted summation of color and depth is ambiguous. To overcome these limitations, we use some predefined planes that are parallel to the ground, allowing us to automatically segment the ground and predict continuous depth for it. We further model depth as a mixture Laplace distribution, which provides a more certain objective for optimization. Previous works have shown that MDE networks only use the vertical image position of objects to estimate the depth and ignore relative sizes. We address this problem for the first time in both stereo and monocular training using resize cropping data augmentation. Based on our analysis of resize cropping, we combine it with our plane definition and improve our training strategy so that the network could learn the relationship between depth and both the vertical image position and relative size of objects. We further combine the self-distillation stage with post-processing to provide more accurate supervision and save extra time in post-processing. We conduct extensive experiments to demonstrate the effectiveness of our analysis and improvements. ",
    "url": "https://arxiv.org/abs/2210.01612",
    "authors": [
      "Ruoyu Wang",
      "Zehao Yu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01625",
    "title": "Energy Consumption of Neural Networks on NVIDIA Edge Boards: an  Empirical Model",
    "abstract": "Recently, there has been a trend of shifting the execution of deep learning inference tasks toward the edge of the network, closer to the user, to reduce latency and preserve data privacy. At the same time, growing interest is being devoted to the energetic sustainability of machine learning. At the intersection of these trends, we hence find the energetic characterization of machine learning at the edge, which is attracting increasing attention. Unfortunately, calculating the energy consumption of a given neural network during inference is complicated by the heterogeneity of the possible underlying hardware implementation. In this work, we hence aim at profiling the energetic consumption of inference tasks for some modern edge nodes and deriving simple but realistic models. To this end, we performed a large number of experiments to collect the energy consumption of convolutional and fully connected layers on two well-known edge boards by NVIDIA, namely Jetson TX2 and Xavier. From the measurements, we have then distilled a simple, practical model that can provide an estimate of the energy consumption of a certain inference task on the considered boards. We believe that this model can be used in many contexts as, for instance, to guide the search for efficient architectures in Neural Architecture Search, as a heuristic in Neural Network pruning, or to find energy-efficient offloading strategies in a Split computing context, or simply to evaluate the energetic performance of Deep Neural Network architectures. ",
    "url": "https://arxiv.org/abs/2210.01625",
    "authors": [
      "Seyyidahmed Lahmer",
      "Aria Khoshsirat",
      "Michele Rossi",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01632",
    "title": "Backdoor Attacks in the Supply Chain of Masked Image Modeling",
    "abstract": "Masked image modeling (MIM) revolutionizes self-supervised learning (SSL) for image pre-training. In contrast to previous dominating self-supervised methods, i.e., contrastive learning, MIM attains state-of-the-art performance by masking and reconstructing random patches of the input image. However, the associated security and privacy risks of this novel generative method are unexplored. In this paper, we perform the first security risk quantification of MIM through the lens of backdoor attacks. Different from previous work, we are the first to systematically threat modeling on SSL in every phase of the model supply chain, i.e., pre-training, release, and downstream phases. Our evaluation shows that models built with MIM are vulnerable to existing backdoor attacks in release and downstream phases and are compromised by our proposed method in pre-training phase. For instance, on CIFAR10, the attack success rate can reach 99.62%, 96.48%, and 98.89% in the downstream phase, release phase, and pre-training phase, respectively. We also take the first step to investigate the success factors of backdoor attacks in the pre-training phase and find the trigger number and trigger pattern play key roles in the success of backdoor attacks while trigger location has only tiny effects. In the end, our empirical study of the defense mechanisms across three detection-level on model supply chain phases indicates that different defenses are suitable for backdoor attacks in different phases. However, backdoor attacks in the release phase cannot be detected by all three detection-level methods, calling for more effective defenses in future research. ",
    "url": "https://arxiv.org/abs/2210.01632",
    "authors": [
      "Xinyue Shen",
      "Xinlei He",
      "Zheng Li",
      "Yun Shen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01637",
    "title": "Mining Duplicate Questions of Stack Overflow",
    "abstract": "There has a been a significant rise in the use of Community Question Answering sites (CQAs) over the last decade owing primarily to their ability to leverage the wisdom of the crowd. Duplicate questions have a crippling effect on the quality of these sites. Tackling duplicate questions is therefore an important step towards improving quality of CQAs. In this regard, we propose two neural network based architectures for duplicate question detection on Stack Overflow. We also propose explicitly modeling the code present in questions to achieve results that surpass the state of the art. ",
    "url": "https://arxiv.org/abs/2210.01637",
    "authors": [
      "Mihir Kale",
      "Anirudha Rayasam",
      "Radhika Parik",
      "Pranav Dheram"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01662",
    "title": "DGORL: Distributed Graph Optimization based Relative Localization of  Multi-Robot Systems",
    "abstract": "An optimization problem is at the heart of many robotics estimating, planning, and optimum control problems. Several attempts have been made at model-based multi-robot localization, and few have formulated the multi-robot collaborative localization problem as a factor graph problem to solve through graph optimization. Here, the optimization objective is to minimize the errors of estimating the relative location estimates in a distributed manner. Our novel graph-theoretic approach to solving this problem consists of three major components; (connectivity) graph formation, expansion through transition model, and optimization of relative poses. First, we estimate the relative pose-connectivity graph using the received signal strength between the connected robots, indicating relative ranges between them. Then, we apply a motion model to formulate graph expansion and optimize them using g$^2$o graph optimization as a distributed solver over dynamic networks. Finally, we theoretically analyze the algorithm and numerically validate its optimality and performance through extensive simulations. The results demonstrate the practicality of the proposed solution compared to a state-of-the-art algorithm for collaborative localization in multi-robot systems. ",
    "url": "https://arxiv.org/abs/2210.01662",
    "authors": [
      "Ehsan Latif",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.01676",
    "title": "Robust Target Training for Multi-Source Domain Adaptation",
    "abstract": "Given multiple labeled source domains and a single target domain, most existing multi-source domain adaptation (MSDA) models are trained on data from all domains jointly in one step. Such an one-step approach limits their ability to adapt to the target domain. This is because the training set is dominated by the more numerous and labeled source domain data. The source-domain-bias can potentially be alleviated by introducing a second training step, where the model is fine-tuned with the unlabeled target domain data only using pseudo labels as supervision. However, the pseudo labels are inevitably noisy and when used unchecked can negatively impact the model performance. To address this problem, we propose a novel Bi-level Optimization based Robust Target Training (BORT$^2$) method for MSDA. Given any existing fully-trained one-step MSDA model, BORT$^2$ turns it to a labeling function to generate pseudo-labels for the target data and trains a target model using pseudo-labeled target data only. Crucially, the target model is a stochastic CNN which is designed to be intrinsically robust against label noise generated by the labeling function. Such a stochastic CNN models each target instance feature as a Gaussian distribution with an entropy maximization regularizer deployed to measure the label uncertainty, which is further exploited to alleviate the negative impact of noisy pseudo labels. Training the labeling function and the target model poses a nested bi-level optimization problem, for which we formulate an elegant solution based on implicit differentiation. Extensive experiments demonstrate that our proposed method achieves the state of the art performance on three MSDA benchmarks, including the large-scale DomainNet dataset. Our code will be available at \\url{https://github.com/Zhongying-Deng/BORT2} ",
    "url": "https://arxiv.org/abs/2210.01676",
    "authors": [
      "Zhongying Deng",
      "Da Li",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01679",
    "title": "Detection and Evaluation of Clusters within Sequential Data",
    "abstract": "Motivated by theoretical advancements in dimensionality reduction techniques we use a recent model, called Block Markov Chains, to conduct a practical study of clustering in real-world sequential data. Clustering algorithms for Block Markov Chains possess theoretical optimality guarantees and can be deployed in sparse data regimes. Despite these favorable theoretical properties, a thorough evaluation of these algorithms in realistic settings has been lacking. We address this issue and investigate the suitability of these clustering algorithms in exploratory data analysis of real-world sequential data. In particular, our sequential data is derived from human DNA, written text, animal movement data and financial markets. In order to evaluate the determined clusters, and the associated Block Markov Chain model, we further develop a set of evaluation tools. These tools include benchmarking, spectral noise analysis and statistical model selection tools. An efficient implementation of the clustering algorithm and the new evaluation tools is made available together with this paper. Practical challenges associated to real-world data are encountered and discussed. It is ultimately found that the Block Markov Chain model assumption, together with the tools developed here, can indeed produce meaningful insights in exploratory data analyses despite the complexity and sparsity of real-world data. ",
    "url": "https://arxiv.org/abs/2210.01679",
    "authors": [
      "Alexander Van Werde",
      "Albert Senen-Cerda",
      "Gianluca Kosmella",
      "Jaron Sanders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01694",
    "title": "The Complexity of Online Graph Games",
    "abstract": "Online computation is a concept to model uncertainty where not all information on a problem instance is known in advance. An online algorithm receives requests which reveal the instance piecewise and has to respond with irrevocable decisions. Often, an adversary is assumed that constructs the instance knowing the deterministic behavior of the algorithm. From a game theoretical point of view, the adversary and the online algorithm are players in a two-player game. By applying this view on combinatorial graph problems, especially on problems where the solution is a subset of the vertices, we analyze their complexity. For this, we introduce a framework based on gadget reductions from 3-Satisfiability and extend it to an online setting where the graph is a priori known by a map. This is done by identifying a set of rules for the reductions and providing schemes for gadgets. The extension of the framework to the online setting enable reductions from TQBF. We provide example reductions to the well-known problems Vertex Cover, Independent Set and Dominating Set and prove that they are PSPACE-complete. Thus, this paper establishes that the online version with a map of NP-complete graph problems form a large class of PSPACE-complete problems. ",
    "url": "https://arxiv.org/abs/2210.01694",
    "authors": [
      "Janosch Fuchs",
      "Christoph Gr\u00fcne",
      "Tom Jan\u00dfen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.01697",
    "title": "Efficient implicit solvers for models of neuronal networks",
    "abstract": "We introduce economical versions of standard implicit ODE solvers that are specifically tailored for the efficient and accurate simulation of neural networks. The specific versions of the ODE solvers proposed here, allow to achieve a significant increase in the efficiency of network simulations, by reducing the size of the algebraic system being solved at each time step, a technique inspired by very successful semi-implicit approaches in computational fluid dynamics and structural mechanics. While we focus here specifically on Explicit first step, Diagonally Implicit Runge Kutta methods (ESDIRK), similar simplifications can also be applied to any implicit ODE solver. In order to demonstrate the capabilities of the proposed methods, we consider networks based on three different single cell models with slow-fast dynamics, including the classical FitzHugh-Nagumo model, a Intracellular Calcium Concentration model and the Hindmarsh-Rose model. Numerical experiments on the simulation of networks of increasing size based on these models demonstrate the increased efficiency of the proposed methods. ",
    "url": "https://arxiv.org/abs/2210.01697",
    "authors": [
      "Luca Bonaventura",
      "Soledad Fern\u00e1ndez-Garc\u00eda",
      "Macarena G\u00f3mez-M\u00e1rmol"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.01703",
    "title": "Improving Label-Deficient Keyword Spotting Using Self-Supervised  Pretraining",
    "abstract": "In recent years, the development of accurate deep keyword spotting (KWS) models has resulted in KWS technology being embedded in a number of technologies such as voice assistants. Many of these models rely on large amounts of labelled data to achieve good performance. As a result, their use is restricted to applications for which a large labelled speech data set can be obtained. Self-supervised learning seeks to mitigate the need for large labelled data sets by leveraging unlabelled data, which is easier to obtain in large amounts. However, most self-supervised methods have only been investigated for very large models, whereas KWS models are desired to be small. In this paper, we investigate the use of self-supervised pretraining for the smaller KWS models in a label-deficient scenario. We pretrain the Keyword Transformer model using the self-supervised framework Data2Vec and carry out experiments on a label-deficient setup of the Google Speech Commands data set. It is found that the pretrained models greatly outperform the models without pretraining, showing that Data2Vec pretraining can increase the performance of KWS models in label-deficient scenarios. The source code is made publicly available. ",
    "url": "https://arxiv.org/abs/2210.01703",
    "authors": [
      "Holger Severin Bovbjerg",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.01723",
    "title": "Dense Prediction Transformer for Scale Estimation in Monocular Visual  Odometry",
    "abstract": "Monocular visual odometry consists of the estimation of the position of an agent through images of a single camera, and it is applied in autonomous vehicles, medical robots, and augmented reality. However, monocular systems suffer from the scale ambiguity problem due to the lack of depth information in 2D frames. This paper contributes by showing an application of the dense prediction transformer model for scale estimation in monocular visual odometry systems. Experimental results show that the scale drift problem of monocular systems can be reduced through the accurate estimation of the depth map by this model, achieving competitive state-of-the-art performance on a visual odometry benchmark. ",
    "url": "https://arxiv.org/abs/2210.01723",
    "authors": [
      "Andr\u00e9 O. Fran\u00e7ani",
      "Marcos R. O. A. Maximo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01727",
    "title": "Enhanced CNN with Global Features for Fault Diagnosis of Complex  Chemical Processes",
    "abstract": "Convolutional neural network (CNN) models have been widely used for fault diagnosis of complex systems. However, traditional CNN models rely on small kernel filters to obtain local features from images. Thus, an excessively deep CNN is required to capture global features, which are critical for fault diagnosis of dynamical systems. In this work, we present an improved CNN that embeds global features (GF-CNN). Our method uses a multi-layer perceptron (MLP) for dimension reduction to directly extract global features and integrate them into the CNN. The advantage of this method is that both local and global patterns in images can be captured by a simple model architecture instead of establishing deep CNN models. The proposed method is applied to the fault diagnosis of the Tennessee Eastman process. Simulation results show that the GF-CNN can significantly improve the fault diagnosis performance compared to traditional CNN. The proposed method can also be applied to other areas such as computer vision and image processing. ",
    "url": "https://arxiv.org/abs/2210.01727",
    "authors": [
      "Qiugang Lu",
      "Saif S. S. Al-Wahaibi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.01732",
    "title": "Robust Multi-Agent Coordination from CaTL+ Specifications",
    "abstract": "We consider the problem of controlling a heterogeneous multi-agent system required to satisfy temporal logic requirements. Capability Temporal Logic (CaTL) was recently proposed to formalize such specifications for deploying a team of autonomous agents with different capabilities and cooperation requirements. In this paper, we extend CaTL to a new logic CaTL+, which is more expressive than CaTL and has semantics over a continuous workspace shared by all agents. We define two novel robustness metrics for CaTL+: the traditional robustness and the exponential robustness. The latter is sound, differentiable almost everywhere and eliminates masking, which is one of the main limitations of the traditional robustness metric. We formulate a control synthesis problem to maximize CaTL+ robustness and propose a two-step optimization method to solve this problem. Simulation results are included to illustrate the increased expressivity of CaTL+ and the efficacy of the proposed control synthesis approach. ",
    "url": "https://arxiv.org/abs/2210.01732",
    "authors": [
      "Wenliang Liu",
      "Kevin Leahy",
      "Zachary Serlin",
      "Calin Belta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.01741",
    "title": "Neural Conservation Laws: A Divergence-Free Perspective",
    "abstract": "We investigate the parameterization of deep neural networks that by design satisfy the continuity equation, a fundamental conservation law. This is enabled by the observation that solutions of the continuity equation can be represented as a divergence-free vector field. We hence propose building divergence-free neural networks through the concept of differential forms, and with the aid of automatic differentiation, realize two practical constructions. As a result, we can parameterize pairs of densities and vector fields that always satisfy the continuity equation by construction, foregoing the need for extra penalty methods or expensive numerical simulation. Furthermore, we prove these models are universal and so can be used to represent any divergence-free vector field. Finally, we experimentally validate our approaches on neural network-based solutions to fluid equations, solving for the Hodge decomposition, and learning dynamical optimal transport maps the Hodge decomposition, and learning dynamical optimal transport maps. ",
    "url": "https://arxiv.org/abs/2210.01741",
    "authors": [
      "Jack Richter-Powell",
      "Yaron Lipman",
      "Ricky T. Q. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01742",
    "title": "CADet: Fully Self-Supervised Anomaly Detection With Contrastive Learning",
    "abstract": "Handling out-of-distribution (OOD) samples has become a major stake in the real-world deployment of machine learning systems. This work explores the application of self-supervised contrastive learning to the simultaneous detection of two types of OOD samples: unseen classes and adversarial perturbations. Since in practice the distribution of such samples is not known in advance, we do not assume access to OOD examples. We show that similarity functions trained with contrastive learning can be leveraged with the maximum mean discrepancy (MMD) two-sample test to verify whether two independent sets of samples are drawn from the same distribution. Inspired by this approach, we introduce CADet (Contrastive Anomaly Detection), a method based on image augmentations to perform anomaly detection on single samples. CADet compares favorably to adversarial detection methods to detect adversarially perturbed samples on ImageNet. Simultaneously, it achieves comparable performance to unseen label detection methods on two challenging benchmarks: ImageNet-O and iNaturalist. CADet is fully self-supervised and requires neither labels for in-distribution samples nor access to OOD examples. ",
    "url": "https://arxiv.org/abs/2210.01742",
    "authors": [
      "Charles Guille-Escuret",
      "Pau Rodriguez",
      "David Vazquez",
      "Ioannis Mitliagkas",
      "Joao Monteiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01753",
    "title": "HYPRO: A Hybridly Normalized Probabilistic Model for Long-Horizon  Prediction of Event Sequences",
    "abstract": "In this paper, we tackle the important yet under-investigated problem of making long-horizon prediction of event sequences. Existing state-of-the-art models do not perform well at this task due to their autoregressive structure. We propose HYPRO, a hybridly normalized probabilistic model that naturally fits this task: its first part is an autoregressive base model that learns to propose predictions; its second part is an energy function that learns to reweight the proposals such that more realistic predictions end up with higher probabilities. We also propose efficient training and inference algorithms for this model. Experiments on multiple real-world datasets demonstrate that our proposed HYPRO model can significantly outperform previous models at making long-horizon predictions of future events. We also conduct a range of ablation studies to investigate the effectiveness of each component of our proposed methods. ",
    "url": "https://arxiv.org/abs/2210.01753",
    "authors": [
      "Siqiao Xue",
      "Xiaoming Shi",
      "James Y Zhang",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01771",
    "title": "AnoML-IoT: An End to End Re-configurable Multi-protocol Anomaly  Detection Pipeline for Internet of Things",
    "abstract": "The rapid development in ubiquitous computing has enabled the use of microcontrollers as edge devices. These devices are used to develop truly distributed IoT-based mechanisms where machine learning (ML) models are utilized. However, integrating ML models to edge devices requires an understanding of various software tools such as programming languages and domain-specific knowledge. Anomaly detection is one of the domains where a high level of expertise is required to achieve promising results. In this work, we present AnoML which is an end-to-end data science pipeline that allows the integration of multiple wireless communication protocols, anomaly detection algorithms, deployment to the edge, fog, and cloud platforms with minimal user interaction. We facilitate the development of IoT anomaly detection mechanisms by reducing the barriers that are formed due to the heterogeneity of an IoT environment. The proposed pipeline supports four main phases: (i) data ingestion, (ii) model training, (iii) model deployment, (iv) inference and maintaining. We evaluate the pipeline with two anomaly detection datasets while comparing the efficiency of several machine learning algorithms within different nodes. We also provide the source code (https://gitlab.com/IOTGarage/anoml-iot-analytics) of the developed tools which are the main components of the pipeline. ",
    "url": "https://arxiv.org/abs/2210.01771",
    "authors": [
      "Hakan Kayan",
      "Yasar Majib",
      "Wael Alsafery",
      "Mahmoud Barhamgi",
      "Charith Perera"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.01778",
    "title": "Semantics-based Privacy by Design for Internet of Things Applications",
    "abstract": "As Internet of Things (IoT) technologies become more widespread in everyday life, privacy issues are becoming more prominent. The aim of this research is to develop a personal assistant that can answer software engineers' questions about Privacy by Design (PbD) practices during the design phase of IoT system development. Semantic web technologies are used to model the knowledge underlying PbD measurements, their intersections with privacy patterns, IoT system requirements and the privacy patterns that should be applied across IoT systems. This is achieved through the development of the PARROT ontology, developed through a set of representative IoT use cases relevant for software developers. This was supported by gathering Competency Questions (CQs) through a series of workshops, resulting in 81 curated CQs. These CQs were then recorded as SPARQL queries, and the developed ontology was evaluated using the Common Pitfalls model with the help of the Prot\\'eg\\'e HermiT Reasoner and the Ontology Pitfall Scanner (OOPS!), as well as evaluation by external experts. The ontology was assessed within a user study that identified that the PARROT ontology can answer up to 58\\% of privacy-related questions from software engineers. ",
    "url": "https://arxiv.org/abs/2210.01778",
    "authors": [
      "Lamya Alkhariji",
      "Suparna De",
      "Omer Rana",
      "Charith Perera"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.01779",
    "title": "Perspective Aware Road Obstacle Detection",
    "abstract": "While road obstacle detection techniques have become increasingly effective, they typically ignore the fact that, in practice, the apparent size of the obstacles decreases as their distance to the vehicle increases. In this paper, we account for this by computing a scale map encoding the apparent size of a hypothetical object at every image location. We then leverage this perspective map to (i) generate training data by injecting synthetic objects onto the road in a more realistic fashion than existing methods; and (ii) incorporate perspective information in the decoding part of the detection network to guide the obstacle detector. Our results on standard benchmarks show that, together, these two strategies significantly boost the obstacle detection performance, allowing our approach to consistently outperform state-of-the-art methods in terms of instance-level obstacle detection. ",
    "url": "https://arxiv.org/abs/2210.01779",
    "authors": [
      "Krzysztof Lis",
      "Sina Honari",
      "Pascal Fua",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01781",
    "title": "COPILOT: Human Collision Prediction and Localization from Multi-view  Egocentric Videos",
    "abstract": "To produce safe human motions, assistive wearable exoskeletons must be equipped with a perception system that enables anticipating potential collisions from egocentric observations. However, previous approaches to exoskeleton perception greatly simplify the problem to specific types of environments, limiting their scalability. In this paper, we propose the challenging and novel problem of predicting human-scene collisions for diverse environments from multi-view egocentric RGB videos captured from an exoskeleton. By classifying which body joints will collide with the environment and predicting a collision region heatmap that localizes potential collisions in the environment, we aim to develop an exoskeleton perception system that generalizes to complex real-world scenes and provides actionable outputs for downstream control. We propose COPILOT, a video transformer-based model that performs both collision prediction and localization simultaneously, leveraging multi-view video inputs via a proposed joint space-time-viewpoint attention operation. To train and evaluate the model, we build a synthetic data generation framework to simulate virtual humans moving in photo-realistic 3D environments. This framework is then used to establish a dataset consisting of 8.6M egocentric RGBD frames to enable future work on the problem. Extensive experiments suggest that our model achieves promising performance and generalizes to unseen scenes as well as real world. We apply COPILOT to a downstream collision avoidance task, and successfully reduce collision cases by 29% on unseen scenes using a simple closed-loop control algorithm. ",
    "url": "https://arxiv.org/abs/2210.01781",
    "authors": [
      "Boxiao Pan",
      "Bokui Shen",
      "Davis Rempe",
      "Despoina Paschalidou",
      "Kaichun Mo",
      "Yanchao Yang",
      "Leonidas J. Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01787",
    "title": "Rethinking Lipschitz Neural Networks for Certified L-infinity Robustness",
    "abstract": "Designing neural networks with bounded Lipschitz constant is a promising way to obtain certifiably robust classifiers against adversarial examples. However, the relevant progress for the important $\\ell_\\infty$ perturbation setting is rather limited, and a principled understanding of how to design expressive $\\ell_\\infty$ Lipschitz networks is still lacking. In this paper, we bridge the gap by studying certified $\\ell_\\infty$ robustness from a novel perspective of representing Boolean functions. We derive two fundamental impossibility results that hold for any standard Lipschitz network: one for robust classification on finite datasets, and the other for Lipschitz function approximation. These results identify that networks built upon norm-bounded affine layers and Lipschitz activations intrinsically lose expressive power even in the two-dimensional case, and shed light on how recently proposed Lipschitz networks (e.g., GroupSort and $\\ell_\\infty$-distance nets) bypass these impossibilities by leveraging order statistic functions. Finally, based on these insights, we develop a unified Lipschitz network that generalizes prior works, and design a practical version that can be efficiently trained (making certified robust training free). Extensive experiments show that our approach is scalable, efficient, and consistently yields better certified robustness across multiple datasets and perturbation radii than prior Lipschitz networks. ",
    "url": "https://arxiv.org/abs/2210.01787",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01788",
    "title": "Robust self-healing prediction model for high dimensional data",
    "abstract": "Owing to the advantages of increased accuracy and the potential to detect unseen patterns, provided by data mining techniques they have been widely incorporated for standard classification problems. They have often been used for high precision disease prediction in the medical field, and several hybrid prediction models capable of achieving high accuracies have been proposed. Though this stands true most of the previous models fail to efficiently address the recurring issue of bad data quality which plagues most high dimensional data, and especially proves troublesome in the highly sensitive medical data. This work proposes a robust self healing (RSH) hybrid prediction model which functions by using the data in its entirety by removing errors and inconsistencies from it rather than discarding any data. Initial processing involves data preparation followed by cleansing or scrubbing through context-dependent attribute correction, which ensures that there is no significant loss of relevant information before the feature selection and prediction phases. An ensemble of heterogeneous classifiers, subjected to local boosting, is utilized to build the prediction model and genetic algorithm based wrapper feature selection technique wrapped on the respective classifiers is employed to select the corresponding optimal set of features, which warrant higher accuracy. The proposed method is compared with some of the existing high performing models and the results are analyzed. ",
    "url": "https://arxiv.org/abs/2210.01788",
    "authors": [
      "Anirudha Rayasam",
      "Nagamma Patil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01120",
    "title": "Predicting CO$_2$ Absorption in Ionic Liquids with Molecular Descriptors  and Explainable Graph Neural Networks",
    "abstract": "Ionic Liquids (ILs) provide a promising solution for CO$_2$ capture and storage to mitigate global warming. However, identifying and designing the high-capacity IL from the giant chemical space requires expensive, and exhaustive simulations and experiments. Machine learning (ML) can accelerate the process of searching for desirable ionic molecules through accurate and efficient property predictions in a data-driven manner. But existing descriptors and ML models for the ionic molecule suffer from the inefficient adaptation of molecular graph structure. Besides, few works have investigated the explainability of ML models to help understand the learned features that can guide the design of efficient ionic molecules. In this work, we develop both fingerprint-based ML models and Graph Neural Networks (GNNs) to predict the CO$_2$ absorption in ILs. Fingerprint works on graph structure at the feature extraction stage, while GNNs directly handle molecule structure in both the feature extraction and model prediction stage. We show that our method outperforms previous ML models by reaching a high accuracy (MAE of 0.0137, $R^2$ of 0.9884). Furthermore, we take the advantage of GNNs feature representation and develop a substructure-based explanation method that provides insight into how each chemical fragments within IL molecules contribute to the CO$_2$ absorption prediction of ML models. We also show that our explanation result agrees with some ground truth from the theoretical reaction mechanism of CO$_2$ absorption in ILs, which can advise on the design of novel and efficient functional ILs in the future. ",
    "url": "https://arxiv.org/abs/2210.01120",
    "authors": [
      "Yue Jian",
      "Yuyang Wang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01124",
    "title": "Automatic Neural Network Hyperparameter Optimization for Extrapolation:  Lessons Learned from Visible and Near-Infrared Spectroscopy of Mango Fruit",
    "abstract": "Neural networks are configured by choosing an architecture and hyperparameter values; doing so often involves expert intuition and hand-tuning to find a configuration that extrapolates well without overfitting. This paper considers automatic methods for configuring a neural network that extrapolates in time for the domain of visible and near-infrared (VNIR) spectroscopy. In particular, we study the effect of (a) selecting samples for validating configurations and (b) using ensembles. Most of the time, models are built of the past to predict the future. To encourage the neural network model to extrapolate, we consider validating model configurations on samples that are shifted in time similar to the test set. We experiment with three validation set choices: (1) a random sample of 1/3 of non-test data (the technique used in previous work), (2) using the latest 1/3 (sorted by time), and (3) using a semantically meaningful subset of the data. Hyperparameter optimization relies on the validation set to estimate test-set error, but neural network variance obfuscates the true error value. Ensemble averaging - computing the average across many neural networks - can reduce the variance of prediction errors. To test these methods, we do a comprehensive study of a held-out 2018 harvest season of mango fruit given VNIR spectra from 3 prior years. We find that ensembling improves the state-of-the-art model's variance and accuracy. Furthermore, hyperparameter optimization experiments - with and without ensemble averaging and with each validation set choice - show that when ensembling is combined with using the latest 1/3 of samples as the validation set, a neural network configuration is found automatically that is on par with the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2210.01124",
    "authors": [
      "Matthew Dirks",
      "David Poole"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01169",
    "title": "Neural-network solutions to stochastic reaction networks",
    "abstract": "The stochastic reaction network is widely used to model stochastic processes in physics, chemistry and biology. However, the size of the state space increases exponentially with the number of species, making it challenging to investigate the time evolution of the chemical master equation for the reaction network. Here, we propose a machine-learning approach using the variational autoregressive network to solve the chemical master equation. The approach is based on the reinforcement learning framework and does not require any data simulated in prior by another method. Different from simulating single trajectories, the proposed approach tracks the time evolution of the joint probability distribution in the state space of species counts, and supports direct sampling on configurations and computing their normalized joint probabilities. We apply the approach to various systems in physics and biology, and demonstrate that it accurately generates the probability distribution over time in the genetic toggle switch, the early life self-replicator, the epidemic model and the intracellular signaling cascade. The variational autoregressive network exhibits a plasticity in representing the multi-modal distribution by feedback regulations, cooperates with the conservation law, enables time-dependent reaction rates, and is efficient for high-dimensional reaction networks with allowing a flexible upper count limit. The results suggest a general approach to investigate stochastic reaction networks based on modern machine learning. ",
    "url": "https://arxiv.org/abs/2210.01169",
    "authors": [
      "Ying Tang",
      "Jiayu Weng",
      "Pan Zhang"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2210.01269",
    "title": "Course-Prerequisite Networks for Analyzing and Understanding Academic  Curricula",
    "abstract": "Understanding a complex system of relationships between courses is of great importance for the university's educational mission. This paper is dedicated to the study of course-prerequisite networks that model interactions between courses, represent the flow of knowledge in academic curricula, and serve as a key tool for visualizing, analyzing, and optimizing complex curricula. We show how course-prerequisite networks can be used by students, faculty, and administrators for detecting important courses, improving existing and creating new courses, navigating complex curricula, allocating teaching resources, increasing interdisciplinary interactions between departments, revamping curricula, and enhancing the overall students' learning experience. The proposed methodology is illustrated with a network of courses taught at the California Institute of Technology. ",
    "url": "https://arxiv.org/abs/2210.01269",
    "authors": [
      "Pavlos Stavrinides",
      "Konstantin Zuev"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.01300",
    "title": "Revealing Unobservables by Deep Learning: Generative Element Extraction  Networks (GEEN)",
    "abstract": "Latent variable models are crucial in scientific research, where a key variable, such as effort, ability, and belief, is unobserved in the sample but needs to be identified. This paper proposes a novel method for estimating realizations of a latent variable $X^*$ in a random sample that contains its multiple measurements. With the key assumption that the measurements are independent conditional on $X^*$, we provide sufficient conditions under which realizations of $X^*$ in the sample are locally unique in a class of deviations, which allows us to identify realizations of $X^*$. To the best of our knowledge, this paper is the first to provide such identification in observation. We then use the Kullback-Leibler distance between the two probability densities with and without the conditional independence as the loss function to train a Generative Element Extraction Networks (GEEN) that maps from the observed measurements to realizations of $X^*$ in the sample. The simulation results imply that this proposed estimator works quite well and the estimated values are highly correlated with realizations of $X^*$. Our estimator can be applied to a large class of latent variable models and we expect it will change how people deal with latent variables. ",
    "url": "https://arxiv.org/abs/2210.01300",
    "authors": [
      "Yingyao Hu",
      "Yang Liu",
      "Jiaxiong Yao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2210.01401",
    "title": "Spanning tree methods for sampling graph partitions",
    "abstract": "In the last decade, computational approaches to graph partitioning have made a major impact in the analysis of political redistricting, including in U.S. courts of law. Mathematically, a districting plan can be viewed as a balanced partition of a graph into connected subsets. Examining a large sample of valid alternative districting plans can help us recognize gerrymandering against an appropriate neutral baseline. One algorithm that is widely used to produce random samples of districting plans is a Markov chain called recombination (or ReCom), which repeatedly fuses adjacent districts, forms a spanning tree of their union, and splits that spanning tree with a balanced cut to form new districts. One drawback is that this chain's stationary distribution has no known closed form when there are three or more districts. In this paper, we modify ReCom slightly to give it a property called reversibility, resulting in a new Markov chain, RevReCom. This new chain converges to the simple, natural distribution that ReCom was originally designed to approximate: a plan's stationary probability is proportional to the product of the number of spanning trees of each district. This spanning tree score is a measure of district \"compactness\" (or shape) that is also aligned with notions of community structure from network science. After deriving the steady state formally, we present diagnostic evidence that the convergence is efficient enough for the method to be practically useful, giving high-quality samples for full-sized problems within several hours. In addition to the primary application of benchmarking of redistricting plans (i.e., describing a normal range for statistics), this chain can also be used to validate other methods that target the spanning tree distribution. ",
    "url": "https://arxiv.org/abs/2210.01401",
    "authors": [
      "Sarah Cannon",
      "Moon Duchin",
      "Dana Randall",
      "Parker Rule"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.01413",
    "title": "Tikhonov Regularization is Optimal Transport Robust under Martingale  Constraints",
    "abstract": "Distributionally robust optimization has been shown to offer a principled way to regularize learning models. In this paper, we find that Tikhonov regularization is distributionally robust in an optimal transport sense (i.e., if an adversary chooses distributions in a suitable optimal transport neighborhood of the empirical measure), provided that suitable martingale constraints are also imposed. Further, we introduce a relaxation of the martingale constraints which not only provides a unified viewpoint to a class of existing robust methods but also leads to new regularization tools. To realize these novel tools, tractable computational algorithms are proposed. As a byproduct, the strong duality theorem proved in this paper can be potentially applied to other problems of independent interest. ",
    "url": "https://arxiv.org/abs/2210.01413",
    "authors": [
      "Jiajin Li",
      "Sirui Lin",
      "Jose Blanchet",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01538",
    "title": "Analysis of the performance of U-Net neural networks for the  segmentation of living cells",
    "abstract": "The automated analysis of microscopy images is a challenge in the context of single-cell tracking and quantification. This work has as goals the study of the performance of deep learning for segmenting microscopy images and the improvement of the previously available pipeline for tracking single cells. Deep learning techniques, mainly convolutional neural networks, have been applied to cell segmentation problems and have shown high accuracy and fast performance. To perform the image segmentation, an analysis of hyperparameters was done in order to implement a convolutional neural network with U-Net architecture. Furthermore, different models were built in order to optimize the size of the network and the number of learnable parameters. The trained network is then used in the pipeline that localizes the traps in a microfluidic device, performs the image segmentation on trap images, and evaluates the fluorescence intensity and the area of single cells over time. The tracking of the cells during an experiment is performed by image processing algorithms, such as centroid estimation and watershed. Finally, with all improvements in the neural network to segment single cells and in the pipeline, quasi-real-time image analysis was enabled, where 6.20GB of data was processed in 4 minutes. ",
    "url": "https://arxiv.org/abs/2210.01538",
    "authors": [
      "Andr\u00e9 O. Fran\u00e7ani"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.01598",
    "title": "On the hull and interval numbers of oriented graphs",
    "abstract": "In this work, for a given oriented graph $D$, we study its interval and hull numbers, denoted by ${in}(D)$ and ${hn}(D)$, respectively, in the geodetic, ${P_3}$ and ${P_3^*}$ convexities. This last one, we believe to be formally defined and first studied in this paper, although its undirected version is well-known in the literature. Concerning bounds, for a strongly oriented graph $D$, we prove that ${hn_g}(D)\\leq m(D)-n(D)+2$ and that there is a strongly oriented graph such that ${hn_g}(D) = m(D)-n(D)$. We also determine exact values for the hull numbers in these three convexities for tournaments, which imply polynomial-time algorithms to compute them. These results allows us to deduce polynomial-time algorithms to compute ${hn_{P_3}}(D)$ when the underlying graph of $D$ is split or cobipartite. Moreover, we provide a meta-theorem by proving that if deciding whether ${in_g}(D)\\leq k$ or ${hn_g}(D)\\leq k$ is NP-hard or W[i]-hard parameterized by $k$, for some $i\\in\\mathbb{Z_+^*}$, then the same holds even if the underlying graph of $D$ is bipartite. Next, we prove that deciding whether ${hn_{P_3}}(D)\\leq k$ or ${hn_{P_3^*}}(D)\\leq k$ is W[2]-hard parameterized by $k$, even if the underlying graph of $D$ is bipartite; that deciding whether ${in_{P_3}}(D)\\leq k$ or ${in_{P_3^*}}(D)\\leq k$ is NP-complete, even if $D$ has no directed cycles and the underlying graph of $D$ is a chordal bipartite graph; and that deciding whether ${in_{P_3}}(D)\\leq k$ or ${in_{P_3^*}}(D)\\leq k$ is W[2]-hard parameterized by $k$, even if the underlying graph of $D$ is split. We also argue that the interval and hull numbers in the oriented $P_3$ and $P_3^*$ convexities can be computed in polynomial time for graphs of bounded tree-width by using Courcelle's theorem. ",
    "url": "https://arxiv.org/abs/2210.01598",
    "authors": [
      "J. Araujo",
      "A. K. Maia",
      "P. P. Medeiros",
      "L. Penso"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.01699",
    "title": "Robust feedback stabilization of interacting multi-agent systems under  uncertainty",
    "abstract": "We consider control strategies for large--scale interacting agent systems under uncertainty. The particular focus is on the design of robust controls that allow to bound the variance of the controlled system over time. To this end we consider $\\mathcal{H}_\\infty$ control strategies on the agent and mean field description of the system. We show a bound on the $\\mathcal{H}_\\infty$ norm for a stabilizing controller independent on the number of agents. Furthermore, we compare the new control with existing approaches to treat uncertainty by generalized polynomial chaos expansion. Numerical results are presented for one-dimensional and two--dimensional agent systems. ",
    "url": "https://arxiv.org/abs/2210.01699",
    "authors": [
      "Giacomo Albi",
      "Michael Herty",
      "Chiara Segala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.01713",
    "title": "Anatomically constrained CT image translation for heterogeneous blood  vessel segmentation",
    "abstract": "Anatomical structures such as blood vessels in contrast-enhanced CT (ceCT) images can be challenging to segment due to the variability in contrast medium diffusion. The combined use of ceCT and contrast-free (CT) CT images can improve the segmentation performances, but at the cost of a double radiation exposure. To limit the radiation dose, generative models could be used to synthesize one modality, instead of acquiring it. The CycleGAN approach has recently attracted particular attention because it alleviates the need for paired data that are difficult to obtain. Despite the great performances demonstrated in the literature, limitations still remain when dealing with 3D volumes generated slice by slice from unpaired datasets with different fields of view. We present an extension of CycleGAN to generate high fidelity images, with good structural consistency, in this context. We leverage anatomical constraints and automatic region of interest selection by adapting the Self-Supervised Body Regressor. These constraints enforce anatomical consistency and allow feeding anatomically-paired input images to the algorithm. Results show qualitative and quantitative improvements, compared to stateof-the-art methods, on the translation task between ceCT and CT images (and vice versa). ",
    "url": "https://arxiv.org/abs/2210.01713",
    "authors": [
      "Giammarco La Barbera",
      "Haithem Boussaid",
      "Francesco Maso",
      "Sabine Sarnacki",
      "Laurence Rouet",
      "Pietro Gori",
      "Isabelle Bloch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01769",
    "title": "Mind Reader: Reconstructing complex images from brain activities",
    "abstract": "Understanding how the brain encodes external stimuli and how these stimuli can be decoded from the measured brain activities are long-standing and challenging questions in neuroscience. In this paper, we focus on reconstructing the complex image stimuli from fMRI (functional magnetic resonance imaging) signals. Unlike previous works that reconstruct images with single objects or simple shapes, our work aims to reconstruct image stimuli that are rich in semantics, closer to everyday scenes, and can reveal more perspectives. However, data scarcity of fMRI datasets is the main obstacle to applying state-of-the-art deep learning models to this problem. We find that incorporating an additional text modality is beneficial for the reconstruction problem compared to directly translating brain signals to images. Therefore, the modalities involved in our method are: (i) voxel-level fMRI signals, (ii) observed images that trigger the brain signals, and (iii) textual description of the images. To further address data scarcity, we leverage an aligned vision-language latent space pre-trained on massive datasets. Instead of training models from scratch to find a latent space shared by the three modalities, we encode fMRI signals into this pre-aligned latent space. Then, conditioned on embeddings in this space, we reconstruct images with a generative model. The reconstructed images from our pipeline balance both naturalness and fidelity: they are photo-realistic and capture the ground truth image contents well. ",
    "url": "https://arxiv.org/abs/2210.01769",
    "authors": [
      "Sikun Lin",
      "Thomas Sprague",
      "Ambuj K Singh"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2101.11560",
    "title": "Wisdom of the Contexts: Active Ensemble Learning for Contextual Anomaly  Detection",
    "abstract": " Title: Wisdom of the Contexts: Active Ensemble Learning for Contextual Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2101.11560",
    "authors": [
      "Ece Calikus",
      "Slawomir Nowaczyk",
      "Mohamed-Rafik Bouguelia",
      "Onur Dikmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.07981",
    "title": "SiMaN: Sign-to-Magnitude Network Binarization",
    "abstract": " Comments: Accepted by IEEE TPAMI, 2022 ",
    "url": "https://arxiv.org/abs/2102.07981",
    "authors": [
      "Mingbao Lin",
      "Rongrong Ji",
      "Zihan Xu",
      "Baochang Zhang",
      "Fei Chao",
      "Chia-Wen Lin",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.03692",
    "title": "Provable Guarantees against Data Poisoning Using Self-Expansion and  Compatibility",
    "abstract": " Title: Provable Guarantees against Data Poisoning Using Self-Expansion and  Compatibility ",
    "url": "https://arxiv.org/abs/2105.03692",
    "authors": [
      "Charles Jin",
      "Melinda Sun",
      "Martin Rinard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.11168",
    "title": "Adversarially Robust One-class Novelty Detection",
    "abstract": " Comments: Accepted in IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI), 2022 ",
    "url": "https://arxiv.org/abs/2108.11168",
    "authors": [
      "Shao-Yuan Lo",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.02393",
    "title": "Geometric Algebra Attention Networks for Small Point Clouds",
    "abstract": " Title: Geometric Algebra Attention Networks for Small Point Clouds ",
    "url": "https://arxiv.org/abs/2110.02393",
    "authors": [
      "Matthew Spellings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.06253",
    "title": "StateAFL: Greybox Fuzzing for Stateful Network Servers",
    "abstract": " Comments: The tool is available at this https URL ",
    "url": "https://arxiv.org/abs/2110.06253",
    "authors": [
      "Roberto Natella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2111.00273",
    "title": "Cross-Modality Fusion Transformer for Multispectral Object Detection",
    "abstract": " Comments: 9 figures, 5 tables, submitted to IMAGE AND VISION COMPUTING ",
    "url": "https://arxiv.org/abs/2111.00273",
    "authors": [
      "Fang Qingyun",
      "Han Dapeng",
      "Wang Zhaokui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.10639",
    "title": "Implicit Acoustic Echo Cancellation for Keyword Spotting and  Device-Directed Speech Detection",
    "abstract": " Comments: To be presented at SLT 2022 ",
    "url": "https://arxiv.org/abs/2111.10639",
    "authors": [
      "Samuele Cornell",
      "Thomas Balestri",
      "Thibaud S\u00e9n\u00e9chal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.11707",
    "title": "Deps-SAN: Neural Machine Translation with Dependency-Scaled  Self-Attention Network",
    "abstract": " Title: Deps-SAN: Neural Machine Translation with Dependency-Scaled  Self-Attention Network ",
    "url": "https://arxiv.org/abs/2111.11707",
    "authors": [
      "Ru Peng",
      "Nankai Lin",
      "Yi Fang",
      "Shengyi Jiang",
      "Tianyong Hao",
      "Boyu Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.00988",
    "title": "Deep Transfer Learning: A Novel Collaborative Learning Model for  Cyberattack Detection Systems in IoT Networks",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2112.00988",
    "authors": [
      "Tran Viet Khoa",
      "Dinh Thai Hoang",
      "Nguyen Linh Trung",
      "Cong T. Nguyen",
      "Tran Thi Thuy Quynh",
      "Diep N. Nguyen",
      "Nguyen Viet Ha",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02252",
    "title": "Channel Exchanging Networks for Multimodal and Multitask Dense Image  Prediction",
    "abstract": " Comments: Accepted by TPAMI 2022. Code is available at this https URL arXiv admin note: text overlap with arXiv:2011.05005 ",
    "url": "https://arxiv.org/abs/2112.02252",
    "authors": [
      "Yikai Wang",
      "Fuchun Sun",
      "Wenbing Huang",
      "Fengxiang He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06013",
    "title": "Efficient Document-level Event Extraction via Pseudo-Trigger-aware  Pruned Complete Graph",
    "abstract": " Comments: Accepted to IJCAI'2022 ",
    "url": "https://arxiv.org/abs/2112.06013",
    "authors": [
      "Tong Zhu",
      "Xiaoye Qu",
      "Wenliang Chen",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Nicholas Jing Yuan",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.08288",
    "title": "Improving Both Domain Robustness and Domain Adaptability in Machine  Translation",
    "abstract": " Comments: Accepted to COLING 2022 ",
    "url": "https://arxiv.org/abs/2112.08288",
    "authors": [
      "Wen Lai",
      "Jind\u0159ich Libovick\u00fd",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.12717",
    "title": "Forward Composition Propagation for Explainable Neural Reasoning",
    "abstract": " Title: Forward Composition Propagation for Explainable Neural Reasoning ",
    "url": "https://arxiv.org/abs/2112.12717",
    "authors": [
      "Isel Grau",
      "Gonzalo N\u00e1poles",
      "Marilyn Bello",
      "Yamisleydi Salgueiro",
      "Agnieszka Jastrzebska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.14249",
    "title": "A Finite Sample Theorem for Longitudinal Causal Inference with Machine  Learning: Long Term, Dynamic, and Mediated Effects",
    "abstract": " Comments: 71 pages ",
    "url": "https://arxiv.org/abs/2112.14249",
    "authors": [
      "Rahul Singh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2201.01778",
    "title": "Quantum Capsule Networks",
    "abstract": " Comments: 7 pages (main text) + 7 pages (supplementary information), 8 figures ",
    "url": "https://arxiv.org/abs/2201.01778",
    "authors": [
      "Zidu Liu",
      "Pei-Xin Shen",
      "Weikang Li",
      "L.-M. Duan",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.06082",
    "title": "End-to-End V2X Latency Modeling and Analysis in 5G Networks",
    "abstract": " Comments: 15 pages, 8 figures, 15 tables ",
    "url": "https://arxiv.org/abs/2201.06082",
    "authors": [
      "B. Coll-Perales",
      "M.C. Lucas-Esta\u00f1",
      "T. Shimizu",
      "J. Gozalvez",
      "T. Higuchi",
      "S. Avedisov",
      "O. Altintas",
      "M. Sepulcre"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.04347",
    "title": "Gradient Methods Provably Converge to Non-Robust Networks",
    "abstract": " Comments: Minor fixes made for the NeurIPS CR version ",
    "url": "https://arxiv.org/abs/2202.04347",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09300",
    "title": "Exploring Adversarially Robust Training for Unsupervised Domain  Adaptation",
    "abstract": " Comments: Accepted at Asian Conference on Computer Vision (ACCV) 2022 ",
    "url": "https://arxiv.org/abs/2202.09300",
    "authors": [
      "Shao-Yuan Lo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10517",
    "title": "Individualized PATE: Differentially Private Machine Learning with  Individual Privacy Guarantees",
    "abstract": " Comments: accepted for publication at PoPETs'23 ",
    "url": "https://arxiv.org/abs/2202.10517",
    "authors": [
      "Franziska Boenisch",
      "Christopher M\u00fchl",
      "Roy Rinberg",
      "Jannis Ihrig",
      "Adam Dziedzic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.11202",
    "title": "Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning",
    "abstract": " Comments: The first two authors contributed equally to this paper ",
    "url": "https://arxiv.org/abs/2202.11202",
    "authors": [
      "Hao He",
      "Kaiwen Zha",
      "Dina Katabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09424",
    "title": "elBERto: Self-supervised Commonsense Learning for Question Answering",
    "abstract": " Title: elBERto: Self-supervised Commonsense Learning for Question Answering ",
    "url": "https://arxiv.org/abs/2203.09424",
    "authors": [
      "Xunlin Zhan",
      "Yuan Li",
      "Xiao Dong",
      "Xiaodan Liang",
      "Zhiting Hu",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11387",
    "title": "Privacy Rarely Considered: Exploring Considerations in the Adoption of  Third-Party Services by Websites",
    "abstract": " Comments: 25 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2203.11387",
    "authors": [
      "Christine Utz",
      "Sabrina Amft",
      "Martin Degeling",
      "Thorsten Holz",
      "Sascha Fahl",
      "Florian Schaub"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.11740",
    "title": "Plasticity Neural Network Based on Astrocytic effects at Critical  Period, Synaptic Competition and Rebalance by Current and Mnemonic Brain  Plasticity and Synapse Formation",
    "abstract": " Title: Plasticity Neural Network Based on Astrocytic effects at Critical  Period, Synaptic Competition and Rebalance by Current and Mnemonic Brain  Plasticity and Synapse Formation ",
    "url": "https://arxiv.org/abs/2203.11740",
    "authors": [
      "Jun-Bo Tao",
      "Bai-Qing Sun",
      "Wei-Dong Zhu",
      "Shi-You Qu",
      "Ling-Kun Chen",
      "Jia-Qiang Li",
      "Chong Wu",
      "Yu Xiong",
      "Jiaxuan Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15706",
    "title": "Stabilized Neural Ordinary Differential Equations for Long-Time  Forecasting of Dynamical Systems",
    "abstract": " Title: Stabilized Neural Ordinary Differential Equations for Long-Time  Forecasting of Dynamical Systems ",
    "url": "https://arxiv.org/abs/2203.15706",
    "authors": [
      "Alec J. Linot",
      "Joshua W. Burby",
      "Qi Tang",
      "Prasanna Balaprakash",
      "Michael D. Graham",
      "Romit Maulik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02765",
    "title": "Code Search: A Survey of Techniques for Finding Code",
    "abstract": " Title: Code Search: A Survey of Techniques for Finding Code ",
    "url": "https://arxiv.org/abs/2204.02765",
    "authors": [
      "Luca Di Grazia",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.07731",
    "title": "Transfer learning based physics-informed neural networks for solving  inverse problems in engineering structures under different loading scenarios",
    "abstract": " Comments: updated version ",
    "url": "https://arxiv.org/abs/2205.07731",
    "authors": [
      "Chen Xu",
      "Ba Trung Cao",
      "Yong Yuan",
      "G\u00fcnther Meschke"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2205.09653",
    "title": "Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide  Neural Networks",
    "abstract": " Comments: Neurips 2022 Camera Ready. Fixed Appendix typos. 55 pages ",
    "url": "https://arxiv.org/abs/2205.09653",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10933",
    "title": "AutoJoin: Efficient Adversarial Training for Robust Maneuvering via  Denoising Autoencoder and Joint Learning",
    "abstract": " Title: AutoJoin: Efficient Adversarial Training for Robust Maneuvering via  Denoising Autoencoder and Joint Learning ",
    "url": "https://arxiv.org/abs/2205.10933",
    "authors": [
      "Michael Villarreal",
      "Bibek Poudel",
      "Ryan Wickman",
      "Yu Shen",
      "Weizi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.12134",
    "title": "Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box  Score-Based Query Attacks",
    "abstract": " Comments: accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.12134",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Cihang Xie",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.14962",
    "title": "Sampling-free Inference for Ab-Initio Potential Energy Surface Networks",
    "abstract": " Title: Sampling-free Inference for Ab-Initio Potential Energy Surface Networks ",
    "url": "https://arxiv.org/abs/2205.14962",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2205.15614",
    "title": "Communication-Efficient Distributionally Robust Decentralized Learning",
    "abstract": " Comments: Manuscript submitted for publication ",
    "url": "https://arxiv.org/abs/2205.15614",
    "authors": [
      "Matteo Zecchin",
      "Marios Kountouris",
      "David Gesbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.15765",
    "title": "Strategic Classification with Graph Neural Networks",
    "abstract": " Title: Strategic Classification with Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2205.15765",
    "authors": [
      "Itay Eilat",
      "Ben Finkelshtein",
      "Chaim Baskin",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02887",
    "title": "Sample Complexity of Nonparametric Off-Policy Evaluation on  Low-Dimensional Manifolds using Deep Networks",
    "abstract": " Comments: 52 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2206.02887",
    "authors": [
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.05070",
    "title": "Fundamental Limits in Formal Verification of Message-Passing Neural  Networks",
    "abstract": " Title: Fundamental Limits in Formal Verification of Message-Passing Neural  Networks ",
    "url": "https://arxiv.org/abs/2206.05070",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2206.13903",
    "title": "AS-IntroVAE: Adversarial Similarity Distance Makes Robust IntroVAE",
    "abstract": " Comments: ACML conference paper ",
    "url": "https://arxiv.org/abs/2206.13903",
    "authors": [
      "Changjie Lu",
      "Shen Zheng",
      "Zirui Wang",
      "Omar Dib",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14337",
    "title": "Deformable Graph Transformer",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2206.14337",
    "authors": [
      "Jinyoung Park",
      "Seongjun Yun",
      "Hyeonjin Park",
      "Jaewoo Kang",
      "Jisu Jeong",
      "Kyung-Min Kim",
      "Jung-woo Ha",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02338",
    "title": "Mitigating Propagation Failures in PINNs using Evolutionary Sampling",
    "abstract": " Comments: 34 pages, 46 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2207.02338",
    "authors": [
      "Arka Daw",
      "Jie Bu",
      "Sifan Wang",
      "Paris Perdikaris",
      "Anuj Karpatne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05729",
    "title": "Physical Passive Patch Adversarial Attacks on Visual Odometry Systems",
    "abstract": " Comments: Accepted to ACCV 2022 ",
    "url": "https://arxiv.org/abs/2207.05729",
    "authors": [
      "Yaniv Nemcovsky",
      "Matan Jacoby",
      "Alex M. Bronstein",
      "Chaim Baskin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09597",
    "title": "Feasible Adversarial Robust Reinforcement Learning for Underspecified  Environments",
    "abstract": " Comments: Added new theory sections. Added comparison to self-play. Added adversary mixed-strategy analysis ",
    "url": "https://arxiv.org/abs/2207.09597",
    "authors": [
      "JB Lanier",
      "Stephen McAleer",
      "Pierre Baldi",
      "Roy Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.10324",
    "title": "Improved Chest Anomaly Localization without Pixel-level Annotation via  Image Translation Network Application in Pseudo-paired Registration Domain",
    "abstract": " Title: Improved Chest Anomaly Localization without Pixel-level Annotation via  Image Translation Network Application in Pseudo-paired Registration Domain ",
    "url": "https://arxiv.org/abs/2207.10324",
    "authors": [
      "Kyungsu Kim",
      "Seong Je Oh",
      "Tae Uk Kim",
      "Myung Jin Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.14192",
    "title": "Mining Cross-Person Cues for Body-Part Interactiveness Learning in HOI  Detection",
    "abstract": " Comments: To appear in ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.14192",
    "authors": [
      "Xiaoqian Wu",
      "Yong-Lu Li",
      "Xinpeng Liu",
      "Junyi Zhang",
      "Yuzhe Wu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00780",
    "title": "Visual correspondence-based explanations improve AI robustness and  human-AI team accuracy",
    "abstract": " Comments: NeurIPS 2022 conference paper ",
    "url": "https://arxiv.org/abs/2208.00780",
    "authors": [
      "Giang Nguyen",
      "Mohammad Reza Taesiri",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.03067",
    "title": "Large vocabulary speech recognition for languages of Africa:  multilingual modeling and self-supervised learning",
    "abstract": " Title: Large vocabulary speech recognition for languages of Africa:  multilingual modeling and self-supervised learning ",
    "url": "https://arxiv.org/abs/2208.03067",
    "authors": [
      "Sandy Ritchie",
      "You-Chi Cheng",
      "Mingqing Chen",
      "Rajiv Mathews",
      "Daan van Esch",
      "Bo Li",
      "Khe Chai Sim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2208.03211",
    "title": "Why do networks have inhibitory/negative connections?",
    "abstract": " Comments: Submitted ",
    "url": "https://arxiv.org/abs/2208.03211",
    "authors": [
      "Qingyang Wang",
      "Michael A. Powell",
      "Ali Geisa",
      "Eric Bridgeford",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.09727",
    "title": "Security Implications of Large Language Model Code Assistants: A User  Study",
    "abstract": " Comments: 16 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2208.09727",
    "authors": [
      "Gustavo Sandoval",
      "Hammond Pearce",
      "Teo Nys",
      "Ramesh Karri",
      "Brendan Dolan-Gavitt",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10387",
    "title": "Constants of motion network",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2208.10387",
    "authors": [
      "Muhammad Firmansyah Kasim",
      "Yi Heng Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2208.11266",
    "title": "SCALE: Online Self-Supervised Lifelong Learning without Prior Knowledge",
    "abstract": " Comments: Submitted for review ",
    "url": "https://arxiv.org/abs/2208.11266",
    "authors": [
      "Xiaofan Yu",
      "Yunhui Guo",
      "Sicun Gao",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.12697",
    "title": "Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction",
    "abstract": " Title: Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction ",
    "url": "https://arxiv.org/abs/2208.12697",
    "authors": [
      "Tong Wu",
      "Jiaqi Wang",
      "Xingang Pan",
      "Xudong Xu",
      "Christian Theobalt",
      "Ziwei Liu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02884",
    "title": "Multi-Grained Angle Representation for Remote Sensing Object Detection",
    "abstract": " Comments: 13 pages, 9 figures, 14 tables ",
    "url": "https://arxiv.org/abs/2209.02884",
    "authors": [
      "Hao Wang",
      "Zhanchao Huang",
      "Zhengchao Chen",
      "Ying Song",
      "Wei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.05683",
    "title": "One-shot Network Pruning at Initialization with Discriminative Image  Patches",
    "abstract": " Comments: BMVC 2022 ",
    "url": "https://arxiv.org/abs/2209.05683",
    "authors": [
      "Yinan Yang",
      "Yu Wang",
      "Ying Ji",
      "Heng Qi",
      "Jien Kato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.09883",
    "title": "Leveraging Local Patch Differences in Multi-Object Scenes for Generative  Adversarial Attacks",
    "abstract": " Comments: Accepted at WACV 2023 (Round 1), camera-ready version ",
    "url": "https://arxiv.org/abs/2209.09883",
    "authors": [
      "Abhishek Aich",
      "Shasha Li",
      "Chengyu Song",
      "M. Salman Asif",
      "Srikanth V. Krishnamurthy",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14649",
    "title": "Factor Graph Fusion of Raw GNSS Sensing with IMU and Lidar for Precise  Robot Localization without a Base Station",
    "abstract": " Comments: 7 pages, 4 figures, accompanying video: this https URL ",
    "url": "https://arxiv.org/abs/2209.14649",
    "authors": [
      "Jonas Beuchert",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14930",
    "title": "Graph Anomaly Detection with Graph Neural Networks: Current Status and  Challenges",
    "abstract": " Comments: 9 pages, 2 figures, 1 tables; to appear in the IEEE Access (Please cite our journal version.) ",
    "url": "https://arxiv.org/abs/2209.14930",
    "authors": [
      "Hwan Kim",
      "Byung Suk Lee",
      "Won-Yong Shin",
      "Sungsu Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.15265",
    "title": "Overparameterized ReLU Neural Networks Learn the Simplest Models: Neural  Isometry and Exact Recovery",
    "abstract": " Title: Overparameterized ReLU Neural Networks Learn the Simplest Models: Neural  Isometry and Exact Recovery ",
    "url": "https://arxiv.org/abs/2209.15265",
    "authors": [
      "Yifei Wang",
      "Yixuan Hua",
      "Emmanuel Cand\u00e9s",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.15575",
    "title": "Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio",
    "abstract": " Title: Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio ",
    "url": "https://arxiv.org/abs/2209.15575",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Pedro P. B. de Gusmao",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.15597",
    "title": "MEIM: Multi-partition Embedding Interaction Beyond Block Term Format for  Efficient and Expressive Link Prediction",
    "abstract": " Comments: Accepted at the International Joint Conference on Artificial Intelligence (IJCAI), 2022; add appendix with extra experiments ",
    "url": "https://arxiv.org/abs/2209.15597",
    "authors": [
      "Hung Nghiep Tran",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00108",
    "title": "ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled  neural networks",
    "abstract": " Comments: 10 pages, 6 figures. For website see this https URL . For source code, see this https URL ",
    "url": "https://arxiv.org/abs/2210.00108",
    "authors": [
      "Tim Clifford",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Ross Anderson",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00411",
    "title": "Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening  Problem",
    "abstract": " Comments: 8 pages, 7 figures, published to WACV2023 ",
    "url": "https://arxiv.org/abs/2210.00411",
    "authors": [
      "Xingyu Chen",
      "Ruonan Zhang",
      "Ji Jiang",
      "Yan Wang",
      "Ge Li",
      "Thomas H. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": " Comments: This paper is the full version of a paper to appear in CCS 2022 ",
    "url": "https://arxiv.org/abs/2210.00486",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00584",
    "title": "FLCert: Provably Secure Federated Learning against Poisoning Attacks",
    "abstract": " Comments: To appear in Transactions on Information Forensics and Security. arXiv admin note: text overlap with arXiv:2102.01854 ",
    "url": "https://arxiv.org/abs/2210.00584",
    "authors": [
      "Xiaoyu Cao",
      "Zaixi Zhang",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00743",
    "title": "An Embarrassingly Simple Approach for Intellectual Property Rights  Protection on Recurrent Neural Networks",
    "abstract": " Comments: Accepted at AACL-IJCNLP 2022 (Fig. 1 updated) ",
    "url": "https://arxiv.org/abs/2210.00743",
    "authors": [
      "Zhi Qin Tan",
      "Hao Shan Wong",
      "Chee Seng Chan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01075",
    "title": "Decompiling x86 Deep Neural Network Executables",
    "abstract": " Comments: The extended version of a paper to appear in the Proceedings of the 32nd USENIX Security Symposium, 2023, (USENIX Security '23), 25 pages ",
    "url": "https://arxiv.org/abs/2210.01075",
    "authors": [
      "Zhibo Liu",
      "Yuanyuan Yuan",
      "Shuai Wang",
      "Xiaofei Xie",
      "Lei Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  }
]