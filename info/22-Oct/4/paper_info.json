[
  {
    "id": "arXiv:2210.00008",
    "title": "Adversarial Attacks on Transformers-Based Malware Detectors",
    "abstract": "Signature-based malware detectors have proven to be insufficient as even a small change in malignant executable code can bypass these signature-based detectors. Many machine learning-based models have been proposed to efficiently detect a wide variety of malware. Many of these models are found to be susceptible to adversarial attacks - attacks that work by generating intentionally designed inputs that can force these models to misclassify. Our work aims to explore vulnerabilities in the current state of the art malware detectors to adversarial attacks. We train a Transformers-based malware detector, carry out adversarial attacks resulting in a misclassification rate of 23.9% and propose defenses that reduce this misclassification rate to half. An implementation of our work can be found at https://github.com/yashjakhotiya/Adversarial-Attacks-On-Transformers. ",
    "url": "https://arxiv.org/abs/2210.00008",
    "authors": [
      "Yash Jakhotiya",
      "Heramb Patil",
      "Jugal Rawlani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00026",
    "title": "CRC-Aided Short Convolutional Codes and RCU Bounds for Orthogonal  Signaling",
    "abstract": "We extend earlier work on the design of convolutional code-specific CRC codes to $Q$-ary alphabets, with an eye toward $Q$-ary orthogonal signaling. Starting with distance-spectrum optimal, zero-terminated, $Q$-ary convolutional codes, we design $Q$-ary CRC codes so that the CRC/convolutional concatenation is distance-spectrum optimal. The $Q$-ary code symbols are mapped to a $Q$-ary orthogonal signal set and sent over an AWGN channel with noncoherent reception. We focus on $Q = 4$, rate-1/2 convolutional codes in our designs. The random coding union bound and normal approximation are used in earlier works as benchmarks for performance for distance-spectrum optimal convolutional codes. We derive a saddlepoint approximation of the random coding union bound for the coded noncoherent signaling channel, as well as a normal approximation for this channel, and compare the performance of our codes to these limits. Our best design is within $0.6$ dB of the RCU bound at a frame error rate of $10^{-4}$. ",
    "url": "https://arxiv.org/abs/2210.00026",
    "authors": [
      "Jacob King",
      "William Ryan",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.00030",
    "title": "VIP: Towards Universal Visual Reward and Representation via  Value-Implicit Pre-Training",
    "abstract": "Reward and representation learning are two long-standing challenges for learning an expanding set of robot manipulation skills from sensory observations. Given the inherent cost and scarcity of in-domain, task-specific robot data, learning from large, diverse, offline human videos has emerged as a promising path towards acquiring a generally useful visual representation for control; however, how these human videos can be used for general-purpose reward learning remains an open question. We introduce $\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a self-supervised pre-trained visual representation capable of generating dense and smooth reward functions for unseen robotic tasks. VIP casts representation learning from human videos as an offline goal-conditioned reinforcement learning problem and derives a self-supervised dual goal-conditioned value-function objective that does not depend on actions, enabling pre-training on unlabeled human videos. Theoretically, VIP can be understood as a novel implicit time contrastive objective that generates a temporally smooth embedding, enabling the value function to be implicitly defined via the embedding distance, which can then be used to construct the reward for any goal-image specified downstream task. Trained on large-scale Ego4D human videos and without any fine-tuning on in-domain, task-specific data, VIP's frozen representation can provide dense visual reward for an extensive set of simulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual control methods and significantly outperforming all prior pre-trained representations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL on a suite of real-world robot tasks with as few as 20 trajectories. ",
    "url": "https://arxiv.org/abs/2210.00030",
    "authors": [
      "Yecheng Jason Ma",
      "Shagun Sodhani",
      "Dinesh Jayaraman",
      "Osbert Bastani",
      "Vikash Kumar",
      "Amy Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00032",
    "title": "Direct Embedding of Temporal Network Edges via Time-Decayed Line Graphs",
    "abstract": "Temporal networks model a variety of important phenomena involving timed interactions between entities. Existing methods for machine learning on temporal networks generally exhibit at least one of two limitations. First, time is assumed to be discretized, so if the time data is continuous, the user must determine the discretization and discard precise time information. Second, edge representations can only be calculated indirectly from the nodes, which may be suboptimal for tasks like edge classification. We present a simple method that avoids both shortcomings: construct the line graph of the network, which includes a node for each interaction, and weigh the edges of this graph based on the difference in time between interactions. From this derived graph, edge representations for the original network can be computed with efficient classical methods. The simplicity of this approach facilitates explicit theoretical analysis: we can constructively show the effectiveness of our method's representations for a natural synthetic model of temporal networks. Empirical results on real-world networks demonstrate our method's efficacy and efficiency on both edge classification and temporal link prediction. ",
    "url": "https://arxiv.org/abs/2210.00032",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Ryan A. Rossi",
      "Sungchul Kim",
      "Tong Yu",
      "Jane Hoffswell",
      "Nedim Lipka",
      "Shunan Guo",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.00035",
    "title": "Neural Causal Models for Counterfactual Identification and Estimation",
    "abstract": "Evaluating hypothetical statements about how the world would be had a different course of action been taken is arguably one key capability expected from modern AI systems. Counterfactual reasoning underpins discussions in fairness, the determination of blame and responsibility, credit assignment, and regret. In this paper, we study the evaluation of counterfactual statements through neural models. Specifically, we tackle two causal problems required to make such evaluations, i.e., counterfactual identification and estimation from an arbitrary combination of observational and experimental data. First, we show that neural causal models (NCMs) are expressive enough and encode the structural constraints necessary for performing counterfactual reasoning. Second, we develop an algorithm for simultaneously identifying and estimating counterfactual distributions. We show that this algorithm is sound and complete for deciding counterfactual identification in general settings. Third, considering the practical implications of these results, we introduce a new strategy for modeling NCMs using generative adversarial networks. Simulations corroborate with the proposed methodology. ",
    "url": "https://arxiv.org/abs/2210.00035",
    "authors": [
      "Kevin Xia",
      "Yushu Pan",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00041",
    "title": "Communication-Enabled Multi-Agent Decentralised Deep Reinforcement  Learning to Optimise Energy-Efficiency in UAV-Assisted Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed to provide wireless connectivity to static and mobile ground users in situations of increased network demand or points-of-failure in existing terrestrial cellular infrastructure. However, UAVs are energy-constrained and may experience interference from nearby UAV cells sharing the same frequency spectrum, thereby impacting the system's energy efficiency (EE). We aim to address research gaps that focus on optimising the system's EE using a 2D trajectory optimisation of UAVs serving only static ground users, and neglect the impact of interference from nearby UAV cells. Unlike previous work that assume global spatial knowledge of ground users' location via a central controller that periodically scans the network perimeter and provides real-time updates to the UAVs for decision making, we focus on a realistic decentralised approach suitable in emergencies. Thus, we apply a decentralised Multi-Agent Reinforcement Learning (MARL) approach that maximizes the system's EE by jointly optimising each UAV's 3D trajectory, number of connected static and mobile users, and the energy consumed, while taking into account the impact of interference and the UAVs' coordination on the system's EE in a dynamic network environment. To address this, we propose a direct collaborative Communication-enabled Multi-Agent Decentralised Double Deep Q-Network (CMAD-DDQN) approach. The CMAD-DDQN is a collaborative algorithm that allows UAVs to explicitly share knowledge by communicating with its nearest neighbours based on existing 3GPP guidelines. Our approach is able to maximise the system's EE without degrading the coverage performance in the network. Simulation results show that the proposed approach outperforms existing baselines in term of maximising the systems' EE by about 15% - 85%. ",
    "url": "https://arxiv.org/abs/2210.00041",
    "authors": [
      "Babatunji Omoniwa",
      "Boris Galkin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.00053",
    "title": "Kernel Normalized Convolutional Networks for Privacy-Preserving Machine  Learning",
    "abstract": "Normalization is an important but understudied challenge in privacy-related application domains such as federated learning (FL) and differential privacy (DP). While the unsuitability of batch normalization for FL and DP has already been shown, the impact of the other normalization methods on the performance of federated or differentially private models is not well-known. To address this, we draw a performance comparison among layer normalization (LayerNorm), group normalization (GroupNorm), and the recently proposed kernel normalization (KernelNorm) in FL and DP settings. Our results indicate LayerNorm and GroupNorm provide no performance gain compared to the baseline (i.e. no normalization) for shallow models, but they considerably enhance performance of deeper models. KernelNorm, on the other hand, significantly outperforms its competitors in terms of accuracy and convergence rate (or communication efficiency) for both shallow and deeper models. Given these key observations, we propose a kernel normalized ResNet architecture called KNResNet-13 for differentially private learning environments. Using the proposed architecture, we provide new state-of-the-art accuracy values on the CIFAR-10 and Imagenette datasets. ",
    "url": "https://arxiv.org/abs/2210.00053",
    "authors": [
      "Reza Nasirigerdeh",
      "Javad Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00062",
    "title": "Learning Robust Kernel Ensembles with Kernel Average Pooling",
    "abstract": "Model ensembles have long been used in machine learning to reduce the variance in individual model predictions, making them more robust to input perturbations. Pseudo-ensemble methods like dropout have also been commonly used in deep learning models to improve generalization. However, the application of these techniques to improve neural networks' robustness against input perturbations remains underexplored. We introduce Kernel Average Pool (KAP), a new neural network building block that applies the mean filter along the kernel dimension of the layer activation tensor. We show that ensembles of kernels with similar functionality naturally emerge in convolutional neural networks equipped with KAP and trained with backpropagation. Moreover, we show that when combined with activation noise, KAP models are remarkably robust against various forms of adversarial attacks. Empirical evaluations on CIFAR10, CIFAR100, TinyImagenet, and Imagenet datasets show substantial improvements in robustness against strong adversarial attacks such as AutoAttack that are on par with adversarially trained networks but are importantly obtained without training on any adversarial examples. ",
    "url": "https://arxiv.org/abs/2210.00062",
    "authors": [
      "Pouya Bashivan",
      "Adam Ibrahim",
      "Amirozhan Dehghani",
      "Yifei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.00084",
    "title": "Contrastive Graph Few-Shot Learning",
    "abstract": "Prevailing deep graph learning models often suffer from label sparsity issue. Although many graph few-shot learning (GFL) methods have been developed to avoid performance degradation in face of limited annotated data, they excessively rely on labeled data, where the distribution shift in the test phase might result in impaired generalization ability. Additionally, they lack a general purpose as their designs are coupled with task or data-specific characteristics. To this end, we propose a general and effective Contrastive Graph Few-shot Learning framework (CGFL). CGFL leverages a self-distilled contrastive learning procedure to boost GFL. Specifically, our model firstly pre-trains a graph encoder with contrastive learning using unlabeled data. Later, the trained encoder is frozen as a teacher model to distill a student model with a contrastive loss. The distilled model is finally fed to GFL. CGFL learns data representation in a self-supervised manner, thus mitigating the distribution shift impact for better generalization and making model task and data-independent for a general graph mining purpose. Furthermore, we introduce an information-based method to quantitatively measure the capability of CGFL. Comprehensive experiments demonstrate that CGFL outperforms state-of-the-art baselines on several graph mining tasks in the few-shot scenario. We also provide quantitative measurement of CGFL's success. ",
    "url": "https://arxiv.org/abs/2210.00084",
    "authors": [
      "Chunhui Zhang",
      "Hongfu Liu",
      "Jundong Li",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00087",
    "title": "D-Align: Dual Query Co-attention Network for 3D Object Detection Based  on Multi-frame Point Cloud Sequence",
    "abstract": "LiDAR sensors are widely used for 3D object detection in various mobile robotics applications. LiDAR sensors continuously generate point cloud data in real-time. Conventional 3D object detectors detect objects using a set of points acquired over a fixed duration. However, recent studies have shown that the performance of object detection can be further enhanced by utilizing spatio-temporal information obtained from point cloud sequences. In this paper, we propose a new 3D object detector, named D-Align, which can effectively produce strong bird's-eye-view (BEV) features by aligning and aggregating the features obtained from a sequence of point sets. The proposed method includes a novel dual-query co-attention network that uses two types of queries, including target query set (T-QS) and support query set (S-QS), to update the features of target and support frames, respectively. D-Align aligns S-QS to T-QS based on the temporal context features extracted from the adjacent feature maps and then aggregates S-QS with T-QS using a gated attention mechanism. The dual queries are updated through multiple attention layers to progressively enhance the target frame features used to produce the detection results. Our experiments on the nuScenes dataset show that the proposed D-Align method greatly improved the performance of a single frame-based baseline method and significantly outperformed the latest 3D object detectors. ",
    "url": "https://arxiv.org/abs/2210.00087",
    "authors": [
      "Junhyung Lee",
      "Junho Koh",
      "Youngwoo Lee",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00094",
    "title": "Adaptive Weight Decay: On The Fly Weight Decay Tuning for Improving  Robustness",
    "abstract": "We introduce adaptive weight decay, which automatically tunes the hyper-parameter for weight decay during each training iteration. For classification problems, we propose changing the value of the weight decay hyper-parameter on the fly based on the strength of updates from the classification loss (i.e., gradient of cross-entropy), and the regularization loss (i.e., $\\ell_2$-norm of the weights). We show that this simple modification can result in large improvements in adversarial robustness -- an area which suffers from robust overfitting -- without requiring extra data. Specifically, our reformulation results in 20% relative robustness improvement for CIFAR-100, and 10% relative robustness improvement on CIFAR-10 comparing to traditional weight decay. In addition, this method has other desirable properties, such as less sensitivity to learning rate, and smaller weight norms, which the latter contributes to robustness to overfitting to label noise, and pruning. ",
    "url": "https://arxiv.org/abs/2210.00094",
    "authors": [
      "Amin Ghiasi",
      "Ali Shafahi",
      "Reza Ardekani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00100",
    "title": "Image-Based Detection of Modifications in Gas Pump PCBs with Deep  Convolutional Autoencoders",
    "abstract": "In this paper, we introduce an approach for detecting modifications in assembled printed circuit boards based on photographs taken without tight control over perspective and illumination conditions. One instance of this problem is the visual inspection of gas pumps PCBs, which can be modified by fraudsters wishing to deceive costumers or evade taxes. Given the uncontrolled environment and the huge number of possible modifications, we address the problem as a case of anomaly detection, proposing an approach that is directed towards the characteristics of that scenario, while being well-suited for other similar applications. The proposed approach employs a deep convolutional autoencoder trained to reconstruct images of an unmodified board, but which remains unable to do the same for images showing modifications. By comparing the input image with its reconstruction, it is possible to segment anomalies and modifications in a pixel-wise manner. Experiments performed on a dataset built to represent real-world situations (and which we will make publicly available) show that our approach outperforms other state-of-the-art approaches for anomaly segmentation in the considered scenario, while producing comparable results on the popular MVTec-AD dataset for a more general object anomaly detection task. ",
    "url": "https://arxiv.org/abs/2210.00100",
    "authors": [
      "Diulhio Candido de Oliveira",
      "Bogdan Tomoyuki Nassu",
      "Marco Aurelio Wehrmeister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00102",
    "title": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP  Initialization",
    "abstract": "Training graph neural networks (GNNs) on large graphs is complex and extremely time consuming. This is attributed to overheads caused by sparse matrix multiplication, which are sidestepped when training multi-layer perceptrons (MLPs) with only node features. MLPs, by ignoring graph context, are simple and faster for graph data, however they usually sacrifice prediction accuracy, limiting their applications for graph data. We observe that for most message passing-based GNNs, we can trivially derive an analog MLP (we call this a PeerMLP) whose weights can be made identical, making us curious about how do GNNs using weights from a fully trained PeerMLP perform? Surprisingly, we find that GNNs initialized with such weights significantly outperform their PeerMLPs for graph data, motivating us to use PeerMLP training as a precursor, initialization step to GNN training. To this end, we propose an embarrassingly simple, yet hugely effective initialization method for GNN training acceleration, called MLPInit. Our extensive experiments on multiple large-scale graph datasets with diverse GNN architectures validate that MLPInit can accelerate the training of GNNs (up to 33X speedup on OGB-products) and often improve prediction performance (e.g., up to 7.97% improvement for GraphSAGE across 7 datasets for node classification, and up to 17.81% improvement across 4 datasets for link prediction on metric Hits@10). Most importantly, MLPInit is extremely simple to implement and can be flexibly used as a plug-and-play initialization method for message passing-based GNNs. ",
    "url": "https://arxiv.org/abs/2210.00102",
    "authors": [
      "Xiaotian Han",
      "Tong Zhao",
      "Yozen Liu",
      "Xia Hu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.00105",
    "title": "A Decade of Knowledge Graphs in Natural Language Processing: A Survey",
    "abstract": "In pace with developments in the research field of artificial intelligence, knowledge graphs (KGs) have attracted a surge of interest from both academia and industry. As a representation of semantic relations between entities, KGs have proven to be particularly relevant for natural language processing (NLP), experiencing a rapid spread and wide adoption within recent years. Given the increasing amount of research work in this area, several KG-related approaches have been surveyed in the NLP research community. However, a comprehensive study that categorizes established topics and reviews the maturity of individual research streams remains absent to this day. Contributing to closing this gap, we systematically analyzed 507 papers from the literature on KGs in NLP. Our survey encompasses a multifaceted review of tasks, research types, and contributions. As a result, we present a structured overview of the research landscape, provide a taxonomy of tasks, summarize our findings, and highlight directions for future work. ",
    "url": "https://arxiv.org/abs/2210.00105",
    "authors": [
      "Phillip Schneider",
      "Tim Schopf",
      "Juraj Vladika",
      "Mikhail Galkin",
      "Elena Simperl",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00108",
    "title": "ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled  neural networks",
    "abstract": "Early backdoor attacks against machine learning set off an arms race in attack and defence development. Defences have since appeared demonstrating some ability to detect backdoors in models or even remove them. These defences work by inspecting the training data, the model, or the integrity of the training procedure. In this work, we show that backdoors can be added during compilation, circumventing any safeguards in the data preparation and model training stages. As an illustration, the attacker can insert weight-based backdoors during the hardware compilation step that will not be detected by any training or data-preparation process. Next, we demonstrate that some backdoors, such as ImpNet, can only be reliably detected at the stage where they are inserted and removing them anywhere else presents a significant challenge. We conclude that machine-learning model security requires assurance of provenance along the entire technical pipeline, including the data, model architecture, compiler, and hardware specification. ",
    "url": "https://arxiv.org/abs/2210.00108",
    "authors": [
      "Tim Clifford",
      "Ilia Shumailov",
      "Yiren Zhao",
      "Ross Anderson",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00116",
    "title": "Predicting Cellular Responses with Variational Causal Inference and  Refined Relational Information",
    "abstract": "Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advantage of our approach over state-of-the-art deep learning models for individual response prediction. ",
    "url": "https://arxiv.org/abs/2210.00116",
    "authors": [
      "Yulun Wu",
      "Robert A. Barton",
      "Zichen Wang",
      "Vassilis N. Ioannidis",
      "Carlo De Donno",
      "Layne C. Price",
      "Luis F. Voloch",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00120",
    "title": "NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning",
    "abstract": "Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have also led to physics-informed deep neural models capable of representing complex dynamical Partial Differential Equations (PDEs). Inspired by these developments, we propose Neural Time Fields (NTFields) for robot motion planning in cluttered scenarios. Our framework represents a wave propagation model generating continuous arrival time to find path solutions informed by a nonlinear first-order PDE called Eikonal Equation. We evaluate our method in various cluttered 3D environments, including the Gibson dataset, and demonstrate its ability to solve motion planning problems for 4-DOF and 6-DOF robot manipulators where the traditional grid-based Eikonal planners often face the curse of dimensionality. Furthermore, the results show that our method exhibits high success rates and significantly lower computational times than the state-of-the-art methods, including NMPs that require training data from classical planners. ",
    "url": "https://arxiv.org/abs/2210.00120",
    "authors": [
      "Ruiqi Ni",
      "Ahmed H. Qureshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.00122",
    "title": "Adversarial Robustness of Representation Learning for Knowledge Graphs",
    "abstract": "Knowledge graphs represent factual knowledge about the world as relationships between concepts and are critical for intelligent decision making in enterprise applications. New knowledge is inferred from the existing facts in the knowledge graphs by encoding the concepts and relations into low-dimensional feature vector representations. The most effective representations for this task, called Knowledge Graph Embeddings (KGE), are learned through neural network architectures. Due to their impressive predictive performance, they are increasingly used in high-impact domains like healthcare, finance and education. However, are the black-box KGE models adversarially robust for use in domains with high stakes? This thesis argues that state-of-the-art KGE models are vulnerable to data poisoning attacks, that is, their predictive performance can be degraded by systematically crafted perturbations to the training knowledge graph. To support this argument, two novel data poisoning attacks are proposed that craft input deletions or additions at training time to subvert the learned model's performance at inference time. These adversarial attacks target the task of predicting the missing facts in knowledge graphs using KGE models, and the evaluation shows that the simpler attacks are competitive with or outperform the computationally expensive ones. The thesis contributions not only highlight and provide an opportunity to fix the security vulnerabilities of KGE models, but also help to understand the black-box predictive behaviour of KGE models. ",
    "url": "https://arxiv.org/abs/2210.00122",
    "authors": [
      "Peru Bhardwaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00124",
    "title": "Implicit Neural Spatial Representations for Time-dependent PDEs",
    "abstract": "Numerically solving partial differential equations (PDEs) often entails spatial and temporal discretizations. Traditional methods (e.g., finite difference, finite element, smoothed-particle hydrodynamics) frequently adopt explicit spatial discretizations, such as grids, meshes, and point clouds, where each degree-of-freedom corresponds to a location in space. While these explicit spatial correspondences are intuitive to model and understand, these representations are not necessarily optimal for accuracy, memory-usage, or adaptivity. In this work, we explore implicit neural representation as an alternative spatial discretization, where spatial information is implicitly stored in the neural network weights. With implicit neural spatial representation, PDE-constrained time-stepping translates into updating neural network weights, which naturally integrates with commonly adopted optimization time integrators. We validate our approach on a variety of classic PDEs with examples involving large elastic deformations, turbulent fluids, and multiscale phenomena. While slower to compute than traditional representations, our approach exhibits higher accuracy, lower memory consumption, and dynamically adaptive allocation of degrees of freedom without complex remeshing. ",
    "url": "https://arxiv.org/abs/2210.00124",
    "authors": [
      "Honglin Chen",
      "Rundi Wu",
      "Eitan Grinspun",
      "Changxi Zheng",
      "Peter Yichen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.00127",
    "title": "Robust Person Identification: A WiFi Vision-based Approach",
    "abstract": "Person re-identification (Re-ID) has become increasingly important as it supports a wide range of security applications. Traditional person Re-ID mainly relies on optical camera-based systems, which incur several limitations due to the changes in the appearance of people, occlusions, and human poses. In this work, we propose a WiFi vision-based system, 3D-ID, for person Re-ID in 3D space. Our system leverages the advances of WiFi and deep learning to help WiFi devices see, identify, and recognize people. In particular, we leverage multiple antennas on next-generation WiFi devices and 2D AoA estimation of the signal reflections to enable WiFi to visualize a person in the physical environment. We then leverage deep learning to digitize the visualization of the person into 3D body representation and extract both the static body shape and dynamic walking patterns for person Re-ID. Our evaluation results under various indoor environments show that the 3D-ID system achieves an overall rank-1 accuracy of 85.3%. Results also show that our system is resistant to various attacks. The proposed 3D-ID is thus very promising as it could augment or complement camera-based systems. ",
    "url": "https://arxiv.org/abs/2210.00127",
    "authors": [
      "Yili Ren",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.00136",
    "title": "IMB-NAS: Neural Architecture Search for Imbalanced Datasets",
    "abstract": "Class imbalance is a ubiquitous phenomenon occurring in real world data distributions. To overcome its detrimental effect on training accurate classifiers, existing work follows three major directions: class re-balancing, information transfer, and representation learning. In this paper, we propose a new and complementary direction for improving performance on long tailed datasets - optimizing the backbone architecture through neural architecture search (NAS). We find that an architecture's accuracy obtained on a balanced dataset is not indicative of good performance on imbalanced ones. This poses the need for a full NAS run on long tailed datasets which can quickly become prohibitively compute intensive. To alleviate this compute burden, we aim to efficiently adapt a NAS super-network from a balanced source dataset to an imbalanced target one. Among several adaptation strategies, we find that the most effective one is to retrain the linear classification head with reweighted loss, while freezing the backbone NAS super-network trained on a balanced source dataset. We perform extensive experiments on multiple datasets and provide concrete insights to optimize architectures for long tailed datasets. ",
    "url": "https://arxiv.org/abs/2210.00136",
    "authors": [
      "Rahul Duggal",
      "Shengyun Peng",
      "Hao Zhou",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00139",
    "title": "Code Reviews in Open Source Projects : How Do Gender Biases Affect  Participation and Outcomes?",
    "abstract": "Context: Contemporary software development organizations lack diversity and the ratios of women in Free and open-source software (FOSS) communities are even lower than the industry average. Although the results of recent studies hint the existence of biases against women, it is unclear to what extent such biases influence the outcomes of various software development tasks. Aim: We aim to identify whether the outcomes of or participation in code reviews (or pull requests) are influenced by the gender of a developer.. Approach: With this goal, this study includes a total 1010 FOSS projects. We developed six regression models for each of the 14 dataset (i.e., 10 Gerrit based and four Github) to identify if code acceptance, review intervals, and code review participation differ based on the gender and gender neutral profile of a developer. Key findings: Our results find significant gender biases during code acceptance among 13 out of the 14 datasets, with seven seven favoring men and the remaining six favoring women. We also found significant differences between men and women in terms of code review intervals, with women encountering longer delays in three cases and the opposite in seven. Our results indicate reviewer selection as one of the most gender biased aspects among most of the projects, with women having significantly lower code review participation among 11 out of the 14 cases. Since most of the review assignments are based on invitations, this result suggests possible affinity biases among the developers. Conclusion: Though gender bias exists among many projects, direction and amplitude of bias varies based on project size, community and culture. Similar bias mitigation strategies may not work across all communities, as characteristics of biases and their underlying causes differ. ",
    "url": "https://arxiv.org/abs/2210.00139",
    "authors": [
      "Sayma Sultana",
      "Asif Kamal Turzo",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.00162",
    "title": "Diving into Unified Data-Model Sparsity for Class-Imbalanced Graph  Representation Learning",
    "abstract": "Even pruned by the state-of-the-art network compression methods, Graph Neural Networks (GNNs) training upon non-Euclidean graph data often encounters relatively higher time costs, due to its irregular and nasty density properties, compared with data in the regular Euclidean space. Another natural property concomitantly with graph is class-imbalance which cannot be alleviated by the massive graph data while hindering GNNs' generalization. To fully tackle these unpleasant properties, (i) theoretically, we introduce a hypothesis about what extent a subset of the training data can approximate the full dataset's learning effectiveness. The effectiveness is further guaranteed and proved by the gradients' distance between the subset and the full set; (ii) empirically, we discover that during the learning process of a GNN, some samples in the training dataset are informative for providing gradients to update model parameters. Moreover, the informative subset is not fixed during training process. Samples that are informative in the current training epoch may not be so in the next one. We also notice that sparse subnets pruned from a well-trained GNN sometimes forget the information provided by the informative subset, reflected in their poor performances upon the subset. Based on these findings, we develop a unified data-model dynamic sparsity framework named Graph Decantation (GraphDec) to address challenges brought by training upon a massive class-imbalanced graph data. The key idea of GraphDec is to identify the informative subset dynamically during the training process by adopting sparse graph contrastive learning. Extensive experiments on benchmark datasets demonstrate that GraphDec outperforms baselines for graph and node tasks, with respect to classification accuracy and data usage efficiency. ",
    "url": "https://arxiv.org/abs/2210.00162",
    "authors": [
      "Chunhui Zhang",
      "Chao Huang",
      "Yijun Tian",
      "Qianlong Wen",
      "Zhongyu Ouyang",
      "Youhuan Li",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00173",
    "title": "Predictive Inference with Feature Conformal Prediction",
    "abstract": "Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Experiments on various predictive inference tasks corroborate the efficacy of our method. ",
    "url": "https://arxiv.org/abs/2210.00173",
    "authors": [
      "Jiaye Teng",
      "Chuan Wen",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Yang Gao",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00175",
    "title": "Technical Report-IoT Devices Proximity Authentication In Ad Hoc Network  Environment",
    "abstract": "Internet of Things (IoT) is a distributed communication technology system that offers the possibility for physical devices (e.g. vehicles home appliances sensors actuators etc.) known as Things to connect and exchange data more importantly without human interaction. Since IoT plays a significant role in our daily lives we must secure the IoT environment to work effectively. Among the various security requirements authentication to the IoT devices is essential as it is the first step in preventing any negative impact of possible attackers. Using the current IEEE 802.11 infrastructure this paper implements an IoT devices authentication scheme based on something that is in the IoT devices environment (i.e. ambient access points). Data from the broadcast messages (i.e. beacon frame characteristics) are utilized to implement the authentication factor that confirms proximity between two devices in an ad hoc IoT network. ",
    "url": "https://arxiv.org/abs/2210.00175",
    "authors": [
      "Ali Abdullah S. AlQahtani",
      "Hosam Alamleh",
      "Baker Al Smadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00176",
    "title": "A Combinatorial Perspective on the Optimization of Shallow ReLU Networks",
    "abstract": "The NP-hard problem of optimizing a shallow ReLU network can be characterized as a combinatorial search over each training example's activation pattern followed by a constrained convex problem given a fixed set of activation patterns. We explore the implications of this combinatorial aspect of ReLU optimization in this work. We show that it can be naturally modeled via a geometric and combinatoric object known as a zonotope with its vertex set isomorphic to the set of feasible activation patterns. This assists in analysis and provides a foundation for further research. We demonstrate its usefulness when we explore the sensitivity of the optimal loss to perturbations of the training data. Later we discuss methods of zonotope vertex selection and its relevance to optimization. Overparameterization assists in training by making a randomly chosen vertex more likely to contain a good solution. We then introduce a novel polynomial-time vertex selection procedure that provably picks a vertex containing the global optimum using only double the minimum number of parameters required to fit the data. We further introduce a local greedy search heuristic over zonotope vertices and demonstrate that it outperforms gradient descent on underparameterized problems. ",
    "url": "https://arxiv.org/abs/2210.00176",
    "authors": [
      "Michael Matena",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00178",
    "title": "On the tightness of linear relaxation based robustness certification  methods",
    "abstract": "There has been a rapid development and interest in adversarial training and defenses in the machine learning community in the recent years. One line of research focuses on improving the performance and efficiency of adversarial robustness certificates for neural networks \\cite{gowal:19, wong_zico:18, raghunathan:18, WengTowardsFC:18, wong:scalable:18, singh:convex_barrier:19, Huang_etal:19, single-neuron-relax:20, Zhang2020TowardsSA}. While each providing a certification to lower (or upper) bound the true distortion under adversarial attacks via relaxation, less studied was the tightness of relaxation. In this paper, we analyze a family of linear outer approximation based certificate methods via a meta algorithm, IBP-Lin. The aforementioned works often lack quantitative analysis to answer questions such as how does the performance of the certificate method depend on the network configuration and the choice of approximation parameters. Under our framework, we make a first attempt at answering these questions, which reveals that the tightness of linear approximation based certification can depend heavily on the configuration of the trained networks. ",
    "url": "https://arxiv.org/abs/2210.00178",
    "authors": [
      "Cheng Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00181",
    "title": "EAPruning: Evolutionary Pruning for Vision Transformers and CNNs",
    "abstract": "Structured pruning greatly eases the deployment of large neural networks in resource-constrained environments. However, current methods either involve strong domain expertise, require extra hyperparameter tuning, or are restricted only to a specific type of network, which prevents pervasive industrial applications. In this paper, we undertake a simple and effective approach that can be easily applied to both vision transformers and convolutional neural networks. Specifically, we consider pruning as an evolution process of sub-network structures that inherit weights through reconstruction techniques. We achieve a 50% FLOPS reduction for ResNet50 and MobileNetV1, leading to 1.37x and 1.34x speedup respectively. For DeiT-Base, we reach nearly 40% FLOPs reduction and 1.4x speedup. Our code will be made available. ",
    "url": "https://arxiv.org/abs/2210.00181",
    "authors": [
      "Qingyuan Li",
      "Bo Zhang",
      "Xiangxiang Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00213",
    "title": "HyperHawkes: Hypernetwork based Neural Temporal Point Process",
    "abstract": "Temporal point process serves as an essential tool for modeling time-to-event data in continuous time space. Despite having massive amounts of event sequence data from various domains like social media, healthcare etc., real world application of temporal point process faces two major challenges: 1) it is not generalizable to predict events from unseen sequences in dynamic environment 2) they are not capable of thriving in continually evolving environment with minimal supervision while retaining previously learnt knowledge. To tackle these issues, we propose \\textit{HyperHawkes}, a hypernetwork based temporal point process framework which is capable of modeling time of occurrence of events for unseen sequences. Thereby, we solve the problem of zero-shot learning for time-to-event modeling. We also develop a hypernetwork based continually learning temporal point process for continuous modeling of time-to-event sequences with minimal forgetting. In this way, \\textit{HyperHawkes} augments the temporal point process with zero-shot modeling and continual learning capabilities. We demonstrate the application of the proposed framework through our experiments on two real-world datasets. Our results show the efficacy of the proposed approach in terms of predicting future events under zero-shot regime for unseen event sequences. We also show that the proposed model is able to predict sequences continually while retaining information from previous event sequences, hence mitigating catastrophic forgetting for time-to-event data. ",
    "url": "https://arxiv.org/abs/2210.00213",
    "authors": [
      "Manisha Dubey",
      "P.K. Srijith",
      "Maunendra Sankar Desarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00220",
    "title": "A Dual-Attention Learning Network with Word and Sentence Embedding for  Medical Visual Question Answering",
    "abstract": "Research in medical visual question answering (MVQA) can contribute to the development of computeraided diagnosis. MVQA is a task that aims to predict accurate and convincing answers based on given medical images and associated natural language questions. This task requires extracting medical knowledge-rich feature content and making fine-grained understandings of them. Therefore, constructing an effective feature extraction and understanding scheme are keys to modeling. Existing MVQA question extraction schemes mainly focus on word information, ignoring medical information in the text. Meanwhile, some visual and textual feature understanding schemes cannot effectively capture the correlation between regions and keywords for reasonable visual reasoning. In this study, a dual-attention learning network with word and sentence embedding (WSDAN) is proposed. We design a module, transformer with sentence embedding (TSE), to extract a double embedding representation of questions containing keywords and medical information. A dualattention learning (DAL) module consisting of self-attention and guided attention is proposed to model intensive intramodal and intermodal interactions. With multiple DAL modules (DALs), learning visual and textual co-attention can increase the granularity of understanding and improve visual reasoning. Experimental results on the ImageCLEF 2019 VQA-MED (VQA-MED 2019) and VQA-RAD datasets demonstrate that our proposed method outperforms previous state-of-the-art methods. According to the ablation studies and Grad-CAM maps, WSDAN can extract rich textual information and has strong visual reasoning ability. ",
    "url": "https://arxiv.org/abs/2210.00220",
    "authors": [
      "Xiaofei Huang",
      "Hongfang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00221",
    "title": "Motion-inductive Self-supervised Object Discovery in Videos",
    "abstract": "In this paper, we consider the task of unsupervised object discovery in videos. Previous works have shown promising results via processing optical flows to segment objects. However, taking flow as input brings about two drawbacks. First, flow cannot capture sufficient cues when objects remain static or partially occluded. Second, it is challenging to establish temporal coherency from flow-only input, due to the missing texture information. To tackle these limitations, we propose a model for directly processing consecutive RGB frames, and infer the optical flow between any pair of frames using a layered representation, with the opacity channels being treated as the segmentation. Additionally, to enforce object permanence, we apply temporal consistency loss on the inferred masks from randomly-paired frames, which refer to the motions at different paces, and encourage the model to segment the objects even if they may not move at the current time point. Experimentally, we demonstrate superior performance over previous state-of-the-art methods on three public video segmentation datasets (DAVIS2016, SegTrackv2, and FBMS-59), while being computationally efficient by avoiding the overhead of computing optical flow as input. ",
    "url": "https://arxiv.org/abs/2210.00221",
    "authors": [
      "Shuangrui Ding",
      "Weidi Xie",
      "Yabo Chen",
      "Rui Qian",
      "Xiaopeng Zhang",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00222",
    "title": "Solving practical multi-body dynamics problems using a single neural  operator",
    "abstract": "As a fundamental design tool in many engineering disciplines, multi-body dynamics (MBD) models a complex structure with a differential equation group containing multiple physical quantities. Engineers must constantly adjust structures at the design stage, which requires a highly efficient solver. The rise of deep learning technologies has offered new perspectives on MBD. Unfortunately, existing black-box models suffer from poor accuracy and robustness, while the advanced methodologies of single-output operator regression cannot deal with multiple quantities simultaneously. To address these challenges, we propose PINO-MBD, a deep learning framework for solving practical MBD problems based on the theory of physics-informed neural operator (PINO). PINO-MBD uses a single network for all quantities in a multi-body system, instead of training dozens, or even hundreds of networks as in the existing literature. We demonstrate the flexibility and feasibility of PINO-MBD for one toy example and two practical applications: vehicle-track coupled dynamics (VTCD) and reliability analysis of a four-storey building. The performance of VTCD indicates that our framework outperforms existing software and machine learning-based methods in terms of efficiency and precision, respectively. For the reliability analysis, PINO-MBD can provide higher-resolution results in less than a quarter of the time incurred when using the probability density evolution method (PDEM). This framework integrates mechanics and deep learning technologies and may reveal a new concept for MBD and probabilistic engineering. ",
    "url": "https://arxiv.org/abs/2210.00222",
    "authors": [
      "Wenhao Ding",
      "Qing He",
      "Hanghang Tong",
      "Qingjing Wang",
      "Ping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00226",
    "title": "Towards Understanding and Mitigating Dimensional Collapse in  Heterogeneous Federated Learning",
    "abstract": "Federated learning aims to train models collaboratively across different clients without the sharing of data for privacy considerations. However, one major challenge for this learning paradigm is the {\\em data heterogeneity} problem, which refers to the discrepancies between the local data distributions among various clients. To tackle this problem, we first study how data heterogeneity affects the representations of the globally aggregated models. Interestingly, we find that heterogeneous data results in the global model suffering from severe {\\em dimensional collapse}, in which representations tend to reside in a lower-dimensional space instead of the ambient space. Moreover, we observe a similar phenomenon on models locally trained on each client and deduce that the dimensional collapse on the global model is inherited from local models. In addition, we theoretically analyze the gradient flow dynamics to shed light on how data heterogeneity result in dimensional collapse for local models. To remedy this problem caused by the data heterogeneity, we propose {\\sc FedDecorr}, a novel method that can effectively mitigate dimensional collapse in federated learning. Specifically, {\\sc FedDecorr} applies a regularization term during local training that encourages different dimensions of representations to be uncorrelated. {\\sc FedDecorr}, which is implementation-friendly and computationally-efficient, yields consistent improvements over baselines on standard benchmark datasets. Code will be released. ",
    "url": "https://arxiv.org/abs/2210.00226",
    "authors": [
      "Yujun Shi",
      "Jian Liang",
      "Wenqing Zhang",
      "Vincent Y. F. Tan",
      "Song Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00248",
    "title": "Heterogeneous Graph Contrastive Multi-view Learning",
    "abstract": "Inspired by the success of contrastive learning (CL) in computer vision and natural language processing, graph contrastive learning (GCL) has been developed to learn discriminative node representations on graph datasets. However, the development of GCL on Heterogeneous Information Networks (HINs) is still in the infant stage. For example, it is unclear how to augment the HINs without substantially altering the underlying semantics, and how to design the contrastive objective to fully capture the rich semantics. Moreover, early investigations demonstrate that CL suffers from sampling bias, whereas conventional debiasing techniques are empirically shown to be inadequate for GCL. How to mitigate the sampling bias for heterogeneous GCL is another important problem. To address the aforementioned challenges, we propose a novel Heterogeneous Graph Contrastive Multi-view Learning (HGCML) model. In particular, we use metapaths as the augmentation to generate multiple subgraphs as multi-views, and propose a contrastive objective to maximize the mutual information between any pairs of metapath-induced views. To alleviate the sampling bias, we further propose a positive sampling strategy to explicitly select positives for each node via jointly considering semantic and structural information preserved on each metapath view. Extensive experiments demonstrate HGCML consistently outperforms state-of-the-art baselines on five real-world benchmark datasets. ",
    "url": "https://arxiv.org/abs/2210.00248",
    "authors": [
      "Zehong Wang",
      "Qi Li",
      "Donghua Yu",
      "Xiaolong Han",
      "Xiao-Zhi Gao",
      "Shigen Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00262",
    "title": "Frequency Estimation of Evolving Data Under Local Differential Privacy",
    "abstract": "Collecting and analyzing evolving longitudinal data has become a common practice. One possible approach to protect the users' privacy in this context is to use local differential privacy (LDP) protocols, which ensure the privacy protection of all users even in the case of a breach or data misuse. Existing LDP data collection protocols such as Google's RAPPOR and Microsoft's dBitFlipPM have longitudinal privacy linear to the domain size k, which can be excessive for large domains, such as Internet domains. To solve this issue, in this paper we introduce a new LDP data collection protocol for longitudinal frequency monitoring named LOngitudinal LOcal HAshing (LOLOHA) with formal privacy guarantees. In addition, the privacy-utility trade-off of our protocol is only linear with respect to a reduced domain size 2<=g<<k. LOLOHA combines a domain reduction approach via local hashing with double randomization to minimize the privacy leakage incurred by data updates. As demonstrated by our theoretical analysis as well as our experimental evaluation, LOLOHA achieves a utility competitive to current state-of-the-art protocols, while substantially minimizing the longitudinal privacy budget consumption by up to k/g orders of magnitude. ",
    "url": "https://arxiv.org/abs/2210.00262",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Carlos Pinz\u00f3n",
      "Catuscia Palamidessi",
      "S\u00e9bastien Gambs"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00270",
    "title": "ML for Location Prediction Using RSSI On WiFi 2.4 GHZ Frequency Band",
    "abstract": "For decades, the determination of an objects location has been implemented utilizing different technologies. Despite GPS (Global Positioning System) provides a scalable efficient and cost effective location services however the satellite emitted signals cannot be exploited indoor to effectively determine the location. In contrast to GPS which is a cost effective localization technology for outdoor locations several technologies have been studied for indoor localization. These include Wireless Fidelity (Wi-Fi) Bluetooth Low Energy (BLE) and Received Signal Strength Indicator (RSSI) etc. This paper presents an enhanced method of using RSSI as a mean to determine an objects location by applying some Machine Learning (ML) concepts. The binary classification is defined by considering the adjacency of the coordinates denoting objects locations. The proposed features were tested empirically via multiple classifiers that achieved a maximum of 96 percent accuracy. ",
    "url": "https://arxiv.org/abs/2210.00270",
    "authors": [
      "Ali Abdullah S. AlQahtani",
      "Nazim Choudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00272",
    "title": "FINDE: Neural Differential Equations for Finding and Preserving  Invariant Quantities",
    "abstract": "Many real-world dynamical systems are associated with first integrals (a.k.a. invariant quantities), which are quantities that remain unchanged over time. The discovery and understanding of first integrals are fundamental and important topics both in the natural sciences and in industrial applications. First integrals arise from the conservation laws of system energy, momentum, and mass, and from constraints on states; these are typically related to specific geometric structures of the governing equations. Existing neural networks designed to ensure such first integrals have shown excellent accuracy in modeling from data. However, these models incorporate the underlying structures, and in most situations where neural networks learn unknown systems, these structures are also unknown. This limitation needs to be overcome for scientific discovery and modeling of unknown systems. To this end, we propose first integral-preserving neural differential equation (FINDE). By leveraging the projection method and the discrete gradient method, FINDE finds and preserves first integrals from data, even in the absence of prior knowledge about underlying structures. Experimental results demonstrate that FINDE can predict future states of target systems much longer and find various quantities consistent with well-known first integrals in a unified manner. ",
    "url": "https://arxiv.org/abs/2210.00272",
    "authors": [
      "Takashi Matsubara",
      "Takaharu Yaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.00283",
    "title": "Swift Markov Logic for Probabilistic Reasoning on Knowledge Graphs",
    "abstract": "We provide a framework for probabilistic reasoning in Vadalog-based Knowledge Graphs (KGs), satisfying the requirements of ontological reasoning: full recursion, powerful existential quantification, expression of inductive definitions. Vadalog is a Knowledge Representation and Reasoning (KRR) language based on Warded Datalog+/-, a logical core language of existential rules, with a good balance between computational complexity and expressive power. Handling uncertainty is essential for reasoning with KGs. Yet Vadalog and Warded Datalog+/- are not covered by the existing probabilistic logic programming and statistical relational learning approaches for several reasons, including insufficient support for recursion with existential quantification, and the impossibility to express inductive definitions. In this work, we introduce Soft Vadalog, a probabilistic extension to Vadalog, satisfying these desiderata. A Soft Vadalog program induces what we call a Probabilistic Knowledge Graph (PKG), which consists of a probability distribution on a network of chase instances, structures obtained by grounding the rules over a database using the chase procedure. We exploit PKGs for probabilistic marginal inference. We discuss the theory and present MCMC-chase, a Monte Carlo method to use Soft Vadalog in practice. We apply our framework to solve data management and industrial problems, and experimentally evaluate it in the Vadalog system. Under consideration in Theory and Practice of Logic Programming (TPLP). ",
    "url": "https://arxiv.org/abs/2210.00283",
    "authors": [
      "Luigi Bellomarini",
      "Eleonora Laurenza",
      "Emanuel Sallinger",
      "Evgeny Sherkhonov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00286",
    "title": "NeuroEvo: A Cloud-based Platform for Automated Design and Training of  Neural Networks using Evolutionary and Particle Swarm Algorithms",
    "abstract": "Evolutionary algorithms (EAs) provide unique advantages for optimizing neural networks in complex search spaces. This paper introduces a new web platform, NeuroEvo (neuroevo.io), that allows users to interactively design and train neural network classifiers using evolutionary and particle swarm algorithms. The classification problem and training data are provided by the user and, upon completion of the training process, the best classifier is made available to download and implement in Python, Java, and JavaScript. NeuroEvo is a cloud-based application that leverages GPU parallelization to improve the speed with which the independent evolutionary steps, such as mutation, crossover, and fitness evaluation, are executed across the population. This paper outlines the training algorithms and opportunities for users to specify design decisions and hyperparameter settings. The algorithms described in this paper are also made available as a Python package, neuroevo (PyPI: https://pypi.org/project/neuroevo/). ",
    "url": "https://arxiv.org/abs/2210.00286",
    "authors": [
      "Philip Schroeder"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00289",
    "title": "Robust Power Allocation and Linear Precoding for Cell-Free and  Multi-Cell Massive MIMO Systems",
    "abstract": "Multi-Cell (MC) systems are present in mobile network operations from the first generation to the fifth generation of wireless networks, and considers the signals of all users to a base station (BS) centered in a cell. Cell-Free (CF) systems works with a large number of distributed antennas serving users at the same time. In this context, Multiple-input multiple-output (MIMO) techniques are used in both topologies and result in performance gains and interference reduction. In order to achieve the benefits mentioned, proper precoder design and power allocation techniques are required in the downlink (DL). In general, DL schemes assume perfect channel state information at the transmitter (CSIT), which is not realistic. This paper studies MC and CF with MIMO systems equipped with linear precoders in the DL and proposes an adaptive algorithm to allocate power in the presence of imperfect CSIT. The proposed robust adaptive power allocation outperforms standard adaptive and uniform power allocation. Simulations also compare the performance of both systems frameworks using minimum mean-square error (MMSE) precoders with robust adaptive power allocation and adaptive power allocation. ",
    "url": "https://arxiv.org/abs/2210.00289",
    "authors": [
      "E. F. de Almeida",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.00292",
    "title": "DeltaBound Attack: Efficient decision-based attack in low queries regime",
    "abstract": "Deep neural networks and other machine learning systems, despite being extremely powerful and able to make predictions with high accuracy, are vulnerable to adversarial attacks. We proposed the DeltaBound attack: a novel, powerful attack in the hard-label setting with $\\ell_2$ norm bounded perturbations. In this scenario, the attacker has only access to the top-1 predicted label of the model and can be therefore applied to real-world settings such as remote API. This is a complex problem since the attacker has very little information about the model. Consequently, most of the other techniques present in the literature require a massive amount of queries for attacking a single example. Oppositely, this work mainly focuses on the evaluation of attack's power in the low queries regime $\\leq 1000$ queries) with $\\ell_2$ norm in the hard-label settings. We find that the DeltaBound attack performs as well and sometimes better than current state-of-the-art attacks while remaining competitive across different kinds of models. Moreover, we evaluate our method against not only deep neural networks, but also non-deep learning models, such as Gradient Boosting Decision Trees and Multinomial Naive Bayes. ",
    "url": "https://arxiv.org/abs/2210.00292",
    "authors": [
      "Lorenzo Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00294",
    "title": "Gait-based Age Group Classification with Adaptive Graph Neural Network",
    "abstract": "Deep learning techniques have recently been utilized for model-free age-associated gait feature extraction. However, acquiring model-free gait demands accurate pre-processing such as background subtraction, which is non-trivial in unconstrained environments. On the other hand, model-based gait can be obtained without background subtraction and is less affected by covariates. For model-based gait-based age group classification problems, present works rely solely on handcrafted features, where feature extraction is tedious and requires domain expertise. This paper proposes a deep learning approach to extract age-associated features from model-based gait for age group classification. Specifically, we first develop an unconstrained gait dataset called Multimedia University Gait Age and Gender dataset (MMU GAG). Next, the body joint coordinates are determined via pose estimation algorithms and represented as compact gait graphs via a novel part aggregation scheme. Then, a Part-AdaptIve Residual Graph Convolutional Neural Network (PairGCN) is designed for age-associated feature learning. Experiments suggest that PairGCN features are far more informative than handcrafted features, yielding up to 99% accuracy for classifying subjects as a child, adult, or senior in the MMU GAG dataset. ",
    "url": "https://arxiv.org/abs/2210.00294",
    "authors": [
      "Timilehin B. Aderinola",
      "Tee Connie",
      "Thian Song Ong",
      "Andrew Beng Jin Teoh",
      "Michael Kah Ong Goh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00298",
    "title": "An Ensemble of Convolutional Neural Networks to Detect Foliar Diseases  in Apple Plants",
    "abstract": "Apple diseases, if not diagnosed early, can lead to massive resource loss and pose a serious threat to humans and animals who consume the infected apples. Hence, it is critical to diagnose these diseases early in order to manage plant health and minimize the risks associated with them. However, the conventional approach of monitoring plant diseases entails manual scouting and analyzing the features, texture, color, and shape of the plant leaves, resulting in delayed diagnosis and misjudgments. Our work proposes an ensembled system of Xception, InceptionResNet, and MobileNet architectures to detect 5 different types of apple plant diseases. The model has been trained on the publicly available Plant Pathology 2021 dataset and can classify multiple diseases in a given plant leaf. The system has achieved outstanding results in multi-class and multi-label classification and can be used in a real-time setting to monitor large apple plantations to aid the farmers manage their yields effectively. ",
    "url": "https://arxiv.org/abs/2210.00298",
    "authors": [
      "Kush Vora",
      "Dishant Padalia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00299",
    "title": "Federated Representation Learning via Maximal Coding Rate Reduction",
    "abstract": "We propose a federated methodology to learn low-dimensional representations from a dataset that is distributed among several clients. In particular, we move away from the commonly-used cross-entropy loss in federated learning, and seek to learn shared low-dimensional representations of the data in a decentralized manner via the principle of maximal coding rate reduction (MCR2). Our proposed method, which we refer to as FLOW, utilizes MCR2 as the objective of choice, hence resulting in representations that are both between-class discriminative and within-class compressible. We theoretically show that our distributed algorithm achieves a first-order stationary point. Moreover, we demonstrate, via numerical experiments, the utility of the learned low-dimensional representations. ",
    "url": "https://arxiv.org/abs/2210.00299",
    "authors": [
      "Juan Cervino",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.00305",
    "title": "PromptKG: A Prompt Learning Framework for Knowledge Graph Representation  Learning and Application",
    "abstract": "Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph structure and text-rich entity/relation information. KG representation models should consider graph structures and text semantics, but no comprehensive open-sourced framework is mainly designed for KG regarding informative text description. In this paper, we present PromptKG, a prompt learning framework for KG representation learning and application that equips the cutting-edge text-based methods, integrates a new prompt learning model and supports various tasks (e.g., knowledge graph completion, question answering, recommendation, and knowledge probing). PromptKG is publicly open-sourced at https://github.com/zjunlp/PromptKG with long-term technical support. ",
    "url": "https://arxiv.org/abs/2210.00305",
    "authors": [
      "Xin Xie",
      "Zhoubo Li",
      "Xiaohan Wang",
      "Shumin Deng",
      "Feiyu Xiong",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00310",
    "title": "Clustering for directed graphs using parametrized random walk diffusion  kernels",
    "abstract": "Clustering based on the random walk operator has been proven effective for undirected graphs, but its generalization to directed graphs (digraphs) is much more challenging. Although the random walk operator is well-defined for digraphs, in most cases such graphs are not strongly connected, and hence the associated random walks are not irreducible, which is a crucial property for clustering that exists naturally in the undirected setting. To remedy this, the usual workaround is to either naively symmetrize the adjacency matrix or to replace the natural random walk operator by the teleporting random walk operator, but this can lead to the loss of valuable information carried by edge directionality. In this paper, we introduce a new clustering framework, the Parametrized Random Walk Diffusion Kernel Clustering (P-RWDKC), which is suitable for handling both directed and undirected graphs. Our framework is based on the diffusion geometry and the generalized spectral clustering framework. Accordingly, we propose an algorithm that automatically reveals the cluster structure at a given scale, by considering the random walk dynamics associated with a parametrized kernel operator, and by estimating its critical diffusion time. Experiments on $K$-NN graphs constructed from real-world datasets and real-world graphs show that our clustering approach performs well in all tested cases, and outperforms existing approaches in most of them. ",
    "url": "https://arxiv.org/abs/2210.00310",
    "authors": [
      "Harry Sevi",
      "Matthieu Jonckheere",
      "Argyris Kalogeratos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00312",
    "title": "Multimodal Analogical Reasoning over Knowledge Graphs",
    "abstract": "Analogical reasoning is fundamental to human cognition and holds an important place in various fields. However, previous studies mainly focus on single-modal analogical reasoning and ignore taking advantage of structure knowledge. Notably, the research in cognitive psychology has demonstrated that information from multimodal sources always brings more powerful cognitive transfer than single modality sources. To this end, we introduce the new task of multimodal analogical reasoning over knowledge graphs, which requires multimodal reasoning ability with the help of background knowledge. Specifically, we construct a Multimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph MarKG. We evaluate with multimodal knowledge graph embedding and pre-trained Transformer baselines, illustrating the potential challenges of the proposed task. We further propose a novel model-agnostic Multimodal analogical reasoning framework with Transformer (MarT) motivated by the structure mapping theory, which can obtain better performance. ",
    "url": "https://arxiv.org/abs/2210.00312",
    "authors": [
      "Ningyu Zhang",
      "Lei Li",
      "Xiang Chen",
      "Xiaozhuan Liang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00313",
    "title": "CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family",
    "abstract": "Polar codes are widely used state-of-the-art codes for reliable communication that have recently been included in the 5th generation wireless standards (5G). However, there remains room for the design of polar decoders that are both efficient and reliable in the short blocklength regime. Motivated by recent successes of data-driven channel decoders, we introduce a novel $\\textbf{C}$ur$\\textbf{RI}$culum based $\\textbf{S}$equential neural decoder for $\\textbf{P}$olar codes (CRISP). We design a principled curriculum, guided by information-theoretic insights, to train CRISP and show that it outperforms the successive-cancellation (SC) decoder and attains near-optimal reliability performance on the Polar(16,32) and Polar(22, 64) codes. The choice of the proposed curriculum is critical in achieving the accuracy gains of CRISP, as we show by comparing against other curricula. More notably, CRISP can be readily extended to Polarization-Adjusted-Convolutional (PAC) codes, where existing SC decoders are significantly less reliable. To the best of our knowledge, CRISP constructs the first data-driven decoder for PAC codes and attains near-optimal performance on the PAC(16, 32) code. ",
    "url": "https://arxiv.org/abs/2210.00313",
    "authors": [
      "S Ashwin Hebbar",
      "Viraj Nadkarni",
      "Ashok Vardhan Makkuva",
      "Suma Bhat",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00319",
    "title": "PathFinder: Discovering Decision Pathways in Deep Neural Networks",
    "abstract": "Explainability is becoming an increasingly important topic for deep neural networks. Though the operation in convolutional layers is easier to understand, processing becomes opaque in fully-connected layers. The basic idea in our work is that each instance, as it flows through the layers, causes a different activation pattern in the hidden layers and in our Paths methodology, we cluster these activation vectors for each hidden layer and then see how the clusters in successive layers connect to one another as activation flows from the input layer to the output. We find that instances of the same class follow a small number of cluster sequences over the layers, which we name ``decision paths.\" Such paths explain how classification decisions are typically made, and also help us determine outliers that follow unusual paths. We also propose using the Sankey diagram to visualize such pathways. We validate our method with experiments on two feed-forward networks trained on MNIST and CELEB data sets, and one recurrent network trained on PenDigits. ",
    "url": "https://arxiv.org/abs/2210.00319",
    "authors": [
      "Ozan \u0130rsoy",
      "Ethem Alpayd\u0131n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00325",
    "title": "Privacy-preserving Decentralized Federated Learning over Time-varying  Communication Graph",
    "abstract": "Establishing how a set of learners can provide privacy-preserving federated learning in a fully decentralized (peer-to-peer, no coordinator) manner is an open problem. We propose the first privacy-preserving consensus-based algorithm for the distributed learners to achieve decentralized global model aggregation in an environment of high mobility, where the communication graph between the learners may vary between successive rounds of model aggregation. In particular, in each round of global model aggregation, the Metropolis-Hastings method is applied to update the weighted adjacency matrix based on the current communication topology. In addition, the Shamir's secret sharing scheme is integrated to facilitate privacy in reaching consensus of the global model. The paper establishes the correctness and privacy properties of the proposed algorithm. The computational efficiency is evaluated by a simulation built on a federated learning framework with a real-word dataset. ",
    "url": "https://arxiv.org/abs/2210.00325",
    "authors": [
      "Yang Lu",
      "Zhengxin Yu",
      "Neeraj Suri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.00328",
    "title": "CodeDSI: Differentiable Code Search",
    "abstract": "Reimplementing solutions to previously solved software engineering problems is not only inefficient but also introduces inadequate and error-prone code. Many existing methods achieve impressive performance on this issue by using autoregressive text-generation models trained on code. However, these methods are not without their flaws. The generated code from these models can be buggy, lack documentation, and introduce vulnerabilities that may go unnoticed by developers. An alternative to code generation -- neural code search -- is a field of machine learning where a model takes natural language queries as input and, in turn, relevant code samples from a database are returned. Due to the nature of this pre-existing database, code samples can be documented, tested, licensed, and checked for vulnerabilities before being used by developers in production. In this work, we present CodeDSI, an end-to-end unified approach to code search. CodeDSI is trained to directly map natural language queries to their respective code samples, which can be retrieved later. In an effort to improve the performance of code search, we have investigated docid representation strategies, impact of tokenization on docid structure, and dataset sizes on overall code search performance. Our results demonstrate CodeDSI strong performance, exceeding conventional robust baselines by 2-6% across varying dataset sizes. ",
    "url": "https://arxiv.org/abs/2210.00328",
    "authors": [
      "Usama Nadeem",
      "Noah Ziems",
      "Shaoen Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.00330",
    "title": "Social VR and multi-party holographic communications: Opportunities,  Challenges and Impact in the Education and Training Sectors",
    "abstract": "Technological advances can bring many benefits to our daily lives, and this includes the education and training sectors. In the last years, online education, teaching and training models are becoming increasingly adopted, in part influenced by major circumstances like the pandemic. The use of videoconferencing tools in such sectors has become fundamental, but recent research has shown their multiple limitations in terms of relevant aspects, like comfort, interaction quality, situational awareness, (co-)presence, etc. This study elaborates on a new communication, interaction and collaboration medium that becomes a promising candidate to overcome such limitations, by adopting immersive technologies: Social Virtual Reality (VR). First, this article provides a comprehensive review of studies having provided initial evidence on (potential) benefits provided by Social VR in relevant use cases related to education, such as online classes, training and co-design activities, virtual conferences and interactive visits to virtual spaces, many of them including comparisons with classical tools like 2D conferencing. Likewise, the potential benefits of integrating realistic and volumetric users' representations to enable multi-party holographic communications in Social VR is also discussed. Next, this article identifies and elaborates on key limitations of existing studies in this field, including both technological and methodological aspects. Finally, it discusses key remaining challenges to be addressed to fully exploit the potential of Social VR in the education sector. ",
    "url": "https://arxiv.org/abs/2210.00330",
    "authors": [
      "Mario Montagud",
      "Gianluca Cernigliaro",
      "Miguel Arevalillo-Herr\u00e1ez",
      "Miguel Garc\u00eda-Pineda",
      "Jaume Segura-Garcia",
      "Sergi Fern\u00e1ndez"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.00339",
    "title": "Longitudinal Sentiment Analyses for Radicalization Research:  Intertemporal Dynamics on Social Media Platforms and their Implications",
    "abstract": "This discussion paper demonstrates how longitudinal sentiment analyses can depict intertemporal dynamics on social media platforms, what challenges are inherent and how further research could benefit from a longitudinal perspective. Furthermore and since tools for sentiment analyses shall simplify and accelerate the analytical process regarding qualitative data at acceptable inter-rater reliability, their applicability in the context of radicalization research will be examined regarding the Tweets collected on January 6th 2021, the day of the storming of the U.S. Capitol in Washington. Therefore, a total of 49,350 Tweets will be analyzed evenly distributed within three different sequences: before, during and after the U.S. Capitol in Washington was stormed. These sequences highlight the intertemporal dynamics within comments on social media platforms as well as the possible benefits of a longitudinal perspective when using conditional means and conditional variances. Limitations regarding the identification of supporters of such events and associated hate speech as well as common application errors will be demonstrated as well. As a result, only under certain conditions a longitudinal sentiment analysis can increase the accuracy of evidence based predictions in the context of radicalization research. ",
    "url": "https://arxiv.org/abs/2210.00339",
    "authors": [
      "Dennis Klinkhammer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.00350",
    "title": "Zero-Shot Policy Transfer with Disentangled Task Representation of  Meta-Reinforcement Learning",
    "abstract": "Humans are capable of abstracting various tasks as different combinations of multiple attributes. This perspective of compositionality is vital for human rapid learning and adaption since previous experiences from related tasks can be combined to generalize across novel compositional settings. In this work, we aim to achieve zero-shot policy generalization of Reinforcement Learning (RL) agents by leveraging the task compositionality. Our proposed method is a meta- RL algorithm with disentangled task representation, explicitly encoding different aspects of the tasks. Policy generalization is then performed by inferring unseen compositional task representations via the obtained disentanglement without extra exploration. The evaluation is conducted on three simulated tasks and a challenging real-world robotic insertion task. Experimental results demonstrate that our proposed method achieves policy generalization to unseen compositional tasks in a zero-shot manner. ",
    "url": "https://arxiv.org/abs/2210.00350",
    "authors": [
      "Zheng Wu",
      "Yichen Xie",
      "Wenzhao Lian",
      "Changhao Wang",
      "Yanjiang Guo",
      "Jianyu Chen",
      "Stefan Schaal",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00356",
    "title": "Social and environmental impact of recent developments in machine  learning on biology and chemistry research",
    "abstract": "Potential societal and environmental effects such as the rapidly increasing resource use and the associated environmental impact, reproducibility issues, and exclusivity, the privatization of ML research leading to a public research brain-drain, a narrowing of the research effort caused by a focus on deep learning, and the introduction of biases through a lack of sociodemographic diversity in data and personnel caused by recent developments in machine learning are a current topic of discussion and scientific publications. However, these discussions and publications focus mainly on computer science-adjacent fields, including computer vision and natural language processing or basic ML research. Using bibliometric analysis of the complete and full-text analysis of the open-access literature, we show that the same observations can be made for applied machine learning in chemistry and biology. These developments can potentially affect basic and applied research, such as drug discovery and development, beyond the known issue of biased data sets. ",
    "url": "https://arxiv.org/abs/2210.00356",
    "authors": [
      "Daniel Probst"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00361",
    "title": "Evaluation of Pre-Trained CNN Models for Geographic Fake Image Detection",
    "abstract": "Thanks to the remarkable advances in generative adversarial networks (GANs), it is becoming increasingly easy to generate/manipulate images. The existing works have mainly focused on deepfake in face images and videos. However, we are currently witnessing the emergence of fake satellite images, which can be misleading or even threatening to national security. Consequently, there is an urgent need to develop detection methods capable of distinguishing between real and fake satellite images. To advance the field, in this paper, we explore the suitability of several convolutional neural network (CNN) architectures for fake satellite image detection. Specifically, we benchmark four CNN models by conducting extensive experiments to evaluate their performance and robustness against various image distortions. This work allows the establishment of new baselines and may be useful for the development of CNN-based methods for fake satellite image detection. ",
    "url": "https://arxiv.org/abs/2210.00361",
    "authors": [
      "Sid Ahmed Fezza",
      "Mohammed Yasser Ouis",
      "Bachir Kaddar",
      "Wassim Hamidouche",
      "Abdenour Hadid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00368",
    "title": "Parameter-varying neural ordinary differential equations with  partition-of-unity networks",
    "abstract": "In this study, we propose parameter-varying neural ordinary differential equations (NODEs) where the evolution of model parameters is represented by partition-of-unity networks (POUNets), a mixture of experts architecture. The proposed variant of NODEs, synthesized with POUNets, learn a meshfree partition of space and represent the evolution of ODE parameters using sets of polynomials associated to each partition. We demonstrate the effectiveness of the proposed method for three important tasks: data-driven dynamics modeling of (1) hybrid systems, (2) switching linear dynamical systems, and (3) latent dynamics for dynamical systems with varying external forcing. ",
    "url": "https://arxiv.org/abs/2210.00368",
    "authors": [
      "Kookjin Lee",
      "Nathaniel Trask"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00379",
    "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review",
    "abstract": "Neural Radiance Field (NeRF), a new novel view synthesis with implicit scene representation has taken the field of Computer Vision by storm. As a novel view synthesis and 3D reconstruction method, NeRF models find applications in robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, and more. Since the original paper by Mildenhall et al., more than 250 preprints were published, with more than 100 eventually being accepted in tier one Computer Vision Conferences. Given NeRF popularity and the current interest in this research area, we believe it necessary to compile a comprehensive survey of NeRF papers from the past two years, which we organized into both architecture, and application based taxonomies. We also provide an introduction to the theory of NeRF based novel view synthesis, and a benchmark comparison of the performance and speed of key NeRF models. By creating this survey, we hope to introduce new researchers to NeRF, provide a helpful reference for influential works in this field, as well as motivate future research directions with our discussion section. ",
    "url": "https://arxiv.org/abs/2210.00379",
    "authors": [
      "Kyle Gao",
      "Yina Gao",
      "Hongjie He",
      "Denning Lu",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00380",
    "title": "Causal Knowledge Transfer from Task Affinity",
    "abstract": "Recent developments in deep representation models through counterfactual balancing have led to a promising framework for estimating Individual Treatment Effects (ITEs) that are essential to causal inference in the Neyman-Rubin potential outcomes framework. While Randomized Control Trials are vital to understanding causal effects, they are sometimes infeasible, costly, or unethical to conduct. Motivated by these potential obstacles to data acquisition, we focus on transferring the causal knowledge acquired in prior experiments to new scenarios for which only limited data is available. To this end, we first observe that the absolute values of ITEs are invariant under the action of the symmetric group on the labels of treatments. Given this invariance, we propose a symmetrized task distance for calculating the similarity of a target scenario with those encountered before. The aforementioned task distance is then used to transfer causal knowledge from the closest of all the available previously learned tasks to the target scenario. We provide upper bounds on the counterfactual loss and ITE error of the target task indicating the transferability of causal knowledge. Empirical studies are provided for various real-world, semi-synthetic, and synthetic datasets demonstrating that the proposed symmetrized task distance is strongly related to the estimation of the counterfactual loss. Numerical results indicate that transferring causal knowledge reduces the amount of required data by up to 95% when compared to training from scratch. These results reveal the promise of our method when applied to important albeit challenging real-world scenarios such as transferring the knowledge of treatment effects (e.g., medicine, social policy, personal training, etc.) studied on a population to other groups absent in the study. ",
    "url": "https://arxiv.org/abs/2210.00380",
    "authors": [
      "Ahmed Aloui",
      "Juncheng Dong",
      "Cat P. Le",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00405",
    "title": "Basic Binary Convolution Unit for Binarized Image Restoration Network",
    "abstract": "Lighter and faster image restoration (IR) models are crucial for the deployment on resource-limited devices. Binary neural network (BNN), one of the most promising model compression methods, can dramatically reduce the computations and parameters of full-precision convolutional neural networks (CNN). However, there are different properties between BNN and full-precision CNN, and we can hardly use the experience of designing CNN to develop BNN. In this study, we reconsider components in binary convolution, such as residual connection, BatchNorm, activation function, and structure, for IR tasks. We conduct systematic analyses to explain each component's role in binary convolution and discuss the pitfalls. Specifically, we find that residual connection can reduce the information loss caused by binarization; BatchNorm can solve the value range gap between residual connection and binary convolution; The position of the activation function dramatically affects the performance of BNN. Based on our findings and analyses, we design a simple yet efficient basic binary convolution unit (BBCU). Furthermore, we divide IR networks into four parts and specially design variants of BBCU for each part to explore the benefit of binarizing these parts. We conduct experiments on different IR tasks, and our BBCU significantly outperforms other BNNs and lightweight models, which shows that BBCU can serve as a basic unit for binarized IR networks. All codes and models will be released. ",
    "url": "https://arxiv.org/abs/2210.00405",
    "authors": [
      "Bin Xia",
      "Yulun Zhang",
      "Yitong Wang",
      "Yapeng Tian",
      "Wenming Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.00411",
    "title": "Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening  Problem",
    "abstract": "Self-supervised monocular depth estimation (MDE) models universally suffer from the notorious edge-fattening issue. Triplet loss, popular for metric learning, has made a great success in many computer vision tasks. In this paper, we redesign the patch-based triplet loss in MDE to alleviate the ubiquitous edge-fattening issue. We show two drawbacks of the raw triplet loss in MDE and demonstrate our problem-driven redesigns. First, we present a min. operator based strategy applied to all negative samples, to prevent well-performing negatives sheltering the error of edge-fattening negatives. Second, we split the anchor-positive distance and anchor-negative distance from within the original triplet, which directly optimizes the positives without any mutual effect with the negatives. Extensive experiments show the combination of these two small redesigns can achieve unprecedented results: Our powerful and versatile triplet loss not only makes our model outperform all previous SoTA by a large margin, but also provides substantial performance boosts to a large number of existing models, while introducing no extra inference computation at all. ",
    "url": "https://arxiv.org/abs/2210.00411",
    "authors": [
      "Xingyu Chen",
      "Ruonan Zhang",
      "Ji Jiang",
      "Yan Wang",
      "Ge Li",
      "Thomas H. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00415",
    "title": "Metric Distribution to Vector: Constructing Data Representation via  Broad-Scale Discrepancies",
    "abstract": "Graph embedding provides a feasible methodology to conduct pattern classification for graph-structured data by mapping each data into the vectorial space. Various pioneering works are essentially coding method that concentrates on a vectorial representation about the inner properties of a graph in terms of the topological constitution, node attributions, link relations, etc. However, the classification for each targeted data is a qualitative issue based on understanding the overall discrepancies within the dataset scale. From the statistical point of view, these discrepancies manifest a metric distribution over the dataset scale if the distance metric is adopted to measure the pairwise similarity or dissimilarity. Therefore, we present a novel embedding strategy named $\\mathbf{MetricDistribution2vec}$ to extract such distribution characteristics into the vectorial representation for each data. We demonstrate the application and effectiveness of our representation method in the supervised prediction tasks on extensive real-world structural graph datasets. The results have gained some unexpected increases compared with a surge of baselines on all the datasets, even if we take the lightweight models as classifiers. Moreover, the proposed methods also conducted experiments in Few-Shot classification scenarios, and the results still show attractive discrimination in rare training samples based inference. ",
    "url": "https://arxiv.org/abs/2210.00415",
    "authors": [
      "Xue Liu",
      "Dan Sun",
      "Xiaobo Cao",
      "Hao Ye",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00418",
    "title": "Subspace Learning for Feature Selection via Rank Revealing QR  Factorization: Unsupervised and Hybrid Approaches with Non-negative Matrix  Factorization and Evolutionary Algorithm",
    "abstract": "The selection of most informative and discriminative features from high-dimensional data has been noticed as an important topic in machine learning and data engineering. Using matrix factorization-based techniques such as nonnegative matrix factorization for feature selection has emerged as a hot topic in feature selection. The main goal of feature selection using matrix factorization is to extract a subspace which approximates the original space but in a lower dimension. In this study, rank revealing QR (RRQR) factorization, which is computationally cheaper than singular value decomposition (SVD), is leveraged in obtaining the most informative features as a novel unsupervised feature selection technique. This technique uses the permutation matrix of QR for feature selection which is a unique property to this factorization method. Moreover, QR factorization is embedded into non-negative matrix factorization (NMF) objective function as a new unsupervised feature selection method. Lastly, a hybrid feature selection algorithm is proposed by coupling RRQR, as a filter-based technique, and a Genetic algorithm as a wrapper-based technique. In this method, redundant features are removed using RRQR factorization and the most discriminative subset of features are selected using the Genetic algorithm. The proposed algorithm shows to be dependable and robust when compared against state-of-the-art feature selection algorithms in supervised, unsupervised, and semi-supervised settings. All methods are tested on seven available microarray datasets using KNN, SVM and C4.5 classifiers. In terms of evaluation metrics, the experimental results shows that the proposed method is comparable with the state-of-the-art feature selection. ",
    "url": "https://arxiv.org/abs/2210.00418",
    "authors": [
      "Amir Moslemi",
      "Arash Ahmadian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.00423",
    "title": "Improved Algorithms for Neural Active Learning",
    "abstract": "We improve the theoretical and empirical performance of neural-network(NN)-based active learning algorithms for the non-parametric streaming setting. In particular, we introduce two regret metrics by minimizing the population loss that are more suitable in active learning than the one used in state-of-the-art (SOTA) related work. Then, the proposed algorithm leverages the powerful representation of NNs for both exploitation and exploration, has the query decision-maker tailored for $k$-class classification problems with the performance guarantee, utilizes the full feedback, and updates parameters in a more practical and efficient manner. These careful designs lead to a better regret upper bound, improving by a multiplicative factor $O(\\log T)$ and removing the curse of both input dimensionality and the complexity of the function to be learned. Furthermore, we show that the algorithm can achieve the same performance as the Bayes-optimal classifier in the long run under the hard-margin setting in classification problems. In the end, we use extensive experiments to evaluate the proposed algorithm and SOTA baselines, to show the improved empirical performance. ",
    "url": "https://arxiv.org/abs/2210.00423",
    "authors": [
      "Yikun Ban",
      "Yuheng Zhang",
      "Hanghang Tong",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00430",
    "title": "Understanding Adversarial Robustness Against On-manifold Adversarial  Examples",
    "abstract": "Deep neural networks (DNNs) are shown to be vulnerable to adversarial examples. A well-trained model can be easily attacked by adding small perturbations to the original data. One of the hypotheses of the existence of the adversarial examples is the off-manifold assumption: adversarial examples lie off the data manifold. However, recent research showed that on-manifold adversarial examples also exist. In this paper, we revisit the off-manifold assumption and want to study a question: at what level is the poor performance of neural networks against adversarial attacks due to on-manifold adversarial examples? Since the true data manifold is unknown in practice, we consider two approximated on-manifold adversarial examples on both real and synthesis datasets. On real datasets, we show that on-manifold adversarial examples have greater attack rates than off-manifold adversarial examples on both standard-trained and adversarially-trained models. On synthetic datasets, theoretically, We prove that on-manifold adversarial examples are powerful, yet adversarial training focuses on off-manifold directions and ignores the on-manifold adversarial examples. Furthermore, we provide analysis to show that the properties derived theoretically can also be observed in practice. Our analysis suggests that on-manifold adversarial examples are important, and we should pay more attention to on-manifold adversarial examples for training robust models. ",
    "url": "https://arxiv.org/abs/2210.00430",
    "authors": [
      "Jiancong Xiao",
      "Liusha Yang",
      "Yanbo Fan",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00450",
    "title": "Citation Trajectory Prediction via Publication Influence Representation  Using Temporal Knowledge Graph",
    "abstract": "Predicting the impact of publications in science and technology has become an important research area, which is useful in various real world scenarios such as technology investment, research direction selection, and technology policymaking. Citation trajectory prediction is one of the most popular tasks in this area. Existing approaches mainly rely on mining temporal and graph data from academic articles. Some recent methods are capable of handling cold-start prediction by aggregating metadata features of new publications. However, the implicit factors causing citations and the richer information from handling temporal and attribute features still need to be explored. In this paper, we propose CTPIR, a new citation trajectory prediction framework that is able to represent the influence (the momentum of citation) of either new or existing publications using the history information of all their attributes. Our framework is composed of three modules: difference-preserved graph embedding, fine-grained influence representation, and learning-based trajectory calculation. To test the effectiveness of our framework in more situations, we collect and construct a new temporal knowledge graph dataset from the real world, named AIPatent, which stems from global patents in the field of artificial intelligence. Experiments are conducted on both the APS academic dataset and our contributed AIPatent dataset. The results demonstrate the strengths of our approach in the citation trajectory prediction task. ",
    "url": "https://arxiv.org/abs/2210.00450",
    "authors": [
      "Chang Zong",
      "Yueting Zhuang",
      "Weiming Lu",
      "Jian Shao",
      "Siliang Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.00451",
    "title": "Asynchronous Activity Detection for Cell-Free Massive MIMO: From  Centralized to Distributed Algorithms",
    "abstract": "Device activity detection in the emerging cell-free massive multiple-input multiple-output (MIMO) systems has been recognized as a crucial task in machine-type communications, in which multiple access points (APs) jointly identify the active devices from a large number of potential devices based on the received signals. Most of the existing works addressing this problem rely on the impractical assumption that different active devices transmit signals synchronously. However, in practice, synchronization cannot be guaranteed due to the low-cost oscillators, which brings additional discontinuous and nonconvex constraints to the detection problem. To address this challenge, this paper reveals an equivalent reformulation to the asynchronous activity detection problem, which facilitates the development of a centralized algorithm and a distributed algorithm that satisfy the highly nonconvex constraints in a gentle fashion as the iteration number increases, so that the sequence generated by the proposed algorithms can get around bad stationary points. To reduce the capacity requirements of the fronthauls, we further design a communication-efficient accelerated distributed algorithm. Simulation results demonstrate that the proposed centralized and distributed algorithms outperform state-of-the-art approaches, and the proposed accelerated distributed algorithm achieves a close detection performance to that of the centralized algorithm but with a much smaller number of bits to be transmitted on the fronthaul links. ",
    "url": "https://arxiv.org/abs/2210.00451",
    "authors": [
      "Yang Li",
      "Qingfeng Lin",
      "Ya-Feng Liu",
      "Bo Ai",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.00453",
    "title": "Neural Graphical Models",
    "abstract": "Graphs are ubiquitous and are often used to understand the dynamics of a system. Probabilistic Graphical Models comprising Bayesian and Markov networks, and Conditional Independence graphs are some of the popular graph representation techniques. They can model relationships between features (nodes) together with the underlying distribution. Although theoretically these models can represent very complex dependency functions, in practice often simplifying assumptions are made due to computational limitations associated with graph operations. This work introduces Neural Graphical Models (NGMs) which attempt to represent complex feature dependencies with reasonable computational costs. Specifically, given a graph of feature relationships and corresponding samples, we capture the dependency structure between the features along with their complex function representations by using neural networks as a multi-task learning framework. We provide efficient learning, inference and sampling algorithms for NGMs. Moreover, NGMs can fit generic graph structures including directed, undirected and mixed-edge graphs as well as support mixed input data types. We present empirical studies that show NGMs' capability to represent Gaussian graphical models, inference analysis of a lung cancer data and extract insights from a real world infant mortality data provided by CDC. ",
    "url": "https://arxiv.org/abs/2210.00453",
    "authors": [
      "Harsh Shrivastava",
      "Urszula Chajewska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00457",
    "title": "Towards a Complete Direct Mapping From Relational Databases To Property  Graphs",
    "abstract": "It is increasingly common to find complex data represented through the graph model. Contrary to relational models, graphs offer a high capacity for executing analytical tasks on complex data. Since a huge amount of data is still presented in terms of relational tables, it is necessary to understand how to translate this data into graphs. This paper proposes a complete mapping process that allows transforming any relational database (schema and instance) into a property graph database (schema and instance). Contrary to existing mappings, our solution preserves the three fundamental mapping properties, namely: information preservation, semantic preservation and query preservation. Moreover, we study mapping any SQL query into an equivalent Cypher query, which makes our solution practical. Existing solutions are either incomplete or based on non-practical query language. Thus, this work is the first complete and practical solution for mapping relations to graphs. ",
    "url": "https://arxiv.org/abs/2210.00457",
    "authors": [
      "Abdelkrim Boudaoud",
      "Houari Mahfoud",
      "Azeddine Chikh"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.00465",
    "title": "Assessing the impact of contextual information in hate speech detection",
    "abstract": "In recent years, hate speech has gained great relevance in social networks and other virtual media because of its intensity and its relationship with violent acts against members of protected groups. Due to the great amount of content generated by users, great effort has been made in the research and development of automatic tools to aid the analysis and moderation of this speech, at least in its most threatening forms. One of the limitations of current approaches to automatic hate speech detection is the lack of context. Most studies and resources are performed on data without context; that is, isolated messages without any type of conversational context or the topic being discussed. This restricts the available information to define if a post on a social network is hateful or not. In this work, we provide a novel corpus for contextualized hate speech detection based on user responses to news posts from media outlets on Twitter. This corpus was collected in the Rioplatense dialectal variety of Spanish and focuses on hate speech associated with the COVID-19 pandemic. Classification experiments using state-of-the-art techniques show evidence that adding contextual information improves hate speech detection performance for two proposed tasks (binary and multi-label prediction). We make our code, models, and corpus available for further research. ",
    "url": "https://arxiv.org/abs/2210.00465",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Franco Luque",
      "Demian Zayat",
      "Mart\u00edn Kondratzky",
      "Agust\u00edn Moro",
      "Pablo Serrati",
      "Joaqu\u00edn Zajac",
      "Paula Miguel",
      "Natalia Debandi",
      "Agust\u00edn Gravano",
      "Viviana Cotik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00476",
    "title": "Robust Bayesian optimization with reinforcement learned acquisition  functions",
    "abstract": "In Bayesian optimization (BO) for expensive black-box optimization tasks, acquisition function (AF) guides sequential sampling and plays a pivotal role for efficient convergence to better optima. Prevailing AFs usually rely on artificial experiences in terms of preferences for exploration or exploitation, which runs a risk of a computational waste or traps in local optima and resultant re-optimization. To address the crux, the idea of data-driven AF selection is proposed, and the sequential AF selection task is further formalized as a Markov decision process (MDP) and resort to powerful reinforcement learning (RL) technologies. Appropriate selection policy for AFs is learned from superior BO trajectories to balance between exploration and exploitation in real time, which is called reinforcement-learning-assisted Bayesian optimization (RLABO). Competitive and robust BO evaluations on five benchmark problems demonstrate RL's recognition of the implicit AF selection pattern and imply the proposal's potential practicality for intelligent AF selection as well as efficient optimization in expensive black-box problems. ",
    "url": "https://arxiv.org/abs/2210.00476",
    "authors": [
      "Zijing Liu",
      "Xiyao Qu",
      "Xuejun Liu",
      "Hongqiang Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.00482",
    "title": "Compositional Generalization in Unsupervised Compositional  Representation Learning: A Study on Disentanglement and Emergent Language",
    "abstract": "Deep learning models struggle with compositional generalization, i.e. the ability to recognize or generate novel combinations of observed elementary concepts. In hopes of enabling compositional generalization, various unsupervised learning algorithms have been proposed with inductive biases that aim to induce compositional structure in learned representations (e.g. disentangled representation and emergent language learning). In this work, we evaluate these unsupervised learning algorithms in terms of how well they enable compositional generalization. Specifically, our evaluation protocol focuses on whether or not it is easy to train a simple model on top of the learned representation that generalizes to new combinations of compositional factors. We systematically study three unsupervised representation learning algorithms -- $\\beta$-VAE, $\\beta$-TCVAE, and emergent language (EL) autoencoders -- on two datasets that allow directly testing compositional generalization. We find that directly using the bottleneck representation with simple models and few labels may lead to worse generalization than using representations from layers before or after the learned representation itself. In addition, we find that the previously proposed metrics for evaluating the levels of compositionality are not correlated with actual compositional generalization in our framework. Surprisingly, we find that increasing pressure to produce a disentangled representation produces representations with worse generalization, while representations from EL models show strong compositional generalization. Taken together, our results shed new light on the compositional generalization behavior of different unsupervised learning algorithms with a new setting to rigorously test this behavior, and suggest the potential benefits of delevoping EL learning algorithms for more generalizable representations. ",
    "url": "https://arxiv.org/abs/2210.00482",
    "authors": [
      "Zhenlin Xu",
      "Marc Niethamme",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": "In order to perform machine learning among multiple parties while protecting the privacy of raw data, privacy-preserving machine learning based on secure multi-party computation (MPL for short) has been a hot spot in recent. The configuration of MPL usually follows the peer-to-peer architecture, where each party has the same chance to reveal the output result. However, typical business scenarios often follow a hierarchical architecture where a powerful, usually \\textit{privileged party}, leads the tasks of machine learning. Only the \\textit{privileged party} can reveal the final model even if other \\textit{assistant parties} collude with each other. It is even required to avoid the abort of machine learning to ensure the scheduled deadlines and/or save used computing resources when part of \\textit{assistant parties} drop out. Motivated by the above scenarios, we propose \\pmpl, a robust MPL framework with a \\textit{privileged party}. \\pmpl supports three-party training in the semi-honest setting. By setting alternate shares for the \\textit{privileged party}, \\pmpl is robust to tolerate one of the rest two parties dropping out during the training. With the above settings, we design a series of efficient protocols based on vector space secret sharing for \\pmpl to bridge the gap between vector space secret sharing and machine learning. Finally, the experimental results show that the performance of \\pmpl is promising when we compare it with the state-of-the-art MPL frameworks. Especially, in the LAN setting, \\pmpl is around $16\\times$ and $5\\times$ faster than \\texttt{TF-encrypted} (with \\texttt{ABY3} as the back-end framework) for the linear regression, and logistic regression, respectively. Besides, the accuracy of trained models of linear regression, logistic regression, and BP neural networks can reach around 97\\%, 99\\%, and 96\\% on MNIST dataset respectively. ",
    "url": "https://arxiv.org/abs/2210.00486",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00490",
    "title": "Incentive Mechanism and Path Planning for UAV Hitching over Traffic  Networks",
    "abstract": "Package delivery via the UAVs is a promising transport mode to provide efficient and green logistic services, especially in urban areas or complicated topography. However, the energy storage limit of the UAV makes it difficult to perform long-distance delivery tasks. In this paper, we propose a novel multimodal logistics framework, in which the UAVs can call on ground vehicles to provide hitch services to save their own energy and extend their delivery distance. This multimodal logistics framework is formulated as a two-stage model to jointly consider the incentive mechanism design for ground vehicles and path planning for UAVs. In Stage I, to deal with the motivations for ground vehicles to assist UAV delivery, a dynamic pricing scheme is proposed to best balance the vehicle response time and payments to ground vehicles. It shows that a higher price should be decided if the vehicle response time is long to encourage more vehicles to offer a ride. In Stage II, the task allocation and path planning of the UAVs over traffic network is studied based on the vehicle response time obtained in Stage I. To address pathfinding with restrictions and the performance degradation of the pathfinding algorithm due to the rising number of conflicts in multi-agent pathfinding, we propose the suboptimal conflict avoidance-based path search (CABPS) algorithm, which has polynomial time complexity. Finally, we validate our results via simulations. It is shown that our approach is able to increase the success rate of UAV package delivery. Moreover, we estimate the delivery time of the UAV in a pessimistic case, it is still twice as fast as the delivery time of the ground vehicle only. ",
    "url": "https://arxiv.org/abs/2210.00490",
    "authors": [
      "Ziyi Lu",
      "Na Yu",
      "Xuehe Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.00507",
    "title": "Fast and Robust Video-Based Exercise Classification via Body Pose  Tracking and Scalable Multivariate Time Series Classifiers",
    "abstract": "Technological advancements have spurred the usage of machine learning based applications in sports science. Physiotherapists, sports coaches and athletes actively look to incorporate the latest technologies in order to further improve performance and avoid injuries. While wearable sensors are very popular, their use is hindered by constraints on battery power and sensor calibration, especially for use cases which require multiple sensors to be placed on the body. Hence, there is renewed interest in video-based data capture and analysis for sports science. In this paper, we present the application of classifying S\\&C exercises using video. We focus on the popular Military Press exercise, where the execution is captured with a video-camera using a mobile device, such as a mobile phone, and the goal is to classify the execution into different types. Since video recordings need a lot of storage and computation, this use case requires data reduction, while preserving the classification accuracy and enabling fast prediction. To this end, we propose an approach named BodyMTS to turn video into time series by employing body pose tracking, followed by training and prediction using multivariate time series classifiers. We analyze the accuracy and robustness of BodyMTS and show that it is robust to different types of noise caused by either video quality or pose estimation factors. We compare BodyMTS to state-of-the-art deep learning methods which classify human activity directly from videos and show that BodyMTS achieves similar accuracy, but with reduced running time and model engineering effort. Finally, we discuss some of the practical aspects of employing BodyMTS in this application in terms of accuracy and robustness under reduced data quality and size. We show that BodyMTS achieves an average accuracy of 87\\%, which is significantly higher than the accuracy of human domain experts. ",
    "url": "https://arxiv.org/abs/2210.00507",
    "authors": [
      "Ashish Singh",
      "Antonio Bevilacqua",
      "Thach Le Nguyen",
      "Feiyan Hu",
      "Kevin McGuinness",
      "Martin OReilly",
      "Darragh Whelan",
      "Brian Caulfield",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00513",
    "title": "Gradient Gating for Deep Multi-Rate Learning on Graphs",
    "abstract": "We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs. ",
    "url": "https://arxiv.org/abs/2210.00513",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "Michael W. Mahoney",
      "Michael M. Bronstein",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00518",
    "title": "High Precision Differentiation Techniques for Data-Driven Solution of  Nonlinear PDEs by Physics-Informed Neural Networks",
    "abstract": "Time-dependent Partial Differential Equations with given initial conditions are considered in this paper. New differentiation techniques of the unknown solution with respect to time variable are proposed. It is shown that the proposed techniques allow to generate accurate higher order derivatives simultaneously for a set of spatial points. The calculated derivatives can then be used for data-driven solution in different ways. An application for Physics Informed Neural Networks by the well-known DeepXDE software solution in Python under Tensorflow background framework has been presented for three real-life PDEs: Burgers', Allen-Cahn and Schrodinger equations. ",
    "url": "https://arxiv.org/abs/2210.00518",
    "authors": [
      "Marat S. Mukhametzhanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00533",
    "title": "Strategic Communication via Cascade Multiple Description Network",
    "abstract": "In decentralized decision-making problems, agents choose their actions based on locally available information and knowledge about decision rules or strategies of other agents. We consider a three-node cascade network with an encoder, a relay and a decoder, having distinct objectives captured by cost functions. In such a cascade network, agents choose their respective strategies sequentially, as a response to the former agent's strategy and in a way to influence the decision of the latter agent in the network. We assume the encoder commits to a strategy before the communication takes place. Upon revelation of the encoding strategy, the relay commits to a strategy and reveals it. The communication starts, the source sequence is drawn and processed by the encoder and relay. Then, the decoder observes a sequences of symbols, updates its Bayesian posterior beliefs accordingly, and takes the optimal action. This is an extension of the Bayesian persuasion problem in the Game Theory literature. In this work, we provide an information-theoretic approach to study the fundamental limit of the strategic communication via three-node cascade network. Our goal is to characterize the optimal strategies of the encoder, the relay and the decoder, and study the asymptotic behavior of the encoder's minimal long-run cost function. ",
    "url": "https://arxiv.org/abs/2210.00533",
    "authors": [
      "Rony Bou Rouphael",
      "Ma\u00ebl Le trust"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.00538",
    "title": "Heterogeneous Graph Neural Network for Privacy-Preserving Recommendation",
    "abstract": "Social networks are considered to be heterogeneous graph neural networks (HGNNs) with deep learning technological advances. HGNNs, compared to homogeneous data, absorb various aspects of information about individuals in the training stage. That means more information has been covered in the learning result, especially sensitive information. However, the privacy-preserving methods on homogeneous graphs only preserve the same type of node attributes or relationships, which cannot effectively work on heterogeneous graphs due to the complexity. To address this issue, we propose a novel heterogeneous graph neural network privacy-preserving method based on a differential privacy mechanism named HeteDP, which provides a double guarantee on graph features and topology. In particular, we first define a new attack scheme to reveal privacy leakage in the heterogeneous graphs. Specifically, we design a two-stage pipeline framework, which includes the privacy-preserving feature encoder and the heterogeneous link reconstructor with gradients perturbation based on differential privacy to tolerate data diversity and against the attack. To better control the noise and promote model performance, we utilize a bi-level optimization pattern to allocate a suitable privacy budget for the above two modules. Our experiments on four public benchmarks show that the HeteDP method is equipped to resist heterogeneous graph privacy leakage with admirable model generalization. ",
    "url": "https://arxiv.org/abs/2210.00538",
    "authors": [
      "Yuecen Wei",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Jia Wu",
      "Jinyan Wang",
      "Xianxian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00546",
    "title": "Siamese-NAS: Using Trained Samples Efficiently to Find Lightweight  Neural Architecture by Prior Knowledge",
    "abstract": "In the past decade, many architectures of convolution neural networks were designed by handcraft, such as Vgg16, ResNet, DenseNet, etc. They all achieve state-of-the-art level on different tasks in their time. However, it still relies on human intuition and experience, and it also takes so much time consumption for trial and error. Neural Architecture Search (NAS) focused on this issue. In recent works, the Neural Predictor has significantly improved with few training architectures as training samples. However, the sampling efficiency is already considerable. In this paper, our proposed Siamese-Predictor is inspired by past works of predictor-based NAS. It is constructed with the proposed Estimation Code, which is the prior knowledge about the training procedure. The proposed Siamese-Predictor gets significant benefits from this idea. This idea causes it to surpass the current SOTA predictor on NASBench-201. In order to explore the impact of the Estimation Code, we analyze the relationship between it and accuracy. We also propose the search space Tiny-NanoBench for lightweight CNN architecture. This well-designed search space is easier to find better architecture with few FLOPs than NASBench-201. In summary, the proposed Siamese-Predictor is a predictor-based NAS. It achieves the SOTA level, especially with limited computation budgets. It applied to the proposed Tiny-NanoBench can just use a few trained samples to find extremely lightweight CNN architecture. ",
    "url": "https://arxiv.org/abs/2210.00546",
    "authors": [
      "Yu-Ming Zhang",
      "Jun-Wei Hsieh",
      "Chun-Chieh Lee",
      "Kuo-Chin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00557",
    "title": "Adaptive Smoothness-weighted Adversarial Training for Multiple  Perturbations with Its Stability Analysis",
    "abstract": "Adversarial Training (AT) has been demonstrated as one of the most effective methods against adversarial examples. While most existing works focus on AT with a single type of perturbation e.g., the $\\ell_\\infty$ attacks), DNNs are facing threats from different types of adversarial examples. Therefore, adversarial training for multiple perturbations (ATMP) is proposed to generalize the adversarial robustness over different perturbation types (in $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ norm-bounded perturbations). However, the resulting model exhibits trade-off between different attacks. Meanwhile, there is no theoretical analysis of ATMP, limiting its further development. In this paper, we first provide the smoothness analysis of ATMP and show that $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ adversaries give different contributions to the smoothness of the loss function of ATMP. Based on this, we develop the stability-based excess risk bounds and propose adaptive smoothness-weighted adversarial training for multiple perturbations. Theoretically, our algorithm yields better bounds. Empirically, our experiments on CIFAR10 and CIFAR100 achieve the state-of-the-art performance against the mixture of multiple perturbations attacks. ",
    "url": "https://arxiv.org/abs/2210.00557",
    "authors": [
      "Jiancong Xiao",
      "Zeyu Qin",
      "Yanbo Fan",
      "Baoyuan Wu",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00563",
    "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social  Science",
    "abstract": "In social science, formal and quantitative models, such as ones describing economic growth and collective action, are used to formulate mechanistic explanations, provide predictions, and uncover questions about observed phenomena. Here, we demonstrate the use of a machine learning system to aid the discovery of symbolic models that capture nonlinear and dynamical relationships in social science datasets. By extending neuro-symbolic methods to find compact functions and differential equations in noisy and longitudinal data, we show that our system can be used to discover interpretable models from real-world data in economics and sociology. Augmenting existing workflows with symbolic regression can help uncover novel relationships and explore counterfactual models during the scientific process. We propose that this AI-assisted framework can bridge parametric and non-parametric models commonly employed in social science research by systematically exploring the space of nonlinear models and enabling fine-grained control over expressivity and interpretability. ",
    "url": "https://arxiv.org/abs/2210.00563",
    "authors": [
      "Julia Balla",
      "Sihao Huang",
      "Owen Dugan",
      "Rumen Dangovski",
      "Marin Soljacic"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2210.00573",
    "title": "Natural Gradient Ascent in Evolutionary Games",
    "abstract": "We study evolutionary games with a continuous trait space in which replicator dynamics are restricted to the manifold of multidimensional Gaussian distributions. We demonstrate that the replicator equations are natural gradient flow for maximization of the mean fitness. Our findings extend previous results on information-geometric aspects of evolutionary games with a finite strategy set. Throughout the paper we exploit the information-geometric approach and the relation between evolutionary dynamics and Natural Evolution Strategies, the concept that has been developed within the framework of black-box optimization. This relation sheds a new light on the replicator dynamics as a compromise between maximization of the mean fitness and preservation of diversity in the population. ",
    "url": "https://arxiv.org/abs/2210.00573",
    "authors": [
      "Vladimir Ja\u0107imovi\u0107"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.00583",
    "title": "The Dynamic of Consensus in Deep Networks and the Identification of  Noisy Labels",
    "abstract": "Deep neural networks have incredible capacity and expressibility, and can seemingly memorize any training set. This introduces a problem when training in the presence of noisy labels, as the noisy examples cannot be distinguished from clean examples by the end of training. Recent research has dealt with this challenge by utilizing the fact that deep networks seem to memorize clean examples much earlier than noisy examples. Here we report a new empirical result: for each example, when looking at the time it has been memorized by each model in an ensemble of networks, the diversity seen in noisy examples is much larger than the clean examples. We use this observation to develop a new method for noisy labels filtration. The method is based on a statistics of the data, which captures the differences in ensemble learning dynamics between clean and noisy data. We test our method on three tasks: (i) noise amount estimation; (ii) noise filtration; (iii) supervised classification. We show that our method improves over existing baselines in all three tasks using a variety of datasets, noise models, and noise levels. Aside from its improved performance, our method has two other advantages. (i) Simplicity, which implies that no additional hyperparameters are introduced. (ii) Our method is modular: it does not work in an end-to-end fashion, and can therefore be used to clean a dataset for any other future usage. ",
    "url": "https://arxiv.org/abs/2210.00583",
    "authors": [
      "Daniel Shwartz",
      "Uri Stern",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00584",
    "title": "FLCert: Provably Secure Federated Learning against Poisoning Attacks",
    "abstract": "Due to its distributed nature, federated learning is vulnerable to poisoning attacks, in which malicious clients poison the training process via manipulating their local training data and/or local model updates sent to the cloud server, such that the poisoned global model misclassifies many indiscriminate test inputs or attacker-chosen ones. Existing defenses mainly leverage Byzantine-robust federated learning methods or detect malicious clients. However, these defenses do not have provable security guarantees against poisoning attacks and may be vulnerable to more advanced attacks. In this work, we aim to bridge the gap by proposing FLCert, an ensemble federated learning framework, that is provably secure against poisoning attacks with a bounded number of malicious clients. Our key idea is to divide the clients into groups, learn a global model for each group of clients using any existing federated learning method, and take a majority vote among the global models to classify a test input. Specifically, we consider two methods to group the clients and propose two variants of FLCert correspondingly, i.e., FLCert-P that randomly samples clients in each group, and FLCert-D that divides clients to disjoint groups deterministically. Our extensive experiments on multiple datasets show that the label predicted by our FLCert for a test input is provably unaffected by a bounded number of malicious clients, no matter what poisoning attacks they use. ",
    "url": "https://arxiv.org/abs/2210.00584",
    "authors": [
      "Xiaoyu Cao",
      "Zaixi Zhang",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00588",
    "title": "DFA: Dynamic Feature Aggregation for Efficient Video Object Detection",
    "abstract": "Video object detection is a fundamental yet challenging task in computer vision. One practical solution is to take advantage of temporal information from the video and apply feature aggregation to enhance the object features in each frame. Though effective, those existing methods always suffer from low inference speeds because they use a fixed number of frames for feature aggregation regardless of the input frame. Therefore, this paper aims to improve the inference speed of the current feature aggregation-based video object detectors while maintaining their performance. To achieve this goal, we propose a vanilla dynamic aggregation module that adaptively selects the frames for feature enhancement. Then, we extend the vanilla dynamic aggregation module to a more effective and reconfigurable deformable version. Finally, we introduce inplace distillation loss to improve the representations of objects aggregated with fewer frames. Extensive experimental results validate the effectiveness and efficiency of our proposed methods: On the ImageNet VID benchmark, integrated with our proposed methods, FGFA and SELSA can improve the inference speed by 31% and 76% respectively while getting comparable performance on accuracy. ",
    "url": "https://arxiv.org/abs/2210.00588",
    "authors": [
      "Yiming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00590",
    "title": "Community Learning: Understanding A Community Through NLP for Positive  Impact",
    "abstract": "A post-pandemic world resulted in economic upheaval, particularly for the cities' communities. While significant work in NLP4PI focuses on national and international events, there is a gap in bringing such state-of-the-art methods into the community development field. In order to help with community development, we must learn about the communities we develop. To that end, we propose the task of community learning as a computational task of extracting natural language data about the community, transforming and loading it into a suitable knowledge graph structure for further downstream applications. We study two particular cases of homelessness and education in showing the visualization capabilities of a knowledge graph, and also discuss other usefulness such a model can provide. ",
    "url": "https://arxiv.org/abs/2210.00590",
    "authors": [
      "Md Towhidul Absar Chowdhury",
      "Naveen Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00597",
    "title": "Composition of Differential Privacy & Privacy Amplification by  Subsampling",
    "abstract": "This chapter is meant to be part of the book ``Differential Privacy for Artificial Intelligence Applications.'' We give an introduction to the most important property of differential privacy -- composition: running multiple independent analyses on the data of a set of people will still be differentially private as long as each of the analyses is private on its own -- as well as the related topic of privacy amplification by subsampling. This chapter introduces the basic concepts and gives proofs of the key results needed to apply these tools in practice. ",
    "url": "https://arxiv.org/abs/2210.00597",
    "authors": [
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00608",
    "title": "Establishing Meta-Decision-Making for AI: An Ontology of Relevance,  Representation and Reasoning",
    "abstract": "We propose an ontology of building decision-making systems, with the aim of establishing Meta-Decision-Making for Artificial Intelligence (AI), improving autonomy, and creating a framework to build metrics and benchmarks upon. To this end, we propose the three parts of Relevance, Representation, and Reasoning, and discuss their value in ensuring safety and mitigating risk in the context of third wave cognitive systems. Our nomenclature reflects the literature on decision-making, and our ontology allows researchers that adopt it to frame their work in relation to one or more of these parts. ",
    "url": "https://arxiv.org/abs/2210.00608",
    "authors": [
      "Cosmin Badea",
      "Leilani Gilpin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.00613",
    "title": "The boundaries of meaning: a case study in neural machine translation",
    "abstract": "The success of deep learning in natural language processing raises intriguing questions about the nature of linguistic meaning and ways in which it can be processed by natural and artificial systems. One such question has to do with subword segmentation algorithms widely employed in language modeling, machine translation, and other tasks since 2016. These algorithms often cut words into semantically opaque pieces, such as 'period', 'on', 't', and 'ist' in 'period|on|t|ist'. The system then represents the resulting segments in a dense vector space, which is expected to model grammatical relations among them. This representation may in turn be used to map 'period|on|t|ist' (English) to 'par|od|ont|iste' (French). Thus, instead of being modeled at the lexical level, translation is reformulated more generally as the task of learning the best bilingual mapping between the sequences of subword segments of two languages; and sometimes even between pure character sequences: 'p|e|r|i|o|d|o|n|t|i|s|t' $\\rightarrow$ 'p|a|r|o|d|o|n|t|i|s|t|e'. Such subword segmentations and alignments are at work in highly efficient end-to-end machine translation systems, despite their allegedly opaque nature. The computational value of such processes is unquestionable. But do they have any linguistic or philosophical plausibility? I attempt to cast light on this question by reviewing the relevant details of the subword segmentation algorithms and by relating them to important philosophical and linguistic debates, in the spirit of making artificial intelligence more transparent and explainable. ",
    "url": "https://arxiv.org/abs/2210.00613",
    "authors": [
      "Yuri Balashov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00615",
    "title": "iCTGAN--An Attack Mitigation Technique for Random-vector Attack on  Accelerometer-based Gait Authentication Systems",
    "abstract": "A recent study showed that commonly (vanilla) studied implementations of accelerometer-based gait authentication systems ($v$ABGait) are susceptible to random-vector attack. The same study proposed a beta noise-assisted implementation ($\\beta$ABGait) to mitigate the attack. In this paper, we assess the effectiveness of the random-vector attack on both $v$ABGait and $\\beta$ABGait using three accelerometer-based gait datasets. In addition, we propose $i$ABGait, an alternative implementation of ABGait, which uses a Conditional Tabular Generative Adversarial Network. Then we evaluate $i$ABGait's resilience against the traditional zero-effort and random-vector attacks. The results show that $i$ABGait mitigates the impact of the random-vector attack to a reasonable extent and outperforms $\\beta$ABGait in most experimental settings. ",
    "url": "https://arxiv.org/abs/2210.00615",
    "authors": [
      "Jun Hyung Mo",
      "Rajesh Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00621",
    "title": "Optimization for Robustness Evaluation beyond $\\ell_p$ Metrics",
    "abstract": "Empirical evaluation of deep learning models against adversarial attacks entails solving nontrivial constrained optimization problems. Popular algorithms for solving these constrained problems rely on projected gradient descent (PGD) and require careful tuning of multiple hyperparameters. Moreover, PGD can only handle $\\ell_1$, $\\ell_2$, and $\\ell_\\infty$ attack models due to the use of analytical projectors. In this paper, we introduce a novel algorithmic framework that blends a general-purpose constrained-optimization solver PyGRANSO, With Constraint-Folding (PWCF), to add reliability and generality to robustness evaluation. PWCF 1) finds good-quality solutions without the need of delicate hyperparameter tuning, and 2) can handle general attack models, e.g., general $\\ell_p$ ($p \\geq 0$) and perceptual attacks, which are inaccessible to PGD-based algorithms. ",
    "url": "https://arxiv.org/abs/2210.00621",
    "authors": [
      "Hengyue Liang",
      "Buyun Liang",
      "Ying Cui",
      "Tim Mitchell",
      "Ju Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.00627",
    "title": "MonoNHR: Monocular Neural Human Renderer",
    "abstract": "Existing neural human rendering methods struggle with a single image input due to the lack of information in invisible areas and the depth ambiguity of pixels in visible areas. In this regard, we propose Monocular Neural Human Renderer (MonoNHR), a novel approach that renders robust free-viewpoint images of an arbitrary human given only a single image. MonoNHR is the first method that (i) renders human subjects never seen during training in a monocular setup, and (ii) is trained in a weakly-supervised manner without geometry supervision. First, we propose to disentangle 3D geometry and texture features and to condition the texture inference on the 3D geometry features. Second, we introduce a Mesh Inpainter module that inpaints the occluded parts exploiting human structural priors such as symmetry. Experiments on ZJU-MoCap, AIST, and HUMBI datasets show that our approach significantly outperforms the recent methods adapted to the monocular case. ",
    "url": "https://arxiv.org/abs/2210.00627",
    "authors": [
      "Hongsuk Choi",
      "Gyeongsik Moon",
      "Matthieu Armando",
      "Vincent Leroy",
      "Kyoung Mu Lee",
      "Gregory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00635",
    "title": "Robust Empirical Risk Minimization with Tolerance",
    "abstract": "Developing simple, sample-efficient learning algorithms for robust classification is a pressing issue in today's tech-dominated world, and current theoretical techniques requiring exponential sample complexity and complicated improper learning rules fall far from answering the need. In this work we study the fundamental paradigm of (robust) $\\textit{empirical risk minimization}$ (RERM), a simple process in which the learner outputs any hypothesis minimizing its training error. RERM famously fails to robustly learn VC classes (Montasser et al., 2019a), a bound we show extends even to `nice' settings such as (bounded) halfspaces. As such, we study a recent relaxation of the robust model called $\\textit{tolerant}$ robust learning (Ashtiani et al., 2022) where the output classifier is compared to the best achievable error over slightly larger perturbation sets. We show that under geometric niceness conditions, a natural tolerant variant of RERM is indeed sufficient for $\\gamma$-tolerant robust learning VC classes over $\\mathbb{R}^d$, and requires only $\\tilde{O}\\left( \\frac{VC(H)d\\log \\frac{D}{\\gamma\\delta}}{\\epsilon^2}\\right)$ samples for robustness regions of (maximum) diameter $D$. ",
    "url": "https://arxiv.org/abs/2210.00635",
    "authors": [
      "Robi Bhattacharjee",
      "Max Hopkins",
      "Akash Kumar",
      "Hantao Yu",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00638",
    "title": "What shapes the loss landscape of self-supervised learning?",
    "abstract": "Prevention of complete and dimensional collapse of representations has recently become a design principle for self-supervised learning (SSL). However, questions remain in our theoretical understanding: When do those collapses occur? What are the mechanisms and causes? We provide answers to these questions by thoroughly analyzing SSL loss landscapes for a linear model. We derive an analytically tractable theory of SSL landscape and show that it accurately captures an array of collapse phenomena and identifies their causes. Finally, we leverage the interpretability afforded by the analytical theory to understand how dimensional collapse can be beneficial and what affects the robustness of SSL against data imbalance. ",
    "url": "https://arxiv.org/abs/2210.00638",
    "authors": [
      "Liu Ziyin",
      "Ekdeep Singh Lubana",
      "Masahito Ueda",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2210.00643",
    "title": "Spectral Augmentation for Self-Supervised Learning on Graphs",
    "abstract": "Graph contrastive learning (GCL), as an emerging self-supervised learning technique on graphs, aims to learn representations via instance discrimination. Its performance heavily relies on graph augmentation to reflect invariant patterns that are robust to small perturbations; yet it still remains unclear about what graph invariance GCL should capture. Recent studies mainly perform topology augmentations in a uniformly random manner in the spatial domain, ignoring its influence on the intrinsic structural properties embedded in the spectral domain. In this work, we aim to find a principled way for topology augmentations by exploring the invariance of graphs from the spectral perspective. We develop spectral augmentation which guides topology augmentations by maximizing the spectral change. Extensive experiments on both graph and node classification tasks demonstrate the effectiveness of our method in self-supervised representation learning. The proposed method also brings promising generalization capability in transfer learning, and is equipped with intriguing robustness property under adversarial attacks. Our study sheds light on a general principle for graph topology augmentation. ",
    "url": "https://arxiv.org/abs/2210.00643",
    "authors": [
      "Lu Lin",
      "Jinghui Chen",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00646",
    "title": "Pixel-global Self-supervised Learning with Uncertainty-aware Context  Stabilizer",
    "abstract": "We developed a novel SSL approach to capture global consistency and pixel-level local consistencies between differently augmented views of the same images to accommodate downstream discriminative and dense predictive tasks. We adopted the teacher-student architecture used in previous contrastive SSL methods. In our method, the global consistency is enforced by aggregating the compressed representations of augmented views of the same image. The pixel-level consistency is enforced by pursuing similar representations for the same pixel in differently augmented views. Importantly, we introduced an uncertainty-aware context stabilizer to adaptively preserve the context gap created by the two views from different augmentations. Moreover, we used Monte Carlo dropout in the stabilizer to measure uncertainty and adaptively balance the discrepancy between the representations of the same pixels in different views. ",
    "url": "https://arxiv.org/abs/2210.00646",
    "authors": [
      "Zhuangzhuang Zhang",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00647",
    "title": "IntrinsicNeRF: Learning Intrinsic Neural Radiance Fields for Editable  Novel View Synthesis",
    "abstract": "We present intrinsic neural radiance fields, dubbed IntrinsicNeRF, that introduce intrinsic decomposition into the NeRF-based~\\cite{mildenhall2020nerf} neural rendering method and can perform editable novel view synthesis in room-scale scenes while existing inverse rendering combined with neural rendering methods~\\cite{zhang2021physg, zhang2022modeling} can only work on object-specific scenes. Given that intrinsic decomposition is a fundamentally ambiguous and under-constrained inverse problem, we propose a novel distance-aware point sampling and adaptive reflectance iterative clustering optimization method that enables IntrinsicNeRF with traditional intrinsic decomposition constraints to be trained in an unsupervised manner, resulting in temporally consistent intrinsic decomposition results. To cope with the problem of different adjacent instances of similar reflectance in a scene being incorrectly clustered together, we further propose a hierarchical clustering method with coarse-to-fine optimization to obtain a fast hierarchical indexing representation. It enables compelling real-time augmented reality applications such as scene recoloring, material editing, and illumination variation. Extensive experiments on Blender Object and Replica Scene demonstrate that we can obtain high-quality, consistent intrinsic decomposition results and high-fidelity novel view synthesis even for challenging sequences. Code and data are available on the project webpage: https://zju3dv.github.io/intrinsic_nerf/. ",
    "url": "https://arxiv.org/abs/2210.00647",
    "authors": [
      "Weicai Ye",
      "Shuo Chen",
      "Chong Bao",
      "Hujun Bao",
      "Marc Pollefeys",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.00672",
    "title": "Evolution is Still Good: Theoretical Analysis of Evolutionary Algorithms  on General Cover Problems",
    "abstract": "Theoretical studies on evolutionary algorithms have developed vigorously in recent years. Many such algorithms have theoretical guarantees in both running time and approximation ratio. Some approximation mechanism seems to be inherently embedded in many evolutionary algorithms. In this paper, we identify such a relation by proposing a unified analysis framework for a generalized simple multi-objective evolutionary algorithm (GSEMO), and apply it on a minimum weight general cover problem. For a wide range of problems (including the the minimum submodular cover problem in which the submodular function is real-valued, and the minimum connected dominating set problem for which the potential function is non-submodular), GSEMO yields asymptotically tight approximation ratios in expected polynomial time. ",
    "url": "https://arxiv.org/abs/2210.00672",
    "authors": [
      "Yaoyao Zhang",
      "Chaojie Zhu",
      "Shaojie Tang",
      "Ringli Ran",
      "Ding-Zhu Du",
      "Zhao Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.00689",
    "title": "Multipod Convolutional Network",
    "abstract": "In this paper, we introduce a convolutional network which we call MultiPodNet consisting of a combination of two or more convolutional networks which process the input image in parallel to achieve the same goal. Output feature maps of parallel convolutional networks are fused at the fully connected layer of the network. We experimentally observed that three parallel pod networks (TripodNet) produce the best results in commonly used object recognition datasets. Baseline pod networks can be of any type. In this paper, we use ResNets as baseline networks and their inputs are augmented image patches. The number of parameters of the TripodNet is about three times that of a single ResNet. We train the TripodNet using the standard backpropagation type algorithms. In each individual ResNet, parameters are initialized with different random numbers during training. The TripodNet achieved state-of-the-art performance on CIFAR-10 and ImageNet datasets. For example, it improved the accuracy of a single ResNet from 91.66% to 92.47% under the same training process on the CIFAR-10 dataset. ",
    "url": "https://arxiv.org/abs/2210.00689",
    "authors": [
      "Hongyi Pan",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00698",
    "title": "NAS-based Recursive Stage Partial Network (RSPNet) for Light-Weight  Semantic Segmentation",
    "abstract": "Current NAS-based semantic segmentation methods focus on accuracy improvements rather than light-weight design. In this paper, we proposed a two-stage framework to design our NAS-based RSPNet model for light-weight semantic segmentation. The first architecture search determines the inner cell structure, and the second architecture search considers exponentially growing paths to finalize the outer structure of the network. It was shown in the literature that the fusion of high- and low-resolution feature maps produces stronger representations. To find the expected macro structure without manual design, we adopt a new path-attention mechanism to efficiently search for suitable paths to fuse useful information for better segmentation. Our search for repeatable micro-structures from cells leads to a superior network architecture in semantic segmentation. In addition, we propose an RSP (recursive Stage Partial) architecture to search a light-weight design for NAS-based semantic segmentation. The proposed architecture is very efficient, simple, and effective that both the macro- and micro- structure searches can be completed in five days of computation on two V100 GPUs. The light-weight NAS architecture with only 1/4 parameter size of SoTA architectures can achieve SoTA performance on semantic segmentation on the Cityscapes dataset without using any backbones. ",
    "url": "https://arxiv.org/abs/2210.00698",
    "authors": [
      "Yi-Chun Wang",
      "Jun-Wei Hsieh",
      "Ming-Ching Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00704",
    "title": "Combined Dynamic Virtual Spatiotemporal Graph Mapping for Traffic  Prediction",
    "abstract": "The continuous expansion of the urban construction scale has recently contributed to the demand for the dynamics of traffic intersections that are managed, making adaptive modellings become a hot topic. Existing deep learning methods are powerful to fit complex heterogeneous graphs. However, they still have drawbacks, which can be roughly classified into two categories, 1) spatiotemporal async-modelling approaches separately consider temporal and spatial dependencies, resulting in weak generalization and large instability while aggregating; 2) spatiotemporal sync-modelling is hard to capture long-term temporal dependencies because of the local receptive field. In order to overcome above challenges, a \\textbf{C}ombined \\textbf{D}ynamic \\textbf{V}irtual spatiotemporal \\textbf{G}raph \\textbf{M}apping \\textbf{(CDVGM)} is proposed in this work. The contributions are the following: 1) a dynamic virtual graph Laplacian ($DVGL$) is designed, which considers both the spatial signal passing and the temporal features simultaneously; 2) the Long-term Temporal Strengthen model ($LT^2S$) for improving the stability of time series forecasting; Extensive experiments demonstrate that CDVGM has excellent performances of fast convergence speed and low resource consumption and achieves the current SOTA effect in terms of both accuracy and generalization. The code is available at \\hyperlink{https://github.com/Dandelionym/CDVGM.}{https://github.com/Dandelionym/CDVGM.} ",
    "url": "https://arxiv.org/abs/2210.00704",
    "authors": [
      "Yingming Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00708",
    "title": "EraseNet: A Recurrent Residual Network for Supervised Document Cleaning",
    "abstract": "Document denoising is considered one of the most challenging tasks in computer vision. There exist millions of documents that are still to be digitized, but problems like document degradation due to natural and man-made factors make this task very difficult. This paper introduces a supervised approach for cleaning dirty documents using a new fully convolutional auto-encoder architecture. This paper focuses on restoring documents with discrepancies like deformities caused due to aging of a document, creases left on the pages that were xeroxed, random black patches, lightly visible text, etc., and also improving the quality of the image for better optical character recognition system (OCR) performance. Removing noise from scanned documents is a very important step before the documents as this noise can severely affect the performance of an OCR system. The experiments in this paper have shown promising results as the model is able to learn a variety of ordinary as well as unusual noises and rectify them efficiently. ",
    "url": "https://arxiv.org/abs/2210.00708",
    "authors": [
      "Yashowardhan Shinde",
      "Kishore Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.00712",
    "title": "PSENet: Progressive Self-Enhancement Network for Unsupervised  Extreme-Light Image Enhancement",
    "abstract": "The extremes of lighting (e.g. too much or too little light) usually cause many troubles for machine and human vision. Many recent works have mainly focused on under-exposure cases where images are often captured in low-light conditions (e.g. nighttime) and achieved promising results for enhancing the quality of images. However, they are inferior to handling images under over-exposure. To mitigate this limitation, we propose a novel unsupervised enhancement framework which is robust against various lighting conditions while does not require any well-exposed images to serve as the ground-truths. Our main concept is to construct pseudo-ground-truth images synthesized from multiple source images that simulate all potential exposure scenarios to train the enhancement network. Our extensive experiments show that the proposed approach consistently outperforms the current state-of-the-art unsupervised counterparts in several public datasets in terms of both quantitative metrics and qualitative results. Our code is available at https://github.com/VinAIResearch/PSENet-Image-Enhancement. ",
    "url": "https://arxiv.org/abs/2210.00712",
    "authors": [
      "Hue Nguyen",
      "Diep Tran",
      "Khoi Nguyen",
      "Rang Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00719",
    "title": "To Improve Is to Change: Towards Improving Mood Prediction by Learning  Changes in Emotion",
    "abstract": "Although the terms mood and emotion are closely related and often used interchangeably, they are distinguished based on their duration, intensity and attribution. To date, hardly any computational models have (a) examined mood recognition, and (b) modelled the interplay between mood and emotional state in their analysis. In this paper, as a first step towards mood prediction, we propose a framework that utilises both dominant emotion (or mood) labels, and emotional change labels on the AFEW-VA database. Experiments evaluating unimodal (trained only using mood labels) and multimodal (trained with both mood and emotion change labels) convolutional neural networks confirm that incorporating emotional change information in the network training process can significantly improve the mood prediction performance, thus highlighting the importance of modelling emotion and mood simultaneously for improved performance in affective state recognition. ",
    "url": "https://arxiv.org/abs/2210.00719",
    "authors": [
      "Soujanya Narayana",
      "Ramanathan Subramanian",
      "Ibrahim Radwan",
      "Roland Goecke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.00728",
    "title": "Learning from the Dark: Boosting Graph Convolutional Neural Networks  with Diverse Negative Samples",
    "abstract": "Graph Convolutional Neural Networks (GCNs) has been generally accepted to be an effective tool for node representations learning. An interesting way to understand GCNs is to think of them as a message passing mechanism where each node updates its representation by accepting information from its neighbours (also known as positive samples). However, beyond these neighbouring nodes, graphs have a large, dark, all-but forgotten world in which we find the non-neighbouring nodes (negative samples). In this paper, we show that this great dark world holds a substantial amount of information that might be useful for representation learning. Most specifically, it can provide negative information about the node representations. Our overall idea is to select appropriate negative samples for each node and incorporate the negative information contained in these samples into the representation updates. Moreover, we show that the process of selecting the negative samples is not trivial. Our theme therefore begins by describing the criteria for a good negative sample, followed by a determinantal point process algorithm for efficiently obtaining such samples. A GCN, boosted by diverse negative samples, then jointly considers the positive and negative information when passing messages. Experimental evaluations show that this idea not only improves the overall performance of standard representation learning but also significantly alleviates over-smoothing problems. ",
    "url": "https://arxiv.org/abs/2210.00728",
    "authors": [
      "Wei Duan",
      "Junyu Xuan",
      "Maoying Qiao",
      "Jie Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00737",
    "title": "FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients",
    "abstract": "Federated Learning (FL) effectively protects client data privacy. However, client absence or leaving during training can seriously degrade model performances, particularly for unbalanced and non-IID client data. We address this issue by generating data digests from the raw data and using them to guide training at the FL moderator. The proposed FL framework, called FedDig, can tolerate unexpected client absence in cross-silo scenarios while preserving client data privacy because the digests de-identify the raw data by mixing encoded features in the features space. We evaluate FedDig using EMNIST, CIFAR-10, and CIFAR-100; the results consistently outperform against three baseline algorithms (FedAvg, FedProx, and FedNova) by large margins in various client absence scenarios. ",
    "url": "https://arxiv.org/abs/2210.00737",
    "authors": [
      "Chih-Fan Hsu",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00743",
    "title": "An Embarrassingly Simple Approach for Intellectual Property Rights  Protection on Recurrent Neural Networks",
    "abstract": "Capitalise on deep learning models, offering Natural Language Processing (NLP) solutions as a part of the Machine Learning as a Service (MLaaS) has generated handsome revenues. At the same time, it is known that the creation of these lucrative deep models is non-trivial. Therefore, protecting these inventions intellectual property rights (IPR) from being abused, stolen and plagiarized is vital. This paper proposes a practical approach for the IPR protection on recurrent neural networks (RNN) without all the bells and whistles of existing IPR solutions. Particularly, we introduce the Gatekeeper concept that resembles the recurrent nature in RNN architecture to embed keys. Also, we design the model training scheme in a way such that the protected RNN model will retain its original performance iff a genuine key is presented. Extensive experiments showed that our protection scheme is robust and effective against ambiguity and removal attacks in both white-box and black-box protection schemes on different RNN variants. Code is available at https://github.com/zhiqin1998/RecurrentIPR ",
    "url": "https://arxiv.org/abs/2210.00743",
    "authors": [
      "Zhi Qin Tan",
      "Hao Shan Wong",
      "Chee Seng Chan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.00753",
    "title": "Push-Pull: Characterizing the Adversarial Robustness for Audio-Visual  Active Speaker Detection",
    "abstract": "Audio-visual active speaker detection (AVASD) is well-developed, and now is an indispensable front-end for several multi-modal applications. However, to the best of our knowledge, the adversarial robustness of AVASD models hasn't been investigated, not to mention the effective defense against such attacks. In this paper, we are the first to reveal the vulnerability of AVASD models under audio-only, visual-only, and audio-visual adversarial attacks through extensive experiments. What's more, we also propose a novel audio-visual interaction loss (AVIL) for making attackers difficult to find feasible adversarial examples under an allocated attack budget. The loss aims at pushing the inter-class embeddings to be dispersed, namely non-speech and speech clusters, sufficiently disentangled, and pulling the intra-class embeddings as close as possible to keep them compact. Experimental results show the AVIL outperforms the adversarial training by 33.14 mAP (%) under multi-modal attacks. ",
    "url": "https://arxiv.org/abs/2210.00753",
    "authors": [
      "Xuanjun Chen",
      "Haibin Wu",
      "Helen Meng",
      "Hung-yi Lee",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.00754",
    "title": "Lexical semantics enhanced neural word embeddings",
    "abstract": "Current breakthroughs in natural language processing have benefited dramatically from neural language models, through which distributional semantics can leverage neural data representations to facilitate downstream applications. Since neural embeddings use context prediction on word co-occurrences to yield dense vectors, they are inevitably prone to capture more semantic association than semantic similarity. To improve vector space models in deriving semantic similarity, we post-process neural word embeddings through deep metric learning, through which we can inject lexical-semantic relations, including syn/antonymy and hypo/hypernymy, into a distributional space. We introduce hierarchy-fitting, a novel semantic specialization approach to modelling semantic similarity nuances inherently stored in the IS-A hierarchies. Hierarchy-fitting attains state-of-the-art results on the common- and rare-word benchmark datasets for deriving semantic similarity from neural word embeddings. It also incorporates an asymmetric distance function to specialize hypernymy's directionality explicitly, through which it significantly improves vanilla embeddings in multiple evaluation tasks of detecting hypernymy and directionality without negative impacts on semantic similarity judgement. The results demonstrate the efficacy of hierarchy-fitting in specializing neural embeddings with semantic relations in late fusion, potentially expanding its applicability to aggregating heterogeneous data and various knowledge resources for learning multimodal semantic spaces. ",
    "url": "https://arxiv.org/abs/2210.00754",
    "authors": [
      "Dongqiang Yang",
      "Ning Li",
      "Li Zou",
      "Hongwei Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00757",
    "title": "Fully Transformer Network for Change Detection of Remote Sensing Images",
    "abstract": "Recently, change detection (CD) of remote sensing images have achieved great progress with the advances of deep learning. However, current methods generally deliver incomplete CD regions and irregular CD boundaries due to the limited representation ability of the extracted visual features. To relieve these issues, in this work we propose a novel learning framework named Fully Transformer Network (FTN) for remote sensing image CD, which improves the feature extraction from a global view and combines multi-level visual features in a pyramid manner. More specifically, the proposed framework first utilizes the advantages of Transformers in long-range dependency modeling. It can help to learn more discriminative global-level features and obtain complete CD regions. Then, we introduce a pyramid structure to aggregate multi-level visual features from Transformers for feature enhancement. The pyramid structure grafted with a Progressive Attention Module (PAM) can improve the feature representation ability with additional interdependencies through channel attentions. Finally, to better train the framework, we utilize the deeply-supervised learning with multiple boundaryaware loss functions. Extensive experiments demonstrate that our proposed method achieves a new state-of-the-art performance on four public CD benchmarks. For model reproduction, the source code is released at https://github.com/AI-Zhpp/FTN. ",
    "url": "https://arxiv.org/abs/2210.00757",
    "authors": [
      "Tianyu Yan",
      "Zifu Wan",
      "Pingping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.00765",
    "title": "Few-Shot Segmentation via Rich Prototype Generation and Recurrent  Prediction Enhancement",
    "abstract": "Prototype learning and decoder construction are the keys for few-shot segmentation. However, existing methods use only a single prototype generation mode, which can not cope with the intractable problem of objects with various scales. Moreover, the one-way forward propagation adopted by previous methods may cause information dilution from registered features during the decoding process. In this research, we propose a rich prototype generation module (RPGM) and a recurrent prediction enhancement module (RPEM) to reinforce the prototype learning paradigm and build a unified memory-augmented decoder for few-shot segmentation, respectively. Specifically, the RPGM combines superpixel and K-means clustering to generate rich prototype features with complementary scale relationships and adapt the scale gap between support and query images. The RPEM utilizes the recurrent mechanism to design a round-way propagation decoder. In this way, registered features can provide object-aware information continuously. Experiments show that our method consistently outperforms other competitors on two popular benchmarks PASCAL-${{5}^{i}}$ and COCO-${{20}^{i}}$. ",
    "url": "https://arxiv.org/abs/2210.00765",
    "authors": [
      "Hongsheng Wang",
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Jinqing Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00766",
    "title": "Dual Gradient Descent EMF-Aware MU-MIMO Beamforming in RIS-Aided 6G  Networks",
    "abstract": "Reconfigurable Intelligent Surface (RIS) is one of the key technologies for the upcoming 6th Generation (6G) communications, which can improve the signal strength at the receivers by adding artificial propagation paths. In the context of Downlink (DL) Multi-User Multiple-Input Multiple-Output (MU-MIMO) communications, designing an appropriate Beamforming (BF) scheme to take full advantage of this reconfigured propagation environment and improve the network capacity is a major challenge. Due to the spatial dimension provided by MIMO systems, independent data streams can be transmitted to multiple users simultaneously on the same radio resources. It is important to note that serving the same subset of users over a period of time may lead to undesired areas where the average Electromagnetic Field Exposure (EMFE) exceeds regulatory limits. To address this challenge, in this paper, we propose a Dual Gradient Descent (Dual-GD)-based Electromagnetic Field (EMF)-aware MU-MIMO BF scheme that aims to optimize the overall capacity under EMFE constraints in RIS-aided 6G cellular networks. ",
    "url": "https://arxiv.org/abs/2210.00766",
    "authors": [
      "Yi Yu",
      "Rita Ibrahim",
      "Dinh-Thuy Phan-Huy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.00767",
    "title": "Unsupervised Search Algorithm Configuration using Query Performance  Prediction",
    "abstract": "Search engine configuration can be quite difficult for inexpert developers. Instead, an auto-configuration approach can be used to speed up development time. Yet, such an automatic process usually requires relevance labels to train a supervised model. In this work, we suggest a simple solution based on query performance prediction that requires no relevance labels but only a sample of queries in a given domain. Using two example usecases we demonstrate the merits of our solution. ",
    "url": "https://arxiv.org/abs/2210.00767",
    "authors": [
      "Haggai Roitman"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00808",
    "title": "A Multi Camera Unsupervised Domain Adaptation Pipeline for Object  Detection in Cultural Sites through Adversarial Learning and Self-Training",
    "abstract": "Object detection algorithms allow to enable many interesting applications which can be implemented in different devices, such as smartphones and wearable devices. In the context of a cultural site, implementing these algorithms in a wearable device, such as a pair of smart glasses, allow to enable the use of augmented reality (AR) to show extra information about the artworks and enrich the visitors' experience during their tour. However, object detection algorithms require to be trained on many well annotated examples to achieve reasonable results. This brings a major limitation since the annotation process requires human supervision which makes it expensive in terms of time and costs. A possible solution to reduce these costs consist in exploiting tools to automatically generate synthetic labeled images from a 3D model of the site. However, models trained with synthetic data do not generalize on real images acquired in the target scenario in which they are supposed to be used. Furthermore, object detectors should be able to work with different wearable devices or different mobile devices, which makes generalization even harder. In this paper, we present a new dataset collected in a cultural site to study the problem of domain adaptation for object detection in the presence of multiple unlabeled target domains corresponding to different cameras and a labeled source domain obtained considering synthetic images for training purposes. We present a new domain adaptation method which outperforms current state-of-the-art approaches combining the benefits of aligning the domains at the feature and pixel level with a self-training process. We release the dataset at the following link https://iplab.dmi.unict.it/OBJ-MDA/ and the code of the proposed architecture at https://github.com/fpv-iplab/STMDA-RetinaNet. ",
    "url": "https://arxiv.org/abs/2210.00808",
    "authors": [
      "Giovanni Pasqualino",
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00825",
    "title": "Self-omics: A Self-supervised Learning Framework for Multi-omics Cancer  Data",
    "abstract": "We have gained access to vast amounts of multi-omics data thanks to Next Generation Sequencing. However, it is challenging to analyse this data due to its high dimensionality and much of it not being annotated. Lack of annotated data is a significant problem in machine learning, and Self-Supervised Learning (SSL) methods are typically used to deal with limited labelled data. However, there is a lack of studies that use SSL methods to exploit inter-omics relationships on unlabelled multi-omics data. In this work, we develop a novel and efficient pre-training paradigm that consists of various SSL components, including but not limited to contrastive alignment, data recovery from corrupted samples, and using one type of omics data to recover other omic types. Our pre-training paradigm improves performance on downstream tasks with limited labelled data. We show that our approach outperforms the state-of-the-art method in cancer type classification on the TCGA pan-cancer dataset in semi-supervised setting. Moreover, we show that the encoders that are pre-trained using our approach can be used as powerful feature extractors even without fine-tuning. Our ablation study shows that the method is not overly dependent on any pretext task component. The network architectures in our approach are designed to handle missing omic types and multiple datasets for pre-training and downstream training. Our pre-training paradigm can be extended to perform zero-shot classification of rare cancers. ",
    "url": "https://arxiv.org/abs/2210.00825",
    "authors": [
      "Sayed Hashim",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2210.00828",
    "title": "Mastering Spatial Graph Prediction of Road Networks",
    "abstract": "Accurately predicting road networks from satellite images requires a global understanding of the network topology. We propose to capture such high-level information by introducing a graph-based framework that simulates the addition of sequences of graph edges using a reinforcement learning (RL) approach. In particular, given a partially generated graph associated with a satellite image, an RL agent nominates modifications that maximize a cumulative reward. As opposed to standard supervised techniques that tend to be more restricted to commonly used surrogate losses, these rewards can be based on various complex, potentially non-continuous, metrics of interest. This yields more power and flexibility to encode problem-dependent knowledge. Empirical results on several benchmark datasets demonstrate enhanced performance and increased high-level reasoning about the graph topology when using a tree-based search. We further highlight the superiority of our approach under substantial occlusions by introducing a new synthetic benchmark dataset for this task. ",
    "url": "https://arxiv.org/abs/2210.00828",
    "authors": [
      "Sotiris Anagnostidis",
      "Aurelien Lucchi",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00842",
    "title": "A micromechanics-based recurrent neural networks model for  path-dependent cyclic deformation of short fiber composites",
    "abstract": "The macroscopic response of short fiber reinforced composites is dependent on an extensive range of microstructural parameters. Thus, micromechanical modeling of these materials is challenging and in some cases, computationally expensive. This is particularly important when path-dependent plastic behavior is needed to be predicted. A solution to this challenge is to enhance micromechanical solutions with machine learning techniques such as artificial neural networks. In this work, a recurrent deep neural network model is trained to predict the path-dependent elasto-plastic stress response of short fiber reinforced composites, given the microstructural parameters and the strain path. Micromechanical meanfield simulations are conducted to create a data base for training the validating the model. The model gives very accurate predictions in a computationally efficient manner when compared with independent micromechanical simulations. ",
    "url": "https://arxiv.org/abs/2210.00842",
    "authors": [
      "J. Friemann",
      "B. Dashtbozorg",
      "M. Fagerstr\u00f6m",
      "S.M. Mirkhalaf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.00848",
    "title": "I Speak, You Verify: Toward Trustworthy Neural Program Synthesis",
    "abstract": "We develop an approach for improving the trustworthiness and overall accuracy of program synthesizers based on large language models for source code. Given a natural language description of a programming problem, our method samples both candidate programs as well as candidate predicates specifying how the program should behave. We learn to analyze the agreement between programs and predicates to judge both which program is most likely to be correct, and also judge whether the language model is able to solve the programming problem in the first place. This latter capacity allows favoring high precision over broad recall: fostering trust by only proposing a program when the system is certain that it is correct. ",
    "url": "https://arxiv.org/abs/2210.00848",
    "authors": [
      "Darren Key",
      "Wen-Ding Li",
      "Kevin Ellis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.00853",
    "title": "Road Network Variation Based on HD Map Analysis for the Simulative  Safety Assurance of Automated Vehicles",
    "abstract": "The validation and verification of automated driving functions (ADFs) is a challenging task on the journey of making those functions available to the public beyond the current research context. Simulation is a valuable building block for scenario-based testing that can help to model traffic situations that are relevant for ADFs. In addition to the surrounding traffic and environment of the ADF under test, the logical description and automated generation of concrete road networks have an important role. We aim to reduce efforts for manual map generation and to improve the automated testing process during development. Hence, this paper proposes a method to analyze real road networks and extract relevant parameters for the variation of synthetic simulation maps that correspond to real-world properties. Consequently, characteristics for inner-city junctions are selected from Here HD map. Then, parameter distributions are determined, analyzed and used to generate variations of road networks in the OpenDRIVE standard. The presented methodology enables efficient road network modeling which can be used for large scale simulations. The developed road network generation tool is publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2210.00853",
    "authors": [
      "Daniel Becker",
      "Christian Geller",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.00854",
    "title": "Deep learning and multi-level featurization of graph representations of  microstructural data",
    "abstract": "Many material response functions depend strongly on microstructure, such as inhomogeneities in phase or orientation. Homogenization presents the task of predicting the mean response of a sample of the microstructure to external loading for use in subgrid models and structure-property explorations. Although many microstructural fields have obvious segmentations, learning directly from the graph induced by the segmentation can be difficult because this representation does not encode all the information of the full field. We develop a means of deep learning of hidden features on the reduced graph given the native discretization and a segmentation of the initial input field. The features are associated with regions represented as nodes on the reduced graph. This reduced representation is then the basis for the subsequent multi-level/scale graph convolutional network model. There are a number of advantages of reducing the graph before fully processing with convolutional layers it, such as interpretable features and efficiency on large meshes. We demonstrate the performance of the proposed network relative to convolutional neural networks operating directly on the native discretization of the data using three physical exemplars. ",
    "url": "https://arxiv.org/abs/2210.00854",
    "authors": [
      "Reese Jones",
      "Cosmin Safta",
      "Ari Frankel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00867",
    "title": "DRACo-SLAM: Distributed Robust Acoustic Communication-efficient SLAM for  Imaging Sonar Equipped Underwater Robot Teams",
    "abstract": "An essential task for a multi-robot system is generating a common understanding of the environment and relative poses between robots. Cooperative tasks can be executed only when a vehicle has knowledge of its own state and the states of the team members. However, this has primarily been achieved with direct rendezvous between underwater robots, via inter-robot ranging. We propose a novel distributed multi-robot simultaneous localization and mapping (SLAM) framework for underwater robots using imaging sonar-based perception. By passing only scene descriptors between robots, we do not need to pass raw sensor data unless there is a likelihood of inter-robot loop closure. We utilize pairwise consistent measurement set maximization (PCM), making our system robust to erroneous loop closures. The functionality of our system is demonstrated using two real-world datasets, one with three robots and another with two robots. We show that our system effectively estimates the trajectories of the multi-robot system and keeps the bandwidth requirements of inter-robot communication low. To our knowledge, this paper describes the first instance of multi-robot SLAM using real imaging sonar data (which we implement offline, using simulated communication). Code link: https://github.com/jake3991/DRACo-SLAM. ",
    "url": "https://arxiv.org/abs/2210.00867",
    "authors": [
      "John McConnell",
      "Yewei Huang",
      "Paul Szenher",
      "Ivana Collado-Gonzalez",
      "Brendan Englot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.00875",
    "title": "Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset  Copyright Protection",
    "abstract": "Deep neural networks (DNNs) have demonstrated their superiority in practice. Arguably, the rapid development of DNNs is largely benefited from high-quality (open-sourced) datasets, based on which researchers and developers can easily evaluate and improve their learning methods. Since the data collection is usually time-consuming or even expensive, how to protect their copyrights is of great significance and worth further exploration. In this paper, we revisit dataset ownership verification. We find that existing verification methods introduced new security risks in DNNs trained on the protected dataset, due to the targeted nature of poison-only backdoor watermarks. To alleviate this problem, in this work, we explore the untargeted backdoor watermarking scheme, where the abnormal model behaviors are not deterministic. Specifically, we introduce two dispersibilities and prove their correlation, based on which we design the untargeted backdoor watermark under both poisoned-label and clean-label settings. We also discuss how to use the proposed untargeted backdoor watermark for dataset ownership verification. Experiments on benchmark datasets verify the effectiveness of our methods and their resistance to existing backdoor defenses. Our codes are available at \\url{https://github.com/THUYimingLi/Untargeted_Backdoor_Watermark}. ",
    "url": "https://arxiv.org/abs/2210.00875",
    "authors": [
      "Yiming Li",
      "Yang Bai",
      "Yong Jiang",
      "Yong Yang",
      "Shu-Tao Xia",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00881",
    "title": "Predicting the Future of AI with AI: High-quality link prediction in an  exponentially growing knowledge network",
    "abstract": "A tool that could suggest new personalized research directions and ideas by taking insights from the scientific literature could significantly accelerate the progress of science. A field that might benefit from such an approach is artificial intelligence (AI) research, where the number of scientific publications has been growing exponentially over the last years, making it challenging for human researchers to keep track of the progress. Here, we use AI techniques to predict the future research directions of AI itself. We develop a new graph-based benchmark based on real-world data -- the Science4Cast benchmark, which aims to predict the future state of an evolving semantic network of AI. For that, we use more than 100,000 research papers and build up a knowledge network with more than 64,000 concept nodes. We then present ten diverse methods to tackle this task, ranging from pure statistical to pure learning methods. Surprisingly, the most powerful methods use a carefully curated set of network features, rather than an end-to-end AI approach. It indicates a great potential that can be unleashed for purely ML approaches without human knowledge. Ultimately, better predictions of new future research directions will be a crucial component of more advanced research suggestion tools. ",
    "url": "https://arxiv.org/abs/2210.00881",
    "authors": [
      "Mario Krenn",
      "Lorenzo Buffoni",
      "Bruno Coutinho",
      "Sagi Eppel",
      "Jacob Gates Foster",
      "Andrew Gritsevskiy",
      "Harlin Lee",
      "Yichao Lu",
      "Joao P. Moutinho",
      "Nima Sanjabi",
      "Rishi Sonthalia",
      "Ngoc Mai Tran",
      "Francisco Valente",
      "Yangxinyu Xie",
      "Rose Yu",
      "Michael Kopp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00891",
    "title": "Information Removal at the bottleneck in Deep Neural Networks",
    "abstract": "Deep learning models are nowadays broadly deployed to solve an incredibly large variety of tasks. Commonly, leveraging over the availability of \"big data\", deep neural networks are trained as black-boxes, minimizing an objective function at its output. This however does not allow control over the propagation of some specific features through the model, like gender or race, for solving some an uncorrelated task. This raises issues either in the privacy domain (considering the propagation of unwanted information) and of bias (considering that these features are potentially used to solve the given task). In this work we propose IRENE, a method to achieve information removal at the bottleneck of deep neural networks, which explicitly minimizes the estimated mutual information between the features to be kept ``private'' and the target. Experiments on a synthetic dataset and on CelebA validate the effectiveness of the proposed approach, and open the road towards the development of approaches guaranteeing information removal in deep neural networks. ",
    "url": "https://arxiv.org/abs/2210.00891",
    "authors": [
      "Enzo Tartaglione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00894",
    "title": "A Novel Explainable Out-of-Distribution Detection Approach for Spiking  Neural Networks",
    "abstract": "Research around Spiking Neural Networks has ignited during the last years due to their advantages when compared to traditional neural networks, including their efficient processing and inherent ability to model complex temporal dynamics. Despite these differences, Spiking Neural Networks face similar issues than other neural computation counterparts when deployed in real-world settings. This work addresses one of the practical circumstances that can hinder the trustworthiness of this family of models: the possibility of querying a trained model with samples far from the distribution of its training data (also referred to as Out-of-Distribution or OoD data). Specifically, this work presents a novel OoD detector that can identify whether test examples input to a Spiking Neural Network belong to the distribution of the data over which it was trained. For this purpose, we characterize the internal activations of the hidden layers of the network in the form of spike count patterns, which lay a basis for determining when the activations induced by a test instance is atypical. Furthermore, a local explanation method is devised to produce attribution maps revealing which parts of the input instance push most towards the detection of an example as an OoD sample. Experimental results are performed over several image classification datasets to compare the proposed detector to other OoD detection schemes from the literature. As the obtained results clearly show, the proposed detector performs competitively against such alternative schemes, and produces relevance attribution maps that conform to expectations for synthetically created OoD instances. ",
    "url": "https://arxiv.org/abs/2210.00894",
    "authors": [
      "Aitor Martinez Seras",
      "Javier Del Ser",
      "Jesus L. Lobo",
      "Pablo Garcia-Bringas",
      "Nikola Kasabov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00898",
    "title": "Robust $Q$-learning Algorithm for Markov Decision Processes under  Wasserstein Uncertainty",
    "abstract": "We present a novel $Q$-learning algorithm to solve distributionally robust Markov decision problems, where the corresponding ambiguity set of transition probabilities for the underlying Markov decision process is a Wasserstein ball around a (possibly estimated) reference measure. We prove convergence of the presented algorithm and provide several examples also using real data to illustrate both the tractability of our algorithm as well as the benefits of considering distributional robustness when solving stochastic optimal control problems, in particular when the estimated distributions turn out to be misspecified in practice. ",
    "url": "https://arxiv.org/abs/2210.00898",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.00910",
    "title": "Hypothesis Engineering for Zero-Shot Hate Speech Detection",
    "abstract": "Standard approaches to hate speech detection rely on sufficient available hate speech annotations. Extending previous work that repurposes natural language inference (NLI) models for zero-shot text classification, we propose a simple approach that combines multiple hypotheses to improve English NLI-based zero-shot hate speech detection. We first conduct an error analysis for vanilla NLI-based zero-shot hate speech detection and then develop four strategies based on this analysis. The strategies use multiple hypotheses to predict various aspects of an input text and combine these predictions into a final verdict. We find that the zero-shot baseline used for the initial error analysis already outperforms commercial systems and fine-tuned BERT-based hate speech detection models on HateCheck. The combination of the proposed strategies further increases the zero-shot accuracy of 79.4% on HateCheck by 7.9 percentage points (pp), and the accuracy of 69.6% on ETHOS by 10.0pp. ",
    "url": "https://arxiv.org/abs/2210.00910",
    "authors": [
      "Janis Goldzycher",
      "Gerold Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00918",
    "title": "Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based  Virtual Try-On",
    "abstract": "Previous virtual try-on methods usually focus on aligning a clothing item with a person, limiting their ability to exploit the complex pose, shape and skin color of the person, as well as the overall structure of the clothing, which is vital to photo-realistic virtual try-on. To address this potential weakness, we propose a fill in fabrics (FIFA) model, a self-supervised conditional generative adversarial network based framework comprised of a Fabricator and a unified virtual try-on pipeline with a Segmenter, Warper and Fuser. The Fabricator aims to reconstruct the clothing image when provided with a masked clothing as input, and learns the overall structure of the clothing by filling in fabrics. A virtual try-on pipeline is then trained by transferring the learned representations from the Fabricator to Warper in an effort to warp and refine the target clothing. We also propose to use a multi-scale structural constraint to enforce global context at multiple scales while warping the target clothing to better fit the pose and shape of the person. Extensive experiments demonstrate that our FIFA model achieves state-of-the-art results on the standard VITON dataset for virtual try-on of clothing items, and is shown to be effective at handling complex poses and retaining the texture and embroidery of the clothing. ",
    "url": "https://arxiv.org/abs/2210.00918",
    "authors": [
      "H. Zunair",
      "Y. Gobeil",
      "S. Mercier",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00920",
    "title": "Unbiased Scene Graph Generation using Predicate Similarities",
    "abstract": "Scene Graphs are widely applied in computer vision as a graphical representation of relationships between objects shown in images. However, these applications have not yet reached a practical stage of development owing to biased training caused by long-tailed predicate distributions. In recent years, many studies have tackled this problem. In contrast, relatively few works have considered predicate similarities as a unique dataset feature which also leads to the biased prediction. Due to the feature, infrequent predicates (e.g., parked on, covered in) are easily misclassified as closely-related frequent predicates (e.g., on, in). Utilizing predicate similarities, we propose a new classification scheme that branches the process to several fine-grained classifiers for similar predicate groups. The classifiers aim to capture the differences among similar predicates in detail. We also introduce the idea of transfer learning to enhance the features for the predicates which lack sufficient training samples to learn the descriptive representations. The results of extensive experiments on the Visual Genome dataset show that the combination of our method and an existing debiasing approach greatly improves performance on tail predicates in challenging SGCls/SGDet tasks. Nonetheless, the overall performance of the proposed approach does not reach that of the current state of the art, so further analysis remains necessary as future work. ",
    "url": "https://arxiv.org/abs/2210.00920",
    "authors": [
      "Misaki Ohashi",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00933",
    "title": "Perceptual Attacks of No-Reference Image Quality Models with  Human-in-the-Loop",
    "abstract": "No-reference image quality assessment (NR-IQA) aims to quantify how humans perceive visual distortions of digital images without access to their undistorted references. NR-IQA models are extensively studied in computational vision, and are widely used for performance evaluation and perceptual optimization of man-made vision systems. Here we make one of the first attempts to examine the perceptual robustness of NR-IQA models. Under a Lagrangian formulation, we identify insightful connections of the proposed perceptual attack to previous beautiful ideas in computer vision and machine learning. We test one knowledge-driven and three data-driven NR-IQA methods under four full-reference IQA models (as approximations to human perception of just-noticeable differences). Through carefully designed psychophysical experiments, we find that all four NR-IQA models are vulnerable to the proposed perceptual attack. More interestingly, we observe that the generated counterexamples are not transferable, manifesting themselves as distinct design flows of respective NR-IQA methods. ",
    "url": "https://arxiv.org/abs/2210.00933",
    "authors": [
      "Weixia Zhang",
      "Dingquan Li",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Guodong Guo",
      "Xiaokang Yang",
      "Kede Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.00941",
    "title": "Unsupervised Multimodal Change Detection Based on Structural  Relationship Graph Representation Learning",
    "abstract": "Unsupervised multimodal change detection is a practical and challenging topic that can play an important role in time-sensitive emergency applications. To address the challenge that multimodal remote sensing images cannot be directly compared due to their modal heterogeneity, we take advantage of two types of modality-independent structural relationships in multimodal images. In particular, we present a structural relationship graph representation learning framework for measuring the similarity of the two structural relationships. Firstly, structural graphs are generated from preprocessed multimodal image pairs by means of an object-based image analysis approach. Then, a structural relationship graph convolutional autoencoder (SR-GCAE) is proposed to learn robust and representative features from graphs. Two loss functions aiming at reconstructing vertex information and edge information are presented to make the learned representations applicable for structural relationship similarity measurement. Subsequently, the similarity levels of two structural relationships are calculated from learned graph representations and two difference images are generated based on the similarity levels. After obtaining the difference images, an adaptive fusion strategy is presented to fuse the two difference images. Finally, a morphological filtering-based postprocessing approach is employed to refine the detection results. Experimental results on five datasets with different modal combinations demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.00941",
    "authors": [
      "Hongruixuan Chen",
      "Naoto Yokoya",
      "Chen Wu",
      "Bo Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.00944",
    "title": "Attention Distillation: self-supervised vision transformer students need  more guidance",
    "abstract": "Self-supervised learning has been widely applied to train high-quality vision transformers. Unleashing their excellent performance on memory and compute constraint devices is therefore an important research topic. However, how to distill knowledge from one self-supervised ViT to another has not yet been explored. Moreover, the existing self-supervised knowledge distillation (SSKD) methods focus on ConvNet based architectures are suboptimal for ViT knowledge distillation. In this paper, we study knowledge distillation of self-supervised vision transformers (ViT-SSKD). We show that directly distilling information from the crucial attention mechanism from teacher to student can significantly narrow the performance gap between both. In experiments on ImageNet-Subset and ImageNet-1K, we show that our method AttnDistill outperforms existing self-supervised knowledge distillation (SSKD) methods and achieves state-of-the-art k-NN accuracy compared with self-supervised learning (SSL) methods learning from scratch (with the ViT-S model). We are also the first to apply the tiny ViT-T model on self-supervised learning. Moreover, AttnDistill is independent of self-supervised learning algorithms, it can be adapted to ViT based SSL methods to improve the performance in future research. The code is here: https://github.com/wangkai930418/attndistill ",
    "url": "https://arxiv.org/abs/2210.00944",
    "authors": [
      "Kai Wang",
      "Fei Yang",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00949",
    "title": "Module-wise Training of Residual Networks via the Minimizing Movement  Scheme",
    "abstract": "Greedy layer-wise or module-wise training of neural networks is compelling in constrained and on-device settings, as it circumvents a number of problems of end-to-end back-propagation. However, it suffers from a stagnation problem, whereby early layers overfit and deeper layers stop increasing the test accuracy after a certain depth. We propose to solve this issue by introducing a simple module-wise regularization inspired by the minimizing movement scheme for gradient flows in distribution space. The method, which we call TRGL for Transport Regularized Greedy Learning, is particularly well-adapted to residual networks. We study it theoretically, proving that it leads to greedy modules that are regular and that successively solve the task. Experimentally, we show improved accuracy of module-wise trained networks when our regularization is added. ",
    "url": "https://arxiv.org/abs/2210.00949",
    "authors": [
      "Skander Karkar",
      "Ibrahim Ayed",
      "Emmanuel de B\u00e9zenac",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00956",
    "title": "Minimizing Age of Processed Information in Wireless Networks",
    "abstract": "The freshness of real-time status processing of time-sensitive information is crucial for several applications, including healthcare monitoring and autonomous vehicles. This freshness is considered in this paper for the system where unprocessed information is sent from sensors to a base station over a shared wireless network. The base station has a dedicated non-preemptive processor with a constant processing time to process information from each sensor. The age of processed information is the time elapsed since the generation of the packet that was most recently processed by a processor. Our objective is to minimize the average age of processed information over an infinite time-horizon. We first show that a drop-free policy simplifies the system without sacrificing optimality. From this simplification, we propose three transmission-scheduling policies with 2-optimal guarantees for different requirements. A distributed Power-2 policy can be implemented without a central scheduler. With a central scheduler, both Back-Off and Max-Weight policies are near optimal with different advantages. The Back-Off policy guarantees a bound on the maximum age of processed information, while the Max-Weight policy achieves the lowest average age in simulation without the guarantee of bound. Simulation results confirm our theoretical findings. ",
    "url": "https://arxiv.org/abs/2210.00956",
    "authors": [
      "Chanikarn Nikunram",
      "Wasin Meesena",
      "Stephen John Turner",
      "Sucha Supittayapornpong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.00960",
    "title": "Stability Analysis and Generalization Bounds of Adversarial Training",
    "abstract": "In adversarial machine learning, deep neural networks can fit the adversarial examples on the training dataset but have poor generalization ability on the test set. This phenomenon is called robust overfitting, and it can be observed when adversarially training neural nets on common datasets, including SVHN, CIFAR-10, CIFAR-100, and ImageNet. In this paper, we study the robust overfitting issue of adversarial training by using tools from uniform stability. One major challenge is that the outer function (as a maximization of the inner function) is nonsmooth, so the standard technique (e.g., hardt et al., 2016) cannot be applied. Our approach is to consider $\\eta$-approximate smoothness: we show that the outer function satisfies this modified smoothness assumption with $\\eta$ being a constant related to the adversarial perturbation. Based on this, we derive stability-based generalization bounds for stochastic gradient descent (SGD) on the general class of $\\eta$-approximate smooth functions, which covers the adversarial loss. Our results provide a different understanding of robust overfitting from the perspective of uniform stability. Additionally, we show that a few popular techniques for adversarial training (\\emph{e.g.,} early stopping, cyclic learning rate, and stochastic weight averaging) are stability-promoting in theory. ",
    "url": "https://arxiv.org/abs/2210.00960",
    "authors": [
      "Jiancong Xiao",
      "Yanbo Fan",
      "Ruoyu Sun",
      "Jue Wang",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00968",
    "title": "Membership Inference Attacks Against Text-to-image Generation Models",
    "abstract": "Text-to-image generation models have recently attracted unprecedented attention as they unlatch imaginative applications in all areas of life. However, developing such models requires huge amounts of data that might contain privacy-sensitive information, e.g., face identity. While privacy risks have been extensively demonstrated in the image classification and GAN generation domains, privacy risks in the text-to-image generation domain are largely unexplored. In this paper, we perform the first privacy analysis of text-to-image generation models through the lens of membership inference. Specifically, we propose three key intuitions about membership information and design four attack methodologies accordingly. We conduct comprehensive evaluations on two mainstream text-to-image generation models including sequence-to-sequence modeling and diffusion-based modeling. The empirical results show that all of the proposed attacks can achieve significant performance, in some cases even close to an accuracy of 1, and thus the corresponding risk is much more severe than that shown by existing membership inference attacks. We further conduct an extensive ablation study to analyze the factors that may affect the attack performance, which can guide developers and researchers to be alert to vulnerabilities in text-to-image generation models. All these findings indicate that our proposed attacks pose a realistic privacy threat to the text-to-image generation models. ",
    "url": "https://arxiv.org/abs/2210.00968",
    "authors": [
      "Yixin Wu",
      "Ning Yu",
      "Zheng Li",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00979",
    "title": "Dissipative Imitation Learning for Robust Dynamic Output Feedback",
    "abstract": "Robust imitation learning seeks to mimic expert controller behavior while ensuring stability, but current methods require accurate plant models. Here, robust imitation learning is addressed for stabilizing poorly modeled plants with linear dynamic output feedback. Open-loop input-output properties are used to characterize an uncertain plant, and the feedback matrix of the dynamic controller is learned while enforcing stability through the controller's open-loop QSR-dissipativity properties. The imitation learning method is applied to two systems with parametric uncertainty. ",
    "url": "https://arxiv.org/abs/2210.00979",
    "authors": [
      "Amy K. Strong",
      "Ethan J. LoCicero",
      "Leila Bridgeman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.00992",
    "title": "Feature Embedding by Template Matching as a ResNet Block",
    "abstract": "Convolution blocks serve as local feature extractors and are the key to success of the neural networks. To make local semantic feature embedding rather explicit, we reformulate convolution blocks as feature selection according to the best matching kernel. In this manner, we show that typical ResNet blocks indeed perform local feature embedding via template matching once batch normalization (BN) followed by a rectified linear unit (ReLU) is interpreted as arg-max optimizer. Following this perspective, we tailor a residual block that explicitly forces semantically meaningful local feature embedding through using label information. Specifically, we assign a feature vector to each local region according to the classes that the corresponding region matches. We evaluate our method on three popular benchmark datasets with several architectures for image classification and consistently show that our approach substantially improves the performance of the baseline architectures. ",
    "url": "https://arxiv.org/abs/2210.00992",
    "authors": [
      "Ada Gorgun",
      "Yeti Z. Gurbuz",
      "A. Aydin Alatan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00993",
    "title": "Efficient Bayes Inference in Neural Networks through Adaptive Importance  Sampling",
    "abstract": "Bayesian neural networks (BNNs) have received an increased interest in the last years. In BNNs, a complete posterior distribution of the unknown weight and bias parameters of the network is produced during the training stage. This probabilistic estimation offers several advantages with respect to point-wise estimates, in particular, the ability to provide uncertainty quantification when predicting new data. This feature inherent to the Bayesian paradigm, is useful in countless machine learning applications. It is particularly appealing in areas where decision-making has a crucial impact, such as medical healthcare or autonomous driving. The main challenge of BNNs is the computational cost of the training procedure since Bayesian techniques often face a severe curse of dimensionality. Adaptive importance sampling (AIS) is one of the most prominent Monte Carlo methodologies benefiting from sounded convergence guarantees and ease for adaptation. This work aims to show that AIS constitutes a successful approach for designing BNNs. More precisely, we propose a novel algorithm PMCnet that includes an efficient adaptation mechanism, exploiting geometric information on the complex (often multimodal) posterior distribution. Numerical results illustrate the excellent performance and the improved exploration capabilities of the proposed method for both shallow and deep neural networks. ",
    "url": "https://arxiv.org/abs/2210.00993",
    "authors": [
      "Yunshi Huang",
      "Emilie Chouzenoux",
      "Victor Elvira",
      "Jean-Christophe Pesquet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01002",
    "title": "ASGNN: Graph Neural Networks with Adaptive Structure",
    "abstract": "The graph neural network (GNN) models have presented impressive achievements in numerous machine learning tasks. However, many existing GNN models are shown to be vulnerable to adversarial attacks, which creates a stringent need to build robust GNN architectures. In this work, we propose a novel interpretable message passing scheme with adaptive structure (ASMP) to defend against adversarial attacks on graph structure. Layers in ASMP are derived based on optimization steps that minimize an objective function that learns the node feature and the graph structure simultaneously. ASMP is adaptive in the sense that the message passing process in different layers is able to be carried out over dynamically adjusted graphs. Such property allows more fine-grained handling of the noisy (or perturbed) graph structure and hence improves the robustness. Convergence properties of the ASMP scheme are theoretically established. Integrating ASMP with neural networks can lead to a new family of GNN models with adaptive structure (ASGNN). Extensive experiments on semi-supervised node classification tasks demonstrate that the proposed ASGNN outperforms the state-of-the-art GNN architectures in terms of classification performance under various adversarial attacks. ",
    "url": "https://arxiv.org/abs/2210.01002",
    "authors": [
      "Zepeng Zhang",
      "Songtao Lu",
      "Zengfeng Huang",
      "Ziping Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01015",
    "title": "Robust Set Stability of Logic Dynamical Systems with respect to  Uncertain Switching",
    "abstract": "This paper proposes several definitions of robust stability for logic dynamical systems (LDSs) with uncertain switching, including robust/uniform robust set stability and asymptotical (or infinitely convergent)/finite-time set stability with ratio one. It is proved herein that an LDS is robustly set stable if and only if the destination set contains all loops (i.e., the paths from each state to itself); an LDS is uniformly robustly set stable, or finite-time set stable with ratio one, if and only if all states outside the destination set are unreachable from any self-reachable state; and an LDS is asymptotically set stable with ratio one if and only if the largest robustly invariant subset (LRIS) in the destination set is reachable from any state. In addition, it is proved that uniform robust set stability implies robust set stability, and robust set stability implies asymptotical set stability with ratio one. However, the inverse claims are not generally true. The relations between robust stability and stability under random switching are revealed, that is, the asymptotical/finite-time set stability with ratio one under uncertain switching is equivalent to asymptotical/finite-time set stability of the LDS under random switching. Furthermore, it is proved that, for uniform set stability and asymptotical/finite-time set stability with ratio one, the set stability is equivalent to the stability with respect to the LRIS in the destination set. However, robust set stability does not imply robust stability with respect to the LRIS in the destination set. This finding corrects a result in a previous study. ",
    "url": "https://arxiv.org/abs/2210.01015",
    "authors": [
      "Yuqian Guo",
      "Zhitao Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.01032",
    "title": "Hip Fracture Prediction using the First Principal Component Derived from  FEA-Computed Fracture Loads",
    "abstract": "Hip fracture risk assessment is an important but challenging task. Quantitative CT-based patient specific finite element analysis (FEA) computes the force (fracture load) to break the proximal femur in a particular loading condition. It provides different structural information about the proximal femur that can influence a subject overall fracture risk. To obtain a more robust measure of fracture risk, we used principal component analysis (PCA) to develop a global FEA computed fracture risk index that incorporates the FEA-computed yield and ultimate failure loads and energies to failure in four loading conditions (single-limb stance and impact from a fall onto the posterior, posterolateral, and lateral aspects of the greater trochanter) of 110 hip fracture subjects and 235 age and sex matched control subjects from the AGES-Reykjavik study. We found that the first PC (PC1) of the FE parameters was the only significant predictor of hip fracture. Using a logistic regression model, we determined if prediction performance for hip fracture using PC1 differed from that using FE parameters combined by stratified random resampling with respect to hip fracture status. The results showed that the average of the area under the receive operating characteristic curve (AUC) using PC1 was always higher than that using all FE parameters combined in the male subjects. The AUC of PC1 and AUC of the FE parameters combined were not significantly different than that in the female subjects or in all subjects ",
    "url": "https://arxiv.org/abs/2210.01032",
    "authors": [
      "Xuewei Cao",
      "Joyce H Keyak",
      "Sigurdur Sigurdsson",
      "Chen Zhao",
      "Weihua Zhou",
      "Anqi Liu",
      "Thomas Lang",
      "Hong-Wen Deng",
      "Vilmundur Gudnason",
      "Qiuying Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.01035",
    "title": "Expediting Large-Scale Vision Transformer for Dense Prediction without  Fine-tuning",
    "abstract": "Vision transformers have recently achieved competitive results across various vision tasks but still suffer from heavy computation costs when processing a large number of tokens. Many advanced approaches have been developed to reduce the total number of tokens in large-scale vision transformers, especially for image classification tasks. Typically, they select a small group of essential tokens according to their relevance with the class token, then fine-tune the weights of the vision transformer. Such fine-tuning is less practical for dense prediction due to the much heavier computation and GPU memory cost than image classification. In this paper, we focus on a more challenging problem, i.e., accelerating large-scale vision transformers for dense prediction without any additional re-training or fine-tuning. In response to the fact that high-resolution representations are necessary for dense prediction, we present two non-parametric operators, a token clustering layer to decrease the number of tokens and a token reconstruction layer to increase the number of tokens. The following steps are performed to achieve this: (i) we use the token clustering layer to cluster the neighboring tokens together, resulting in low-resolution representations that maintain the spatial structures; (ii) we apply the following transformer layers only to these low-resolution representations or clustered tokens; and (iii) we use the token reconstruction layer to re-create the high-resolution representations from the refined low-resolution representations. The results obtained by our method are promising on five dense prediction tasks, including object detection, semantic segmentation, panoptic segmentation, instance segmentation, and depth estimation. ",
    "url": "https://arxiv.org/abs/2210.01035",
    "authors": [
      "Weicong Liang",
      "Yuhui Yuan",
      "Henghui Ding",
      "Xiao Luo",
      "Weihong Lin",
      "Ding Jia",
      "Zheng Zhang",
      "Chao Zhang",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01075",
    "title": "Decompiling x86 Deep Neural Network Executables",
    "abstract": "Due to their widespread use on heterogeneous hardware devices, deep learning (DL) models are compiled into executables by DL compilers to fully leverage low-level hardware primitives. This approach allows DL computations to be undertaken at low cost across a variety of computing platforms, including CPUs, GPUs, and various hardware accelerators. We present BTD (Bin to DNN), a decompiler for deep neural network (DNN) executables. BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters that are (nearly) identical to those of the input models. BTD delivers a practical framework to process DNN executables compiled by different DL compilers and with full optimizations enabled on x86 platforms. It employs learning-based techniques to infer DNN operators, dynamic analysis to reveal network architectures, and symbolic execution to facilitate inferring dimensions and parameters of DNN operators. Our evaluation reveals that BTD enables accurate recovery of full specifications of complex DNNs with millions of parameters (e.g., ResNet). The recovered DNN specifications can be re-compiled into a new DNN executable exhibiting identical behavior to the input executable. We show that BTD can boost two representative attacks, adversarial example generation and knowledge stealing, against DNN executables. We also demonstrate cross-architecture legacy code reuse using BTD, and envision BTD being used for other critical downstream tasks like DNN security hardening and patching. ",
    "url": "https://arxiv.org/abs/2210.01075",
    "authors": [
      "Zhibo Liu",
      "Yuanyuan Yuan",
      "Shuai Wang",
      "Xiaofei Xie",
      "Lei Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01077",
    "title": "Improving Convolutional Neural Networks for Fault Diagnosis by  Assimilating Global Features",
    "abstract": "Deep learning techniques have become prominent in modern fault diagnosis for complex processes. In particular, convolutional neural networks (CNNs) have shown an appealing capacity to deal with multivariate time-series data by converting them into images. However, existing CNN techniques mainly focus on capturing local or multi-scale features from input images. A deep CNN is often required to indirectly extract global features, which are critical to describe the images converted from multivariate dynamical data. This paper proposes a novel local-global CNN (LG-CNN) architecture that directly accounts for both local and global features for fault diagnosis. Specifically, the local features are acquired by traditional local kernels whereas global features are extracted by using 1D tall and fat kernels that span the entire height and width of the image. Both local and global features are then merged for classification using fully-connected layers. The proposed LG-CNN is validated on the benchmark Tennessee Eastman process (TEP) dataset. Comparison with traditional CNN shows that the proposed LG-CNN can greatly improve the fault diagnosis performance without significantly increasing the model complexity. This is attributed to the much wider local receptive field created by the LG-CNN than that by CNN. The proposed LG-CNN architecture can be easily extended to other image processing and computer vision tasks. ",
    "url": "https://arxiv.org/abs/2210.01077",
    "authors": [
      "Saif S. S. Al-Wahaibi",
      "Qiugang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.01078",
    "title": "Unsupervised Model Selection for Time-series Anomaly Detection",
    "abstract": "Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question i.e. Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, prediction error, model centrality, and performance on injected synthetic anomalies, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data. ",
    "url": "https://arxiv.org/abs/2210.01078",
    "authors": [
      "Mononito Goswami",
      "Cristian Challu",
      "Laurent Callot",
      "Lenon Minorics",
      "Andrey Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01090",
    "title": "Nonstationary data stream classification with online active learning and  siamese neural networks",
    "abstract": "We have witnessed in recent years an ever-growing volume of information becoming available in a streaming manner in various application areas. As a result, there is an emerging need for online learning methods that train predictive models on-the-fly. A series of open challenges, however, hinder their deployment in practice. These are, learning as data arrive in real-time one-by-one, learning from data with limited ground truth information, learning from nonstationary data, and learning from severely imbalanced data, while occupying a limited amount of memory for data storage. We propose the ActiSiamese algorithm, which addresses these challenges by combining online active learning, siamese networks, and a multi-queue memory. It develops a new density-based active learning strategy which considers similarity in the latent (rather than the input) space. We conduct an extensive study that compares the role of different active learning budgets and strategies, the performance with/without memory, the performance with/without ensembling, in both synthetic and real-world datasets, under different data nonstationarity characteristics and class imbalance levels. ActiSiamese outperforms baseline and state-of-the-art algorithms, and is effective under severe imbalance, even only when a fraction of the arriving instances' labels is available. We publicly release our code to the community. ",
    "url": "https://arxiv.org/abs/2210.01090",
    "authors": [
      "Kleanthis Malialis",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01111",
    "title": "MultiGuard: Provably Robust Multi-label Classification against  Adversarial Examples",
    "abstract": "Multi-label classification, which predicts a set of labels for an input, has many applications. However, multiple recent studies showed that multi-label classification is vulnerable to adversarial examples. In particular, an attacker can manipulate the labels predicted by a multi-label classifier for an input via adding carefully crafted, human-imperceptible perturbation to it. Existing provable defenses for multi-class classification achieve sub-optimal provable robustness guarantees when generalized to multi-label classification. In this work, we propose MultiGuard, the first provably robust defense against adversarial examples to multi-label classification. Our MultiGuard leverages randomized smoothing, which is the state-of-the-art technique to build provably robust classifiers. Specifically, given an arbitrary multi-label classifier, our MultiGuard builds a smoothed multi-label classifier via adding random noise to the input. We consider isotropic Gaussian noise in this work. Our major theoretical contribution is that we show a certain number of ground truth labels of an input are provably in the set of labels predicted by our MultiGuard when the $\\ell_2$-norm of the adversarial perturbation added to the input is bounded. Moreover, we design an algorithm to compute our provable robustness guarantees. Empirically, we evaluate our MultiGuard on VOC 2007, MS-COCO, and NUS-WIDE benchmark datasets. Our code is available at: \\url{https://github.com/quwenjie/MultiGuard} ",
    "url": "https://arxiv.org/abs/2210.01111",
    "authors": [
      "Jinyuan Jia",
      "Wenjie Qu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00042",
    "title": "Direct Estimation of Porosity from Seismic Data using Rock and Wave  Physics Informed Neural Networks (RW-PINN)",
    "abstract": "Petrophysical inversion is an important aspect of reservoir modeling. However due to the lack of a unique and straightforward relationship between seismic traces and rock properties, predicting petrophysical properties directly from seismic data is a complex task. Many studies have attempted to identify the direct end-to-end link using supervised machine learning techniques, but face different challenges such as a lack of large petrophysical training dataset or estimates that may not conform with physics or depositional history of the rocks. We present a rock and wave physics informed neural network (RW-PINN) model that can estimate porosity directly from seismic image traces with no or limited number of wells, with predictions that are consistent with rock physics and geologic knowledge of deposition. As an example, we use the uncemented sand rock physics model and normal-incidence wave physics to guide the learning of RW-PINN to eventually get good estimates of porosities from normal-incidence seismic traces and limited well data. Training RW-PINN with few wells (weakly supervised) helps in tackling the problem of non-uniqueness as different porosity logs can give similar seismic traces. We use weighted normalized root mean square error loss function to train the weakly supervised network and demonstrate the impact of different weights on porosity predictions. The RW-PINN estimated porosities and seismic traces are compared to predictions from a completely supervised model, which gives slightly better porosity estimates but poorly matches the seismic traces, in addition to requiring a large amount of labeled training data. In this paper, we demonstrate the complete workflow for executing petrophysical inversion of seismic data using self-supervised or weakly supervised rock physics informed neural networks. ",
    "url": "https://arxiv.org/abs/2210.00042",
    "authors": [
      "Divakar Vashisth",
      "Tapan Mukerji"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00050",
    "title": "Distributionally Robust Covariance Steering with Optimal Risk Allocation",
    "abstract": "This article extends the optimal covariance steering (CS) problem for discrete time linear stochastic systems modeled using moment-based ambiguity sets. To hedge against the uncertainty in the state distributions while performing covariance steering, distributionally robust risk constraints are employed during the optimal allocation of the risk. Specifically, a distributionally robust iterative risk allocation (DR-IRA) formalism is used to solve the optimal risk allocation problem for the CS problem using a two-stage approach. The upper-stage of DR-IRA is a convex problem that optimizes the risk, while the lower-stage optimizes the controller with the new distributionally robust risk constraints. The proposed framework results in solutions that are robust against arbitrary distributions in the considered ambiguity set. Finally, we demonstrate our proposed approach using numerical simulations. Addressing the covariance steering problem through the lens of distributional robustness marks the novel contribution of this article. ",
    "url": "https://arxiv.org/abs/2210.00050",
    "authors": [
      "Venkatraman Renganathan",
      "Joshua Pilipovsky",
      "Panagiotis Tsoitras"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.00079",
    "title": "Causal Estimation for Text Data with (Apparent) Overlap Violations",
    "abstract": "Consider the problem of estimating the causal effect of some attribute of a text document; for example: what effect does writing a polite vs. rude email have on response time? To estimate a causal effect from observational data, we need to adjust for confounding aspects of the text that affect both the treatment and outcome -- e.g., the topic or writing level of the text. These confounding aspects are unknown a priori, so it seems natural to adjust for the entirety of the text (e.g., using a transformer). However, causal identification and estimation procedures rely on the assumption of overlap: for all levels of the adjustment variables, there is randomness leftover so that every unit could have (not) received treatment. Since the treatment here is itself an attribute of the text, it is perfectly determined, and overlap is apparently violated. The purpose of this paper is to show how to handle causal identification and obtain robust causal estimation in the presence of apparent overlap violations. In brief, the idea is to use supervised representation learning to produce a data representation that preserves confounding information while eliminating information that is only predictive of the treatment. This representation then suffices for adjustment and can satisfy overlap. Adapting results on non-parametric estimation, we find that this procedure is robust to conditional outcome misestimation, yielding a low-bias estimator with valid uncertainty quantification under weak conditions. Empirical results show strong improvements in bias and uncertainty quantification relative to the natural baseline. ",
    "url": "https://arxiv.org/abs/2210.00079",
    "authors": [
      "Lin Gui",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00158",
    "title": "Local and global expansion in random geometric graphs",
    "abstract": "Consider a random geometric 2-dimensional simplicial complex $X$ sampled as follows: first, sample $n$ vectors $\\boldsymbol{u_1},\\ldots,\\boldsymbol{u_n}$ uniformly at random on $\\mathbb{S}^{d-1}$; then, for each triple $i,j,k \\in [n]$, add $\\{i,j,k\\}$ and all of its subsets to $X$ if and only if $\\langle{\\boldsymbol{u_i},\\boldsymbol{u_j}}\\rangle \\ge \\tau, \\langle{\\boldsymbol{u_i},\\boldsymbol{u_k}}\\rangle \\ge \\tau$, and $\\langle \\boldsymbol{u_j}, \\boldsymbol{u_k}\\rangle \\ge \\tau$. We prove that for every $\\varepsilon > 0$, there exists a choice of $d = \\Theta(\\log n)$ and $\\tau = \\tau(\\varepsilon,d)$ so that with high probability, $X$ is a high-dimensional expander of average degree $n^\\varepsilon$ in which each $1$-link has spectral gap bounded away from $\\frac{1}{2}$. To our knowledge, this is the first demonstration of a natural distribution over $2$-dimensional expanders of arbitrarily small polynomial average degree and spectral link expansion better than $\\frac{1}{2}$. All previously known constructions are algebraic. This distribution also furnishes an example of simplicial complexes for which the trickle-down theorem is nearly tight. En route, we prove general bounds on the spectral expansion of random induced subgraphs of arbitrary vertex transitive graphs, which may be of independent interest. For example, one consequence is an almost-sharp bound on the second eigenvalue of random $n$-vertex geometric graphs on $\\mathbb{S}^{d-1}$, which was previously unknown for most $n,d$ pairs. ",
    "url": "https://arxiv.org/abs/2210.00158",
    "authors": [
      "Siqi Liu",
      "Sidhanth Mohanty",
      "Tselil Schramm",
      "Elizabeth Yang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2210.00353",
    "title": "Sustained oscillations in multi-topic belief dynamics over signed  networks",
    "abstract": "We study the dynamics of belief formation on multiple interconnected topics in networks of agents with a shared belief system. We establish sufficient conditions and necessary conditions under which sustained oscillations of beliefs arise on the network in a Hopf bifurcation and characterize the role of the communication graph and the belief system graph in shaping the relative phase and amplitude patterns of the oscillations. ",
    "url": "https://arxiv.org/abs/2210.00353",
    "authors": [
      "Anastasia Bizyaeva",
      "Alessio Franci",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.00367",
    "title": "A Comparison of Transformer, Convolutional, and Recurrent Neural  Networks on Phoneme Recognition",
    "abstract": "Phoneme recognition is a very important part of speech recognition that requires the ability to extract phonetic features from multiple frames. In this paper, we compare and analyze CNN, RNN, Transformer, and Conformer models using phoneme recognition. For CNN, the ContextNet model is used for the experiments. First, we compare the accuracy of various architectures under different constraints, such as the receptive field length, parameter size, and layer depth. Second, we interpret the performance difference of these models, especially when the observable sequence length varies. Our analyses show that Transformer and Conformer models benefit from the long-range accessibility of self-attention through input frames. ",
    "url": "https://arxiv.org/abs/2210.00367",
    "authors": [
      "Kyuhong Shim",
      "Wonyong Sung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00376",
    "title": "Convolutional Neural Networks on Manifolds: From Graphs and Back",
    "abstract": "Geometric deep learning has gained much attention in recent years due to more available data acquired from non-Euclidean domains. Some examples include point clouds for 3D models and wireless sensor networks in communications. Graphs are common models to connect these discrete data points and capture the underlying geometric structure. With the large amount of these geometric data, graphs with arbitrarily large size tend to converge to a limit model -- the manifold. Deep neural network architectures have been proved as a powerful technique to solve problems based on these data residing on the manifold. In this paper, we propose a manifold neural network (MNN) composed of a bank of manifold convolutional filters and point-wise nonlinearities. We define a manifold convolution operation which is consistent with the discrete graph convolution by discretizing in both space and time domains. To sum up, we focus on the manifold model as the limit of large graphs and construct MNNs, while we can still bring back graph neural networks by the discretization of MNNs. We carry out experiments based on point-cloud dataset to showcase the performance of our proposed MNNs. ",
    "url": "https://arxiv.org/abs/2210.00376",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00383",
    "title": "Conditions for minimally tough graphs",
    "abstract": "Katona, Solt\\'esz, and Varga showed that no induced subgraph can be excluded from the class of minimally tough graphs. In this paper, we consider the opposite question, namely which induced subgraphs, if any, must necessarily be present in each minimally $t$-tough graph. Katona and Varga showed that for any rational number $t \\in (1/2,1]$, every minimally $t$-tough graph contains a hole. We complement this result by showing that for any rational number $t>1$, every minimally $t$-tough graph must contain either a hole or an induced subgraph isomorphic to the $k$-sun for some integer $k \\ge 3$. We also show that for any rational number $t > 1/2$, every minimally $t$-tough graph must contain either an induced $4$-cycle, an induced $5$-cycle, or two independent edges as an induced subgraph. ",
    "url": "https://arxiv.org/abs/2210.00383",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Blas Fern\u00e1ndez",
      "Gyula Y. Katona",
      "Martin Milani\u010d",
      "Kitti Varga"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.00407",
    "title": "PCONet: A Convolutional Neural Network Architecture to Detect Polycystic  Ovary Syndrome (PCOS) from Ovarian Ultrasound Images",
    "abstract": "Polycystic Ovary Syndrome (PCOS) is an endrocrinological dysfunction prevalent among women of reproductive age. PCOS is a combination of syndromes caused by an excess of androgens - a group of sex hormones - in women. Syndromes including acne, alopecia, hirsutism, hyperandrogenaemia, oligo-ovulation, etc. are caused by PCOS. It is also a major cause of female infertility. An estimated 15% of reproductive-aged women are affected by PCOS globally. The necessity of detecting PCOS early due to the severity of its deleterious effects cannot be overstated. In this paper, we have developed PCONet - a Convolutional Neural Network (CNN) - to detect polycistic ovary from ovarian ultrasound images. We have also fine tuned InceptionV3 - a pretrained convolutional neural network of 45 layers - by utilizing the transfer learning method to classify polcystic ovarian ultrasound images. We have compared these two models on various quantitative performance evaluation parameters and demonstrated that PCONet is the superior one among these two with an accuracy of 98.12%, whereas the fine tuned InceptionV3 showcased an accuracy of 96.56% on test images. ",
    "url": "https://arxiv.org/abs/2210.00407",
    "authors": [
      "A.K.M. Salman Hosain",
      "Md Humaion Kabir Mehedi",
      "Irteza Enan Kabir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00437",
    "title": "A Unified Framework for Optimization-Based Graph Coarsening",
    "abstract": "Graph coarsening is a widely used dimensionality reduction technique for approaching large-scale graph machine learning problems. Given a large graph, graph coarsening aims to learn a smaller-tractable graph while preserving the properties of the originally given graph. Graph data consist of node features and graph matrix (e.g., adjacency and Laplacian). The existing graph coarsening methods ignore the node features and rely solely on a graph matrix to simplify graphs. In this paper, we introduce a novel optimization-based framework for graph dimensionality reduction. The proposed framework lies in the unification of graph learning and dimensionality reduction. It takes both the graph matrix and the node features as the input and learns the coarsen graph matrix and the coarsen feature matrix jointly while ensuring desired properties. The proposed optimization formulation is a multi-block non-convex optimization problem, which is solved efficiently by leveraging block majorization-minimization, $\\log$ determinant, Dirichlet energy, and regularization frameworks. The proposed algorithms are provably convergent and practically amenable to numerous tasks. It is also established that the learned coarsened graph is $\\epsilon\\in(0,1)$ similar to the original graph. Extensive experiments elucidate the efficacy of the proposed framework for real-world applications. ",
    "url": "https://arxiv.org/abs/2210.00437",
    "authors": [
      "Manoj Kumar",
      "Anurag Sharma",
      "Sandeep Kumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.00506",
    "title": "Loc-VAE: Learning Structurally Localized Representation from 3D Brain MR  Images for Content-Based Image Retrieval",
    "abstract": "Content-based image retrieval (CBIR) systems are an emerging technology that supports reading and interpreting medical images. Since 3D brain MR images are high dimensional, dimensionality reduction is necessary for CBIR using machine learning techniques. In addition, for a reliable CBIR system, each dimension in the resulting low-dimensional representation must be associated with a neurologically interpretable region. We propose a localized variational autoencoder (Loc-VAE) that provides neuroanatomically interpretable low-dimensional representation from 3D brain MR images for clinical CBIR. Loc-VAE is based on $\\beta$-VAE with the additional constraint that each dimension of the low-dimensional representation corresponds to a local region of the brain. The proposed Loc-VAE is capable of acquiring representation that preserves disease features and is highly localized, even under high-dimensional compression ratios (4096:1). The low-dimensional representation obtained by Loc-VAE improved the locality measure of each dimension by 4.61 points compared to naive $\\beta$-VAE, while maintaining comparable brain reconstruction capability and information about the diagnosis of Alzheimer's disease. ",
    "url": "https://arxiv.org/abs/2210.00506",
    "authors": [
      "Kei Nishimaki",
      "Kumpei Ikuta",
      "Yuto Onga",
      "Hitoshi Iyatomi",
      "Kenichi Oishi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.00520",
    "title": "Periodic orbits in evolutionary game dynamics: An information-theoretic  perspective",
    "abstract": "Even though existence of non-convergent evolution of the states of populations in ecological and evolutionary contexts is an undeniable fact, insightful game-theoretic interpretations of such outcomes are scarce in the literature of evolutionary game theory. Here we tap into the information-theoretic concept of relative entropy in order to construct a game-theoretic interpretation for periodic orbits in a wide class of evolutionary game dynamics. Effectively, we present a consistent generalization of the evolutionarily stable strategy-the cornerstone of the evolutionary game theory-and aptly term the generalized concept: information stable orbit. The information stable orbit captures the essence of the evolutionarily stable strategy in that it compares the total payoff obtained against an evolving mutant with the total payoff that the mutant gets while playing against itself. Furthermore, we discuss the connection of the information stable orbit with the dynamical stability of the corresponding periodic orbit. ",
    "url": "https://arxiv.org/abs/2210.00520",
    "authors": [
      "Sayak Bhattacharjee",
      "Vikash Kumar Dubey",
      "Archan Mukhopadhyay",
      "Sagar Chakraborty"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Information Theory (cs.IT)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2210.00623",
    "title": "Inability of a graph neural network heuristic to outperform greedy  algorithms in solving combinatorial optimization problems like Max-Cut",
    "abstract": "In Nature Machine Intelligence 4, 367 (2022), Schuetz et al provide a scheme to employ graph neural networks (GNN) as a heuristic to solve a variety of classical, NP-hard combinatorial optimization problems. It describes how the network is trained on sample instances and the resulting GNN heuristic is evaluated applying widely used techniques to determine its ability to succeed. Clearly, the idea of harnessing the powerful abilities of such networks to ``learn'' the intricacies of complex, multimodal energy landscapes in such a hands-off approach seems enticing. And based on the observed performance, the heuristic promises to be highly scalable, with a computational cost linear in the input size $n$, although there is likely a significant overhead in the pre-factor due to the GNN itself. However, closer inspection shows that the reported results for this GNN are only minutely better than those for gradient descent and get outperformed by a greedy algorithm, for example, for Max-Cut. The discussion also highlights what I believe are some common misconceptions in the evaluations of heuristics. ",
    "url": "https://arxiv.org/abs/2210.00623",
    "authors": [
      "Stefan Boettcher"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.00688",
    "title": "On the infinite-depth limit of finite-width neural networks",
    "abstract": "In this paper, we study the infinite-depth limit of finite-width residual neural networks with random Gaussian weights. With proper scaling, we show that by fixing the width and taking the depth to infinity, the vector of pre-activations converges in distribution to a zero-drift diffusion process. Unlike the infinite-width limit where the pre-activation converge weakly to a Gaussian random variable, we show that the infinite-depth limit yields different distributions depending on the choice of the activation function. We document two cases where these distributions have closed-form (different) expressions. We further show an intriguing phase-transition phenomenon of the post-activation norms when the width increases from 3 to 4. Lastly, we study the sequential limit infinite-depth-then-infinite-width, and show some key differences with the more commonly studied infinite-width-then-infinite-depth limit. ",
    "url": "https://arxiv.org/abs/2210.00688",
    "authors": [
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.00695",
    "title": "Automated Performance Estimation for Decentralized Optimization via  Network Size Independent Problems",
    "abstract": "We develop a novel formulation of the Performance Estimation Problem (PEP) for decentralized optimization whose size is independent of the number of agents in the network. The PEP approach allows computing automatically the worst-case performance and worst-case instance of first-order optimization methods by solving an SDP. Unlike previous work, the size of our new PEP formulation is independent of the network size. For this purpose, we take a global view of the decentralized problem and we also decouple the consensus subspace and its orthogonal complement. We apply our methodology to different decentralized methods such as DGD, DIGing and EXTRA and obtain numerically tight performance guarantees that are valid for any network size. ",
    "url": "https://arxiv.org/abs/2210.00695",
    "authors": [
      "Sebastien Colla",
      "Julien M. Hendrickx"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.00802",
    "title": "DDoS: A Graph Neural Network based Drug Synergy Prediction Algorithm",
    "abstract": "Background: Drug synergy occurs when the combined effect of two drugs is greater than the sum of the individual drugs' effect. While cell line data measuring the effect of single drugs are readily available, there is relatively less comparable data on drug synergy given the vast amount of possible drug combinations. Thus, there is interest to use computational approaches to predict drug synergy for untested pairs of drugs. Methods: We introduce a Graph Neural Network (GNN) based model for drug synergy prediction, which utilizes drug chemical structures and cell line gene expression data. We use information from the largest drug combination database available (DrugComb), combining drug synergy scores in order to construct high confidence benchmark datasets. Results: Our proposed solution for drug synergy predictions offers a number of benefits: 1) It is trained on high confidence benchmark dataset. 2) It utilizes 34 distinct drug synergy datasets to learn on a wide variety of drugs and cell lines representations. 3) It learns task-specific drug representations, instead of relying on generalized and pre-computed chemical drug features. 4) It achieves similar or better prediction performance (AUPR scores ranging from 0.777 to 0.964) compared to state-of-the-art baseline models when tested on various benchmark datasets. Conclusions: We demonstrate that a GNN based model can provide state-of-the-art drug synergy predictions by learning task-specific representations of drugs. ",
    "url": "https://arxiv.org/abs/2210.00802",
    "authors": [
      "Kyriakos Schwarz",
      "Alicia Pliego-Mendieta",
      "Lara Planas-Paz",
      "Chantal Pauli",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.00824",
    "title": "Random Data Augmentation based Enhancement: A Generalized Enhancement  Approach for Medical Datasets",
    "abstract": "Over the years, the paradigm of medical image analysis has shifted from manual expertise to automated systems, often using deep learning (DL) systems. The performance of deep learning algorithms is highly dependent on data quality. Particularly for the medical domain, it is an important aspect as medical data is very sensitive to quality and poor quality can lead to misdiagnosis. To improve the diagnostic performance, research has been done both in complex DL architectures and in improving data quality using dataset dependent static hyperparameters. However, the performance is still constrained due to data quality and overfitting of hyperparameters to a specific dataset. To overcome these issues, this paper proposes random data augmentation based enhancement. The main objective is to develop a generalized, data-independent and computationally efficient enhancement approach to improve medical data quality for DL. The quality is enhanced by improving the brightness and contrast of images. In contrast to the existing methods, our method generates enhancement hyperparameters randomly within a defined range, which makes it robust and prevents overfitting to a specific dataset. To evaluate the generalization of the proposed method, we use four medical datasets and compare its performance with state-of-the-art methods for both classification and segmentation tasks. For grayscale imagery, experiments have been performed with: COVID-19 chest X-ray, KiTS19, and for RGB imagery with: LC25000 datasets. Experimental results demonstrate that with the proposed enhancement methodology, DL architectures outperform other existing methods. Our code is publicly available at: https://github.com/aleemsidra/Augmentation-Based-Generalized-Enhancement ",
    "url": "https://arxiv.org/abs/2210.00824",
    "authors": [
      "Sidra Aleem",
      "Teerath Kumar",
      "Suzanne Little",
      "Malika Bendechache",
      "Rob Brennan",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00870",
    "title": "Multiclass Sentiment Prediction for Stock Trading",
    "abstract": "Python was used to download and format NewsAPI article data relating to 400 publicly traded, low cap. Biotech companies. Crowd-sourcing was used to label a subset of this data to then train and evaluate a variety of models to classify the public sentiment of each company. The best performing models were then used to show that trading entirely off public sentiment could provide market beating returns. ",
    "url": "https://arxiv.org/abs/2210.00870",
    "authors": [
      "Marshall R. McCraw"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00874",
    "title": "Stability Via Adversarial Training of Neural Network Stochastic Control  of Mean-Field Type",
    "abstract": "In this paper, we present an approach to neural network mean-field-type control and its stochastic stability analysis by means of adversarial inputs (aka adversarial attacks). This is a class of data-driven mean-field-type control where the distribution of the variables such as the system states and control inputs are incorporated into the problem. Besides, we present a methodology to validate the feasibility of the approximations of the solutions via neural networks and evaluate their stability. Moreover, we enhance the stability by enlarging the training set with adversarial inputs to obtain a more robust neural network. Finally, a worked-out example based on the linear-quadratic mean-field type control problem (LQ-MTC) is presented to illustrate our methodology. ",
    "url": "https://arxiv.org/abs/2210.00874",
    "authors": [
      "Julian Barreiro-Gomez",
      "Salah Eddine Choutri",
      "Boualem Djehiche"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.00876",
    "title": "Embedding-based neural network for investment return prediction",
    "abstract": "In addition to being familiar with policies, high investment returns also require extensive knowledge of relevant industry knowledge and news. In addition, it is necessary to leverage relevant theories for investment to make decisions, thereby amplifying investment returns. A effective investment return estimate can feedback the future rate of return of investment behavior. In recent years, deep learning are developing rapidly, and investment return prediction based on deep learning has become an emerging research topic. This paper proposes an embedding-based dual branch approach to predict an investment's return. This approach leverages embedding to encode the investment id into a low-dimensional dense vector, thereby mapping high-dimensional data to a low-dimensional manifold, so that highdimensional features can be represented competitively. In addition, the dual branch model realizes the decoupling of features by separately encoding different information in the two branches. In addition, the swish activation function further improves the model performance. Our approach are validated on the Ubiquant Market Prediction dataset. The results demonstrate the superiority of our approach compared to Xgboost, Lightgbm and Catboost. ",
    "url": "https://arxiv.org/abs/2210.00876",
    "authors": [
      "Jianlong Zhu",
      "Dan Xian",
      "Fengxiao",
      "Yichen Nie"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01006",
    "title": "Neural network for determining an asteroid mineral composition from  reflectance spectra",
    "abstract": "Chemical and mineral compositions of asteroids reflect the formation and history of our Solar System. This knowledge is also important for planetary defence and in-space resource utilisation. We aim to develop a fast and robust neural-network-based method for deriving the mineral modal and chemical compositions of silicate materials from their visible and near-infrared spectra. The method should be able to process raw spectra without significant pre-processing. We designed a convolutional neural network with two hidden layers for the analysis of the spectra, and trained it using labelled reflectance spectra. For the training, we used a dataset that consisted of reflectance spectra of real silicate samples stored in the RELAB and C-Tape databases, namely olivine, orthopyroxene, clinopyroxene, their mixtures, and olivine-pyroxene-rich meteorites. We used the model on two datasets. First, we evaluated the model reliability on a test dataset where we compared the model classification with known compositional reference values. The individual classification results are mostly within 10 percentage-point intervals around the correct values. Second, we classified the reflectance spectra of S-complex (Q-type and V-type, also including A-type) asteroids with known Bus-DeMeo taxonomy classes. The predicted mineral chemical composition of S-type and Q-type asteroids agree with the chemical composition of ordinary chondrites. The modal abundances of V-type and A-type asteroids show a dominant contribution of orthopyroxene and olivine, respectively. Additionally, our predictions of the mineral modal composition of S-type and Q-type asteroids show an apparent depletion of olivine related to the attenuation of its diagnostic absorptions with space weathering. This trend is consistent with previous results of the slower pyroxene response to space weathering relative to olivine. ",
    "url": "https://arxiv.org/abs/2210.01006",
    "authors": [
      "David Korda",
      "Antti Penttil\u00e4",
      "Arto Klami",
      "Tom\u00e1\u0161 Kohout"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01019",
    "title": "Plateau in Monotonic Linear Interpolation -- A \"Biased\" View of Loss  Landscape for Deep Networks",
    "abstract": "Monotonic linear interpolation (MLI) - on the line connecting a random initialization with the minimizer it converges to, the loss and accuracy are monotonic - is a phenomenon that is commonly observed in the training of neural networks. Such a phenomenon may seem to suggest that optimization of neural networks is easy. In this paper, we show that the MLI property is not necessarily related to the hardness of optimization problems, and empirical observations on MLI for deep neural networks depend heavily on biases. In particular, we show that interpolating both weights and biases linearly leads to very different influences on the final output, and when different classes have different last-layer biases on a deep network, there will be a long plateau in both the loss and accuracy interpolation (which existing theory of MLI cannot explain). We also show how the last-layer biases for different classes can be different even on a perfectly balanced dataset using a simple model. Empirically we demonstrate that similar intuitions hold on practical networks and realistic datasets. ",
    "url": "https://arxiv.org/abs/2210.01019",
    "authors": [
      "Xiang Wang",
      "Annie N. Wang",
      "Mo Zhou",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01029",
    "title": "WaveFit: An Iterative and Non-autoregressive Neural Vocoder based on  Fixed-Point Iteration",
    "abstract": "Denoising diffusion probabilistic models (DDPMs) and generative adversarial networks (GANs) are popular generative models for neural vocoders. The DDPMs and GANs can be characterized by the iterative denoising framework and adversarial training, respectively. This study proposes a fast and high-quality neural vocoder called \\textit{WaveFit}, which integrates the essence of GANs into a DDPM-like iterative framework based on fixed-point iteration. WaveFit iteratively denoises an input signal, and trains a deep neural network (DNN) for minimizing an adversarial loss calculated from intermediate outputs at all iterations. Subjective (side-by-side) listening tests showed no statistically significant differences in naturalness between human natural speech and those synthesized by WaveFit with five iterations. Furthermore, the inference speed of WaveFit was more than 240 times faster than WaveRNN. Audio demos are available at \\url{google.github.io/df-conformer/wavefit/}. ",
    "url": "https://arxiv.org/abs/2210.01029",
    "authors": [
      "Yuma Koizumi",
      "Kohei Yatabe",
      "Heiga Zen",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1901.09193",
    "title": "Scene Text Synthesis for Efficient and Effective Deep Network Training",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/1901.09193",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Hongyuan Zhu",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1905.11475",
    "title": "GAT: Generative Adversarial Training for Adversarial Example Detection  and Robust Classification",
    "abstract": " Comments: ICLR 2020, code is available at this https URL; v4 fixed error in Figure 2 ",
    "url": "https://arxiv.org/abs/1905.11475",
    "authors": [
      "Xuwang Yin",
      "Soheil Kolouri",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1911.10454",
    "title": "Regularized and Smooth Double Core Tensor Factorization for  Heterogeneous Data",
    "abstract": " Comments: 49 pages, 4 figures ",
    "url": "https://arxiv.org/abs/1911.10454",
    "authors": [
      "Davoud Ataee Tarzanagh",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.16365",
    "title": "Multi-Partition Embedding Interaction with Block Term Format for  Knowledge Graph Completion",
    "abstract": " Comments: Accepted at the European Conference on Artificial Intelligence (ECAI), 2020; add source code; update appendix ",
    "url": "https://arxiv.org/abs/2006.16365",
    "authors": [
      "Hung Nghiep Tran",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.07066",
    "title": "Towards Realistic 3D Embedding via View Alignment",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2007.07066",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Shijian Lu",
      "Feiying Ma",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2010.00577",
    "title": "Interpreting Graph Neural Networks for NLP With Differentiable Edge  Masking",
    "abstract": " Title: Interpreting Graph Neural Networks for NLP With Differentiable Edge  Masking ",
    "url": "https://arxiv.org/abs/2010.00577",
    "authors": [
      "Michael Sejr Schlichtkrull",
      "Nicola De Cao",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.05157",
    "title": "Bridging the Performance Gap between FGSM and PGD Adversarial Training",
    "abstract": " Title: Bridging the Performance Gap between FGSM and PGD Adversarial Training ",
    "url": "https://arxiv.org/abs/2011.05157",
    "authors": [
      "Tianjin Huang",
      "Vlado Menkovski",
      "Yulong Pei",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.03178",
    "title": "Probabilistic Federated Learning of Neural Networks Incorporated with  Global Posterior Information",
    "abstract": " Comments: The proposed algorithm lacks sufficient proof ",
    "url": "https://arxiv.org/abs/2012.03178",
    "authors": [
      "Peng Xiao",
      "Samuel Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "abstract": " Title: Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning ",
    "url": "https://arxiv.org/abs/2104.02230",
    "authors": [
      "Yang Chen",
      "Hong Liu",
      "Pinhao Song",
      "Linhui Dai",
      "Xiaochuan Zhang",
      "Runwei Ding",
      "Shengquan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.03154",
    "title": "Improving Robustness of Deep Reinforcement Learning Agents: Environment  Attack based on the Critic Network",
    "abstract": " Comments: 8 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2104.03154",
    "authors": [
      "Lucas Schott",
      "Hatem Hajri",
      "Sylvain Lamprier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.05477",
    "title": "Stochastic Stability of Discrete-time Phase-coupled Oscillators over  Uncertain and Random Networks",
    "abstract": " Title: Stochastic Stability of Discrete-time Phase-coupled Oscillators over  Uncertain and Random Networks ",
    "url": "https://arxiv.org/abs/2104.05477",
    "authors": [
      "Matin Jafarian",
      "Mohammad H. Mamduhi",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2104.07631",
    "title": "Fair and Reliable Reconnections for Temporary Disruptions in Electric  Distribution Networks using Submodularity",
    "abstract": " Comments: 36 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2104.07631",
    "authors": [
      "Cyrus Hettle",
      "Swati Gupta",
      "Daniel Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2104.14654",
    "title": "Adversarial Inverse Reinforcement Learning for Mean Field Games",
    "abstract": " Title: Adversarial Inverse Reinforcement Learning for Mean Field Games ",
    "url": "https://arxiv.org/abs/2104.14654",
    "authors": [
      "Yang Chen",
      "Libo Zhang",
      "Jiamou Liu",
      "Michael Witbrock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.15098",
    "title": "Molecule Generation by Principal Subgraph Mining and Assembling",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.15098",
    "authors": [
      "Xiangzhe Kong",
      "Wenbing Huang",
      "Zhixing Tan",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2107.02238",
    "title": "High-Speed CMOS-Free Purely Spintronic Asynchronous Recurrent Neural  Network",
    "abstract": " Title: High-Speed CMOS-Free Purely Spintronic Asynchronous Recurrent Neural  Network ",
    "url": "https://arxiv.org/abs/2107.02238",
    "authors": [
      "Pranav O. Mathews",
      "Christian B. Duffee",
      "Abel Thayil",
      "Ty E. Stovall",
      "Christopher H. Bennett",
      "Felipe Garcia-Sanchez",
      "Matthew J. Marinella",
      "Jean Anne C. Incorvia",
      "Naimul Hassan",
      "Xuan Hu",
      "Joseph S. Friedman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2107.02453",
    "title": "Neural Mixture Models with Expectation-Maximization for End-to-end Deep  Clustering",
    "abstract": " Comments: Accepted and published at Neurocomputing 2022 ",
    "url": "https://arxiv.org/abs/2107.02453",
    "authors": [
      "Dumindu Tissera",
      "Kasun Vithanage",
      "Rukshan Wijesinghe",
      "Alex Xavier",
      "Sanath Jayasena",
      "Subha Fernando",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.04401",
    "title": "Improving Model Robustness with Latent Distribution Locally and Globally",
    "abstract": " Title: Improving Model Robustness with Latent Distribution Locally and Globally ",
    "url": "https://arxiv.org/abs/2107.04401",
    "authors": [
      "Zhuang Qian",
      "Shufei Zhang",
      "Kaizhu Huang",
      "Qiufeng Wang",
      "Rui Zhang",
      "Xinping Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.04565",
    "title": "Universal Multilayer Network Exploration by Random Walk with Restart",
    "abstract": " Title: Universal Multilayer Network Exploration by Random Walk with Restart ",
    "url": "https://arxiv.org/abs/2107.04565",
    "authors": [
      "Anthony Baptista",
      "Aitor Gonzalez",
      "Ana\u00efs Baudot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2107.09249",
    "title": "Self-Supervised Aggregation of Diverse Experts for Test-Agnostic  Long-Tailed Recognition",
    "abstract": " Comments: NeurIPS 2022. Source code: this https URL ",
    "url": "https://arxiv.org/abs/2107.09249",
    "authors": [
      "Yifan Zhang",
      "Bryan Hooi",
      "Lanqing Hong",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.12100",
    "title": "Predicting Influential Higher-Order Patterns in Temporal Network Data",
    "abstract": " Comments: 18 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2107.12100",
    "authors": [
      "Christoph Gote",
      "Vincenzo Perri",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2108.01941",
    "title": "Automatic cerebral hemisphere segmentation in rat MRI with lesions via  attention-based convolutional neural networks",
    "abstract": " Comments: Published in NeuroInformatics ",
    "url": "https://arxiv.org/abs/2108.01941",
    "authors": [
      "Juan Miguel Valverde",
      "Artem Shatillo",
      "Riccardo de Feo",
      "Jussi Tohka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.11299",
    "title": "Availability Attacks Against Neural Network Certifiers Based on  Backdoors",
    "abstract": " Title: Availability Attacks Against Neural Network Certifiers Based on  Backdoors ",
    "url": "https://arxiv.org/abs/2108.11299",
    "authors": [
      "Tobias Lorenz",
      "Marta Kwiatkowska",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.02732",
    "title": "On Margin Maximization in Linear and ReLU Networks",
    "abstract": " Comments: This version includes some minor updates ",
    "url": "https://arxiv.org/abs/2110.02732",
    "authors": [
      "Gal Vardi",
      "Ohad Shamir",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.11088",
    "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "abstract": " Title: RoMA: a Method for Neural Network Robustness Measurement and Assessment ",
    "url": "https://arxiv.org/abs/2110.11088",
    "authors": [
      "Natan Levy",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.00684",
    "title": "Graph Structural Attack by Perturbing Spectral Distance",
    "abstract": " Comments: Proceedings of the 28th ACM SIGKDD international conference on knowledge discovery & data mining (KDD'22) ",
    "url": "https://arxiv.org/abs/2111.00684",
    "authors": [
      "Lu Lin",
      "Ethan Blaser",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.03030",
    "title": "Exact Representation of Sparse Networks with Symmetric Nonnegative  Embeddings",
    "abstract": " Title: Exact Representation of Sparse Networks with Symmetric Nonnegative  Embeddings ",
    "url": "https://arxiv.org/abs/2111.03030",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Ryan A. Rossi",
      "Anup Rao",
      "Tung Mai",
      "Nedim Lipka",
      "Zhao Song",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.11827",
    "title": "A General Divergence Modeling Strategy for Salient Object Detection",
    "abstract": " Comments: Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2111.11827",
    "authors": [
      "Xinyu Tian",
      "Jing Zhang",
      "Yuchao Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": " Comments: Tech report ",
    "url": "https://arxiv.org/abs/2111.12273",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02494",
    "title": "Implicit Neural Deformation for Sparse-View Face Reconstruction",
    "abstract": " Comments: 10 pages, 6 figures, The 30th Pacific Conference on Computer Graphics and Applications. Pacific Graphics(PG) 2022 ",
    "url": "https://arxiv.org/abs/2112.02494",
    "authors": [
      "Moran Li",
      "Haibin Huang",
      "Yi Zheng",
      "Mengtian Li",
      "Nong Sang",
      "Chongyang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03237",
    "title": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "abstract": " Title: From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection ",
    "url": "https://arxiv.org/abs/2112.03237",
    "authors": [
      "Maan Qraitem",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04744",
    "title": "Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks",
    "abstract": " Title: Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2112.04744",
    "authors": [
      "Jun Wang",
      "Zhoujing Li",
      "Yixuan Qiao",
      "Qiming Qin",
      "Peng Gao",
      "Guotong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.06343",
    "title": "Change Detection Meets Visual Question Answering",
    "abstract": " Title: Change Detection Meets Visual Question Answering ",
    "url": "https://arxiv.org/abs/2112.06343",
    "authors": [
      "Zhenghang Yuan",
      "Lichao Mou",
      "Zhitong Xiong",
      "Xiaoxiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11644",
    "title": "Reconstructing social sensitivity from evolution of content volume in  Twitter",
    "abstract": " Title: Reconstructing social sensitivity from evolution of content volume in  Twitter ",
    "url": "https://arxiv.org/abs/2112.11644",
    "authors": [
      "Sebasti\u00e1n Pinto",
      "Marcos Trevisan",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.14804",
    "title": "Learning Spatially-Adaptive Squeeze-Excitation Networks for Image  Synthesis and Image Recognition",
    "abstract": " Title: Learning Spatially-Adaptive Squeeze-Excitation Networks for Image  Synthesis and Image Recognition ",
    "url": "https://arxiv.org/abs/2112.14804",
    "authors": [
      "Jianghao Shen",
      "Tianfu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.00627",
    "title": "Uncertainty Detection and Reduction in Neural Decoding of EEG Signals",
    "abstract": " Title: Uncertainty Detection and Reduction in Neural Decoding of EEG Signals ",
    "url": "https://arxiv.org/abs/2201.00627",
    "authors": [
      "Tiehang Duan",
      "Zhenyi Wang",
      "Sheng Liu",
      "Sargur N. Srihari",
      "Hui Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": " Title: Deep Generative Model for Periodic Graphs ",
    "url": "https://arxiv.org/abs/2201.11932",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12632",
    "title": "Towards Robust Deep Active Learning for Scientific Computing",
    "abstract": " Title: Towards Robust Deep Active Learning for Scientific Computing ",
    "url": "https://arxiv.org/abs/2201.12632",
    "authors": [
      "Simiao Ren",
      "Yang Deng",
      "Willie J. Padilla",
      "Jordan Malof"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12674",
    "title": "Rewiring with Positional Encodings for Graph Neural Networks",
    "abstract": " Title: Rewiring with Positional Encodings for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2201.12674",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12843",
    "title": "Graph Representation Learning Through Recoverability",
    "abstract": " Title: Graph Representation Learning Through Recoverability ",
    "url": "https://arxiv.org/abs/2201.12843",
    "authors": [
      "Maxim Fishman",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Almog David",
      "Ron Banner",
      "Avi Mendelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07792",
    "title": "Efficient Content Delivery in User-Centric and Cache-Enabled Vehicular  Edge Networks with Deadline-Constrained Heterogeneous Demands",
    "abstract": " Title: Efficient Content Delivery in User-Centric and Cache-Enabled Vehicular  Edge Networks with Deadline-Constrained Heterogeneous Demands ",
    "url": "https://arxiv.org/abs/2202.07792",
    "authors": [
      "Md Ferdous Pervej",
      "Richeng Jin",
      "Shih-Chun Lin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.13013",
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation  Learning",
    "abstract": " Comments: 42 pages ",
    "url": "https://arxiv.org/abs/2202.13013",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Lingxiao Zhao",
      "Tess Smidt",
      "Suvrit Sra",
      "Haggai Maron",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.13060",
    "title": "Graph Attention Retrospective",
    "abstract": " Comments: 53 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2202.13060",
    "authors": [
      "Kimon Fountoulakis",
      "Amit Levi",
      "Shenghao Yang",
      "Aseem Baranwal",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01721",
    "title": "Asymptotic Optimality of Speed-Aware JSQ for Heterogeneous Systems",
    "abstract": " Comments: 36 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2203.01721",
    "authors": [
      "Sanidhay Bhambay",
      "Arpan Mukhopadhyay"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2203.03392",
    "title": "Naturally-meaningful and efficient descriptors: machine learning of  material properties based on robust one-shot ab initio descriptors",
    "abstract": " Comments: 13 pages, accepted in Journal of Cheminformatics ",
    "url": "https://arxiv.org/abs/2203.03392",
    "authors": [
      "Sherif Abdulkader Tawfik",
      "Salvy P. Russo"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07815",
    "title": "Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification",
    "abstract": " Title: Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification ",
    "url": "https://arxiv.org/abs/2203.07815",
    "authors": [
      "Tian Xia",
      "Pedro Sanchez",
      "Chen Qin",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11315",
    "title": "Landscape Analysis for Surrogate Models in the Evolutionary Black-Box  Context",
    "abstract": " Comments: 25 pages main article, 28 pages supplementary material, 3 figures, currently under review at Evolutionary Computation journal ",
    "url": "https://arxiv.org/abs/2203.11315",
    "authors": [
      "Zbyn\u011bk Pitra",
      "Jan Koza",
      "Ji\u0159\u00ed Tumpach",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.14094",
    "title": "SlimFL: Federated Learning with Superposition Coding over Slimmable  Neural Networks",
    "abstract": " Title: SlimFL: Federated Learning with Superposition Coding over Slimmable  Neural Networks ",
    "url": "https://arxiv.org/abs/2203.14094",
    "authors": [
      "Won Joon Yun",
      "Yunseok Kwak",
      "Hankyul Baek",
      "Soyi Jung",
      "Mingyue Ji",
      "Mehdi Bennis",
      "Jihong Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2204.00616",
    "title": "Simplicial Embeddings in Self-Supervised Learning and Downstream  Classification",
    "abstract": " Comments: 30 pages, 8 figures, Preprint ",
    "url": "https://arxiv.org/abs/2204.00616",
    "authors": [
      "Samuel Lavoie",
      "Christos Tsirigotis",
      "Max Schwarzer",
      "Ankit Vani",
      "Michael Noukhovitch",
      "Kenji Kawaguchi",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.12489",
    "title": "Sound Localization by Self-Supervised Time Delay Estimation",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2204.12489",
    "authors": [
      "Ziyang Chen",
      "David F. Fouhey",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.13620",
    "title": "Generative Adversarial Networks for Image Super-Resolution: A Survey",
    "abstract": " Title: Generative Adversarial Networks for Image Super-Resolution: A Survey ",
    "url": "https://arxiv.org/abs/2204.13620",
    "authors": [
      "Chunwei Tian",
      "Xuanyu Zhang",
      "Jerry Chun-Wei Lin",
      "Wangmeng Zuo",
      "Yanning Zhang",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.00362",
    "title": "A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization",
    "abstract": " Title: A Simple and General Duality Proof for Wasserstein Distributionally  Robust Optimization ",
    "url": "https://arxiv.org/abs/2205.00362",
    "authors": [
      "Luhao Zhang",
      "Jincheng Yang",
      "Rui Gao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.06570",
    "title": "Convergence of Deep Neural Networks with General Activation Functions  and Pooling",
    "abstract": " Comments: incomplete ",
    "url": "https://arxiv.org/abs/2205.06570",
    "authors": [
      "Wentao Huang",
      "Yuesheng Xu",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2205.09801",
    "title": "Graph Neural Networks Are More Powerful Than we Think",
    "abstract": " Title: Graph Neural Networks Are More Powerful Than we Think ",
    "url": "https://arxiv.org/abs/2205.09801",
    "authors": [
      "Charilaos I. Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10089",
    "title": "Kernel Normalized Convolutional Networks",
    "abstract": " Title: Kernel Normalized Convolutional Networks ",
    "url": "https://arxiv.org/abs/2205.10089",
    "authors": [
      "Reza Nasirigerdeh",
      "Reihaneh Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10664",
    "title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks",
    "abstract": " Comments: Preprint: 17 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.10664",
    "authors": [
      "Guangji Bai",
      "Chen Ling",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12519",
    "title": "Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset",
    "abstract": " Title: Structure Aware and Class Balanced 3D Object Detection on nuScenes  Dataset ",
    "url": "https://arxiv.org/abs/2205.12519",
    "authors": [
      "Sushruth Nagesh",
      "Asfiya Baig",
      "Savitha Srinivasan",
      "Akshay Rangesh",
      "Mohan Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12940",
    "title": "Conformal Prediction Intervals with Temporal Dependence",
    "abstract": " Comments: 16 pages (main paper, including references) + 6 pages (supplementary material). Transactions of Machine Learning Research (September 2022). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2205.12940",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2205.13022",
    "title": "Towards Using Data-Influence Methods to Detect Noisy Samples in Source  Code Corpora",
    "abstract": " Comments: The 37th IEEE/ACM International Conference on Automated Software Engineering ",
    "url": "https://arxiv.org/abs/2205.13022",
    "authors": [
      "Anh T. V. Dau",
      "Thang Nguyen-Duc",
      "Hoang Thanh-Tung",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2205.13147",
    "title": "Matryoshka Representation Learning",
    "abstract": " Comments: 35 pages, 12 figures. NeurIPS 2022 camera ready publication ",
    "url": "https://arxiv.org/abs/2205.13147",
    "authors": [
      "Aditya Kusupati",
      "Gantavya Bhatt",
      "Aniket Rege",
      "Matthew Wallingford",
      "Aditya Sinha",
      "Vivek Ramanujan",
      "William Howard-Snyder",
      "Kaifeng Chen",
      "Sham Kakade",
      "Prateek Jain",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13524",
    "title": "PREF: Phasorial Embedding Fields for Compact Neural Representations",
    "abstract": " Title: PREF: Phasorial Embedding Fields for Compact Neural Representations ",
    "url": "https://arxiv.org/abs/2205.13524",
    "authors": [
      "Binbin Huang",
      "Xinhao Yan",
      "Anpei Chen",
      "Shenghua Gao",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2205.14691",
    "title": "On the Robustness of Safe Reinforcement Learning under Observational  Perturbations",
    "abstract": " Comments: 30 pages, 4 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2205.14691",
    "authors": [
      "Zuxin Liu",
      "Zijian Guo",
      "Zhepeng Cen",
      "Huan Zhang",
      "Jie Tan",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2205.15987",
    "title": "Achieving Lightweight Federated Advertising with Self-Supervised Split  Distillation",
    "abstract": " Comments: Accepted to the Trustworthy Federated Learning workshop of IJCAI2022 (FL-IJCAI22). 6 pages, 3 figures, 3 tables Old title: Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer ",
    "url": "https://arxiv.org/abs/2205.15987",
    "authors": [
      "Wenjie Li",
      "Qiaolin Xia",
      "Junfeng Deng",
      "Hao Cheng",
      "Jiangming Liu",
      "Kouying Xue",
      "Yong Cheng",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.00057",
    "title": "Distributed Graph Neural Network Training with Periodic Stale  Representation Synchronization",
    "abstract": " Comments: Preprint: 20 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.00057",
    "authors": [
      "Zheng Chai",
      "Guangji Bai",
      "Liang Zhao",
      "Yue Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2206.00236",
    "title": "Continuous Prediction with Experts' Advice",
    "abstract": " Comments: 30 pages, 1 figure. Version 2 diff: minor edits, reorganization for a journal submission, correct statement of Lemma 5.1 and a better formatted proof of the same lemma ",
    "url": "https://arxiv.org/abs/2206.00236",
    "authors": [
      "Victor Sanches Portella",
      "Christopher Liaw",
      "Nicholas J. A. Harvey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00787",
    "title": "On the Generalization of Neural Combinatorial Optimization Heuristics",
    "abstract": " Comments: Published in ECML PKDD 2022 ",
    "url": "https://arxiv.org/abs/2206.00787",
    "authors": [
      "Sahil Manchanda",
      "Sofia Michel",
      "Darko Drakulic",
      "Jean-Marc Andreoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01545",
    "title": "Mesh-free Eulerian Physics-Informed Neural Networks",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2206.01545",
    "authors": [
      "Fabricio Arend Torres",
      "Marcello Massimo Negri",
      "Monika Nagy-Huber",
      "Maxim Samarin",
      "Volker Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02607",
    "title": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural  Representations",
    "abstract": " Title: CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural  Representations ",
    "url": "https://arxiv.org/abs/2206.02607",
    "authors": [
      "Peter Yichen Chen",
      "Jinxu Xiang",
      "Dong Heon Cho",
      "Yue Chang",
      "G A Pershing",
      "Henrique Teles Maia",
      "Maurizio Chiaramonte",
      "Kevin Carlberg",
      "Eitan Grinspun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.07729",
    "title": "Taxonomy of Benchmarks in Graph Representation Learning",
    "abstract": " Title: Taxonomy of Benchmarks in Graph Representation Learning ",
    "url": "https://arxiv.org/abs/2206.07729",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Dylan Sandfelder",
      "Devin Kreuzer",
      "Anna Little",
      "Sarah McGuire",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08396",
    "title": "User Customizable and Robust Geo-Indistinguishability for Location  Privacy",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2206.08396",
    "authors": [
      "Primal Pappachan",
      "Chenxi Qiu",
      "Anna Squicciarini",
      "Vishnu Sharma Hunsur Manjunath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.09305",
    "title": "Adversarial Scrutiny of Evidentiary Statistical Software",
    "abstract": " Comments: Typos corrected, appendix B removed ",
    "url": "https://arxiv.org/abs/2206.09305",
    "authors": [
      "Rediet Abebe",
      "Moritz Hardt",
      "Angela Jin",
      "John Miller",
      "Ludwig Schmidt",
      "Rebecca Wexler"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02632",
    "title": "Network Pruning via Feature Shift Minimization",
    "abstract": " Title: Network Pruning via Feature Shift Minimization ",
    "url": "https://arxiv.org/abs/2207.02632",
    "authors": [
      "Yuanzhi Duan",
      "Yue Zhou",
      "Peng He",
      "Qiang Liu",
      "Shukai Duan",
      "Xiaofang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05013",
    "title": "Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models",
    "abstract": " Title: Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models ",
    "url": "https://arxiv.org/abs/2207.05013",
    "authors": [
      "Alexey N. Korovin",
      "Innokentiy S. Humonen",
      "Artem I. Samtsevich",
      "Roman A. Eremin",
      "Artem I. Vasilyev",
      "Vladimir D. Lazarev",
      "Semen A. Budennyy"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10035",
    "title": "Fully Sparse 3D Object Detection",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.10035",
    "authors": [
      "Lue Fan",
      "Feng Wang",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.10293",
    "title": "Affective Behavior Analysis using Action Unit Relation Graph and  Multi-task Cross Attention",
    "abstract": " Title: Affective Behavior Analysis using Action Unit Relation Graph and  Multi-task Cross Attention ",
    "url": "https://arxiv.org/abs/2207.10293",
    "authors": [
      "Dang-Khanh Nguyen",
      "Sudarshan Pant",
      "Ngoc-Huynh Ho",
      "Guee-Sang Lee",
      "Soo-Huyng Kim",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.14709",
    "title": "Robust Quantitative Susceptibility Mapping via Approximate Message  Passing",
    "abstract": " Comments: Keywords: Approximate message passing, Compressive sensing, Parameter estimation, QSM ",
    "url": "https://arxiv.org/abs/2207.14709",
    "authors": [
      "Shuai Huang",
      "James J. Lah",
      "Jason W. Allen",
      "Deqiang Qiu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.05994",
    "title": "Anomaly segmentation model for defects detection in electroluminescence  images of heterojunction solar cells",
    "abstract": " Title: Anomaly segmentation model for defects detection in electroluminescence  images of heterojunction solar cells ",
    "url": "https://arxiv.org/abs/2208.05994",
    "authors": [
      "Alexey Korovin",
      "Artem Vasilyev",
      "Fedor Egorov",
      "Dmitry Saykin",
      "Evgeny Terukov",
      "Igor Shakhray",
      "Leonid Zhukov",
      "Semen Budennyy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.06876",
    "title": "Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces",
    "abstract": " Title: Conformal Navigation Transformations with Application to Robot  Navigation in Complex Workspaces ",
    "url": "https://arxiv.org/abs/2208.06876",
    "authors": [
      "Li Fan",
      "Jianchang Liu",
      "Wenle Zhang",
      "Peng Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.06957",
    "title": "Syntax-driven Data Augmentation for Named Entity Recognition",
    "abstract": " Comments: submitted to Pattern-based Approaches to NLP in the Age of Deep Learning 2022 (Pan-DL 2022) ",
    "url": "https://arxiv.org/abs/2208.06957",
    "authors": [
      "Arie Pratama Sutiono",
      "Gus Hahn-Powell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08084",
    "title": "AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2208.08084",
    "authors": [
      "Zhijun Tu",
      "Xinghao Chen",
      "Pengju Ren",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.08110",
    "title": "PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation",
    "abstract": " Title: PCC: Paraphrasing with Bottom-k Sampling and Cyclic Learning for  Curriculum Data Augmentation ",
    "url": "https://arxiv.org/abs/2208.08110",
    "authors": [
      "Hongyuan Lu",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.10606",
    "title": "LEAPER: Fast and Accurate FPGA-based System Performance Prediction via  Transfer Learning",
    "abstract": " Title: LEAPER: Fast and Accurate FPGA-based System Performance Prediction via  Transfer Learning ",
    "url": "https://arxiv.org/abs/2208.10606",
    "authors": [
      "Gagandeep Singh",
      "Dionysios Diamantopoulos",
      "Juan G\u00f3mez-Luna",
      "Sander Stuijk",
      "Henk Corporaal",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11112",
    "title": "DeepInteraction: 3D Object Detection via Modality Interaction",
    "abstract": " Comments: To appear at NeurIPS 2022. 16 pages, 7 figure ",
    "url": "https://arxiv.org/abs/2208.11112",
    "authors": [
      "Zeyu Yang",
      "Jiaqi Chen",
      "Zhenwei Miao",
      "Wei Li",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.13422",
    "title": "Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios",
    "abstract": " Title: Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios ",
    "url": "https://arxiv.org/abs/2208.13422",
    "authors": [
      "Hao Xu",
      "Bo Li",
      "Fei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.14845",
    "title": "Listen2YourHeart: A Self-Supervised Approach for Detecting Murmur in  Heart-Beat Sounds",
    "abstract": " Comments: To be published in the proceedings of CinC 2022 (this https URL). This is a preprint version of the final paper ",
    "url": "https://arxiv.org/abs/2208.14845",
    "authors": [
      "Aristotelis Ballas",
      "Vasileios Papapanagiotou",
      "Anastasios Delopoulos",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.03416",
    "title": "Bispectral Neural Networks",
    "abstract": " Title: Bispectral Neural Networks ",
    "url": "https://arxiv.org/abs/2209.03416",
    "authors": [
      "Sophia Sanborn",
      "Christian Shewmake",
      "Bruno Olshausen",
      "Christopher Hillar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.06351",
    "title": "DevNet: Self-supervised Monocular Depth Learning via Density Volume  Construction",
    "abstract": " Comments: Accepted by European Conference on Computer Vision 2022 (ECCV2022) ",
    "url": "https://arxiv.org/abs/2209.06351",
    "authors": [
      "Kaichen Zhou",
      "Lanqing Hong",
      "Changhao Chen",
      "Hang Xu",
      "Chaoqiang Ye",
      "Qingyong Hu",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.09124",
    "title": "DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using  Attention-Based Generative Adverserial Network",
    "abstract": " Title: DMMGAN: Diverse Multi Motion Prediction of 3D Human Joints using  Attention-Based Generative Adverserial Network ",
    "url": "https://arxiv.org/abs/2209.09124",
    "authors": [
      "Payam Nikdel",
      "Mohammad Mahdavian",
      "Mo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.09528",
    "title": "Demonstration of SDN-Based Heterogeneous Quantum Key Distribution Chain  Orchestration over Optical Networks",
    "abstract": " Title: Demonstration of SDN-Based Heterogeneous Quantum Key Distribution Chain  Orchestration over Optical Networks ",
    "url": "https://arxiv.org/abs/2209.09528",
    "authors": [
      "Yuan Cao",
      "Yongli Zhao",
      "Jie Zhang",
      "Qin Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.09941",
    "title": "Predicting Drug-Drug Interactions using Deep Generative Models on Graphs",
    "abstract": " Title: Predicting Drug-Drug Interactions using Deep Generative Models on Graphs ",
    "url": "https://arxiv.org/abs/2209.09941",
    "authors": [
      "Nhat Khang Ngo",
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11388",
    "title": "LGDN: Language-Guided Denoising Network for Video-Language Modeling",
    "abstract": " Comments: Accepted by NeurIPS2022 ",
    "url": "https://arxiv.org/abs/2209.11388",
    "authors": [
      "Haoyu Lu",
      "Mingyu Ding",
      "Nanyi Fei",
      "Yuqi Huo",
      "Zhiwu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.11537",
    "title": "Planar graph with twin-width seven",
    "abstract": " Title: Planar graph with twin-width seven ",
    "url": "https://arxiv.org/abs/2209.11537",
    "authors": [
      "Daniel Kral",
      "Ander Lamaison"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2209.11628",
    "title": "A Neural Model for Regular Grammar Induction",
    "abstract": " Comments: Accepted to the 21st IEEE International Conference on Machine Learning and Applications (ICMLA) 2022, 6 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2209.11628",
    "authors": [
      "Peter Belc\u00e1k",
      "David Hofer",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.11785",
    "title": "Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search",
    "abstract": " Title: Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2209.11785",
    "authors": [
      "S\u0142awomir Kierat",
      "Mateusz Sieniawski",
      "Denys Fridman",
      "Chen-Han Yu",
      "Szymon Migacz",
      "Pawe\u0142 Morkisz",
      "Alex-Fit Florea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12138",
    "title": "Towards Stable Co-saliency Detection and Object Co-segmentation",
    "abstract": " Title: Towards Stable Co-saliency Detection and Object Co-segmentation ",
    "url": "https://arxiv.org/abs/2209.12138",
    "authors": [
      "Bo Li",
      "Lv Tang",
      "Senyun Kuang",
      "Mofei Song",
      "Shouhong Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12629",
    "title": "Power System Anomaly Detection and Classification Utilizing WLS-EKF  State Estimation and Machine Learning",
    "abstract": " Comments: 12 pages, 11 figures, source code is available ",
    "url": "https://arxiv.org/abs/2209.12629",
    "authors": [
      "Sajjad Asefi",
      "Mile Mitrovic",
      "Dragan \u0106etenovi\u0107",
      "Victor Levi",
      "Elena Gryazina",
      "Vladimir Terzija"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12846",
    "title": "Codes parameterized by the edges of a bipartite graph with a perfect  matching",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2209.12846",
    "authors": [
      "Manuel Gonzalez Sarabia",
      "Rafael H. Villarreal"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.13388",
    "title": "Efficient Fault Detection Architecture of Bit-Parallel Multiplier in  Polynomial Basis of GF(2m) Using BCH Code",
    "abstract": " Comments: 8 pages, 4 Figures, 3 Tables ",
    "url": "https://arxiv.org/abs/2209.13388",
    "authors": [
      "Saeideh Nabipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2209.13701",
    "title": "Spectral clustering and model reduction for weakly-connected coherent  network systems",
    "abstract": " Title: Spectral clustering and model reduction for weakly-connected coherent  network systems ",
    "url": "https://arxiv.org/abs/2209.13701",
    "authors": [
      "Hancheng Min",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.13767",
    "title": "Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster)",
    "abstract": " Title: Internet Outage Detection using Passive Analysis (Poster Abstract and  Poster) ",
    "url": "https://arxiv.org/abs/2209.13767",
    "authors": [
      "Asma Enayet",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.14265",
    "title": "360FusionNeRF: Panoramic Neural Radiance Fields with Joint Guidance",
    "abstract": " Comments: 8 pages, Fig 3, Submitted to IEEE RAL. arXiv admin note: text overlap with arXiv:2106.10859, arXiv:2104.00677, arXiv:2203.09957, arXiv:2204.00928 by other authors ",
    "url": "https://arxiv.org/abs/2209.14265",
    "authors": [
      "Shreyas Kulkarni",
      "Peng Yin",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14553",
    "title": "Regularizing Neural Network Training via Identity-wise Discriminative  Feature Suppression",
    "abstract": " Comments: DICTA 2022 ",
    "url": "https://arxiv.org/abs/2209.14553",
    "authors": [
      "Avraham Chapman",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15486",
    "title": "Graph Neural Networks for Link Prediction with Subgraph Sketching",
    "abstract": " Comments: 9 pages, 6 figures, 6 appendices ",
    "url": "https://arxiv.org/abs/2209.15486",
    "authors": [
      "Benjamin Paul Chamberlain",
      "Sergey Shirobokov",
      "Emanuele Rossi",
      "Fabrizio Frasca",
      "Thomas Markovich",
      "Nils Hammerla",
      "Michael M. Bronstein",
      "Max Hansmire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  }
]