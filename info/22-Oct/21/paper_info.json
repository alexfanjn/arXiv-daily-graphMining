[
  {
    "id": "arXiv:2210.10780",
    "title": "An out-of-distribution discriminator based on Bayesian neural network  epistemic uncertainty",
    "abstract": "Neural networks have revolutionized the field of machine learning with increased predictive capability. In addition to improving the predictions of neural networks, there is a simultaneous demand for reliable uncertainty quantification on estimates made by machine learning methods such as neural networks. Bayesian neural networks (BNNs) are an important type of neural network with built-in capability for quantifying uncertainty. This paper discusses aleatoric and epistemic uncertainty in BNNs and how they can be calculated. With an example dataset of images where the goal is to identify the amplitude of an event in the image, it is shown that epistemic uncertainty tends to be lower in images which are well-represented in the training dataset and tends to be high in images which are not well-represented. An algorithm for out-of-distribution (OoD) detection with BNN epistemic uncertainty is introduced along with various experiments demonstrating factors influencing the OoD detection capability in a BNN. The OoD detection capability with epistemic uncertainty is shown to be comparable to the OoD detection in the discriminator network of a generative adversarial network (GAN) with comparable network architecture. ",
    "url": "https://arxiv.org/abs/2210.10780",
    "authors": [
      "Ethan Ancell",
      "Christopher Bennett",
      "Bert Debusschere",
      "Sapan Agarwal",
      "Park Hays",
      "T. Patrick Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10807",
    "title": "Self-Supervised Representation Learning for CAD",
    "abstract": "The design of man-made objects is dominated by computer aided design (CAD) tools. Assisting design with data-driven machine learning methods is hampered by lack of labeled data in CAD's native format; the parametric boundary representation (B-Rep). Several data sets of mechanical parts in B-Rep format have recently been released for machine learning research. However, large scale databases are largely unlabeled, and labeled datasets are small. Additionally, task specific label sets are rare, and costly to annotate. This work proposes to leverage unlabeled CAD geometry on supervised learning tasks. We learn a novel, hybrid implicit/explicit surface representation for B-Rep geometry, and show that this pre-training significantly improves few-shot learning performance and also achieves state-of-the-art performance on several existing B-Rep benchmarks. ",
    "url": "https://arxiv.org/abs/2210.10807",
    "authors": [
      "Benjamin T. Jones",
      "Michael Hu",
      "Vladimir G. Kim",
      "Adriana Schulz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.10849",
    "title": "Black Box Model Explanations and the Human Interpretability Expectations  -- An Analysis in the Context of Homicide Prediction",
    "abstract": "Strategies based on Explainable Artificial Intelligence - XAI have promoted better human interpretability of the results of black box machine learning models. The XAI measures being currently used (Ciu, Dalex, Eli5, Lofo, Shap, and Skater) provide various forms of explanations, including global rankings of relevance of attributes. Current research points to the need for further studies on how these explanations meet the Interpretability Expectations of human experts and how they can be used to make the model even more transparent while taking into account specific complexities of the model and dataset being analyzed, as well as important human factors of sensitive real-world contexts/problems. Intending to shed light on the explanations generated by XAI measures and their interpretabilities, this research addresses a real-world classification problem related to homicide prediction, duly endorsed by the scientific community, replicated its proposed black box model and used 6 different XAI measures to generate explanations and 6 different human experts to generate what this research referred to as Interpretability Expectations - IE. The results were computed by means of comparative analysis and identification of relationships among all the attribute ranks produced, and ~49% concordance was found among attributes indicated by means of XAI measures and human experts, ~41% exclusively by XAI measures and ~10% exclusively by human experts. The results allow for answering: \"Do the different XAI measures generate similar explanations for the proposed problem?\", \"Are the interpretability expectations generated among different human experts similar?\", \"Do the explanations generated by XAI measures meet the interpretability expectations of human experts?\" and \"Can Interpretability Explanations and Expectations work together?\", all of which concerning the context of homicide prediction. ",
    "url": "https://arxiv.org/abs/2210.10849",
    "authors": [
      "Jos\u00e9 Ribeiro",
      "N\u00edkolas Carneiro",
      "Ronnie Alves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10861",
    "title": "QA Domain Adaptation using Hidden Space Augmentation and Self-Supervised  Contrastive Adaptation",
    "abstract": "Question answering (QA) has recently shown impressive results for answering questions from customized domains. Yet, a common challenge is to adapt QA models to an unseen target domain. In this paper, we propose a novel self-supervised framework called QADA for QA domain adaptation. QADA introduces a novel data augmentation pipeline used to augment training QA samples. Different from existing methods, we enrich the samples via hidden space augmentation. For questions, we introduce multi-hop synonyms and sample augmented token embeddings with Dirichlet distributions. For contexts, we develop an augmentation method which learns to drop context spans via a custom attentive sampling strategy. Additionally, contrastive learning is integrated in the proposed self-supervised adaptation framework QADA. Unlike existing approaches, we generate pseudo labels and propose to train the model via a novel attention-based contrastive adaptation method. The attention weights are used to build informative features for discrepancy estimation that helps the QA model separate answers and generalize across source and target domains. To the best of our knowledge, our work is the first to leverage hidden space augmentation and attention-based contrastive adaptation for self-supervised domain adaptation in QA. Our evaluation shows that QADA achieves considerable improvements on multiple target datasets over state-of-the-art baselines in QA domain adaptation. ",
    "url": "https://arxiv.org/abs/2210.10861",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Bernhard Kratzwald",
      "Stefan Feuerriegel",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10876",
    "title": "Exiting the Simulation: The Road to Robust and Resilient Autonomous  Vehicles at Scale",
    "abstract": "In the past two decades, autonomous driving has been catalyzed into reality by the growing capabilities of machine learning. This paradigm shift possesses significant potential to transform the future of mobility and reshape our society as a whole. With the recent advances in perception, planning, and control capabilities, autonomous driving technologies are being rolled out for public trials, yet we remain far from being able to rigorously ensure the resilient operations of these systems across the long-tailed nature of the driving environment. Given the limitations of real-world testing, autonomous vehicle simulation stands as the critical component in exploring the edge of autonomous driving capabilities, developing the robust behaviors required for successful real-world operation, and enabling the extraction of hidden risks from these complex systems prior to deployment. This paper presents the current state-of-the-art simulation frameworks and methodologies used in the development of autonomous driving systems, with a focus on outlining how simulation is used to build the resiliency required for real-world operation and the methods developed to bridge the gap between simulation and reality. A synthesis of the key challenges surrounding autonomous driving simulation is presented, specifically highlighting the opportunities to further advance the ability to continuously learn in simulation and effectively transfer the learning into the real-world - enabling autonomous vehicles to exit the guardrails of simulation and deliver robust and resilient operations at scale. ",
    "url": "https://arxiv.org/abs/2210.10876",
    "authors": [
      "Richard Chakra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10879",
    "title": "G-Augment: Searching For The Meta-Structure Of Data Augmentation  Policies For ASR",
    "abstract": "Data augmentation is a ubiquitous technique used to provide robustness to automatic speech recognition (ASR) training. However, even as so much of the ASR training process has become automated and more \"end-to-end\", the data augmentation policy (what augmentation functions to use, and how to apply them) remains hand-crafted. We present Graph-Augment, a technique to define the augmentation space as directed acyclic graphs (DAGs) and search over this space to optimize the augmentation policy itself. We show that given the same computational budget, policies produced by G-Augment are able to perform better than SpecAugment policies obtained by random search on fine-tuning tasks on CHiME-6 and AMI. G-Augment is also able to establish a new state-of-the-art ASR performance on the CHiME-6 evaluation set (30.7% WER). We further demonstrate that G-Augment policies show better transfer properties across warm-start to cold-start training and model size compared to random-searched SpecAugment policies. ",
    "url": "https://arxiv.org/abs/2210.10879",
    "authors": [
      "Gary Wang",
      "Ekin D.Cubuk",
      "Andrew Rosenberg",
      "Shuyang Cheng",
      "Ron J. Weiss",
      "Bhuvana Ramabhadran",
      "Pedro J. Moreno",
      "Quoc V. Le",
      "Daniel S. Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.10880",
    "title": "Learning to Invert: Simple Adaptive Attacks for Gradient Inversion in  Federated Learning",
    "abstract": "Gradient inversion attack enables recovery of training samples from model updates in federated learning (FL) and constitutes a serious threat to data privacy. To mitigate this vulnerability, prior work proposed both principled defenses based on differential privacy, as well as heuristic defenses based on gradient compression as countermeasures. These defenses have so far been very effective, in particular those based on gradient compression that allow the model to maintain high accuracy while greatly reducing the attack's effectiveness. In this work, we argue that such findings do not accurately reflect the privacy risk in FL, and show that existing defenses can be broken by a simple adaptive attack that trains a model using auxiliary data to learn how to invert gradients on both vision and language tasks. ",
    "url": "https://arxiv.org/abs/2210.10880",
    "authors": [
      "Ruihan Wu",
      "Xiangyu Chen",
      "Chuan Guo",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.10886",
    "title": "Backdoor Attack and Defense in Federated Generative Adversarial  Network-based Medical Image Synthesis",
    "abstract": "Deep Learning-based image synthesis techniques have been applied in healthcare research for generating medical images to support open research and augment medical datasets. Training generative adversarial neural networks (GANs) usually require large amounts of training data. Federated learning (FL) provides a way of training a central model using distributed data while keeping raw data locally. However, given that the FL server cannot access the raw data, it is vulnerable to backdoor attacks, an adversarial by poisoning training data. Most backdoor attack strategies focus on classification models and centralized domains. It is still an open question if the existing backdoor attacks can affect GAN training and, if so, how to defend against the attack in the FL setting. In this work, we investigate the overlooked issue of backdoor attacks in federated GANs (FedGANs). The success of this attack is subsequently determined to be the result of some local discriminators overfitting the poisoned data and corrupting the local GAN equilibrium, which then further contaminates other clients when averaging the generator's parameters and yields high generator loss. Therefore, we proposed FedDetect, an efficient and effective way of defending against the backdoor attack in the FL setting, which allows the server to detect the client's adversarial behavior based on their losses and block the malicious clients. Our extensive experiments on two medical datasets with different modalities demonstrate the backdoor attack on FedGANs can result in synthetic images with low fidelity. After detecting and suppressing the detected malicious clients using the proposed defense strategy, we show that FedGANs can synthesize high-quality medical datasets (with labels) for data augmentation to improve classification models' performance. ",
    "url": "https://arxiv.org/abs/2210.10886",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10897",
    "title": "Distribution Shift Detection for Deep Neural Networks",
    "abstract": "To deploy and operate deep neural models in production, the quality of their predictions, which might be contaminated benignly or manipulated maliciously by input distributional deviations, must be monitored and assessed. Specifically, we study the case of monitoring the healthy operation of a deep neural network (DNN) receiving a stream of data, with the aim of detecting input distributional deviations over which the quality of the network's predictions is potentially damaged. Using selective prediction principles, we propose a distribution deviation detection method for DNNs. The proposed method is derived from a tight coverage generalization bound computed over a sample of instances drawn from the true underlying distribution. Based on this bound, our detector continuously monitors the operation of the network over a test window and fires off an alarm whenever a deviation is detected. This novel detection method consistently and significantly outperforms the state of the art with respect to the CIFAR-10 and ImageNet datasets, thus establishing a new performance bar for this task, while being substantially more efficient in time and space complexities. ",
    "url": "https://arxiv.org/abs/2210.10897",
    "authors": [
      "Guy Bar-Shalom",
      "Yonatan Geifman",
      "Ran El-Yaniv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10936",
    "title": "FedRecover: Recovering from Poisoning Attacks in Federated Learning  using Historical Information",
    "abstract": "Federated learning is vulnerable to poisoning attacks in which malicious clients poison the global model via sending malicious model updates to the server. Existing defenses focus on preventing a small number of malicious clients from poisoning the global model via robust federated learning methods and detecting malicious clients when there are a large number of them. However, it is still an open challenge how to recover the global model from poisoning attacks after the malicious clients are detected. A naive solution is to remove the detected malicious clients and train a new global model from scratch, which incurs large cost that may be intolerable for resource-constrained clients such as smartphones and IoT devices. In this work, we propose FedRecover, which can recover an accurate global model from poisoning attacks with small cost for the clients. Our key idea is that the server estimates the clients' model updates instead of asking the clients to compute and communicate them during the recovery process. In particular, the server stores the global models and clients' model updates in each round, when training the poisoned global model. During the recovery process, the server estimates a client's model update in each round using its stored historical information. Moreover, we further optimize FedRecover to recover a more accurate global model using warm-up, periodic correction, abnormality fixing, and final tuning strategies, in which the server asks the clients to compute and communicate their exact model updates. Theoretically, we show that the global model recovered by FedRecover is close to or the same as that recovered by train-from-scratch under some assumptions. Empirically, our evaluation on four datasets, three federated learning methods, as well as untargeted and targeted poisoning attacks (e.g., backdoor attacks) shows that FedRecover is both accurate and efficient. ",
    "url": "https://arxiv.org/abs/2210.10936",
    "authors": [
      "Xiaoyu Cao",
      "Jinyuan Jia",
      "Zaixi Zhang",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10946",
    "title": "Causally-guided Regularization of Graph Attention Improves  Generalizability",
    "abstract": "However, the inferred attentions are vulnerable to spurious correlations and connectivity in the training data, hampering the generalizability of the model. We introduce CAR, a general-purpose regularization framework for graph attention networks. Embodying a causal inference approach, \\methodname aligns the attention mechanism with the causal effects of active interventions on graph connectivity in a scalable manner. CAR is compatible with a variety of graph attention architectures, and we show that it systematically improves generalizability on various node classification tasks. Our ablation studies indicate that \\methodname hones in on the aspects of graph structure most pertinent to the prediction (e.g., homophily), and does so more effectively than alternative approaches. Finally, we also show that CAR enhances interpretability of attention weights by accentuating node-neighbor relations that point to causal hypotheses. For social media network-sized graphs, a CAR-guided graph rewiring approach could allow us to combine the scalability of graph convolutional methods with the higher performance of graph attention. ",
    "url": "https://arxiv.org/abs/2210.10946",
    "authors": [
      "Alexander P. Wu",
      "Thomas Markovich",
      "Bonnie Berger",
      "Nils Hammerla",
      "Rohit Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10965",
    "title": "IDM-Follower: A Model-Informed Deep Learning Method for Long-Sequence  Car-Following Trajectory Prediction",
    "abstract": "Model-based and learning-based methods are two major types of methodologies to model car following behaviors. Model-based methods describe the car-following behaviors with explicit mathematical equations, while learning-based methods focus on getting a mapping between inputs and outputs. Both types of methods have advantages and weaknesses. Meanwhile, most car-following models are generative and only consider the inputs of the speed, position, and acceleration of the last time step. To address these issues, this study proposes a novel framework called IDM-Follower that can generate a sequence of following vehicle trajectory by a recurrent autoencoder informed by a physical car-following model, the Intelligent Driving Model (IDM).We implement a novel structure with two independent encoders and a self-attention decoder that could sequentially predict the following trajectories. A loss function considering the discrepancies between predictions and labeled data integrated with discrepancies from model-based predictions is implemented to update the neural network parameters. Numerical experiments with multiple settings on simulation and NGSIM datasets show that the IDM-Follower can improve the prediction performance compared to the model-based or learning-based methods alone. Analysis on different noise levels also shows good robustness of the model. ",
    "url": "https://arxiv.org/abs/2210.10965",
    "authors": [
      "Yilin Wang",
      "Yiheng Feng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.10969",
    "title": "SSiT: Saliency-guided Self-supervised Image Transformer for Diabetic  Retinopathy Grading",
    "abstract": "Self-supervised learning (SSL) has been widely applied to learn image representations through exploiting unlabeled images. However, it has not been fully explored in the medical image analysis field. In this work, we propose Saliency-guided Self-Supervised image Transformer (SSiT) for diabetic retinopathy (DR) grading from fundus images. We novelly introduce saliency maps into SSL, with a goal of guiding self-supervised pre-training with domain-specific prior knowledge. Specifically, two saliency-guided learning tasks are employed in SSiT: (1) We conduct saliency-guided contrastive learning based on the momentum contrast, wherein we utilize fundus images' saliency maps to remove trivial patches from the input sequences of the momentum-updated key encoder. And thus, the key encoder is constrained to provide target representations focusing on salient regions, guiding the query encoder to capture salient features. (2) We train the query encoder to predict the saliency segmentation, encouraging preservation of fine-grained information in the learned representations. Extensive experiments are conducted on four publicly-accessible fundus image datasets. The proposed SSiT significantly outperforms other representative state-of-the-art SSL methods on all datasets and under various evaluation settings, establishing the effectiveness of the learned representations from SSiT. The source code is available at https://github.com/YijinHuang/SSiT. ",
    "url": "https://arxiv.org/abs/2210.10969",
    "authors": [
      "Yijin Huang",
      "Junyan Lyu",
      "Pujin Cheng",
      "Roger Tam",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10972",
    "title": "A Multimodal Sensor Fusion Framework Robust to Missing Modalities for  Person Recognition",
    "abstract": "Utilizing the sensor characteristics of the audio, visible camera, and thermal camera, the robustness of person recognition can be enhanced. Existing multimodal person recognition frameworks are primarily formulated assuming that multimodal data is always available. In this paper, we propose a novel trimodal sensor fusion framework using the audio, visible, and thermal camera, which addresses the missing modality problem. In the framework, a novel deep latent embedding framework, termed the AVTNet, is proposed to learn multiple latent embeddings. Also, a novel loss function, termed missing modality loss, accounts for possible missing modalities based on the triplet loss calculation while learning the individual latent embeddings. Additionally, a joint latent embedding utilizing the trimodal data is learnt using the multi-head attention transformer, which assigns attention weights to the different modalities. The different latent embeddings are subsequently used to train a deep neural network. The proposed framework is validated on the Speaking Faces dataset. A comparative analysis with baseline algorithms shows that the proposed framework significantly increases the person recognition accuracy while accounting for missing modalities. ",
    "url": "https://arxiv.org/abs/2210.10972",
    "authors": [
      "Vijay John",
      "Yasutomo Kawanishi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10983",
    "title": "PSA-Det3D: Pillar Set Abstraction for 3D object Detection",
    "abstract": "Small object detection for 3D point cloud is a challenging problem because of two limitations: (1) Perceiving small objects is much more diffcult than normal objects due to the lack of valid points. (2) Small objects are easily blocked which breaks the shape of their meshes in 3D point cloud. In this paper, we propose a pillar set abstraction (PSA) and foreground point compensation (FPC) and design a point-based detection network, PSA-Det3D, to improve the detection performance for small object. The PSA embeds a pillar query operation on the basis of set abstraction (SA) to expand its receptive field of the network, which can aggregate point-wise features effectively. To locate more occluded objects, we persent a proposal generation layer consisting of a foreground point segmentation and a FPC module. Both the foreground points and the estimated centers are finally fused together to generate the detection result. The experiments on the KITTI 3D detection benchmark show that our proposed PSA-Det3D outperforms other algorithms with high accuracy for small object detection. ",
    "url": "https://arxiv.org/abs/2210.10983",
    "authors": [
      "Zhicong Huang",
      "Jingwen Zhao",
      "Zhijie Zheng",
      "Dihu Chena",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10984",
    "title": "RAIS: Robust and Accurate Interactive Segmentation via Continual  Learning",
    "abstract": "Interactive image segmentation aims at segmenting a target region through a way of human-computer interaction. Recent works based on deep learning have achieved excellent performance, while most of them focus on improving the accuracy of the training set and ignore potential improvement on the test set. In the inference phase, they tend to have a good performance on similar domains to the training set, and lack adaptability to domain shift, so they require more user efforts to obtain satisfactory results. In this work, we propose RAIS, a robust and accurate architecture for interactive segmentation with continuous learning, where the model can learn from both train and test data sets. For efficient learning on the test set, we propose a novel optimization strategy to update global and local parameters with a basic segmentation module and adaptation module, respectively. Moreover, we perform extensive experiments on several benchmarks that show our method can handle data distribution shifts and achieves SOTA performance compared with recent interactive segmentation methods. Besides, our method also shows its robustness in the datasets of remote sensing and medical imaging where the data domains are completely different between training and testing. ",
    "url": "https://arxiv.org/abs/2210.10984",
    "authors": [
      "Yuying Hao",
      "Yi Liu",
      "Juncai Peng",
      "Haoyi Xiong",
      "Guowei Chen",
      "Shiyu Tang",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10992",
    "title": "NIFT: Neural Interaction Field and Template for Object Manipulation",
    "abstract": "We introduce NIFT, Neural Interaction Field and Template, a descriptive and robust interaction representation of object manipulations to facilitate imitation learning. Given a few object manipulation demos, NIFT guides the generation of the interaction imitation for a new object instance by matching the Neural Interaction Template (NIT) extracted from the demos to the Neural Interaction Field (NIF) defined for the new object. Specifically, the NIF is a neural field which encodes the relationship between each spatial point and a given object, where the relative position is defined by a spherical distance function rather than occupancies or signed distances, which are commonly adopted by conventional neural fields but less informative. For a given demo interaction, the corresponding NIT is defined by a set of spatial points sampled in the NIF of the demo object with associated neural features. To better capture the interaction, the points are sampled on the interaction bisector surface, which consists of points that are equidistant to two interacting objects and has been used extensively for interaction representation. With both point selection and pointwise features defined for better interaction encoding, NIT effectively guides the feature matching in the NIFs of the new object instances to optimize the object poses to realize the manipulation while imitating the demo interactions. Experiments show that our NIFT solution outperforms state-of-the-art imitation learning methods for object manipulation and generalizes better to objects from new categories. ",
    "url": "https://arxiv.org/abs/2210.10992",
    "authors": [
      "Zeyu Huang",
      "Juzhan Xu",
      "Sisi Dai",
      "Kai Xu",
      "Hao Zhang",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.10993",
    "title": "A Magnetic Framelet-Based Convolutional Neural Network for Directed  Graphs",
    "abstract": "Spectral Graph Convolutional Networks (spectral GCNNs), a powerful tool for analyzing and processing graph data, typically apply frequency filtering via Fourier transform to obtain representations with selective information. Although research shows that spectral GCNNs can be enhanced by framelet-based filtering, the massive majority of such research only considers undirected graphs. In this paper, we introduce Framelet-MagNet, a magnetic framelet-based spectral GCNN for directed graphs (digraphs). The model applies the framelet transform to digraph signals to form a more sophisticated representation for filtering. Digraph framelets are constructed with the complex-valued magnetic Laplacian, simultaneously leading to signal processing in both real and complex domains. We empirically validate the predictive power of Framelet-MagNet over a range of state-of-the-art models in node classification, link prediction, and denoising. ",
    "url": "https://arxiv.org/abs/2210.10993",
    "authors": [
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.10994",
    "title": "MBTI Personality Prediction for Fictional Characters Using Movie Scripts",
    "abstract": "An NLP model that understands stories should be able to understand the characters in them. To support the development of neural models for this purpose, we construct a benchmark, Story2Personality. The task is to predict a movie character's MBTI or Big 5 personality types based on the narratives of the character. Experiments show that our task is challenging for the existing text classification models, as none is able to largely outperform random guesses. We further proposed a multi-view model for personality prediction using both verbal and non-verbal descriptions, which gives improvement compared to using only verbal descriptions. The uniqueness and challenges in our dataset call for the development of narrative comprehension techniques from the perspective of understanding characters. ",
    "url": "https://arxiv.org/abs/2210.10994",
    "authors": [
      "Yisi Sang",
      "Xiangyang Mou",
      "Mo Yu",
      "Dakuo Wang",
      "Jing Li",
      "Jeffrey Stanton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11012",
    "title": "Law Article-Enhanced Legal Case Matching: a Model-Agnostic Causal  Learning Approach",
    "abstract": "Legal case matching, which automatically constructs a model to estimate the similarities between the source and target cases, has played an essential role in intelligent legal systems. Semantic text matching models have been applied to the task where the source and target legal cases are considered as long-form text documents. These general-purpose matching models make the predictions solely based on the texts in the legal cases, overlooking the essential role of the law articles in legal case matching. In the real world, the matching results (e.g., relevance labels) are dramatically affected by the law articles because the contents and the judgments of a legal case are radically formed on the basis of law. From the causal sense, a matching decision is affected by the mediation effect from the cited law articles by the legal cases, and the direct effect of the key circumstances (e.g., detailed fact descriptions) in the legal cases. In light of the observation, this paper proposes a model-agnostic causal learning framework called Law-Match, under which the legal case matching models are learned by respecting the corresponding law articles. Given a pair of legal cases and the related law articles, Law-Match considers the embeddings of the law articles as instrumental variables (IVs), and the embeddings of legal cases as treatments. Using IV regression, the treatments can be decomposed into law-related and law-unrelated parts, respectively reflecting the mediation and direct effects. These two parts are then combined with different weights to collectively support the final matching prediction. We show that the framework is model-agnostic, and a number of legal case matching models can be applied as the underlying models. Comprehensive experiments show that Law-Match can outperform state-of-the-art baselines on three public datasets. ",
    "url": "https://arxiv.org/abs/2210.11012",
    "authors": [
      "Zhongxiang Sun",
      "Jun Xu",
      "Xiao Zhang",
      "Zhenhua Dong",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.11016",
    "title": "Towards Sustainable Self-supervised Learning",
    "abstract": "Although increasingly training-expensive, most self-supervised learning (SSL) models have repeatedly been trained from scratch but not fully utilized, since only a few SOTAs are employed for downstream tasks. In this work, we explore a sustainable SSL framework with two major challenges: i) learning a stronger new SSL model based on the existing pretrained SSL model, also called as \"base\" model, in a cost-friendly manner, ii) allowing the training of the new model to be compatible with various base models. We propose a Target-Enhanced Conditional (TEC) scheme which introduces two components to the existing mask-reconstruction based SSL. Firstly, we propose patch-relation enhanced targets which enhances the target given by base model and encourages the new model to learn semantic-relation knowledge from the base model by using incomplete inputs. This hardening and target-enhancing help the new model surpass the base model, since they enforce additional patch relation modeling to handle incomplete input. Secondly, we introduce a conditional adapter that adaptively adjusts new model prediction to align with the target of different base models. Extensive experimental results show that our TEC scheme can accelerate the learning speed, and also improve SOTA SSL base models, e.g., MAE and iBOT, taking an explorative step towards sustainable SSL. ",
    "url": "https://arxiv.org/abs/2210.11016",
    "authors": [
      "Shanghua Gao",
      "Pan Zhou",
      "Ming-Ming Cheng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11018",
    "title": "Infrared and visible image fusion via dual-domain adversarial learning",
    "abstract": "The GAN-based infrared and visible image fusion methods have gained ever-increasing attention due to its effectiveness and superiority. However, the existing methods adopt the global pixel distribution of source images as the basis for discrimination, which fails to focus on the key modality information. Moreover, the dual-discriminator based methods suffer from the confrontation between the discriminators. To this end, we propose a dual-domain adversarial based infrared and visible image fusion method (D2AFGAN). In this method, two unique discrimination strategies are designed to improve the fusion performance. Specifically, we introduce the spatial attention modules (SAM) into the generator to obtain the spatial attention maps, and then the attention maps are utilized to force the discrimination of infrared images to focus on the target regions. In addition, we extend the discrimination range of visible information to the wavelet subspace, which can force the generator to restore the high-frequency details of visible images. Ablation experiments demonstrate the effectiveness of our method in eliminating the confrontation between discriminators. And the comparison experiments on public datasets demonstrate the effectiveness and superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.11018",
    "authors": [
      "Xiaowen Liu",
      "Renhua Wang",
      "Hongtao Huo",
      "Jing Li",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.11020",
    "title": "Maximum Common Subgraph Guided Graph Retrieval: Late and Early  Interaction Networks",
    "abstract": "The graph retrieval problem is to search in a large corpus of graphs for ones that are most similar to a query graph. A common consideration for scoring similarity is the maximum common subgraph (MCS) between the query and corpus graphs, usually counting the number of common edges (i.e., MCES). In some applications, it is also desirable that the common subgraph be connected, i.e., the maximum common connected subgraph (MCCS). Finding exact MCES and MCCS is intractable, but may be unnecessary if ranking corpus graphs by relevance is the goal. We design fast and trainable neural functions that approximate MCES and MCCS well. Late interaction methods compute dense representations for the query and corpus graph separately, and compare these representations using simple similarity functions at the last stage, leading to highly scalable systems. Early interaction methods combine information from both graphs right from the input stages, are usually considerably more accurate, but slower. We propose both late and early interaction neural MCES and MCCS formulations. They are both based on a continuous relaxation of a node alignment matrix between query and corpus nodes. For MCCS, we propose a novel differentiable network for estimating the size of the largest connected common subgraph. Extensive experiments with seven data sets show that our proposals are superior among late interaction models in terms of both accuracy and speed. Our early interaction models provide accuracy competitive with the state of the art, at substantially greater speeds. ",
    "url": "https://arxiv.org/abs/2210.11020",
    "authors": [
      "Indradyumna Roy",
      "Soumen Chakrabarti",
      "Abir De"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.11021",
    "title": "Independence Testing-Based Approach to Causal Discovery under  Measurement Error and Linear Non-Gaussian Models",
    "abstract": "Causal discovery aims to recover causal structures generating the observational data. Despite its success in certain problems, in many real-world scenarios the observed variables are not the target variables of interest, but the imperfect measures of the target variables. Causal discovery under measurement error aims to recover the causal graph among unobserved target variables from observations made with measurement error. We consider a specific formulation of the problem, where the unobserved target variables follow a linear non-Gaussian acyclic model, and the measurement process follows the random measurement error model. Existing methods on this formulation rely on non-scalable over-complete independent component analysis (OICA). In this work, we propose the Transformed Independent Noise (TIN) condition, which checks for independence between a specific linear transformation of some measured variables and certain other measured variables. By leveraging the non-Gaussianity and higher-order statistics of data, TIN is informative about the graph structure among the unobserved target variables. By utilizing TIN, the ordered group decomposition of the causal model is identifiable. In other words, we could achieve what once required OICA to achieve by only conducting independence tests. Experimental results on both synthetic and real-world data demonstrate the effectiveness and reliability of our method. ",
    "url": "https://arxiv.org/abs/2210.11021",
    "authors": [
      "Haoyue Dai",
      "Peter Spirtes",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.11024",
    "title": "A survey on Self Supervised learning approaches for improving Multimodal  representation learning",
    "abstract": "Recently self supervised learning has seen explosive growth and use in variety of machine learning tasks because of its ability to avoid the cost of annotating large-scale datasets. This paper gives an overview for best self supervised learning approaches for multimodal learning. The presented approaches have been aggregated by extensive study of the literature and tackle the application of self supervised learning in different ways. The approaches discussed are cross modal generation, cross modal pretraining, cyclic translation, and generating unimodal labels in self supervised fashion. ",
    "url": "https://arxiv.org/abs/2210.11024",
    "authors": [
      "Naman Goyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11029",
    "title": "DeepRING: Learning Roto-translation Invariant Representation for LiDAR  based Place Recognition",
    "abstract": "LiDAR based place recognition is popular for loop closure detection and re-localization. In recent years, deep learning brings improvements to place recognition by learnable feature extraction. However, these methods degenerate when the robot re-visits previous places with large perspective difference. To address the challenge, we propose DeepRING to learn the roto-translation invariant representation from LiDAR scan, so that robot visits the same place with different perspective can have similar representations. There are two keys in DeepRING: the feature is extracted from sinogram, and the feature is aggregated by magnitude spectrum. The two steps keeps the final representation with both discrimination and roto-translation invariance. Moreover, we state the place recognition as a one-shot learning problem with each place being a class, leveraging relation learning to build representation similarity. Substantial experiments are carried out on public datasets, validating the effectiveness of each proposed component, and showing that DeepRING outperforms the comparative methods, especially in dataset level generalization. ",
    "url": "https://arxiv.org/abs/2210.11029",
    "authors": [
      "Sha Lu",
      "Xuecheng Xu",
      "Li Tang",
      "Rong Xiong",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.11033",
    "title": "Neural Estimation of Submodular Functions with Applications to  Differentiable Subset Selection",
    "abstract": "Submodular functions and variants, through their ability to characterize diversity and coverage, have emerged as a key tool for data selection and summarization. Many recent approaches to learn submodular functions suffer from limited expressiveness. In this work, we propose FLEXSUBNET, a family of flexible neural models for both monotone and non-monotone submodular functions. To fit a latent submodular function from (set, value) observations, FLEXSUBNET applies a concave function on modular functions in a recursive manner. We do not draw the concave function from a restricted family, but rather learn from data using a highly expressive neural network that implements a differentiable quadrature procedure. Such an expressive neural model for concave functions may be of independent interest. Next, we extend this setup to provide a novel characterization of monotone \\alpha-submodular functions, a recently introduced notion of approximate submodular functions. We then use this characterization to design a novel neural model for such functions. Finally, we consider learning submodular set functions under distant supervision in the form of (perimeter-set, high-value-subset) pairs. This yields a novel subset selection method based on an order-invariant, yet greedy sampler built around the above neural set functions. Our experiments on synthetic and real data show that FLEXSUBNET outperforms several baselines. ",
    "url": "https://arxiv.org/abs/2210.11033",
    "authors": [
      "Abir De",
      "Soumen Chakrabarti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11034",
    "title": "Enhancing Out-of-Distribution Detection in Natural Language  Understanding via Implicit Layer Ensemble",
    "abstract": "Out-of-distribution (OOD) detection aims to discern outliers from the intended data distribution, which is crucial to maintaining high reliability and a good user experience. Most recent studies in OOD detection utilize the information from a single representation that resides in the penultimate layer to determine whether the input is anomalous or not. Although such a method is straightforward, the potential of diverse information in the intermediate layers is overlooked. In this paper, we propose a novel framework based on contrastive learning that encourages intermediate features to learn layer-specialized representations and assembles them implicitly into a single representation to absorb rich information in the pre-trained language model. Extensive experiments in various intent classification and OOD datasets demonstrate that our approach is significantly more effective than other works. ",
    "url": "https://arxiv.org/abs/2210.11034",
    "authors": [
      "Hyunsoo Cho",
      "Choonghyun Park",
      "Jaewook Kang",
      "Kang Min Yoo",
      "Taeuk Kim",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11035",
    "title": "PointTAD: Multi-Label Temporal Action Detection with Learnable Query  Points",
    "abstract": "Traditional temporal action detection (TAD) usually handles untrimmed videos with small number of action instances from a single label (e.g., ActivityNet, THUMOS). However, this setting might be unrealistic as different classes of actions often co-occur in practice. In this paper, we focus on the task of multi-label temporal action detection that aims to localize all action instances from a multi-label untrimmed video. Multi-label TAD is more challenging as it requires for fine-grained class discrimination within a single video and precise localization of the co-occurring instances. To mitigate this issue, we extend the sparse query-based detection paradigm from the traditional TAD and propose the multi-label TAD framework of PointTAD. Specifically, our PointTAD introduces a small set of learnable query points to represent the important frames of each action instance. This point-based representation provides a flexible mechanism to localize the discriminative frames at boundaries and as well the important frames inside the action. Moreover, we perform the action decoding process with the Multi-level Interactive Module to capture both point-level and instance-level action semantics. Finally, our PointTAD employs an end-to-end trainable framework simply based on RGB input for easy deployment. We evaluate our proposed method on two popular benchmarks and introduce the new metric of detection-mAP for multi-label TAD. Our model outperforms all previous methods by a large margin under the detection-mAP metric, and also achieves promising results under the segmentation-mAP metric. Code is available at https://github.com/MCG-NJU/PointTAD. ",
    "url": "https://arxiv.org/abs/2210.11035",
    "authors": [
      "Jing Tan",
      "Xiaotong Zhao",
      "Xintian Shi",
      "Bing Kang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11055",
    "title": "Shepherding Heterogeneous Flock with Model-Based Discrimination",
    "abstract": "The problem of guiding a flock of agents to a destination by the repulsion forces exerted by a smaller number of external agents is called the shepherding problem. This problem has attracted attention due to its potential applications, including diverting birds away for preventing airplane accidents, recovering spilled oil in the ocean, and guiding a swarm of robots for mapping. Although there have been various studies on the shepherding problem, most of them place the uniformity assumption on the dynamics of agents to be guided. However, we can find various practical situations where this assumption does not necessarily hold. In this paper, we propose a shepherding method for a flock of agents consisting of normal agents to be guided and other variant agents. In this method, the shepherd discriminates normal and variant agents based on their behaviors' deviation from the one predicted by the potentially inaccurate model of the normal agents. As for the discrimination process, we propose two methods using static and dynamic thresholds. Our simulation results show that the proposed methods outperform a conventional method for various types of variant agents. ",
    "url": "https://arxiv.org/abs/2210.11055",
    "authors": [
      "Anna Fujioka",
      "Masaki Ogura",
      "Naoki Wakamiya"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.11058",
    "title": "Representation Learning with Diffusion Models",
    "abstract": "Diffusion models (DMs) have achieved state-of-the-art results for image synthesis tasks as well as density estimation. Applied in the latent space of a powerful pretrained autoencoder (LDM), their immense computational requirements can be significantly reduced without sacrificing sampling quality. However, DMs and LDMs lack a semantically meaningful representation space as the diffusion process gradually destroys information in the latent variables. We introduce a framework for learning such representations with diffusion models (LRDM). To that end, a LDM is conditioned on the representation extracted from the clean image by a separate encoder. In particular, the DM and the representation encoder are trained jointly in order to learn rich representations specific to the generative denoising process. By introducing a tractable representation prior, we can efficiently sample from the representation distribution for unconditional image synthesis without training of any additional model. We demonstrate that i) competitive image generation results can be achieved with image-parameterized LDMs, ii) LRDMs are capable of learning semantically meaningful representations, allowing for faithful image reconstructions and semantic interpolations. Our implementation is available at https://github.com/jeremiastraub/diffusion. ",
    "url": "https://arxiv.org/abs/2210.11058",
    "authors": [
      "Jeremias Traub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11060",
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "abstract": "This paper introduces Doc2Bot, a novel dataset for building machines that help users seek information via conversations. This is of particular interest for companies and organizations that own a large number of manuals or instruction books. Despite its potential, the nature of our task poses several challenges: (1) documents contain various structures that hinder the ability of machines to comprehend, and (2) user information needs are often underspecified. Compared to prior datasets that either focus on a single structural type or overlook the role of questioning to uncover user needs, the Doc2Bot dataset is developed to target such challenges systematically. Our dataset contains over 100,000 turns based on Chinese documents from five domains, larger than any prior document-grounded dialog dataset for information seeking. We propose three tasks in Doc2Bot: (1) dialog state tracking to track user intentions, (2) dialog policy learning to plan system actions and contents, and (3) response generation which generates responses based on the outputs of the dialog policy. Baseline methods based on the latest deep learning models are presented, indicating that our proposed tasks are challenging and worthy of further research. ",
    "url": "https://arxiv.org/abs/2210.11060",
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam-Tu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.11061",
    "title": "Analyzing the Robustness of Decentralized Horizontal and Vertical  Federated Learning Architectures in a Non-IID Scenario",
    "abstract": "Federated learning (FL) allows participants to collaboratively train machine and deep learning models while protecting data privacy. However, the FL paradigm still presents drawbacks affecting its trustworthiness since malicious participants could launch adversarial attacks against the training process. Related work has studied the robustness of horizontal FL scenarios under different attacks. However, there is a lack of work evaluating the robustness of decentralized vertical FL and comparing it with horizontal FL architectures affected by adversarial attacks. Thus, this work proposes three decentralized FL architectures, one for horizontal and two for vertical scenarios, namely HoriChain, VertiChain, and VertiComb. These architectures present different neural networks and training protocols suitable for horizontal and vertical scenarios. Then, a decentralized, privacy-preserving, and federated use case with non-IID data to classify handwritten digits is deployed to evaluate the performance of the three architectures. Finally, a set of experiments computes and compares the robustness of the proposed architectures when they are affected by different data poisoning based on image watermarks and gradient poisoning adversarial attacks. The experiments show that even though particular configurations of both attacks can destroy the classification performance of the architectures, HoriChain is the most robust one. ",
    "url": "https://arxiv.org/abs/2210.11061",
    "authors": [
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Alberto Huertas Celdr\u00e1n",
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Daniel Demeter",
      "G\u00e9r\u00f4me Bovet",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11064",
    "title": "Competitive Equilibrium for Dynamic Multi-Agent Systems: Social Shaping  and Price Trajectories",
    "abstract": "In this paper, we consider dynamic multi-agent systems (MAS) for decentralized resource allocation. The MAS operates at a competitive equilibrium to ensure supply and demand are balanced. First, we investigate the MAS over a finite horizon. The utility functions of agents are parameterized to incorporate individual preferences. We shape individual preferences through a set of utility functions to guarantee the resource price at a competitive equilibrium remains socially acceptable, i.e., the price is upper-bounded by an affordability threshold. We show this problem is solvable at the conceptual level. Next, we consider quadratic MAS and formulate the associated social shaping problem as a multi-agent linear quadratic regulator (LQR) problem which enables us to propose explicit utility sets using quadratic programming and dynamic programming. Then, a numerical algorithm is presented for calculating a tight range of the preference function parameters which guarantees a socially accepted price. We investigate the properties of a competitive equilibrium over an infinite horizon. Considering general utility functions, we show that under feasibility assumptions, any competitive equilibrium maximizes the social welfare. Then, we prove that for sufficiently small initial conditions, the social welfare maximization solution constitutes a competitive equilibrium with zero price. We also prove for general feasible initial conditions, there exists a time instant after which the optimal price, corresponding to a competitive equilibrium, becomes zero. Finally, we specifically focus on quadratic MAS and propose explicit results. ",
    "url": "https://arxiv.org/abs/2210.11064",
    "authors": [
      "Zeinab Salehi",
      "Yijun Chen",
      "Elizabeth L. Ratnam",
      "Ian R. Petersen",
      "Guodong Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.11068",
    "title": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly  Detection Performance",
    "abstract": "Accurately extracting driving events is the way to maximize computational efficiency and anomaly detection performance in the tire frictional nose-based anomaly detection task. This study proposes a concise and highly useful method for improving the precision of the event extraction that is hindered by extra noise such as wind noise, which is difficult to characterize clearly due to its randomness. The core of the proposed method is based on the identification of the road friction sound corresponding to the frequency of interest and removing the opposite characteristics with several frequency filters. Our method enables precision maximization of driving event extraction while improving anomaly detection performance by an average of 8.506%. Therefore, we conclude our method is a practical solution suitable for road surface anomaly detection purposes in outdoor edge computing environments. ",
    "url": "https://arxiv.org/abs/2210.11068",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Won Seok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.11075",
    "title": "Freeze then Train: Towards Provable Representation Learning under  Spurious Correlations and Feature Noise",
    "abstract": "The existence of spurious correlations such as image backgrounds in the training environment can make empirical risk minimization (ERM) perform badly in the test environment. To address this problem, Kirichenko et al. (2022) empirically found that the core features that are causally related to the outcome can still be learned well even with the presence of spurious correlations. This opens a promising strategy to first train a feature learner rather than a classifier, and then perform linear probing (last layer retraining) in the test environment. However, a theoretical understanding of when and why this approach works is lacking. In this paper, we find that core features are only learned well when they are less noisy than spurious features, which is not necessarily true in practice. We provide both theories and experiments to support this finding and to illustrate the importance of feature noise. Moreover, we propose an algorithm called Freeze then Train (FTT), that first freezes certain salient features and then trains the rest of the features using ERM. We theoretically show that FTT preserves features that are more beneficial to test time probing. Across two commonly used real-world benchmarks, FTT outperforms ERM, JTT and CVaR-DRO, with especially substantial improvement in accuracy (by 4.8%) when the feature noise is large. ",
    "url": "https://arxiv.org/abs/2210.11075",
    "authors": [
      "Haotian Ye",
      "James Zou",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11092",
    "title": "Robustcaps: a transformation-robust capsule network for image  classification",
    "abstract": "Geometric transformations of the training data as well as the test data present challenges to the use of deep neural networks to vision-based learning tasks. In order to address this issue, we present a deep neural network model that exhibits the desirable property of transformation-robustness. Our model, termed RobustCaps, uses group-equivariant convolutions in an improved capsule network model. RobustCaps uses a global context-normalised procedure in its routing algorithm to learn transformation-invariant part-whole relationships within image data. This learning of such relationships allows our model to outperform both capsule and convolutional neural network baselines on transformation-robust classification tasks. Specifically, RobustCaps achieves state-of-the-art accuracies on CIFAR-10, FashionMNIST, and CIFAR-100 when the images in these datasets are subjected to train and test-time rotations and translations. ",
    "url": "https://arxiv.org/abs/2210.11092",
    "authors": [
      "Sai Raam Venkataraman",
      "S. Balasubramanian",
      "R. Raghunatha Sarma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11095",
    "title": "Iterative collaborative routing among equivariant capsules for  transformation-robust capsule networks",
    "abstract": "Transformation-robustness is an important feature for machine learning models that perform image classification. Many methods aim to bestow this property to models by the use of data augmentation strategies, while more formal guarantees are obtained via the use of equivariant models. We recognise that compositional, or part-whole structure is also an important aspect of images that has to be considered for building transformation-robust models. Thus, we propose a capsule network model that is, at once, equivariant and compositionality-aware. Equivariance of our capsule network model comes from the use of equivariant convolutions in a carefully-chosen novel architecture. The awareness of compositionality comes from the use of our proposed novel, iterative, graph-based routing algorithm, termed Iterative collaborative routing (ICR). ICR, the core of our contribution, weights the predictions made for capsules based on an iteratively averaged score of the degree-centralities of its nearest neighbours. Experiments on transformed image classification on FashionMNIST, CIFAR-10, and CIFAR-100 show that our model that uses ICR outperforms convolutional and capsule baselines to achieve state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2210.11095",
    "authors": [
      "Sai Raam Venkataraman",
      "S. Balasubramanian",
      "R. Raghunatha Sarma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11096",
    "title": "Robust One-Shot Singing Voice Conversion",
    "abstract": "Many existing works on singing voice conversion (SVC) require clean recordings of target singer's voice for training. However, it is often difficult to collect them in advance and singing voices are often distorted with reverb and accompaniment music. In this work, we propose robust one-shot SVC (ROSVC) that performs any-to-any SVC robustly even on such distorted singing voices using less than 10s of a reference voice. To this end, we propose two-stage training method called Robustify. In the first stage, a novel one-shot SVC model based on a generative adversarial network is trained on clean data to ensure high-quality conversion. In the second stage, enhancement modules are introduced to the encoders of the model to improve the robustness against distortions in the feature space. Experimental results show that the proposed method outperforms one-shot SVC baselines for both seen and unseen singers and greatly improves the robustness against the distortions. ",
    "url": "https://arxiv.org/abs/2210.11096",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.11106",
    "title": "Robust Multi-Read Reconstruction from Contaminated Clusters Using Deep  Neural Network for DNA Storage",
    "abstract": "DNA has immense potential as an emerging data storage medium. The principle of DNA storage is the conversion and flow of digital information between binary code stream, quaternary base, and actual DNA fragments. This process will inevitably introduce errors, posing challenges to accurate data recovery. Sequence reconstruction consists of inferring the DNA reference from a cluster of erroneous copies. A common assumption in existing methods is that all the strands within a cluster are noisy copies originating from the same reference, thereby contributing equally to the reconstruction. However, this is not always valid considering the existence of contaminated sequences caused, for example, by DNA fragmentation and rearrangement during the DNA storage process.This paper proposed a robust multi-read reconstruction model using DNN, which is resilient to contaminated clusters with outlier sequences, as well as to noisy reads with IDS errors. The effectiveness and robustness of the method are validated on three next-generation sequencing datasets, where a series of comparative experiments are performed by simulating varying contamination levels that occurring during the process of DNA storage. ",
    "url": "https://arxiv.org/abs/2210.11106",
    "authors": [
      "Yun Qin",
      "Fei Zhu",
      "Bo Xi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.11124",
    "title": "Forest: Structural Code Editing with Multiple Cursors",
    "abstract": "Software developers frequently refactor code. Often, a single logical refactoring change involves changing multiple related components in a source base such as renaming each occurrence of a variable or function. While many code editors can perform such common and generic refactorings, they do not support more complex refactorings or those that are specific to a given code base. For those, as a flexible - albeit less interactive - alternative, developers can write refactoring scripts that can implement arbitrarily complex logic by manipulating the program's tree representation. In this work, we present Forest, a structural code editor that aims to bridge the gap between the interactiveness of code editors and the expressiveness of refactoring scripts. While structural editors have occupied a niche as general code editors, the key insight of this work is that they enable a novel structural multi-cursor design that allows Forest to reach a similar expressiveness as refactoring scripts; Forest allows to perform a single action simultaneously in multiple program locations and thus support complex refactorings. To support interactivity, Forest provides features typical for text code editors such as writing and displaying the program through its textual representation. Our evaluation demonstrates that Forest allows performing edits similar to those from refactoring scripts, while still being interactive. We attempted to perform edits from 48 real-world refactoring scripts using Forest and found that 11 were possible, while another 17 would be possible with added features. We believe that a multi-cursor setting plays to the strengths of structural editing, since it benefits from reliable and expressive commands. Our results suggest that multi-cursor structural editors could be practical for performing small-scale specialized refactorings. ",
    "url": "https://arxiv.org/abs/2210.11124",
    "authors": [
      "Philippe Voinov",
      "Manuel Rigger",
      "Zhendong Su"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.11151",
    "title": "Transformer-based Entity Typing in Knowledge Graphs",
    "abstract": "We investigate the knowledge graph entity typing task which aims at inferring plausible entity types. In this paper, we propose a novel Transformer-based Entity Typing (TET) approach, effectively encoding the content of neighbors of an entity. More precisely, TET is composed of three different mechanisms: a local transformer allowing to infer missing types of an entity by independently encoding the information provided by each of its neighbors; a global transformer aggregating the information of all neighbors of an entity into a single long sequence to reason about more complex entity types; and a context transformer integrating neighbors content based on their contribution to the type inference through information exchange between neighbor pairs. Furthermore, TET uses information about class membership of types to semantically strengthen the representation of an entity. Experiments on two real-world datasets demonstrate the superior performance of TET compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2210.11151",
    "authors": [
      "Zhiwei Hu",
      "V\u00edctor Guti\u00e9rrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11161",
    "title": "From Modelling to Understanding Children's Behaviour in the Context of  Robotics and Social Artificial Intelligence",
    "abstract": "Understanding and modelling children's cognitive processes and their behaviour in the context of their interaction with robots and social artificial intelligence systems is a fundamental prerequisite for meaningful and effective robot interventions. However, children's development involve complex faculties such as exploration, creativity and curiosity which are challenging to model. Also, often children express themselves in a playful way which is different from a typical adult behaviour. Different children also have different needs, and it remains a challenge in the current state of the art that those of neurodiverse children are under-addressed. With this workshop, we aim to promote a common ground among different disciplines such as developmental sciences, artificial intelligence and social robotics and discuss cutting-edge research in the area of user modelling and adaptive systems for children. ",
    "url": "https://arxiv.org/abs/2210.11161",
    "authors": [
      "Serge Thill",
      "Vicky Charisi",
      "Tony Belpaeme",
      "Ana Paiva"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11164",
    "title": "Graph Neural Networks with Trainable Adjacency Matrices for Fault  Diagnosis on Multivariate Sensor Data",
    "abstract": "Timely detected anomalies in the chemical technological processes, as well as the earliest detection of the cause of the fault, significantly reduce the production cost in the industrial factories. Data on the state of the technological process and the operation of production equipment are received by a large number of different sensors. To better predict the behavior of the process and equipment, it is necessary not only to consider the behavior of the signals in each sensor separately, but also to take into account their correlation and hidden relationships with each other. Graph-based data representation helps with this. The graph nodes can be represented as data from the different sensors, and the edges can display the influence of these data on each other. In this work, the possibility of applying graph neural networks to the problem of fault diagnosis in a chemical process is studied. It was proposed to construct a graph during the training of graph neural network. This allows to train models on data where the dependencies between the sensors are not known in advance. In this work, several methods for obtaining adjacency matrices were considered, as well as their quality was studied. It has also been proposed to use multiple adjacency matrices in one model. We showed state-of-the-art performance on the fault diagnosis task with the Tennessee Eastman Process dataset. The proposed graph neural networks outperformed the results of recurrent neural networks. ",
    "url": "https://arxiv.org/abs/2210.11164",
    "authors": [
      "Alexander Kovalenko",
      "Vitaliy Pozdnyakov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11168",
    "title": "User Value in Modern Payment Platforms: A Graph Approach",
    "abstract": "Payment platforms have significantly evolved in recent years to keep pace with the proliferation of online and cashless payments. These platforms are increasingly aligned with online social networks, allowing users to interact with each other and transfer small amounts of money in a Peer-to-Peer fashion. This poses new challenges for analysing payment data, as traditional methods are only user-centric or business-centric and neglect the network users build during the interaction. This paper proposes a first methodology for measuring user value in modern payment platforms. We combine quantitative user-centric metrics with an analysis of the graph created by users' activities and its topological features inspired by the evolution of opinions in social networks. We showcase our approach using a dataset from a large operational payment platform and show how it can support business decisions and marketing campaign design, e.g., by targeting specific users. ",
    "url": "https://arxiv.org/abs/2210.11168",
    "authors": [
      "Laura Arditti",
      "Martino Trevisan",
      "Luca Vassio",
      "Alberto De Lazzari",
      "Alberto Danese"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.11169",
    "title": "Content-based Graph Privacy Advisor",
    "abstract": "People may be unaware of the privacy risks of uploading an image online. In this paper, we present an image privacy classifier that uses scene information and object cardinality as cues for the prediction of image privacy. Our Graph Privacy Advisor (GPA) model simplifies a state-of-the-art graph model and improves its performance by refining the relevance of the content-based information extracted from the image. We determine the most informative visual features to be used for the privacy classification task and reduce the complexity of the model by replacing high-dimensional image-based feature vectors with lower-dimensional, more effective features. We also address the biased prior information by modelling object co-occurrences instead of the frequency of object occurrences in each class. ",
    "url": "https://arxiv.org/abs/2210.11169",
    "authors": [
      "Dimitrios Stoidis",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11170",
    "title": "Coordinates Are NOT Lonely -- Codebook Prior Helps Implicit Neural 3D  Representations",
    "abstract": "Implicit neural 3D representation has achieved impressive results in surface or scene reconstruction and novel view synthesis, which typically uses the coordinate-based multi-layer perceptrons (MLPs) to learn a continuous scene representation. However, existing approaches, such as Neural Radiance Field (NeRF) and its variants, usually require dense input views (i.e. 50-150) to obtain decent results. To relive the over-dependence on massive calibrated images and enrich the coordinate-based feature representation, we explore injecting the prior information into the coordinate-based network and introduce a novel coordinate-based model, CoCo-INR, for implicit neural 3D representation. The cores of our method are two attention modules: codebook attention and coordinate attention. The former extracts the useful prototypes containing rich geometry and appearance information from the prior codebook, and the latter propagates such prior information into each coordinate and enriches its feature representation for a scene or object surface. With the help of the prior information, our method can render 3D views with more photo-realistic appearance and geometries than the current methods using fewer calibrated images available. Experiments on various scene reconstruction datasets, including DTU and BlendedMVS, and the full 3D head reconstruction dataset, H3DS, demonstrate the robustness under fewer input views and fine detail-preserving capability of our proposed method. ",
    "url": "https://arxiv.org/abs/2210.11170",
    "authors": [
      "Fukun Yin",
      "Wen Liu",
      "Zilong Huang",
      "Pei Cheng",
      "Tao Chen",
      "Gang YU"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11173",
    "title": "Mathematical Justification of Hard Negative Mining via Isometric  Approximation Theorem",
    "abstract": "In deep metric learning, the Triplet Loss has emerged as a popular method to learn many computer vision and natural language processing tasks such as facial recognition, object detection, and visual-semantic embeddings. One issue that plagues the Triplet Loss is network collapse, an undesirable phenomenon where the network projects the embeddings of all data onto a single point. Researchers predominately solve this problem by using triplet mining strategies. While hard negative mining is the most effective of these strategies, existing formulations lack strong theoretical justification for their empirical success. In this paper, we utilize the mathematical theory of isometric approximation to show an equivalence between the Triplet Loss sampled by hard negative mining and an optimization problem that minimizes a Hausdorff-like distance between the neural network and its ideal counterpart function. This provides the theoretical justifications for hard negative mining's empirical efficacy. In addition, our novel application of the isometric approximation theorem provides the groundwork for future forms of hard negative mining that avoid network collapse. Our theory can also be extended to analyze other Euclidean space-based metric learning methods like Ladder Loss or Contrastive Learning. ",
    "url": "https://arxiv.org/abs/2210.11173",
    "authors": [
      "Albert Xu",
      "Jhih-Yi Hsieh",
      "Bhaskar Vundurthy",
      "Eliana Cohen",
      "Howie Choset",
      "Lu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11174",
    "title": "Overlapping Community Detection using Dynamic Dilated Aggregation in  Deep Residual GCN",
    "abstract": "Overlapping community detection is a key problem in graph mining. Some research has considered applying graph convolutional networks (GCN) to tackle the problem. However, it is still challenging to incorporate deep graph convolutional networks in the case of general irregular graphs. In this study, we design a deep dynamic residual graph convolutional network (DynaResGCN) based on our novel dynamic dilated aggregation mechanisms and a unified end-to-end encoder-decoder-based framework to detect overlapping communities in networks. The deep DynaResGCN model is used as the encoder, whereas we incorporate the Bernoulli-Poisson (BP) model as the decoder. Consequently, we apply our overlapping community detection framework in a research topics dataset without having ground truth, a set of networks from Facebook having a reliable (hand-labeled) ground truth, and in a set of very large co-authorship networks having empirical (not hand-labeled) ground truth. Our experimentation on these datasets shows significantly superior performance over many state-of-the-art methods for the detection of overlapping communities in networks. ",
    "url": "https://arxiv.org/abs/2210.11174",
    "authors": [
      "Md Nurul Muttakin",
      "Md Iqbal Hossain",
      "Md Saidur Rahman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11177",
    "title": "Towards Better Guided Attention and Human Knowledge Insertion in Deep  Convolutional Neural Networks",
    "abstract": "Attention Branch Networks (ABNs) have been shown to simultaneously provide visual explanation and improve the performance of deep convolutional neural networks (CNNs). In this work, we introduce Multi-Scale Attention Branch Networks (MSABN), which enhance the resolution of the generated attention maps, and improve the performance. We evaluate MSABN on benchmark image recognition and fine-grained recognition datasets where we observe MSABN outperforms ABN and baseline models. We also introduce a new data augmentation strategy utilizing the attention maps to incorporate human knowledge in the form of bounding box annotations of the objects of interest. We show that even with a limited number of edited samples, a significant performance gain can be achieved with this strategy. ",
    "url": "https://arxiv.org/abs/2210.11177",
    "authors": [
      "Ankit Gupta",
      "Ida-Maria Sintorn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11182",
    "title": "Facial Expression Video Generation Based-On Spatio-temporal  Convolutional GAN: FEV-GAN",
    "abstract": "Facial expression generation has always been an intriguing task for scientists and researchers all over the globe. In this context, we present our novel approach for generating videos of the six basic facial expressions. Starting from a single neutral facial image and a label indicating the desired facial expression, we aim to synthesize a video of the given identity performing the specified facial expression. Our approach, referred to as FEV-GAN (Facial Expression Video GAN), is based on Spatio-temporal Convolutional GANs, that are known to model both content and motion in the same network. Previous methods based on such a network have shown a good ability to generate coherent videos with smooth temporal evolution. However, they still suffer from low image quality and low identity preservation capability. In this work, we address this problem by using a generator composed of two image encoders. The first one is pre-trained for facial identity feature extraction and the second for spatial feature extraction. We have qualitatively and quantitatively evaluated our model on two international facial expression benchmark databases: MUG and Oulu-CASIA NIR&VIS. The experimental results analysis demonstrates the effectiveness of our approach in generating videos of the six basic facial expressions while preserving the input identity. The analysis also proves that the use of both identity and spatial features enhances the decoder ability to better preserve the identity and generate high-quality videos. The code and the pre-trained model will soon be made publicly available. ",
    "url": "https://arxiv.org/abs/2210.11182",
    "authors": [
      "Hamza Bouzid",
      "Lahoucine Ballihi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11201",
    "title": "Robust Imitation via Mirror Descent Inverse Reinforcement Learning",
    "abstract": "Recently, adversarial imitation learning has shown a scalable reward acquisition method for inverse reinforcement learning (IRL) problems. However, estimated reward signals often become uncertain and fail to train a reliable statistical model since the existing methods tend to solve hard optimization problems directly. Inspired by a first-order optimization method called mirror descent, this paper proposes to predict a sequence of reward functions, which are iterative solutions for a constrained convex problem. IRL solutions derived by mirror descent are tolerant to the uncertainty incurred by target density estimation since the amount of reward learning is regulated with respect to local geometric constraints. We prove that the proposed mirror descent update rule ensures robust minimization of a Bregman divergence in terms of a rigorous regret bound of $\\mathcal{O}(1/T)$ for step sizes $\\{\\eta_t\\}_{t=1}^{T}$. Our IRL method was applied on top of an adversarial framework, and it outperformed existing adversarial methods in an extensive suite of benchmarks. ",
    "url": "https://arxiv.org/abs/2210.11201",
    "authors": [
      "Dong-Sig Han",
      "Hyunseo Kim",
      "Hyundo Lee",
      "Je-Hwan Ryu",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11204",
    "title": "PalGAN: Image Colorization with Palette Generative Adversarial Networks",
    "abstract": "Multimodal ambiguity and color bleeding remain challenging in colorization. To tackle these problems, we propose a new GAN-based colorization approach PalGAN, integrated with palette estimation and chromatic attention. To circumvent the multimodality issue, we present a new colorization formulation that estimates a probabilistic palette from the input gray image first, then conducts color assignment conditioned on the palette through a generative model. Further, we handle color bleeding with chromatic attention. It studies color affinities by considering both semantic and intensity correlation. In extensive experiments, PalGAN outperforms state-of-the-arts in quantitative evaluation and visual comparison, delivering notable diverse, contrastive, and edge-preserving appearances. With the palette design, our method enables color transfer between images even with irrelevant contexts. ",
    "url": "https://arxiv.org/abs/2210.11204",
    "authors": [
      "Yi Wang",
      "Menghan Xia",
      "Lu Qi",
      "Jing Shao",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11212",
    "title": "Robust prescribed-time coordination control of cooperative-antagonistic  networks with disturbances",
    "abstract": "This article targets at addressing the robust prescribed-time coordination control (PTCC) problems for single-integrator cooperative-antagonistic networks (CANs) with external disturbances under arbitrary fixed signed digraphs without any structural constraints. Toward this end, the PTCC problems for nominal single-integrator CANs without disturbances are first investigated and a fully distributed control protocol with a time-varying gain, which grows to infinity as the time approaches the settling time, is proposed utilizing the relative states of neighboring agents. Then, based on the proposed control protocol for the nominal single-integrator CANs, a new second-order prescribed-time sliding mode control protocol is constructed to achieve accurate PTCC for single-integrator CANs in the presence of external disturbances. Using Lyapunov based analysis, sufficient conditions to guarantee the prescribed-time stability, bipartite consensus, interval bipartite consensus, and bipartite containment of single-integrator CANs without or with disturbances are, respectively, derived. In the end, numerical simulations are given to confirm the derived results. ",
    "url": "https://arxiv.org/abs/2210.11212",
    "authors": [
      "Zhen-Hua Zhu",
      "Huaiyu Wu",
      "Zhi-Hong Guan",
      "Zhi-Wei Liu",
      "Yang Chen",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.11226",
    "title": "Comparing Machine Learning Techniques for Alfalfa Biomass Yield  Prediction",
    "abstract": "The alfalfa crop is globally important as livestock feed, so highly efficient planting and harvesting could benefit many industries, especially as the global climate changes and traditional methods become less accurate. Recent work using machine learning (ML) to predict yields for alfalfa and other crops has shown promise. Previous efforts used remote sensing, weather, planting, and soil data to train machine learning models for yield prediction. However, while remote sensing works well, the models require large amounts of data and cannot make predictions until the harvesting season begins. Using weather and planting data from alfalfa variety trials in Kentucky and Georgia, our previous work compared feature selection techniques to find the best technique and best feature set. In this work, we trained a variety of machine learning models, using cross validation for hyperparameter optimization, to predict biomass yields, and we showed better accuracy than similar work that employed more complex techniques. Our best individual model was a random forest with a mean absolute error of 0.081 tons/acre and R{$^2$} of 0.941. Next, we expanded this dataset to include Wisconsin and Mississippi, and we repeated our experiments, obtaining a higher best R{$^2$} of 0.982 with a regression tree. We then isolated our testing datasets by state to explore this problem's eligibility for domain adaptation (DA), as we trained on multiple source states and tested on one target state. This Trivial DA (TDA) approach leaves plenty of room for improvement through exploring more complex DA techniques in forthcoming work. ",
    "url": "https://arxiv.org/abs/2210.11226",
    "authors": [
      "Jonathan Vance",
      "Khaled Rasheed",
      "Ali Missaoui",
      "Frederick Maier",
      "Christian Adkins",
      "Chris Whitmire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11231",
    "title": "Knowledge Graph Enhanced Relation Extraction Datasets",
    "abstract": "Knowledge-enhanced methods that take advantage of auxiliary knowledge graphs recently emerged in relation extraction, and they surpass traditional text-based relation extraction methods. However, there are no unified public benchmarks that currently involve evidence sentences and knowledge graphs for knowledge-enhanced relation extraction. To combat these issues, we propose KGRED, a knowledge graph enhanced relation extraction dataset with features as follows: (1) the benchmarks are based on widely-used distantly supervised relation extraction datasets; (2) we refine these existing datasets to improve the data quality, and we also construct auxiliary knowledge graphs for these existing datasets through entity linking to support knowledge-enhanced relation extraction tasks; (3) with the new benchmarks we curated, we build baselines in two popular relation extraction settings including sentence-level and bag-level relation extraction, and we also make comparisons among the latest knowledge-enhanced relation extraction methods. KGRED provides high-quality relation extraction datasets with auxiliary knowledge graphs for evaluating the performance of knowledge-enhanced relation extraction methods. Meanwhile, our experiments on KGRED reveal the influence of knowledge graph information on relation extraction tasks. ",
    "url": "https://arxiv.org/abs/2210.11231",
    "authors": [
      "Yucong Lin",
      "Hongming Xiao",
      "Jiani Liu",
      "Zichao Lin",
      "Keming Lu",
      "Feifei Wang",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11233",
    "title": "Context-driven Visual Object Recognition based on Knowledge Graphs",
    "abstract": "Current deep learning methods for object recognition are purely data-driven and require a large number of training samples to achieve good results. Due to their sole dependence on image data, these methods tend to fail when confronted with new environments where even small deviations occur. Human perception, however, has proven to be significantly more robust to such distribution shifts. It is assumed that their ability to deal with unknown scenarios is based on extensive incorporation of contextual knowledge. Context can be based either on object co-occurrences in a scene or on memory of experience. In accordance with the human visual cortex which uses context to form different object representations for a seen image, we propose an approach that enhances deep learning methods by using external contextual knowledge encoded in a knowledge graph. Therefore, we extract different contextual views from a generic knowledge graph, transform the views into vector space and infuse it into a DNN. We conduct a series of experiments to investigate the impact of different contextual views on the learned object representations for the same image dataset. The experimental results provide evidence that the contextual views influence the image representations in the DNN differently and therefore lead to different predictions for the same images. We also show that context helps to strengthen the robustness of object recognition models for out-of-distribution images, usually occurring in transfer learning tasks or real-world scenarios. ",
    "url": "https://arxiv.org/abs/2210.11233",
    "authors": [
      "Sebastian Monka",
      "Lavdim Halilaj",
      "Achim Rettinger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2210.11235",
    "title": "Interpretable Machine Learning for Detection and Classification of  Ransomware Families Based on API Calls",
    "abstract": "Ransomware has appeared as one of the major global threats in recent days The alarming increasing rate of ransomware attacks and new ransomware variants intrigue the researchers to constantly examine the distinguishing traits of ransomware and refine their detection strategies Application Programming Interface API is a way for one program to collaborate with another API calls are the medium by which they communicate Ransomware uses this strategy to interact with the OS and makes a significantly higher number of calls in different sequences to ask for taking action This research work utilizes the frequencies of different API calls to detect and classify ransomware families First a WebCrawler is developed to automate collecting the Windows Portable Executable PE files of 15 different ransomware families By extracting different frequencies of 68 API calls we develop our dataset in the first phase of the two phase feature engineering process After selecting the most significant features in the second phase of the feature engineering process we deploy six Supervised Machine Learning models Naive Bayes Logistic Regression Random Forest Stochastic Gradient Descent K Nearest Neighbor and Support Vector Machine Then the performances of all the classifiers are compared to select the best model The results reveal that Logistic Regression can efficiently classify ransomware into their corresponding families securing 9915 accuracy Finally instead of relying on the Black box characteristic of the Machine Learning models we present the interpretability of our best performing model using SHAP values to ascertain the transparency and trustworthiness of the models prediction ",
    "url": "https://arxiv.org/abs/2210.11235",
    "authors": [
      "Rawshan Ara Mowri",
      "Madhuri Siddula",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11239",
    "title": "The State-of-the-Art in AI-Based Malware Detection Techniques: A Review",
    "abstract": "Artificial Intelligence techniques have evolved rapidly in recent years, revolutionising the approaches used to fight against cybercriminals. But as the cyber security field has progressed, so has malware development, making it an economic imperative to strengthen businesses' defensive capability against malware attacks. This review aims to outline the state-of-the-art AI techniques used in malware detection and prevention, providing an in-depth analysis of the latest studies in this field. The algorithms investigated consist of Shallow Learning, Deep Learning and Bio-Inspired Computing, applied to a variety of platforms, such as PC, cloud, Android and IoT. This survey also touches on the rapid adoption of AI by cybercriminals as a means to create ever more advanced malware and exploit the AI algorithms designed to defend against them. ",
    "url": "https://arxiv.org/abs/2210.11239",
    "authors": [
      "Adam Wolsey"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11242",
    "title": "Attacking Motion Estimation with Adversarial Snow",
    "abstract": "Current adversarial attacks for motion estimation (optical flow) optimize small per-pixel perturbations, which are unlikely to appear in the real world. In contrast, we exploit a real-world weather phenomenon for a novel attack with adversarially optimized snow. At the core of our attack is a differentiable renderer that consistently integrates photorealistic snowflakes with realistic motion into the 3D scene. Through optimization we obtain adversarial snow that significantly impacts the optical flow while being indistinguishable from ordinary snow. Surprisingly, the impact of our novel attack is largest on methods that previously showed a high robustness to small L_p perturbations. ",
    "url": "https://arxiv.org/abs/2210.11242",
    "authors": [
      "Jenny Schmalfuss",
      "Lukas Mehl",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11269",
    "title": "Accurate Extrinsic Prediction of Physical Systems Using Transformers",
    "abstract": "Accurate high-altitude wind forecasting is important for air traffic control. And the large volume of data available for this task makes deep neural network-based models a possibility. However, special methods are required because the data is measured only sparsely: along the main aircraft trajectories and arranged sparsely in space, namely along the main air corridors. Several deep learning approaches have been proposed, and in this work, we show that Transformers can fit this data efficiently and are able to extrapolate coherently from a context set. We show this by an extensive comparison of Transformers to numerous existing deep learning-based baselines in the literature. Besides high-altitude wind forecasting, we compare competing models on other dynamical physical systems, namely those modelled by partial differential equations, in particular the Poisson equation and Darcy Flow equation. For these experiments, in the case where the data is arranged non-regularly in space, Transformers outperform all the other evaluated methods. We also compared them in a more standard setup where the data is arranged on a grid and show that the Transformers are competitive with state-of-the-art methods, even though it does not require regular spacing. The code and datasets of the different experiments will be made publicly available at publication time. ",
    "url": "https://arxiv.org/abs/2210.11269",
    "authors": [
      "Arnaud Pannatier",
      "Kyle Matoba",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2210.11275",
    "title": "Hypothesis Testing using Causal and Causal Variational Generative Models",
    "abstract": "Hypothesis testing and the usage of expert knowledge, or causal priors, has not been well explored in the context of generative models. We propose a novel set of generative architectures, Causal Gen and Causal Variational Gen, that can utilize nonparametric structural causal knowledge combined with a deep learning functional approximation. We show how, using a deliberate (non-random) split of training and testing data, these models can generalize better to similar, but out-of-distribution data points, than non-causal generative models and prediction models such as Variational autoencoders and Fully Connected Neural Networks. We explore using this generalization error as a proxy for causal model hypothesis testing. We further show how dropout can be used to learn functional relationships of structural models that are difficult to learn with traditional methods. We validate our methods on a synthetic pendulum dataset, as well as a trauma surgery ground level fall dataset. ",
    "url": "https://arxiv.org/abs/2210.11275",
    "authors": [
      "Jeffrey Jiang",
      "Omead Pooladzandi",
      "Sunay Bhat",
      "Gregory Pottie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.11277",
    "title": "TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting  Decomposition",
    "abstract": "Creation of 3D content by stylization is a promising yet challenging problem in computer vision and graphics research. In this work, we focus on stylizing photorealistic appearance renderings of a given surface mesh of arbitrary topology. Motivated by the recent surge of cross-modal supervision of the Contrastive Language-Image Pre-training (CLIP) model, we propose TANGO, which transfers the appearance style of a given 3D shape according to a text prompt in a photorealistic manner. Technically, we propose to disentangle the appearance style as the spatially varying bidirectional reflectance distribution function, the local geometric variation, and the lighting condition, which are jointly optimized, via supervision of the CLIP loss, by a spherical Gaussians based differentiable renderer. As such, TANGO enables photorealistic 3D style transfer by automatically predicting reflectance effects even for bare, low-quality meshes, without training on a task-specific dataset. Extensive experiments show that TANGO outperforms existing methods of text-driven 3D style transfer in terms of photorealistic quality, consistency of 3D geometry, and robustness when stylizing low-quality meshes. Our codes and results are available at our project webpage https://cyw-3d.github.io/tango/. ",
    "url": "https://arxiv.org/abs/2210.11277",
    "authors": [
      "Yongwei Chen",
      "Rui Chen",
      "Jiabao Lei",
      "Yabin Zhang",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11279",
    "title": "DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for  Multiple Intent Detection",
    "abstract": "While interacting with chatbots, users may elicit multiple intents in a single dialogue utterance. Instead of training a dedicated multi-intent detection model, we propose DialogUSR, a dialogue utterance splitting and reformulation task that first splits multi-intent user query into several single-intent sub-queries and then recovers all the coreferred and omitted information in the sub-queries. DialogUSR can serve as a plug-in and domain-agnostic module that empowers the multi-intent detection for the deployed chatbots with minimal efforts. We collect a high-quality naturally occurring dataset that covers 23 domains with a multi-step crowd-souring procedure. To benchmark the proposed dataset, we propose multiple action-based generative models that involve end-to-end and two-stage training, and conduct in-depth analyses on the pros and cons of the proposed baselines. ",
    "url": "https://arxiv.org/abs/2210.11279",
    "authors": [
      "Haoran Meng",
      "Zheng Xin",
      "Tianyu Liu",
      "Zizhen Wang",
      "He Feng",
      "Binghuai Lin",
      "Xuemin Zhao",
      "Yunbo Cao",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11287",
    "title": "MoCoDA: Model-based Counterfactual Data Augmentation",
    "abstract": "The number of states in a dynamic process is exponential in the number of objects, making reinforcement learning (RL) difficult in complex, multi-object domains. For agents to scale to the real world, they will need to react to and reason about unseen combinations of objects. We argue that the ability to recognize and use local factorization in transition dynamics is a key element in unlocking the power of multi-object reasoning. To this end, we show that (1) known local structure in the environment transitions is sufficient for an exponential reduction in the sample complexity of training a dynamics model, and (2) a locally factored dynamics model provably generalizes out-of-distribution to unseen states and actions. Knowing the local structure also allows us to predict which unseen states and actions this dynamics model will generalize to. We propose to leverage these observations in a novel Model-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies a learned locally factored dynamics model to an augmented distribution of states and actions to generate counterfactual transitions for RL. MoCoDA works with a broader set of local structures than prior work and allows for direct control over the augmented training distribution. We show that MoCoDA enables RL agents to learn policies that generalize to unseen states and actions. We use MoCoDA to train an offline RL agent to solve an out-of-distribution robotics manipulation task on which standard offline RL algorithms fail. ",
    "url": "https://arxiv.org/abs/2210.11287",
    "authors": [
      "Silviu Pitis",
      "Elliot Creager",
      "Ajay Mandlekar",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.11291",
    "title": "Cyclical Self-Supervision for Semi-Supervised Ejection Fraction  Prediction from Echocardiogram Videos",
    "abstract": "Left-ventricular ejection fraction (LVEF) is an important indicator of heart failure. Existing methods for LVEF estimation from video require large amounts of annotated data to achieve high performance, e.g. using 10,030 labeled echocardiogram videos to achieve mean absolute error (MAE) of 4.10. Labeling these videos is time-consuming however and limits potential downstream applications to other heart diseases. This paper presents the first semi-supervised approach for LVEF prediction. Unlike general video prediction tasks, LVEF prediction is specifically related to changes in the left ventricle (LV) in echocardiogram videos. By incorporating knowledge learned from predicting LV segmentations into LVEF regression, we can provide additional context to the model for better predictions. To this end, we propose a novel Cyclical Self-Supervision (CSS) method for learning video-based LV segmentation, which is motivated by the observation that the heartbeat is a cyclical process with temporal repetition. Prediction masks from our segmentation model can then be used as additional input for LVEF regression to provide spatial context for the LV region. We also introduce teacher-student distillation to distill the information from LV segmentation masks into an end-to-end LVEF regression model that only requires video inputs. Results show our method outperforms alternative semi-supervised methods and can achieve MAE of 4.17, which is competitive with state-of-the-art supervised performance, using half the number of labels. Validation on an external dataset also shows improved generalization ability from using our method. ",
    "url": "https://arxiv.org/abs/2210.11291",
    "authors": [
      "Weihang Dai",
      "Xiaomeng Li",
      "Xinpeng Ding",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11322",
    "title": "The Effectiveness of Social Media Engagement Strategy on Disaster  Fundraising",
    "abstract": "Social media has been a powerful tool and an integral part of communication, especially during natural disasters. Social media platforms help nonprofits in effective disaster management by disseminating crucial information to various communities at the earliest. Besides spreading information to every corner of the world, various platforms incorporate many features that give access to host online fundraising events, process online donations, etc. The current literature lacks the theoretical structure investigating the correlation between social media engagement and crisis management. Large nonprofit organisations like the Australian Red Cross have upscaled their operations to help nearly 6,000 bushfire survivors through various grants and helped 21,563 people with psychological support and other assistance through their recovery program (Australian Red Cross, 2021). This paper considers the case of bushfires in Australia 2019-2020 to inspect the role of social media in escalating fundraising via analysing the donation data of the Australian Red Cross from October 2019 - March 2020 and analysing the level of public interaction with their Facebook page and its content in the same period. ",
    "url": "https://arxiv.org/abs/2210.11322",
    "authors": [
      "Vivek Velivela",
      "Chahat Raj",
      "Muhammad Salman Tiwana",
      "Raj Prasanna",
      "Mahendra Samarawickrama",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11341",
    "title": "SS-VAERR: Self-Supervised Apparent Emotional Reaction Recognition from  Video",
    "abstract": "This work focuses on the apparent emotional reaction recognition (AERR) from the video-only input, conducted in a self-supervised fashion. The network is first pre-trained on different self-supervised pretext tasks and later fine-tuned on the downstream target task. Self-supervised learning facilitates the use of pre-trained architectures and larger datasets that might be deemed unfit for the target task and yet might be useful to learn informative representations and hence provide useful initializations for further fine-tuning on smaller more suitable data. Our presented contribution is two-fold: (1) an analysis of different state-of-the-art (SOTA) pretext tasks for the video-only apparent emotional reaction recognition architecture, and (2) an analysis of various combinations of the regression and classification losses that are likely to improve the performance further. Together these two contributions result in the current state-of-the-art performance for the video-only spontaneous apparent emotional reaction recognition with continuous annotations. ",
    "url": "https://arxiv.org/abs/2210.11341",
    "authors": [
      "Marija Jegorova",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11359",
    "title": "Data-Efficient Strategies for Expanding Hate Speech Detection into  Under-Resourced Languages",
    "abstract": "Hate speech is a global phenomenon, but most hate speech datasets so far focus on English-language content. This hinders the development of more effective hate speech detection models in hundreds of languages spoken by billions across the world. More data is needed, but annotating hateful content is expensive, time-consuming and potentially harmful to annotators. To mitigate these issues, we explore data-efficient strategies for expanding hate speech detection into under-resourced languages. In a series of experiments with mono- and multilingual models across five non-English languages, we find that 1) a small amount of target-language fine-tuning data is needed to achieve strong performance, 2) the benefits of using more such data decrease exponentially, and 3) initial fine-tuning on readily-available English data can partially substitute target-language data and improve model generalisability. Based on these findings, we formulate actionable recommendations for hate speech detection in low-resource language settings. ",
    "url": "https://arxiv.org/abs/2210.11359",
    "authors": [
      "Paul R\u00f6ttger",
      "Debora Nozza",
      "Federico Bianchi",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.11404",
    "title": "Self-Supervised Learning with Masked Image Modeling for Teeth Numbering,  Detection of Dental Restorations, and Instance Segmentation in Dental  Panoramic Radiographs",
    "abstract": "The computer-assisted radiologic informative report is currently emerging in dental practice to facilitate dental care and reduce time consumption in manual panoramic radiographic interpretation. However, the amount of dental radiographs for training is very limited, particularly from the point of view of deep learning. This study aims to utilize recent self-supervised learning methods like SimMIM and UM-MAE to increase the model efficiency and understanding of the limited number of dental radiographs. We use the Swin Transformer for teeth numbering, detection of dental restorations, and instance segmentation tasks. To the best of our knowledge, this is the first study that applied self-supervised learning methods to Swin Transformer on dental panoramic radiographs. Our results show that the SimMIM method obtained the highest performance of 90.4% and 88.9% on detecting teeth and dental restorations and instance segmentation, respectively, increasing the average precision by 13.4 and 12.8 over the random initialization baseline. Moreover, we augment and correct the existing dataset of panoramic radiographs. The code and the dataset are available at https://github.com/AmaniHAlmalki/DentalMIM. ",
    "url": "https://arxiv.org/abs/2210.11404",
    "authors": [
      "Amani Almalki",
      "Longin Jan Latecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11407",
    "title": "Similarity of Neural Architectures Based on Input Gradient  Transferability",
    "abstract": "In this paper, we aim to design a quantitative similarity function between two neural architectures. Specifically, we define a model similarity using input gradient transferability. We generate adversarial samples of two networks and measure the average accuracy of the networks on adversarial samples of each other. If two networks are highly correlated, then the attack transferability will be high, resulting in high similarity. Using the similarity score, we investigate two topics: (1) Which network component contributes to the model diversity? (2) How does model diversity affect practical scenarios? We answer the first question by providing feature importance analysis and clustering analysis. The second question is validated by two different scenarios: model ensemble and knowledge distillation. Our findings show that model diversity takes a key role when interacting with different neural architectures. For example, we found that more diversity leads to better ensemble performance. We also observe that the relationship between teacher and student networks and distillation performance depends on the choice of the base architecture of the teacher and student networks. We expect our analysis tool helps a high-level understanding of differences between various neural architectures as well as practical guidance when using multiple architectures. ",
    "url": "https://arxiv.org/abs/2210.11407",
    "authors": [
      "Jaehui Hwang",
      "Dongyoon Han",
      "Byeongho Heo",
      "Song Park",
      "Sanghyuk Chun",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11419",
    "title": "GPR-Net: Multi-view Layout Estimation via a Geometry-aware Panorama  Registration Network",
    "abstract": "Reconstructing 3D layouts from multiple $360^{\\circ}$ panoramas has received increasing attention recently as estimating a complete layout of a large-scale and complex room from a single panorama is very difficult. The state-of-the-art method, called PSMNet, introduces the first learning-based framework that jointly estimates the room layout and registration given a pair of panoramas. However, PSMNet relies on an approximate (i.e., \"noisy\") registration as input. Obtaining this input requires a solution for wide baseline registration which is a challenging problem. In this work, we present a complete multi-view panoramic layout estimation framework that jointly learns panorama registration and layout estimation given a pair of panoramas without relying on a pose prior. The major improvement over PSMNet comes from a novel Geometry-aware Panorama Registration Network or GPR-Net that effectively tackles the wide baseline registration problem by exploiting the layout geometry and computing fine-grained correspondences on the layout boundaries, instead of the global pixel-space. Our architecture consists of two parts. First, given two panoramas, we adopt a vision transformer to learn a set of 1D horizon features sampled on the panorama. These 1D horizon features encode the depths of individual layout boundary samples and the correspondence and covisibility maps between layout boundaries. We then exploit a non-linear registration module to convert these 1D horizon features into a set of corresponding 2D boundary points on the layout. Finally, we estimate the final relative camera pose via RANSAC and obtain the complete layout simply by taking the union of registered layouts. Experimental results indicate that our method achieves state-of-the-art performance in both panorama registration and layout estimation on a large-scale indoor panorama dataset ZInD. ",
    "url": "https://arxiv.org/abs/2210.11419",
    "authors": [
      "Jheng-Wei Su",
      "Chi-Han Peng",
      "Peter Wonka",
      "Hung-Kuo Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11421",
    "title": "Application of artificial neural network to determine the thickness  profile of thin film",
    "abstract": "In this paper, we introduce a novel artificial neural network (ANN) based scheme to estimate the thickness of thin films deposited on a given substrate. Here we consider the visible interference pattern between a plane wave and a diverging wave reflected from the thin film surface that records the thickness information of the thin film. We assume a uniform thickness profile of the film. However, the thickness increases as the deposition takes place. We extract the intensity data along a line through the center of the interference pattern. We train our network by using a number of such line information of known thickness profiles. The performance of the trained network is then tested by estimating the thickness of unknown surfaces. The numerical simulation results show that the proposed technique can be very much useful for automated measurement of thickness, quickly and in real time, during deposition ",
    "url": "https://arxiv.org/abs/2210.11421",
    "authors": [
      "Archana Bora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2210.11452",
    "title": "Global Convergence of SGD On Two Layer Neural Nets",
    "abstract": "In this note we demonstrate provable convergence of SGD to the global minima of appropriately regularized $\\ell_2-$empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates, if they are using adequately smooth and bounded activations like sigmoid and tanh. We build on the results in [1] and leverage a constant amount of Frobenius norm regularization on the weights, along with sampling of the initial weights from an appropriate distribution. We also give a continuous time SGD convergence result that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence loss functions on constant sized neural nets which are \"Villani Functions\". [1] Bin Shi, Weijie J. Su, and Michael I. Jordan. On learning rates and schr\\\"odinger operators, 2020. arXiv:2004.06977 ",
    "url": "https://arxiv.org/abs/2210.11452",
    "authors": [
      "Pulkit Gopalani",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.11456",
    "title": "MixMask: Revisiting Masked Siamese Self-supervised Learning in  Asymmetric Distance",
    "abstract": "Recent advances in self-supervised learning integrate Masked Modeling and Siamese Networks into a single framework to fully reap the advantages of both the two techniques. However, previous erasing-based masking scheme in masked image modeling is not originally designed for siamese networks. Existing approaches simply inherit the default loss design from previous siamese networks, and ignore the information loss and distance change after employing masking operation in the frameworks. In this paper, we propose a filling-based masking strategy called MixMask to prevent information loss due to the randomly erased areas of an image in vanilla masking method. We further introduce a dynamic loss function design with soft distance to adapt the integrated architecture and avoid mismatches between transformed input and objective in Masked Siamese ConvNets (MSCN). The dynamic loss distance is calculated according to the proposed mix-masking scheme. Extensive experiments are conducted on various datasets of CIFAR-100, Tiny-ImageNet and ImageNet-1K. The results demonstrate that the proposed framework can achieve better accuracy on linear probing, semi-supervised and {supervised finetuning}, which outperforms the state-of-the-art MSCN by a significant margin. We also show the superiority on downstream tasks of object detection and segmentation. Our source code is available at https://github.com/LightnessOfBeing/MixMask. ",
    "url": "https://arxiv.org/abs/2210.11456",
    "authors": [
      "Kirill Vishniakov",
      "Eric Xing",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11464",
    "title": "Self-Supervised Learning via Maximum Entropy Coding",
    "abstract": "A mainstream type of current self-supervised learning methods pursues a general-purpose representation that can be well transferred to downstream tasks, typically by optimizing on a given pretext task such as instance discrimination. In this work, we argue that existing pretext tasks inevitably introduce biases into the learned representation, which in turn leads to biased transfer performance on various downstream tasks. To cope with this issue, we propose Maximum Entropy Coding (MEC), a more principled objective that explicitly optimizes on the structure of the representation, so that the learned representation is less biased and thus generalizes better to unseen downstream tasks. Inspired by the principle of maximum entropy in information theory, we hypothesize that a generalizable representation should be the one that admits the maximum entropy among all plausible representations. To make the objective end-to-end trainable, we propose to leverage the minimal coding length in lossy data coding as a computationally tractable surrogate for the entropy, and further derive a scalable reformulation of the objective that allows fast computation. Extensive experiments demonstrate that MEC learns a more generalizable representation than previous methods based on specific pretext tasks. It achieves state-of-the-art performance consistently on various downstream tasks, including not only ImageNet linear probe, but also semi-supervised classification, object detection, instance segmentation, and object tracking. Interestingly, we show that existing batch-wise and feature-wise self-supervised objectives could be seen equivalent to low-order approximations of MEC. Code and pre-trained models are available at https://github.com/xinliu20/MEC. ",
    "url": "https://arxiv.org/abs/2210.11464",
    "authors": [
      "Xin Liu",
      "Zhongdao Wang",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11469",
    "title": "G2NetPL: Generic Game-Theoretic Network for Partial-Label Image  Classification",
    "abstract": "Multi-label image classification aims to predict all possible labels in an image. It is usually formulated as a partial-label learning problem, since it could be expensive in practice to annotate all the labels in every training image. Existing works on partial-label learning focus on the case where each training image is labeled with only a subset of its positive/negative labels. To effectively address partial-label classification, this paper proposes an end-to-end Generic Game-theoretic Network (G2NetPL) for partial-label learning, which can be applied to most partial-label settings, including a very challenging, but annotation-efficient case where only a subset of the training images are labeled, each with only one positive label, while the rest of the training images remain unlabeled. In G2NetPL, each unobserved label is associated with a soft pseudo label, which, together with the network, formulates a two-player non-zero-sum non-cooperative game. The objective of the network is to minimize the loss function with given pseudo labels, while the pseudo labels will seek convergence to 1 (positive) or 0 (negative) with a penalty of deviating from the predicted labels determined by the network. In addition, we introduce a confidence-aware scheduler into the loss of the network to adaptively perform easy-to-hard learning for different labels. Extensive experiments demonstrate that our proposed G2NetPL outperforms many state-of-the-art multi-label classification methods under various partial-label settings on three different datasets. ",
    "url": "https://arxiv.org/abs/2210.11469",
    "authors": [
      "Rabab Abdelfattah",
      "Xin Zhang",
      "Mostafa M. Fouda",
      "Xiaofeng Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10784",
    "title": "Graph Regularized Probabilistic Matrix Factorization for Drug-Drug  Interactions Prediction",
    "abstract": "Co-administration of two or more drugs simultaneously can result in adverse drug reactions. Identifying drug-drug interactions (DDIs) is necessary, especially for drug development and for repurposing old drugs. DDI prediction can be viewed as a matrix completion task, for which matrix factorization (MF) appears as a suitable solution. This paper presents a novel Graph Regularized Probabilistic Matrix Factorization (GRPMF) method, which incorporates expert knowledge through a novel graph-based regularization strategy within an MF framework. An efficient and sounded optimization algorithm is proposed to solve the resulting non-convex problem in an alternating fashion. The performance of the proposed method is evaluated through the DrugBank dataset, and comparisons are provided against state-of-the-art techniques. The results demonstrate the superior performance of GRPMF when compared to its counterparts. ",
    "url": "https://arxiv.org/abs/2210.10784",
    "authors": [
      "Stuti Jain",
      "Emilie Chouzenoux",
      "Kriti Kumar",
      "Angshul Majumdar"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10887",
    "title": "Data-Driven Distributionally Robust Electric Vehicle Balancing for  Mobility-on-Demand Systems under Demand and Supply Uncertainties",
    "abstract": "As electric vehicle (EV) technologies become mature, EV has been rapidly adopted in modern transportation systems, and is expected to provide future autonomous mobility-on-demand (AMoD) service with economic and societal benefits. However, EVs require frequent recharges due to their limited and unpredictable cruising ranges, and they have to be managed efficiently given the dynamic charging process. It is urgent and challenging to investigate a computationally efficient algorithm that provide EV AMoD system performance guarantees under model uncertainties, instead of using heuristic demand or charging models. To accomplish this goal, this work designs a data-driven distributionally robust optimization approach for vehicle supply-demand ratio and charging station utilization balancing, while minimizing the worst-case expected cost considering both passenger mobility demand uncertainties and EV supply uncertainties. We then derive an equivalent computationally tractable form for solving the distributionally robust problem in a computationally efficient way under ellipsoid uncertainty sets constructed from data. Based on E-taxi system data of Shenzhen city, we show that the average total balancing cost is reduced by 14.49%, the average unfairness of supply-demand ratio and utilization is reduced by 15.78% and 34.51% respectively with the distributionally robust vehicle balancing method, compared with solutions which do not consider model uncertainties. ",
    "url": "https://arxiv.org/abs/2210.10887",
    "authors": [
      "Sihong He",
      "Lynn Pepin",
      "Guang Wang",
      "Desheng Zhang",
      "Fei Miao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.10950",
    "title": "ESPNN: Deep Neural Network on the IAEA stopping power database. Atomic  targets",
    "abstract": "The International Atomic Energy Agency (IAEA) stopping power database is a highly valued public resource compiling most of the experimental measurements published over nearly a century. The database -- accessible to the global scientific community -- is continuously updated and has been extensively employed in theoretical and experimental research for more than thirty years. This work aims to employ machine learning algorithms on the 2021 IAEA database to predict accurate electronic stopping power cross sections for any ion and target combination in a wide range of incident energies. Unsupervised machine learning methods are applied to clean the database in an automated manner. These techniques purge the data by removing suspicious outliers and old isolated values. A large portion of the remaining data is used to train a deep neural network, while the rest is set aside, constituting the test set. The present work considers collisional systems only with atomic targets. The first version of the electronic stopping power neural network code (espnn), openly available to users, is shown to yield predicted values in excellent agreement with the experimental results of the test set. ",
    "url": "https://arxiv.org/abs/2210.10950",
    "authors": [
      "F. Bivort Haiek",
      "A.M.P. Mendez",
      "C.C. Montanari",
      "D.M. Mitnik"
    ],
    "subjectives": [
      "Atomic and Molecular Clusters (physics.atm-clus)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10962",
    "title": "Optimization on Manifolds via Graph Gaussian Processes",
    "abstract": "This paper integrates manifold learning techniques within a \\emph{Gaussian process upper confidence bound} algorithm to optimize an objective function on a manifold. Our approach is motivated by applications where a full representation of the manifold is not available and querying the objective is expensive. We rely on a point cloud of manifold samples to define a graph Gaussian process surrogate model for the objective. Query points are sequentially chosen using the posterior distribution of the surrogate model given all previous queries. We establish regret bounds in terms of the number of queries and the size of the point cloud. Several numerical examples complement the theory and illustrate the performance of our method. ",
    "url": "https://arxiv.org/abs/2210.10962",
    "authors": [
      "Hwanwoo Kim",
      "Daniel Sanz-Alonso",
      "Ruiyi Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.10998",
    "title": "Semi-supervised object detection based on single-stage detector for  thighbone fracture localization",
    "abstract": "The thighbone is the largest bone supporting the lower body. If the thighbone fracture is not treated in time, it will lead to lifelong inability to walk. Correct diagnosis of thighbone disease is very important in orthopedic medicine. Deep learning is promoting the development of fracture detection technology. However, the existing computer aided diagnosis (CAD) methods baesd on deep learning rely on a large number of manually labeled data, and labeling these data costs a lot of time and energy. Therefore, we develop a object detection method with limited labeled image quantity and apply it to the thighbone fracture localization. In this work, we build a semi-supervised object detection(SSOD) framework based on single-stage detector, which including three modules: adaptive difficult sample oriented (ADSO) module, Fusion Box and deformable expand encoder (Dex encoder). ADSO module takes the classification score as the label reliability evaluation criterion by weighting, Fusion Box is designed to merge similar pseudo boxes into a reliable box for box regression and Dex encoder is proposed to enhance the adaptability of image augmentation. The experiment is conducted on the thighbone fracture dataset, which includes 3484 training thigh fracture images and 358 testing thigh fracture images. The experimental results show that the proposed method achieves the state-of-the-art AP in thighbone fracture detection at different labeled data rates, i.e. 1%, 5% and 10%. Besides, we use full data to achieve knowledge distillation, our method achieves 86.2% AP50 and 52.6% AP75. ",
    "url": "https://arxiv.org/abs/2210.10998",
    "authors": [
      "Jinman Wei",
      "Jinkun Yao",
      "Guoshan Zhanga",
      "Bin Guan",
      "Yueming Zhang",
      "Shaoquan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11019",
    "title": "Single Image Super-Resolution Using Lightweight Networks Based on Swin  Transformer",
    "abstract": "Image super-resolution reconstruction is an important task in the field of image processing technology, which can restore low resolution image to high quality image with high resolution. In recent years, deep learning has been applied in the field of image super-resolution reconstruction. With the continuous development of deep neural network, the quality of the reconstructed images has been greatly improved, but the model complexity has also been increased. In this paper, we propose two lightweight models named as MSwinSR and UGSwinSR based on Swin Transformer. The most important structure in MSwinSR is called Multi-size Swin Transformer Block (MSTB), which mainly contains four parallel multi-head self-attention (MSA) blocks. UGSwinSR combines U-Net and GAN with Swin Transformer. Both of them can reduce the model complexity, but MSwinSR can reach a higher objective quality, while UGSwinSR can reach a higher perceptual quality. The experimental results demonstrate that MSwinSR increases PSNR by $\\mathbf{0.07dB}$ compared with the state-of-the-art model SwinIR, while the number of parameters can reduced by $\\mathbf{30.68\\%}$, and the calculation cost can reduced by $\\mathbf{9.936\\%}$. UGSwinSR can effectively reduce the amount of calculation of the network, which can reduced by $\\mathbf{90.92\\%}$ compared with SwinIR. ",
    "url": "https://arxiv.org/abs/2210.11019",
    "authors": [
      "Bolong Zhang",
      "Juan Chen",
      "Quan Wen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11045",
    "title": "Robust Image Registration with Absent Correspondences in Pre-operative  and Follow-up Brain MRI Scans of Diffuse Glioma Patients",
    "abstract": "Registration of pre-operative and follow-up brain MRI scans is challenging due to the large variation of tissue appearance and missing correspondences in tumour recurrence regions caused by tumour mass effect. Although recent deep learning-based deformable registration methods have achieved remarkable success in various medical applications, most of them are not capable of registering images with pathologies. In this paper, we propose a 3-step registration pipeline for pre-operative and follow-up brain MRI scans that consists of 1) a multi-level affine registration, 2) a conditional deep Laplacian pyramid image registration network (cLapIRN) with forward-backward consistency constraint, and 3) a non-linear instance optimization method. We apply the method to the Brain Tumor Sequence Registration (BraTS-Reg) Challenge. Our method achieves accurate and robust registration of brain MRI scans with pathologies, which achieves a median absolute error of 1.64 mm and 88% of successful registration rate in the validation set of BraTS-Reg challenge. ",
    "url": "https://arxiv.org/abs/2210.11045",
    "authors": [
      "Tony C. W. Mok",
      "Albert C. S. Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11053",
    "title": "The Network Structure of Unequal Diffusion",
    "abstract": "Social networks affect the diffusion of information, and thus have the potential to reduce or amplify inequality in access to opportunity. We show empirically that social networks often exhibit a much larger potential for unequal diffusion across groups along paths of length 2 and 3 than expected by our random graph models. We argue that homophily alone cannot not fully explain the extent of unequal diffusion and attribute this mismatch to unequal distribution of cross-group links among the nodes. Based on this insight, we develop a variant of the stochastic block model that incorporates the heterogeneity in cross-group linking. The model provides an unbiased and consistent estimate of assortativity or homophily on paths of length 2 and provide a more accurate estimate along paths of length 3 than existing models. We characterize the null distribution of its log-likelihood ratio test and argue that the goodness of fit test is valid only when the network is dense. Based on our empirical observations and modeling results, we conclude that the impact of any departure from equal distribution of links to source nodes in the diffusion process is not limited to its first order effects as some nodes will have fewer direct links to the sources. More importantly, this unequal distribution will also lead to second order effects as the whole group will have fewer diffusion paths to the sources. ",
    "url": "https://arxiv.org/abs/2210.11053",
    "authors": [
      "Eaman Jahani",
      "Dean Eckles",
      "Alex 'Sandy' Pentland"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.11059",
    "title": "DisC-VC: Disentangled and F0-Controllable Neural Voice Conversion",
    "abstract": "Voice conversion is a task to convert a non-linguistic feature of a given utterance. Since naturalness of speech strongly depends on its pitch pattern, in some applications, it would be desirable to keep the original rise/fall pitch pattern while changing the speaker identity. Some of the existing methods address this problem by either using a source-filter model or developing a neural network that takes an F0 pattern as input to the model. Although the latter approach can achieve relatively high sound quality compared to the former one, there is no consideration for discrepancy between the target and generated F0 patterns in its training process. In this paper, we propose a new variational-autoencoder-based voice conversion model accompanied by an auxiliary network, which ensures that the conversion result correctly reflects the specified F0/timbre information. We show the effectiveness of the proposed method by objective and subjective evaluations. ",
    "url": "https://arxiv.org/abs/2210.11059",
    "authors": [
      "Chihiro Watanabe",
      "Hirokazu Kameoka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.11132",
    "title": "A general model-and-run solver for multistage robust discrete linear  optimization",
    "abstract": "The necessity to deal with uncertain data is a major challenge in decision making. Robust optimization emerged as one of the predominant paradigms to produce solutions that hedge against uncertainty. In order to obtain an even more realistic description of the underlying problem where the decision maker can react to newly disclosed information, multistage models can be used. However, due to their computational difficulty, multistage problems beyond two stages have received less attention and are often only addressed using approximation rather than optimization schemes. Even less attention is paid to the consideration of decision-dependent uncertainty in a multistage setting. We explore multistage robust optimization via quantified linear programs, which are linear programs with ordered variables that are either existentially or universally quantified. Building upon a (mostly) discrete setting where the uncertain parameters -- the universally quantified variables -- are only restricted by their bounds, we present an augmented version that allows stating the discrete uncertainty set via a linear constraint system that also can be affected by decision variables. We present a general search-based solution approach and introduce our solver Yasol that is able to deal with multistage robust linear discrete optimization problems, with final mixed-integer recourse actions and a discrete uncertainty set, which even can be decision-dependent. In doing so, we provide a convenient model-and-run approach, that can serve as baseline for computational experiments in the field of multistage robust optimization, providing optimal solutions for problems with an arbitrary number of decision stages. ",
    "url": "https://arxiv.org/abs/2210.11132",
    "authors": [
      "Michael Hartisch",
      "Ulf Lorenz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.11152",
    "title": "Machine Learning for $K$-adaptability in Two-stage Robust Optimization",
    "abstract": "Two-stage robust optimization problems constitute one of the hardest optimization problem classes. One of the solution approaches to this class of problems is $K$-adaptability. This approach simultaneously seeks the best partitioning of the uncertainty set of scenarios into $K$ subsets, and optimizes decisions corresponding to each of these subsets. In general case, it is solved using the $K$-adaptability branch-and-bound algorithm, which requires exploration of exponentially-growing solution trees. To accelerate finding high-quality solutions in such trees, we propose a machine learning-based node selection strategy. In particular, we construct a feature engineering scheme based on general two-stage robust optimization insights that allows us to train our machine learning tool on a database of resolved B\\&B trees, and to apply it as-is to problems of different sizes and/or types. We experimentally show that using our learned node selection strategy outperforms a vanilla, random node selection strategy when tested on problems of the same type as the training problems, also in case the $K$-value or the problem size differs from the training ones. ",
    "url": "https://arxiv.org/abs/2210.11152",
    "authors": [
      "Esther Julien",
      "Krzysztof Postek",
      "\u015e. \u0130lker Birbil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11184",
    "title": "On completely regular codes with minimum eigenvalue in geometric graphs",
    "abstract": "We prove that any completely regular code with minimum eigenvalue in any geometric graph G corresponds to a completely regular code in the clique graph of G. Studying the interrelation of these codes, a complete characterization of the completely regular codes in the Johnson graphs J(n,w) with covering radius w-1 and strength 1 is obtained. In particular this result finishes a characterization of the completely regular codes in the Johnson graphs J(n,3). We also classify the completely regular codes of strength 1 in the Johnson graphs J(n,4) with only one case for the eigenvalues left open. ",
    "url": "https://arxiv.org/abs/2210.11184",
    "authors": [
      "I.Yu.Mogilnykh",
      "K. V. Vorob'ev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.11238",
    "title": "Analysis of Smooth Pursuit Assessment in Virtual Reality and Concussion  Detection using BiLSTM",
    "abstract": "The sport-related concussion (SRC) battery relies heavily upon subjective symptom reporting in order to determine the diagnosis of a concussion. Unfortunately, athletes with SRC may return-to-play (RTP) too soon if they are untruthful of their symptoms. It is critical to provide accurate assessments that can overcome underreporting to prevent further injury. To lower the risk of injury, a more robust and precise method for detecting concussion is needed to produce reliable and objective results. In this paper, we propose a novel approach to detect SRC using long short-term memory (LSTM) recurrent neural network (RNN) architectures from oculomotor data. In particular, we propose a new error metric that incorporates mean squared error in different proportions. The experimental results on the smooth pursuit test of the VR-VOMS dataset suggest that the proposed approach can predict concussion symptoms with higher accuracy compared to symptom provocation on the vestibular ocular motor screening (VOMS). ",
    "url": "https://arxiv.org/abs/2210.11238",
    "authors": [
      "Prithul Sarker",
      "Khondker Fariha Hossain",
      "Isayas Berhe Adhanom",
      "Philip K Pavilionis",
      "Nicholas G. Murray",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.11245",
    "title": "Neural ODEs as Feedback Policies for Nonlinear Optimal Control",
    "abstract": "Neural ordinary differential equations (Neural ODEs) model continuous time dynamics as differential equations parametrized with neural networks. Thanks to their modeling flexibility, they have been adopted for multiple tasks where the continuous time nature of the process is specially relevant, as in system identification and time series analysis. When applied in a control setting, it is possible to adapt their use to approximate optimal nonlinear feedback policies. This formulation follows the same approach as policy gradients in reinforcement learning, covering the case where the environment consists of known deterministic dynamics given by a system of differential equations. The white box nature of the model specification allows the direct calculation of policy gradients through sensitivity analysis, avoiding the inexact and inefficient gradient estimation through sampling. In this work we propose the use of a neural control policy posed as a Neural ODE to solve general nonlinear optimal control problems while satisfying both state and control constraints, which are crucial for real world scenarios. Since the state feedback policy partially modifies the model dynamics, the whole space phase of the system is reshaped upon the optimization. This approach is a sensible approximation to the historically intractable closed loop solution of nonlinear control problems that efficiently exploits the availability of a dynamical system model. ",
    "url": "https://arxiv.org/abs/2210.11245",
    "authors": [
      "Ilya Orson Sandoval",
      "Panagiotis Petsagkourakis",
      "Ehecatl Antonio del Rio-Chanona"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.11355",
    "title": "Network Synthetic Interventions: A Framework for Panel Data with Network  Interference",
    "abstract": "We propose a generalization of the synthetic controls and synthetic interventions methodology to incorporate network interference. We consider the estimation of unit-specific treatment effects from panel data where there are spillover effects across units and in the presence of unobserved confounding. Key to our approach is a novel latent factor model that takes into account network interference and generalizes the factor models typically used in panel data settings. We propose an estimator, \"network synthetic interventions\", and show that it consistently estimates the mean outcomes for a unit under an arbitrary sequence of treatments for itself and its neighborhood, given certain observation patterns hold in the data. We corroborate our theoretical findings with simulations. ",
    "url": "https://arxiv.org/abs/2210.11355",
    "authors": [
      "Anish Agarwal",
      "Sarah Cen",
      "Devavrat Shah",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.11408",
    "title": "Hierarchical Deep Learning with Generative Adversarial Network for  Automatic Cardiac Diagnosis from ECG Signals",
    "abstract": "Cardiac disease is the leading cause of death in the US. Accurate heart disease detection is of critical importance for timely medical treatment to save patients' lives. Routine use of electrocardiogram (ECG) is the most common method for physicians to assess the electrical activities of the heart and detect possible abnormal cardiac conditions. Fully utilizing the ECG data for reliable heart disease detection depends on developing effective analytical models. In this paper, we propose a two-level hierarchical deep learning framework with Generative Adversarial Network (GAN) for automatic diagnosis of ECG signals. The first-level model is composed of a Memory-Augmented Deep auto-Encoder with GAN (MadeGAN), which aims to differentiate abnormal signals from normal ECGs for anomaly detection. The second-level learning aims at robust multi-class classification for different arrhythmias identification, which is achieved by integrating the transfer learning technique to transfer knowledge from the first-level learning with the multi-branching architecture to handle the data-lacking and imbalanced data issue. We evaluate the performance of the proposed framework using real-world medical data from the MIT-BIH arrhythmia database. Experimental results show that our proposed model outperforms existing methods that are commonly used in current practice. ",
    "url": "https://arxiv.org/abs/2210.11408",
    "authors": [
      "Zekai Wang",
      "Stavros Stavrakis",
      "Bing Yao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11420",
    "title": "Granger Causality for Compressively Sensed Sparse Signals",
    "abstract": "Compressed sensing is a scheme that allows for sparse signals to be acquired, transmitted and stored using far fewer measurements than done by conventional means employing Nyquist sampling theorem. Since many naturally occurring signals are sparse (in some domain), compressed sensing has rapidly seen popularity in a number of applied physics and engineering applications, particularly in designing signal and image acquisition strategies, e.g., magnetic resonance imaging, quantum state tomography, scanning tunneling microscopy, analog to digital conversion technologies. Contemporaneously, causal inference has become an important tool for the analysis and understanding of processes and their interactions in many disciplines of science, especially those dealing with complex systems. Direct causal analysis for compressively sensed data is required to avoid the task of reconstructing the compressed data. Also, for some sparse signals, such as for sparse temporal data, it may be difficult to discover causal relations directly using available data-driven/ model-free causality estimation techniques. In this work, we provide a mathematical proof that structured compressed sensing matrices, specifically Circulant and Toeplitz, preserve causal relationships in the compressed signal domain, as measured by Granger Causality. We then verify this theorem on a number of bivariate and multivariate coupled sparse signal simulations which are compressed using these matrices. We also demonstrate a real world application of network causal connectivity estimation from sparse neural spike train recordings from rat prefrontal cortex. ",
    "url": "https://arxiv.org/abs/2210.11420",
    "authors": [
      "Aditi Kathpalia",
      "Nithin Nagaraj"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2210.11423",
    "title": "Multi-Mode High Altitude Platform Stations (HAPS) for Next Generation  Wireless Networks",
    "abstract": "The high altitude platform station (HAPS) concept has recently received notable attention from both industry and academia to support future wireless networks. A HAPS can be equipped with 5th generation (5G) and beyond technologies such as massive multiple-input multiple-output (MIMO) and reconfigurable intelligent surface (RIS). Hence, it is expected that HAPS will support numerous applications in both rural and urban areas. However, this comes at the expense of high energy consumption and thus shorter loitering time. To tackle this issue, we envision the use of a multi-mode HAPS that can adaptively switch between different modes so as to reduce energy consumption and extend the HAPS loitering time. These modes comprise a HAPS super macro base station (HAPS-SMBS) mode for enhanced computing, caching, and communication services, a HAPS relay station (HAPS-RS) mode for active communication, and a HAPS-RIS mode for passive communication. This multimode HAPS ensures that operations rely mostly on the passive communication payload, while switching to an energy-greedy active mode only when necessary. In this article, we begin with a brief review of HAPS features compared to other non-terrestrial systems, followed by an exposition of the different HAPS modes proposed. Subsequently, we illustrate the envisioned multi-mode HAPS, and discuss its benefits and challenges. Finally, we validate the multi-mode efficiency through a case study. ",
    "url": "https://arxiv.org/abs/2210.11423",
    "authors": [
      "Safwan Alfattani",
      "Wael Jaafar",
      "Halim Yanikomeroglu",
      "Abbas Yonga\u00e7oglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2011.10725",
    "title": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "abstract": " Title: Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud ",
    "url": "https://arxiv.org/abs/2011.10725",
    "authors": [
      "Xiucai Ding",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2102.08581",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": " Title: Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning ",
    "url": "https://arxiv.org/abs/2102.08581",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.08453",
    "title": "R&R: Metric-guided Adversarial Sentence Generation",
    "abstract": " Comments: Accepted to Finding of AACL-IJCNLP2022 ",
    "url": "https://arxiv.org/abs/2104.08453",
    "authors": [
      "Lei Xu",
      "Alfredo Cuesta-Infante",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.04080",
    "title": "Exponentially convergent multiscale methods for high frequency  heterogeneous Helmholtz equations",
    "abstract": " Title: Exponentially convergent multiscale methods for high frequency  heterogeneous Helmholtz equations ",
    "url": "https://arxiv.org/abs/2105.04080",
    "authors": [
      "Yifan Chen",
      "Thomas Y. Hou",
      "Yixuan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.03917",
    "title": "Mixture Outlier Exposure: Towards Out-of-Distribution Detection in  Fine-grained Environments",
    "abstract": " Comments: Accepted by WACV'23 ",
    "url": "https://arxiv.org/abs/2106.03917",
    "authors": [
      "Jingyang Zhang",
      "Nathan Inkawhich",
      "Randolph Linderman",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.06090",
    "title": "Graph Neural Networks for Natural Language Processing: A Survey",
    "abstract": " Comments: 127 pages, accepted by Foundations and Trends in Machine Learning ",
    "url": "https://arxiv.org/abs/2106.06090",
    "authors": [
      "Lingfei Wu",
      "Yu Chen",
      "Kai Shen",
      "Xiaojie Guo",
      "Hanning Gao",
      "Shucheng Li",
      "Jian Pei",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": " Comments: Appeared in ICML 2022 (errata added on 19 Oct., 2022) ",
    "url": "https://arxiv.org/abs/2106.10771",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.00637",
    "title": "ML4C: Seeing Causality Through Latent Vicinity",
    "abstract": " Comments: causal discovery, supervised causal learning, vicinity, identifiability, learnability ",
    "url": "https://arxiv.org/abs/2110.00637",
    "authors": [
      "Haoyue Dai",
      "Rui Ding",
      "Yuanyuan Jiang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.03162",
    "title": "Embedding Arithmetic of Multimodal Queries for Image Retrieval",
    "abstract": " Comments: accepted at O-DRUM (CVPR workshop 2022) ",
    "url": "https://arxiv.org/abs/2112.03162",
    "authors": [
      "Guillaume Couairon",
      "Matthieu Cord",
      "Matthijs Douze",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.06786",
    "title": "On using the complex step method for the approximation of Fr\u00e9chet  derivatives of matrix functions in automorphism groups",
    "abstract": " Title: On using the complex step method for the approximation of Fr\u00e9chet  derivatives of matrix functions in automorphism groups ",
    "url": "https://arxiv.org/abs/2112.06786",
    "authors": [
      "Tom Werner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.14337",
    "title": "Closer Look at the Transferability of Adversarial Examples: How They  Fool Different Models Differently",
    "abstract": " Comments: 25 pages, 13 figures, Accepted at the IEEE Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2112.14337",
    "authors": [
      "Futa Waseda",
      "Sosuke Nishikawa",
      "Trung-Nghia Le",
      "Huy H. Nguyen",
      "Isao Echizen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15577",
    "title": "How Infinitely Wide Neural Networks Can Benefit from Multi-task Learning  -- an Exact Macroscopic Characterization",
    "abstract": " Comments: 13 pages + appendix ",
    "url": "https://arxiv.org/abs/2112.15577",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.08455",
    "title": "LOSTIN: Logic Optimization via Spatio-Temporal Information with Hybrid  Graph Models",
    "abstract": " Title: LOSTIN: Logic Optimization via Spatio-Temporal Information with Hybrid  Graph Models ",
    "url": "https://arxiv.org/abs/2201.08455",
    "authors": [
      "Nan Wu",
      "Jiwon Lee",
      "Yuan Xie",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2201.09186",
    "title": "pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing",
    "abstract": " Title: pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing ",
    "url": "https://arxiv.org/abs/2201.09186",
    "authors": [
      "Jiasi Weng",
      "Jian Weng",
      "Gui Tang",
      "Anjia Yang",
      "Ming Li",
      "Jia-Nan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11596",
    "title": "FairEGM: Fair Link Prediction and Recommendation via Emulated Graph  Modification",
    "abstract": " Comments: 14 pages, 3 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2201.11596",
    "authors": [
      "Sean Current",
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05903",
    "title": "Can We Talk? An Exploratory Study of Gender and Network Ties in a Local  Government Setting",
    "abstract": " Title: Can We Talk? An Exploratory Study of Gender and Network Ties in a Local  Government Setting ",
    "url": "https://arxiv.org/abs/2202.05903",
    "authors": [
      "Leisha DeHart-Davis",
      "Nicole Humphrey",
      "Travis A. Whetsell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.06483",
    "title": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "abstract": " Title: BiFSMN: Binary Neural Network for Keyword Spotting ",
    "url": "https://arxiv.org/abs/2202.06483",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Yao Tian",
      "Zejun Ma",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.06729",
    "title": "Random walk informed community detection reveals heterogeneities in the  lymph node conduits network",
    "abstract": " Title: Random walk informed community detection reveals heterogeneities in the  lymph node conduits network ",
    "url": "https://arxiv.org/abs/2202.06729",
    "authors": [
      "Sol\u00e8ne Song",
      "Malek Senoussi",
      "Paul Escande",
      "Paul Villoutreix"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2202.10679",
    "title": "Physics-Informed Graph Learning",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2202.10679",
    "authors": [
      "Ciyuan Peng",
      "Feng Xia",
      "Vidya Saikrishna",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00418",
    "title": "Recovery of Missing Sensor Data by Reconstructing Time-varying Graph  Signals",
    "abstract": " Comments: Five pages, two figures, 2022 30th European Signal Processing Conference (EUSIPCO). Published version available at: this https URL ",
    "url": "https://arxiv.org/abs/2203.00418",
    "authors": [
      "Anindya Mondal",
      "Mayukhmali Das",
      "Aditi Chatterjee",
      "Palaniandavar Venkateswaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.00725",
    "title": "A Conformer Based Acoustic Model for Robust Automatic Speech Recognition",
    "abstract": " Comments: 5 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2203.00725",
    "authors": [
      "Yufeng Yang",
      "Peidong Wang",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01116",
    "title": "Superiorized Adaptive Projected Subgradient Method with Application to  MIMO Detection",
    "abstract": " Comments: Submitted to IEEE Transactions on Signal Processing for possible publication ",
    "url": "https://arxiv.org/abs/2203.01116",
    "authors": [
      "Jochen Fink",
      "Renato L. G. Cavalcante",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.02053",
    "title": "Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive  Representation Learning",
    "abstract": " Comments: Published at NeurIPS 2022. Code and data are available at this https URL ",
    "url": "https://arxiv.org/abs/2203.02053",
    "authors": [
      "Weixin Liang",
      "Yuhui Zhang",
      "Yongchan Kwon",
      "Serena Yeung",
      "James Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.07682",
    "title": "Enriched CNN-Transformer Feature Aggregation Networks for  Super-Resolution",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2203.07682",
    "authors": [
      "Jinsu Yoo",
      "Taehoon Kim",
      "Sihaeng Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10537",
    "title": "Iwin: Human-Object Interaction Detection via Transformer with Irregular  Windows",
    "abstract": " Comments: Accepted to ECCV 2022 ",
    "url": "https://arxiv.org/abs/2203.10537",
    "authors": [
      "Danyang Tu",
      "Xiongkuo Min",
      "Huiyu Duan",
      "Guodong Guo",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.06601",
    "title": "A Study of Causal Confusion in Preference-Based Reward Learning",
    "abstract": " Title: A Study of Causal Confusion in Preference-Based Reward Learning ",
    "url": "https://arxiv.org/abs/2204.06601",
    "authors": [
      "Jeremy Tien",
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "Anca D. Dragan",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.07615",
    "title": "TabNAS: Rejection Sampling for Neural Architecture Search on Tabular  Datasets",
    "abstract": " Comments: NeurIPS 2022; 30 pages, 15 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2204.07615",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.08152",
    "title": "Back to the Future: Bidirectional Information Decoupling Network for  Multi-turn Dialogue Modeling",
    "abstract": " Comments: Accepted by EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.08152",
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.13004",
    "title": "Defending Person Detection Against Adversarial Patch Attack by using  Universal Defensive Frame",
    "abstract": " Comments: Accepted at IEEE Transactions on Image Processing (TIP), 2022 ",
    "url": "https://arxiv.org/abs/2204.13004",
    "authors": [
      "Youngjoon Yu",
      "Hong Joo Lee",
      "Hakmin Lee",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13778",
    "title": "Inferring Implicit Relations in Complex Questions with Language Models",
    "abstract": " Comments: Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.13778",
    "authors": [
      "Uri Katz",
      "Mor Geva",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.14030",
    "title": "Neural Implicit Representations for Physical Parameter Inference from a  Single Video",
    "abstract": " Comments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2204.14030",
    "authors": [
      "Florian Hofherr",
      "Lukas Koestler",
      "Florian Bernard",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": " Title: Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation ",
    "url": "https://arxiv.org/abs/2205.09389",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10479",
    "title": "DEER: Descriptive Knowledge Graph for Explaining Entity Relationships",
    "abstract": " Comments: Accepted to EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2205.10479",
    "authors": [
      "Jie Huang",
      "Kerui Zhu",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representations",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2205.10852",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Jing Chen",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.11432",
    "title": "Logical Reasoning with Span-Level Predictions for Interpretable and  Robust NLI Models",
    "abstract": " Comments: Accepted at EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2205.11432",
    "authors": [
      "Joe Stacey",
      "Pasquale Minervini",
      "Haim Dubossarsky",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11691",
    "title": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
    "abstract": " Title: High-Order Pooling for Graph Neural Networks with Tensor Decomposition ",
    "url": "https://arxiv.org/abs/2205.11691",
    "authors": [
      "Chenqing Hua",
      "Guillaume Rabusseau",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13418",
    "title": "Avoiding Barren Plateaus with Classical Deep Neural Networks",
    "abstract": " Title: Avoiding Barren Plateaus with Classical Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2205.13418",
    "authors": [
      "Lucas Friedrich",
      "Jonas Maziero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13462",
    "title": "FedDebias: Reducing the Local Learning Bias Improves Federated Learning  on Heterogeneous Data",
    "abstract": " Title: FedDebias: Reducing the Local Learning Bias Improves Federated Learning  on Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2205.13462",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13647",
    "title": "Learning to Reason with Neural Networks: Generalization, Unseen Data and  Boolean Measures",
    "abstract": " Comments: To appear in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13647",
    "authors": [
      "Emmanuel Abbe",
      "Samy Bengio",
      "Elisabetta Cornacchia",
      "Jon Kleinberg",
      "Aryo Lotfi",
      "Maithra Raghu",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00278",
    "title": "On the Perils of Cascading Robust Classifiers",
    "abstract": " Title: On the Perils of Cascading Robust Classifiers ",
    "url": "https://arxiv.org/abs/2206.00278",
    "authors": [
      "Ravi Mangal",
      "Zifan Wang",
      "Chi Zhang",
      "Klas Leino",
      "Corina Pasareanu",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05091",
    "title": "Muffliato: Peer-to-Peer Privacy Amplification for Decentralized  Optimization and Averaging",
    "abstract": " Title: Muffliato: Peer-to-Peer Privacy Amplification for Decentralized  Optimization and Averaging ",
    "url": "https://arxiv.org/abs/2206.05091",
    "authors": [
      "Edwige Cyffers",
      "Mathieu Even",
      "Aur\u00e9lien Bellet",
      "Laurent Massouli\u00e9"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09391",
    "title": "Towards Adversarial Attack on Vision-Language Pre-training Models",
    "abstract": " Comments: Accepted by ACM MM2022. Code is available in GitHub ",
    "url": "https://arxiv.org/abs/2206.09391",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2206.09960",
    "title": "A Fast Algorithm for Ranking Users by their Influence in Online Social  Platforms",
    "abstract": " Comments: Proceedings of the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) ",
    "url": "https://arxiv.org/abs/2206.09960",
    "authors": [
      "Nouamane Arhachoui",
      "Esteban Bautista",
      "Maximilien Danisch",
      "Anastasios Giovanidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.11081",
    "title": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "abstract": " Title: Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks ",
    "url": "https://arxiv.org/abs/2206.11081",
    "authors": [
      "Hongjoon Ahn",
      "Yongyi Yang",
      "Quan Gan",
      "Taesup Moon",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.06827",
    "title": "Point-to-Box Network for Accurate Object Detection via Single Point  Supervision",
    "abstract": " Comments: Accepted by ECCV2022, github: this https URL ",
    "url": "https://arxiv.org/abs/2207.06827",
    "authors": [
      "Pengfei Chen",
      "Xuehui Yu",
      "Xumeng Han",
      "Najmul Hassan",
      "Kai Wang",
      "Jiachen Li",
      "Jian Zhao",
      "Humphrey Shi",
      "Zhenjun Han",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07888",
    "title": "SizeShiftReg: a Regularization Method for Improving Size-Generalization  in Graph Neural Networks",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.07888",
    "authors": [
      "Davide Buffelli",
      "Pietro Li\u00f2",
      "Fabio Vandin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11311",
    "title": "Understanding Non-linearity in Graph Neural Networks from the  Bayesian-Inference Perspective",
    "abstract": " Title: Understanding Non-linearity in Graph Neural Networks from the  Bayesian-Inference Perspective ",
    "url": "https://arxiv.org/abs/2207.11311",
    "authors": [
      "Rongzhe Wei",
      "Haoteng Yin",
      "Junteng Jia",
      "Austin R. Benson",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.14358",
    "title": "Topological structure of complex predictions",
    "abstract": " Title: Topological structure of complex predictions ",
    "url": "https://arxiv.org/abs/2207.14358",
    "authors": [
      "Meng Liu",
      "Tamal K. Dey",
      "David F. Gleich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2208.05863",
    "title": "GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions",
    "abstract": " Title: GEM-2: Next Generation Molecular Property Prediction Network by Modeling  Full-range Many-body Interactions ",
    "url": "https://arxiv.org/abs/2208.05863",
    "authors": [
      "Lihang Liu",
      "Donglong He",
      "Xiaomin Fang",
      "Shanzhuo Zhang",
      "Fan Wang",
      "Jingzhou He",
      "Hua Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2208.09316",
    "title": "UKP-SQuARE v2: Explainability and Adversarial Attacks for Trustworthy QA",
    "abstract": " Comments: Accepted at AACL 2022 as Demo Paper ",
    "url": "https://arxiv.org/abs/2208.09316",
    "authors": [
      "Rachneet Sachdeva",
      "Haritz Puerto",
      "Tim Baumg\u00e4rtner",
      "Sewin Tariverdian",
      "Hao Zhang",
      "Kexin Wang",
      "Hossain Shaikh Saadi",
      "Leonardo F. R. Ribeiro",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.12210",
    "title": "Learning Relational Causal Models with Cycles through Relational  Acyclification",
    "abstract": " Title: Learning Relational Causal Models with Cycles through Relational  Acyclification ",
    "url": "https://arxiv.org/abs/2208.12210",
    "authors": [
      "Ragib Ahsan",
      "David Arbour",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.03891",
    "title": "IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal  Triplets via Pre-trained Autoregressive Language Model",
    "abstract": " Comments: Camera-ready for CASE@EMNLP ",
    "url": "https://arxiv.org/abs/2209.03891",
    "authors": [
      "Martin Fajcik",
      "Muskaan Singh",
      "Juan Zuluaga-Gomez",
      "Esa\u00fa Villatoro-Tello",
      "Sergio Burdisso",
      "Petr Motlicek",
      "Pavel Smrz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07699",
    "title": "Graph Contrastive Learning with Cross-view Reconstruction",
    "abstract": " Title: Graph Contrastive Learning with Cross-view Reconstruction ",
    "url": "https://arxiv.org/abs/2209.07699",
    "authors": [
      "Qianlong Wen",
      "Zhongyu Ouyang",
      "Chunhui Zhang",
      "Yiyue Qian",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.08885",
    "title": "Causal Effect Estimation with Global Probabilistic Forecasting: A Case  Study of the Impact of Covid-19 Lockdowns on Energy Demand",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2209.08885",
    "authors": [
      "Ankitha Nandipura Prasanna",
      "Priscila Grecov",
      "Angela Dieyu Weng",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2209.15148",
    "title": "Embedded System Performance Analysis for Implementing a Portable  Drowsiness Detection System for Drivers",
    "abstract": " Comments: 16 pages, 11 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2209.15148",
    "authors": [
      "Minjeong Kim",
      "Jimin Koo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.15214",
    "title": "Construction and Applications of Billion-Scale Pre-trained Multimodal  Business Knowledge Graph",
    "abstract": " Comments: Work in Progress ",
    "url": "https://arxiv.org/abs/2209.15214",
    "authors": [
      "Shumin Deng",
      "Chengming Wang",
      "Zhoubo Li",
      "Ningyu Zhang",
      "Zelin Dai",
      "Hehong Chen",
      "Feiyu Xiong",
      "Ming Yan",
      "Qiang Chen",
      "Mosha Chen",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Bryan Hooi",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.02595",
    "title": "Exploration of A Self-Supervised Speech Model: A Study on Emotional  Corpora",
    "abstract": " Comments: Accepted for SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.02595",
    "authors": [
      "Yuanchao Li",
      "Yumnah Mohamied",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.03435",
    "title": "IDPL: Intra-subdomain adaptation adversarial learning segmentation  method based on Dynamic Pseudo Labels",
    "abstract": " Comments: Accepted at The 29th International Conference on Neural Information Processing (ICONIP 2022) ",
    "url": "https://arxiv.org/abs/2210.03435",
    "authors": [
      "Xuewei Li",
      "Weilun Zhang",
      "Jie Gao",
      "Xuzhou Fu",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06820",
    "title": "Personalized Federated Hypernetworks for Privacy Preservation in  Multi-Task Reinforcement Learning",
    "abstract": " Title: Personalized Federated Hypernetworks for Privacy Preservation in  Multi-Task Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2210.06820",
    "authors": [
      "Doseok Jang",
      "Larry Yan",
      "Lucas Spangher",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.07002",
    "title": "Anonymizing Speech with Generative Adversarial Networks to Preserve  Speaker Privacy",
    "abstract": " Comments: IEEE Spoken Language Technology Workshop 2022 ",
    "url": "https://arxiv.org/abs/2210.07002",
    "authors": [
      "Sarina Meyer",
      "Pascal Tilli",
      "Pavel Denisov",
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07920",
    "title": "MOVE: Unsupervised Movable Object Segmentation and Detection",
    "abstract": " Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2210.07920",
    "authors": [
      "Adam Bielski",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07978",
    "title": "Improving generalizability of distilled self-supervised speech  processing models under distorted settings",
    "abstract": " Comments: Accepted by IEEE SLT2022 ",
    "url": "https://arxiv.org/abs/2210.07978",
    "authors": [
      "Kuan-Po Huang",
      "Yu-Kuan Fu",
      "Tsu-Yuan Hsu",
      "Fabian Ritter Gutierrez",
      "Fan-Lin Wang",
      "Liang-Hsuan Tseng",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.08209",
    "title": "Large Language Models for Multi-label Propaganda Detection",
    "abstract": " Title: Large Language Models for Multi-label Propaganda Detection ",
    "url": "https://arxiv.org/abs/2210.08209",
    "authors": [
      "Tanmay Chavan",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08332",
    "title": "Code Recommendation for Open Source Software Developers",
    "abstract": " Comments: 10 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2210.08332",
    "authors": [
      "Yiqiao Jin",
      "Yunsheng Bai",
      "Yanqiao Zhu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08994",
    "title": "Knowledge Representation for Conceptual, Motivational, and Affective  Processes in Natural Language Communication",
    "abstract": " Comments: 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2210.08994",
    "authors": [
      "Seng-Beng Ho",
      "Zhaoxia Wang",
      "Boon-Kiat Quek",
      "Erik Cambria"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09420",
    "title": "Differentiable Physics Simulation of Dynamics-Augmented Neural Objects",
    "abstract": " Title: Differentiable Physics Simulation of Dynamics-Augmented Neural Objects ",
    "url": "https://arxiv.org/abs/2210.09420",
    "authors": [
      "Simon Le Cleac'h",
      "Hong-Xing Yu",
      "Michelle Guo",
      "Taylor A. Howell",
      "Ruohan Gao",
      "Jiajun Wu",
      "Zachary Manchester",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09535",
    "title": "Graph Anomaly Detection with Unsupervised GNNs",
    "abstract": " Comments: ICDM 2022 Short Paper Extension ",
    "url": "https://arxiv.org/abs/2210.09535",
    "authors": [
      "Lingxiao Zhao",
      "Saurabh Sawlani",
      "Arvind Srinivasan",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.09706",
    "title": "Privacy Explanations -- A Means to End-User Trust",
    "abstract": " Title: Privacy Explanations -- A Means to End-User Trust ",
    "url": "https://arxiv.org/abs/2210.09706",
    "authors": [
      "Wasja Brunotte",
      "Alexander Specht",
      "Larissa Chazette",
      "Kurt Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.09837",
    "title": "Deep Scattering Spectrum germaneness to Fault Detection and Diagnosis  for Component-level Prognostics and Health Management (PHM)",
    "abstract": " Comments: need changes ",
    "url": "https://arxiv.org/abs/2210.09837",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10488",
    "title": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "abstract": " Title: Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective ",
    "url": "https://arxiv.org/abs/2210.10488",
    "authors": [
      "Adaku Uchendu",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]