[
  {
    "id": "arXiv:2210.01795",
    "title": "BayesFT: Bayesian Optimization for Fault Tolerant Neural Network  Architecture",
    "abstract": "To deploy deep learning algorithms on resource-limited scenarios, an emerging device-resistive random access memory (ReRAM) has been regarded as promising via analog computing. However, the practicability of ReRAM is primarily limited due to the weight drifting of ReRAM neural networks due to multi-factor reasons, including manufacturing, thermal noises, and etc. In this paper, we propose a novel Bayesian optimization method for fault tolerant neural network architecture (BayesFT). For neural architecture search space design, instead of conducting neural architecture search on the whole feasible neural architecture search space, we first systematically explore the weight drifting tolerance of different neural network components, such as dropout, normalization, number of layers, and activation functions in which dropout is found to be able to improve the neural network robustness to weight drifting. Based on our analysis, we propose an efficient search space by only searching for dropout rates for each layer. Then, we use Bayesian optimization to search for the optimal neural architecture robust to weight drifting. Empirical experiments demonstrate that our algorithmic framework has outperformed the state-of-the-art methods by up to 10 times on various tasks, such as image classification and object detection. ",
    "url": "https://arxiv.org/abs/2210.01795",
    "authors": [
      "Nanyang Ye",
      "Jingbiao Mei",
      "Zhicheng Fang",
      "Yuwen Zhang",
      "Ziqing Zhang",
      "Huaying Wu",
      "Xiaoyao Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01798",
    "title": "Latent Hierarchical Causal Structure Discovery with Rank Constraints",
    "abstract": "Most causal discovery procedures assume that there are no latent confounders in the system, which is often violated in real-world problems. In this paper, we consider a challenging scenario for causal structure identification, where some variables are latent and they form a hierarchical graph structure to generate the measured variables; the children of latent variables may still be latent and only leaf nodes are measured, and moreover, there can be multiple paths between every pair of variables (i.e., it is beyond tree structure). We propose an estimation procedure that can efficiently locate latent variables, determine their cardinalities, and identify the latent hierarchical structure, by leveraging rank deficiency constraints over the measured variables. We show that the proposed algorithm can find the correct Markov equivalence class of the whole graph asymptotically under proper restrictions on the graph structure. ",
    "url": "https://arxiv.org/abs/2210.01798",
    "authors": [
      "Biwei Huang",
      "Charles Jia Han Low",
      "Feng Xie",
      "Clark Glymour",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01799",
    "title": "STGIN: A Spatial Temporal Graph-Informer Network for Long Sequence  Traffic Speed Forecasting",
    "abstract": "Accurate long series forecasting of traffic information is critical for the development of intelligent traffic systems. We may benefit from the rapid growth of neural network analysis technology to better understand the underlying functioning patterns of traffic networks as a result of this progress. Due to the fact that traffic data and facility utilization circumstances are sequentially dependent on past and present situations, several related neural network techniques based on temporal dependency extraction models have been developed to solve the problem. The complicated topological road structure, on the other hand, amplifies the effect of spatial interdependence, which cannot be captured by pure temporal extraction approaches. Additionally, the typical Deep Recurrent Neural Network (RNN) topology has a constraint on global information extraction, which is required for comprehensive long-term prediction. This study proposes a new spatial-temporal neural network architecture, called Spatial-Temporal Graph-Informer (STGIN), to handle the long-term traffic parameters forecasting issue by merging the Informer and Graph Attention Network (GAT) layers for spatial and temporal relationships extraction. The attention mechanism potentially guarantees long-term prediction performance without significant information loss from distant inputs. On two real-world traffic datasets with varying horizons, experimental findings validate the long sequence prediction abilities, and further interpretation is provided. ",
    "url": "https://arxiv.org/abs/2210.01799",
    "authors": [
      "Ruikang Luo",
      "Yaofeng Song",
      "Liping Huang",
      "Yicheng Zhang",
      "Rong Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01801",
    "title": "Safe Reinforcement Learning From Pixels Using a Stochastic Latent  Representation",
    "abstract": "We address the problem of safe reinforcement learning from pixel observations. Inherent challenges in such settings are (1) a trade-off between reward optimization and adhering to safety constraints, (2) partial observability, and (3) high-dimensional observations. We formalize the problem in a constrained, partially observable Markov decision process framework, where an agent obtains distinct reward and safety signals. To address the curse of dimensionality, we employ a novel safety critic using the stochastic latent actor-critic (SLAC) approach. The latent variable model predicts rewards and safety violations, and we use the safety critic to train safe policies. Using well-known benchmark environments, we demonstrate competitive performance over existing approaches with respects to computational requirements, final reward return, and satisfying the safety constraints. ",
    "url": "https://arxiv.org/abs/2210.01801",
    "authors": [
      "Yannick Hogewind",
      "Thiago D. Simao",
      "Tal Kachman",
      "Nils Jansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01803",
    "title": "Federated Graph-based Networks with Shared Embedding",
    "abstract": "Nowadays, user privacy is becoming an issue that cannot be bypassed for system developers, especially for that of web applications where data can be easily transferred through internet. Thankfully, federated learning proposes an innovative method to train models with distributed devices while data are kept in local storage. However, unlike general neural networks, although graph-based networks have achieved great success in classification tasks and advanced recommendation system, its high performance relies on the rich context provided by a graph structure, which is vulnerable when data attributes are incomplete. Therefore, the latter becomes a realistic problem when implementing federated learning for graph-based networks. Knowing that data embedding is a representation in a different space, we propose our Federated Graph-based Networks with Shared Embedding (Feras), which uses shared embedding data to train the network and avoids the direct sharing of original data. A solid theoretical proof of the convergence of Feras is given in this work. Experiments on different datasets (PPI, Flickr, Reddit) are conducted to show the efficiency of Feras for centralized learning. Finally, Feras enables the training of current graph-based models in the federated learning framework for privacy concern. ",
    "url": "https://arxiv.org/abs/2210.01803",
    "authors": [
      "Tianyi Yu",
      "Pei Lai",
      "Fei Teng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01834",
    "title": "Invariant Aggregator for Defending Federated Backdoor Attacks",
    "abstract": "Federated learning is gaining popularity as it enables training of high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Specifically, an adversary can perform backdoor attacks to control model predictions via poisoning the training dataset with a trigger. In this work, we propose a mitigation for backdoor attacks in a federated learning setup. Our solution forces the model optimization trajectory to focus on the invariant directions that are generally useful for utility and avoid selecting directions that favor few and possibly malicious clients. Concretely, we consider the sign consistency of the pseudo-gradient (the client update) as an estimation of the invariance. Following this, our approach performs dimension-wise filtering to remove pseudo-gradient elements with low sign consistency. Then, a robust mean estimator eliminates outliers among the remaining dimensions. Our theoretical analysis further shows the necessity of the defense combination and illustrates how our proposed solution defends the federated learning model. Empirical results on three datasets with different modalities and varying number of clients show that our approach mitigates backdoor attacks with a negligible cost on the model utility. ",
    "url": "https://arxiv.org/abs/2210.01834",
    "authors": [
      "Xiaoyang Wang",
      "Dimitrios Dimitriadis",
      "Sanmi Koyejo",
      "Shruti Tople"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01849",
    "title": "Link Partitioning on Simplicial Complexes Using Higher-Order Laplacians",
    "abstract": "Link partitioning is a popular approach in network science used for discovering overlapping communities by identifying clusters of strongly connected links. Current link partitioning methods are specifically designed for networks modelled by graphs representing pairwise relationships. Therefore, these methods are incapable of utilizing higher-order information about group interactions in network data which is increasingly available. Simplicial complexes extend the dyadic model of graphs and can model polyadic relationships which are ubiquitous and crucial in many complex social and technological systems. In this paper, we introduce a link partitioning method that leverages higher-order (i.e. triadic and higher) information in simplicial complexes for better community detection. Our method utilizes a novel random walk on links of simplicial complexes defined by the higher-order Laplacian--a generalization of the graph Laplacian that incorporates polyadic relationships of the network. We transform this random walk into a graph-based random walk on a lifted line graph--a dual graph in which links are nodes while nodes and higher-order connections are links--and optimize for the standard notion of modularity. We show that our method is guaranteed to provide interpretable link partitioning results under mild assumptions. We also offer new theoretical results on the spectral properties of simplicial complexes by studying the spectrum of the link random walk. Experiment results on real-world community detection tasks show that our higher-order approach significantly outperforms existing graph-based link partitioning methods. ",
    "url": "https://arxiv.org/abs/2210.01849",
    "authors": [
      "Xinyi Wu",
      "Arnab Sarker",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2210.01858",
    "title": "Structural Balance Considerations for Networks with Preference Orders as  Node Attributes",
    "abstract": "We discuss possible definitions of structural balance conditions in a network with preference orderings as node attributes. The main result is that for the case with three alternatives ($A,B,C$) we reduce the $(3!)^3 = 216$ possible configurations of triangles to $10$ equivalence classes, and use these as measures of balance of a triangle towards possible extensions of structural balance theory. Moreover, we derive a general formula for the number of equivalent classes for preferences on $n$ alternatives. Finally, we analyze a real-world data set and compare its empirical distribution of triangle equivalence classes to a null hypothesis in which preferences are randomly assigned to the nodes. ",
    "url": "https://arxiv.org/abs/2210.01858",
    "authors": [
      "Olle Abrahamsson",
      "Danyo Danev",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.01869",
    "title": "Memory in humans and deep language models: Linking hypotheses for model  augmentation",
    "abstract": "The computational complexity of the self-attention mechanism in Transformer models significantly limits their ability to generalize over long temporal durations. Memory-augmentation, or the explicit storing of past information in external memory for subsequent predictions, has become a constructive avenue for mitigating this limitation. We argue that memory-augmented Transformers can benefit substantially from considering insights from the memory literature in humans. We detail an approach to integrating evidence from the human memory system through the specification of cross-domain linking hypotheses. We then provide an empirical demonstration to evaluate the use of surprisal as a linking hypothesis, and further identify the limitations of this approach to inform future research. ",
    "url": "https://arxiv.org/abs/2210.01869",
    "authors": [
      "Omri Raccah",
      "Pheobe Chen",
      "Ted L. Willke",
      "David Poeppel",
      "Vy A. Vo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01884",
    "title": "Self-supervised Pre-training for Semantic Segmentation in an Indoor  Scene",
    "abstract": "The ability to endow maps of indoor scenes with semantic information is an integral part of robotic agents which perform different tasks such as target driven navigation, object search or object rearrangement. The state-of-the-art methods use Deep Convolutional Neural Networks (DCNNs) for predicting semantic segmentation of an image as useful representation for these tasks. The accuracy of semantic segmentation depends on the availability and the amount of labeled data from the target environment or the ability to bridge the domain gap between test and training environment. We propose RegConsist, a method for self-supervised pre-training of a semantic segmentation model, exploiting the ability of the agent to move and register multiple views in the novel environment. Given the spatial and temporal consistency cues used for pixel level data association, we use a variant of contrastive learning to train a DCNN model for predicting semantic segmentation from RGB views in the target environment. The proposed method outperforms models pre-trained on ImageNet and achieves competitive performance when using models that are trained for exactly the same task but on a different dataset. We also perform various ablation studies to analyze and demonstrate the efficacy of our proposed method. ",
    "url": "https://arxiv.org/abs/2210.01884",
    "authors": [
      "Sulabh Shrestha",
      "Yimeng Li",
      "Jana Kosecka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01891",
    "title": "AdaWAC: Adaptively Weighted Augmentation Consistency Regularization for  Volumetric Medical Image Segmentation",
    "abstract": "Sample reweighting is an effective strategy for learning from training data coming from a mixture of subpopulations. In volumetric medical image segmentation, the data inputs are similarly distributed, but the associated data labels fall into two subpopulations -- \"label-sparse\" and \"label-dense\" -- depending on whether the data image occurs near the beginning/end of the volumetric scan or the middle. Existing reweighting algorithms have focused on hard- and soft- thresholding of the label-sparse data, which results in loss of information and reduced sample efficiency by discarding valuable data input. For this setting, we propose AdaWAC as an adaptive weighting algorithm that introduces a set of trainable weights which, at the saddle point of the underlying objective, assigns label-dense samples to supervised cross-entropy loss and label-sparse samples to unsupervised consistency regularization. We provide a convergence guarantee for AdaWAC by recasting the optimization as online mirror descent on a saddle point problem. Moreover, we empirically demonstrate that AdaWAC not only enhances segmentation performance and sample efficiency but also improves robustness to the subpopulation shift in labels. ",
    "url": "https://arxiv.org/abs/2210.01891",
    "authors": [
      "Yijun Dong",
      "Yuege Xie",
      "Rachel Ward"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01892",
    "title": "Polysemanticity and Capacity in Neural Networks",
    "abstract": "Individual neurons in neural networks often represent a mixture of unrelated features. This phenomenon, called polysemanticity, can make interpreting neural networks more difficult and so we aim to understand its causes. We propose doing so through the lens of feature \\emph{capacity}, which is the fractional dimension each feature consumes in the embedding space. We show that in a toy model the optimal capacity allocation tends to monosemantically represent the most important features, polysemantically represent less important features (in proportion to their impact on the loss), and entirely ignore the least important features. Polysemanticity is more prevalent when the inputs have higher kurtosis or sparsity and more prevalent in some architectures than others. Given an optimal allocation of capacity, we go on to study the geometry of the embedding space. We find a block-semi-orthogonal structure, with differing block sizes in different models, highlighting the impact of model architecture on the interpretability of its neurons. ",
    "url": "https://arxiv.org/abs/2210.01892",
    "authors": [
      "Adam Scherlis",
      "Kshitij Sachan",
      "Adam S. Jermyn",
      "Joe Benton",
      "Buck Shlegeris"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01906",
    "title": "Tree Mover's Distance: Bridging Graph Metrics and Stability of Graph  Neural Networks",
    "abstract": "Understanding generalization and robustness of machine learning models fundamentally relies on assuming an appropriate metric on the data space. Identifying such a metric is particularly challenging for non-Euclidean data such as graphs. Here, we propose a pseudometric for attributed graphs, the Tree Mover's Distance (TMD), and study its relation to generalization. Via a hierarchical optimal transport problem, TMD reflects the local distribution of node attributes as well as the distribution of local computation trees, which are known to be decisive for the learning behavior of graph neural networks (GNNs). First, we show that TMD captures properties relevant to graph classification: a simple TMD-SVM performs competitively with standard GNNs. Second, we relate TMD to generalization of GNNs under distribution shifts, and show that it correlates well with performance drop under such shifts. ",
    "url": "https://arxiv.org/abs/2210.01906",
    "authors": [
      "Ching-Yao Chuang",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01910",
    "title": "Learning Signal Temporal Logic through Neural Network for Interpretable  Classification",
    "abstract": "Machine learning techniques using neural networks have achieved promising success for time-series data classification. However, the models that they produce are challenging to verify and interpret. In this paper, we propose an explainable neural-symbolic framework for the classification of time-series behaviors. In particular, we use an expressive formal language, namely Signal Temporal Logic (STL), to constrain the search of the computation graph for a neural network. We design a novel time function and sparse softmax function to improve the soundness and precision of the neural-STL framework. As a result, we can efficiently learn a compact STL formula for the classification of time-series data through off-the-shelf gradient-based tools. We demonstrate the computational efficiency, compactness, and interpretability of the proposed method through driving scenarios and naval surveillance case studies, compared with state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2210.01910",
    "authors": [
      "Danyang Li",
      "Mingyu Cai",
      "Cristian-Ioan Vasile",
      "Roberto Tron"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01917",
    "title": "Dfferentiable Raycasting for Self-supervised Occupancy Forecasting",
    "abstract": "Motion planning for safe autonomous driving requires learning how the environment around an ego-vehicle evolves with time. Ego-centric perception of driveable regions in a scene not only changes with the motion of actors in the environment, but also with the movement of the ego-vehicle itself. Self-supervised representations proposed for large-scale planning, such as ego-centric freespace, confound these two motions, making the representation difficult to use for downstream motion planners. In this paper, we use geometric occupancy as a natural alternative to view-dependent representations such as freespace. Occupancy maps naturally disentangle the motion of the environment from the motion of the ego-vehicle. However, one cannot directly observe the full 3D occupancy of a scene (due to occlusion), making it difficult to use as a signal for learning. Our key insight is to use differentiable raycasting to \"render\" future occupancy predictions into future LiDAR sweep predictions, which can be compared with ground-truth sweeps for self-supervised learning. The use of differentiable raycasting allows occupancy to emerge as an internal representation within the forecasting network. In the absence of groundtruth occupancy, we quantitatively evaluate the forecasting of raycasted LiDAR sweeps and show improvements of upto 15 F1 points. For downstream motion planners, where emergent occupancy can be directly used to guide non-driveable regions, this representation relatively reduces the number of collisions with objects by up to 17% as compared to freespace-centric motion planners. ",
    "url": "https://arxiv.org/abs/2210.01917",
    "authors": [
      "Tarasha Khurana",
      "Peiyun Hu",
      "Achal Dave",
      "Jason ZIglar",
      "David Held",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01922",
    "title": "Semantics-aware Dataset Discovery from Data Lakes with Contextualized  Column-based Representation Learning",
    "abstract": "Dataset discovery from data lakes is essential in many real application scenarios. In this paper, we propose Starmie, an end-to-end framework for dataset discovery from data lakes (with table union search as the main use case). Our proposed framework features a contrastive learning method to train column encoders from pre-trained language models in a fully unsupervised manner. The column encoder of Starmie captures the rich contextual semantic information within tables by leveraging a contrastive multi-column pre-training strategy. We utilize the cosine similarity between column embedding vectors as the column unionability score and propose a filter-and-verification framework that allows exploring a variety of design choices to compute the unionability score between two tables accordingly. Empirical evaluation results on real table benchmark datasets show that Starmie outperforms the best-known solutions in the effectiveness of table union search by 6.8 in MAP and recall. Moreover, Starmie is the first to employ the HNSW (Hierarchical Navigable Small World) index for accelerate query processing of table union search which provides a 3,000X performance gain over the linear scan baseline and a 400X performance gain over an LSH index (the state-of-the-art solution for data lake indexing). ",
    "url": "https://arxiv.org/abs/2210.01922",
    "authors": [
      "Grace Fan",
      "Jin Wang",
      "Yuliang Li",
      "Dan Zhang",
      "Ren\u00e9e Miller"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.01933",
    "title": "PreprintMatch: a tool for preprint publication detection applied to  analyze global inequities in scientific publishing",
    "abstract": "Preprints, versions of scientific manuscripts that precede peer review, are growing in popularity. They offer an opportunity to democratize and accelerate research, as they have no publication costs or a lengthy peer review process. Preprints are often later published in peer-reviewed venues, but these publications and the original preprints are frequently not linked in any way. To this end, we developed a tool, PreprintMatch, to find matches between preprints and their corresponding published papers, if they exist. This tool outperforms existing techniques to match preprints and papers, both on matching performance and speed. PreprintMatch was applied to search for matches between preprints (from bioRxiv and medRxiv), and PubMed. The preliminary nature of preprints offers a unique perspective into scientific projects at a relatively early stage, and with better matching between preprint and paper, we explored questions related to research inequity. We found that preprints from low income countries are published as peer-reviewed papers at a lower rate than high income countries (39.6\\% and 61.1\\%, respectively), and our data is consistent with previous work that cite a lack of resources, lack of stability, and policy choices to explain this discrepancy. Preprints from low income countries were also found to be published quicker (178 vs 203 days) and with less title, abstract, and author similarity to the published version compared to high income countries. Low income countries add more authors from the preprint to the published version than high income countries (0.42 authors vs 0.32, respectively), a practice that is significantly more frequent in China compared to similar countries. Finally, we find that some publishers publish work with authors from lower income countries more frequently than others. PreprintMatch is available at \\url{https://github.com/PeterEckmann1/preprint-match}. ",
    "url": "https://arxiv.org/abs/2210.01933",
    "authors": [
      "Peter Eckmann",
      "Anita Bandrowski"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2210.01940",
    "title": "On the Robustness of Deep Clustering Models: Adversarial Attacks and  Defenses",
    "abstract": "Clustering models constitute a class of unsupervised machine learning methods which are used in a number of application pipelines, and play a vital role in modern data science. With recent advancements in deep learning -- deep clustering models have emerged as the current state-of-the-art over traditional clustering approaches, especially for high-dimensional image datasets. While traditional clustering approaches have been analyzed from a robustness perspective, no prior work has investigated adversarial attacks and robustness for deep clustering models in a principled manner. To bridge this gap, we propose a blackbox attack using Generative Adversarial Networks (GANs) where the adversary does not know which deep clustering model is being used, but can query it for outputs. We analyze our attack against multiple state-of-the-art deep clustering models and real-world datasets, and find that it is highly successful. We then employ some natural unsupervised defense approaches, but find that these are unable to mitigate our attack. Finally, we attack Face++, a production-level face clustering API service, and find that we can significantly reduce its performance as well. Through this work, we thus aim to motivate the need for truly robust deep clustering models. ",
    "url": "https://arxiv.org/abs/2210.01940",
    "authors": [
      "Anshuman Chhabra",
      "Ashwin Sekhari",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.01944",
    "title": "A Framework for Large Scale Synthetic Graph Dataset Generation",
    "abstract": "Recently there has been increasing interest in developing and deploying deep graph learning algorithms for many graph analysis tasks such as node and edge classification, link prediction, and clustering with numerous practical applications such as fraud detection, drug discovery, or recommender systems. Allbeit there is a limited number of publicly available graph-structured datasets, most of which are tiny compared to production-sized applications with trillions of edges and billions of nodes. Further, new algorithms and models are benchmarked across similar datasets with similar properties. In this work, we tackle this shortcoming by proposing a scalable synthetic graph generation tool that can mimic the original data distribution of real-world graphs and scale them to arbitrary sizes. This tool can be used then to learn a set of parametric models from proprietary datasets that can subsequently be released to researchers to study various graph methods on the synthetic data increasing prototype development and novel applications. Finally, the performance of the graph learning algorithms depends not only on the size but also on the dataset's structure. We show how our framework generalizes across a set of datasets, mimicking both structural and feature distributions as well as its scalability across varying dataset sizes. ",
    "url": "https://arxiv.org/abs/2210.01944",
    "authors": [
      "Sajad Darabi",
      "Piotr Bigaj",
      "Dawid Majchrowski",
      "Pawel Morkisz",
      "Alex Fit-Florea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.01953",
    "title": "Robust Fair Clustering: A Novel Fairness Attack and Defense Framework",
    "abstract": "Clustering algorithms are widely used in many societal resource allocation applications, such as loan approvals and candidate recruitment, among others, and hence, biased or unfair model outputs can adversely impact individuals that rely on these applications. To this end, many fair clustering approaches have been recently proposed to counteract this issue. Due to the potential for significant harm, it is essential to ensure that fair clustering algorithms provide consistently fair outputs even under adversarial influence. However, fair clustering algorithms have not been studied from an adversarial attack perspective. In contrast to previous research, we seek to bridge this gap and conduct a robustness analysis against fair clustering by proposing a novel black-box fairness attack. Through comprehensive experiments, we find that state-of-the-art models are highly susceptible to our attack as it can reduce their fairness performance significantly. Finally, we propose Consensus Fair Clustering (CFC), the first robust fair clustering approach that transforms consensus clustering into a fair graph partitioning problem, and iteratively learns to generate fair cluster outputs. Experimentally, we observe that CFC is highly robust to the proposed attack and is thus a truly robust fair clustering alternative. ",
    "url": "https://arxiv.org/abs/2210.01953",
    "authors": [
      "Anshuman Chhabra",
      "Peizhao Li",
      "Prasant Mohapatra",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.01969",
    "title": "Hierarchical Adversarial Inverse Reinforcement Learning",
    "abstract": "Hierarchical Imitation Learning (HIL) has been proposed to recover highly-complex behaviors in long-horizontal tasks from expert demonstrations by modeling the task hierarchy with the option framework. Existing methods either overlook the causal relationship between the subtask and its corresponding policy or fail to learn the policy in an end-to-end fashion, which leads to suboptimality. In this work, we develop a novel HIL algorithm based on Adversarial Inverse Reinforcement Learning and adapt it with the Expectation-Maximization algorithm in order to directly recover a hierarchical policy from the unannotated demonstrations. Further, we introduce a directed information term to the objective function to enhance the causality and propose a Variational Autoencoder framework for learning with our objectives in an end-to-end fashion. Theoretical justifications and evaluations on challenging robotic control tasks are provided to show the superiority of our algorithm. The codes are available at https://github.com/LucasCJYSDL/HierAIRL. ",
    "url": "https://arxiv.org/abs/2210.01969",
    "authors": [
      "Jiayu Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01974",
    "title": "Towards Prototype-Based Self-Explainable Graph Neural Network",
    "abstract": "Graph Neural Networks (GNNs) have shown great ability in modeling graph-structured data for various domains. However, GNNs are known as black-box models that lack interpretability. Without understanding their inner working, we cannot fully trust them, which largely limits their adoption in high-stake scenarios. Though some initial efforts have been taken to interpret the predictions of GNNs, they mainly focus on providing post-hoc explanations using an additional explainer, which could misrepresent the true inner working mechanism of the target GNN. The works on self-explainable GNNs are rather limited. Therefore, we study a novel problem of learning prototype-based self-explainable GNNs that can simultaneously give accurate predictions and prototype-based explanations on predictions. We design a framework which can learn prototype graphs that capture representative patterns of each class as class-level explanations. The learned prototypes are also used to simultaneously make prediction for for a test instance and provide instance-level explanation. Extensive experiments on real-world and synthetic datasets show the effectiveness of the proposed framework for both prediction accuracy and explanation quality. ",
    "url": "https://arxiv.org/abs/2210.01974",
    "authors": [
      "Enyan Dai",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01985",
    "title": "A Multi-Stage Automated Online Network Data Stream Analytics Framework  for IIoT Systems",
    "abstract": "Industry 5.0 aims at maximizing the collaboration between humans and machines. Machines are capable of automating repetitive jobs, while humans handle creative tasks. As a critical component of Industrial Internet of Things (IIoT) systems for service delivery, network data stream analytics often encounter concept drift issues due to dynamic IIoT environments, causing performance degradation and automation difficulties. In this paper, we propose a novel Multi-Stage Automated Network Analytics (MSANA) framework for concept drift adaptation in IIoT systems, consisting of dynamic data pre-processing, the proposed Drift-based Dynamic Feature Selection (DD-FS) method, dynamic model learning & selection, and the proposed Window-based Performance Weighted Probability Averaging Ensemble (W-PWPAE) model. It is a complete automated data stream analytics framework that enables automatic, effective, and efficient data analytics for IIoT systems in Industry 5.0. Experimental results on two public IoT datasets demonstrate that the proposed framework outperforms state-of-the-art methods for IIoT data stream analytics. ",
    "url": "https://arxiv.org/abs/2210.01985",
    "authors": [
      "Li Yang",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.01986",
    "title": "MAtt: A Manifold Attention Network for EEG Decoding",
    "abstract": "Recognition of electroencephalographic (EEG) signals highly affect the efficiency of non-invasive brain-computer interfaces (BCIs). While recent advances of deep-learning (DL)-based EEG decoders offer improved performances, the development of geometric learning (GL) has attracted much attention for offering exceptional robustness in decoding noisy EEG data. However, there is a lack of studies on the merged use of deep neural networks (DNNs) and geometric learning for EEG decoding. We herein propose a manifold attention network (mAtt), a novel geometric deep learning (GDL)-based model, featuring a manifold attention mechanism that characterizes spatiotemporal representations of EEG data fully on a Riemannian symmetric positive definite (SPD) manifold. The evaluation of the proposed MAtt on both time-synchronous and -asyncronous EEG datasets suggests its superiority over other leading DL methods for general EEG decoding. Furthermore, analysis of model interpretation reveals the capability of MAtt in capturing informative EEG features and handling the non-stationarity of brain dynamics. ",
    "url": "https://arxiv.org/abs/2210.01986",
    "authors": [
      "Yue-Ting Pan",
      "Jing-Lun Chou",
      "Chun-Shu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.02009",
    "title": "Multi-Camera Collaborative Depth Prediction via Consistent Structure  Estimation",
    "abstract": "Depth map estimation from images is an important task in robotic systems. Existing methods can be categorized into two groups including multi-view stereo and monocular depth estimation. The former requires cameras to have large overlapping areas and sufficient baseline between cameras, while the latter that processes each image independently can hardly guarantee the structure consistency between cameras. In this paper, we propose a novel multi-camera collaborative depth prediction method that does not require large overlapping areas while maintaining structure consistency between cameras. Specifically, we formulate the depth estimation as a weighted combination of depth basis, in which the weights are updated iteratively by a refinement network driven by the proposed consistency loss. During the iterative update, the results of depth estimation are compared across cameras and the information of overlapping areas is propagated to the whole depth maps with the help of basis formulation. Experimental results on DDAD and NuScenes datasets demonstrate the superior performance of our method. ",
    "url": "https://arxiv.org/abs/2210.02009",
    "authors": [
      "Jialei Xu",
      "Xianming Liu",
      "Yuanchao Bai",
      "Junjun Jiang",
      "Kaixuan Wang",
      "Xiaozhi Chen",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02016",
    "title": "Multi-task Self-supervised Graph Neural Networks Enable Stronger Task  Generalization",
    "abstract": "Self-supervised learning (SSL) for graph neural networks (GNNs) has attracted increasing attention from the graph machine learning community in recent years, owing to its capability to learn performant node embeddings without costly label information. One weakness of conventional SSL frameworks for GNNs is that they learn through a single philosophy, such as mutual information maximization or generative reconstruction. When applied to various downstream tasks, these frameworks rarely perform equally well for every task, because one philosophy may not span the extensive knowledge required for all tasks. In light of this, we introduce ParetoGNN, a multi-task SSL framework for node representation learning over graphs. Specifically, ParetoGNN is self-supervised by manifold pretext tasks observing multiple philosophies. To reconcile different philosophies, we explore a multiple-gradient descent algorithm, such that ParetoGNN actively learns from every pretext task while minimizing potential conflicts. We conduct comprehensive experiments over four downstream tasks (i.e., node classification, node clustering, link prediction, and partition prediction), and our proposal achieves the best overall performance across tasks on 11 widely adopted benchmark datasets. Besides, we observe that learning from multiple philosophies enhances not only the task generalization but also the single task performance, demonstrating that ParetoGNN achieves better task generalization via the disjoint yet complementary knowledge learned from different philosophies. ",
    "url": "https://arxiv.org/abs/2210.02016",
    "authors": [
      "Mingxuan Ju",
      "Tong Zhao",
      "Qianlong Wen",
      "Wenhao Yu",
      "Neil Shah",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02017",
    "title": "Infectious Probability Analysis on COVID-19 Spreading with Wireless Edge  Networks",
    "abstract": "The emergence of infectious disease COVID-19 has challenged and changed the world in an unprecedented manner. The integration of wireless networks with edge computing (namely wireless edge networks) brings opportunities to address this crisis. In this paper, we aim to investigate the prediction of the infectious probability and propose precautionary measures against COVID-19 with the assistance of wireless edge networks. Due to the availability of the recorded detention time and the density of individuals within a wireless edge network, we propose a stochastic geometry-based method to analyze the infectious probability of individuals. The proposed method can well keep the privacy of individuals in the system since it does not require to know the location or trajectory of each individual. Moreover, we also consider three types of mobility models and the static model of individuals. Numerical results show that analytical results well match with simulation results, thereby validating the accuracy of the proposed model. Moreover, numerical results also offer many insightful implications. Thereafter, we also offer a number of countermeasures against the spread of COVID-19 based on wireless edge networks. This study lays the foundation toward predicting the infectious risk in realistic environment and points out directions in mitigating the spread of infectious diseases with the aid of wireless edge networks. ",
    "url": "https://arxiv.org/abs/2210.02017",
    "authors": [
      "Xuran Li",
      "Shuaishuai Guo",
      "Hong-Ning Dai",
      "Dengwang Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.02021",
    "title": "Exploring Effective Knowledge Transfer for Few-shot Object Detection",
    "abstract": "Recently, few-shot object detection~(FSOD) has received much attention from the community, and many methods are proposed to address this problem from a knowledge transfer perspective. Though promising results have been achieved, these methods fail to achieve shot-stable:~methods that excel in low-shot regimes are likely to struggle in high-shot regimes, and vice versa. We believe this is because the primary challenge of FSOD changes when the number of shots varies. In the low-shot regime, the primary challenge is the lack of inner-class variation. In the high-shot regime, as the variance approaches the real one, the main hindrance to the performance comes from misalignment between learned and true distributions. However, these two distinct issues remain unsolved in most existing FSOD methods. In this paper, we propose to overcome these challenges by exploiting rich knowledge the model has learned and effectively transferring them to the novel classes. For the low-shot regime, we propose a distribution calibration method to deal with the lack of inner-class variation problem. Meanwhile, a shift compensation method is proposed to compensate for possible distribution shift during fine-tuning. For the high-shot regime, we propose to use the knowledge learned from ImageNet as guidance for the feature learning in the fine-tuning stage, which will implicitly align the distributions of the novel classes. Although targeted toward different regimes, these two strategies can work together to further improve the FSOD performance. Experiments on both the VOC and COCO benchmarks show that our proposed method can significantly outperform the baseline method and produce competitive results in both low-shot settings (shot<5) and high-shot settings (shot>=5). Code is available at https://github.com/JulioZhao97/EffTrans_Fsdet.git. ",
    "url": "https://arxiv.org/abs/2210.02021",
    "authors": [
      "Zhiyuan Zhao",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02023",
    "title": "DreamShard: Generalizable Embedding Table Placement for Recommender  Systems",
    "abstract": "We study embedding table placement for distributed recommender systems, which aims to partition and place the tables on multiple hardware devices (e.g., GPUs) to balance the computation and communication costs. Although prior work has explored learning-based approaches for the device placement of computational graphs, embedding table placement remains to be a challenging problem because of 1) the operation fusion of embedding tables, and 2) the generalizability requirement on unseen placement tasks with different numbers of tables and/or devices. To this end, we present DreamShard, a reinforcement learning (RL) approach for embedding table placement. DreamShard achieves the reasoning of operation fusion and generalizability with 1) a cost network to directly predict the costs of the fused operation, and 2) a policy network that is efficiently trained on an estimated Markov decision process (MDP) without real GPU execution, where the states and the rewards are estimated with the cost network. Equipped with sum and max representation reductions, the two networks can directly generalize to any unseen tasks with different numbers of tables and/or devices without fine-tuning. Extensive experiments show that DreamShard substantially outperforms the existing human expert and RNN-based strategies with up to 19% speedup over the strongest baseline on large-scale synthetic tables and our production tables. The code is available at https://github.com/daochenzha/dreamshard ",
    "url": "https://arxiv.org/abs/2210.02023",
    "authors": [
      "Daochen Zha",
      "Louis Feng",
      "Qiaoyu Tan",
      "Zirui Liu",
      "Kwei-Herng Lai",
      "Bhargav Bhushanam",
      "Yuandong Tian",
      "Arun Kejariwal",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02024",
    "title": "Perfect Reconstruction Two-Channel Filter Banks on Arbitrary Graphs",
    "abstract": "This paper extends the existing theory of perfect reconstruction two-channel filter banks from bipartite graphs to non-bipartite graphs. By generalizing the concept of downsampling/upsampling we establish the frame of two-channel filter bank on arbitrary connected, undirected and weighted graphs. Then the equations for perfect reconstruction of the filter banks are presented and solved under proper conditions. Algorithms for designing orthogonal and biorthogonal banks are given and two typical orthogonal two-channel filter banks are calculated. The locality and approximation properties of such filter banks are discussed theoretically and experimentally. ",
    "url": "https://arxiv.org/abs/2210.02024",
    "authors": [
      "Junxia You",
      "Lihua Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.02034",
    "title": "Clustering Semantic Predicates in the Open Research Knowledge Graph",
    "abstract": "When semantically describing knowledge graphs (KGs), users have to make a critical choice of a vocabulary (i.e. predicates and resources). The success of KG building is determined by the convergence of shared vocabularies so that meaning can be established. The typical lifecycle for a new KG construction can be defined as follows: nascent phases of graph construction experience terminology divergence, while later phases of graph construction experience terminology convergence and reuse. In this paper, we describe our approach tailoring two AI-based clustering algorithms for recommending predicates (in RDF statements) about resources in the Open Research Knowledge Graph (ORKG) https://orkg.org/. Such a service to recommend existing predicates to semantify new incoming data of scholarly publications is of paramount importance for fostering terminology convergence in the ORKG. Our experiments show very promising results: a high precision with relatively high recall in linear runtime performance. Furthermore, this work offers novel insights into the predicate groups that automatically accrue loosely as generic semantification patterns for semantification of scholarly knowledge spanning 44 research fields. ",
    "url": "https://arxiv.org/abs/2210.02034",
    "authors": [
      "Omar Arab Oghli",
      "Jennifer D'Souza",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02040",
    "title": "GT-GAN: General Purpose Time Series Synthesis with Generative  Adversarial Networks",
    "abstract": "Time series synthesis is an important research topic in the field of deep learning, which can be used for data augmentation. Time series data types can be broadly classified into regular or irregular. However, there are no existing generative models that show good performance for both types without any model changes. Therefore, we present a general purpose model capable of synthesizing regular and irregular time series data. To our knowledge, we are the first designing a general purpose time series synthesis model, which is one of the most challenging settings for time series synthesis. To this end, we design a generative adversarial network-based method, where many related techniques are carefully integrated into a single framework, ranging from neural ordinary/controlled differential equations to continuous time-flow processes. Our method outperforms all existing methods. ",
    "url": "https://arxiv.org/abs/2210.02040",
    "authors": [
      "Jinsung Jeon",
      "Jeonghak Kim",
      "Haryong Song",
      "Seunghyeon Cho",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02041",
    "title": "Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks",
    "abstract": "Unrestricted color attacks, which manipulate semantically meaningful color of an image, have shown their stealthiness and success in fooling both human eyes and deep neural networks. However, current works usually sacrifice the flexibility of the uncontrolled setting to ensure the naturalness of adversarial examples. As a result, the black-box attack performance of these methods is limited. To boost transferability of adversarial examples without damaging image quality, we propose a novel Natural Color Fool (NCF) which is guided by realistic color distributions sampled from a publicly available dataset and optimized by our neighborhood search and initialization reset. By conducting extensive experiments and visualizations, we convincingly demonstrate the effectiveness of our proposed method. Notably, on average, results show that our NCF can outperform state-of-the-art approaches by 15.0%$\\sim$32.9% for fooling normally trained models and 10.0%$\\sim$25.3% for evading defense methods. Our code is available at https://github.com/ylhz/Natural-Color-Fool. ",
    "url": "https://arxiv.org/abs/2210.02041",
    "authors": [
      "Shengming Yuan",
      "Qilong Zhang",
      "Lianli Gao",
      "Yaya Cheng",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02060",
    "title": "Graph Classification via Discriminative Edge Feature Learning",
    "abstract": "Spectral graph convolutional neural networks (GCNNs) have been producing encouraging results in graph classification tasks. However, most spectral GCNNs utilize fixed graphs when aggregating node features, while omitting edge feature learning and failing to get an optimal graph structure. Moreover, many existing graph datasets do not provide initialized edge features, further restraining the ability of learning edge features via spectral GCNNs. In this paper, we try to address this issue by designing an edge feature scheme and an add-on layer between every two stacked graph convolution layers in GCNN. Both are lightweight while effective in filling the gap between edge feature learning and performance enhancement of graph classification. The edge feature scheme makes edge features adapt to node representations at different graph convolution layers. The add-on layers help adjust the edge features to an optimal graph structure. To test the effectiveness of our method, we take Euclidean positions as initial node features and extract graphs with semantic information from point cloud objects. The node features of our extracted graphs are more scalable for edge feature learning than most existing graph datasets (in one-hot encoded label format). Three new graph datasets are constructed based on ModelNet40, ModelNet10 and ShapeNet Part datasets. Experimental results show that our method outperforms state-of-the-art graph classification methods on the new datasets by reaching 96.56% overall accuracy on Graph-ModelNet40, 98.79% on Graph-ModelNet10 and 97.91% on Graph-ShapeNet Part. The constructed graph datasets will be released to the community. ",
    "url": "https://arxiv.org/abs/2210.02060",
    "authors": [
      "Yang Yi",
      "Xuequan Lu",
      "Shang Gao",
      "Antonio Robles-Kelly",
      "Yuejie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02071",
    "title": "Advanced Deep Learning Architectures for Accurate Detection of  Subsurface Tile Drainage Pipes from Remote Sensing Images",
    "abstract": "Subsurface tile drainage pipes provide agronomic, economic and environmental benefits. By lowering the water table of wet soils, they improve the aeration of plant roots and ultimately increase the productivity of farmland. They do however also provide an entryway of agrochemicals into subsurface water bodies and increase nutrition loss in soils. For maintenance and infrastructural development, accurate maps of tile drainage pipe locations and drained agricultural land are needed. However, these maps are often outdated or not present. Different remote sensing (RS) image processing techniques have been applied over the years with varying degrees of success to overcome these restrictions. Recent developments in deep learning (DL) techniques improve upon the conventional techniques with machine learning segmentation models. In this study, we introduce two DL-based models: i) improved U-Net architecture; and ii) Visual Transformer-based encoder-decoder in the framework of tile drainage pipe detection. Experimental results confirm the effectiveness of both models in terms of detection accuracy when compared to a basic U-Net architecture. Our code and models are publicly available at \\url{https://git.tu-berlin.de/rsim/drainage-pipes-detection}. ",
    "url": "https://arxiv.org/abs/2210.02071",
    "authors": [
      "Tom L. Breitkopf",
      "Leonard W. Hackel",
      "Mahdyar Ravanbakhsh",
      "Anne-Karin Cooke",
      "Sandra Willkommen",
      "Stefan Broda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.02077",
    "title": "Exploring The Role of Mean Teachers in Self-supervised Masked  Auto-Encoders",
    "abstract": "Masked image modeling (MIM) has become a popular strategy for self-supervised learning~(SSL) of visual representations with Vision Transformers. A representative MIM model, the masked auto-encoder (MAE), randomly masks a subset of image patches and reconstructs the masked patches given the unmasked patches. Concurrently, many recent works in self-supervised learning utilize the student/teacher paradigm which provides the student with an additional target based on the output of a teacher composed of an exponential moving average (EMA) of previous students. Although common, relatively little is known about the dynamics of the interaction between the student and teacher. Through analysis on a simple linear model, we find that the teacher conditionally removes previous gradient directions based on feature similarities which effectively acts as a conditional momentum regularizer. From this analysis, we present a simple SSL method, the Reconstruction-Consistent Masked Auto-Encoder (RC-MAE) by adding an EMA teacher to MAE. We find that RC-MAE converges faster and requires less memory usage than state-of-the-art self-distillation methods during pre-training, which may provide a way to enhance the practicality of prohibitively expensive self-supervised learning of Vision Transformer models. Additionally, we show that RC-MAE achieves more robustness and better performance compared to MAE on downstream tasks such as ImageNet-1K classification, object detection, and instance segmentation. ",
    "url": "https://arxiv.org/abs/2210.02077",
    "authors": [
      "Youngwan Lee",
      "Jeffrey Willette",
      "Jonghee Kim",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02089",
    "title": "Transformer-based conditional generative adversarial network for  multivariate time series generation",
    "abstract": "Conditional generation of time-dependent data is a task that has much interest, whether for data augmentation, scenario simulation, completing missing data, or other purposes. Recent works proposed a Transformer-based Time series generative adversarial network (TTS-GAN) to address the limitations of recurrent neural networks. However, this model assumes a unimodal distribution and tries to generate samples around the expectation of the real data distribution. One of its limitations is that it may generate a random multivariate time series; it may fail to generate samples in the presence of multiple sub-components within an overall distribution. One could train models to fit each sub-component separately to overcome this limitation. Our work extends the TTS-GAN by conditioning its generated output on a particular encoded context allowing the use of one model to fit a mixture distribution with multiple sub-components. Technically, it is a conditional generative adversarial network that models realistic multivariate time series under different types of conditions, such as categorical variables or multivariate time series. We evaluate our model on UniMiB Dataset, which contains acceleration data following the XYZ axes of human activities collected using Smartphones. We use qualitative evaluations and quantitative metrics such as Principal Component Analysis (PCA), and we introduce a modified version of the Frechet inception distance (FID) to measure the performance of our model and the statistical similarities between the generated and the real data distributions. We show that this transformer-based CGAN can generate realistic high-dimensional and long data sequences under different kinds of conditions. ",
    "url": "https://arxiv.org/abs/2210.02089",
    "authors": [
      "Abdellah Madane",
      "Mohamed-djallel Dilmi",
      "Florent Forest",
      "Hanane Azzag",
      "Mustapha Lebbah",
      "Jerome Lacaille"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02090",
    "title": "Joint Communication and Computation in Hybrid Cloud/Mobile Edge  Computing Networks",
    "abstract": "Facing a vast amount of connections, huge performance demands, and the need for reliable connectivity, the sixth generation of communication networks (6G) is envisioned to implement disruptive technologies that jointly spur connectivity, performance, and reliability. In this context, this paper proposes, and evaluates the benefit of, a hybrid central cloud (CC) computing and mobile edge computing (MEC) platform, especially introduced to balance the network resources required for joint computation and communication. Consider a hybrid cloud and MEC system, where several power-hungry multi-antenna unmanned aerial vehicles (UAVs) are deployed at the cell-edge to boost the CC connectivity and relieve part of its computation burden. While the multi-antenna base stations are connected to the cloud via capacity-limited fronthaul links, the UAVs serve the cell-edge users with limited power and computational capabilities. The paper then considers the problem of maximizing the weighted network sum-rate subject to per-user delay, computational capacity, and power constraints, so as to determine the beamforming vectors and computation allocations. Such intricate non-convex optimization problem is tackled using an iterative algorithm that relies on $\\ell_0$-norm relaxation, successive convex approximation, and fractional programming, and has the compelling ability to be implemented in a distributed fashion across the multiple UAVs and the CC. The paper results illustrate the numerical prospects of the proposed algorithm for enabling joint communication and computation, and highlight the appreciable improvements of data processing delays and throughputs as compared to conventional system strategies. ",
    "url": "https://arxiv.org/abs/2210.02090",
    "authors": [
      "Robert-Jeron Reifert",
      "Hayssam Dahrouj",
      "Basem Shihada",
      "Aydin Sezgin",
      "Tareq Y. Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.02093",
    "title": "Centralized Feature Pyramid for Object Detection",
    "abstract": "Visual feature pyramid has shown its superiority in both effectiveness and efficiency in a wide range of applications. However, the existing methods exorbitantly concentrate on the inter-layer feature interactions but ignore the intra-layer feature regulations, which are empirically proved beneficial. Although some methods try to learn a compact intra-layer feature representation with the help of the attention mechanism or the vision transformer, they ignore the neglected corner regions that are important for dense prediction tasks. To address this problem, in this paper, we propose a Centralized Feature Pyramid (CFP) for object detection, which is based on a globally explicit centralized feature regulation. Specifically, we first propose a spatial explicit visual center scheme, where a lightweight MLP is used to capture the globally long-range dependencies and a parallel learnable visual center mechanism is used to capture the local corner regions of the input images. Based on this, we then propose a globally centralized regulation for the commonly-used feature pyramid in a top-down fashion, where the explicit visual center information obtained from the deepest intra-layer feature is used to regulate frontal shallow features. Compared to the existing feature pyramids, CFP not only has the ability to capture the global long-range dependencies, but also efficiently obtain an all-round yet discriminative feature representation. Experimental results on the challenging MS-COCO validate that our proposed CFP can achieve the consistent performance gains on the state-of-the-art YOLOv5 and YOLOX object detection baselines. ",
    "url": "https://arxiv.org/abs/2210.02093",
    "authors": [
      "Yu Quan",
      "Dong Zhang",
      "Liyan Zhang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02097",
    "title": "Teaching Yourself:c Graph Self-Distillation on Neighborhood for Node  Classification",
    "abstract": "Recent years have witnessed great success in handling graph-related tasks with Graph Neural Networks (GNNs). Despite their great academic success, Multi-Layer Perceptrons (MLPs) remain the primary workhorse for practical industrial applications. One reason for this academic-industrial gap is the neighborhood-fetching latency incurred by data dependency in GNNs, which make it hard to deploy for latency-sensitive applications that require fast inference. Conversely, without involving any feature aggregation, MLPs have no data dependency and infer much faster than GNNs, but their performance is less competitive. Motivated by these complementary strengths and weaknesses, we propose a Graph Self-Distillation on Neighborhood (GSDN) framework to reduce the gap between GNNs and MLPs. Specifically, the GSDN framework is based purely on MLPs, where structural information is only implicitly used as prior to guide knowledge self-distillation between the neighborhood and the target, substituting the explicit neighborhood information propagation as in GNNs. As a result, GSDN enjoys the benefits of graph topology-awareness in training but has no data dependency in inference. Extensive experiments have shown that the performance of vanilla MLPs can be greatly improved with self-distillation, e.g., GSDN improves over stand-alone MLPs by 15.54\\% on average and outperforms the state-of-the-art GNNs on six datasets. Regarding inference speed, GSDN infers 75X-89X faster than existing GNNs and 16X-25X faster than other inference acceleration methods. ",
    "url": "https://arxiv.org/abs/2210.02097",
    "authors": [
      "Lirong Wu",
      "Jun Xia",
      "Haitao Lin",
      "Zhangyang Gao",
      "Zicheng Liu",
      "Guojiang Zhao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02099",
    "title": "Automated Graph Self-supervised Learning via Multi-teacher Knowledge  Distillation",
    "abstract": "Self-supervised learning on graphs has recently achieved remarkable success in graph representation learning. With hundreds of self-supervised pretext tasks proposed over the past few years, the research community has greatly developed, and the key is no longer to design more powerful but complex pretext tasks, but to make more effective use of those already on hand. This paper studies the problem of how to automatically, adaptively, and dynamically learn instance-level self-supervised learning strategies for each node from a given pool of pretext tasks. In this paper, we propose a novel multi-teacher knowledge distillation framework for Automated Graph Self-Supervised Learning (AGSSL), which consists of two main branches: (i) Knowledge Extraction: training multiple teachers with different pretext tasks, so as to extract different levels of knowledge with different inductive biases; (ii) Knowledge Integration: integrating different levels of knowledge and distilling them into the student model. Without simply treating different teachers as equally important, we provide a provable theoretical guideline for how to integrate the knowledge of different teachers, i.e., the integrated teacher probability should be close to the true Bayesian class-probability. To approach the theoretical optimum in practice, two adaptive knowledge integration strategies are proposed to construct a relatively \"good\" integrated teacher. Extensive experiments on eight datasets show that AGSSL can benefit from multiple pretext tasks, outperforming the corresponding individual tasks; by combining a few simple but classical pretext tasks, the resulting performance is comparable to other leading counterparts. ",
    "url": "https://arxiv.org/abs/2210.02099",
    "authors": [
      "Lirong Wu",
      "Yufei Huang",
      "Haitao Lin",
      "Zicheng Liu",
      "Tianyu Fan",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02121",
    "title": "A spectral algorithm for finding maximum cliques in dense random  intersection graphs",
    "abstract": "In a random intersection graph $G_{n,m,p}$, each of $n$ vertices selects a random subset of a set of $m$ labels by including each label independently with probability $p$ and edges are drawn between vertices that have at least one label in common. Among other applications, such graphs have been used to model social networks, in which individuals correspond to vertices and various features (e.g. ideas, interests) correspond to labels; individuals sharing at least one common feature are connected and this is abstracted by edges in random intersection graphs. In this paper, we consider the problem of finding maximum cliques when the input graph is $G_{n,m,p}$. Current algorithms for this problem are successful with high probability only for relatively sparse instances, leaving the dense case mostly unexplored. We present a spectral algorithm for finding large cliques that processes vertices according to respective values in the second largest eigenvector of the adjacency matrix of induced subgraphs of the input graph corresponding to common neighbors of small cliques. Leveraging on the Single Label Clique Theorem from [15], we were able to construct random instances, without the need to externally plant a large clique in the input graph. In particular, we used label choices to determine the maximum clique and then concealed label information by just giving the adjacency matrix of $G_{n, m, p}$ as input to the algorithm. Our experimental evaluation showed that our spectral algorithm clearly outperforms existing polynomial time algorithms, both with respect to the failure probability and the approximation guarantee metrics, especially in the dense regime, thus suggesting that spectral properties of random intersection graphs may be also used to construct efficient algorithms for other NP-hard graph theoretical problems as well. ",
    "url": "https://arxiv.org/abs/2210.02121",
    "authors": [
      "Filippos Christodoulou",
      "Sotiris Nikoletseas",
      "Christoforos Raptopoulos",
      "Paul Spirakis"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.02143",
    "title": "Common Vulnerability Scoring System Prediction based on Open Source  Intelligence Information Sources",
    "abstract": "The number of newly published vulnerabilities is constantly increasing. Until now, the information available when a new vulnerability is published is manually assessed by experts using a Common Vulnerability Scoring System (CVSS) vector and score. This assessment is time consuming and requires expertise. Various works already try to predict CVSS vectors or scores using machine learning based on the textual descriptions of the vulnerability to enable faster assessment. However, for this purpose, previous works only use the texts available in databases such as National Vulnerability Database. With this work, the publicly available web pages referenced in the National Vulnerability Database are analyzed and made available as sources of texts through web scraping. A Deep Learning based method for predicting the CVSS vector is implemented and evaluated. The present work provides a classification of the National Vulnerability Database's reference texts based on the suitability and crawlability of their texts. While we identified the overall influence of the additional texts is negligible, we outperformed the state-of-the-art with our Deep Learning prediction models. ",
    "url": "https://arxiv.org/abs/2210.02143",
    "authors": [
      "Philipp Kuehn",
      "David N. Relke",
      "Christian Reuter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02156",
    "title": "Fine-Tuning with Differential Privacy Necessitates an Additional  Hyperparameter Search",
    "abstract": "Models need to be trained with privacy-preserving learning algorithms to prevent leakage of possibly sensitive information contained in their training data. However, canonical algorithms like differentially private stochastic gradient descent (DP-SGD) do not benefit from model scale in the same way as non-private learning. This manifests itself in the form of unappealing tradeoffs between privacy and utility (accuracy) when using DP-SGD on complex tasks. To remediate this tension, a paradigm is emerging: fine-tuning with differential privacy from a model pretrained on public (i.e., non-sensitive) training data. In this work, we identify an oversight of existing approaches for differentially private fine tuning. They do not tailor the fine-tuning approach to the specifics of learning with privacy. Our main result is to show how carefully selecting the layers being fine-tuned in the pretrained neural network allows us to establish new state-of-the-art tradeoffs between privacy and accuracy. For instance, we achieve 77.9% accuracy for $(\\varepsilon, \\delta)=(2, 10^{-5})$ on CIFAR-100 for a model pretrained on ImageNet. Our work calls for additional hyperparameter search to configure the differentially private fine-tuning procedure itself. ",
    "url": "https://arxiv.org/abs/2210.02156",
    "authors": [
      "Yannis Cattan",
      "Christopher A. Choquette-Choo",
      "Nicolas Papernot",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.02159",
    "title": "Differentiable Mathematical Programming for Object-Centric  Representation Learning",
    "abstract": "We propose topology-aware feature partitioning into $k$ disjoint partitions for given scene features as a method for object-centric representation learning. To this end, we propose to use minimum $s$-$t$ graph cuts as a partitioning method which is represented as a linear program. The method is topologically aware since it explicitly encodes neighborhood relationships in the image graph. To solve the graph cuts our solution relies on an efficient, scalable, and differentiable quadratic programming approximation. Optimizations specific to cut problems allow us to solve the quadratic programs and compute their gradients significantly more efficiently compared with the general quadratic programming approach. Our results show that our approach is scalable and outperforms existing methods on object discovery tasks with textured scenes and objects. ",
    "url": "https://arxiv.org/abs/2210.02159",
    "authors": [
      "Adeel Pervez",
      "Phillip Lippe",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02161",
    "title": "Security and Privacy Concerns in Cloud-based Scientific and Business  Workflows: A Systematic Review",
    "abstract": "Today, the number of data-intensive and compute-intensive applications like business and scientific workflows has dramatically increased, which made cloud computing more popular in the matter of delivering a large amount of computing resources on demand. On the other hand, security is a critical issue affecting the wide adoption of cloud technologies, especially for workflows that are mostly dealing with sensitive data and tasks. In this paper, we carry out a review of the state-of-the-art on how security and privacy concerns in scientific and business workflows in cloud environments are being addressed and identify the limitations and gaps in the current body of knowledge in this area. In this extensive literature review, we first present a classification of the state-of-the-art security solutions organized according to the phases of the workflow life cycle they target. Based on our findings, we provide a detailed review and classification of the most relevant available literature focusing on the execution, monitoring, and adaptation phases of workflows. Finally, we present a list of open research issues related to the security of cloud-based workflows and discuss them. ",
    "url": "https://arxiv.org/abs/2210.02161",
    "authors": [
      "Nafiseh Soveizi",
      "Fatih Turkmen",
      "Dimka Karastoyanova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.02166",
    "title": "Generalized Moving Horizon Estimation for Nonlinear Systems with  Robustness to Measurement Outliers",
    "abstract": "Moving horizon estimation (MHE) is an effective filtering technique for dynamic systems. While there has been noticeable progress in the stability analysis of MHE, there is lack of research on robustifying MHE against measurement outliers. To bridge this gap, we propose a generalized MHE approach by utilizing the loss-theoretic perspective of Generalized Bayesian Inference. In particular, we design a robust loss function by leveraging the \\{beta}-divergence and propose the \\{beta} moving horizon estimator to handle the outliers. Analytical influence functions are derived to analyze the robustness of the MHE methods. Based on this, we prove that for the case of linear Gaussian systems, the gross error sensitivity of the proposed estimator remains bounded, while for the standard MHE, it is unbounded. The effectiveness of the proposed approach is demonstrated in simulations on both linear and nonlinear systems. ",
    "url": "https://arxiv.org/abs/2210.02166",
    "authors": [
      "Wenhan Cao",
      "Chang Liu",
      "Zhiqian Lan",
      "Yingxi Piao",
      "Shengbo Eben Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.02168",
    "title": "Bayesian Quadrature for Probability Threshold Robustness of Partially  Undefined Functions",
    "abstract": "In engineering design, one often wishes to calculate the probability that the performance of a system is satisfactory under uncertainty. State of the art algorithms exist to solve this problem using active learning with Gaussian process models. However, these algorithms cannot be applied to problems which often occur in the autonomous vehicle domain where the performance of a system may be undefined under certain circumstances. Na\\\"ive modification of existing algorithms by simply masking undefined values will introduce a discontinuous system performance function, and would be unsuccessful because these algorithms are known to fail for discontinuous performance functions. We solve this problem using a hierarchical model for the system performance, where undefined performance is classified before the performance is regressed. This enables active learning Gaussian process methods to be applied to problems where the performance of the system is sometimes undefined, and we demonstrate this by testing our methodology on synthetic numerical examples for the autonomous driving domain. ",
    "url": "https://arxiv.org/abs/2210.02168",
    "authors": [
      "Jonathan Sadeghi",
      "Romain Mueller",
      "John Redford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02191",
    "title": "On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks",
    "abstract": "In many applications with real-world consequences, it is crucial to develop reliable uncertainty estimation for the predictions made by the AI decision systems. Targeting at the goal of estimating uncertainty, various deep neural network (DNN) based uncertainty estimation algorithms have been proposed. However, the robustness of the uncertainty returned by these algorithms has not been systematically explored. In this work, to raise the awareness of the research community on robust uncertainty estimation, we show that state-of-the-art uncertainty estimation algorithms could fail catastrophically under our proposed adversarial attack despite their impressive performance on uncertainty estimation. In particular, we aim at attacking the out-domain uncertainty estimation: under our attack, the uncertainty model would be fooled to make high-confident predictions for the out-domain data, which they originally would have rejected. Extensive experimental results on various benchmark image datasets show that the uncertainty estimated by state-of-the-art methods could be easily corrupted by our attack. ",
    "url": "https://arxiv.org/abs/2210.02191",
    "authors": [
      "Huimin Zeng",
      "Zhenrui Yue",
      "Yang Zhang",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02192",
    "title": "Are All Losses Created Equal: A Neural Collapse Perspective",
    "abstract": "While cross entropy (CE) is the most commonly used loss to train deep neural networks for classification tasks, many alternative losses have been developed to obtain better empirical performance. Among them, which one is the best to use is still a mystery, because there seem to be multiple factors affecting the answer, such as properties of the dataset, the choice of network architecture, and so on. This paper studies the choice of loss function by examining the last-layer features of deep networks, drawing inspiration from a recent line work showing that the global optimal solution of CE and mean-square-error (MSE) losses exhibits a Neural Collapse phenomenon. That is, for sufficiently large networks trained until convergence, (i) all features of the same class collapse to the corresponding class mean and (ii) the means associated with different classes are in a configuration where their pairwise distances are all equal and maximized. We extend such results and show through global solution and landscape analyses that a broad family of loss functions including commonly used label smoothing (LS) and focal loss (FL) exhibits Neural Collapse. Hence, all relevant losses(i.e., CE, LS, FL, MSE) produce equivalent features on training data. Based on the unconstrained feature model assumption, we provide either the global landscape analysis for LS loss or the local landscape analysis for FL loss and show that the (only!) global minimizers are neural collapse solutions, while all other critical points are strict saddles whose Hessian exhibit negative curvature directions either in the global scope for LS loss or in the local scope for FL loss near the optimal solution. The experiments further show that Neural Collapse features obtained from all relevant losses lead to largely identical performance on test data as well, provided that the network is sufficiently large and trained until convergence. ",
    "url": "https://arxiv.org/abs/2210.02192",
    "authors": [
      "Jinxin Zhou",
      "Chong You",
      "Xiao Li",
      "Kangning Liu",
      "Sheng Liu",
      "Qing Qu",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02202",
    "title": "A new family of Constitutive Artificial Neural Networks towards  automated model discovery",
    "abstract": "For more than 100 years, chemical, physical, and material scientists have proposed competing constitutive models to best characterize the behavior of natural and man-made materials in response to mechanical loading. Now, computer science offers a universal solution: Neural Networks. Neural Networks are powerful function approximators that can learn constitutive relations from large data without any knowledge of the underlying physics. However, classical Neural Networks entirely ignore a century of research in constitutive modeling, violate thermodynamic considerations, and fail to predict the behavior outside the training regime. Here we design a new family of Constitutive Artificial Neural Networks that inherently satisfy common kinematic, thermodynamic, and physic constraints and, at the same time, constrain the design space of admissible functions to create robust approximators, even in the presence of sparse data. Towards this goal we revisit the non-linear field theories of mechanics and reverse-engineer the network input to account for material objectivity, symmetry, and incompressibility; the network output to enforce thermodynamic consistency; the activation functions to implement physically reasonable restrictions; and the network architecture to ensure polyconvexity. We demonstrate that this new class of models is a generalization of the classical neo Hooke, Blatz Ko, Mooney Rivlin, Yeoh, and Demiray models and that the network weights have a clear physical interpretation. When trained with classical benchmark data for rubber under uniaxial tension, biaxial extension, and pure shear, our network autonomously selects the best constitutive model and learns its set of parameters. Our findings suggests that Constitutive Artificial Neural Networks have the potential to induce a paradigm shift in constitutive modeling, from user-defined model selection to automated model discovery. ",
    "url": "https://arxiv.org/abs/2210.02202",
    "authors": [
      "Kevin Linka",
      "Ellen Kuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2210.02206",
    "title": "Improving Visual-Semantic Embedding with Adaptive Pooling and  Optimization Objective",
    "abstract": "Visual-Semantic Embedding (VSE) aims to learn an embedding space where related visual and semantic instances are close to each other. Recent VSE models tend to design complex structures to pool visual and semantic features into fixed-length vectors and use hard triplet loss for optimization. However, we find that: (1) combining simple pooling methods is no worse than these sophisticated methods; and (2) only considering the most difficult-to-distinguish negative sample leads to slow convergence and poor Recall@K improvement. To this end, we propose an adaptive pooling strategy that allows the model to learn how to aggregate features through a combination of simple pooling methods. We also introduce a strategy to dynamically select a group of negative samples to make the optimization converge faster and perform better. Experimental results on Flickr30K and MS-COCO demonstrate that a standard VSE using our pooling and optimization strategies outperforms current state-of-the-art systems (at least 1.0% on the metrics of recall) in image-to-text and text-to-image retrieval. Source code of our experiments is available at https://github.com/96-Zachary/vse_2ad. ",
    "url": "https://arxiv.org/abs/2210.02206",
    "authors": [
      "Zijian Zhang",
      "Chang Shu",
      "Ya Xiao",
      "Yuan Shen",
      "Di Zhu",
      "Jing Xiao",
      "Youxin Chen",
      "Jey Han Lau",
      "Qian Zhang",
      "Zheng Lu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.02215",
    "title": "On the Statistical Complexity of Estimation and Testing under Privacy  Constraints",
    "abstract": "Producing statistics that respect the privacy of the samples while still maintaining their accuracy is an important topic of research. We study minimax lower bounds when the class of estimators is restricted to the differentially private ones. In particular, we show that characterizing the power of a distributional test under differential privacy can be done by solving a transport problem. With specific coupling constructions, this observation allows us to derivate Le Cam-type and Fano-type inequalities for both regular definitions of differential privacy and for divergence-based ones (based on Renyi divergence). We then proceed to illustrate our results on three simple, fully worked out examples. In particular, we show that the problem class has a huge importance on the provable degradation of utility due to privacy. For some problems, privacy leads to a provable degradation only when the rate of the privacy parameters is small enough whereas for other problem, the degradation systematically occurs under much looser hypotheses on the privacy parametters. Finally, we show that the known privacy guarantees of DP-SGLD, a private convex solver, when used to perform maximum likelihood, leads to an algorithm that is near-minimax optimal in both the sample size and the privacy tuning parameters of the problem for a broad class of parametric estimation procedures that includes exponential families. ",
    "url": "https://arxiv.org/abs/2210.02215",
    "authors": [
      "Cl\u00e9ment Lalanne",
      "Aur\u00e9lien Garivier",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.02224",
    "title": "Neural Distillation as a State Representation Bottleneck in  Reinforcement Learning",
    "abstract": "Learning a good state representation is a critical skill when dealing with multiple tasks in Reinforcement Learning as it allows for transfer and better generalization between tasks. However, defining what constitute a useful representation is far from simple and there is so far no standard method to find such an encoding. In this paper, we argue that distillation -- a process that aims at imitating a set of given policies with a single neural network -- can be used to learn a state representation displaying favorable characteristics. In this regard, we define three criteria that measure desirable features of a state encoding: the ability to select important variables in the input space, the ability to efficiently separate states according to their corresponding optimal action, and the robustness of the state encoding on new tasks. We first evaluate these criteria and verify the contribution of distillation on state representation on a toy environment based on the standard inverted pendulum problem, before extending our analysis on more complex visual tasks from the Atari and Procgen benchmarks. ",
    "url": "https://arxiv.org/abs/2210.02224",
    "authors": [
      "Valentin Guillet",
      "Dennis G. Wilson",
      "Carlos Aguilar-Melchor",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02227",
    "title": "Comprint: Image Forgery Detection and Localization using Compression  Fingerprints",
    "abstract": "Manipulation tools that realistically edit images are widely available, making it easy for anyone to create and spread misinformation. In an attempt to fight fake news, forgery detection and localization methods were designed. However, existing methods struggle to accurately reveal manipulations found in images on the internet, i.e., in the wild. That is because the type of forgery is typically unknown, in addition to the tampering traces being damaged by recompression. This paper presents Comprint, a novel forgery detection and localization method based on the compression fingerprint or comprint. It is trained on pristine data only, providing generalization to detect different types of manipulation. Additionally, we propose a fusion of Comprint with the state-of-the-art Noiseprint, which utilizes a complementary camera model fingerprint. We carry out an extensive experimental analysis and demonstrate that Comprint has a high level of accuracy on five evaluation datasets that represent a wide range of manipulation types, mimicking in-the-wild circumstances. Most notably, the proposed fusion significantly outperforms state-of-the-art reference methods. As such, Comprint and the fusion Comprint+Noiseprint represent a promising forensics tool to analyze in-the-wild tampered images. ",
    "url": "https://arxiv.org/abs/2210.02227",
    "authors": [
      "Hannes Mareen",
      "Dante Vanden Bussche",
      "Fabrizio Guillaro",
      "Davide Cozzolino",
      "Glenn Van Wallendael",
      "Peter Lambert",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.02234",
    "title": "Thermal (and Hybrid Thermal/Audio) Side-Channel Attacks on Keyboard  Input",
    "abstract": "To date, there has been no systematic investigation of thermal profiles of keyboards, and thus no efforts have been made to secure them. This serves as our main motivation for constructing a means for password harvesting from keyboard thermal emanations. Specifically, we introduce Thermanator: a new post-factum insider attack based on heat transfer caused by a user typing a password on a typical external (plastic) keyboard. We conduct and describe a user study that collected thermal residues from 30 users entering 10 unique passwords (both weak and strong) on 4 popular commodity keyboards. Results show that entire sets of key-presses can be recovered by non-expert users as late as 30 seconds after initial password entry, while partial sets can be recovered as late as 1 minute after entry. However, the thermal residue side-channel lacks information about password length, duplicate key-presses, and key-press ordering. To overcome these limitations, we leverage keyboard acoustic emanations and combine the two to yield AcuTherm, the first hybrid side-channel attack on keyboards. AcuTherm significantly reduces password search without the need for any training on the victim's typing. We report results gathered for many representative passwords based on a user study involving 19 subjects. The takeaway of this work is three-fold: (1) using plastic keyboards to enter secrets (such as passwords and PINs) is even less secure than previously recognized, (2) post-factum thermal imaging attacks are realistic, and (3) hybrid (multiple side-channel) attacks are both realistic and effective. ",
    "url": "https://arxiv.org/abs/2210.02234",
    "authors": [
      "Tyler Kaczmarek",
      "Ercan Ozturk",
      "Pier Paolo Tricomi",
      "Gene Tsudik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02235",
    "title": "Over-the-Air Federated Learning with Privacy Protection via Correlated  Additive Perturbations",
    "abstract": "In this paper, we consider privacy aspects of wireless federated learning (FL) with Over-the-Air (OtA) transmission of gradient updates from multiple users/agents to an edge server. By exploiting the waveform superposition property of multiple access channels, OtA FL enables the users to transmit their updates simultaneously with linear processing techniques, which improves resource efficiency. However, this setting is vulnerable to privacy leakage since an adversary node can hear directly the uncoded message. Traditional perturbation-based methods provide privacy protection while sacrificing the training accuracy due to the reduced signal-to-noise ratio. In this work, we aim at minimizing privacy leakage to the adversary and the degradation of model accuracy at the edge server at the same time. More explicitly, spatially correlated perturbations are added to the gradient vectors at the users before transmission. Using the zero-sum property of the correlated perturbations, the side effect of the added perturbation on the aggregated gradients at the edge server can be minimized. In the meanwhile, the added perturbation will not be canceled out at the adversary, which prevents privacy leakage. Theoretical analysis of the perturbation covariance matrix, differential privacy, and model convergence is provided, based on which an optimization problem is formulated to jointly design the covariance matrix and the power scaling factor to balance between privacy protection and convergence performance. Simulation results validate the correlated perturbation approach can provide strong defense ability while guaranteeing high learning accuracy. ",
    "url": "https://arxiv.org/abs/2210.02235",
    "authors": [
      "Jialing Liao",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.02236",
    "title": "On the Use of Deep Learning in Software Defect Prediction",
    "abstract": "Context: Automated software defect prediction (SDP) methods are increasingly applied, often with the use of machine learning (ML) techniques. Yet, the existing ML-based approaches require manually extracted features, which are cumbersome, time consuming and hardly capture the semantic information reported in bug reporting tools. Deep learning (DL) techniques provide practitioners with the opportunities to automatically extract and learn from more complex and high-dimensional data. Objective: The purpose of this study is to systematically identify, analyze, summarize, and synthesize the current state of the utilization of DL algorithms for SDP in the literature. Method: We systematically selected a pool of 102 peer-reviewed studies and then conducted a quantitative and qualitative analysis using the data extracted from these studies. Results: Main highlights include: (1) most studies applied supervised DL; (2) two third of the studies used metrics as an input to DL algorithms; (3) Convolutional Neural Network is the most frequently used DL algorithm. Conclusion: Based on our findings, we propose to (1) develop more comprehensive DL approaches that automatically capture the needed features; (2) use diverse software artifacts other than source code; (3) adopt data augmentation techniques to tackle the class imbalance problem; (4) publish replication packages. ",
    "url": "https://arxiv.org/abs/2210.02236",
    "authors": [
      "G\u00f6rkem Giray",
      "Kwabena Ebo Bennin",
      "\u00d6mer K\u00f6ksal",
      "\u00d6nder Babur",
      "Bedir Tekinerdogan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.02240",
    "title": "On Neural Consolidation for Transfer in Reinforcement Learning",
    "abstract": "Although transfer learning is considered to be a milestone in deep reinforcement learning, the mechanisms behind it are still poorly understood. In particular, predicting if knowledge can be transferred between two given tasks is still an unresolved problem. In this work, we explore the use of network distillation as a feature extraction method to better understand the context in which transfer can occur. Notably, we show that distillation does not prevent knowledge transfer, including when transferring from multiple tasks to a new one, and we compare these results with transfer without prior distillation. We focus our work on the Atari benchmark due to the variability between different games, but also to their similarities in terms of visual features. ",
    "url": "https://arxiv.org/abs/2210.02240",
    "authors": [
      "Valentin Guillet",
      "Dennis G. Wilson",
      "Carlos Aguilar-Melchor",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.02248",
    "title": "Crowding out the truth? A simple model of misinformation, polarization  and meaningful social interactions",
    "abstract": "This paper provides a simple theoretical framework to evaluate the effect of key parameters of ranking algorithms, namely popularity and personalization parameters, on measures of platform engagement, misinformation and polarization. The results show that an increase in the weight assigned to online social interactions (e.g., likes and shares) and to personalized content may increase engagement on the social media platform, while at the same time increasing misinformation and/or polarization. By exploiting Facebook's 2018 \"Meaningful Social Interactions\" algorithmic ranking update, we also provide direct empirical support for some of the main predictions of the model. ",
    "url": "https://arxiv.org/abs/2210.02248",
    "authors": [
      "Fabrizio Germano",
      "Vicen\u00e7 G\u00f3mez",
      "Francesco Sobbrio"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.02289",
    "title": "Coverage and Capacity of Joint Communication and Sensing in Wireless  Networks",
    "abstract": "From an information theoretic perspective, joint communication and sensing (JCAS) represents a natural generalization of communication network functionality. However, it requires the reevaluation of network performance from a multi-objective perspective. We develop a novel mathematical framework for characterizing the sensing and communication coverage probability and ergodic capacity in JCAS networks. We employ an information theoretic formulation of radar tracking to extend the notions of coverage probability and ergodic capacity to the radar setting. Using this framework, we analyze the downlink sensing and communication coverage and capacity of a JCAS network employing a shared multicarrier waveform and analog beamforming. Leveraging tools from stochastic geometry, we derive upper and lower bounds for these quantities. We also develop several general technical results including: i) a method for obtaining closed form bounds on the Laplace Transform of a shot noise process, ii) an analog of H\\\"older's Inequality to the setting of harmonic means, and iii) a relation between the Laplace and Mellin Transforms of a non-negative random variable. We use the derived bounds to investigate the performance of JCAS networks under varying base station and blockage density. Among several insights, our analysis indicates that network densification improves sensing performance - in contrast to communications. ",
    "url": "https://arxiv.org/abs/2210.02289",
    "authors": [
      "Nicholas R. Olson",
      "Jeffrey G. Andrews",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.02299",
    "title": "SHINE-Mapping: Large-Scale 3D Mapping Using Sparse Hierarchical Implicit  Neural Representations",
    "abstract": "Accurate mapping of large-scale environments is an essential building block of most outdoor autonomous systems. Challenges of traditional mapping methods include the balance between memory consumption and mapping accuracy. This paper addresses the problems of achieving large-scale 3D reconstructions with implicit representations using 3D LiDAR measurements. We learn and store implicit features through an octree-based hierarchical structure, which is sparse and extensible. The features can be turned into signed distance values through a shallow neural network. We leverage binary cross entropy loss to optimize the local features with the 3D measurements as supervision. Based on our implicit representation, we design an incremental mapping system with regularization to tackle the issue of catastrophic forgetting in continual learning. Our experiments show that our 3D reconstructions are more accurate, complete, and memory-efficient than current state-of-the-art 3D mapping methods. ",
    "url": "https://arxiv.org/abs/2210.02299",
    "authors": [
      "Xingguang Zhong",
      "Yue Pan",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.02302",
    "title": "GLAD: Grounded Layered Autonomous Driving for Complex Service Tasks",
    "abstract": "Given the current point-to-point navigation capabilities of autonomous vehicles, researchers are looking into complex service requests that require the vehicles to visit multiple points of interest. In this paper, we develop a layered planning framework, called GLAD, for complex service requests in autonomous urban driving. There are three layers for service-level, behavior-level, and motion-level planning. The layered framework is unique in its tight coupling, where the different layers communicate user preferences, safety estimates, and motion costs for system optimization. GLAD is visually grounded by perceptual learning from a dataset of 13.8k instances collected from driving behaviors. GLAD enables autonomous vehicles to efficiently and safely fulfill complex service requests. Experimental results from abstract and full simulation show that our system outperforms a few competitive baselines from the literature. ",
    "url": "https://arxiv.org/abs/2210.02302",
    "authors": [
      "Yan Ding",
      "Cheng Cui",
      "Xiaohan Zhang",
      "Shiqi Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.02330",
    "title": "Revisiting Graph Contrastive Learning from the Perspective of Graph  Spectrum",
    "abstract": "Graph Contrastive Learning (GCL), learning the node representations by augmenting graphs, has attracted considerable attentions. Despite the proliferation of various graph augmentation strategies, some fundamental questions still remain unclear: what information is essentially encoded into the learned representations by GCL? Are there some general graph augmentation rules behind different augmentations? If so, what are they and what insights can they bring? In this paper, we answer these questions by establishing the connection between GCL and graph spectrum. By an experimental investigation in spectral domain, we firstly find the General grAph augMEntation (GAME) rule for GCL, i.e., the difference of the high-frequency parts between two augmented graphs should be larger than that of low-frequency parts. This rule reveals the fundamental principle to revisit the current graph augmentations and design new effective graph augmentations. Then we theoretically prove that GCL is able to learn the invariance information by contrastive invariance theorem, together with our GAME rule, for the first time, we uncover that the learned representations by GCL essentially encode the low-frequency information, which explains why GCL works. Guided by this rule, we propose a spectral graph contrastive learning module (SpCo), which is a general and GCL-friendly plug-in. We combine it with different existing GCL models, and extensive experiments well demonstrate that it can further improve the performances of a wide variety of different GCL methods. ",
    "url": "https://arxiv.org/abs/2210.02330",
    "authors": [
      "Nian Liu",
      "Xiao Wang",
      "Deyu Bo",
      "Chuan Shi",
      "Jian Pei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02357",
    "title": "Image Masking for Robust Self-Supervised Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation is a salient task for 3D scene understanding. Learned jointly with monocular ego-motion estimation, several methods have been proposed to predict accurate pixel-wise depth without using labeled data. Nevertheless, these methods focus on improving performance under ideal conditions without natural or digital corruptions. A general absence of occlusions is assumed even for object-specific depth estimation. These methods are also vulnerable to adversarial attacks, which is a pertinent concern for their reliable deployment on robots and autonomous driving systems. We propose MIMDepth, a method that adapts masked image modeling (MIM) for self-supervised monocular depth estimation. While MIM has been used to learn generalizable features during pre-training, we show how it could be adapted for direct training of monocular depth estimation. Our experiments show that MIMDepth is more robust to noise, blur, weather conditions, digital artifacts, occlusions, as well as untargeted and targeted adversarial attacks. ",
    "url": "https://arxiv.org/abs/2210.02357",
    "authors": [
      "Hemang Chawla",
      "Kishaan Jeeveswaran",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02368",
    "title": "Spatio-Temporal Learnable Proposals for End-to-End Video Object  Detection",
    "abstract": "This paper presents the novel idea of generating object proposals by leveraging temporal information for video object detection. The feature aggregation in modern region-based video object detectors heavily relies on learned proposals generated from a single-frame RPN. This imminently introduces additional components like NMS and produces unreliable proposals on low-quality frames. To tackle these restrictions, we present SparseVOD, a novel video object detection pipeline that employs Sparse R-CNN to exploit temporal information. In particular, we introduce two modules in the dynamic head of Sparse R-CNN. First, the Temporal Feature Extraction module based on the Temporal RoI Align operation is added to extract the RoI proposal features. Second, motivated by sequence-level semantic aggregation, we incorporate the attention-guided Semantic Proposal Feature Aggregation module to enhance object feature representation before detection. The proposed SparseVOD effectively alleviates the overhead of complicated post-processing methods and makes the overall pipeline end-to-end trainable. Extensive experiments show that our method significantly improves the single-frame Sparse RCNN by 8%-9% in mAP. Furthermore, besides achieving state-of-the-art 80.3% mAP on the ImageNet VID dataset with ResNet-50 backbone, our SparseVOD outperforms existing proposal-based methods by a significant margin on increasing IoU thresholds (IoU > 0.5). ",
    "url": "https://arxiv.org/abs/2210.02368",
    "authors": [
      "Khurram Azeem Hashmi",
      "Didier Stricker",
      "Muhammamd Zeshan Afzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02373",
    "title": "Dynamical systems' based neural networks",
    "abstract": "Neural networks have gained much interest because of their effectiveness in many applications. However, their mathematical properties are generally not well understood. If there is some underlying geometric structure inherent to the data or to the function to approximate, it is often desirable to take this into account in the design of the neural network. In this work, we start with a non-autonomous ODE and build neural networks using a suitable, structure-preserving, numerical time-discretisation. The structure of the neural network is then inferred from the properties of the ODE vector field. Besides injecting more structure into the network architectures, this modelling procedure allows a better theoretical understanding of their behaviour. We present two universal approximation results and demonstrate how to impose some particular properties on the neural networks. A particular focus is on 1-Lipschitz architectures including layers that are not 1-Lipschitz. These networks are expressive and robust against adversarial attacks, as shown for the CIFAR-10 dataset. ",
    "url": "https://arxiv.org/abs/2210.02373",
    "authors": [
      "Elena Celledoni",
      "Davide Murari",
      "Brynjulf Owren",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Ferdia Sherry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.02374",
    "title": "Axon: A Language for Dynamic Shapes in Deep Learning Graphs",
    "abstract": "Axon is a language that enables shape and rank inference for tensors in a Deep Learning graphs. It aims to make shapes implicit and inferred, in a similar manner to how types are implicit and inferred in many functional programming languages. Tensor dimensions are represented by expressions consisting of symbolic variables, constants, and arithmetic operators. Tensor shapes can be expressed as either a sequence of these dimension expressions, as a symbolic variable, or as an appending of other shapes. This allows complex constraints on shapes to be expressed. Axon is functional in style, with a type system similar in to Standard ML, extended to include shape information. It provides a suite of built in operators over tensors, including pointwise arithmetic operators, maps, reduction, loops and user defined functions. We describe a shape inference algorithm based on constraint solving which infers information about shapes, from both shape information provided by the programmer and the structure of the program. This allows fully automatic inference of the shapes of tensors for complex Deep Learning graphs. This approach reduces programmer effort when specifying graphs, as tensor shapes are not explicit, allows composition of Deep Learning graphs while maintaining input and output tensor shape compatibility, and aids in automated error detection by identifying shape mismatches at runtime. ",
    "url": "https://arxiv.org/abs/2210.02374",
    "authors": [
      "Alexander Collins",
      "Vinod Grover"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.02382",
    "title": "NeuralMeshing: Differentiable Meshing of Implicit Neural Representations",
    "abstract": "The generation of triangle meshes from point clouds, i.e. meshing, is a core task in computer graphics and computer vision. Traditional techniques directly construct a surface mesh using local decision heuristics, while some recent methods based on neural implicit representations try to leverage data-driven approaches for this meshing process. However, it is challenging to define a learnable representation for triangle meshes of unknown topology and size and for this reason, neural implicit representations rely on non-differentiable post-processing in order to extract the final triangle mesh. In this work, we propose a novel differentiable meshing algorithm for extracting surface meshes from neural implicit representations. Our method produces the mesh in an iterative fashion, which makes it applicable to shapes of various scales and adaptive to the local curvature of the shape. Furthermore, our method produces meshes with regular tessellation patterns and fewer triangle faces compared to existing methods. Experiments demonstrate the comparable reconstruction performance and favorable mesh properties over baselines. ",
    "url": "https://arxiv.org/abs/2210.02382",
    "authors": [
      "Mathias Vetsch",
      "Sandro Lombardi",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02394",
    "title": "Social Balance on Networks: Local Minima and Best Edge Dynamics",
    "abstract": "Structural balance theory is an established framework for studying social relationships of friendship and enmity. These relationships are modeled by a signed network whose energy potential measures the level of imbalance, while stochastic dynamics drives the network towards a state of minimum energy that captures social balance. It is known that this energy landscape has local minima that can trap socially-aware dynamics, preventing it from reaching balance. Here we first study the robustness and attractor properties of these local minima. We show that a stochastic process can reach them from an abundance of initial states, and that some local minima cannot be escaped by mild perturbations of the network. Motivated by these anomalies, we introduce Best Edge Dynamics (BED), a new plausible stochastic process. We prove that BED always reaches balance, and that it does so fast in various interesting settings. ",
    "url": "https://arxiv.org/abs/2210.02394",
    "authors": [
      "Krishnendu Chatterjee",
      "Jakub Svoboda",
      "\u00d0or\u0111e \u017dikeli\u0107",
      "Andreas Pavlogiannis",
      "Josef Tkadlec"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.02396",
    "title": "Temporally Consistent Video Transformer for Long-Term Video Prediction",
    "abstract": "Generating long, temporally consistent video remains an open challenge in video generation. Primarily due to computational limitations, most prior methods limit themselves to training on a small subset of frames that are then extended to generate longer videos through a sliding window fashion. Although these techniques may produce sharp videos, they have difficulty retaining long-term temporal consistency due to their limited context length. In this work, we present Temporally Consistent Video Transformer (TECO), a vector-quantized latent dynamics video prediction model that learns compressed representations to efficiently condition on long videos of hundreds of frames during both training and generation. We use a MaskGit prior for dynamics prediction which enables both sharper and faster generations compared to prior work. Our experiments show that TECO outperforms SOTA baselines in a variety of video prediction benchmarks ranging from simple mazes in DMLab, large 3D worlds in Minecraft, and complex real-world videos from Kinetics-600. In addition, to better understand the capabilities of video prediction models in modeling temporal consistency, we introduce several challenging video prediction tasks consisting of agents randomly traversing 3D scenes of varying difficulty. This presents a challenging benchmark for video prediction in partially observable environments where a model must understand what parts of the scenes to re-create versus invent depending on its past observations or generations. Generated videos are available at https://wilson1yan.github.io/teco ",
    "url": "https://arxiv.org/abs/2210.02396",
    "authors": [
      "Wilson Yan",
      "Danijar Hafner",
      "Stephen James",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02406",
    "title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks",
    "abstract": "Few-shot prompting is a surprisingly powerful way to use Large Language Models (LLMs) to solve various tasks. However, this approach struggles as the task complexity increases or when the individual reasoning steps of the task themselves are hard to learn, especially when embedded in more complex tasks. To address this, we propose Decomposed Prompting, a new approach to solve complex tasks by decomposing them (via prompting) into simpler sub-tasks that can be delegated to a library of prompting-based LLMs dedicated to these sub-tasks. This modular structure allows each prompt to be optimized for its specific sub-task, further decomposed if necessary, and even easily replaced with more effective prompts, trained models, or symbolic functions if desired. We show that the flexibility and modularity of Decomposed Prompting allows it to outperform prior work on few-shot prompting using GPT3. On symbolic reasoning tasks, we can further decompose sub-tasks that are hard for LLMs into even simpler solvable sub-tasks. When the complexity comes from the input length, we can recursively decompose the task into the same task but with smaller inputs. We also evaluate our approach on textual multi-step reasoning tasks: on long-context multi-hop QA task, we can more effectively teach the sub-tasks via our separate sub-tasks prompts; and on open-domain multi-hop QA, we can incorporate a symbolic information retrieval within our decomposition framework, leading to improved performance on both tasks. ",
    "url": "https://arxiv.org/abs/2210.02406",
    "authors": [
      "Tushar Khot",
      "Harsh Trivedi",
      "Matthew Finlayson",
      "Yao Fu",
      "Kyle Richardson",
      "Peter Clark",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.02411",
    "title": "Dynamical Isometry for Residual Networks",
    "abstract": "The training success, training speed and generalization ability of neural networks rely crucially on the choice of random parameter initialization. It has been shown for multiple architectures that initial dynamical isometry is particularly advantageous. Known initialization schemes for residual blocks, however, miss this property and suffer from degrading separability of different inputs for increasing depth and instability without Batch Normalization or lack feature diversity. We propose a random initialization scheme, RISOTTO, that achieves perfect dynamical isometry for residual networks with ReLU activation functions even for finite depth and width. It balances the contributions of the residual and skip branches unlike other schemes, which initially bias towards the skip connections. In experiments, we demonstrate that in most cases our approach outperforms initialization schemes proposed to make Batch Normalization obsolete, including Fixup and SkipInit, and facilitates stable training. Also in combination with Batch Normalization, we find that RISOTTO often achieves the overall best result. ",
    "url": "https://arxiv.org/abs/2210.02411",
    "authors": [
      "Advait Gadhikar",
      "Rebekka Burkholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02437",
    "title": "ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild",
    "abstract": "Benchmarking initiatives support the meaningful comparison of competing solutions to prominent problems in speech and language processing. Successive benchmarking evaluations typically reflect a progressive evolution from ideal lab conditions towards to those encountered in the wild. ASVspoof, the spoofing and deepfake detection initiative and challenge series, has followed the same trend. This article provides a summary of the ASVspoof 2021 challenge and the results of 37 participating teams. For the logical access task, results indicate that countermeasures solutions are robust to newly introduced encoding and transmission effects. Results for the physical access task indicate the potential to detect replay attacks in real, as opposed to simulated physical spaces, but a lack of robustness to variations between simulated and real acoustic environments. The DF task, new to the 2021 edition, targets solutions to the detection of manipulated, compressed speech data posted online. While detection solutions offer some resilience to compression effects, they lack generalization across different source datasets. In addition to a summary of the top-performing systems for each task, new analyses of influential data factors and results for hidden data subsets, the article includes a review of post-challenge results, an outline of the principal challenge limitations and a road-map for the future of ASVspoof. Link to the ASVspoof challenge and related resources: https://www.asvspoof.org/index2021.html ",
    "url": "https://arxiv.org/abs/2210.02437",
    "authors": [
      "Xuechen Liu",
      "Xin Wang",
      "Md Sahidullah",
      "Jose Patino",
      "H\u00e9ctor Delgado",
      "Tomi Kinnunen",
      "Massimiliano Todisco",
      "Junichi Yamagishi",
      "Nicholas Evans",
      "Andreas Nautsch",
      "Kong Aik Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.02443",
    "title": "Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D  Object Detection",
    "abstract": "While recent camera-only 3D detection methods leverage multiple timesteps, the limited history they use significantly hampers the extent to which temporal fusion can improve object perception. Observing that existing works' fusion of multi-frame images are instances of temporal stereo matching, we find that performance is hindered by the interplay between 1) the low granularity of matching resolution and 2) the sub-optimal multi-view setup produced by limited history usage. Our theoretical and empirical analysis demonstrates that the optimal temporal difference between views varies significantly for different pixels and depths, making it necessary to fuse many timesteps over long-term history. Building on our investigation, we propose to generate a cost volume from a long history of image observations, compensating for the coarse but efficient matching resolution with a more optimal multi-view matching setup. Further, we augment the per-frame monocular depth predictions used for long-term, coarse matching with short-term, fine-grained matching and find that long and short term temporal fusion are highly complementary. While maintaining high efficiency, our framework sets new state-of-the-art on nuScenes, achieving first place on the test set and outperforming previous best art by 5.2% mAP and 3.7% NDS on the validation set. Code will be released $\\href{https://github.com/Divadi/SOLOFusion}{here.}$ ",
    "url": "https://arxiv.org/abs/2210.02443",
    "authors": [
      "Jinhyung Park",
      "Chenfeng Xu",
      "Shijia Yang",
      "Kurt Keutzer",
      "Kris Kitani",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01341",
    "title": "Safe and Stable Control Synthesis for Uncertain System Models via  Distributionally Robust Optimization",
    "abstract": "This paper considers enforcing safety and stability of dynamical systems in the presence of model uncertainty. Safety and stability constraints may be specified using a control barrier function (CBF) and a control Lyapunov function (CLF), respectively. To take model uncertainty into account, robust and chance formulations of the constraints are commonly considered. However, this requires known error bounds or a known distribution for the model uncertainty, and the resulting formulations may suffer from over-conservatism or over-confidence. In this paper, we assume that only a finite set of model parametric uncertainty samples is available and formulate a distributionally robust chance-constrained program (DRCCP) for control synthesis with CBF safety and CLF stability guarantees. To enable the efficient computation of control inputs during online execution, we provide a reformulation of the DRCCP as a second-order cone program (SOCP). Our formulation is evaluated in an adaptive cruise control example in comparison to 1) a baseline CLF-CBF quadratic programming approach, 2) a robust approach that assumes known error bounds of the system uncertainty, and 3) a chance-constrained approach that assumes a known Gaussian Process distribution of the uncertainty. ",
    "url": "https://arxiv.org/abs/2210.01341",
    "authors": [
      "Kehan Long",
      "Yinzhuang Yi",
      "Jorge Cortes",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.01806",
    "title": "Low-Light Image Restoration Based on Retina Model using Neural Networks",
    "abstract": "We report the possibility of using a simple neural network for effortless restoration of low-light images inspired by the retina model, which mimics the neurophysiological principles and dynamics of various types of optical neurons. The proposed neural network model saves the cost of computational overhead in contrast with traditional signal-processing models, and generates results comparable with complicated deep learning models from the subjective perceptual perspective. This work shows that to directly simulate the functionalities of retinal neurons using neural networks not only avoids the manually seeking for the optimal parameters, but also paves the way to build corresponding artificial versions for certain neurobiological organizations. ",
    "url": "https://arxiv.org/abs/2210.01806",
    "authors": [
      "Yurui Ming",
      "Yuanyuan Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02113",
    "title": "Optimization-Informed Neural Networks",
    "abstract": "Solving constrained nonlinear optimization problems (CNLPs) is a longstanding problem that arises in various fields, e.g., economics, computer science, and engineering. We propose optimization-informed neural networks (OINN), a deep learning approach to solve CNLPs. By neurodynamic optimization methods, a CNLP is first reformulated as an initial value problem (IVP) involving an ordinary differential equation (ODE) system. A neural network model is then used as an approximate solution for this IVP, with the endpoint being the prediction to the CNLP. We propose a novel training algorithm that directs the model to hold the best prediction during training. In a nutshell, OINN transforms a CNLP into a neural network training problem. By doing so, we can solve CNLPs based on deep learning infrastructure only, without using standard optimization solvers or numerical integration solvers. The effectiveness of the proposed approach is demonstrated through a collection of classical problems, e.g., variational inequalities, nonlinear complementary problems, and standard CNLPs. ",
    "url": "https://arxiv.org/abs/2210.02113",
    "authors": [
      "Dawen Wu",
      "Abdel Lisser"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.02126",
    "title": "Stock Volatility Prediction using Time Series and Deep Learning Approach",
    "abstract": "Volatility clustering is a crucial property that has a substantial impact on stock market patterns. Nonetheless, developing robust models for accurately predicting future stock price volatility is a difficult research topic. For predicting the volatility of three equities listed on India's national stock market (NSE), we propose multiple volatility models depending on the generalized autoregressive conditional heteroscedasticity (GARCH), Glosten-Jagannathan-GARCH (GJR-GARCH), Exponential general autoregressive conditional heteroskedastic (EGARCH), and LSTM framework. Sector-wise stocks have been chosen in our study. The sectors which have been considered are banking, information technology (IT), and pharma. yahoo finance has been used to obtain stock price data from Jan 2017 to Dec 2021. Among the pulled-out records, the data from Jan 2017 to Dec 2020 have been taken for training, and data from 2021 have been chosen for testing our models. The performance of predicting the volatility of stocks of three sectors has been evaluated by implementing three different types of GARCH models as well as by the LSTM model are compared. It has been observed the LSTM performed better in predicting volatility in pharma over banking and IT sectors. In tandem, it was also observed that E-GARCH performed better in the case of the banking sector and for IT and pharma, GJR-GARCH performed better. ",
    "url": "https://arxiv.org/abs/2210.02126",
    "authors": [
      "Ananda Chatterjee",
      "Hrisav Bhowmick",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02129",
    "title": "Personalized Decentralized Bilevel Optimization over Stochastic and  Directed Networks",
    "abstract": "While personalization in distributed learning has been extensively studied, existing approaches employ dedicated algorithms to optimize their specific type of parameters (e.g., client clusters or model interpolation weights), making it difficult to simultaneously optimize different types of parameters to yield better performance. Moreover, their algorithms require centralized or static undirected communication networks, which can be vulnerable to center-point failures or deadlocks. This study proposes optimizing various types of parameters using a single algorithm that runs on more practical communication environments. First, we propose a gradient-based bilevel optimization that reduces most personalization approaches to the optimization of client-wise hyperparameters. Second, we propose a decentralized algorithm to estimate gradients with respect to the hyperparameters, which can run even on stochastic and directed communication networks. Our empirical results demonstrated that the gradient-based bilevel optimization enabled combining existing personalization approaches which led to state-of-the-art performance, confirming it can perform on multiple simulated communication environments including a stochastic and directed network. ",
    "url": "https://arxiv.org/abs/2210.02129",
    "authors": [
      "Naoyuki Terashita",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02157",
    "title": "The Influence of Learning Rule on Representation Dynamics in Wide Neural  Networks",
    "abstract": "It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient descent (GD) and biologically-plausible alternatives including feedback alignment (FA), direct feedback alignment (DFA), and error modulated Hebbian learning (Hebb), as well as gated linear networks (GLN). We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel's evolution can be determined self-consistently with dynamical mean field theory (DMFT). This DMFT enables comparisons of the feature and prediction dynamics induced by each of these learning rules. In the lazy limit, we find that DFA and Hebb can only learn using the last layer features, while full FA can utilize earlier layers with a scale determined by the initial correlation between feedforward and feedback weight matrices. In the rich regime, DFA and FA utilize a temporally evolving and depth-dependent NTK. Counterintuitively, we find that FA networks trained in the rich regime exhibit more feature learning if initialized with smaller correlation between the forward and backward pass weights. GLNs admit a very simple formula for their lazy limit kernel and preserve conditional Gaussianity of their preactivations under gating functions. Error modulated Hebb rules show very small task-relevant alignment of their kernels and perform most task relevant learning in the last layer. ",
    "url": "https://arxiv.org/abs/2210.02157",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02184",
    "title": "Rediscovery of Numerical L\u00fcscher's Formula from the Neural Network",
    "abstract": "We present that by predicting the spectrum in discrete space from the phase shift in continuous space, the neural network can remarkably reproduce the numerical L\\\"uscher's formula to a high precision. The model-independent property of the L\\\"uscher's formula is naturally realized by the generalizability of the neural network. This exhibits the great potential of the neural network to extract model-independent relation between model-dependent quantities, and this data-driven approach could greatly facilitate the discovery of the physical principles underneath the intricate data. ",
    "url": "https://arxiv.org/abs/2210.02184",
    "authors": [
      "Yu Lu",
      "Yi-Jia Wang",
      "Ying Chen",
      "Jia-Jun Wu"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)"
    ]
  },
  {
    "id": "arXiv:2210.02226",
    "title": "Null Hypothesis Test for Anomaly Detection",
    "abstract": "We extend the use of Classification Without Labels for anomaly detection with a hypothesis test designed to exclude the background-only hypothesis. By testing for statistical independence of the two discriminating dataset regions, we are able exclude the background-only hypothesis without relying on fixed anomaly score cuts or extrapolations of background estimates between regions. The method relies on the assumption of conditional independence of anomaly score features and dataset regions, which can be ensured using existing decorrelation techniques. As a benchmark example, we consider the LHC Olympics dataset where we show that mutual information represents a suitable test for statistical independence and our method exhibits excellent and robust performance at different signal fractions even in presence of realistic feature correlations. ",
    "url": "https://arxiv.org/abs/2210.02226",
    "authors": [
      "Jernej F. Kamenik",
      "Manuel Szewc"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2210.02241",
    "title": "HeartSpot: Privatized and Explainable Data Compression for Cardiomegaly  Detection",
    "abstract": "Advances in data-driven deep learning for chest X-ray image analysis underscore the need for explainability, privacy, large datasets and significant computational resources. We frame privacy and explainability as a lossy single-image compression problem to reduce both computational and data requirements without training. For Cardiomegaly detection in chest X-ray images, we propose HeartSpot and four spatial bias priors. HeartSpot priors define how to sample pixels based on domain knowledge from medical literature and from machines. HeartSpot privatizes chest X-ray images by discarding up to 97% of pixels, such as those that reveal the shape of the thoracic cage, bones, small lesions and other sensitive features. HeartSpot priors are ante-hoc explainable and give a human-interpretable image of the preserved spatial features that clearly outlines the heart. HeartSpot offers strong compression, with up to 32x fewer pixels and 11x smaller filesize. Cardiomegaly detectors using HeartSpot are up to 9x faster to train or at least as accurate (up to +.01 AUC ROC) when compared to a baseline DenseNet121. HeartSpot is post-hoc explainable by re-using existing attribution methods without requiring access to the original non-privatized image. In summary, HeartSpot improves speed and accuracy, reduces image size, improves privacy and ensures explainability. Source code: https://www.github.com/adgaudio/HeartSpot ",
    "url": "https://arxiv.org/abs/2210.02241",
    "authors": [
      "Elvin Johnson",
      "Shreshta Mohan",
      "Alex Gaudio",
      "Asim Smailagic",
      "Christos Faloutsos",
      "Aur\u00e9lio Campilho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02271",
    "title": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "abstract": "Conformal prediction is a widely used method to quantify uncertainty in settings where the data is independent and identically distributed (IID), or more generally, exchangeable. Conformal prediction takes in a pre-trained classifier, a calibration dataset and a confidence level as inputs, and returns a function which maps feature vectors to subsets of classes. The output of the returned function for a new feature vector (i.e., a test data point) is guaranteed to contain the true class with the pre-specified confidence. Despite its success and usefulness in IID settings, extending conformal prediction to non-exchangeable (e.g., Markovian) data in a manner that provably preserves all desirable theoretical properties has largely remained an open problem. As a solution, we extend conformal prediction to the setting of a Hidden Markov Model (HMM) with unknown parameters. The key idea behind the proposed method is to partition the non-exchangeable Markovian data from the HMM into exchangeable blocks by exploiting the de Finetti's Theorem for Markov Chains discovered by Diaconis and Freedman (1980). The permutations of the exchangeable blocks are then viewed as randomizations of the observed Markovian data from the HMM. The proposed method provably retains all desirable theoretical guarantees offered by the classical conformal prediction framework and is general enough to be useful in many sequential prediction problems. ",
    "url": "https://arxiv.org/abs/2210.02271",
    "authors": [
      "Buddhika Nettasinghe",
      "Samrat Chatterjee",
      "Ramakrishna Tipireddy",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.02339",
    "title": "Particle clustering in turbulence: Prediction of spatial and statistical  properties with deep learning",
    "abstract": "We demonstrate the utility of deep learning for modeling the clustering of particles that are aerodynamically coupled to turbulent fluids. Using a Lagrangian particle module within the ATHENA++ hydrodynamics code, we simulate the dynamics of particles in the Epstein drag regime within a periodic domain of isotropic forced hydrodynamic turbulence. This setup is an idealized model relevant to the collisional growth of micron to mmsized dust particles in early stage planet formation. The simulation data is used to train a U-Net deep learning model to predict gridded three-dimensional representations of the particle density and velocity fields, given as input the corresponding fluid fields. The trained model qualitatively captures the filamentary structure of clustered particles in a highly non-linear regime. We assess model fidelity by calculating metrics of the density structure (the radial distribution function) and of the velocity field (the relative velocity and the relative radial velocity between particles). Although trained only on the spatial fields, the model predicts these statistical quantities with errors that are typically < 10%. Our results suggest that, given appropriately expanded training data, deep learning could be used to accelerate calculations of particle clustering and collision outcomes both in protoplanetary disks, and in related two-fluid turbulence problems that arise in other disciplines. ",
    "url": "https://arxiv.org/abs/2210.02339",
    "authors": [
      "Yan-Mong Chan",
      "Natascha Manger",
      "Yin Li",
      "Chao-Chin Yang",
      "Zhaohuan Zhu",
      "Philip J. Armitage",
      "Shirley Ho"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2210.02349",
    "title": "Fitting a Directional Microstructure Model to Diffusion-Relaxation MRI  Data with Self-Supervised Machine Learning",
    "abstract": "Machine learning is a powerful approach for fitting microstructural models to diffusion MRI data. Early machine learning microstructure imaging implementations trained regressors to estimate model parameters in a supervised way, using synthetic training data with known ground truth. However, a drawback of this approach is that the choice of training data impacts fitted parameter values. Self-supervised learning is emerging as an attractive alternative to supervised learning in this context. Thus far, both supervised and self-supervised learning have typically been applied to isotropic models, such as intravoxel incoherent motion (IVIM), as opposed to models where the directionality of anisotropic structures is also estimated. In this paper, we demonstrate self-supervised machine learning model fitting for a directional microstructural model. In particular, we fit a combined T1-ball-stick model to the multidimensional diffusion (MUDI) challenge diffusion-relaxation dataset. Our self-supervised approach shows clear improvements in parameter estimation and computational time, for both simulated and in-vivo brain data, compared to standard non-linear least squares fitting. Code for the artificial neural net constructed for this study is available for public use from the following GitHub repository: https://github.com/jplte/deep-T1-ball-stick ",
    "url": "https://arxiv.org/abs/2210.02349",
    "authors": [
      "Jason P. Lim",
      "Stefano B. Blumberg",
      "Neil Narayan",
      "Sean C. Epstein",
      "Daniel C. Alexander",
      "Marco Palombo",
      "Paddy J. Slator"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:1910.08635",
    "title": "Tree-based Intelligent Intrusion Detection System in Internet of  Vehicles",
    "abstract": " Comments: Published in IEEE Global Communications Conference (GLOBECOM) 2019; Code is available at Github link: this https URL ",
    "url": "https://arxiv.org/abs/1910.08635",
    "authors": [
      "Li Yang",
      "Abdallah Moubayed",
      "Ismail Hamieh",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.15578",
    "title": "Universal Medical Image Segmentation using 3D Fabric Image  Representation Encoding Networks",
    "abstract": " Title: Universal Medical Image Segmentation using 3D Fabric Image  Representation Encoding Networks ",
    "url": "https://arxiv.org/abs/2006.15578",
    "authors": [
      "Siyu Liu",
      "Wei Dai",
      "Craig Engstrom",
      "Jurgen Fripp",
      "Stuart Crozier",
      "Jason A. Dowling",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2007.06686",
    "title": "A Systematic Survey on Deep Generative Models for Graph Generation",
    "abstract": " Comments: Accepted in TPAMI ",
    "url": "https://arxiv.org/abs/2007.06686",
    "authors": [
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.01102",
    "title": "An Analytic Propositional Proof System on Graphs",
    "abstract": " Title: An Analytic Propositional Proof System on Graphs ",
    "url": "https://arxiv.org/abs/2012.01102",
    "authors": [
      "Matteo Acclavio",
      "Ross Horne",
      "Lutz Stra\u00dfburger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2103.00882",
    "title": "K-apices Of Minor-closed Graph Classes. I. Bounding The Obstructions",
    "abstract": " Comments: 46 pages and 12 figures. arXiv admin note: text overlap with arXiv:2004.12692 ",
    "url": "https://arxiv.org/abs/2103.00882",
    "authors": [
      "Ignasi Sau",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2104.03158",
    "title": "Beyond Impute-Then-Regress: Adapting Prediction to Missing Data",
    "abstract": " Title: Beyond Impute-Then-Regress: Adapting Prediction to Missing Data ",
    "url": "https://arxiv.org/abs/2104.03158",
    "authors": [
      "Dimitris Bertsimas",
      "Arthur Delarue",
      "Jean Pauphilet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.07154",
    "title": "What and When to Look?: Temporal Span Proposal Network for Video  Relation Detection",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2107.07154",
    "authors": [
      "Sangmin Woo",
      "Junhyug Noh",
      "Kangil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.08965",
    "title": "PCNN: A physics-constrained neural network for multiphase flows",
    "abstract": " Comments: 29 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2109.08965",
    "authors": [
      "Haoyang Zheng",
      "Ziyang Huang",
      "Guang Lin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.01729",
    "title": "Stochastic coordinate transformations with applications to robust  machine learning",
    "abstract": " Title: Stochastic coordinate transformations with applications to robust  machine learning ",
    "url": "https://arxiv.org/abs/2110.01729",
    "authors": [
      "Julio Enrique Castrillon-Candas",
      "Dingning Liu",
      "Mark Kon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.06763",
    "title": "Efficient Estimation in NPIV Models: A Comparison of Various Neural  Networks-Based Estimators",
    "abstract": " Title: Efficient Estimation in NPIV Models: A Comparison of Various Neural  Networks-Based Estimators ",
    "url": "https://arxiv.org/abs/2110.06763",
    "authors": [
      "Jiafeng Chen",
      "Xiaohong Chen",
      "Elie Tamer"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2110.13413",
    "title": "Does your graph need a confidence boost? Convergent boosted smoothing on  graphs with tabular node features",
    "abstract": " Title: Does your graph need a confidence boost? Convergent boosted smoothing on  graphs with tabular node features ",
    "url": "https://arxiv.org/abs/2110.13413",
    "authors": [
      "Jiuhai Chen",
      "Jonas Mueller",
      "Vassilis N. Ioannidis",
      "Soji Adeshina",
      "Yangkun Wang",
      "Tom Goldstein",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.02098",
    "title": "Distributed Extended Object Tracking Information Filter Over Sensor  Networks",
    "abstract": " Comments: This paper contains 23 pages with single-column, 24 figures ",
    "url": "https://arxiv.org/abs/2111.02098",
    "authors": [
      "Zhifei Li",
      "Yan Liang",
      "Linfeng Xu",
      "Shuli Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.10541",
    "title": "Graph-augmented Learning to Rank for Querying Large-scale Knowledge  Graph",
    "abstract": " Comments: Accepted by AACL 2022 ",
    "url": "https://arxiv.org/abs/2111.10541",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Po Hu",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.04329",
    "title": "Neural Residual Flow Fields for Efficient Video Representations",
    "abstract": " Comments: Accepted for ACCV 2022, codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2201.04329",
    "authors": [
      "Daniel Rho",
      "Junwoo Cho",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": " Comments: This paper has been accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.11932",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13329",
    "title": "Can Adversarial Training Be Manipulated By Non-Robust Features?",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2201.13329",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Hongxin Wei",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.05189",
    "title": "Understanding Rare Spurious Correlations in Neural Networks",
    "abstract": " Title: Understanding Rare Spurious Correlations in Neural Networks ",
    "url": "https://arxiv.org/abs/2202.05189",
    "authors": [
      "Yao-Yuan Yang",
      "Chi-Ning Chou",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.05488",
    "title": "Fast Adversarial Training with Noise Augmentation: A Unified Perspective  on RandStart and GradAlign",
    "abstract": " Title: Fast Adversarial Training with Noise Augmentation: A Unified Perspective  on RandStart and GradAlign ",
    "url": "https://arxiv.org/abs/2202.05488",
    "authors": [
      "Axi Niu",
      "Kang Zhang",
      "Chaoning Zhang",
      "Chenshuang Zhang",
      "In So Kweon",
      "Chang D. Yoo",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.05687",
    "title": "Towards Adversarially Robust Deepfake Detection: An Ensemble Approach",
    "abstract": " Title: Towards Adversarially Robust Deepfake Detection: An Ensemble Approach ",
    "url": "https://arxiv.org/abs/2202.05687",
    "authors": [
      "Ashish Hooda",
      "Neal Mangaokar",
      "Ryan Feng",
      "Kassem Fawaz",
      "Somesh Jha",
      "Atul Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.12570",
    "title": "Multi-Instance Causal Representation Learning for Instance Label  Prediction and Out-of-Distribution Generalization",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.12570",
    "authors": [
      "Weijia Zhang",
      "Xuanhui Zhang",
      "Han-Wen Deng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00307",
    "title": "Temporal Perceiver: A General Architecture for Arbitrary Boundary  Detection",
    "abstract": " Title: Temporal Perceiver: A General Architecture for Arbitrary Boundary  Detection ",
    "url": "https://arxiv.org/abs/2203.00307",
    "authors": [
      "Jing Tan",
      "Yuhong Wang",
      "Gangshan Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01631",
    "title": "Fully-Connected Network on Noncompact Symmetric Space and Ridgelet  Transform based on Helgason-Fourier Analysis",
    "abstract": " Comments: replaced with the published version (ICML2022) ",
    "url": "https://arxiv.org/abs/2203.01631",
    "authors": [
      "Sho Sonoda",
      "Isao Ishikawa",
      "Masahiro Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04306",
    "title": "Diffusion Models for Medical Anomaly Detection",
    "abstract": " Title: Diffusion Models for Medical Anomaly Detection ",
    "url": "https://arxiv.org/abs/2203.04306",
    "authors": [
      "Julia Wolleb",
      "Florentin Bieder",
      "Robin Sandk\u00fchler",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06768",
    "title": "Probabilistically Robust Recourse: Navigating the Trade-offs between  Costs and Robustness in Algorithmic Recourse",
    "abstract": " Title: Probabilistically Robust Recourse: Navigating the Trade-offs between  Costs and Robustness in Algorithmic Recourse ",
    "url": "https://arxiv.org/abs/2203.06768",
    "authors": [
      "Martin Pawelczyk",
      "Teresa Datta",
      "Johannes van-den-Heuvel",
      "Gjergji Kasneci",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.11793",
    "title": "A Perspective on Neural Capacity Estimation: Viability and Reliability",
    "abstract": " Comments: 33 pages, 9 figures, under revison for possible journal publication ",
    "url": "https://arxiv.org/abs/2203.11793",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini",
      "Nariman Farsad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2204.00352",
    "title": "On the Efficiency of Integrating Self-supervised Learning and  Meta-learning for User-defined Few-shot Keyword Spotting",
    "abstract": " Comments: Accepted by SLT 2022 ",
    "url": "https://arxiv.org/abs/2204.00352",
    "authors": [
      "Wei-Tsung Kao",
      "Yuan-Kuei Wu",
      "Chia-Ping Chen",
      "Zhi-Sheng Chen",
      "Yu-Pao Tsai",
      "Hung-Yi Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.00673",
    "title": "Learnable latent embeddings for joint behavioral and neural analysis",
    "abstract": " Comments: Website: cebra.ai ",
    "url": "https://arxiv.org/abs/2204.00673",
    "authors": [
      "Steffen Schneider",
      "Jin Hwa Lee",
      "Mackenzie Weygandt Mathis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.02765",
    "title": "Code Search: A Survey of Techniques for Finding Code",
    "abstract": " Title: Code Search: A Survey of Techniques for Finding Code ",
    "url": "https://arxiv.org/abs/2204.02765",
    "authors": [
      "Luca Di Grazia",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2205.09332",
    "title": "Accelerated Training of Physics-Informed Neural Networks (PINNs) using  Meshless Discretizations",
    "abstract": " Comments: Accepted at the 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.09332",
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12796",
    "title": "Non-rigid Point Cloud Registration with Neural Deformation Pyramid",
    "abstract": " Comments: NeurIPS'2022 camera ready. Code: this https URL ",
    "url": "https://arxiv.org/abs/2205.12796",
    "authors": [
      "Yang Li",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14327",
    "title": "Efficient Policy Iteration for Robust Markov Decision Processes via  Regularization",
    "abstract": " Title: Efficient Policy Iteration for Robust Markov Decision Processes via  Regularization ",
    "url": "https://arxiv.org/abs/2205.14327",
    "authors": [
      "Navdeep Kumar",
      "Kfir Levy",
      "Kaixin Wang",
      "Shie Mannor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15674",
    "title": "Generalised Implicit Neural Representations",
    "abstract": " Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.15674",
    "authors": [
      "Daniele Grattarola",
      "Pierre Vandergheynst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.15856",
    "title": "coVariance Neural Networks",
    "abstract": " Title: coVariance Neural Networks ",
    "url": "https://arxiv.org/abs/2205.15856",
    "authors": [
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Corey McMillan",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02574",
    "title": "On the duality between contrastive and non-contrastive self-supervised  learning",
    "abstract": " Title: On the duality between contrastive and non-contrastive self-supervised  learning ",
    "url": "https://arxiv.org/abs/2206.02574",
    "authors": [
      "Quentin Garrido",
      "Yubei Chen",
      "Adrien Bardes",
      "Laurent Najman",
      "Yann Lecun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03491",
    "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks",
    "abstract": " Title: EiX-GNN : Concept-level eigencentrality explainer for graph neural  networks ",
    "url": "https://arxiv.org/abs/2206.03491",
    "authors": [
      "Adrien Raison",
      "Pascal Bourdon",
      "David Helbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.05224",
    "title": "A Multi-Task Benchmark for Korean Legal Language Understanding and  Judgement Prediction",
    "abstract": " Comments: Accepted at NeurIPS 2022 Datasets and Benchmarks track ",
    "url": "https://arxiv.org/abs/2206.05224",
    "authors": [
      "Wonseok Hwang",
      "Dongjun Lee",
      "Kyoungyeon Cho",
      "Hanuhl Lee",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.06424",
    "title": "Look, Radiate, and Learn: Self-supervised Localisation via Radio-Visual  Correspondence",
    "abstract": " Title: Look, Radiate, and Learn: Self-supervised Localisation via Radio-Visual  Correspondence ",
    "url": "https://arxiv.org/abs/2206.06424",
    "authors": [
      "Mohammed Alloulah",
      "Maximilian Arnold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2206.10292",
    "title": "Artificial Neural Network evaluation of Poincar\u00e9 constant for Voronoi  polygons",
    "abstract": " Title: Artificial Neural Network evaluation of Poincar\u00e9 constant for Voronoi  polygons ",
    "url": "https://arxiv.org/abs/2206.10292",
    "authors": [
      "Beatrice Crippa",
      "Silvia Bertoluzza",
      "Micol Pennacchio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.13728",
    "title": "Boosting R-CNN: Reweighting R-CNN Samples by RPN's Error for Underwater  Object Detection",
    "abstract": " Title: Boosting R-CNN: Reweighting R-CNN Samples by RPN's Error for Underwater  Object Detection ",
    "url": "https://arxiv.org/abs/2206.13728",
    "authors": [
      "Pinhao Song",
      "Pengteng Li",
      "Linhui Dai",
      "Tao Wang",
      "Zhan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06131",
    "title": "Continual Meta-Reinforcement Learning for UAV-Aided Vehicular Wireless  Networks",
    "abstract": " Comments: submitted for conference publication ",
    "url": "https://arxiv.org/abs/2207.06131",
    "authors": [
      "Riccardo Marini",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Chiara Buratti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.06229",
    "title": "Stochastic Functional Analysis and Multilevel Vector Field Anomaly  Detection",
    "abstract": " Title: Stochastic Functional Analysis and Multilevel Vector Field Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2207.06229",
    "authors": [
      "Julio E Castrillon-Candas",
      "Mark Kon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2207.06343",
    "title": "TCT: Convexifying Federated Learning using Bootstrapped Neural Tangent  Kernels",
    "abstract": " Comments: Accepted at Neural Information Processing Systems (NeurIPS) 2022. V2 releases code ",
    "url": "https://arxiv.org/abs/2207.06343",
    "authors": [
      "Yaodong Yu",
      "Alexander Wei",
      "Sai Praneeth Karimireddy",
      "Yi Ma",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.08323",
    "title": "PlaneSDF-based Change Detection for Long-term Dense Mapping",
    "abstract": " Comments: 8 pages, 7 figures, and 1 table. To be published in Robotics and Automation Letters and IROS 2022. Link to supplementary video added in the abstract: this https URL ",
    "url": "https://arxiv.org/abs/2207.08323",
    "authors": [
      "Jiahui Fu",
      "Chengyuan Lin",
      "Yuichi Taguchi",
      "Andrea Cohen",
      "Yifu Zhang",
      "Stephen Mylabathula",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.00789",
    "title": "Self-supervised learning with rotation-invariant kernels",
    "abstract": " Title: Self-supervised learning with rotation-invariant kernels ",
    "url": "https://arxiv.org/abs/2208.00789",
    "authors": [
      "L\u00e9on Zheng",
      "Gilles Puy",
      "Elisa Riccietti",
      "Patrick P\u00e9rez",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.05433",
    "title": "Detecting COVID-19 from digitized ECG printouts using 1D convolutional  neural networks",
    "abstract": " Comments: Accepted with minor revision by Plos One ",
    "url": "https://arxiv.org/abs/2208.05433",
    "authors": [
      "Thao Nguyen",
      "Hieu H. Pham",
      "Huy Khiem Le",
      "Anh Tu Nguyen",
      "Ngoc Tien Thanh",
      "Cuong Do"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspectives",
    "abstract": " Comments: 183 pages, 36 figures ",
    "url": "https://arxiv.org/abs/2208.07541",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.08797",
    "title": "Exploiting Sentiment and Common Sense for Zero-shot Stance Detection",
    "abstract": " Title: Exploiting Sentiment and Common Sense for Zero-shot Stance Detection ",
    "url": "https://arxiv.org/abs/2208.08797",
    "authors": [
      "Yun Luo",
      "Zihan Liu",
      "Yuefeng Shi",
      "Stan Z Li",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.08910",
    "title": "Learned Indexing in Proteins: Extended Work on Substituting Complex  Distance Calculations with Embedding and Clustering Techniques",
    "abstract": " Comments: 14 pages, 7 figures, short version published in SISAP 2022 as a short paper ",
    "url": "https://arxiv.org/abs/2208.08910",
    "authors": [
      "Jaroslav O\u013eha",
      "Ter\u00e9zia Slanin\u00e1kov\u00e1",
      "Martin Gendiar",
      "Matej Antol",
      "Vlastislav Dohnal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09656",
    "title": "A Domain Generalization Approach for Out-Of-Distribution 12-lead ECG  Classification with Convolutional Neural Networks",
    "abstract": " Comments: This paper has been accepted at: IEEE BigDataService2022 (this http URL) ",
    "url": "https://arxiv.org/abs/2208.09656",
    "authors": [
      "Aristotelis Ballas",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.05040",
    "title": "SANCL: Multimodal Review Helpfulness Prediction with Selective Attention  and Natural Contrastive Learning",
    "abstract": " Comments: Accepted as a long paper at COLING 2022 ",
    "url": "https://arxiv.org/abs/2209.05040",
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Zhen Hai",
      "Soujanya Poria",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08966",
    "title": "Will It Blend? Mixing Training Paradigms & Prompting for Argument  Quality Prediction",
    "abstract": " Comments: Accepted at the 9th Workshop on Argument Mining (2022) ",
    "url": "https://arxiv.org/abs/2209.08966",
    "authors": [
      "Michiel van der Meer",
      "Myrthe Reuver",
      "Urja Khurana",
      "Lea Krause",
      "Selene B\u00e1ez Santamar\u00eda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.10391",
    "title": "IoU-Enhanced Attention for End-to-End Task Specific Object Detection",
    "abstract": " Comments: ACCV2022 ",
    "url": "https://arxiv.org/abs/2209.10391",
    "authors": [
      "Jing Zhao",
      "Shengjian Wu",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14649",
    "title": "Factor Graph Fusion of Raw GNSS Sensing with IMU and Lidar for Precise  Robot Localization without a Base Station",
    "abstract": " Comments: 7 pages, 4 figures, accompanying video: this https URL ",
    "url": "https://arxiv.org/abs/2209.14649",
    "authors": [
      "Jonas Beuchert",
      "Marco Camurri",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.00465",
    "title": "Assessing the impact of contextual information in hate speech detection",
    "abstract": " Title: Assessing the impact of contextual information in hate speech detection ",
    "url": "https://arxiv.org/abs/2210.00465",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Franco Luque",
      "Demian Zayat",
      "Mart\u00edn Kondratzky",
      "Agust\u00edn Moro",
      "Pablo Serrati",
      "Joaqu\u00edn Zajac",
      "Paula Miguel",
      "Natalia Debandi",
      "Agust\u00edn Gravano",
      "Viviana Cotik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.00597",
    "title": "Composition of Differential Privacy & Privacy Amplification by  Subsampling",
    "abstract": " Title: Composition of Differential Privacy & Privacy Amplification by  Subsampling ",
    "url": "https://arxiv.org/abs/2210.00597",
    "authors": [
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00737",
    "title": "FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients",
    "abstract": " Title: FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients ",
    "url": "https://arxiv.org/abs/2210.00737",
    "authors": [
      "Chih-Fan Hsu",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01274",
    "title": "Random Weight Factorization Improves the Training of Continuous Neural  Representations",
    "abstract": " Comments: 33 pages, 21 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2210.01274",
    "authors": [
      "Sifan Wang",
      "Hanwen Wang",
      "Jacob H. Seidman",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01448",
    "title": "Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with  Hierarchical Neural Embeddings",
    "abstract": " Comments: SIGGRAPH Asia 2022 (Journal Track); Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2210.01448",
    "authors": [
      "Tenglong Ao",
      "Qingzhe Gao",
      "Yuke Lou",
      "Baoquan Chen",
      "Libin Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.01699",
    "title": "Robust feedback stabilization of interacting multi-agent systems under  uncertainty",
    "abstract": " Comments: 27 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2210.01699",
    "authors": [
      "Giacomo Albi",
      "Michael Herty",
      "Chiara Segala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ]
  }
]