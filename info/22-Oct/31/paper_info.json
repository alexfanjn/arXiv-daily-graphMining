[
  {
    "id": "arXiv:2210.15667",
    "title": "Probabilistic Prediction of Coalescence Flutter Using Measurements:  Application to the Flutter Margin Method",
    "abstract": "Zimmerman and Weissenburger's flutter margin method is widely used to estimate the aeroelastic coalescence flutter speed. In contrast to aeroelastic decay rates, the flutter margin exhibits monotonic decay with respect to airspeed redering it effective in extrapolating the flutter speed using flight test data conducted at pre-flutter airspeeds. This paper reports the generalization of the Bayesian formulation of the flutter margin method by Khalil et al. developed to tackle measurement and modeling uncertainties. This paper improves the predictive performance of the previous algorithm by incorporating the joint prior of aeroelastic modal frequencies and decay rates among airspeeds in order to better estimate the joint posterior of modal parameters using observational data. The modal parameter prior is constructed using the classical two-degree-of-freedom pitch-plunge aeroelastic model whose system matrices (e.g. structural stiffness and damping matrices) vary randomly. Such joint modal parameter prior enforces statistical dependence among posteriors of modal parameters and the associated flutter margins across airspeeds. Numerical studies demonstrate a considerable reduction of uncertainties on the predicted flutter speed obtained from the generalized Bayesian flutter margin method. This improved algorithm can cut cost by reducing the number of flight tests and better assess the uncertainty against aeroelastic flutter. ",
    "url": "https://arxiv.org/abs/2210.15667",
    "authors": [
      "Sandip Chajjed",
      "Mohammad Khalil",
      "Dominique Poirel",
      "Chris Pettit",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.15676",
    "title": "Deepening Neural Networks Implicitly and Locally via Recurrent Attention  Strategy",
    "abstract": "More and more empirical and theoretical evidence shows that deepening neural networks can effectively improve their performance under suitable training settings. However, deepening the backbone of neural networks will inevitably and significantly increase computation and parameter size. To mitigate these problems, we propose a simple-yet-effective Recurrent Attention Strategy (RAS), which implicitly increases the depth of neural networks with lightweight attention modules by local parameter sharing. The extensive experiments on three widely-used benchmark datasets demonstrate that RAS can improve the performance of neural networks at a slight addition of parameter size and computation, performing favorably against other existing well-known attention modules. ",
    "url": "https://arxiv.org/abs/2210.15676",
    "authors": [
      "Shanshan Zhong",
      "Wushao Wen",
      "Jinghui Qin",
      "Zhongzhan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15700",
    "title": "TAD: Transfer Learning-based Multi-Adversarial Detection of Evasion  Attacks against Network Intrusion Detection Systems",
    "abstract": "Nowadays, intrusion detection systems based on deep learning deliver state-of-the-art performance. However, recent research has shown that specially crafted perturbations, called adversarial examples, are capable of significantly reducing the performance of these intrusion detection systems. The objective of this paper is to design an efficient transfer learning-based adversarial detector and then to assess the effectiveness of using multiple strategically placed adversarial detectors compared to a single adversarial detector for intrusion detection systems. In our experiments, we implement existing state-of-the-art models for intrusion detection. We then attack those models with a set of chosen evasion attacks. In an attempt to detect those adversarial attacks, we design and implement multiple transfer learning-based adversarial detectors, each receiving a subset of the information passed through the IDS. By combining their respective decisions, we illustrate that combining multiple detectors can further improve the detectability of adversarial traffic compared to a single detector in the case of a parallel IDS design. ",
    "url": "https://arxiv.org/abs/2210.15700",
    "authors": [
      "Islam Debicha",
      "Richard Bauwens",
      "Thibault Debatty",
      "Jean-Michel Dricot",
      "Tayeb Kenaza",
      "Wim Mees"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15718",
    "title": "QUILL: Query Intent with Large Language Models using Retrieval  Augmentation and Multi-stage Distillation",
    "abstract": "Large Language Models (LLMs) have shown impressive results on a variety of text understanding tasks. Search queries though pose a unique challenge, given their short-length and lack of nuance or context. Complicated feature engineering efforts do not always lead to downstream improvements as their performance benefits may be offset by increased complexity of knowledge distillation. Thus, in this paper we make the following contributions: (1) We demonstrate that Retrieval Augmentation of queries provides LLMs with valuable additional context enabling improved understanding. While Retrieval Augmentation typically increases latency of LMs (thus hurting distillation efficacy), (2) we provide a practical and effective way of distilling Retrieval Augmentation LLMs. Specifically, we use a novel two-stage distillation approach that allows us to carry over the gains of retrieval augmentation, without suffering the increased compute typically associated with it. (3) We demonstrate the benefits of the proposed approach (QUILL) on a billion-scale, real-world query understanding system resulting in huge gains. Via extensive experiments, including on public benchmarks, we believe this work offers a recipe for practical use of retrieval-augmented query understanding. ",
    "url": "https://arxiv.org/abs/2210.15718",
    "authors": [
      "Krishna Srinivasan",
      "Karthik Raman",
      "Anupam Samanta",
      "Lingrui Liao",
      "Luca Bertelli",
      "Mike Bendersky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.15721",
    "title": "GraphMAD: Graph Mixup for Data Augmentation using Data-Driven Convex  Clustering",
    "abstract": "We develop a novel data-driven nonlinear mixup mechanism for graph data augmentation and present different mixup functions for sample pairs and their labels. Mixup is a data augmentation method to create new training data by linearly interpolating between pairs of data samples and their labels. Mixup of graph data is challenging since the interpolation between graphs of potentially different sizes is an ill-posed operation. Hence, a promising approach for graph mixup is to first project the graphs onto a common latent feature space and then explore linear and nonlinear mixup strategies in this latent space. In this context, we propose to (i) project graphs onto the latent space of continuous random graph models known as graphons, (ii) leverage convex clustering in this latent space to generate nonlinear data-driven mixup functions, and (iii) investigate the use of different mixup functions for labels and data samples. We evaluate our graph data augmentation performance on benchmark datasets and demonstrate that nonlinear data-driven mixup functions can significantly improve graph classification. ",
    "url": "https://arxiv.org/abs/2210.15721",
    "authors": [
      "Madeline Navarro",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15722",
    "title": "PatchRot: A Self-Supervised Technique for Training Vision Transformers",
    "abstract": "Vision transformers require a huge amount of labeled data to outperform convolutional neural networks. However, labeling a huge dataset is a very expensive process. Self-supervised learning techniques alleviate this problem by learning features similar to supervised learning in an unsupervised way. In this paper, we propose a self-supervised technique PatchRot that is crafted for vision transformers. PatchRot rotates images and image patches and trains the network to predict the rotation angles. The network learns to extract both global and local features from an image. Our extensive experiments on different datasets showcase PatchRot training learns rich features which outperform supervised learning and compared baseline. ",
    "url": "https://arxiv.org/abs/2210.15722",
    "authors": [
      "Sachin Chhabra",
      "Prabal Bijoy Dutta",
      "Hemanth Venkateswara",
      "Baoxin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15731",
    "title": "Beyond Homophily with Graph Echo State Networks",
    "abstract": "Graph Echo State Networks (GESN) have already demonstrated their efficacy and efficiency in graph classification tasks. However, semi-supervised node classification brought out the problem of over-smoothing in end-to-end trained deep models, which causes a bias towards high homophily graphs. We evaluate for the first time GESN on node classification tasks with different degrees of homophily, analyzing also the impact of the reservoir radius. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to fully trained deep models that implement ad hoc variations in the architectural bias, with a gain in terms of efficiency. ",
    "url": "https://arxiv.org/abs/2210.15731",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15741",
    "title": "Spatio-temporal predictive tasks for abnormal event detection in videos",
    "abstract": "Abnormal event detection in videos is a challenging problem, partly due to the multiplicity of abnormal patterns and the lack of their corresponding annotations. In this paper, we propose new constrained pretext tasks to learn object level normality patterns. Our approach consists in learning a mapping between down-scaled visual queries and their corresponding normal appearance and motion characteristics at the original resolution. The proposed tasks are more challenging than reconstruction and future frame prediction tasks which are widely used in the literature, since our model learns to jointly predict spatial and temporal features rather than reconstructing them. We believe that more constrained pretext tasks induce a better learning of normality patterns. Experiments on several benchmark datasets demonstrate the effectiveness of our approach to localize and track anomalies as it outperforms or reaches the current state-of-the-art on spatio-temporal evaluation metrics. ",
    "url": "https://arxiv.org/abs/2210.15741",
    "authors": [
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15745",
    "title": "DICTION: DynamIC robusT whIte bOx watermarkiNg scheme",
    "abstract": "Deep neural network (DNN) watermarking is a suitable method for protecting the ownership of deep learning (DL) models derived from computationally intensive processes and painstakingly compiled and annotated datasets. It secretly embeds an identifier (watermark) within the model, which can be retrieved by the owner to prove ownership. In this paper, we first provide a unified framework for white box DNN watermarking schemes. It includes current state-of-the art methods outlining their theoretical inter-connections. In second, we introduce DICTION, a new white-box Dynamic Robust watermarking scheme, we derived from this framework. Its main originality stands on a generative adversarial network (GAN) strategy where the watermark extraction function is a DNN trained as a GAN discriminator, and the target model to watermark as a GAN generator taking a GAN latent space as trigger set input. DICTION can be seen as a generalization of DeepSigns which, to the best of knowledge, is the only other Dynamic white-box watermarking scheme from the literature. Experiments conducted on the same model test set as Deepsigns demonstrate that our scheme achieves much better performance. Especially, and contrarily to DeepSigns, with DICTION one can increase the watermark capacity while preserving at best the model accuracy and ensuring simultaneously a strong robustness against a wide range of watermark removal and detection attacks. ",
    "url": "https://arxiv.org/abs/2210.15745",
    "authors": [
      "Reda Bellafqira",
      "Gouenou Coatrieux"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.15759",
    "title": "Self-supervised language learning from raw audio: Lessons from the Zero  Resource Speech Challenge",
    "abstract": "Recent progress in self-supervised or unsupervised machine learning has opened the possibility of building a full speech processing system from raw audio without using any textual representations or expert labels such as phonemes, dictionaries or parse trees. The contribution of the Zero Resource Speech Challenge series since 2015 has been to break down this long-term objective into four well-defined tasks -- Acoustic Unit Discovery, Spoken Term Discovery, Discrete Resynthesis, and Spoken Language Modeling -- and introduce associated metrics and benchmarks enabling model comparison and cumulative progress. We present an overview of the six editions of this challenge series since 2015, discuss the lessons learned, and outline the areas which need more work or give puzzling results. ",
    "url": "https://arxiv.org/abs/2210.15759",
    "authors": [
      "Ewan Dunbar",
      "Nicolas Hamilakis",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15764",
    "title": "Noise Injection Node Regularization for Robust Learning",
    "abstract": "We introduce Noise Injection Node Regularization (NINR), a method of injecting structured noise into Deep Neural Networks (DNN) during the training stage, resulting in an emergent regularizing effect. We present theoretical and empirical evidence for substantial improvement in robustness against various test data perturbations for feed-forward DNNs when trained under NINR. The novelty in our approach comes from the interplay of adaptive noise injection and initialization conditions such that noise is the dominant driver of dynamics at the start of training. As it simply requires the addition of external nodes without altering the existing network structure or optimization algorithms, this method can be easily incorporated into many standard problem specifications. We find improved stability against a number of data perturbations, including domain shifts, with the most dramatic improvement obtained for unstructured noise, where our technique outperforms other existing methods such as Dropout or $L_2$ regularization, in some cases. We further show that desirable generalization properties on clean data are generally maintained. ",
    "url": "https://arxiv.org/abs/2210.15764",
    "authors": [
      "Noam Levi",
      "Itay M. Bloch",
      "Marat Freytsis",
      "Tomer Volansky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15765",
    "title": "An Adversarial Active Sampling-based Data Augmentation Framework for  Manufacturable Chip Design",
    "abstract": "Lithography modeling is a crucial problem in chip design to ensure a chip design mask is manufacturable. It requires rigorous simulations of optical and chemical models that are computationally expensive. Recent developments in machine learning have provided alternative solutions in replacing the time-consuming lithography simulations with deep neural networks. However, the considerable accuracy drop still impedes its industrial adoption. Most importantly, the quality and quantity of the training dataset directly affect the model performance. To tackle this problem, we propose a litho-aware data augmentation (LADA) framework to resolve the dilemma of limited data and improve the machine learning model performance. First, we pretrain the neural networks for lithography modeling and a gradient-friendly StyleGAN2 generator. We then perform adversarial active sampling to generate informative and synthetic in-distribution mask designs. These synthetic mask images will augment the original limited training dataset used to finetune the lithography model for improved performance. Experimental results demonstrate that LADA can successfully exploits the neural network capacity by narrowing down the performance gap between the training and testing data instances. ",
    "url": "https://arxiv.org/abs/2210.15765",
    "authors": [
      "Mingjie Liu",
      "Haoyu Yang",
      "Zongyi Li",
      "Kumara Sastry",
      "Saumyadip Mukhopadhyay",
      "Selim Dogru",
      "Anima Anandkumar",
      "David Z. Pan",
      "Brucek Khailany",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15769",
    "title": "Fully-attentive and interpretable: vision and video vision transformers  for pain detection",
    "abstract": "Pain is a serious and costly issue globally, but to be treated, it must first be detected. Vision transformers are a top-performing architecture in computer vision, with little research on their use for pain detection. In this paper, we propose the first fully-attentive automated pain detection pipeline that achieves state-of-the-art performance on binary pain detection from facial expressions. The model is trained on the UNBC-McMaster dataset, after faces are 3D-registered and rotated to the canonical frontal view. In our experiments we identify important areas of the hyperparameter space and their interaction with vision and video vision transformers, obtaining 3 noteworthy models. We analyse the attention maps of one of our models, finding reasonable interpretations for its predictions. We also evaluate Mixup, an augmentation technique, and Sharpness-Aware Minimization, an optimizer, with no success. Our presented models, ViT-1 (F1 score 0.55 +- 0.15), ViViT-1 (F1 score 0.55 +- 0.13), and ViViT-2 (F1 score 0.49 +- 0.04), all outperform earlier works, showing the potential of vision transformers for pain detection. Code is available at https://github.com/IPDTFE/ViT-McMaster ",
    "url": "https://arxiv.org/abs/2210.15769",
    "authors": [
      "Giacomo Fiorentini",
      "Itir Onal Ertugrul",
      "Albert Ali Salah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15773",
    "title": "Data-driven anomaly detection in large battery packs",
    "abstract": "Early detection and tracing of anomalous operation in battery packs are critical to improving performance and ensuring safety. This paper presents a data-driven approach for online anomaly detection in battery packs that uses real-time voltage and temperature data from multiple Li-ion battery cells. Mean-based residuals are generated for cell groups and evaluated using Principal Component Analysis (PCA). The evaluated residuals are then thresholded using a cumulative sum control chart to detect anomalies. A statistical testing of the proposed approach is performed on experimental data from a battery electric locomotive injected with model-based anomalies. The proposed anomaly detection approach has low false positive rate and accurately detects and traces the synthetic voltage and temperature anomalies. The performance of the proposed approach, compared with direct thresholding of mean-based residuals, shows 56% faster detection time, 42% less false negatives, and 60% fewer missed anomalies, while maintaining a comparable false positive rate. The mild external short circuits associated with cell balancing are detected in the voltage signals and necessitate voltage retraining after balancing. Temperature residuals prove to be critical, enabling anomaly detection of module balancing events within 14 minutes that are unobservable from voltage residuals. ",
    "url": "https://arxiv.org/abs/2210.15773",
    "authors": [
      "Kiran Bhaskar",
      "Ajith Kumar",
      "James Bunce",
      "Jacob Pressman",
      "Neil Burkell",
      "Christopher D. Rahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15779",
    "title": "Adapting Neural Models with Sequential Monte Carlo Dropout",
    "abstract": "The ability to adapt to changing environments and settings is essential for robots acting in dynamic and unstructured environments or working alongside humans with varied abilities or preferences. This work introduces an extremely simple and effective approach to adapting neural models in response to changing settings. We first train a standard network using dropout, which is analogous to learning an ensemble of predictive models or distribution over predictions. At run-time, we use a particle filter to maintain a distribution over dropout masks to adapt the neural model to changing settings in an online manner. Experimental results show improved performance in control problems requiring both online and look-ahead prediction, and showcase the interpretability of the inferred masks in a human behaviour modelling task for drone teleoperation. ",
    "url": "https://arxiv.org/abs/2210.15779",
    "authors": [
      "Pamela Carreno-Medrano",
      "Dana Kuli\u0107",
      "Michael Burke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": "In this letter we present tables of convolutional codes with an optimum bidirectional distance profile (OBDP), defined as the minimum of the distance profiles of the code and its corresponding \"reverse\" code. Such codes minimize the average complexity of bidirectional sequential decoding algorithms. The computer search is accelerated by the facts that optimum distance profile (ODP) codes of larger memory must have ODP codes of smaller memory as their \"prefixes\", and that OBDP codes can be obtained by \"concatenating\" ODP and reverse ODP codes of smaller memory. ",
    "url": "https://arxiv.org/abs/2210.15787",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.15790",
    "title": "BI AVAN: Brain inspired Adversarial Visual Attention Network",
    "abstract": "Visual attention is a fundamental mechanism in the human brain, and it inspires the design of attention mechanisms in deep neural networks. However, most of the visual attention studies adopted eye-tracking data rather than the direct measurement of brain activity to characterize human visual attention. In addition, the adversarial relationship between the attention-related objects and attention-neglected background in the human visual system was not fully exploited. To bridge these gaps, we propose a novel brain-inspired adversarial visual attention network (BI-AVAN) to characterize human visual attention directly from functional brain activity. Our BI-AVAN model imitates the biased competition process between attention-related/neglected objects to identify and locate the visual objects in a movie frame the human brain focuses on in an unsupervised manner. We use independent eye-tracking data as ground truth for validation and experimental results show that our model achieves robust and promising results when inferring meaningful human visual attention and mapping the relationship between brain activities and visual stimuli. Our BI-AVAN model contributes to the emerging field of leveraging the brain's functional architecture to inspire and guide the model design in artificial intelligence (AI), e.g., deep neural networks. ",
    "url": "https://arxiv.org/abs/2210.15790",
    "authors": [
      "Heng Huang",
      "Lin Zhao",
      "Xintao Hu",
      "Haixing Dai",
      "Lu Zhang",
      "Dajiang Zhu",
      "Tianming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15804",
    "title": "Handwashing Action Detection System for an Autonomous Social Robot",
    "abstract": "Young children are at an increased risk of contracting contagious diseases such as COVID-19 due to improper hand hygiene. An autonomous social agent that observes children while handwashing and encourages good hand washing practices could provide an opportunity for handwashing behavior to become a habit. In this article, we present a human action recognition system, which is part of the vision system of a social robot platform, to assist children in developing a correct handwashing technique. A modified convolution neural network (CNN) architecture with Channel Spatial Attention Bilinear Pooling (CSAB) frame, with a VGG-16 architecture as the backbone is trained and validated on an augmented dataset. The modified architecture generalizes well with an accuracy of 90% for the WHO-prescribed handwashing steps even in an unseen environment. Our findings indicate that the approach can recognize even subtle hand movements in the video and can be used for gesture detection and classification in social robotics. ",
    "url": "https://arxiv.org/abs/2210.15804",
    "authors": [
      "Sreejith Sasidharan",
      "Pranav Prabha",
      "Devasena Pasupuleti",
      "Anand M Das",
      "Chaitanya Kapoor",
      "Gayathri Manikutty",
      "Praveen Pankajakshan",
      "Bhavani Rao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15805",
    "title": "Towards Reliable Zero Shot Classification in Self-Supervised Models with  Conformal Prediction",
    "abstract": "Self-supervised models trained with a contrastive loss such as CLIP have shown to be very powerful in zero-shot classification settings. However, to be used as a zero-shot classifier these models require the user to provide new captions over a fixed set of labels at test time. In many settings, it is hard or impossible to know if a new query caption is compatible with the source captions used to train the model. We address these limitations by framing the zero-shot classification task as an outlier detection problem and develop a conformal prediction procedure to assess when a given test caption may be reliably used. On a real-world medical example, we show that our proposed conformal procedure improves the reliability of CLIP-style models in the zero-shot classification setting, and we provide an empirical analysis of the factors that may affect its performance. ",
    "url": "https://arxiv.org/abs/2210.15805",
    "authors": [
      "Bhawesh Kumar",
      "Anil Palepu",
      "Rudraksh Tuwani",
      "Andrew Beam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15824",
    "title": "Improving the Modality Representation with Multi-View Contrastive  Learning for Multimodal Sentiment Analysis",
    "abstract": "Modality representation learning is an important problem for multimodal sentiment analysis (MSA), since the highly distinguishable representations can contribute to improving the analysis effect. Previous works of MSA have usually focused on multimodal fusion strategies, and the deep study of modal representation learning was given less attention. Recently, contrastive learning has been confirmed effective at endowing the learned representation with stronger discriminate ability. Inspired by this, we explore the improvement approaches of modality representation with contrastive learning in this study. To this end, we devise a three-stages framework with multi-view contrastive learning to refine representations for the specific objectives. At the first stage, for the improvement of unimodal representations, we employ the supervised contrastive learning to pull samples within the same class together while the other samples are pushed apart. At the second stage, a self-supervised contrastive learning is designed for the improvement of the distilled unimodal representations after cross-modal interaction. At last, we leverage again the supervised contrastive learning to enhance the fused multimodal representation. After all the contrast trainings, we next achieve the classification task based on frozen representations. We conduct experiments on three open datasets, and results show the advance of our model. ",
    "url": "https://arxiv.org/abs/2210.15824",
    "authors": [
      "Peipei Liu",
      "Xin Zheng",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15827",
    "title": "Federated Learning with Intermediate Representation Regularization",
    "abstract": "In contrast to centralized model training that involves data collection, federated learning (FL) enables remote clients to collaboratively train a model without exposing their private data. However, model performance usually degrades in FL due to the heterogeneous data generated by clients of diverse characteristics. One promising strategy to maintain good performance is by limiting the local training from drifting far away from the global model. Previous studies accomplish this by regularizing the distance between the representations learned by the local and global models. However, they only consider representations from the early layers of a model or the layer preceding the output layer. In this study, we introduce FedIntR, which provides a more fine-grained regularization by integrating the representations of intermediate layers into the local training process. Specifically, FedIntR computes a regularization term that encourages the closeness between the intermediate layer representations of the local and global models. Additionally, FedIntR automatically determines the contribution of each layer's representation to the regularization term based on the similarity between local and global representations. We conduct extensive experiments on various datasets to show that FedIntR can achieve equivalent or higher performance compared to the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2210.15827",
    "authors": [
      "Ye Lin Tun",
      "Chu Myaet Thwal",
      "Seong-Bae Park",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15831",
    "title": "Cost Control and Efficiency Optimization in Maintainability  Implementation of Wireless Sensor Networks based on Serverless Computing",
    "abstract": "Wireless sensor network (WSN) has been developed for decades and have performed well in the performance, power consumption, and congestion control. However, the following problems have not been addressed, such as inaccurate cost estimation of device's lifecycle, highly-coupled engineering development, and low utilization of hardware and software resources during the life cycle of WSN. Therefore, we first propose the conceptual view of maintainability implementation for WSN based on Serverless Computing. The maintainability implementation refers to the ability to meet the WSN product to consume the minimum resources with a higher probability in configuration, trial production, debugging, batch production, deployment, operation, and maintenance phases. And then, we discuss that Serverless Computing can be realized at the software functional level of WSN to decouple the device operation and functional development, greatly improve the reuse of resources and exclude the hardware interference. From the perspective of maintainability and cost control, the concept of Serverless Computing can be used to build WSN platforms, which can support the functions of data collection and data management into functional development that may benefit from exploration through upfront expenditures, thereby significantly reducing design, manufacturing, and operational costs. Finally, based on existing technologies and smart city scenarios, the idea of a WSN platform for Serverless Computing is given with a case study. ",
    "url": "https://arxiv.org/abs/2210.15831",
    "authors": [
      "Tiannan Gao",
      "Minxian Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.15834",
    "title": "GM-TCNet: Gated Multi-scale Temporal Convolutional Network using Emotion  Causality for Speech Emotion Recognition",
    "abstract": "In human-computer interaction, Speech Emotion Recognition (SER) plays an essential role in understanding the user's intent and improving the interactive experience. While similar sentimental speeches own diverse speaker characteristics but share common antecedents and consequences, an essential challenge for SER is how to produce robust and discriminative representations through causality between speech emotions. In this paper, we propose a Gated Multi-scale Temporal Convolutional Network (GM-TCNet) to construct a novel emotional causality representation learning component with a multi-scale receptive field. GM-TCNet deploys a novel emotional causality representation learning component to capture the dynamics of emotion across the time domain, constructed with dilated causal convolution layer and gating mechanism. Besides, it utilizes skip connection fusing high-level features from different gated convolution blocks to capture abundant and subtle emotion changes in human speech. GM-TCNet first uses a single type of feature, mel-frequency cepstral coefficients, as inputs and then passes them through the gated temporal convolutional module to generate the high-level features. Finally, the features are fed to the emotion classifier to accomplish the SER task. The experimental results show that our model maintains the highest performance in most cases compared to state-of-the-art techniques. ",
    "url": "https://arxiv.org/abs/2210.15834",
    "authors": [
      "Jia-Xin Ye",
      "Xin-Cheng Wen",
      "Xuan-Ze Wang",
      "Yong Xu",
      "Yan Luo",
      "Chang-Li Wu",
      "Li-Yan Chen",
      "Kun-Hong Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15845",
    "title": "I Know What You Are Searching For: Code Snippet Recommendation from  Stack Overflow Posts",
    "abstract": "Stack Overflow has been heavily used by software developers to seek programming-related information. More and more developers use Community Question and Answer forums, such as Stack Overflow, to search for code examples of how to accomplish a certain coding task. This is often considered to be more efficient than working from source documentation, tutorials or full worked examples. However, due to the complexity of these online Question and Answer forums and the very large volume of information they contain, developers can be overwhelmed by the sheer volume of available information. This makes it hard to find and/or even be aware of the most relevant code examples to meet their needs. To alleviate this issue, in this work we present a query-driven code recommendation tool, named Que2Code, that identifies the best code snippets for a user query from Stack Overflow posts. Our approach has two main stages: (i) semantically-equivalent question retrieval and (ii) best code snippet recommendation. To evaluate the performance of our proposed model, we conduct a large scale experiment to evaluate the effectiveness of the semantically-equivalent question retrieval task and best code snippet recommendation task separately on Python and Java datasets in Stack Overflow. We also perform a human study to measure how real-world developers perceive the results generated by our model. Both the automatic and human evaluation results demonstrate the promising performance of our model, and we have released our code and data to assist other researchers. ",
    "url": "https://arxiv.org/abs/2210.15845",
    "authors": [
      "Zhipeng Gao",
      "Xin Xia",
      "David Lo",
      "John Grundy",
      "Xindong Zhang",
      "Zhenchang Xing"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.15847",
    "title": "Distributed Optimal Control of Graph Symmetric Systems via Graph Filters",
    "abstract": "Designing distributed optimal controllers subject to communication constraints is a difficult problem unless structural assumptions are imposed on the underlying dynamics and information exchange structure, e.g., sparsity, delay, or spatial invariance. In this paper, we borrow ideas from graph signal processing and define and analyze a class of Graph Symmetric Systems (GSSs), which are systems that are symmetric with respect to an underlying graph topology. We show that for linear quadratic problems subject to dynamics defined by a GSS, the optimal centralized controller is given by a novel class of graph filters with transfer function valued filter taps and can be implemented via distributed message passing. We then propose several methods for approximating the optimal centralized graph filter by a distributed controller only requiring communication with a small subset of neighboring subsystems. We further provide stability and suboptimality guarantees for the resulting distributed controllers. Finally, we empirically demonstrate that our approach allows for a principled tradeoff between communication cost and performance while guaranteeing stability. Our results can be viewed as a first step towards bridging the fields of distributed optimal control and graph signal processing. ",
    "url": "https://arxiv.org/abs/2210.15847",
    "authors": [
      "Fengjun Yang",
      "Fernando Gama",
      "Somayeh Sojoudi",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15849",
    "title": "Local-global speaker representation for target speaker extraction",
    "abstract": "Target speaker extraction is to extract the target speaker's voice from a mixture of signals according to the given enrollment utterance. The target speaker's enrollment utterance is also called as anchor speech. The effective utilization of anchor speech is crucial for speaker extraction. In this study, we propose a new system to exploit speaker information from anchor speech fully. Unlike models that use only local or global features of the anchor, the proposed method extracts speaker information on global and local levels and feeds the features into a speech separation network. Our approach benefits from the complementary advantages of both global and local features, and the performance of speaker extraction is improved. We verified the feasibility of this local-global representation (LGR) method using multiple speaker extraction models. Systematic experiments were conducted on the open-source dataset Libri-2talker, and the results showed that the proposed method significantly outperformed the baseline models. ",
    "url": "https://arxiv.org/abs/2210.15849",
    "authors": [
      "Shulin He",
      "Wei Rao",
      "Kanghao Zhang",
      "Yukai Ju",
      "Yang Yang",
      "Xueliang Zhang",
      "Yannan Wang",
      "Shidong Shang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15850",
    "title": "Federated Learning based Energy Demand Prediction with Clustered  Aggregation",
    "abstract": "To reduce negative environmental impacts, power stations and energy grids need to optimize the resources required for power production. Thus, predicting the energy consumption of clients is becoming an important part of every energy management system. Energy usage information collected by the clients' smart homes can be used to train a deep neural network to predict the future energy demand. Collecting data from a large number of distributed clients for centralized model training is expensive in terms of communication resources. To take advantage of distributed data in edge systems, centralized training can be replaced by federated learning where each client only needs to upload model updates produced by training on its local data. These model updates are aggregated into a single global model by the server. But since different clients can have different attributes, model updates can have diverse weights and as a result, it can take a long time for the aggregated global model to converge. To speed up the convergence process, we can apply clustering to group clients based on their properties and aggregate model updates from the same cluster together to produce a cluster specific global model. In this paper, we propose a recurrent neural network based energy demand predictor, trained with federated learning on clustered clients to take advantage of distributed data and speed up the convergence process. ",
    "url": "https://arxiv.org/abs/2210.15850",
    "authors": [
      "Ye Lin Tun",
      "Kyi Thar",
      "Chu Myaet Thwal",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.15853",
    "title": "Speech Enhancement with Intelligent Neural Homomorphic Synthesis",
    "abstract": "Most neural network speech enhancement models ignore speech production mathematical models by directly mapping Fourier transform spectrums or waveforms. In this work, we propose a neural source filter network for speech enhancement. Specifically, we use homomorphic signal processing and cepstral analysis to obtain noisy speech's excitation and vocal tract. Unlike traditional signal processing, we use an attentive recurrent network (ARN) model predicted ratio mask to replace the liftering separation function. Then two convolutional attentive recurrent network (CARN) networks are used to predict the excitation and vocal tract of clean speech, respectively. The system's output is synthesized from the estimated excitation and vocal. Experiments prove that our proposed method performs better, with SI-SNR improving by 1.363dB compared to FullSubNet. ",
    "url": "https://arxiv.org/abs/2210.15853",
    "authors": [
      "Shulin He",
      "Wei Rao",
      "Jinjiang Liu",
      "Jun Chen",
      "Yukai Ju",
      "Xueliang Zhang",
      "Yannan Wang",
      "Shidong Shang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15858",
    "title": "Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit  Representation",
    "abstract": "In this work, we present a dense tracking and mapping system named Vox-Fusion, which seamlessly fuses neural implicit representations with traditional volumetric fusion methods. Our approach is inspired by the recently developed implicit mapping and positioning system and further extends the idea so that it can be freely applied to practical scenarios. Specifically, we leverage a voxel-based neural implicit surface representation to encode and optimize the scene inside each voxel. Furthermore, we adopt an octree-based structure to divide the scene and support dynamic expansion, enabling our system to track and map arbitrary scenes without knowing the environment like in previous works. Moreover, we proposed a high-performance multi-process framework to speed up the method, thus supporting some applications that require real-time performance. The evaluation results show that our methods can achieve better accuracy and completeness than previous methods. We also show that our Vox-Fusion can be used in augmented reality and virtual reality applications. Our source code is publicly available at https://github.com/zju3dv/Vox-Fusion. ",
    "url": "https://arxiv.org/abs/2210.15858",
    "authors": [
      "Xingrui Yang",
      "Hai Li",
      "Hongjia Zhai",
      "Yuhang Ming",
      "Yuqian Liu",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15865",
    "title": "Completely Heterogeneous Federated Learning",
    "abstract": "Federated learning (FL) faces three major difficulties: cross-domain, heterogeneous models, and non-i.i.d. labels scenarios. Existing FL methods fail to handle the above three constraints at the same time, and the level of privacy protection needs to be lowered (e.g., the model architecture and data category distribution can be shared). In this work, we propose the challenging \"completely heterogeneous\" scenario in FL, which refers to that each client will not expose any private information including feature space, model architecture, and label distribution. We then devise an FL framework based on parameter decoupling and data-free knowledge distillation to solve the problem. Experiments show that our proposed method achieves high performance in completely heterogeneous scenarios where other approaches fail. ",
    "url": "https://arxiv.org/abs/2210.15865",
    "authors": [
      "Chang Liu",
      "Yuwen Yang",
      "Xun Cai",
      "Yue Ding",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.15872",
    "title": "Exploring Spatial-Temporal Features for Deepfake Detection and  Localization",
    "abstract": "With the continuous research on Deepfake forensics, recent studies have attempted to provide the fine-grained localization of forgeries, in addition to the coarse classification at the video-level. However, the detection and localization performance of existing Deepfake forensic methods still have plenty of room for further improvement. In this work, we propose a Spatial-Temporal Deepfake Detection and Localization (ST-DDL) network that simultaneously explores spatial and temporal features for detecting and localizing forged regions. Specifically, we design a new Anchor-Mesh Motion (AMM) algorithm to extract temporal (motion) features by modeling the precise geometric movements of the facial micro-expression. Compared with traditional motion extraction methods (e.g., optical flow) designed to simulate large-moving objects, our proposed AMM could better capture the small-displacement facial features. The temporal features and the spatial features are then fused in a Fusion Attention (FA) module based on a Transformer architecture for the eventual Deepfake forensic tasks. The superiority of our ST-DDL network is verified by experimental comparisons with several state-of-the-art competitors, in terms of both video- and pixel-level detection and localization performance. Furthermore, to impel the future development of Deepfake forensics, we build a public forgery dataset consisting of 6000 videos, with many new features such as using widely-used commercial software (e.g., After Effects) for the production, providing online social networks transmitted versions, and splicing multi-source videos. The source code and dataset are available at https://github.com/HighwayWu/ST-DDL. ",
    "url": "https://arxiv.org/abs/2210.15872",
    "authors": [
      "Wu Haiwei",
      "Zhou Jiantao",
      "Zhang Shile",
      "Tian Jinyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.15878",
    "title": "Facial Action Unit Detection and Intensity Estimation from  Self-supervised Representation",
    "abstract": "As a fine-grained and local expression behavior measurement, facial action unit (FAU) analysis (e.g., detection and intensity estimation) has been documented for its time-consuming, labor-intensive, and error-prone annotation. Thus a long-standing challenge of FAU analysis arises from the data scarcity of manual annotations, limiting the generalization ability of trained models to a large extent. Amounts of previous works have made efforts to alleviate this issue via semi/weakly supervised methods and extra auxiliary information. However, these methods still require domain knowledge and have not yet avoided the high dependency on data annotation. This paper introduces a robust facial representation model MAE-Face for AU analysis. Using masked autoencoding as the self-supervised pre-training approach, MAE-Face first learns a high-capacity model from a feasible collection of face images without additional data annotations. Then after being fine-tuned on AU datasets, MAE-Face exhibits convincing performance for both AU detection and AU intensity estimation, achieving a new state-of-the-art on nearly all the evaluation results. Further investigation shows that MAE-Face achieves decent performance even when fine-tuned on only 1\\% of the AU training set, strongly proving its robustness and generalization performance. ",
    "url": "https://arxiv.org/abs/2210.15878",
    "authors": [
      "Bowen Ma",
      "Rudong An",
      "Wei Zhang",
      "Yu Ding",
      "Zeng Zhao",
      "Rongsheng Zhang",
      "Tangjie Lv",
      "Changjie Fan",
      "Zhipeng Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15879",
    "title": "Complex Handwriting Trajectory Recovery: Evaluation Metrics and  Algorithm",
    "abstract": "Many important tasks such as forensic signature verification, calligraphy synthesis, etc, rely on handwriting trajectory recovery of which, however, even an appropriate evaluation metric is still missing. Indeed, existing metrics only focus on the writing orders but overlook the fidelity of glyphs. Taking both facets into account, we come up with two new metrics, the adaptive intersection on union (AIoU) which eliminates the influence of various stroke widths, and the length-independent dynamic time warping (LDTW) which solves the trajectory-point alignment problem. After that, we then propose a novel handwriting trajectory recovery model named Parsing-and-tracing ENcoder-decoder Network (PEN-Net), in particular for characters with both complex glyph and long trajectory, which was believed very challenging. In the PEN-Net, a carefully designed double-stream parsing encoder parses the glyph structure, and a global tracing decoder overcomes the memory difficulty of long trajectory prediction. Our experiments demonstrate that the two new metrics AIoU and LDTW together can truly assess the quality of handwriting trajectory recovery and the proposed PEN-Net exhibits satisfactory performance in various complex-glyph languages including Chinese, Japanese and Indic. ",
    "url": "https://arxiv.org/abs/2210.15879",
    "authors": [
      "Zhounan Chen",
      "Daihui Yang",
      "Jinglin Liang",
      "Xinwu Liu",
      "Yuyi Wang",
      "Zhenghua Peng",
      "Shuangping Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15898",
    "title": "Toward Equation of Motion for Deep Neural Networks: Continuous-time  Gradient Descent and Discretization Error Analysis",
    "abstract": "We derive and solve an ``Equation of Motion'' (EoM) for deep neural networks (DNNs), a differential equation that precisely describes the discrete learning dynamics of DNNs. Differential equations are continuous but have played a prominent role even in the study of discrete optimization (gradient descent (GD) algorithms). However, there still exist gaps between differential equations and the actual learning dynamics of DNNs due to discretization error. In this paper, we start from gradient flow (GF) and derive a counter term that cancels the discretization error between GF and GD. As a result, we obtain EoM, a continuous differential equation that precisely describes the discrete learning dynamics of GD. We also derive discretization error to show to what extent EoM is precise. In addition, we apply EoM to two specific cases: scale- and translation-invariant layers. EoM highlights differences between continuous-time and discrete-time GD, indicating the importance of the counter term for a better description of the discrete learning dynamics of GD. Our experimental results support our theoretical findings. ",
    "url": "https://arxiv.org/abs/2210.15898",
    "authors": [
      "Taiki Miyagawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15904",
    "title": "Self-Supervised Learning with Multi-View Rendering for 3D Point Cloud  Analysis",
    "abstract": "Recently, great progress has been made in 3D deep learning with the emergence of deep neural networks specifically designed for 3D point clouds. These networks are often trained from scratch or from pre-trained models learned purely from point cloud data. Inspired by the success of deep learning in the image domain, we devise a novel pre-training technique for better model initialization by utilizing the multi-view rendering of the 3D data. Our pre-training is self-supervised by a local pixel/point level correspondence loss computed from perspective projection and a global image/point cloud level loss based on knowledge distillation, thus effectively improving upon popular point cloud networks, including PointNet, DGCNN and SR-UNet. These improved models outperform existing state-of-the-art methods on various datasets and downstream tasks. We also analyze the benefits of synthetic and real data for pre-training, and observe that pre-training on synthetic data is also useful for high-level downstream tasks. Code and pre-trained models are available at https://github.com/VinAIResearch/selfsup_pcd. ",
    "url": "https://arxiv.org/abs/2210.15904",
    "authors": [
      "Bach Tran",
      "Binh-Son Hua",
      "Anh Tuan Tran",
      "Minh Hoai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.15911",
    "title": "Joint Semantic Transfer Network for IoT Intrusion Detection",
    "abstract": "In this paper, we propose a Joint Semantic Transfer Network (JSTN) towards effective intrusion detection for large-scale scarcely labelled IoT domain. As a multi-source heterogeneous domain adaptation (MS-HDA) method, the JSTN integrates a knowledge rich network intrusion (NI) domain and another small-scale IoT intrusion (II) domain as source domains, and preserves intrinsic semantic properties to assist target II domain intrusion detection. The JSTN jointly transfers the following three semantics to learn a domain-invariant and discriminative feature representation. The scenario semantic endows source NI and II domain with characteristics from each other to ease the knowledge transfer process via a confused domain discriminator and categorical distribution knowledge preservation. It also reduces the source-target discrepancy to make the shared feature space domain-invariant. Meanwhile, the weighted implicit semantic transfer boosts discriminability via a fine-grained knowledge preservation, which transfers the source categorical distribution to the target domain. The source-target divergence guides the importance weighting during knowledge preservation to reflect the degree of knowledge learning. Additionally, the hierarchical explicit semantic alignment performs centroid-level and representative-level alignment with the help of a geometric similarity-aware pseudo-label refiner, which exploits the value of unlabelled target II domain and explicitly aligns feature representations from a global and local perspective in a concentrated manner. Comprehensive experiments on various tasks verify the superiority of the JSTN against state-of-the-art comparing methods, on average a 10.3% of accuracy boost is achieved. The statistical soundness of each constituting component and the computational efficiency are also verified. ",
    "url": "https://arxiv.org/abs/2210.15911",
    "authors": [
      "Jiashu Wu",
      "Yang Wang",
      "Binhui Xie",
      "Shuang Li",
      "Hao Dai",
      "Kejiang Ye",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15913",
    "title": "GeoGCN: Geometric Dual-domain Graph Convolution Network for Point Cloud  Denoising",
    "abstract": "We propose GeoGCN, a novel geometric dual-domain graph convolution network for point cloud denoising (PCD). Beyond the traditional wisdom of PCD, to fully exploit the geometric information of point clouds, we define two kinds of surface normals, one is called Real Normal (RN), and the other is Virtual Normal (VN). RN preserves the local details of noisy point clouds while VN avoids the global shape shrinkage during denoising. GeoGCN is a new PCD paradigm that, 1) first regresses point positions by spatialbased GCN with the help of VNs, 2) then estimates initial RNs by performing Principal Component Analysis on the regressed points, and 3) finally regresses fine RNs by normalbased GCN. Unlike existing PCD methods, GeoGCN not only exploits two kinds of geometry expertise (i.e., RN and VN) but also benefits from training data. Experiments validate that GeoGCN outperforms SOTAs in terms of both noise-robustness and local-and-global feature preservation. ",
    "url": "https://arxiv.org/abs/2210.15913",
    "authors": [
      "Zhaowei Chen",
      "Peng Li",
      "Zeyong Wei",
      "Honghua Chen",
      "Haoran Xie",
      "Mingqiang Wei",
      "Fu Lee Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15933",
    "title": "PSFormer: Point Transformer for 3D Salient Object Detection",
    "abstract": "We propose PSFormer, an effective point transformer model for 3D salient object detection. PSFormer is an encoder-decoder network that takes full advantage of transformers to model the contextual information in both multi-scale point- and scene-wise manners. In the encoder, we develop a Point Context Transformer (PCT) module to capture region contextual features at the point level; PCT contains two different transformers to excavate the relationship among points. In the decoder, we develop a Scene Context Transformer (SCT) module to learn context representations at the scene level; SCT contains both Upsampling-and-Transformer blocks and Multi-context Aggregation units to integrate the global semantic and multi-level features from the encoder into the global scene context. Experiments show clear improvements of PSFormer over its competitors and validate that PSFormer is more robust to challenging cases such as small objects, multiple objects, and objects with complex structures. ",
    "url": "https://arxiv.org/abs/2210.15933",
    "authors": [
      "Baian Chen",
      "Lipeng Gu",
      "Xin Zhuang",
      "Yiyang Shen",
      "Weiming Wang",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15936",
    "title": "A comprehensive study on self-supervised distillation for speaker  representation learning",
    "abstract": "In real application scenarios, it is often challenging to obtain a large amount of labeled data for speaker representation learning due to speaker privacy concerns. Self-supervised learning with no labels has become a more and more promising way to solve it. Compared with contrastive learning, self-distilled approaches use only positive samples in the loss function and thus are more attractive. In this paper, we present a comprehensive study on self-distilled self-supervised speaker representation learning, especially on critical data augmentation. Our proposed strategy of audio perturbation augmentation has pushed the performance of the speaker representation to a new limit. The experimental results show that our model can achieve a new SoTA on Voxceleb1 speaker verification evaluation benchmark ( i.e., equal error rate (EER) 2.505%, 2.473%, and 4.791% for trial Vox1-O, Vox1-E and Vox1-H , respectively), discarding any speaker labels in the training phase. ",
    "url": "https://arxiv.org/abs/2210.15936",
    "authors": [
      "Zhengyang Chen",
      "Yao Qian",
      "Bing Han",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15944",
    "title": "RoChBert: Towards Robust BERT Fine-tuning for Chinese",
    "abstract": "Despite of the superb performance on a wide range of tasks, pre-trained language models (e.g., BERT) have been proved vulnerable to adversarial texts. In this paper, we present RoChBERT, a framework to build more Robust BERT-based models by utilizing a more comprehensive adversarial graph to fuse Chinese phonetic and glyph features into pre-trained representations during fine-tuning. Inspired by curriculum learning, we further propose to augment the training dataset with adversarial texts in combination with intermediate samples. Extensive experiments demonstrate that RoChBERT outperforms previous methods in significant ways: (i) robust -- RoChBERT greatly improves the model robustness without sacrificing accuracy on benign texts. Specifically, the defense lowers the success rates of unlimited and limited attacks by 59.43% and 39.33% respectively, while remaining accuracy of 93.30%; (ii) flexible -- RoChBERT can easily extend to various language models to solve different downstream tasks with excellent performance; and (iii) efficient -- RoChBERT can be directly applied to the fine-tuning stage without pre-training language model from scratch, and the proposed data augmentation method is also low-cost. ",
    "url": "https://arxiv.org/abs/2210.15944",
    "authors": [
      "Zihan Zhang",
      "Jinfeng Li",
      "Ning Shi",
      "Bo Yuan",
      "Xiangyu Liu",
      "Rong Zhang",
      "Hui Xue",
      "Donghong Sun",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15947",
    "title": "NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed  Neural Radiance Fields",
    "abstract": "Visually exploring in a real-world 4D spatiotemporal space freely in VR has been a long-term quest. The task is especially appealing when only a few or even single RGB cameras are used for capturing the dynamic scene. To this end, we present an efficient framework capable of fast reconstruction, compact modeling, and streamable rendering. First, we propose to decompose the 4D spatiotemporal space according to temporal characteristics. Points in the 4D space are associated with probabilities of belonging to three categories: static, deforming, and new areas. Each area is represented and regularized by a separate neural field. Second, we propose a hybrid representations based feature streaming scheme for efficiently modeling the neural fields. Our approach, coined NeRFPlayer, is evaluated on dynamic scenes captured by single hand-held cameras and multi-camera arrays, achieving comparable or superior rendering performance in terms of quality and speed comparable to recent state-of-the-art methods, achieving reconstruction in 10 seconds per frame and real-time rendering. ",
    "url": "https://arxiv.org/abs/2210.15947",
    "authors": [
      "Liangchen Song",
      "Anpei Chen",
      "Zhong Li",
      "Zhang Chen",
      "Lele Chen",
      "Junsong Yuan",
      "Yi Xu",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.15956",
    "title": "Generalized Laplacian Positional Encoding for Graph Representation  Learning",
    "abstract": "Graph neural networks (GNNs) are the primary tool for processing graph-structured data. Unfortunately, the most commonly used GNNs, called Message Passing Neural Networks (MPNNs) suffer from several fundamental limitations. To overcome these limitations, recent works have adapted the idea of positional encodings to graph data. This paper draws inspiration from the recent success of Laplacian-based positional encoding and defines a novel family of positional encoding schemes for graphs. We accomplish this by generalizing the optimization problem that defines the Laplace embedding to more general dissimilarity functions rather than the 2-norm used in the original formulation. This family of positional encodings is then instantiated by considering p-norms. We discuss a method for calculating these positional encoding schemes, implement it in PyTorch and demonstrate how the resulting positional encoding captures different properties of the graph. Furthermore, we demonstrate that this novel family of positional encodings can improve the expressive power of MPNNs. Lastly, we present preliminary experimental results. ",
    "url": "https://arxiv.org/abs/2210.15956",
    "authors": [
      "Sohir Maskey",
      "Ali Parviz",
      "Maximilian Thiessen",
      "Hannes St\u00e4rk",
      "Ylli Sadikaj",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15958",
    "title": "Modular Model Reduction of Interconnected Systems: A Robust Performance  Analysis Perspective",
    "abstract": "Many complex engineering systems consist of multiple subsystems that are developed by different teams of engineers. To analyse, simulate and control such complex systems, accurate yet computationally efficient models are required. Modular model reduction, in which the subsystem models are reduced individually, is a practical and an efficient method to obtain accurate reduced-order models of such complex systems. However, when subsystems are reduced individually, without taking their interconnections into account, the effect on stability and accuracy of the resulting reduced-order interconnected system is difficult to predict. In this work, a mathematical relation between the accuracy of reduced-order linear-time invariant subsystem models and (stability and accuracy of) resulting reduced-order interconnected linear time-invariant model is introduced. This result can subsequently be used in two ways. Firstly, it can be used to translate accuracy characteristics of the reduced-order subsystem models directly to accuracy properties of the interconnected reduced-order model. Secondly, it can also be used to translate specifications on the interconnected system model accuracy to accuracy requirements on subsystem models that can be used for fit-for-purpose reduction of the subsystem models. These applications of the proposed analysis framework for modular model reduction are demonstrated on an illustrative structural dynamics example. ",
    "url": "https://arxiv.org/abs/2210.15958",
    "authors": [
      "Lars A.L. Janssen",
      "Bart Besselink",
      "Rob H.B. Fey",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15965",
    "title": "System Network Analytics: Evolution and Stable Rules of a State Series",
    "abstract": "System Evolution Analytics on a system that evolves is a challenge because it makes a State Series SS = {S1, S2... SN} (i.e., a set of states ordered by time) with several inter-connected entities changing over time. We present stability characteristics of interesting evolution rules occurring in multiple states. We defined an evolution rule with its stability as the fraction of states in which the rule is interesting. Extensively, we defined stable rule as the evolution rule having stability that exceeds a given threshold minimum stability (minStab). We also defined persistence metric, a quantitative measure of persistent entity-connections. We explain this with an approach and algorithm for System Network Analytics (SysNet-Analytics), which uses minStab to retrieve Network Evolution Rules (NERs) and Stable NERs (SNERs). The retrieved information is used to calculate a proposed System Network Persistence (SNP) metric. This work is automated as a SysNet-Analytics Tool to demonstrate application on real world systems including: software system, natural-language system, retail market system, and IMDb system. We quantified stability and persistence of entity-connections in a system state series. This results in evolution information, which helps in system evolution analytics based on knowledge discovery and data mining. ",
    "url": "https://arxiv.org/abs/2210.15965",
    "authors": [
      "Animesh Chaturvedi",
      "Aruna Tiwari",
      "Nicolas Spyratos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.15972",
    "title": "Contextual Learning in Fourier Complex Field for VHR Remote Sensing  Images",
    "abstract": "Very high-resolution (VHR) remote sensing (RS) image classification is the fundamental task for RS image analysis and understanding. Recently, transformer-based models demonstrated outstanding potential for learning high-order contextual relationships from natural images with general resolution (224x224 pixels) and achieved remarkable results on general image classification tasks. However, the complexity of the naive transformer grows quadratically with the increase in image size, which prevents transformer-based models from VHR RS image (500x500 pixels) classification and other computationally expensive downstream tasks. To this end, we propose to decompose the expensive self-attention (SA) into real and imaginary parts via discrete Fourier transform (DFT) and therefore propose an efficient complex self-attention (CSA) mechanism. Benefiting from the conjugated symmetric property of DFT, CSA is capable to model the high-order contextual information with less than half computations of naive SA. To overcome the gradient explosion in Fourier complex field, we replace the Softmax function with the carefully designed Logmax function to normalize the attention map of CSA and stabilize the gradient propagation. By stacking various layers of CSA blocks, we propose the Fourier Complex Transformer (FCT) model to learn global contextual information from VHR aerial images following the hierarchical manners. Universal experiments conducted on commonly used RS classification data sets demonstrate the effectiveness and efficiency of FCT, especially on very high-resolution RS images. ",
    "url": "https://arxiv.org/abs/2210.15972",
    "authors": [
      "Yan Zhang",
      "Xiyuan Gao",
      "Qingyan Duan",
      "Jiaxu Leng",
      "Xiao Pu",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15976",
    "title": "BEBERT: Efficient and robust binary ensemble BERT",
    "abstract": "Pre-trained BERT models have achieved impressive accuracy on natural language processing (NLP) tasks. However, their excessive amount of parameters hinders them from efficient deployment on edge devices. Binarization of the BERT models can significantly alleviate this issue but comes with a severe accuracy drop compared with their full-precision counterparts. In this paper, we propose an efficient and robust binary ensemble BERT (BEBERT) to bridge the accuracy gap. To the best of our knowledge, this is the first work employing ensemble techniques on binary BERTs, yielding BEBERT, which achieves superior accuracy while retaining computational efficiency. Furthermore, we remove the knowledge distillation procedures during ensemble to speed up the training process without compromising accuracy. Experimental results on the GLUE benchmark show that the proposed BEBERT significantly outperforms the existing binary BERT models in accuracy and robustness with a 2x speedup on training time. Moreover, our BEBERT has only a negligible accuracy loss of 0.3% compared to the full-precision baseline while saving 15x and 13x in FLOPs and model size, respectively. In addition, BEBERT also outperforms other compressed BERTs in accuracy by up to 6.7%. ",
    "url": "https://arxiv.org/abs/2210.15976",
    "authors": [
      "Jiayi Tian",
      "Chao Fang",
      "Haonan Wang",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15985",
    "title": "Understanding Adverse Biological Effect Predictions Using Knowledge  Graphs",
    "abstract": "Extrapolation of adverse biological (toxic) effects of chemicals is an important contribution to expand available hazard data in (eco)toxicology without the use of animals in laboratory experiments. In this work, we extrapolate effects based on a knowledge graph (KG) consisting of the most relevant effect data as domain-specific background knowledge. An effect prediction model, with and without background knowledge, was used to predict mean adverse biological effect concentration of chemicals as a prototypical type of stressors. The background knowledge improves the model prediction performance by up to 40\\% in terms of $R^2$ (\\ie coefficient of determination). We use the KG and KG embeddings to provide quantitative and qualitative insights into the predictions. These insights are expected to improve the confidence in effect prediction. Larger scale implementation of such extrapolation models should be expected to support hazard and risk assessment, by simplifying and reducing testing needs. ",
    "url": "https://arxiv.org/abs/2210.15985",
    "authors": [
      "Erik Bryhn Myklebust",
      "Ernesto Jimenez-Ruiz",
      "Jiaoyan Chen",
      "Raoul Wolf",
      "Knut Erik Tollefsen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.15996",
    "title": "Towards Few-Shot Open-Set Object Detection",
    "abstract": "Open-set object detection (OSOD) aims to detect the known categories and identify unknown objects in a dynamic world, which has achieved significant attentions. However, previous approaches only consider this problem in data-abundant conditions. We seek a solution for few-shot open-set object detection (FSOSOD), which aims to quickly train a detector based on few samples while detecting all known classes and identifying unknown classes. The main challenge for this task is that few training samples tend to overfit on the known classes, and lead to poor open-set performance. We propose a new FSOSOD algorithm to tackle this issue, named FOOD, which contains a novel class dropout cosine classifier (CDCC) and a novel unknown decoupling learner (UDL). To prevent over-fitting, CDCC randomly inactivates parts of the normalized neurons for the logit prediction of all classes, and then decreases the co-adaptability between the class and its neighbors. Alongside, UDL decouples training the unknown class and enables the model to form a compact unknown decision boundary. Thus, the unknown objects can be identified with a confidence probability without any pseudo-unknown samples for training. We compare our method with several state-of-the-art OSOD methods in few-shot scenes and observe that our method improves the recall of unknown classes by 5%-9% across all shots in VOC-COCO dataset setting. ",
    "url": "https://arxiv.org/abs/2210.15996",
    "authors": [
      "Binyi Su",
      "Hua Zhang",
      "Zhong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15997",
    "title": "Universal Adversarial Directions",
    "abstract": "Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure UAD strategy, implying the potential transferability of UADs. We also connect the UAD optimization problem to the well-known principal component analysis (PCA) and develop an efficient PCA-based algorithm for optimizing UADs. We evaluate UADs over multiple benchmark image datasets. Our numerical results show the superior transferability of UADs over standard gradient-based UAPs. ",
    "url": "https://arxiv.org/abs/2210.15997",
    "authors": [
      "Ching Lam Choi",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.15999",
    "title": "Benchmarking performance of object detection under image distortions in  an uncontrolled environment",
    "abstract": "The robustness of object detection algorithms plays a prominent role in real-world applications, especially in uncontrolled environments due to distortions during image acquisition. It has been proven that the performance of object detection methods suffers from in-capture distortions. In this study, we present a performance evaluation framework for the state-of-the-art object detection methods using a dedicated dataset containing images with various distortions at different levels of severity. Furthermore, we propose an original strategy of image distortion generation applied to the MS-COCO dataset that combines some local and global distortions to reach much better performances. We have shown that training using the proposed dataset improves the robustness of object detection by 31.5\\%. Finally, we provide a custom dataset including natural images distorted from MS-COCO to perform a more reliable evaluation of the robustness against common distortions. The database and the generation source codes of the different distortions are made publicly available ",
    "url": "https://arxiv.org/abs/2210.15999",
    "authors": [
      "Ayman Beghdadi",
      "Malik Mallem",
      "Lotfi Beji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.16002",
    "title": "An Online Learning Approach for Vehicle Usage Prediction During COVID-19",
    "abstract": "Today, there is an ongoing transition to more sustainable transportation, and an essential part of this transition is the switch from combustion engine vehicles to battery electric vehicles (BEVs). BEVs have many advantages from a sustainability perspective, but issues such as limited driving range and long recharge times slow down the transition from combustion engines. One way to mitigate these issues is by performing battery thermal preconditioning, which increases the energy efficiency of the battery. However, to optimally perform battery thermal preconditioning, the vehicle usage pattern needs to be known, i.e., how and when the vehicle will be used. This study attempts to predict the departure time and distance of the first drive each day using different online machine learning models. The online machine learning models are trained and evaluated on historical driving data collected from a fleet of BEVs during the COVID-19 pandemic. Additionally, the prediction models are extended to quantify the uncertainty of their predictions, which can be used as guidance to whether the prediction should be used or dismissed. We show that the best-performing prediction models yield an aggregated mean absolute error of 2.75 hours when predicting departure time and 13.37 km when predicting trip distance. ",
    "url": "https://arxiv.org/abs/2210.16002",
    "authors": [
      "Tobias Lindroth",
      "Axel Svensson",
      "Niklas \u00c5kerblom",
      "Mitra Pourabdollah",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16018",
    "title": "Code4ML: a Large-scale Dataset of annotated Machine Learning Code",
    "abstract": "Program code as a data source is gaining popularity in the data science community. Possible applications for models trained on such assets range from classification for data dimensionality reduction to automatic code generation. However, without annotation number of methods that could be applied is somewhat limited. To address the lack of annotated datasets, we present the Code4ML corpus. It contains code snippets, task summaries, competitions and dataset descriptions publicly available from Kaggle - the leading platform for hosting data science competitions. The corpus consists of ~2.5 million snippets of ML code collected from ~100 thousand Jupyter notebooks. A representative fraction of the snippets is annotated by human assessors through a user-friendly interface specially designed for that purpose. Code4ML dataset can potentially help address a number of software engineering or data science challenges through a data-driven approach. For example, it can be helpful for semantic code classification, code auto-completion, and code generation for an ML task specified in natural language. ",
    "url": "https://arxiv.org/abs/2210.16018",
    "authors": [
      "Anastasia Drozdova",
      "Polina Guseva",
      "Ekaterina Trofimova",
      "Anna Scherbakova",
      "Andrey Ustyuzhanin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.16034",
    "title": "A Survey on Causal Representation Learning and Future Work for Medical  Image Analysis",
    "abstract": "Statistical machine learning algorithms have achieved state-of-the-art results on benchmark datasets, outperforming humans in many tasks. However, the out-of-distribution data and confounder, which have an unpredictable causal relationship, significantly degrade the performance of the existing models. Causal Representation Learning (CRL) has recently been a promising direction to address the causal relationship problem in vision understanding. This survey presents recent advances in CRL in vision. Firstly, we introduce the basic concept of causal inference. Secondly, we analyze the CRL theoretical work, especially in invariant risk minimization, and the practical work in feature understanding and transfer learning. Finally, we propose a future research direction in medical image analysis and CRL general theory. ",
    "url": "https://arxiv.org/abs/2210.16034",
    "authors": [
      "Changjie Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16038",
    "title": "Deep Learning-Based Anomaly Detection in Synthetic Aperture Radar  Imaging",
    "abstract": "In this paper, we proposed to investigate unsupervised anomaly detection in Synthetic Aperture Radar (SAR) images. Our approach considers anomalies as abnormal patterns that deviate from their surroundings but without any prior knowledge of their characteristics. In the literature, most model-based algorithms face three main issues. First, the speckle noise corrupts the image and potentially leads to numerous false detections. Second, statistical approaches may exhibit deficiencies in modeling spatial correlation in SAR images. Finally, neural networks based on supervised learning approaches are not recommended due to the lack of annotated SAR data, notably for the class of abnormal patterns. Our proposed method aims to address these issues through a self-supervised algorithm. The speckle is first removed through the deep learning SAR2SAR algorithm. Then, an adversarial autoencoder is trained to reconstruct an anomaly-free SAR image. Finally, a change detection processing step is applied between the input and the output to detect anomalies. Experiments are performed to show the advantages of our method compared to the conventional Reed-Xiaoli algorithm, highlighting the importance of an efficient despeckling pre-processing step. ",
    "url": "https://arxiv.org/abs/2210.16038",
    "authors": [
      "Max Muzeau",
      "Chengfang Ren",
      "S\u00e9bastien Angelliaume",
      "Mihai Datcu",
      "Jean-Philippe Ovarlez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.16041",
    "title": "Centralization Problem for Opinion Convergence in Decentralized Networks",
    "abstract": "This paper aims to provide a new perspective on the interplay between decentralization -- a prevalent character of multi-agent systems -- and centralization, i.e., the task of imposing central control to meet system-level goals. In particular, in the context of networked opinion dynamic model, the paper proposes and discusses a framework for centralization. More precisely, a decentralized network consists of autonomous agents and their social structure that is unknown and dynamic. Centralization is a process of appointing agents in the network to act as access units who provide information and exert influence over their local surroundings. We discuss centralization for the DeGroot model of opinion dynamics, aiming to enforce opinion convergence using the minimum number of access units. We show that the key to the centralization process lies in selecting access units so that they form a dominating set. We then propose algorithms under a new local algorithmic framework, namely prowling, to accomplish this task. To validate our algorithm, we perform systematic experiments over both real-world and synthetic networks and verify that our algorithm outperforms benchmarks. ",
    "url": "https://arxiv.org/abs/2210.16041",
    "authors": [
      "Yiping Liu",
      "Jiamou Liu",
      "Bakhadyr Khoussaino",
      "Miao Qiao",
      "Bo Yan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.16043",
    "title": "Analyzing Acoustic Word Embeddings from Pre-trained Self-supervised  Speech Models",
    "abstract": "Given the strong results of self-supervised models on various tasks, there have been surprisingly few studies exploring self-supervised representations for acoustic word embeddings (AWE), fixed-dimensional vectors representing variable-length spoken word segments. In this work, we study several pre-trained models and pooling methods for constructing AWEs with self-supervised representations. Owing to the contextualized nature of self-supervised representations, we hypothesize that simple pooling methods, such as averaging, might already be useful for constructing AWEs. When evaluating on a standard word discrimination task, we find that HuBERT representations with mean-pooling rival the state of the art on English AWEs. More surprisingly, despite being trained only on English, HuBERT representations evaluated on Xitsonga, Mandarin, and French consistently outperform the multilingual model XLSR-53 (as well as Wav2Vec 2.0 trained on English). ",
    "url": "https://arxiv.org/abs/2210.16043",
    "authors": [
      "Ramon Sanabria",
      "Hao Tang",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.16046",
    "title": "Rawgment: Noise-Accounted RAW Augmentation Enables Recognition in a Wide  Variety of Environments",
    "abstract": "Image recognition models that can work in challenging environments (e.g., extremely dark, blurry, or high dynamic range conditions) must be useful. However, creating a training dataset for such environments is expensive and hard due to the difficulties of data collection and annotation. It is desirable if we could get a robust model without the need of hard-to-obtain dataset. One simple approach is to apply data augmentation such as color jitter and blur to standard RGB (sRGB) images in simple scenes. Unfortunately, this approach struggles to yield realistic images in terms of pixel intensity and noise distribution due to not considering the non-linearity of Image Signal Processor (ISP) and noise characteristics of an image sensor. Instead, we propose a noise-accounted RAW image augmentation method. In essence, color jitter and blur augmentation are applied to a RAW image before applying non-linear ISP, yielding realistic intensity. Furthermore, we introduce a noise amount alignment method that calibrates the domain gap in noise property caused by the augmentation. We show that our proposed noise-accounted RAW augmentation method doubles the image recognition accuracy in challenging environments only with simple training data. ",
    "url": "https://arxiv.org/abs/2210.16046",
    "authors": [
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Atsushi Irie",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.16050",
    "title": "Link Climate: An Interoperable Knowledge Graph Platform for Climate Data",
    "abstract": "Climate science has become more ambitious in recent years as global awareness about the environment has grown. To better understand climate, historical climate (e.g. archived meteorological variables such as temperature, wind, water, etc.) and climate-related data (e.g. geographical features and human activities) are widely used by today's climate research to derive models for an explainable climate change and its effects. However, such data sources are often dispersed across a multitude of disconnected data silos on the Web. Moreover, there is a lack of advanced climate data platforms to enable multi-source heterogeneous climate data analysis, therefore, researchers must face a stern challenge in collecting and analyzing multi-source data. In this paper, we address this problem by proposing a climate knowledge graph for the integration of multiple climate data and other data sources into one service, leveraging Web technologies (e.g. HTTP) for multi-source climate data analysis. The proposed knowledge graph is primarily composed of data from the National Oceanic and Atmospheric Administration's daily climate summaries, OpenStreetMap, and Wikidata, and it supports joint data queries on these widely used databases. This paper shows, with a use case in Ireland and the United Kingdom, how climate researchers could benefit from this platform as it allows them to easily integrate datasets from different domains and geographical locations. ",
    "url": "https://arxiv.org/abs/2210.16050",
    "authors": [
      "Jiantao Wu",
      "Fabrizio Orlandi",
      "Declan O'Sullivan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.16058",
    "title": "Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward  Long-Horizon Goal-Conditioned Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) often struggles to accomplish a sparse-reward long-horizon task in a complex environment. Goal-conditioned reinforcement learning (GCRL) has been employed to tackle this difficult problem via a curriculum of easy-to-reach sub-goals. In GCRL, exploring novel sub-goals is essential for the agent to ultimately find the pathway to the desired goal. How to explore novel sub-goals efficiently is one of the most challenging issues in GCRL. Several goal exploration methods have been proposed to address this issue but still struggle to find the desired goals efficiently. In this paper, we propose a novel learning objective by optimizing the entropy of both achieved and new goals to be explored for more efficient goal exploration in sub-goal selection based GCRL. To optimize this objective, we first explore and exploit the frequently occurring goal-transition patterns mined in the environments similar to the current task to compose skills via skill learning. Then, the pretrained skills are applied in goal exploration. Evaluation on a variety of spare-reward long-horizon benchmark tasks suggests that incorporating our method into several state-of-the-art GCRL baselines significantly boosts their exploration efficiency while improving or maintaining their performance. The source code is available at: https://github.com/GEAPS/GEAPS. ",
    "url": "https://arxiv.org/abs/2210.16058",
    "authors": [
      "Lisheng Wu",
      "Ke Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.16059",
    "title": "An Artificial Intelligence driven Learning Analytics Method to Examine  the Collaborative Problem solving Process from a Complex Adaptive Systems  Perspective",
    "abstract": "Collaborative problem solving (CPS) enables student groups to complete learning tasks, construct knowledge, and solve problems. Previous research has argued the importance to examine the complexity of CPS, including its multimodality, dynamics, and synergy from the complex adaptive systems perspective. However, there is limited empirical research examining the adaptive and temporal characteristics of CPS which might lead to an oversimplified representation of the real complexity of the CPS process. To further understand the nature of CPS in online interaction settings, this research collected multimodal process and performance data (i.e., verbal audios, computer screen recordings, concept map data) and proposed a three-layered analytical framework that integrated AI algorithms with learning analytics to analyze the regularity of groups collaboration patterns. The results detected three types of collaborative patterns in groups, namely the behaviour-oriented collaborative pattern (Type 1) associated with medium-level performance, the communication - behaviour - synergistic collaborative pattern (Type 2) associated with high-level performance, and the communication-oriented collaborative pattern (Type 3) associated with low-level performance. The research further highlighted the multimodal, dynamic, and synergistic characteristics of groups collaborative patterns to explain the emergence of an adaptive, self-organizing system during the CPS process. ",
    "url": "https://arxiv.org/abs/2210.16059",
    "authors": [
      "Fan Ouyang",
      "Weiqi Xu",
      "Mutlu Cukurova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.16063",
    "title": "Defense Against Smart Invaders with Swarms of Sweeping Agents",
    "abstract": "The goal of this research is to devise guaranteed defense policies that allow to protect a given region from the entrance of smart mobile invaders by detecting them using a team of defending agents equipped with identical line sensors. By designing cooperative defense strategies that ensure all invaders are detected, conditions on the defenders' speed are derived. Successful accomplishment of the defense task implies invaders with a known limit on their speed cannot slip past the defenders and enter the guarded region undetected. The desired outcome of the defense protocols is to defend the area and additionally to expand it as much as possible. Expansion becomes possible if the defenders' speed exceeds a critical speed that is necessary to only defend the initial region. We present results on the total search time, critical speeds and maximal expansion possible for two types of novel pincer-movement defense processes, circular and spiral, for any even number of defenders. The proposed spiral process allows to detect invaders at nearly the lowest theoretically optimal speed, and if this speed is exceeded, it also allows to expand the protected region almost to the maximal area. ",
    "url": "https://arxiv.org/abs/2210.16063",
    "authors": [
      "Roee M. Francos",
      "Alfred M. Bruckstein"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.16078",
    "title": "Adaptive Mask-based Pyramid Network for Realistic Bokeh Rendering",
    "abstract": "Bokeh effect highlights an object (or any part of the image) while blurring the rest of the image, and creates a visually pleasant artistic effect. Due to the sensor-based limitations on mobile devices, machine learning (ML) based bokeh rendering has gained attention as a reliable alternative. In this paper, we focus on several improvements in ML-based bokeh rendering; i) on-device performance with high-resolution images, ii) ability to guide bokeh generation with user-editable masks and iii) ability to produce varying blur strength. To this end, we propose Adaptive Mask-based Pyramid Network (AMPN), which is formed of a Mask-Guided Bokeh Generator (MGBG) block and a Laplacian Pyramid Refinement (LPR) block. MGBG consists of two lightweight networks stacked to each other to generate the bokeh effect, and LPR refines and upsamples the output of MGBG to produce the high-resolution bokeh image. We achieve i) via our lightweight, mobile-friendly design choices, ii) via the stacked-network design of MGBG and the weakly-supervised mask prediction scheme and iii) via manually or automatically editing the intensity values of the mask that guide the bokeh generation. In addition to these features, our results show that AMPN produces competitive or better results compared to existing methods on the EBB! dataset, while being faster and smaller than the alternatives. ",
    "url": "https://arxiv.org/abs/2210.16078",
    "authors": [
      "Konstantinos Georgiadis",
      "Albert Sa\u00e0-Garriga",
      "Mehmet Kerim Yucel",
      "Anastasios Drosou",
      "Bruno Manganelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16080",
    "title": "RESUS: Warm-Up Cold Users via Meta-Learning Residual User Preferences in  CTR Prediction",
    "abstract": "Click-Through Rate (CTR) prediction on cold users is a challenging task in recommender systems. Recent researches have resorted to meta-learning to tackle the cold-user challenge, which either perform few-shot user representation learning or adopt optimization-based meta-learning. However, existing methods suffer from information loss or inefficient optimization process, and they fail to explicitly model global user preference knowledge which is crucial to complement the sparse and insufficient preference information of cold users. In this paper, we propose a novel and efficient approach named RESUS, which decouples the learning of global preference knowledge contributed by collective users from the learning of residual preferences for individual users. Specifically, we employ a shared predictor to infer basis user preferences, which acquires global preference knowledge from the interactions of different users. Meanwhile, we develop two efficient algorithms based on the nearest neighbor and ridge regression predictors, which infer residual user preferences via learning quickly from a few user-specific interactions. Extensive experiments on three public datasets demonstrate that our RESUS approach is efficient and effective in improving CTR prediction accuracy on cold users, compared with various state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.16080",
    "authors": [
      "Yanyan Shen",
      "Lifan Zhao",
      "Weiyu Cheng",
      "Zibin Zhang",
      "Wenwen Zhou",
      "Kangyi Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16083",
    "title": "ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy",
    "abstract": "This paper analyzes the effects of dynamically varying video contents and detection latency on the real-time detection accuracy of a detector and proposes a new run-time accuracy variation model, ROMA, based on the findings from the analysis. ROMA is designed to select an optimal detector out of a set of detectors in real time without label information to maximize real-time object detection accuracy. ROMA utilizing four YOLOv4 detectors on an NVIDIA Jetson Nano shows real-time accuracy improvements by 4 to 37% for a scenario of dynamically varying video contents and detection latency consisting of MOT17Det and MOT20Det datasets, compared to individual YOLOv4 detectors and two state-of-the-art runtime techniques. ",
    "url": "https://arxiv.org/abs/2210.16083",
    "authors": [
      "JunKyu Lee",
      "Blesson Varghese",
      "Hans Vandierendonck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16093",
    "title": "A CNN-LSTM Combination Network for Cataract Detection using Eye Fundus  Images",
    "abstract": "According to multiple authoritative authorities, including the World Health Organization, vision-related impairments and disorders are becoming a significant issue. According to a recent report, one of the leading causes of irreversible blindness in persons over the age of 50 is delayed cataract treatment. A cataract is a cloudy spot in the eye's lens that causes visual loss. Cataracts often develop slowly and consequently result in difficulty in driving, reading, and even recognizing faces. This necessitates the development of rapid and dependable diagnosis and treatment solutions for ocular illnesses. Previously, such visual illness diagnosis were done manually, which was time-consuming and prone to human mistake. However, as technology advances, automated, computer-based methods that decrease both time and human labor while producing trustworthy results are now accessible. In this study, we developed a CNN-LSTM-based model architecture with the goal of creating a low-cost diagnostic system that can classify normal and cataractous cases of ocular disease from fundus images. The proposed model was trained on the publicly available ODIR dataset, which included fundus images of patients' left and right eyes. The suggested architecture outperformed previous systems with a state-of-the-art 97.53% accuracy. ",
    "url": "https://arxiv.org/abs/2210.16093",
    "authors": [
      "Dishant Padalia",
      "Abhishek Mazumdar",
      "Bharati Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16101",
    "title": "Layer-wise Shared Attention Network on Dynamical System Perspective",
    "abstract": "Attention networks have successfully boosted accuracy in various vision problems. Previous works lay emphasis on designing a new self-attention module and follow the traditional paradigm that individually plugs the modules into each layer of a network. However, such a paradigm inevitably increases the extra parameter cost with the growth of the number of layers. From the dynamical system perspective of the residual neural network, we find that the feature maps from the layers of the same stage are homogenous, which inspires us to propose a novel-and-simple framework, called the dense and implicit attention (DIA) unit, that shares a single attention module throughout different network layers. With our framework, the parameter cost is independent of the number of layers and we further improve the accuracy of existing popular self-attention modules with significant parameter reduction without any elaborated model crafting. Extensive experiments on benchmark datasets show that the DIA is capable of emphasizing layer-wise feature interrelation and thus leads to significant improvement in various vision tasks, including image classification, object detection, and medical application. Furthermore, the effectiveness of the DIA unit is demonstrated by novel experiments where we destabilize the model training by (1) removing the skip connection of the residual neural network, (2) removing the batch normalization of the model, and (3) removing all data augmentation during training. In these cases, we verify that DIA has a strong regularization ability to stabilize the training, i.e., the dense and implicit connections formed by our method can effectively recover and enhance the information communication across layers and the value of the gradient thus alleviate the training instability. ",
    "url": "https://arxiv.org/abs/2210.16101",
    "authors": [
      "Zhongzhan Huang",
      "Senwei Liang",
      "Mingfu Liang",
      "Weiling He",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16103",
    "title": "Collaborative Multi-Teacher Knowledge Distillation for Learning Low  Bit-width Deep Neural Networks",
    "abstract": "Knowledge distillation which learns a lightweight student model by distilling knowledge from a cumbersome teacher model is an attractive approach for learning compact deep neural networks (DNNs). Recent works further improve student network performance by leveraging multiple teacher networks. However, most of the existing knowledge distillation-based multi-teacher methods use separately pretrained teachers. This limits the collaborative learning between teachers and the mutual learning between teachers and student. Network quantization is another attractive approach for learning compact DNNs. However, most existing network quantization methods are developed and evaluated without considering multi-teacher support to enhance the performance of quantized student model. In this paper, we propose a novel framework that leverages both multi-teacher knowledge distillation and network quantization for learning low bit-width DNNs. The proposed method encourages both collaborative learning between quantized teachers and mutual learning between quantized teachers and quantized student. During learning process, at corresponding layers, knowledge from teachers will form an importance-aware shared knowledge which will be used as input for teachers at subsequent layers and also be used to guide student. Our experimental results on CIFAR100 and ImageNet datasets show that the compact quantized student models trained with our method achieve competitive results compared to other state-of-the-art methods, and in some cases, indeed surpass the full precision models. ",
    "url": "https://arxiv.org/abs/2210.16103",
    "authors": [
      "Cuong Pham",
      "Tuan Hoang",
      "Thanh-Toan Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are known for their fast and versatile applicability. With UAVs' growth in availability and applications, they are now of vital importance in serving as technological support in search-and-rescue(SAR) operations in marine environments. High-resolution cameras and GPUs can be equipped on the UAVs to provide effective and efficient aid to emergency rescue operations. With modern computer vision algorithms, we can detect objects for aiming such rescue missions. However, these modern computer vision algorithms are dependent on numerous amounts of training data from UAVs, which is time-consuming and labor-intensive for maritime environments. To this end, we present a new benchmark suite, \\textit{\\textbf{SeaDroneSim}}, that can be used to create photo-realistic aerial image datasets with the ground truth for segmentation masks of any given object. Utilizing only the synthetic data generated from \\textit{\\textbf{SeaDroneSim}}, we obtain 71 mAP on real aerial images for detecting BlueROV as a feasibility study. This result from the new simulation suit also serves as a baseline for the detection of BlueROV. ",
    "url": "https://arxiv.org/abs/2210.16107",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.16114",
    "title": "Toward Reliable Neural Specifications",
    "abstract": "Having reliable specifications is an unavoidable challenge in achieving verifiable correctness, robustness, and interpretability of AI systems. Existing specifications for neural networks are in the paradigm of data as specification. That is, the local neighborhood centering around a reference input is considered to be correct (or robust). However, our empirical study shows that such a specification is extremely overfitted since usually no data points from the testing set lie in the certified region of the reference input, making them impractical for real-world applications. We propose a new family of specifications called neural representation as specification, which uses the intrinsic information of neural networks - neural activation patterns (NAP), rather than input data to specify the correctness and/or robustness of neural network predictions. We present a simple statistical approach to mining dominant neural activation patterns. We analyze NAPs from a statistical point of view and find that a single NAP can cover a large number of training and testing data points whereas ad hoc data-as-specification only covers the given reference data point. To show the effectiveness of discovered NAPs, we formally verify several important properties, such as various types of misclassifications will never happen for a given NAP, and there is no-ambiguity between different NAPs. We show that by using NAP, we can verify the prediction of the entire input space, while still recalling 84% of the data. Thus, we argue that using NAPs is a more reliable and extensible specification for neural network verification. ",
    "url": "https://arxiv.org/abs/2210.16114",
    "authors": [
      "Chuqin Geng",
      "Nham Le",
      "Xiaojie Xu",
      "Zhaoyue Wang",
      "Arie Gurfinkel",
      "Xujie Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.16117",
    "title": "Improving Transferability of Adversarial Examples on Face Recognition  with Beneficial Perturbation Feature Augmentation",
    "abstract": "Face recognition (FR) models can be easily fooled by adversarial examples, which are crafted by adding imperceptible perturbations on benign face images. To improve the transferability of adversarial examples on FR models, we propose a novel attack method called Beneficial Perturbation Feature Augmentation Attack (BPFA), which reduces the overfitting of the adversarial examples to surrogate FR models by the adversarial strategy. Specifically, in the backpropagation step, BPFA records the gradients on pre-selected features and uses the gradient on the input image to craft adversarial perturbation to be added on the input image. In the next forward propagation step, BPFA leverages the recorded gradients to add perturbations(i.e., beneficial perturbations) that can be pitted against the adversarial perturbation added on the input image on their corresponding features. The above two steps are repeated until the last backpropagation step before the maximum number of iterations is reached. The optimization process of the adversarial perturbation added on the input image and the optimization process of the beneficial perturbations added on the features correspond to a minimax two-player game. Extensive experiments demonstrate that BPFA outperforms the state-of-the-art gradient-based adversarial attacks on FR. ",
    "url": "https://arxiv.org/abs/2210.16117",
    "authors": [
      "Fengfan Zhou",
      "Hefei Ling",
      "Yuxuan Shi",
      "Jiazhong Chen",
      "Zongyi Li",
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16118",
    "title": "Imitation Learning-based Implicit Semantic-aware Communication Networks:  Multi-layer Representation and Collaborative Reasoning",
    "abstract": "Semantic communication has recently attracted significant interest from both industry and academia due to its potential to transform the existing data-focused communication architecture towards a more generally intelligent and goal-oriented semantic-aware networking system. Despite its promising potential, semantic communications and semantic-aware networking are still at their infancy. Most existing works focus on transporting and delivering the explicit semantic information, e.g., labels or features of objects, that can be directly identified from the source signal. The original definition of semantics as well as recent results in cognitive neuroscience suggest that it is the implicit semantic information, in particular the hidden relations connecting different concepts and feature items that plays the fundamental role in recognizing, communicating, and delivering the real semantic meanings of messages. Motivated by this observation, we propose a novel reasoning-based implicit semantic-aware communication network architecture that allows multiple tiers of CDC and edge servers to collaborate and support efficient semantic encoding, decoding, and interpretation for end-users. We introduce a new multi-layer representation of semantic information taking into consideration both the hierarchical structure of implicit semantics as well as the personalized inference preference of individual users. We model the semantic reasoning process as a reinforcement learning process and then propose an imitation-based semantic reasoning mechanism learning (iRML) solution for the edge servers to leaning a reasoning policy that imitates the inference behavior of the source user. A federated GCN-based collaborative reasoning solution is proposed to allow multiple edge servers to jointly construct a shared semantic interpretation model based on decentralized knowledge datasets. ",
    "url": "https://arxiv.org/abs/2210.16118",
    "authors": [
      "Yong Xiao",
      "Zijian Sun",
      "Guangming Shi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.16140",
    "title": "Localized Randomized Smoothing for Collective Robustness Certification",
    "abstract": "Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task of provably bounding the number of robust predictions under this threat model. The only dedicated method that goes beyond certifying each output independently is limited to strictly local models, where each prediction is associated with a small receptive field. We propose a more general collective robustness certificate for all types of models and further show that this approach is beneficial for the larger class of softly local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on our novel localized randomized smoothing approach, where the random perturbation strength for different input regions is proportional to their importance for the outputs. Localized smoothing Pareto-dominates existing certificates on both image segmentation and node classification tasks, simultaneously offering higher accuracy and stronger guarantees. ",
    "url": "https://arxiv.org/abs/2210.16140",
    "authors": [
      "Jan Schuchardt",
      "Tom Wollschl\u00e4ger",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16162",
    "title": "Are Neural Topic Models Broken?",
    "abstract": "Recently, the relationship between automated and human evaluation of topic models has been called into question. Method developers have staked the efficacy of new topic model variants on automated measures, and their failure to approximate human preferences places these models on uncertain ground. Moreover, existing evaluation paradigms are often divorced from real-world use. Motivated by content analysis as a dominant real-world use case for topic modeling, we analyze two related aspects of topic models that affect their effectiveness and trustworthiness in practice for that purpose: the stability of their estimates and the extent to which the model's discovered categories align with human-determined categories in the data. We find that neural topic models fare worse in both respects compared to an established classical method. We take a step toward addressing both issues in tandem by demonstrating that a straightforward ensembling method can reliably outperform the members of the ensemble. ",
    "url": "https://arxiv.org/abs/2210.16162",
    "authors": [
      "Alexander Hoyle",
      "Pranav Goel",
      "Rupak Sarkar",
      "Philip Resnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.16173",
    "title": "Deep Learning Object Detection Approaches to Source Identification",
    "abstract": "Traditionally source identification is solved using threshold based energy detection algorithms. These algorithms frequently sum up the activity in regions, and consider regions above a specific activity threshold to be sources. While these algorithms work for the majority of cases, they often fail to detect signals that occupy small frequency bands, fail to distinguish sources with overlapping frequency bands, and cannot detect any signals under a specified signal to noise ratio. Through the conversion of raw signal data to spectrogram, source identification can be framed as an object detection problem. By leveraging modern advancements in deep learning based object detection, we propose a system that manages to alleviate the failure cases encountered when using traditional source identification algorithms. Our contributions include framing source identification as an object detection problem, the publication of a spectrogram object detection dataset, and evaluation of the RetinaNet and YOLOv5 object detection models trained on the dataset. Our final models achieve Mean Average Precisions of up to 0.906. With such a high Mean Average Precision, these models are sufficiently robust for use in real world applications. ",
    "url": "https://arxiv.org/abs/2210.16173",
    "authors": [
      "Luke Wood",
      "Kevin Anderson",
      "Peter Gerstoft"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.16193",
    "title": "M3FGM:a node masking and multi-granularity message passing-based  federated graph model for spatial-temporal data prediction",
    "abstract": "Researchers are solving the challenges of spatial-temporal prediction by combining Federated Learning (FL) and graph models with respect to the constrain of privacy and security. However, there are still several issues left unattended: 1) Clients might not be able to access the server during inference phase; 2) The graph of clients designed manually in the server model may not reveal the proper relationship between clients. This paper proposes a new embeddings aggregation structured FL approach named node Masking and Multi-granularity Message passing-based Federated Graph Model (M3FGM) for the above issues. The server model of M3FGM employs a MaskNode layer to simulate the case of offline clients. We also redesign the decoder of the client model using a dual-sub-decoders structure so that each client model can use its local data to predict independently when offline. As for the second issue, A new GNN layer named Multi-Granularity Message Passing (MGMP) allows each client node to perceive global and local information.We conducted extensive experiments in two different scenarios on two real traffic datasets. Results show that the proposed model outperforms the baselines and variant models, achieves the best results in both scenarios. ",
    "url": "https://arxiv.org/abs/2210.16193",
    "authors": [
      "Yuxing Tian",
      "Zheng Liu",
      "Yanwen Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16205",
    "title": "Local Model Reconstruction Attacks in Federated Learning and their Uses",
    "abstract": "In this paper, we initiate the study of local model reconstruction attacks for federated learning, where a honest-but-curious adversary eavesdrops the messages exchanged between a targeted client and the server, and then reconstructs the local/personalized model of the victim. The local model reconstruction attack allows the adversary to trigger other classical attacks in a more effective way, since the local model only depends on the client's data and can leak more private information than the global model learned by the server. Additionally, we propose a novel model-based attribute inference attack in federated learning leveraging the local model reconstruction attack. We provide an analytical lower-bound for this attribute inference attack. Empirical results using real world datasets confirm that our local reconstruction attack works well for both regression and classification tasks. Moreover, we benchmark our novel attribute inference attack against the state-of-the-art attacks in federated learning. Our attack results in higher reconstruction accuracy especially when the clients' datasets are heterogeneous. Our work provides a new angle for designing powerful and explainable attacks to effectively quantify the privacy risk in FL. ",
    "url": "https://arxiv.org/abs/2210.16205",
    "authors": [
      "Ilias Driouich",
      "Chuan Xu",
      "Giovanni Neglia",
      "Frederic Giroire",
      "Eoin Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.16222",
    "title": "Improving Lipschitz-Constrained Neural Networks by Learning Activation  Functions",
    "abstract": "Lipschitz-constrained neural networks have several advantages compared to unconstrained ones and can be applied to various different problems. Consequently, they have recently attracted considerable attention in the deep learning community. Unfortunately, it has been shown both theoretically and empirically that networks with ReLU activation functions perform poorly under such constraints. On the contrary, neural networks with learnable 1-Lipschitz linear splines are known to be more expressive in theory. In this paper, we show that such networks are solutions of a functional optimization problem with second-order total-variation regularization. Further, we propose an efficient method to train such 1-Lipschitz deep spline neural networks. Our numerical experiments for a variety of tasks show that our trained networks match or outperform networks with activation functions specifically tailored towards Lipschitz-constrained architectures. ",
    "url": "https://arxiv.org/abs/2210.16222",
    "authors": [
      "Stanislas Ducotterd",
      "Alexis Goujon",
      "Pakshal Bohra",
      "Dimitris Perdios",
      "Sebastian Neumayer",
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16228",
    "title": "Probing for targeted syntactic knowledge through grammatical error  detection",
    "abstract": "Targeted studies testing knowledge of subject-verb agreement (SVA) indicate that pre-trained language models encode syntactic information. We assert that if models robustly encode subject-verb agreement, they should be able to identify when agreement is correct and when it is incorrect. To that end, we propose grammatical error detection as a diagnostic probe to evaluate token-level contextual representations for their knowledge of SVA. We evaluate contextual representations at each layer from five pre-trained English language models: BERT, XLNet, GPT-2, RoBERTa, and ELECTRA. We leverage public annotated training data from both English second language learners and Wikipedia edits, and report results on manually crafted stimuli for subject-verb agreement. We find that masked language models linearly encode information relevant to the detection of SVA errors, while the autoregressive models perform on par with our baseline. However, we also observe a divergence in performance when probes are trained on different training sets, and when they are evaluated on different syntactic constructions, suggesting the information pertaining to SVA error detection is not robustly encoded. ",
    "url": "https://arxiv.org/abs/2210.16228",
    "authors": [
      "Christopher Davis",
      "Christopher Bryant",
      "Andrew Caines",
      "Marek Rei",
      "Paula Buttery"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.16244",
    "title": "Design of Convolutional Extreme Learning Machines for Vision-Based  Navigation Around Small Bodies",
    "abstract": "Deep learning architectures such as convolutional neural networks are the standard in computer vision for image processing tasks. Their accuracy however often comes at the cost of long and computationally expensive training, the need for large annotated datasets, and extensive hyper-parameter searches. On the other hand, a different method known as convolutional extreme learning machine has shown the potential to perform equally with a dramatic decrease in training time. Space imagery, especially about small bodies, could be well suited for this method. In this work, convolutional extreme learning machine architectures are designed and tested against their deep-learning counterparts. Because of the relatively fast training time of the former, convolutional extreme learning machine architectures enable efficient exploration of the architecture design space, which would have been impractical with the latter, introducing a methodology for an efficient design of a neural network architecture for computer vision tasks. Also, the coupling between the image processing method and labeling strategy is investigated and demonstrated to play a major role when considering vision-based navigation around small bodies. ",
    "url": "https://arxiv.org/abs/2210.16244",
    "authors": [
      "Mattia Pugliatti",
      "Francesco Topputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16258",
    "title": "On the Vulnerability of Data Points under Multiple Membership Inference  Attacks and Target Models",
    "abstract": "Membership Inference Attacks (MIAs) infer whether a data point is in the training data of a machine learning model. It is a threat while being in the training data is private information of a data point. MIA correctly infers some data points as members or non-members of the training data. Intuitively, data points that MIA accurately detects are vulnerable. Considering those data points may exist in different target models susceptible to multiple MIAs, the vulnerability of data points under multiple MIAs and target models is worth exploring. This paper defines new metrics that can reflect the actual situation of data points' vulnerability and capture vulnerable data points under multiple MIAs and target models. From the analysis, MIA has an inference tendency to some data points despite a low overall inference performance. Additionally, we implement 54 MIAs, whose average attack accuracy ranges from 0.5 to 0.9, to support our analysis with our scalable and flexible platform, Membership Inference Attacks Platform (VMIAP). Furthermore, previous methods are unsuitable for finding vulnerable data points under multiple MIAs and different target models. Finally, we observe that the vulnerability is not characteristic of the data point but related to the MIA and target model. ",
    "url": "https://arxiv.org/abs/2210.16258",
    "authors": [
      "Mauro Conti",
      "Jiaxin Li",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16269",
    "title": "ATM: Black-box Test Case Minimization based on Test Code Similarity and  Evolutionary Search",
    "abstract": "Executing large test suites is time and resource consuming, sometimes impossible, and such test suites typically contain many redundant test cases. Hence, test case minimization is used to remove redundant test cases that are unlikely to detect new faults. However, most test case minimization techniques rely on code coverage (white-box), model-based features, or requirements specifications, which are not always accessible by test engineers. Recently, a set of novel techniques was proposed, called FAST-R, relying solely on test case code for test case minimization, which appeared to be much more efficient than white-box techniques. However, it achieved a comparable low fault detection capability for Java projects, making its application challenging in practice. This paper proposes ATM (AST-based Test case Minimizer), a similarity-based, search-based test case minimization technique, taking a specific budget as input, that also relies exclusively on the source code of test cases but attempts to achieve higher fault detection through finer-grained similarity analysis and a dedicated search algorithm. ATM transforms test case code into Abstract Syntax Trees (AST) and relies on four tree-based similarity measures to apply evolutionary search, specifically genetic algorithms, to minimize test cases. We evaluated the effectiveness and efficiency of ATM on a large dataset of 16 Java projects with 661 faulty versions using three budgets ranging from 25% to 75% of test suites. ATM achieved significantly higher fault detection rates (0.82 on average), compared to FAST-R (0.61 on average) and random minimization (0.52 on average), when running only 50% of the test cases, within practically acceptable time (1.1-4.3 hours, on average), given that minimization is only occasionally applied when many new test cases are created (major releases). Results achieved for other budgets were consistent. ",
    "url": "https://arxiv.org/abs/2210.16269",
    "authors": [
      "Rongqi Pan",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.16270",
    "title": "Space-Time Graph Neural Networks with Stochastic Graph Perturbations",
    "abstract": "Space-time graph neural networks (ST-GNNs) are recently developed architectures that learn efficient graph representations of time-varying data. ST-GNNs are particularly useful in multi-agent systems, due to their stability properties and their ability to respect communication delays between the agents. In this paper we revisit the stability properties of ST-GNNs and prove that they are stable to stochastic graph perturbations. Our analysis suggests that ST-GNNs are suitable for transfer learning on time-varying graphs and enables the design of generalized convolutional architectures that jointly process time-varying graphs and time-varying signals. Numerical experiments on decentralized control systems validate our theoretical results and showcase the benefits of traditional and generalized ST-GNN architectures. ",
    "url": "https://arxiv.org/abs/2210.16270",
    "authors": [
      "Samar Hadou",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.16280",
    "title": "Clustering Graphs -- Applying a Label Propagation Algorithm to Detect  Communities in Graph Databases",
    "abstract": "In the last few decades, Database Management Systems (DBMSs) became powerful tools for storing large amount of data and executing complex queries over them. In the recent years, the growing amount of unstructured or semi-structured data has seen a shift from representing data in the relational model towards alternative data models. Graph Databases and Graph Database Management Systems (GDBMSs) have seen an increase in use due to their ability to manage highly-interconnected, continuously evolving data. This thesis is a documentation of the work done in implementing a system to identify clusters in graph modeled data using a Label Propagation Community Detection Algorithm. The graph was built using datasets of academic publications in the field of Computer Science obtained from dblp.org . The system developed is a FullStack WebApp consisting of a web-based user interface, an API and the data (nodes, edges, graph) stored in a Graph Database Management System (GDBMS). Described in this document are: - the process of manipulation pre-import and import of the data in a Graph Database Management System (GDBMS) such as ArangoDB, creation of nodes, relations (edges) between the nodes and a graph composed of these nodes and edges; - the GraphQL API implemented in NodeJS to request data from the Graph Database Management System (GDBMS); - the frontend interface made with TypeScript and React consisting of the search functionalities and ability to visualize results in Cytoscape Network Graphs; - the Label Propagation Community Detection Algorithm execution on the graph, the found clusters which are stored and visualized to the user whenever requested. This thesis hopes to contribute with a practical hands-on approach on the graph representation, integration and analysis of interconnected data. ",
    "url": "https://arxiv.org/abs/2210.16280",
    "authors": [
      "Andi Ferhati"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.16286",
    "title": "A Functional-Space Mean-Field Theory of Partially-Trained Three-Layer  Neural Networks",
    "abstract": "To understand the training dynamics of neural networks (NNs), prior studies have considered the infinite-width mean-field (MF) limit of two-layer NN, establishing theoretical guarantees of its convergence under gradient flow training as well as its approximation and generalization capabilities. In this work, we study the infinite-width limit of a type of three-layer NN model whose first layer is random and fixed. To define the limiting model rigorously, we generalize the MF theory of two-layer NNs by treating the neurons as belonging to functional spaces. Then, by writing the MF training dynamics as a kernel gradient flow with a time-varying kernel that remains positive-definite, we prove that its training loss in $L_2$ regression decays to zero at a linear rate. Furthermore, we define function spaces that include the solutions obtainable through the MF training dynamics and prove Rademacher complexity bounds for these spaces. Our theory accommodates different scaling choices of the model, resulting in two regimes of the MF limit that demonstrate distinctive behaviors while both exhibiting feature learning. ",
    "url": "https://arxiv.org/abs/2210.16286",
    "authors": [
      "Zhengdao Chen",
      "Eric Vanden-Eijnden",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.16288",
    "title": "Nonlinear Stability of Complex Droop Control in Converter-Based Power  Systems",
    "abstract": "In this letter, we study the nonlinear stability of converter-based power systems, where the converter dynamics are governed by a complex droop control. This complex droop control augments the well-known power-frequency (p-f) droop control, and it proves to be equivalent to the state-of-the-art dispatchable virtual oscillator control (dVOC). In this regard, it is recognized as a promising grid-forming solution to address the high penetration of converters in future power systems. In previous work, the nonlinear stability of dVOC (i.e., complex droop control) has been proven by prespecifying a nominal synchronous steady state. For a general case of non-nominal (i.e., drooped) synchronous steady states, however, the stability issue requires further investigation. We address this issue in this letter. We provide parametric conditions under which a non-nominal synchronous steady state exists and the system is almost globally asymptotically stable with respect to this non-nominal synchronous steady state. ",
    "url": "https://arxiv.org/abs/2210.16288",
    "authors": [
      "Xiuqiang He",
      "Verena H\u00e4berle",
      "Irina Suboti\u0107",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.16298",
    "title": "Investigating Ensemble Methods for Model Robustness Improvement of Text  Classifiers",
    "abstract": "Large pre-trained language models have shown remarkable performance over the past few years. These models, however, sometimes learn superficial features from the dataset and cannot generalize to the distributions that are dissimilar to the training scenario. There have been several approaches proposed to reduce model's reliance on these bias features which can improve model robustness in the out-of-distribution setting. However, existing methods usually use a fixed low-capacity model to deal with various bias features, which ignore the learnability of those features. In this paper, we analyze a set of existing bias features and demonstrate there is no single model that works best for all the cases. We further show that by choosing an appropriate bias model, we can obtain a better robustness result than baselines with a more sophisticated model design. ",
    "url": "https://arxiv.org/abs/2210.16298",
    "authors": [
      "Jieyu Zhao",
      "Xuezhi Wang",
      "Yao Qin",
      "Jilin Chen",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15709",
    "title": "Improvement-Focused Causal Recourse (ICR)",
    "abstract": "Algorithmic recourse recommendations, such as Karimi et al.'s (2021) causal recourse (CR), inform stakeholders of how to act to revert unfavourable decisions. However, some actions lead to acceptance (i.e., revert the model's decision) but do not lead to improvement (i.e., may not revert the underlying real-world state). To recommend such actions is to recommend fooling the predictor. We introduce a novel method, Improvement-Focused Causal Recourse (ICR), which involves a conceptual shift: Firstly, we require ICR recommendations to guide towards improvement. Secondly, we do not tailor the recommendations to be accepted by a specific predictor. Instead, we leverage causal knowledge to design decision systems that predict accurately pre- and post-recourse. As a result, improvement guarantees translate into acceptance guarantees. We demonstrate that given correct causal knowledge, ICR, in contrast to existing approaches, guides towards both acceptance and improvement. ",
    "url": "https://arxiv.org/abs/2210.15709",
    "authors": [
      "Gunnar K\u00f6nig",
      "Timo Freiesleben",
      "Moritz Grosse-Wentrup"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15712",
    "title": "A mathematical framework for dynamical social interactions with  dissimulation",
    "abstract": "Modeling social interactions is a challenging task that requires flexible frameworks. For instance, dissimulation and externalities are relevant features influencing such systems -- elements that are often neglected in popular models. This paper is devoted to investigating general mathematical frameworks for understanding social situations where agents dissimulate, and may be sensitive to exogenous objective information. Our model comprises a population where the participants can be honest, persuasive, or conforming. Firstly, we consider a non-cooperative setting, where we establish existence, uniqueness and some properties of the Nash equilibria of the game. Secondly, we analyze a cooperative setting, identifying optimal strategies within the Pareto front. In both cases, we develop numerical algorithms allowing us to computationally assess the behavior of our models under various settings. ",
    "url": "https://arxiv.org/abs/2210.15712",
    "authors": [
      "Yuri Saporito",
      "Max O. Souza",
      "Yuri Thamsten"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.15799",
    "title": "Adaptive Physics-Informed Neural Operator for Coarse-Grained  Non-Equilibrium Flows",
    "abstract": "This work proposes a new machine learning (ML)-based paradigm aiming to enhance the computational efficiency of non-equilibrium reacting flow simulations while ensuring compliance with the underlying physics. The framework combines dimensionality reduction and neural operators through a hierarchical and adaptive deep learning strategy to learn the solution of multi-scale coarse-grained governing equations for chemical kinetics. The proposed surrogate's architecture is structured as a tree, where the leaf nodes correspond to separate physics-informed deep operator networks (PI-DeepONets). The hierarchical attribute has two advantages: i) It allows the simplification of the training phase via transfer learning, starting from the slowest temporal scales; ii) It accelerates the prediction step by enabling adaptivity as the surrogate's evaluation is limited to the necessary leaf nodes based on the local degree of non-equilibrium of the gas. The model is applied to the study of chemical kinetics relevant for application to hypersonic flight, and it is tested here on a pure oxygen gas mixture. The proposed ML framework can adaptively predict the dynamics of almost thirty species with a relative error smaller than 4% for a broad range of initial conditions. This work lays the foundation for constructing an efficient ML-based surrogate coupled with reactive Navier-Stokes solvers for accurately characterizing non-equilibrium phenomena. ",
    "url": "https://arxiv.org/abs/2210.15799",
    "authors": [
      "Ivan Zanardi",
      "Simone Venturi",
      "Marco Panesi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15808",
    "title": "Hyper-Connected Transformer Network for Co-Learning Multi-Modality  PET-CT Features",
    "abstract": "[18F]-Fluorodeoxyglucose (FDG) positron emission tomography - computed tomography (PET-CT) has become the imaging modality of choice for diagnosing many cancers. Co-learning complementary PET-CT imaging features is a fundamental requirement for automatic tumor segmentation and for developing computer aided cancer diagnosis systems. We propose a hyper-connected transformer (HCT) network that integrates a transformer network (TN) with a hyper connected fusion for multi-modality PET-CT images. The TN was leveraged for its ability to provide global dependencies in image feature learning, which was achieved by using image patch embeddings with a self-attention mechanism to capture image-wide contextual information. We extended the single-modality definition of TN with multiple TN based branches to separately extract image features. We introduced a hyper connected fusion to fuse the contextual and complementary image features across multiple transformers in an iterative manner. Our results with two non-small cell lung cancer and soft-tissue sarcoma datasets show that HCT achieved better performance in segmentation accuracy when compared to state-of-the-art methods. We also show that HCT produces consistent performance across various image fusion strategies and network backbones. ",
    "url": "https://arxiv.org/abs/2210.15808",
    "authors": [
      "Lei Bi",
      "Xiaohang Fu",
      "Qiufang Liu",
      "Shaoli Song",
      "David Dagan Feng",
      "Michael Fulham",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15821",
    "title": "Secure Distributed Optimization Under Gradient Attacks",
    "abstract": "In this paper, we study secure distributed optimization against arbitrary gradient attack in multi-agent networks. In distributed optimization, there is no central server to coordinate local updates, and each agent can only communicate with its neighbors on a predefined network. We consider the scenario where out of $n$ networked agents, a fixed but unknown fraction $\\rho$ of the agents are under arbitrary gradient attack in that their stochastic gradient oracles return arbitrary information to derail the optimization process, and the goal is to minimize the sum of local objective functions on unattacked agents. We propose a distributed stochastic gradient method that combines local variance reduction and clipping (CLIP-VRG). We show that, in a connected network, when unattacked local objective functions are convex and smooth, share a common minimizer, and their sum is strongly convex, CLIP-VRG leads to almost sure convergence of the iterates to the exact sum cost minimizer at all agents. We quantify a tight upper bound of the fraction $\\rho$ of attacked agents in terms of problem parameters such as the condition number of the associated sum cost that guarantee exact convergence of CLIP-VRG, and characterize its asymptotic convergence rate. Finally, we empirically demonstrate the effectiveness of the proposed method under gradient attacks in both synthetic dataset and image classification datasets. ",
    "url": "https://arxiv.org/abs/2210.15821",
    "authors": [
      "Shuhua Yu",
      "Soummya Kar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.15925",
    "title": "Incorporating Interactive Facts for Stock Selection via Neural Recursive  ODEs",
    "abstract": "Stock selection attempts to rank a list of stocks for optimizing investment decision making, aiming at minimizing investment risks while maximizing profit returns. Recently, researchers have developed various (recurrent) neural network-based methods to tackle this problem. Without exceptions, they primarily leverage historical market volatility to enhance the selection performance. However, these approaches greatly rely on discrete sampled market observations, which either fail to consider the uncertainty of stock fluctuations or predict continuous stock dynamics in the future. Besides, some studies have considered the explicit stock interdependence derived from multiple domains (e.g., industry and shareholder). Nevertheless, the implicit cross-dependencies among different domains are under-explored. To address such limitations, we present a novel stock selection solution -- StockODE, a latent variable model with Gaussian prior. Specifically, we devise a Movement Trend Correlation module to expose the time-varying relationships regarding stock movements. We design Neural Recursive Ordinary Differential Equation Networks (NRODEs) to capture the temporal evolution of stock volatility in a continuous dynamic manner. Moreover, we build a hierarchical hypergraph to incorporate the domain-aware dependencies among the stocks. Experiments conducted on two real-world stock market datasets demonstrate that StockODE significantly outperforms several baselines, such as up to 18.57% average improvement regarding Sharpe Ratio. ",
    "url": "https://arxiv.org/abs/2210.15925",
    "authors": [
      "Qiang Gao",
      "Xinzhu Zhou",
      "Kunpeng Zhang",
      "Li Huang",
      "Siyuan Liu",
      "Fan Zhou"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15982",
    "title": "Dysfluencies Seldom Come Alone -- Detection as a Multi-Label Problem",
    "abstract": "Specially adapted speech recognition models are necessary to handle stuttered speech. For these to be used in a targeted manner, stuttered speech must be reliably detected. Recent works have treated stuttering as a multi-class classification problem or viewed detecting each dysfluency type as an isolated task; that does not capture the nature of stuttering, where one dysfluency seldom comes alone, i.e., co-occurs with others. This work explores an approach based on a modified wav2vec 2.0 system for end-to-end stuttering detection and classification as a multi-label problem. The method is evaluated on combinations of three datasets containing English and German stuttered speech, yielding state-of-the-art results for stuttering detection on the SEP-28k-Extended dataset. Experimental results provide evidence for the transferability of features and the generalizability of the method across datasets and languages. ",
    "url": "https://arxiv.org/abs/2210.15982",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Florian H\u00f6nig",
      "Tobias Bocklet",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.15987",
    "title": "NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit",
    "abstract": "This paper describes the design of NNSVS, an open-source software for neural network-based singing voice synthesis research. NNSVS is inspired by Sinsy, an open-source pioneer in singing voice synthesis research, and provides many additional features such as multi-stream models, autoregressive fundamental frequency models, and neural vocoders. Furthermore, NNSVS provides extensive documentation and numerous scripts to build complete singing voice synthesis systems. Experimental results demonstrate that our best system significantly outperforms our reproduction of Sinsy and other baseline systems. The toolkit is available at https://github.com/nnsvs/nnsvs. ",
    "url": "https://arxiv.org/abs/2210.15987",
    "authors": [
      "Ryuichi Yamamoto",
      "Reo Yoneyama",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.16022",
    "title": "SG-VAD: Stochastic Gates Based Speech Activity Detection",
    "abstract": "We propose a novel voice activity detection (VAD) model in a low-resource environment. Our key idea is to model VAD as a denoising task, and construct a network that is designed to identify nuisance features for a speech classification task. We train the model to simultaneously identify irrelevant features while predicting the type of speech event. Our model contains only 7.8K parameters, outperforms the previously proposed methods on the AVA-Speech evaluation set, and provides comparative results on the HAVIC dataset. We present its architecture, experimental results, and ablation study on the model's components. We publish the code and the models here https://www.github.com/jsvir/vad. ",
    "url": "https://arxiv.org/abs/2210.16022",
    "authors": [
      "Jonathan Svirsky",
      "Ofir Lindenbaum"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16028",
    "title": "Laugh Betrays You? Learning Robust Speaker Representation From Speech  Containing Non-Verbal Fragments",
    "abstract": "The success of automatic speaker verification shows that discriminative speaker representations can be extracted from neutral speech. However, as a kind of non-verbal voice, laughter should also carry speaker information intuitively. Thus, this paper focuses on exploring speaker verification about utterances containing non-verbal laughter segments. We collect a set of clips with laughter components by conducting a laughter detection script on VoxCeleb and part of the CN-Celeb dataset. To further filter untrusted clips, probability scores are calculated by our binary laughter detection classifier, which is pre-trained by pure laughter and neutral speech. After that, based on the clips whose scores are over the threshold, we construct trials under two different evaluation scenarios: Laughter-Laughter (LL) and Speech-Laughter (SL). Then a novel method called Laughter-Splicing based Network (LSN) is proposed, which can significantly boost performance in both scenarios and maintain the performance on the neutral speech, such as the VoxCeleb1 test set. Specifically, our system achieves relative 20% and 22% improvement on Laughter-Laughter and Speech-Laughter trials, respectively. The meta-data and sample clips have been released at https://github.com/nevermoreLin/Laugh_LSN. ",
    "url": "https://arxiv.org/abs/2210.16028",
    "authors": [
      "Yuke Lin",
      "Xiaoyi Qin",
      "Huahua Cui",
      "Zhenyi Zhu",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16060",
    "title": "Deep network series for large-scale high-dynamic range imaging",
    "abstract": "We propose a new approach for large-scale high-dynamic range computational imaging. Deep Neural Networks (DNNs) trained end-to-end can solve linear inverse imaging problems almost instantaneously. While unfolded architectures provide necessary robustness to variations of the measurement setting, embedding large-scale measurement operators in DNN architectures is impractical. Alternative Plug-and-Play (PnP) approaches, where the denoising DNNs are blind to the measurement setting, have proven effective to address scalability and high-dynamic range challenges, but rely on highly iterative algorithms. We propose a residual DNN series approach, where the reconstructed image is built as a sum of residual images progressively increasing the dynamic range, and estimated iteratively by DNNs taking the back-projected data residual of the previous iteration as input. We demonstrate on simulations for radio-astronomical imaging that a series of only few terms provides a high-dynamic range reconstruction of similar quality to state-of-the-art PnP approaches, at a fraction of the cost. ",
    "url": "https://arxiv.org/abs/2210.16060",
    "authors": [
      "Amir Aghabiglou",
      "Matthieu Terris",
      "Adrian Jackson",
      "Yves Wiaux"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16062",
    "title": "Neural Network based Formation of Cognitive Maps of Semantic Spaces and  the Emergence of Abstract Concepts",
    "abstract": "The hippocampal-entorhinal complex plays a major role in the organization of memory and thought. The formation of and navigation in cognitive maps of arbitrary mental spaces via place and grid cells can serve as a representation of memories and experiences and their relations to each other. The multi-scale successor representation is proposed to be the mathematical principle underlying place and grid cell computations. Here, we present a neural network, which learns a cognitive map of a semantic space based on 32 different animal species encoded as feature vectors. The neural network successfully learns the similarities between different animal species, and constructs a cognitive map of 'animal space' based on the principle of successor representations with an accuracy of around 30% which is near to the theoretical maximum regarding the fact that all animal species have more than one possible successor, i.e. nearest neighbor in feature space. Furthermore, a hierarchical structure, i.e. different scales of cognitive maps, can be modeled based on multi-scale successor representations. We find that, in fine-grained cognitive maps, the animal vectors are evenly distributed in feature space. In contrast, in coarse-grained maps, animal vectors are highly clustered according to their biological class, i.e. amphibians, mammals and insects. This could be a possible mechanism explaining the emergence of new abstract semantic concepts. Finally, even completely new or incomplete input can be represented by interpolation of the representations from the cognitive map with remarkable high accuracy of up to 95%. We conclude that the successor representation can serve as a weighted pointer to past memories and experiences, and may therefore be a crucial building block for future machine learning to include prior knowledge, and to derive context knowledge from novel input. ",
    "url": "https://arxiv.org/abs/2210.16062",
    "authors": [
      "Paul Stoewer",
      "Achim Schilling",
      "Andreas Maier",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.16098",
    "title": "Predicting Protein-Ligand Binding Affinity with Equivariant Line Graph  Network",
    "abstract": "Binding affinity prediction of three-dimensional (3D) protein ligand complexes is critical for drug repositioning and virtual drug screening. Existing approaches transform a 3D protein-ligand complex to a two-dimensional (2D) graph, and then use graph neural networks (GNNs) to predict its binding affinity. However, the node and edge features of the 2D graph are extracted based on invariant local coordinate systems of the 3D complex. As a result, the method can not fully learn the global information of the complex, such as, the physical symmetry and the topological information of bonds. To address these issues, we propose a novel Equivariant Line Graph Network (ELGN) for affinity prediction of 3D protein ligand complexes. The proposed ELGN firstly adds a super node to the 3D complex, and then builds a line graph based on the 3D complex. After that, ELGN uses a new E(3)-equivariant network layer to pass the messages between nodes and edges based on the global coordinate system of the 3D complex. Experimental results on two real datasets demonstrate the effectiveness of ELGN over several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2210.16098",
    "authors": [
      "Yiqiang Yi",
      "Xu Wan",
      "Kangfei Zhao",
      "Le Ou-Yang",
      "Peilin Zhao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16110",
    "title": "Towards prediction of turbulent flows at high Reynolds numbers using  high performance computing data and deep learning",
    "abstract": "In this paper, deep learning (DL) methods are evaluated in the context of turbulent flows. Various generative adversarial networks (GANs) are discussed with respect to their suitability for understanding and modeling turbulence. Wasserstein GANs (WGANs) are then chosen to generate small-scale turbulence. Highly resolved direct numerical simulation (DNS) turbulent data is used for training the WGANs and the effect of network parameters, such as learning rate and loss function, is studied. Qualitatively good agreement between DNS input data and generated turbulent structures is shown. A quantitative statistical assessment of the predicted turbulent fields is performed. ",
    "url": "https://arxiv.org/abs/2210.16110",
    "authors": [
      "Mathis Bode",
      "Michael Gauding",
      "Jens Henrik G\u00f6bbert",
      "Baohao Liao",
      "Jenia Jitsev",
      "Heinz Pitsch"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16127",
    "title": "Target-Speaker Voice Activity Detection via Sequence-to-Sequence  Prediction",
    "abstract": "Target-speaker voice activity detection is currently a promising approach for speaker diarization in complex acoustic environments. This paper presents a novel Sequence-to-Sequence Target-Speaker Voice Activity Detection (Seq2Seq-TSVAD) method that can efficiently address the joint modeling of large-scale speakers and predict high-resolution voice activities. Experimental results show that larger speaker capacity and higher output resolution can significantly reduce the diarization error rate (DER), which achieves the new state-of-the-art performance of 4.55% on the VoxConverse test set and 10.77% on Track 1 of the DIHARD-III evaluation set under the widely-used evaluation metrics. ",
    "url": "https://arxiv.org/abs/2210.16127",
    "authors": [
      "Ming Cheng",
      "Weiqing Wang",
      "Yucong Zhang",
      "Xiaoyi Qin",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.16206",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Turbulent Premixed Combustion and Engine-like Flame  Kernel Direct Numerical Simulation Data",
    "abstract": "Models for finite-rate-chemistry in underresolved flows still pose one of the main challenges for predictive simulations of complex configurations. The problem gets even more challenging if turbulence is involved. This work advances the recently developed PIESRGAN modeling approach to turbulent premixed combustion. For that, the physical information processed by the network and considered in the loss function are adjusted, the training process is smoothed, and especially effects from density changes are considered. The resulting model provides good results for a priori and a posteriori tests on direct numerical simulation data of a fully turbulent premixed flame kernel. The limits of the modeling approach are discussed. Finally, the model is employed to compute further realizations of the premixed flame kernel, which are analyzed with a scale-sensitive framework regarding their cycle-to-cycle variations. The work shows that the data-driven PIESRGAN subfilter model can very accurately reproduce direct numerical simulation data on much coarser meshes, which is hardly possible with classical subfilter models, and enables studying statistical processes more efficiently due to the smaller computing cost. ",
    "url": "https://arxiv.org/abs/2210.16206",
    "authors": [
      "Mathis Bode",
      "Michael Gauding",
      "Dominik Goeb",
      "Tobias Falkenstein",
      "Heinz Pitsch"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16215",
    "title": "Physics-Informed Convolutional Neural Networks for Corruption Removal on  Dynamical Systems",
    "abstract": "Measurements on dynamical systems, experimental or otherwise, are often subjected to inaccuracies capable of introducing corruption; removal of which is a problem of fundamental importance in the physical sciences. In this work we propose physics-informed convolutional neural networks for stationary corruption removal, providing the means to extract physical solutions from data, given access to partial ground-truth observations at collocation points. We showcase the methodology for 2D incompressible Navier-Stokes equations in the chaotic-turbulent flow regime, demonstrating robustness to modality and magnitude of corruption. ",
    "url": "https://arxiv.org/abs/2210.16215",
    "authors": [
      "Daniel Kelshaw",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16219",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Finite-Rate-Chemistry Flows and Predicting Lean  Premixed Gas Turbine Combustors",
    "abstract": "The accurate prediction of small scales in underresolved flows is still one of the main challenges in predictive simulations of complex configurations. Over the last few years, data-driven modeling has become popular in many fields as large, often extensively labeled datasets are now available and training of large neural networks has become possible on graphics processing units (GPUs) that speed up the learning process tremendously. In fact, the successful application of deep neural networks in fluid dynamics, such as for underresolved reactive flows, is still challenging. This work advances the recently introduced PIESRGAN to reactive finite-rate-chemistry flows. However, since combustion chemistry typically acts on the smallest scales, the original approach needs to be extended. Therefore, the modeling approach of PIESRGAN is modified to accurately account for the challenges in the context of laminar finite-rate-chemistry flows. The modified PIESRGAN-based model gives good agreement in a priori and a posteriori tests in a laminar lean premixed combustion setup. Furthermore, a reduced PIESRGAN-based model is presented that solves only the major species on a reconstructed field and employs PIERSGAN lookup for the remaining species, utilizing staggering in time. The advantages of the discriminator-supported training are shown, and the usability of the new model demonstrated in the context of a model gas turbine combustor. ",
    "url": "https://arxiv.org/abs/2210.16219",
    "authors": [
      "Mathis Bode"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16248",
    "title": "Applying Physics-Informed Enhanced Super-Resolution Generative  Adversarial Networks to Turbulent Non-Premixed Combustion on Non-Uniform  Meshes and Demonstration of an Accelerated Simulation Workflow",
    "abstract": "This paper extends the methodology to use physics-informed enhanced super-resolution generative adversarial networks (PIESRGANs) for LES subfilter modeling in turbulent flows with finite-rate chemistry and shows a successful application to a non-premixed temporal jet case. This is an important topic considering the need for more efficient and carbon-neutral energy devices to fight the climate change. Multiple a priori and a posteriori results are presented and discussed. As part of this, the impact of the underlying mesh on the prediction quality is emphasized, and a multi-mesh approach is developed. It is demonstrated how LES based on PIESRGAN can be employed to predict cases at Reynolds numbers which were not used for training. Finally, the amount of data needed for a successful prediction is elaborated. ",
    "url": "https://arxiv.org/abs/2210.16248",
    "authors": [
      "Mathis Bode"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16272",
    "title": "Learning with Multigraph Convolutional Filters",
    "abstract": "In this paper, we introduce a convolutional architecture to perform learning when information is supported on multigraphs. Exploiting algebraic signal processing (ASP), we propose a convolutional signal processing model on multigraphs (MSP). Then, we introduce multigraph convolutional neural networks (MGNNs) as stacked and layered structures where information is processed according to an MSP model. We also develop a procedure for tractable computation of filter coefficients in the MGNN and a low cost method to reduce the dimensionality of the information transferred between layers. We conclude by comparing the performance of MGNNs against other learning architectures on an optimal resource allocation task for multi-channel communication systems. ",
    "url": "https://arxiv.org/abs/2210.16272",
    "authors": [
      "Landon Butler",
      "Alejandro Parada-Mayorga",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16281",
    "title": "Terrain-like Graphs and the Median Genocchi Numbers",
    "abstract": "A graph with vertex set $\\{1,\\ldots,n\\}$ is terrain-like if, for any edge pair $\\{a,c\\},\\{b,d\\}$ with $a<b<c<d$, the edge $\\{a,d\\}$ also exists. Terrain-like graphs frequently appear in geometry in the context of visibility graphs. We show that terrain-like graphs are counted by the median Genocchi numbers. To this end, we prove a bijection between terrain-like graphs and Dumont derangements of the second kind. ",
    "url": "https://arxiv.org/abs/2210.16281",
    "authors": [
      "Vincent Froese",
      "Malte Renken"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2005.08632",
    "title": "Universalization of any adversarial attack using very few test examples",
    "abstract": " Comments: Appeared in ACM CODS-COMAD 2022 (Research Track) ",
    "url": "https://arxiv.org/abs/2005.08632",
    "authors": [
      "Sandesh Kamath",
      "Amit Deshpande",
      "K V Subrahmanyam",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.03920",
    "title": "Do ideas have shape? Idea registration as the continuous limit of  artificial neural networks",
    "abstract": " Comments: 65 pages. To appear in Physica D (special issue on Machine Learning and Dynamical Systems) ",
    "url": "https://arxiv.org/abs/2008.03920",
    "authors": [
      "Houman Owhadi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.15274",
    "title": "Provably Training Overparameterized Neural Network Classifiers with  Non-convex Constraints",
    "abstract": " Title: Provably Training Overparameterized Neural Network Classifiers with  Non-convex Constraints ",
    "url": "https://arxiv.org/abs/2012.15274",
    "authors": [
      "You-Lin Chen",
      "Zhaoran Wang",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2102.11469",
    "title": "Analysis of Evolutionary Diversity Optimisation for Permutation Problems",
    "abstract": " Comments: 20 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2102.11469",
    "authors": [
      "Anh Viet Do",
      "Mingyu Guo",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2104.08763",
    "title": "Making Attention Mechanisms More Robust and Interpretable with Virtual  Adversarial Training",
    "abstract": " Comments: 18 pages, 3 figures. Accepted for publication in Springer Applied Intelligence (APIN) ",
    "url": "https://arxiv.org/abs/2104.08763",
    "authors": [
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.07047",
    "title": "Expected Values for Variable Network Games",
    "abstract": " Title: Expected Values for Variable Network Games ",
    "url": "https://arxiv.org/abs/2108.07047",
    "authors": [
      "Subhadip Chakrabarti",
      "Loyimee Gogoi",
      "Robert P Gilles",
      "Surajit Borkotokey",
      "Rajnish Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2109.10561",
    "title": "Few-Shot Sound Source Distance Estimation Using Relation Networks",
    "abstract": " Title: Few-Shot Sound Source Distance Estimation Using Relation Networks ",
    "url": "https://arxiv.org/abs/2109.10561",
    "authors": [
      "Amirreza Sobhdel",
      "Roozbeh Razavi-Far",
      "Saeed Shahrivari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.04004",
    "title": "Trident Pyramid Networks: The importance of processing at the feature  pyramid level for better object detection",
    "abstract": " Comments: Accepted at BMVC 2022 ",
    "url": "https://arxiv.org/abs/2110.04004",
    "authors": [
      "C\u00e9dric Picron",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.08565",
    "title": "Dynamic Graph Echo State Networks",
    "abstract": " Comments: Accepted for oral presentation at ESANN 2021 ",
    "url": "https://arxiv.org/abs/2110.08565",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2110.11024",
    "title": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "abstract": " Comments: 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2110.11024",
    "authors": [
      "Jing Xu",
      "Stefanos Koffas",
      "Oguzhan Ersoy",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.06206",
    "title": "SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph  Reasoning",
    "abstract": " Comments: EMNLP 2022. Code is available at $\\href{this https URL}{\\text{this https URL}}$ ",
    "url": "https://arxiv.org/abs/2201.06206",
    "authors": [
      "Yushi Bai",
      "Xin Lv",
      "Juanzi Li",
      "Lei Hou",
      "Yincen Qu",
      "Zelin Dai",
      "Feiyu Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.09254",
    "title": "How networks shape diversity for better or worse",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2201.09254",
    "authors": [
      "Andrea Musso",
      "Dirk Helbing"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.13086",
    "title": "Securing Federated Sensitive Topic Classification against Poisoning  Attacks",
    "abstract": " Title: Securing Federated Sensitive Topic Classification against Poisoning  Attacks ",
    "url": "https://arxiv.org/abs/2201.13086",
    "authors": [
      "Tianyue Chu",
      "Alvaro Garcia-Recuero",
      "Costas Iordanou",
      "Georgios Smaragdakis",
      "Nikolaos Laoutaris"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.03101",
    "title": "Nonparametric Uncertainty Quantification for Single Deterministic Neural  Network",
    "abstract": " Comments: NeurIPS 2022 paper ",
    "url": "https://arxiv.org/abs/2202.03101",
    "authors": [
      "Nikita Kotelevskii",
      "Aleksandr Artemenkov",
      "Kirill Fedyanin",
      "Fedor Noskov",
      "Alexander Fishkov",
      "Artem Shelmanov",
      "Artem Vazhentsev",
      "Aleksandr Petiushko",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08011",
    "title": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks",
    "abstract": " Title: Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks ",
    "url": "https://arxiv.org/abs/2202.08011",
    "authors": [
      "Jingyan Zhou",
      "Jiawen Deng",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Minlie Huang",
      "Xin Jiang",
      "Qun Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.12560",
    "title": "Kron Reduction and Effective Resistance of Directed Graphs",
    "abstract": " Title: Kron Reduction and Effective Resistance of Directed Graphs ",
    "url": "https://arxiv.org/abs/2202.12560",
    "authors": [
      "Tomohiro Sugiyama",
      "Kazuhiro Sato"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.02592",
    "title": "Sparsity-Inducing Categorical Prior Improves Robustness of the  Information Bottleneck",
    "abstract": " Title: Sparsity-Inducing Categorical Prior Improves Robustness of the  Information Bottleneck ",
    "url": "https://arxiv.org/abs/2203.02592",
    "authors": [
      "Anirban Samaddar",
      "Sandeep Madireddy",
      "Prasanna Balaprakash",
      "Tapabrata Maiti",
      "Gustavo de los Campos",
      "Ian Fischer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.02630",
    "title": "Online Adversarial Stabilization of Unknown Networked Systems",
    "abstract": " Title: Online Adversarial Stabilization of Unknown Networked Systems ",
    "url": "https://arxiv.org/abs/2203.02630",
    "authors": [
      "Jing Yu",
      "Dimitar Ho",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.09303",
    "title": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "abstract": " Title: MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks ",
    "url": "https://arxiv.org/abs/2203.09303",
    "authors": [
      "Angel Villar-Corrales",
      "Ani Karapetyan",
      "Andreas Boltres",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.10885",
    "title": "Zoom Out and Observe: News Environment Perception for Fake News  Detection",
    "abstract": " Comments: ACL 2022 Main Conference (Long Paper) ",
    "url": "https://arxiv.org/abs/2203.10885",
    "authors": [
      "Qiang Sheng",
      "Juan Cao",
      "Xueyao Zhang",
      "Rundong Li",
      "Danding Wang",
      "Yongchun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.14084",
    "title": "3D-OAE: Occlusion Auto-Encoders for Self-Supervised Learning on Point  Clouds",
    "abstract": " Comments: Project page: this https URL; Code and data: this https URL ",
    "url": "https://arxiv.org/abs/2203.14084",
    "authors": [
      "Junsheng Zhou",
      "Xin Wen",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Yue Gao",
      "Yi Fang",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14171",
    "title": "A Speech Representation Anonymization Framework via Selective Noise  Perturbation",
    "abstract": " Title: A Speech Representation Anonymization Framework via Selective Noise  Perturbation ",
    "url": "https://arxiv.org/abs/2203.14171",
    "authors": [
      "Minh Tran",
      "Mohammad Soleymani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.00497",
    "title": "Mining contrast sets in classification, regression, and survival data by  fusing separate and conquer models",
    "abstract": " Comments: 33 pages, 6 figures, 3 tables, 3 algorithms ",
    "url": "https://arxiv.org/abs/2204.00497",
    "authors": [
      "Adam Gudy\u015b",
      "Marek Sikora",
      "\u0141ukasz Wr\u00f3bel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.02446",
    "title": "Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models",
    "abstract": " Comments: To be published in the Fourth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2022) ",
    "url": "https://arxiv.org/abs/2204.02446",
    "authors": [
      "Birendra Jha",
      "Medha Atre",
      "Ashwini Rao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04977",
    "title": "Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures",
    "abstract": " Title: Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures ",
    "url": "https://arxiv.org/abs/2204.04977",
    "authors": [
      "Giovanni Bonetta",
      "Matteo Ribero",
      "Rossella Cancelliere"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09641",
    "title": "SNaC: Coherence Error Detection for Narrative Summarization",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2205.09641",
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.06126",
    "title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform",
    "abstract": " Comments: 15 pages, 13 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2206.06126",
    "authors": [
      "Gaetan Frusque",
      "Olga Fink"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.06369",
    "title": "Towards predicting dynamic stability of power grids with Graph Neural  Networks",
    "abstract": " Comments: 10 pages + references and appendix, 8 figures ",
    "url": "https://arxiv.org/abs/2206.06369",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2206.14547",
    "title": "A Novel Attack to the Permuted Kernel Problem",
    "abstract": " Title: A Novel Attack to the Permuted Kernel Problem ",
    "url": "https://arxiv.org/abs/2206.14547",
    "authors": [
      "Paolo Santini",
      "Marco Baldi",
      "Franco Chiaraluce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14855",
    "title": "SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice",
    "abstract": " Title: SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice ",
    "url": "https://arxiv.org/abs/2206.14855",
    "authors": [
      "Mohit Singhal",
      "Chen Ling",
      "Pujan Paudel",
      "Poojitha Thota",
      "Nihal Kumarswamy",
      "Gianluca Stringhini",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.14976",
    "title": "Semi-Supervised Generative Adversarial Network for Stress Detection  Using Partially Labeled Physiological Data",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2206.14976",
    "authors": [
      "Nibraas Khan",
      "Nilanjan Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.02810",
    "title": "Analyzing Data-Centric Properties for Graph Contrastive Learning",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2208.02810",
    "authors": [
      "Puja Trivedi",
      "Ekdeep Singh Lubana",
      "Mark Heimann",
      "Danai Koutra",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06917",
    "title": "MTCSNN: Multi-task Clinical Siamese Neural Network for Diabetic  Retinopathy Severity Prediction",
    "abstract": " Comments: This paper is not sufficiently exhaustive and lacks some analysis. Besides, certain methods of this paper are from the first author's other co-first authoring research paper. There exist disputes among authors, thus we decide to withdraw this paper currently ",
    "url": "https://arxiv.org/abs/2208.06917",
    "authors": [
      "Chao Feng",
      "Jui Po Hung",
      "Aishan Li",
      "Jieping Yang",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.09021",
    "title": "VAuLT: Augmenting the Vision-and-Language Transformer for Sentiment  Classification on Social Media",
    "abstract": " Comments: 5 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2208.09021",
    "authors": [
      "Georgios Chochlakis",
      "Tejas Srinivasan",
      "Jesse Thomason",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.05800",
    "title": "Time-of-Day Neural Style Transfer for Architectural Photographs",
    "abstract": " Comments: Updated version with corrected equations. Paper published at the International Conference on Computational Photography (ICCP) 2022. 12 pages of content with 6 pages of supplementary materials ",
    "url": "https://arxiv.org/abs/2209.05800",
    "authors": [
      "Yingshu Chen",
      "Tuan-Anh Vu",
      "Ka-Chun Shum",
      "Binh-Son Hua",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2209.07527",
    "title": "Improved proteasomal cleavage prediction with positive-unlabeled  learning",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 8 pages ",
    "url": "https://arxiv.org/abs/2209.07527",
    "authors": [
      "Emilio Dorigatti",
      "Bernd Bischl",
      "Benjamin Schubert"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10643",
    "title": "UPIR: Toward the Design of Unified Parallel Intermediate Representation  for Parallel Programming Models",
    "abstract": " Comments: Typos corrected. Format updated ",
    "url": "https://arxiv.org/abs/2209.10643",
    "authors": [
      "Anjia Wang",
      "Xinyao Yi",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.14734",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "abstract": " Comments: 22 pages. Preprint, under review ",
    "url": "https://arxiv.org/abs/2209.14734",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": " Comments: 7 Pages ",
    "url": "https://arxiv.org/abs/2210.03739",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04095",
    "title": "How do you go where? Improving next location prediction by learning  travel mode information using transformers",
    "abstract": " Comments: updated main figure, 10 pages, camera ready SIGSPATIAL '22 ",
    "url": "https://arxiv.org/abs/2210.04095",
    "authors": [
      "Ye Hong",
      "Henry Martin",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.07715",
    "title": "Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning",
    "abstract": " Title: Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning ",
    "url": "https://arxiv.org/abs/2210.07715",
    "authors": [
      "Tiantian He",
      "Haicang Zhou",
      "Yew-Soon Ong",
      "Gao Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08262",
    "title": "Motion estimation and filtered prediction for dynamic point cloud  attribute compression",
    "abstract": " Comments: Accepted for PCS2022 ",
    "url": "https://arxiv.org/abs/2210.08262",
    "authors": [
      "Haoran Hong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Ryosuke Watanabe",
      "Keisuke Nonaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.09482",
    "title": "You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous  Vehicles Driving Frameworks",
    "abstract": " Comments: Accepted to the 32nd USENIX Security Symposium (2023) ",
    "url": "https://arxiv.org/abs/2210.09482",
    "authors": [
      "Yulong Cao",
      "S. Hrushikesh Bhupathiraju",
      "Pirouz Naghavi",
      "Takeshi Sugawara",
      "Z. Morley Mao",
      "Sara Rampazzi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12791",
    "title": "O-type Stars Stellar Parameter Estimation Using Recurrent Neural  Networks",
    "abstract": " Title: O-type Stars Stellar Parameter Estimation Using Recurrent Neural  Networks ",
    "url": "https://arxiv.org/abs/2210.12791",
    "authors": [
      "Miguel Flores R.",
      "Luis J. Corral",
      "Celia R. Fierro-Santill\u00e1n",
      "Silvana G. Navarro"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14152",
    "title": "SleepMore: Sleep Prediction at Scale via Multi-Device WiFi Sensing",
    "abstract": " Comments: 29 pages, 24 figures, 14 tables ",
    "url": "https://arxiv.org/abs/2210.14152",
    "authors": [
      "Camellia Zakaria",
      "Gizem Yilmaz",
      "Priyanka Mammen",
      "Michael Chee",
      "Prashant Shenoy",
      "Rajesh Balan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14403",
    "title": "Stealthy Measurement-Aided Pole-Dynamics Attacks with Nominal Models",
    "abstract": " Title: Stealthy Measurement-Aided Pole-Dynamics Attacks with Nominal Models ",
    "url": "https://arxiv.org/abs/2210.14403",
    "authors": [
      "Dajun Du",
      "Changda Zhang",
      "Chen Peng",
      "Minrui Fei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.14666",
    "title": "Xiaoicesing 2: A High-Fidelity Singing Voice Synthesizer Based on  Generative Adversarial Network",
    "abstract": " Comments: submitted to icassp2023 ",
    "url": "https://arxiv.org/abs/2210.14666",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": " Title: Broken Neural Scaling Laws ",
    "url": "https://arxiv.org/abs/2210.14891",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15030",
    "title": "A Hierarchical Approach to Conditional Random Fields for System Anomaly  Detection",
    "abstract": " Comments: 8 pages, Preprint, This paper was originally written in 2019 ",
    "url": "https://arxiv.org/abs/2210.15030",
    "authors": [
      "Srishti Mishra",
      "Tvarita Jain",
      "Dinkar Sitaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.15056",
    "title": "UnfoldML: Cost-Aware and Uncertainty-Based Dynamic 2D Prediction for  Multi-Stage Classification",
    "abstract": " Comments: To be published in NeurIPS'22 ",
    "url": "https://arxiv.org/abs/2210.15056",
    "authors": [
      "Yanbo Xu",
      "Alind Khare",
      "Glenn Matlin",
      "Monish Ramadoss",
      "Rishikesan Kamaleswaran",
      "Chao Zhang",
      "Alexey Tumanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15149",
    "title": "Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study",
    "abstract": " Title: Deep Learning for Segmentation-based Hepatic Steatosis Detection on Open  Data: A Multicenter International Validation Study ",
    "url": "https://arxiv.org/abs/2210.15149",
    "authors": [
      "Zhongyi Zhang",
      "Guixia Li",
      "Ziqiang Wang",
      "Feng Xia",
      "Ning Zhao",
      "Huibin Nie",
      "Zezhong Ye",
      "Joshua Lin",
      "Yiyi Hui",
      "Xiangchun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15160",
    "title": "Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection",
    "abstract": " Title: Global-to-local Expression-aware Embeddings for Facial Action Unit  Detection ",
    "url": "https://arxiv.org/abs/2210.15160",
    "authors": [
      "Rudong An",
      "Wei Zhang",
      "Hao Zeng",
      "Wei Chen",
      "Zhigang Deng",
      "Yu Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15248",
    "title": "Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI",
    "abstract": " Title: Unsupervised Knowledge Graph Construction and Event-centric Knowledge  Infusion for Scientific NLI ",
    "url": "https://arxiv.org/abs/2210.15248",
    "authors": [
      "Chenglin Wang",
      "Yucheng Zhou",
      "Guodong Long",
      "Xiaodong Wang",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15305",
    "title": "Deformable Temporal Convolutional Networks for Monaural Noisy  Reverberant Speech Separation",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.15305",
    "authors": [
      "William Ravenscroft",
      "Stefan Goetze",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15401",
    "title": "Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "abstract": " Title: Video-based Remote Physiological Measurement via Self-supervised  Learning ",
    "url": "https://arxiv.org/abs/2210.15401",
    "authors": [
      "Zijie Yue",
      "Miaojing Shi",
      "Shuai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15539",
    "title": "Deep Convolutional Neural Networks for Multi-Target Tracking: A Transfer  Learning Approach",
    "abstract": " Comments: 5 pages, 4 figures; submitted to Proc. ICASSP2023, June 04-09, 2023, Rhodes Island, Greece; Associated code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.15539",
    "authors": [
      "Damian Owerko",
      "Charilaos Kanatsoulis",
      "Alejandro Ribeiro",
      "Donald J. Bucci Jr",
      "Jennifer Bondarchuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  }
]