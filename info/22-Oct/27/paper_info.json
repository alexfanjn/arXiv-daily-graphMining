[
  {
    "id": "arXiv:2210.14225",
    "title": "Flexible Android Malware Detection Model based on Generative Adversarial  Networks with Code Tensor",
    "abstract": "The behavior of malware threats is gradually increasing, heightened the need for malware detection. However, existing malware detection methods only target at the existing malicious samples, the detection of fresh malicious code and variants of malicious code is limited. In this paper, we propose a novel scheme that detects malware and its variants efficiently. Based on the idea of the generative adversarial networks (GANs), we obtain the `true' sample distribution that satisfies the characteristics of the real malware, use them to deceive the discriminator, thus achieve the defense against malicious code attacks and improve malware detection. Firstly, a new Android malware APK to image texture feature extraction segmentation method is proposed, which is called segment self-growing texture segmentation algorithm. Secondly, tensor singular value decomposition (tSVD) based on the low-tubal rank transforms malicious features with different sizes into a fixed third-order tensor uniformly, which is entered into the neural network for training and learning. Finally, a flexible Android malware detection model based on GANs with code tensor (MTFD-GANs) is proposed. Experiments show that the proposed model can generally surpass the traditional malware detection model, with a maximum improvement efficiency of 41.6\\%. At the same time, the newly generated samples of the GANs generator greatly enrich the sample diversity. And retraining malware detector can effectively improve the detection efficiency and robustness of traditional models. ",
    "url": "https://arxiv.org/abs/2210.14225",
    "authors": [
      "Zhao Yang",
      "Fengyang Deng",
      "Linxi Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14226",
    "title": "FedClassAvg: Local Representation Learning for Personalized Federated  Learning on Heterogeneous Neural Networks",
    "abstract": "Personalized federated learning is aimed at allowing numerous clients to train personalized models while participating in collaborative training in a communication-efficient manner without exchanging private data. However, many personalized federated learning algorithms assume that clients have the same neural network architecture, and those for heterogeneous models remain understudied. In this study, we propose a novel personalized federated learning method called federated classifier averaging (FedClassAvg). Deep neural networks for supervised learning tasks consist of feature extractor and classifier layers. FedClassAvg aggregates classifier weights as an agreement on decision boundaries on feature spaces so that clients with not independently and identically distributed (non-iid) data can learn about scarce labels. In addition, local feature representation learning is applied to stabilize the decision boundaries and improve the local feature extraction capabilities for clients. While the existing methods require the collection of auxiliary data or model weights to generate a counterpart, FedClassAvg only requires clients to communicate with a couple of fully connected layers, which is highly communication-efficient. Moreover, FedClassAvg does not require extra optimization problems such as knowledge transfer, which requires intensive computation overhead. We evaluated FedClassAvg through extensive experiments and demonstrated it outperforms the current state-of-the-art algorithms on heterogeneous personalized federated learning tasks. ",
    "url": "https://arxiv.org/abs/2210.14226",
    "authors": [
      "Jaehee Jang",
      "Heonseok Ha",
      "Dahuin Jung",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14228",
    "title": "'A net for everyone': fully personalized and unsupervised neural  networks trained with longitudinal data from a single patient",
    "abstract": "With the rise in importance of personalized medicine, we trained personalized neural networks to detect tumor progression in longitudinal datasets. The model was evaluated on two datasets with a total of 64 scans from 32 patients diagnosed with glioblastoma multiforme (GBM). Contrast-enhanced T1w sequences of brain magnetic resonance imaging (MRI) images were used in this study. For each patient, we trained their own neural network using just two images from different timepoints. Our approach uses a Wasserstein-GAN (generative adversarial network), an unsupervised network architecture, to map the differences between the two images. Using this map, the change in tumor volume can be evaluated. Due to the combination of data augmentation and the network architecture, co-registration of the two images is not needed. Furthermore, we do not rely on any additional training data, (manual) annotations or pre-training neural networks. The model received an AUC-score of 0.87 for tumor change. We also introduced a modified RANO criteria, for which an accuracy of 66% can be achieved. We show that using data from just one patient can be used to train deep neural networks to monitor tumor change. ",
    "url": "https://arxiv.org/abs/2210.14228",
    "authors": [
      "Christian Strack",
      "Kelsey L. Pomykala",
      "Heinz-Peter Schlemmer",
      "Jan Egger",
      "Jens Kleesiek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14229",
    "title": "Causal Information Bottleneck Boosts Adversarial Robustness of Deep  Neural Network",
    "abstract": "The information bottleneck (IB) method is a feasible defense solution against adversarial attacks in deep learning. However, this method suffers from the spurious correlation, which leads to the limitation of its further improvement of adversarial robustness. In this paper, we incorporate the causal inference into the IB framework to alleviate such a problem. Specifically, we divide the features obtained by the IB method into robust features (content information) and non-robust features (style information) via the instrumental variables to estimate the causal effects. With the utilization of such a framework, the influence of non-robust features could be mitigated to strengthen the adversarial robustness. We make an analysis of the effectiveness of our proposed method. The extensive experiments in MNIST, FashionMNIST, and CIFAR-10 show that our method exhibits the considerable robustness against multiple adversarial attacks. Our code would be released. ",
    "url": "https://arxiv.org/abs/2210.14229",
    "authors": [
      "Huan Hua",
      "Jun Yan",
      "Xi Fang",
      "Weiquan Huang",
      "Huilin Yin",
      "Wancheng Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14252",
    "title": "Dynamic Speech Endpoint Detection with Regression Targets",
    "abstract": "Interactive voice assistants have been widely used as input interfaces in various scenarios, e.g. on smart homes devices, wearables and on AR devices. Detecting the end of a speech query, i.e. speech end-pointing, is an important task for voice assistants to interact with users. Traditionally, speech end-pointing is based on pure classification methods along with arbitrary binary targets. In this paper, we propose a novel regression-based speech end-pointing model, which enables an end-pointer to adjust its detection behavior based on context of user queries. Specifically, we present a pause modeling method and show its effectiveness for dynamic end-pointing. Based on our experiments with vendor-collected smartphone and wearables speech queries, our strategy shows a better trade-off between endpointing latency and accuracy, compared to the traditional classification-based method. We further discuss the benefits of this model and generalization of the framework in the paper. ",
    "url": "https://arxiv.org/abs/2210.14252",
    "authors": [
      "Dawei Liang",
      "Hang Su",
      "Tarun Singh",
      "Jay Mahadeokar",
      "Shanil Puri",
      "Jiedan Zhu",
      "Edison Thomaz",
      "Mike Seltzer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14253",
    "title": "Classification and Self-Supervised Regression of Arrhythmic ECG Signals  Using Convolutional Neural Networks",
    "abstract": "Interpretation of electrocardiography (ECG) signals is required for diagnosing cardiac arrhythmia. Recently, machine learning techniques have been applied for automated computer-aided diagnosis. Machine learning tasks can be divided into regression and classification. Regression can be used for noise and artifacts removal as well as resolve issues of missing data from low sampling frequency. Classification task concerns the prediction of output diagnostic classes according to expert-labeled input classes. In this work, we propose a deep neural network model capable of solving regression and classification tasks. Moreover, we combined the two approaches, using unlabeled and labeled data, to train the model. We tested the model on the MIT-BIH Arrhythmia database. Our method showed high effectiveness in detecting cardiac arrhythmia based on modified Lead II ECG records, as well as achieved high quality of ECG signal approximation. For the former, our method attained overall accuracy of 87:33% and balanced accuracy of 80:54%, on par with reference approaches. For the latter, application of self-supervised learning allowed for training without the need for expert labels. The regression model yielded satisfactory performance with fairly accurate prediction of QRS complexes. Transferring knowledge from regression to the classification task, our method attained higher overall accuracy of 87:78%. ",
    "url": "https://arxiv.org/abs/2210.14253",
    "authors": [
      "Bartosz Grabowski",
      "Przemys\u0142aw G\u0142omb",
      "Wojciech Masarczyk",
      "Pawe\u0142 P\u0142awiak",
      "\u00d6zal Y\u0131ld\u0131r\u0131m",
      "U Rajendra Acharya",
      "Ru-San Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.14254",
    "title": "Leveraging Open Data and Task Augmentation to Automated Behavioral  Coding of Psychotherapy Conversations in Low-Resource Scenarios",
    "abstract": "In psychotherapy interactions, the quality of a session is assessed by codifying the communicative behaviors of participants during the conversation through manual observation and annotation. Developing computational approaches for automated behavioral coding can reduce the burden on human coders and facilitate the objective evaluation of the intervention. In the real world, however, implementing such algorithms is associated with data sparsity challenges since privacy concerns lead to limited available in-domain data. In this paper, we leverage a publicly available conversation-based dataset and transfer knowledge to the low-resource behavioral coding task by performing an intermediate language model training via meta-learning. We introduce a task augmentation method to produce a large number of \"analogy tasks\" - tasks similar to the target one - and demonstrate that the proposed framework predicts target behaviors more accurately than all the other baseline models. ",
    "url": "https://arxiv.org/abs/2210.14254",
    "authors": [
      "Zhuohao Chen",
      "Nikolaos Flemotomos",
      "Zac E. Imel",
      "David C. Atkins",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14260",
    "title": "Universal Evasion Attacks on Summarization Scoring",
    "abstract": "The automatic scoring of summaries is important as it guides the development of summarizers. Scoring is also complex, as it involves multiple aspects such as fluency, grammar, and even textual entailment with the source text. However, summary scoring has not been considered a machine learning task to study its accuracy and robustness. In this study, we place automatic scoring in the context of regression machine learning tasks and perform evasion attacks to explore its robustness. Attack systems predict a non-summary string from each input, and these non-summary strings achieve competitive scores with good summarizers on the most popular metrics: ROUGE, METEOR, and BERTScore. Attack systems also \"outperform\" state-of-the-art summarization methods on ROUGE-1 and ROUGE-L, and score the second-highest on METEOR. Furthermore, a BERTScore backdoor is observed: a simple trigger can score higher than any automatic summarization method. The evasion attacks in this work indicate the low robustness of current scoring systems at the system level. We hope that our highlighting of these proposed attacks will facilitate the development of summary scores. ",
    "url": "https://arxiv.org/abs/2210.14260",
    "authors": [
      "Wenchuan Mu",
      "Kwan Hui Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14283",
    "title": "Accelerating Certified Robustness Training via Knowledge Transfer",
    "abstract": "Training deep neural network classifiers that are certifiably robust against adversarial attacks is critical to ensuring the security and reliability of AI-controlled systems. Although numerous state-of-the-art certified training methods have been developed, they are computationally expensive and scale poorly with respect to both dataset and network complexity. Widespread usage of certified training is further hindered by the fact that periodic retraining is necessary to incorporate new data and network improvements. In this paper, we propose Certified Robustness Transfer (CRT), a general-purpose framework for reducing the computational overhead of any certifiably robust training method through knowledge transfer. Given a robust teacher, our framework uses a novel training loss to transfer the teacher's robustness to the student. We provide theoretical and empirical validation of CRT. Our experiments on CIFAR-10 show that CRT speeds up certified robustness training by $8 \\times$ on average across three different architecture generations while achieving comparable robustness to state-of-the-art methods. We also show that CRT can scale to large-scale datasets like ImageNet. ",
    "url": "https://arxiv.org/abs/2210.14283",
    "authors": [
      "Pratik Vaishnavi",
      "Kevin Eykholt",
      "Amir Rahmati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14284",
    "title": "Refining Action Boundaries for One-stage Detection",
    "abstract": "Current one-stage action detection methods, which simultaneously predict action boundaries and the corresponding class, do not estimate or use a measure of confidence in their boundary predictions, which can lead to inaccurate boundaries. We incorporate the estimation of boundary confidence into one-stage anchor-free detection, through an additional prediction head that predicts the refined boundaries with higher confidence. We obtain state-of-the-art performance on the challenging EPIC-KITCHENS-100 action detection as well as the standard THUMOS14 action detection benchmarks, and achieve improvement on the ActivityNet-1.3 benchmark. ",
    "url": "https://arxiv.org/abs/2210.14284",
    "authors": [
      "Hanyuan Wang",
      "Majid Mirmehdi",
      "Dima Damen",
      "Toby Perrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14290",
    "title": "Parallel Order-Based Core Maintenance in Dynamic Graphs",
    "abstract": "The core numbers of vertices in a graph are one of the most well-studied cohesive subgraph models because of the linear running time. In practice, many data graphs are dynamic graphs that are continuously changing by inserting or removing edges. The core numbers are updated in dynamic graphs with edge insertions and deletions, which is called core maintenance. When a burst of a large number of inserted or removed edges come in, we have to handle these edges on time to keep up with the data stream. There are two main sequential algorithms for core maintenance, \\textsc{Traversal} and \\textsc{Order}. It is proved that the \\textsc{Order} algorithm significantly outperforms the \\alg{Traversal} algorithm over all tested graphs with up to 2,083 times speedups. To the best of our knowledge, all existing parallel approaches are based on the \\alg{Traversal} algorithm; also, their parallelism exists only for affected vertices with different core numbers, which will reduce to sequential when all vertices have the same core numbers. In this paper, we propose a new parallel core maintenance algorithm based on the \\alg{Order} algorithm. Importantly, our new approach always has parallelism, even for the graphs where all vertices have the same core numbers. Extensive experiments are conducted over real-world, temporal, and synthetic graphs on a 64-core machine. The results show that for inserting and removing 100,000 edges using 16-worker, our method achieves up to 289x and 10x times speedups compared with the most efficient existing method, respectively. ",
    "url": "https://arxiv.org/abs/2210.14290",
    "authors": [
      "Bin Guo",
      "Emil Sekerinski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14299",
    "title": "OpenStance: Real-world Zero-shot Stance Detection",
    "abstract": "Prior studies of zero-shot stance detection identify the attitude of texts towards unseen topics occurring in the same document corpus. Such task formulation has three limitations: (i) Single domain/dataset. A system is optimized on a particular dataset from a single domain; therefore, the resulting system cannot work well on other datasets; (ii) the model is evaluated on a limited number of unseen topics; (iii) it is assumed that part of the topics has rich annotations, which might be impossible in real-world applications. These drawbacks will lead to an impractical stance detection system that fails to generalize to open domains and open-form topics. This work defines OpenStance: open-domain zero-shot stance detection, aiming to handle stance detection in an open world with neither domain constraints nor topic-specific annotations. The key challenge of OpenStance lies in the open-domain generalization: learning a system with fully unspecific supervision but capable of generalizing to any dataset. To solve OpenStance, we propose to combine indirect supervision, from textual entailment datasets, and weak supervision, from data generated automatically by pre-trained Language Models. Our single system, without any topic-specific supervision, outperforms the supervised method on three popular datasets. To our knowledge, this is the first work that studies stance detection under the open-domain zero-shot setting. All data and code are publicly released. ",
    "url": "https://arxiv.org/abs/2210.14299",
    "authors": [
      "Hanzi Xu",
      "Slobodan Vucetic",
      "Wenpeng Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14307",
    "title": "On Robust Incremental Learning over Many Multilingual Steps",
    "abstract": "Recent work in incremental learning has introduced diverse approaches to tackle catastrophic forgetting from data augmentation to optimized training regimes. However, most of them focus on very few training steps. We propose a method for robust incremental learning over dozens of fine-tuning steps using data from a variety of languages. We show that a combination of data-augmentation and an optimized training regime allows us to continue improving the model even for as many as fifty training steps. Crucially, our augmentation strategy does not require retaining access to previous training data and is suitable in scenarios with privacy constraints. ",
    "url": "https://arxiv.org/abs/2210.14307",
    "authors": [
      "Karan Praharaj",
      "Irina Matveeva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14309",
    "title": "Empowering Long-tail Item Recommendation through Cross Decoupling  Network (CDN)",
    "abstract": "Recommenders provide personalized content recommendations to users. They often suffer from highly skewed long-tail item distributions, with a small fraction of the items receiving most of the user feedback. This hurts model quality especially for the slices without much supervision. Existing work in both academia and industry mainly focuses on re-balancing strategies (e.g., up-sampling and up-weighting), leveraging content features, and transfer learning. However, there still lacks of a deeper understanding of how the long-tail distribution influences the recommendation performance. In this work, we theoretically demonstrate that the prediction of user preference is biased under the long-tail distributions. This bias comes from the discrepancy of both the prior and conditional probabilities between training data and test data. Most existing methods mainly attempt to reduce the bias from the prior perspective, which ignores the discrepancy in the conditional probability. This leads to a severe forgetting issue and results in suboptimal performance. To address the problem, we design a novel Cross Decoupling Network (CDN) to reduce the differences in both prior and conditional probabilities. Specifically, CDN (i) decouples the learning process of memorization and generalization on the item side through a mixture-of-expert structure; (ii) decouples the user samples from different distributions through a regularized bilateral branch network. Finally, a novel adapter is introduced to aggregate the decoupled vectors, and softly shift the training attention to tail items. Extensive experimental results show that CDN significantly outperforms state-of-the-art approaches on popular benchmark datasets, leading to an improvement in HR@50 (hit ratio) of 8.7\\% for overall recommendation and 12.4\\% for tail items. ",
    "url": "https://arxiv.org/abs/2210.14309",
    "authors": [
      "Yin Zhang",
      "Ruoxi Wang",
      "Derek Zhiyuan Cheng",
      "Tiansheng Yao",
      "Xinyang Yi",
      "Lichan Hong",
      "James Caverlee",
      "Ed H. Chi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.14312",
    "title": "JAX-DIPS: Neural bootstrapping of finite discretization methods and  application to elliptic problems with discontinuities",
    "abstract": "We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models for the solution functions and operators of partial differential equations while retaining the accuracy and convergence properties of the state-of-the-art numerical solvers. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. We apply NBM to the important class of elliptic problems with jump conditions across irregular interfaces in three spatial dimensions. We show the method is convergent such that model accuracy improves by increasing number of collocation points in the domain. The algorithms presented here are implemented and released in a software package named JAX-DIPS (https://github.com/JAX-DIPS/JAX-DIPS), standing for differentiable interfacial PDE solver. JAX-DIPS is purely developed in JAX, offering end-to-end differentiability from mesh generation to the higher level discretization abstractions, geometric integrations, and interpolations, thus facilitating research into use of differentiable algorithms for developing hybrid PDE solvers. ",
    "url": "https://arxiv.org/abs/2210.14312",
    "authors": [
      "Pouria Mistani",
      "Samira Pakravan",
      "Rajesh Ilango",
      "Frederic Gibou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.14315",
    "title": "Streaming Submodular Maximization with Differential Privacy",
    "abstract": "In this work, we study the problem of privately maximizing a submodular function in the streaming setting. Extensive work has been done on privately maximizing submodular functions in the general case when the function depends upon the private data of individuals. However, when the size of the data stream drawn from the domain of the objective function is large or arrives very fast, one must privately optimize the objective within the constraints of the streaming setting. We establish fundamental differentially private baselines for this problem and then derive better trade-offs between privacy and utility for the special case of decomposable submodular functions. A submodular function is decomposable when it can be written as a sum of submodular functions; this structure arises naturally when each summand function models the utility of an individual and the goal is to study the total utility of the whole population as in the well-known Combinatorial Public Projects Problem. Finally, we complement our theoretical analysis with experimental corroboration. ",
    "url": "https://arxiv.org/abs/2210.14315",
    "authors": [
      "Anamay Chaturvedi",
      "Huy L\u00ea Nguyen",
      "Thy Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.14320",
    "title": "FO-PINNs: A First-Order formulation for Physics Informed Neural Networks",
    "abstract": "We present FO-PINNs, physics-informed neural networks that are trained using the first-order formulation of the Partial Differential Equation (PDE) losses. We show that FO-PINNs offer significantly higher accuracy in solving parameterized systems compared to traditional PINNs, and reduce time-per-iteration by removing the extra backpropagations needed to compute the second or higher-order derivatives. Additionally, unlike standard PINNs, FO-PINNs can be used with exact imposition of boundary conditions using approximate distance functions, and can be trained using Automatic Mixed Precision (AMP) to further speed up the training. Through two Helmholtz and Navier-Stokes examples, we demonstrate the advantages of FO-PINNs over traditional PINNs in terms of accuracy and training speedup. ",
    "url": "https://arxiv.org/abs/2210.14320",
    "authors": [
      "Rini J. Gladstone",
      "Mohammad A. Nabian",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.14325",
    "title": "Obtrusive Subtleness and Why We Should Focus on Meaning, not Form, in  Social Acceptability Studies",
    "abstract": "Nowadays, interactive technologies are used almost everywhere. As a result, designers need to increasingly make them \"socially acceptable\". Previous work recommends \"subtle\" forms of interaction to increase social acceptability and avoid negative experiences. Although often appropriate, such uniform recommendations neglect the variety of social situations. We demonstrate this limitation in an experiment (N=35), by comparing the observer experience of different forms of interaction in \"face-to-face conversations\", a social situation rarely studied. Here, the typically recommended form of interaction (\"subtle\") led to a more negative observer experience than the usually deprecated form (\"suspenseful\"), in terms of affective experience and product perception. It also made the user appear less extraverted. We conclude by positioning interactions with technology not as separate from the social situation in which they are performed, but as a constitutive part of it that meaningfully relates to other situated activities. ",
    "url": "https://arxiv.org/abs/2210.14325",
    "authors": [
      "Alarith Uhde",
      "Tim zum Hoff",
      "Marc Hassenzahl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.14328",
    "title": "Causal Analysis of Syntactic Agreement Neurons in Multilingual Language  Models",
    "abstract": "Structural probing work has found evidence for latent syntactic information in pre-trained language models. However, much of this analysis has focused on monolingual models, and analyses of multilingual models have employed correlational methods that are confounded by the choice of probing tasks. In this study, we causally probe multilingual language models (XGLM and multilingual BERT) as well as monolingual BERT-based models across various languages; we do this by performing counterfactual perturbations on neuron activations and observing the effect on models' subject-verb agreement probabilities. We observe where in the model and to what extent syntactic agreement is encoded in each language. We find significant neuron overlap across languages in autoregressive multilingual language models, but not masked language models. We also find two distinct layer-wise effect patterns and two distinct sets of neurons used for syntactic agreement, depending on whether the subject and verb are separated by other tokens. Finally, we find that behavioral analyses of language models are likely underestimating how sensitive masked language models are to syntactic information. ",
    "url": "https://arxiv.org/abs/2210.14328",
    "authors": [
      "Aaron Mueller",
      "Yu Xia",
      "Tal Linzen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14350",
    "title": "Detection and estimation of spacecraft maneuvers for catalog maintenance",
    "abstract": "Building and maintaining a catalog of resident space objects involves several tasks, ranging from observations to data analysis. Once acquired, the knowledge of a space object needs to be updated following a dedicated observing schedule. Dynamics mismodeling and unknown maneuvers can alter the catalog's accuracy, resulting in uncorrelated observations originating from the same object. Starting from two independent orbits, this work presents a novel approach to detect and estimate maneuvers of resident space objects, which allows for correlation recovery. The estimation is performed with successive convex optimization without a-priori assumption on the thrust arcs structure and thrust direction. ",
    "url": "https://arxiv.org/abs/2210.14350",
    "authors": [
      "Laura Pirovano",
      "Roberto Armellin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2210.14360",
    "title": "LaundroGraph: Self-Supervised Graph Representation Learning for  Anti-Money Laundering",
    "abstract": "Anti-money laundering (AML) regulations mandate financial institutions to deploy AML systems based on a set of rules that, when triggered, form the basis of a suspicious alert to be assessed by human analysts. Reviewing these cases is a cumbersome and complex task that requires analysts to navigate a large network of financial interactions to validate suspicious movements. Furthermore, these systems have very high false positive rates (estimated to be over 95\\%). The scarcity of labels hinders the use of alternative systems based on supervised learning, reducing their applicability in real-world applications. In this work we present LaundroGraph, a novel self-supervised graph representation learning approach to encode banking customers and financial transactions into meaningful representations. These representations are used to provide insights to assist the AML reviewing process, such as identifying anomalous movements for a given customer. LaundroGraph represents the underlying network of financial interactions as a customer-transaction bipartite graph and trains a graph neural network on a fully self-supervised link prediction task. We empirically demonstrate that our approach outperforms other strong baselines on self-supervised link prediction using a real-world dataset, improving the best non-graph baseline by $12$ p.p. of AUC. The goal is to increase the efficiency of the reviewing process by supplying these AI-powered insights to the analysts upon review. To the best of our knowledge, this is the first fully self-supervised system within the context of AML detection. ",
    "url": "https://arxiv.org/abs/2210.14360",
    "authors": [
      "M\u00e1rio Cardoso",
      "Pedro Saleiro",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.14376",
    "title": "Robustness of Locally Differentially Private Graph Analysis Against  Poisoning",
    "abstract": "Locally differentially private (LDP) graph analysis allows private analysis on a graph that is distributed across multiple users. However, such computations are vulnerable to data poisoning attacks where an adversary can skew the results by submitting malformed data. In this paper, we formally study the impact of poisoning attacks for graph degree estimation protocols under LDP. We make two key technical contributions. First, we observe LDP makes a protocol more vulnerable to poisoning -- the impact of poisoning is worse when the adversary can directly poison their (noisy) responses, rather than their input data. Second, we observe that graph data is naturally redundant -- every edge is shared between two users. Leveraging this data redundancy, we design robust degree estimation protocols under LDP that can significantly reduce the impact of data poisoning and compute degree estimates with high accuracy. We evaluate our proposed robust degree estimation protocols under poisoning attacks on real-world datasets to demonstrate their efficacy in practice. ",
    "url": "https://arxiv.org/abs/2210.14376",
    "authors": [
      "Jacob Imola",
      "Amrita Roy Chowdhury",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14377",
    "title": "Fusing Modalities by Multiplexed Graph Neural Networks for Outcome  Prediction in Tuberculosis",
    "abstract": "In a complex disease such as tuberculosis, the evidence for the disease and its evolution may be present in multiple modalities such as clinical, genomic, or imaging data. Effective patient-tailored outcome prediction and therapeutic guidance will require fusing evidence from these modalities. Such multimodal fusion is difficult since the evidence for the disease may not be uniform across all modalities, not all modality features may be relevant, or not all modalities may be present for all patients. All these nuances make simple methods of early, late, or intermediate fusion of features inadequate for outcome prediction. In this paper, we present a novel fusion framework using multiplexed graphs and derive a new graph neural network for learning from such graphs. Specifically, the framework allows modalities to be represented through their targeted encodings, and models their relationship explicitly via multiplexed graphs derived from salient features in a combined latent space. We present results that show that our proposed method outperforms state-of-the-art methods of fusing modalities for multi-outcome prediction on a large Tuberculosis (TB) dataset. ",
    "url": "https://arxiv.org/abs/2210.14377",
    "authors": [
      "Niharika S. D'Souza",
      "Hongzhi Wang",
      "Andrea Giovannini",
      "Antonio Foncubierta-Rodriguez",
      "Kristen L. Beck",
      "Orest Boyko",
      "Tanveer Syeda-Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.14378",
    "title": "Bilingual Lexicon Induction for Low-Resource Languages using Graph  Matching via Optimal Transport",
    "abstract": "Bilingual lexicons form a critical component of various natural language processing applications, including unsupervised and semisupervised machine translation and crosslingual information retrieval. We improve bilingual lexicon induction performance across 40 language pairs with a graph-matching method based on optimal transport. The method is especially strong with low amounts of supervision. ",
    "url": "https://arxiv.org/abs/2210.14378",
    "authors": [
      "Kelly Marchisio",
      "Ali Saad-Eldin",
      "Kevin Duh",
      "Carey Priebe",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14392",
    "title": "Zero-Shot Learning of a Conditional Generative Adversarial Network for  Data-Free Network Quantization",
    "abstract": "We propose a novel method for training a conditional generative adversarial network (CGAN) without the use of training data, called zero-shot learning of a CGAN (ZS-CGAN). Zero-shot learning of a conditional generator only needs a pre-trained discriminative (classification) model and does not need any training data. In particular, the conditional generator is trained to produce labeled synthetic samples whose characteristics mimic the original training data by using the statistics stored in the batch normalization layers of the pre-trained model. We show the usefulness of ZS-CGAN in data-free quantization of deep neural networks. We achieved the state-of-the-art data-free network quantization of the ResNet and MobileNet classification models trained on the ImageNet dataset. Data-free quantization using ZS-CGAN showed a minimal loss in accuracy compared to that obtained by conventional data-dependent quantization. ",
    "url": "https://arxiv.org/abs/2210.14392",
    "authors": [
      "Yoojin Choi",
      "Mostafa El-Khamy",
      "Jungwon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.14393",
    "title": "Federated Fuzzy Neural Network with Evolutionary Rule Learning",
    "abstract": "Distributed fuzzy neural networks (DFNNs) have attracted increasing attention recently due to their learning abilities in handling data uncertainties in distributed scenarios. However, it is challenging for DFNNs to handle cases in which the local data are non-independent and identically distributed (non-IID). In this paper, we propose a federated fuzzy neural network (FedFNN) with evolutionary rule learning (ERL) to cope with non-IID issues as well as data uncertainties. The FedFNN maintains a global set of rules in a server and a personalized subset of these rules for each local client. ERL is inspired by the theory of biological evolution; it encourages rule variations while activating superior rules and deactivating inferior rules for local clients with non-IID data. Specifically, ERL consists of two stages in an iterative procedure: a rule cooperation stage that updates global rules by aggregating local rules based on their activation statuses and a rule evolution stage that evolves the global rules and updates the activation statuses of the local rules. This procedure improves both the generalization and personalization of the FedFNN for dealing with non-IID issues and data uncertainties. Extensive experiments conducted on a range of datasets demonstrate the superiority of the FedFNN over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.14393",
    "authors": [
      "Leijie Zhang",
      "Ye Shi",
      "Yu-Cheng Chang",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.14403",
    "title": "Stealthy Measurement-Aided Pole-Dynamics Attacks with Nominal Models",
    "abstract": "When traditional pole-dynamics attacks (TPDAs) are implemented with nominal models, model mismatch between exact and nominal models often affects their stealthiness, or even makes the stealthiness lost. To solve this problem, our current paper presents a novel stealthy measurement-aided pole-dynamics attacks (MAPDAs) method with model mismatch. Firstly, the limitations of TPDAs using exact models are revealed, where exact models help ensure the stealthiness of TPDAs but model mismatch severely influences stealthiness of TPDAs. Secondly, to handle the model mismatch, the proposed MAPDAs method is designed using a model reference adaptive control strategy, which can keep stealthiness. Moreover, it is easier to implement as only the measurements are needed in comparison with the existing methods requiring both the measurements and control inputs. Thirdly, we explore the performance of the proposed MAPDAs method using convergence of multivariate measurements, and MAPDAs with model mismatch have the same stealthiness and similar destructiveness as TPDAs. Specifically, MAPDAs with adaptive gains will remain stealthy at an acceptable detection threshold till destructiveness occurs. Finally, experimental results from a networked inverted pendulum system validate the proposed system. ",
    "url": "https://arxiv.org/abs/2210.14403",
    "authors": [
      "Dajun Du",
      "Changda Zhang",
      "Dakui Wu",
      "Chen Peng",
      "Minrui Fei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.14404",
    "title": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "abstract": "In this work, we formulate a novel framework of adversarial robustness using the manifold hypothesis. Our framework provides sufficient conditions for defending against adversarial examples. We develop a test-time defense method with our formulation and variational inference. The developed approach combines manifold learning with the Bayesian framework to provide adversarial robustness without the need for adversarial training. We show that our proposed approach can provide adversarial robustness even if attackers are aware of existence of test-time defense. In additions, our approach can also serve as a test-time defense mechanism for variational autoencoders. ",
    "url": "https://arxiv.org/abs/2210.14404",
    "authors": [
      "Zhaoyuan Yang",
      "Zhiwei Xu",
      "Jing Zhang",
      "Richard Hartley",
      "Peter Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14405",
    "title": "Adversarially Robust Medical Classification via Attentive Convolutional  Neural Networks",
    "abstract": "Convolutional neural network-based medical image classifiers have been shown to be especially susceptible to adversarial examples. Such instabilities are likely to be unacceptable in the future of automated diagnoses. Though statistical adversarial example detection methods have proven to be effective defense mechanisms, additional research is necessary that investigates the fundamental vulnerabilities of deep-learning-based systems and how best to build models that jointly maximize traditional and robust accuracy. This paper presents the inclusion of attention mechanisms in CNN-based medical image classifiers as a reliable and effective strategy for increasing robust accuracy without sacrifice. This method is able to increase robust accuracy by up to 16% in typical adversarial scenarios and up to 2700% in extreme cases. ",
    "url": "https://arxiv.org/abs/2210.14405",
    "authors": [
      "Isaac Wasserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.14408",
    "title": "An Attention-based Long Short-Term Memory Framework for Detection of  Bitcoin Scams",
    "abstract": "Bitcoin is the most common cryptocurrency involved in cyber scams. Cybercriminals often utilize pseudonymity and privacy protection mechanism associated with Bitcoin transactions to make their scams virtually untraceable. The Ponzi scheme has attracted particularly significant attention among Bitcoin fraudulent activities. This paper considers a multi-class classification problem to determine whether a transaction is involved in Ponzi schemes or other cyber scams, or is a non-scam transaction. We design a specifically designed crawler to collect data and propose a novel Attention-based Long Short-Term Memory (A-LSTM) method for the classification problem. The experimental results show that the proposed model has better efficiency and accuracy than existing approaches, including Random Forest, Extra Trees, Gradient Boosting, and classical LSTM. With correctly identified scam features, our proposed A-LSTM achieves an F1-score over 82% for the original data and outperforms the existing approaches. ",
    "url": "https://arxiv.org/abs/2210.14408",
    "authors": [
      "Puyang Zhao",
      "Wei Tian",
      "Lefu Xiao",
      "Xinhui Liu",
      "Jingjin Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14410",
    "title": "Improving Adversarial Robustness via Joint Classification and Multiple  Explicit Detection Classes",
    "abstract": "This work concerns the development of deep networks that are certifiably robust to adversarial attacks. Joint robust classification-detection was recently introduced as a certified defense mechanism, where adversarial examples are either correctly classified or assigned to the \"abstain\" class. In this work, we show that such a provable framework can benefit by extension to networks with multiple explicit abstain classes, where the adversarial examples are adaptively assigned to those. We show that naively adding multiple abstain classes can lead to \"model degeneracy\", then we propose a regularization approach and a training method to counter this degeneracy by promoting full use of the multiple abstain classes. Our experiments demonstrate that the proposed approach consistently achieves favorable standard vs. robust verified accuracy tradeoffs, outperforming state-of-the-art algorithms for various choices of number of abstain classes. ",
    "url": "https://arxiv.org/abs/2210.14410",
    "authors": [
      "Sina Baharlouei",
      "Fatemeh Sheikholeslami",
      "Meisam Razaviyayn",
      "Zico Kolter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14431",
    "title": "Residual Learning of Neural Text Generation with $n$-gram Language Model",
    "abstract": "$N$-gram language models (LM) have been largely superseded by neural LMs as the latter exhibits better performance. However, we find that $n$-gram models can achieve satisfactory performance on a large proportion of testing cases, indicating they have already captured abundant knowledge of the language with relatively low computational cost. With this observation, we propose to learn a neural LM that fits the residual between an $n$-gram LM and the real-data distribution. The combination of $n$-gram and neural LMs not only allows the neural part to focus on the deeper understanding of language but also provides a flexible way to customize an LM by switching the underlying $n$-gram model without changing the neural model. Experimental results on three typical language tasks (i.e., language modeling, machine translation, and summarization) demonstrate that our approach attains additional performance gains over popular standalone neural models consistently. We also show that our approach allows for effective domain adaptation by simply switching to a domain-specific $n$-gram model, without any extra training. Our code is released at https://github.com/ghrua/NgramRes. ",
    "url": "https://arxiv.org/abs/2210.14431",
    "authors": [
      "Huayang Li",
      "Deng Cai",
      "Jin Xu",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14449",
    "title": "Modeling of dendritic solidification and numerical analysis of the  phase-field approach to model complex morphologies in alloys",
    "abstract": "Dendrites are one of the most widely observed patterns in nature and occur across a wide spectrum of physical phenomena. In solidification and growth patterns in metals and crystals, the multi-level branching structures of dendrites pose a modeling challenge, and a full resolution of these structures is computationally demanding. In the literature, theoretical models of dendritic formation and evolution, essentially as extensions of the classical moving boundary Stefan problem exist. Much of this understanding is from the analysis of dendrites occurring during the solidification of metallic alloys. Motivated by the problem of modeling microstructure evolution from liquid melts of pure metals and alloys during MAM, we developed a comprehensive numerical framework for modeling a large variety of dendritic structures that are relevant to metal solidification. In this work, we present a numerical framework encompassing the modeling of Stefan problem formulations relevant to dendritic evolution using a phase-field approach and a finite element method implementation. Using this framework, we model numerous complex dendritic morphologies that are physically relevant to the solidification of pure melts and binary alloys. The distinguishing aspects of this work are - a unified treatment of both pure metals and alloys; novel numerical error estimates of dendritic tip velocity; and the convergence of error for the primal fields of temperature and the order parameter with respect to numerical discretization. To the best of our knowledge, this is a first-of-its-kind study of numerical convergence of the phase-field equations of dendritic growth in a finite element method setting. Further, we modeled various types of physically relevant dendritic solidification patterns in 2D and 3D computational domains. ",
    "url": "https://arxiv.org/abs/2210.14449",
    "authors": [
      "Kunal Bhagat",
      "Shiva Rudraraju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.14452",
    "title": "Short Paper: Static and Microarchitectural ML-Based Approaches For  Detecting Spectre Vulnerabilities and Attacks",
    "abstract": "Spectre intrusions exploit speculative execution design vulnerabilities in modern processors. The attacks violate the principles of isolation in programs to gain unauthorized private user information. Current state-of-the-art detection techniques utilize micro-architectural features or vulnerable speculative code to detect these threats. However, these techniques are insufficient as Spectre attacks have proven to be more stealthy with recently discovered variants that bypass current mitigation mechanisms. Side-channels generate distinct patterns in processor cache, and sensitive information leakage is dependent on source code vulnerable to Spectre attacks, where an adversary uses these vulnerabilities, such as branch prediction, which causes a data breach. Previous studies predominantly approach the detection of Spectre attacks using the microarchitectural analysis, a reactive approach. Hence, in this paper, we present the first comprehensive evaluation of static and microarchitectural analysis-assisted machine learning approaches to detect Spectre vulnerable code snippets (preventive) and Spectre attacks (reactive). We evaluate the performance trade-offs in employing classifiers for detecting Spectre vulnerabilities and attacks. ",
    "url": "https://arxiv.org/abs/2210.14452",
    "authors": [
      "Chidera Biringa",
      "Gaspard Baye",
      "G\u00f6khan Kul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14456",
    "title": "Question-Interlocutor Scope Realized Graph Modeling over Key Utterances  for Dialogue Reading Comprehension",
    "abstract": "In this work, we focus on dialogue reading comprehension (DRC), a task extracting answer spans for questions from dialogues. Dialogue context modeling in DRC is tricky due to complex speaker information and noisy dialogue context. To solve the two problems, previous research proposes two self-supervised tasks respectively: guessing who a randomly masked speaker is according to the dialogue and predicting which utterance in the dialogue contains the answer. Although these tasks are effective, there are still urging problems: (1) randomly masking speakers regardless of the question cannot map the speaker mentioned in the question to the corresponding speaker in the dialogue, and ignores the speaker-centric nature of utterances. This leads to wrong answer extraction from utterances in unrelated interlocutors' scopes; (2) the single utterance prediction, preferring utterances similar to the question, is limited in finding answer-contained utterances not similar to the question. To alleviate these problems, we first propose a new key utterances extracting method. It performs prediction on the unit formed by several contiguous utterances, which can realize more answer-contained utterances. Based on utterances in the extracted units, we then propose Question-Interlocutor Scope Realized Graph (QuISG) modeling. As a graph constructed on the text of utterances, QuISG additionally involves the question and question-mentioning speaker names as nodes. To realize interlocutor scopes, speakers in the dialogue are connected with the words in their corresponding utterances. Experiments on the benchmarks show that our method can achieve better and competitive results against previous works. ",
    "url": "https://arxiv.org/abs/2210.14456",
    "authors": [
      "Jiangnan Li",
      "Mo Yu",
      "Fandong Meng",
      "Zheng Lin",
      "Peng Fu",
      "Weiping Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14457",
    "title": "Towards A Robust Deepfake Detector:Common Artifact Deepfake Detection  Model",
    "abstract": "Existing deepfake detection methods perform poorly on face forgeries generated by unseen face manipulation algorithms. The generalization ability of previous methods is mainly improved by modeling hand-crafted artifact features. Such properties, on the other hand, impede their further improvement. In this paper, we propose a novel deepfake detection method named Common Artifact Deepfake Detection Model, which aims to learn common artifact features in different face manipulation algorithms. To this end, we find that the main obstacle to learning common artifact features is that models are easily misled by the identity representation feature. We call this phenomenon Implicit Identity Leakage (IIL). Extensive experimental results demonstrate that, by learning the binary classifiers with the guidance of the Artifact Detection Module, our method effectively reduces the influence of IIL and outperforms the state-of-the-art by a large margin, proving that hand-crafted artifact feature detectors are not indispensable when tackling deepfake problems. ",
    "url": "https://arxiv.org/abs/2210.14457",
    "authors": [
      "Shichao Dong",
      "Jin Wang",
      "Renhe Ji",
      "Jiajun Liang",
      "Haoqiang Fan",
      "Zheng Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14460",
    "title": "PredNAS: A Universal and Sample Efficient Neural Architecture Search  Framework",
    "abstract": "In this paper, we present a general and effective framework for Neural Architecture Search (NAS), named PredNAS. The motivation is that given a differentiable performance estimation function, we can directly optimize the architecture towards higher performance by simple gradient ascent. Specifically, we adopt a neural predictor as the performance predictor. Surprisingly, PredNAS can achieve state-of-the-art performances on NAS benchmarks with only a few training samples (less than 100). To validate the universality of our method, we also apply our method on large-scale tasks and compare our method with RegNet on ImageNet and YOLOX on MSCOCO. The results demonstrate that our PredNAS can explore novel architectures with competitive performances under specific computational complexity constraints. ",
    "url": "https://arxiv.org/abs/2210.14460",
    "authors": [
      "Liuchun Yuan",
      "Zehao Huang",
      "Naiyan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14463",
    "title": "Bi-Link: Bridging Inductive Link Predictions from Text via Contrastive  Learning of Transformers and Prompts",
    "abstract": "Inductive knowledge graph completion requires models to comprehend the underlying semantics and logic patterns of relations. With the advance of pretrained language models, recent research have designed transformers for link prediction tasks. However, empirical studies show that linearizing triples affects the learning of relational patterns, such as inversion and symmetry. In this paper, we propose Bi-Link, a contrastive learning framework with probabilistic syntax prompts for link predictions. Using grammatical knowledge of BERT, we efficiently search for relational prompts according to learnt syntactical patterns that generalize to large knowledge graphs. To better express symmetric relations, we design a symmetric link prediction model, establishing bidirectional linking between forward prediction and backward prediction. This bidirectional linking accommodates flexible self-ensemble strategies at test time. In our experiments, Bi-Link outperforms recent baselines on link prediction datasets (WN18RR, FB15K-237, and Wikidata5M). Furthermore, we construct Zeshel-Ind as an in-domain inductive entity linking the environment to evaluate Bi-Link. The experimental results demonstrate that our method yields robust representations which can generalize under domain shift. ",
    "url": "https://arxiv.org/abs/2210.14463",
    "authors": [
      "Bohua Peng",
      "Shihao Liang",
      "Mobarakol Islam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14473",
    "title": "Benchmarking Language Models for Code Syntax Understanding",
    "abstract": "Pre-trained language models have demonstrated impressive performance in both natural language processing and program understanding, which represent the input as a token sequence without explicitly modeling its structure. Some prior works show that pre-trained language models can capture the syntactic rules of natural languages without finetuning on syntax understanding tasks. However, there is limited understanding of how well pre-trained models understand the code structure so far. In this work, we perform the first thorough benchmarking of the state-of-the-art pre-trained models for identifying the syntactic structures of programs. Specifically, we introduce CodeSyntax, a large-scale dataset of programs annotated with the syntactic relationships in their corresponding abstract syntax trees. Our key observation is that existing language models pretrained on code still lack the understanding of code syntax. In fact, these pre-trained programming language models fail to match the performance of simple baselines based on positional offsets and keywords. We also present a natural language benchmark to highlight the differences between natural languages and programming languages in terms of syntactic structure understanding. Our findings point out key limitations of existing pre-training methods for programming languages, and suggest the importance of modeling code syntactic structures. ",
    "url": "https://arxiv.org/abs/2210.14473",
    "authors": [
      "Da Shen",
      "Xinyun Chen",
      "Chenguang Wang",
      "Koushik Sen",
      "Dawn Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14480",
    "title": "Meta-node: A Concise Approach to Effectively Learn Complex Relationships  in Heterogeneous Graphs",
    "abstract": "Existing message passing neural networks for heterogeneous graphs rely on the concepts of meta-paths or meta-graphs due to the intrinsic nature of heterogeneous graphs. However, the meta-paths and meta-graphs need to be pre-configured before learning and are highly dependent on expert knowledge to construct them. To tackle this challenge, we propose a novel concept of meta-node for message passing that can learn enriched relational knowledge from complex heterogeneous graphs without any meta-paths and meta-graphs by explicitly modeling the relations among the same type of nodes. Unlike meta-paths and meta-graphs, meta-nodes do not require any pre-processing steps that require expert knowledge. Going one step further, we propose a meta-node message passing scheme and apply our method to a contrastive learning model. In the experiments on node clustering and classification tasks, the proposed meta-node message passing method outperforms state-of-the-arts that depend on meta-paths. Our results demonstrate that effective heterogeneous graph learning is possible without the need for meta-paths that are frequently used in this field. ",
    "url": "https://arxiv.org/abs/2210.14480",
    "authors": [
      "Jiwoong Park",
      "Jisu Jeong",
      "Kyungmin Kim",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.14483",
    "title": "Robust Contextual Linear Bandits",
    "abstract": "Model misspecification is a major consideration in applications of statistical methods and machine learning. However, it is often neglected in contextual bandits. This paper studies a common form of misspecification, an inter-arm heterogeneity that is not captured by context. To address this issue, we assume that the heterogeneity arises due to arm-specific random variables, which can be learned. We call this setting a robust contextual bandit. The arm-specific variables explain the unknown inter-arm heterogeneity, and we incorporate them in the robust contextual estimator of the mean reward and its uncertainty. We develop two efficient bandit algorithms for our setting: a UCB algorithm called RoLinUCB and a posterior-sampling algorithm called RoLinTS. We analyze both algorithms and bound their $n$-round Bayes regret. Our experiments show that RoLinTS is comparably statistically efficient to the classic methods when the misspecification is low, more robust when the misspecification is high, and significantly more computationally efficient than its naive implementation. ",
    "url": "https://arxiv.org/abs/2210.14483",
    "authors": [
      "Rong Zhu",
      "Branislav Kveton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.14485",
    "title": "Reconstruction from edge image combined with color and gradient  difference for industrial surface anomaly detection",
    "abstract": "Reconstruction-based methods are widely explored in industrial visual anomaly detection. Such methods commonly require the model to well reconstruct the normal patterns but fail in the anomalies, and thus the anomalies can be detected by evaluating the reconstruction errors. However, in practice, it's usually difficult to control the generalization boundary of the model. The model with an overly strong generalization capability can even well reconstruct the abnormal regions, making them less distinguishable, while the model with a poor generalization capability can not reconstruct those changeable high-frequency components in the normal regions, which ultimately leads to false positives. To tackle the above issue, we propose a new reconstruction network where we reconstruct the original RGB image from its gray value edges (EdgRec). Specifically, this is achieved by an UNet-type denoising autoencoder with skip connections. The input edge and skip connections can well preserve the high-frequency information in the original image. Meanwhile, the proposed restoration task can force the network to memorize the normal low-frequency and color information. Besides, the denoising design can prevent the model from directly copying the original high-frequent components. To evaluate the anomalies, we further propose a new interpretable hand-crafted evaluation function that considers both the color and gradient differences. Our method achieves competitive results on the challenging benchmark MVTec AD (97.8\\% for detection and 97.7\\% for localization, AUROC). In addition, we conduct experiments on the MVTec 3D-AD dataset and show convincing results using RGB images only. Our code will be available at https://github.com/liutongkun/EdgRec. ",
    "url": "https://arxiv.org/abs/2210.14485",
    "authors": [
      "Tongkun Liu",
      "Bing Li",
      "Zhuo Zhao",
      "Xiao Du",
      "Bingke Jiang",
      "Leqi Geng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14487",
    "title": "Synchronization of Online Social Rhythms via Avatar Communications",
    "abstract": "In this study, we consider users' online communication rhythms (online social rhythms) as coupled oscillators in a complex social network. Users' rhythms may be entrained onto those of their friends, and macro-scale pattern of such rhythms can emerge. We investigated the entrainment in online social rhythms and long-range correlations of the rhythms using an avatar communication dataset. We indicated entrainment in online social rhythms to emerge if the strength of a new connection reaches a threshold. This entrainment spread via densely-connected clusters. Consequently, long-range correlations of online social rhythms extended to about 36% of the network, although offline social life naturally restricts online social rhythms. This research supports an understanding of human social dynamics in terms of systems of coupled oscillators. ",
    "url": "https://arxiv.org/abs/2210.14487",
    "authors": [
      "Masanori Takano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14489",
    "title": "Differentially Private Stochastic Convex Optimization for Network  Routing Applications",
    "abstract": "Network routing problems are common across many engineering applications. Computing optimal routing policies requires knowledge about network demand, i.e., the origin and destination (OD) of all requests in the network. However, privacy considerations make it challenging to share individual OD data that would be required for computing optimal policies. Privacy can be particularly challenging in standard network routing problems because sources and sinks can be easily identified from flow conservation constraints, making feasibility and privacy mutually exclusive. In this paper, we present a differentially private algorithm for network routing problems. The main ingredient is a reformulation of network routing which moves all user data-dependent parameters out of the constraint set and into the objective function. We then present an algorithm for solving this formulation based on a differentially private variant of stochastic gradient descent. In this algorithm, differential privacy is achieved by injecting noise, and one may wonder if this noise injection compromises solution quality. We prove that our algorithm is both differentially private and asymptotically optimal as the size of the training set goes to infinity. We corroborate the theoretical results with numerical experiments on a road traffic network which show that our algorithm provides differentially private and near-optimal solutions in practice. ",
    "url": "https://arxiv.org/abs/2210.14489",
    "authors": [
      "Matthew Tsao",
      "Karthik Gopalakrishnan",
      "Kaidi Yang",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.14495",
    "title": "Two-stage dimensional emotion recognition by fusing predictions of  acoustic and text networks using SVM",
    "abstract": "Automatic speech emotion recognition (SER) by a computer is a critical component for more natural human-machine interaction. As in human-human interaction, the capability to perceive emotion correctly is essential to take further steps in a particular situation. One issue in SER is whether it is necessary to combine acoustic features with other data such as facial expressions, text, and motion capture. This research proposes to combine acoustic and text information by applying a late-fusion approach consisting of two steps. First, acoustic and text features are trained separately in deep learning systems. Second, the prediction results from the deep learning systems are fed into a support vector machine (SVM) to predict the final regression score. Furthermore, the task in this research is dimensional emotion modeling because it can enable a deeper analysis of affective states. Experimental results show that this two-stage, late-fusion approach, obtains higher performance than that of any one-stage processing, with a linear correlation from one-stage to two-stage processing. This late-fusion approach improves previous early fusion results measured in concordance correlation coefficients score. ",
    "url": "https://arxiv.org/abs/2210.14495",
    "authors": [
      "Bagus Tris Atmaja",
      "Masato Akagi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14509",
    "title": "Parallel Gated Neural Network With Attention Mechanisim For Speech  Enhancement",
    "abstract": "Deep learning algorithm are increasingly used for speech enhancement (SE). In supervised methods, global and local information is required for accurate spectral mapping. A key restriction is often poor capture of key contextual information. To leverage long-term for target speakers and compensate distortions of cleaned speech, this paper adopts a sequence-to-sequence (S2S) mapping structure and proposes a novel monaural speech enhancement system, consisting of a Feature Extraction Block (FEB), a Compensation Enhancement Block (ComEB) and a Mask Block (MB). In the FEB a U-net block is used to extract abstract features using complex-valued spectra with one path to suppress the background noise in the magnitude domain using masking methods and the MB takes magnitude features from the FEBand compensates the lost complex-domain features produced from ComEB to restore the final cleaned speech. Experiments are conducted on the Librispeech dataset and results show that the proposed model obtains better performance than recent models in terms of ESTOI and PESQ scores. ",
    "url": "https://arxiv.org/abs/2210.14509",
    "authors": [
      "Jianqiao Cui",
      "Stefan Bleeck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14512",
    "title": "End-to-End Multimodal Representation Learning for Video Dialog",
    "abstract": "Video-based dialog task is a challenging multimodal learning task that has received increasing attention over the past few years with state-of-the-art obtaining new performance records. This progress is largely powered by the adaptation of the more powerful transformer-based language encoders. Despite this progress, existing approaches do not effectively utilize visual features to help solve tasks. Recent studies show that state-of-the-art models are biased toward textual information rather than visual cues. In order to better leverage the available visual information, this study proposes a new framework that combines 3D-CNN network and transformer-based networks into a single visual encoder to extract more robust semantic representations from videos. The visual encoder is jointly trained end-to-end with other input modalities such as text and audio. Experiments on the AVSD task show significant improvement over baselines in both generative and retrieval tasks. ",
    "url": "https://arxiv.org/abs/2210.14512",
    "authors": [
      "Huda Alamri",
      "Anthony Bilic",
      "Michael Hu",
      "Apoorva Beedu",
      "Irfan Essa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14531",
    "title": "Unifying Data Perspectivism and Personalization: An Application to  Social Norms",
    "abstract": "Instead of using a single ground truth for language processing tasks, several recent studies have examined how to represent and predict the labels of the set of annotators. However, often little or no information about annotators is known, or the set of annotators is small. In this work, we examine a corpus of social media posts about conflict from a set of 13k annotators and 210k judgements of social norms. We provide a novel experimental setup that applies personalization methods to the modeling of annotators and compare their effectiveness for predicting the perception of social norms. We further provide an analysis of performance across subsets of social situations that vary by the closeness of the relationship between parties in conflict, and assess where personalization helps the most. ",
    "url": "https://arxiv.org/abs/2210.14531",
    "authors": [
      "Joan Plepi",
      "B\u00e9la Neuendorf",
      "Lucie Flek",
      "Charles Welch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14532",
    "title": "Uncertainty-based Meta-Reinforcement Learning for Robust Radar Tracking",
    "abstract": "Nowadays, Deep Learning (DL) methods often overcome the limitations of traditional signal processing approaches. Nevertheless, DL methods are barely applied in real-life applications. This is mainly due to limited robustness and distributional shift between training and test data. To this end, recent work has proposed uncertainty mechanisms to increase their reliability. Besides, meta-learning aims at improving the generalization capability of DL models. By taking advantage of that, this paper proposes an uncertainty-based Meta-Reinforcement Learning (Meta-RL) approach with Out-of-Distribution (OOD) detection. The presented method performs a given task in unseen environments and provides information about its complexity. This is done by determining first and second-order statistics on the estimated reward. Using information about its complexity, the proposed algorithm is able to point out when tracking is reliable. To evaluate the proposed method, we benchmark it on a radar-tracking dataset. There, we show that our method outperforms related Meta-RL approaches on unseen tracking scenarios in peak performance by 16% and the baseline by 35% while detecting OOD data with an F1-Score of 72%. This shows that our method is robust to environmental changes and reliably detects OOD scenarios. ",
    "url": "https://arxiv.org/abs/2210.14532",
    "authors": [
      "Julius Ott",
      "Lorenzo Servadei",
      "Gianfranco Mauro",
      "Thomas Stadelmayer",
      "Avik Santra",
      "Robert Wille"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.14533",
    "title": "A robust GMRES algorithm in Tensor Train format",
    "abstract": "We consider the solution of linear systems with tensor product structure using a GMRES algorithm. In order to cope with the computational complexity in large dimension both in terms of floating point operations and memory requirement, our algorithm is based on low-rank tensor representation, namely the Tensor Train format. In a backward error analysis framework, we show how the tensor approximation affects the accuracy of the computed solution. With the bacwkward perspective, we investigate the situations where the $(d+1)$-dimensional problem to be solved results from the concatenation of a sequence of $d$-dimensional problems (like parametric linear operator or parametric right-hand side problems), we provide backward error bounds to relate the accuracy of the $(d+1)$-dimensional computed solution with the numerical quality of the sequence of $d$-dimensional solutions that can be extracted form it. This enables to prescribe convergence threshold when solving the $(d+1)$-dimensional problem that ensures the numerical quality of the $d$-dimensional solutions that will be extracted from the $(d+1)$-dimensional computed solution once the solver has converged. The above mentioned features are illustrated on a set of academic examples of varying dimensions and sizes. ",
    "url": "https://arxiv.org/abs/2210.14533",
    "authors": [
      "Olivier Coulaud",
      "Luc Giraud",
      "Martina Iannacito"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14552",
    "title": "A Robust Bias Mitigation Procedure Based on the Stereotype Content Model",
    "abstract": "The Stereotype Content model (SCM) states that we tend to perceive minority groups as cold, incompetent or both. In this paper we adapt existing work to demonstrate that the Stereotype Content model holds for contextualised word embeddings, then use these results to evaluate a fine-tuning process designed to drive a language model away from stereotyped portrayals of minority groups. We find the SCM terms are better able to capture bias than demographic agnostic terms related to pleasantness. Further, we were able to reduce the presence of stereotypes in the model through a simple fine-tuning procedure that required minimal human and computer resources, without harming downstream performance. We present this work as a prototype of a debiasing procedure that aims to remove the need for a priori knowledge of the specifics of bias in the model. ",
    "url": "https://arxiv.org/abs/2210.14552",
    "authors": [
      "Eddie L. Ungless",
      "Amy Rafferty",
      "Hrichika Nag",
      "Bj\u00f6rn Ross"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14556",
    "title": "Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal  Prediction for Multimodal Sentiment Analysis",
    "abstract": "Multimodal representation learning is a challenging task in which previous work mostly focus on either uni-modality pre-training or cross-modality fusion. In fact, we regard modeling multimodal representation as building a skyscraper, where laying stable foundation and designing the main structure are equally essential. The former is like encoding robust uni-modal representation while the later is like integrating interactive information among different modalities, both of which are critical to learning an effective multimodal representation. Recently, contrastive learning has been successfully applied in representation learning, which can be utilized as the pillar of the skyscraper and benefit the model to extract the most important features contained in the multimodal data. In this paper, we propose a novel framework named MultiModal Contrastive Learning (MMCL) for multimodal representation to capture intra- and inter-modality dynamics simultaneously. Specifically, we devise uni-modal contrastive coding with an efficient uni-modal feature augmentation strategy to filter inherent noise contained in acoustic and visual modality and acquire more robust uni-modality representations. Besides, a pseudo siamese network is presented to predict representation across different modalities, which successfully captures cross-modal dynamics. Moreover, we design two contrastive learning tasks, instance- and sentiment-based contrastive learning, to promote the process of prediction and learn more interactive information related to sentiment. Extensive experiments conducted on two public datasets demonstrate that our method surpasses the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.14556",
    "authors": [
      "Ronghao Lin",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14560",
    "title": "Hierarchical Federated Learning with Momentum Acceleration in Multi-Tier  Networks",
    "abstract": "In this paper, we propose Hierarchical Federated Learning with Momentum Acceleration (HierMo), a three-tier worker-edge-cloud federated learning algorithm that applies momentum for training acceleration. Momentum is calculated and aggregated in the three tiers. We provide convergence analysis for HierMo, showing a convergence rate of O(1/T). In the analysis, we develop a new approach to characterize model aggregation, momentum aggregation, and their interactions. Based on this result, {we prove that HierMo achieves a tighter convergence upper bound compared with HierFAVG without momentum}. We also propose HierOPT, which optimizes the aggregation periods (worker-edge and edge-cloud aggregation periods) to minimize the loss given a limited training time. ",
    "url": "https://arxiv.org/abs/2210.14560",
    "authors": [
      "Zhengjie Yang",
      "Sen Fu",
      "Wei Bao",
      "Dong Yuan",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14562",
    "title": "FairCLIP: Social Bias Elimination based on Attribute Prototype Learning  and Representation Neutralization",
    "abstract": "The Vision-Language Pre-training (VLP) models like CLIP have gained popularity in recent years. However, many works found that the social biases hidden in CLIP easily manifest in downstream tasks, especially in image retrieval, which can have harmful effects on human society. In this work, we propose FairCLIP to eliminate the social bias in CLIP-based image retrieval without damaging the retrieval performance achieving the compatibility between the debiasing effect and the retrieval performance. FairCLIP is divided into two steps: Attribute Prototype Learning (APL) and Representation Neutralization (RN). In the first step, we extract the concepts needed for debiasing in CLIP. We use the query with learnable word vector prefixes as the extraction structure. In the second step, we first divide the attributes into target and bias attributes. By analysis, we find that both attributes have an impact on the bias. Therefore, we try to eliminate the bias by using Re-Representation Matrix (RRM) to achieve the neutralization of the representation. We compare the debiasing effect and retrieval performance with other methods, and experiments demonstrate that FairCLIP can achieve the best compatibility. Although FairCLIP is used to eliminate bias in image retrieval, it achieves the neutralization of the representation which is common to all CLIP downstream tasks. This means that FairCLIP can be applied as a general debiasing method for other fairness issues related to CLIP. ",
    "url": "https://arxiv.org/abs/2210.14562",
    "authors": [
      "Junyang Wang",
      "Yi Zhang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14571",
    "title": "Towards the Detection of Diffusion Model Deepfakes",
    "abstract": "Diffusion models (DMs) have recently emerged as a promising method in image synthesis. They have surpassed generative adversarial networks (GANs) in both diversity and quality, and have achieved impressive results in text-to-image and image-to-image modeling. However, to date, only little attention has been paid to the detection of DM-generated images, which is critical to prevent adverse impacts on our society. Although prior work has shown that GAN-generated images can be reliably detected using automated methods, it is unclear whether the same methods are effective against DMs. In this work, we address this challenge and take a first look at detecting DM-generated images. We approach the problem from two different angles: First, we evaluate the performance of state-of-the-art detectors on a variety of DMs. Second, we analyze DM-generated images in the frequency domain and study different factors that influence the spectral properties of these images. Most importantly, we demonstrate that GANs and DMs produce images with different characteristics, which requires adaptation of existing classifiers to ensure reliable detection. We believe this work provides the foundation and starting point for further research to detect DM deepfakes effectively. ",
    "url": "https://arxiv.org/abs/2210.14571",
    "authors": [
      "Jonas Ricker",
      "Simon Damm",
      "Thorsten Holz",
      "Asja Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14576",
    "title": "Uncertainty Sentence Sampling by Virtual Adversarial Perturbation",
    "abstract": "Active learning for sentence understanding attempts to reduce the annotation cost by identifying the most informative examples. Common methods for active learning use either uncertainty or diversity sampling in the pool-based scenario. In this work, to incorporate both predictive uncertainty and sample diversity, we propose Virtual Adversarial Perturbation for Active Learning (VAPAL) , an uncertainty-diversity combination framework, using virtual adversarial perturbation (Miyato et al., 2019) as model uncertainty representation. VAPAL consistently performs equally well or even better than the strong baselines on four sentence understanding datasets: AGNEWS, IMDB, PUBMED, and SST-2, offering a potential option for active learning on sentence understanding tasks. ",
    "url": "https://arxiv.org/abs/2210.14576",
    "authors": [
      "Hanshan Zhang",
      "Zhen Zhang",
      "Hongfei Jiang",
      "Yang Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14577",
    "title": "Disentangling Past-Future Modeling in Sequential Recommendation via Dual  Networks",
    "abstract": "Sequential recommendation (SR) plays an important role in personalized recommender systems because it captures dynamic and diverse preferences from users' real-time increasing behaviors. Unlike the standard autoregressive training strategy, future data (also available during training) has been used to facilitate model training as it provides richer signals about user's current interests and can be used to improve the recommendation quality. However, these methods suffer from a severe training-inference gap, i.e., both past and future contexts are modeled by the same encoder when training, while only historical behaviors are available during inference. This discrepancy leads to potential performance degradation. To alleviate the training-inference gap, we propose a new framework DualRec, which achieves past-future disentanglement and past-future mutual enhancement by a novel dual network. Specifically, a dual network structure is exploited to model the past and future context separately. And a bi-directional knowledge transferring mechanism enhances the knowledge learnt by the dual network. Extensive experiments on four real-world datasets demonstrate the superiority of our approach over baseline methods. Besides, we demonstrate the compatibility of DualRec by instantiating using RNN, Transformer, and filter-MLP as backbones. Further empirical analysis verifies the high utility of modeling future contexts under our DualRec framework. ",
    "url": "https://arxiv.org/abs/2210.14577",
    "authors": [
      "Hengyu Zhang",
      "Enming Yuan",
      "Wei Guo",
      "Zhicheng He",
      "Jiarui Qin",
      "Huifeng Guo",
      "Bo Chen",
      "Xiu Li",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.14582",
    "title": "WebCrack: Dynamic Dictionary Adjustment for Web Weak Password Detection  based on Blasting Response Event Discrimination",
    "abstract": "The feature diversity of different web systems in page elements, submission contents and return information makes it difficult to detect weak password automatically. To solve this problem, multi-factor correlation detection method as integrated in the DBKER algorithm is proposed to achieve automatic detection of web weak passwords and universal passwords. It generates password dictionaries based on PCFG algorithm, proposes to judge blasting result via 4 steps with traditional static keyword features and dynamic page feature information. Then the blasting failure events are discriminated and the usernames are blasted based on response time. Thereafter the weak password dictionary is dynamically adjusted according to the hints provided by the response failure page. Based on the algorithm, this paper implements a detection system named WebCrack. Experimental results of two blasting tests on DedeCMS and Discuz! systems as well as a random backend test show that the proposed method can detect weak passwords and universal passwords of various web systems with an average accuracy rate of about 93.75%, providing security advisories for users' password settings with strong practicability. ",
    "url": "https://arxiv.org/abs/2210.14582",
    "authors": [
      "Xiang Long",
      "Yan Huang",
      "Zhendong Liu",
      "Lansheng Han",
      "Haili Sun",
      "Jingyuan He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.14583",
    "title": "ADR-Lite: A Low-Complexity Adaptive Data Rate Scheme for the LoRa  Network",
    "abstract": "The long-range and low energy consumption requirements in Internet of Things (IoT) applications have led to a new wireless communication technology known as Low Power Wide Area Network (LPWANs). In recent years, the Long Range (LoRa) protocol has gained a lot of attention as one of the most promising technologies in LPWAN. Choosing the right combination of transmission parameters is a major challenge in the LoRa networks. In LoRa, an Adaptive Data Rate (ADR) mechanism is executed to configure each End Device's (ED) transmission parameters, resulting in improved performance metrics. In this paper, we propose a link-based ADR approach that aims to configure the transmission parameters of EDs by making a decision without taking into account the history of the last received packets, resulting in a relatively low space complexity approach. In this study, we present four different scenarios for assessing performance, including a scenario where mobile EDs are considered. Our simulation results show that in a mobile scenario with high channel noise, our proposed algorithm's Packet Delivery Ratio (PDR) is 2.8 times outperforming the original ADR and 1.35 times that of other relevant algorithms. ",
    "url": "https://arxiv.org/abs/2210.14583",
    "authors": [
      "Reza Serati",
      "Benyamin Teymuri",
      "Nikolaos Athanasios Anagnostopoulos",
      "Mehdi Rasti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.14596",
    "title": "Scaling Knowledge Graphs for Automating AI of Digital Twins",
    "abstract": "Digital Twins are digital representations of systems in the Internet of Things (IoT) that are often based on AI models that are trained on data from those systems. Semantic models are used increasingly to link these datasets from different stages of the IoT systems life-cycle together and to automatically configure the AI modelling pipelines. This combination of semantic models with AI pipelines running on external datasets raises unique challenges particular if rolled out at scale. Within this paper we will discuss the unique requirements of applying semantic graphs to automate Digital Twins in different practical use cases. We will introduce the benchmark dataset DTBM that reflects these characteristics and look into the scaling challenges of different knowledge graph technologies. Based on these insights we will propose a reference architecture that is in-use in multiple products in IBM and derive lessons learned for scaling knowledge graphs for configuring AI models for Digital Twins. ",
    "url": "https://arxiv.org/abs/2210.14596",
    "authors": [
      "Joern Ploennigs",
      "Konstantinos Semertzidis",
      "Fabio Lorenzi",
      "Nandana Mihindukulasooriya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.14599",
    "title": "RMLStreamer-SISO: an RDF stream generator from streaming heterogeneous  data",
    "abstract": "Stream-reasoning query languages such as CQELS and C-SPARQL enable query answering over RDF streams. Unfortunately, there currently is a lack of efficient RDF stream generators to feed RDF stream reasoners. State-of-the-art RDF stream generators are limited with regard to the velocity and volume of streaming data they can handle. To efficiently generate RDF streams in a scalable way, we extended the RMLStreamer to also generate RDF streams from dynamic heterogeneous data streams. This paper introduces a scalable solution that relies on a dynamic window approach to generate RDF streams with low latency and high throughput from multiple heterogeneous data streams. Our evaluation shows that our solution outperforms the state-of-the-art by achieving millisecond latency (compared to seconds that state-of-the-art solutions need), constant memory usage for all workloads, and sustainable throughput of around 70,000 records/s (compared to 10,000 records/s that state-of-the-art solutions take). This opens up the access to numerous data streams for integration with the semantic web. ",
    "url": "https://arxiv.org/abs/2210.14599",
    "authors": [
      "Sitt Min Oo",
      "Gerald Haesendonck",
      "Ben De Meester",
      "Anastasia Dimou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.14607",
    "title": "A practical method for occupational skills detection in Vietnamese job  listings",
    "abstract": "Vietnamese labor market has been under an imbalanced development. The number of university graduates is growing, but so is the unemployment rate. This situation is often caused by the lack of accurate and timely labor market information, which leads to skill miss-matches between worker supply and the actual market demands. To build a data monitoring and analytic platform for the labor market, one of the main challenges is to be able to automatically detect occupational skills from labor-related data, such as resumes and job listings. Traditional approaches rely on existing taxonomy and/or large annotated data to build Named Entity Recognition (NER) models. They are expensive and require huge manual efforts. In this paper, we propose a practical methodology for skill detection in Vietnamese job listings. Rather than viewing the task as a NER task, we consider the task as a ranking problem. We propose a pipeline in which phrases are first extracted and ranked in semantic similarity with the phrases' contexts. Then we employ a final classification to detect skill phrases. We collected three datasets and conducted extensive experiments. The results demonstrated that our methodology achieved better performance than a NER model in scarce datasets. ",
    "url": "https://arxiv.org/abs/2210.14607",
    "authors": [
      "Viet-Trung Tran",
      "Hai-Nam Cao",
      "Tuan-Dung Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14638",
    "title": "Fixed-parameter tractability of Graph Isomorphism in graphs with an  excluded minor",
    "abstract": "We prove that Graph Isomorphism and Canonization in graphs excluding a fixed graph $H$ as a minor can be solved by an algorithm working in time $f(H)\\cdot n^{O(1)}$, where $f$ is some function. In other words, we show that these problems are fixed-parameter tractable when parameterized by the size of the excluded minor, with the caveat that the bound on the running time is not necessarily computable. The underlying approach is based on decomposing the graph in a canonical way into unbreakable (intuitively, well-connected) parts, which essentially provides a reduction to the case where the given $H$-minor-free graph is unbreakable itself. This is complemented by an analysis of unbreakable $H$-minor-free graphs, performed in a second subordinate manuscript, which reveals that every such graph can be canonically decomposed into a part that admits few automorphisms and a part that has bounded treewidth. ",
    "url": "https://arxiv.org/abs/2210.14638",
    "authors": [
      "Daniel Lokshtanov",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.14660",
    "title": "Simulated Bifurcation Algorithm for MIMO Detection",
    "abstract": "We study the performance of the simulated bifurcation (SB) algorithm for signal detection in multiple-input multiple-output (MIMO) system, a problem of key interest in modern wireless communication systems. Our results show that SB algorithm can achieve significant performance improvement over the widely used linear minimum-mean square error decoder in terms of the bit error rate versus the signal-to-noise ratio, as well as performance improvement over the coherent Ising machine based MIMO detection method. ",
    "url": "https://arxiv.org/abs/2210.14660",
    "authors": [
      "Wen Zhang",
      "Yu-Lin Zheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14672",
    "title": "Sparsity in Continuous-Depth Neural Networks",
    "abstract": "Neural Ordinary Differential Equations (NODEs) have proven successful in learning dynamical systems in terms of accurately recovering the observed trajectories. While different types of sparsity have been proposed to improve robustness, the generalization properties of NODEs for dynamical systems beyond the observed data are underexplored. We systematically study the influence of weight and feature sparsity on forecasting as well as on identifying the underlying dynamical laws. Besides assessing existing methods, we propose a regularization technique to sparsify \"input-output connections\" and extract relevant features during training. Moreover, we curate real-world datasets consisting of human motion capture and human hematopoiesis single-cell RNA-seq data to realistically analyze different levels of out-of-distribution (OOD) generalization in forecasting and dynamics identification respectively. Our extensive empirical evaluation on these challenging benchmarks suggests that weight sparsity improves generalization in the presence of noise or irregular sampling. However, it does not prevent learning spurious feature dependencies in the inferred dynamics, rendering them impractical for predictions under interventions, or for inferring the true underlying dynamics. Instead, feature sparsity can indeed help with recovering sparse ground-truth dynamics compared to unregularized NODEs. ",
    "url": "https://arxiv.org/abs/2210.14672",
    "authors": [
      "Hananeh Aliee",
      "Till Richter",
      "Mikhail Solonin",
      "Ignacio Ibarra",
      "Fabian Theis",
      "Niki Kilbertus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14675",
    "title": "Comparison of neural closure models for discretised PDEs",
    "abstract": "Neural closure models have recently been proposed as a method for efficiently approximating small scales in multiscale systems with neural networks. The choice of loss function and associated training procedure has a large effect on the accuracy and stability of the resulting neural closure model. In this work, we systematically compare three distinct procedures: \"derivative fitting\", \"trajectory fitting\" with discretise-then-optimise, and \"trajectory fitting\" with optimise-then-discretise. Derivative fitting is conceptually the simplest and computationally the most efficient approach and is found to perform reasonably well on one of the test problems (Kuramoto-Sivashinsky) but poorly on the other (Burgers). Trajectory fitting is computationally more expensive but is more robust and is therefore the preferred approach. Of the two trajectory fitting procedures, the discretise-then-optimise approach produces more accurate models than the optimise-then-discretise approach. While the optimise-then-discretise approach can still produce accurate models, care must be taken in choosing the length of the trajectories used for training, in order to train the models on long-term behaviour while still producing reasonably accurate gradients during training. Two existing theorems are interpreted in a novel way that gives insight into the long-term accuracy of a neural closure model based on how accurate it is in the short term. ",
    "url": "https://arxiv.org/abs/2210.14675",
    "authors": [
      "Hugo Melchers",
      "Daan Crommelin",
      "Barry Koren",
      "Vlado Menkovski",
      "Benjamin Sanderse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.14678",
    "title": "Investigating the Role of Centering Theory in the Context of Neural  Coreference Resolution Systems",
    "abstract": "Centering theory (CT; Grosz et al., 1995) provides a linguistic analysis of the structure of discourse. According to the theory, local coherence of discourse arises from the manner and extent to which successive utterances make reference to the same entities. In this paper, we investigate the connection between centering theory and modern coreference resolution systems. We provide an operationalization of centering and systematically investigate if neural coreference resolvers adhere to the rules of centering theory by defining various discourse metrics and developing a search-based methodology. Our information-theoretic analysis reveals a positive dependence between coreference and centering; but also shows that high-quality neural coreference resolvers may not benefit much from explicitly modeling centering ideas. Our analysis further shows that contextualized embeddings contain much of the coherence information, which helps explain why CT can only provide little gains to modern neural coreference resolvers which make use of pretrained representations. Finally, we discuss factors that contribute to coreference which are not modeled by CT such as world knowledge and recency bias. We formulate a version of CT that also models recency and show that it captures coreference information better compared to vanilla CT. ",
    "url": "https://arxiv.org/abs/2210.14678",
    "authors": [
      "Yuchen Eleanor Jiang",
      "Ryan Cotterell",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14679",
    "title": "On the epidemic threshold of a network",
    "abstract": "The graph invariant examined in this paper is the largest eigenvalue of the adjacency matrix of a graph. Previous work demonstrates the tight relationship between this invariant, the birth and death rate of a contagion spreading on the graph, and the trajectory of the contagion over time. We begin by conducting a simulation confirming this and explore bounds on the birth and death rate in terms of well-known graph invariants. As a result, the change in the largest eigenvalue resulting from removal of a vertex in the network is the best measure of effectiveness of interventions that slow the spread of a contagion. We define the spread centrality of a vertex $v$ in a graph $G$ as the difference between the largest eigenvalues of $G$ and $G-v$. While the spread centrality is a distinct centrality measure and serves as another graph invariant for distinguishing graphs, we found experimental evidence that vertices ranked by the spread centrality and those ranked by eigenvector centrality are strongly correlated. Since eigenvector centrality is easier to compute than the spread centrality, this justifies using eigenvector centrality as a measure of spread, especially in large networks with unknown portions. We also examine two strategies for selecting members of a population to vaccinate. ",
    "url": "https://arxiv.org/abs/2210.14679",
    "authors": [
      "V. Cherniavskyi",
      "G. Dennis",
      "S. R. Kingan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.14682",
    "title": "In search of strong embedding extractors for speaker diarisation",
    "abstract": "Speaker embedding extractors (EEs), which map input audio to a speaker discriminant latent space, are of paramount importance in speaker diarisation. However, there are several challenges when adopting EEs for diarisation, from which we tackle two key problems. First, the evaluation is not straightforward because the features required for better performance differ between speaker verification and diarisation. We show that better performance on widely adopted speaker verification evaluation protocols does not lead to better diarisation performance. Second, embedding extractors have not seen utterances in which multiple speakers exist. These inputs are inevitably present in speaker diarisation because of overlapped speech and speaker changes; they degrade the performance. To mitigate the first problem, we generate speaker verification evaluation protocols that mimic the diarisation scenario better. We propose two data augmentation techniques to alleviate the second problem, making embedding extractors aware of overlapped speech or speaker change input. One technique generates overlapped speech segments, and the other generates segments where two speakers utter sequentially. Extensive experimental results using three state-of-the-art speaker embedding extractors demonstrate that both proposed approaches are effective. ",
    "url": "https://arxiv.org/abs/2210.14682",
    "authors": [
      "Jee-weon Jung",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "Jaesung Huh",
      "Andrew Brown",
      "Youngki Kwon",
      "Shinji Watanabe",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14688",
    "title": "Scaling Law Analysis for Covariance Based Activity Detection in  Cooperative Multi-Cell Massive MIMO",
    "abstract": "This paper studies the covariance based activity detection problem in a multi-cell massive multiple-input multiple-output (MIMO) system, where the active devices transmit their signature sequences to multiple base stations (BSs), and the BSs cooperatively detect the active devices based on the received signals. The scaling law of covariance based activity detection in the single-cell scenario has been thoroughly analyzed in the literature. This paper aims to analyze the scaling law of covariance based activity detection in the multi-cell massive MIMO system. In particular, this paper shows a quadratic scaling law in the multi-cell system under the assumption that the exponent in the classical path-loss model is greater than 2, which demonstrates that in the multi-cell MIMO system the maximum number of active devices that can be correctly detected in each cell increases quadratically as the length of the signature sequence and decreases logarithmically as the number of cells (as the number of antennas tends to infinity). Moreover, this paper also characterizes the distribution of the estimation error in the multi-cell scenario. ",
    "url": "https://arxiv.org/abs/2210.14688",
    "authors": [
      "Ziyue Wang",
      "Ya-Feng Liu",
      "Zhaorui Wang",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.14698",
    "title": "Autoregressive Structured Prediction with Language Models",
    "abstract": "Recent years have seen a paradigm shift in NLP towards using pretrained language models ({PLM}) for a wide range of tasks. However, there are many difficult design decisions to represent structures (e.g. tagged text, coreference chains) in a way such that they can be captured by PLMs. Prior work on structured prediction with PLMs typically flattens the structured output into a sequence, which limits the quality of structural information being learned and leads to inferior performance compared to classic discriminative models. In this work, we describe an approach to model structures as sequences of actions in an autoregressive manner with PLMs, allowing in-structure dependencies to be learned without any loss. Our approach achieves the new state-of-the-art on all the structured prediction tasks we looked at, namely, named entity recognition, end-to-end relation extraction, and coreference resolution. ",
    "url": "https://arxiv.org/abs/2210.14698",
    "authors": [
      "Tianyu Liu",
      "Yuchen Jiang",
      "Nicholas Monath",
      "Ryan Cotterell",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14700",
    "title": "Low-latency Federated Learning with DNN Partition in Distributed  Industrial IoT Networks",
    "abstract": "Federated Learning (FL) empowers Industrial Internet of Things (IIoT) with distributed intelligence of industrial automation thanks to its capability of distributed machine learning without any raw data exchange. However, it is rather challenging for lightweight IIoT devices to perform computation-intensive local model training over large-scale deep neural networks (DNNs). Driven by this issue, we develop a communication-computation efficient FL framework for resource-limited IIoT networks that integrates DNN partition technique into the standard FL mechanism, wherein IIoT devices perform local model training over the bottom layers of the objective DNN, and offload the top layers to the edge gateway side. Considering imbalanced data distribution, we derive the device-specific participation rate to involve the devices with better data distribution in more communication rounds. Upon deriving the device-specific participation rate, we propose to minimize the training delay under the constraints of device-specific participation rate, energy consumption and memory usage. To this end, we formulate a joint optimization problem of device scheduling and resource allocation (i.e. DNN partition point, channel assignment, transmit power, and computation frequency), and solve the long-term min-max mixed integer non-linear programming based on the Lyapunov technique. In particular, the proposed dynamic device scheduling and resource allocation (DDSRA) algorithm can achieve a trade-off to balance the training delay minimization and FL performance. We also provide the FL convergence bound for the DDSRA algorithm with both convex and non-convex settings. Experimental results demonstrate the derived device-specific participation rate in terms of feasibility, and show that the DDSRA algorithm outperforms baselines in terms of test accuracy and convergence time. ",
    "url": "https://arxiv.org/abs/2210.14700",
    "authors": [
      "Xiumei Deng",
      "Jun Li",
      "Chuan Ma",
      "Kang Wei",
      "Long Shi",
      "Ming Ding",
      "Wen Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14702",
    "title": "Privacy Analysis of Samsung's Crowd-Sourced Bluetooth Location Tracking  System",
    "abstract": "We present a detailed privacy analysis of Samsung's Offline Finding (OF) protocol, which is part of Samsung's Find My Mobile (FMM) location tracking system for locating Samsung mobile devices, such as Samsung smartphones and Bluetooth trackers (Galaxy SmartTags). The OF protocol uses Bluetooth Low Energy (BLE) to broadcast a unique beacon for a lost device. This beacon is then picked up by nearby Samsung phones or tablets (the {\\em finder} devices), which then forward the unique beacon, along with the location it was detected at, to a Samsung managed server. The owner of a lost device can then query the server to locate their device. We examine several security and privacy related properties of the OF protocol and its implementation, from the perspectives of the owner, the finder and the vendor. These include examining: the possibility of identifying the owner of a device through the Bluetooth data obtained from the device, the possibility for a malicious actor to perform unwanted tracking against a person by exploiting the OF network, the possibility for the vendor to de-anonymise location reports to determine the locations of the owners or the finders of lost devices, and the possibility for an attacker to compromise the integrity of the location reports. Our findings suggest that there are privacy risks on all accounts, arising from issues in the design and the implementation of the OF protocol. ",
    "url": "https://arxiv.org/abs/2210.14702",
    "authors": [
      "Tingfeng Yu",
      "James Henderson",
      "Alwen Tiu",
      "Thomas Haines"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14706",
    "title": "Rhino: Deep Causal Temporal Relationship Learning With History-dependent  Noise",
    "abstract": "Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains such as climate science, finance, and healthcare. Given the complexity of real-world relationships and the nature of observations in discrete time, causal discovery methods need to consider non-linear relations between variables, instantaneous effects and history-dependent noise (the change of noise distribution due to past actions). However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a novel causal relationship learning framework for time-series data, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by historical observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification. ",
    "url": "https://arxiv.org/abs/2210.14706",
    "authors": [
      "Wenbo Gong",
      "Joel Jennings",
      "Cheng Zhang",
      "Nick Pawlowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.14707",
    "title": "Is Out-of-Distribution Detection Learnable?",
    "abstract": "Supervised learning aims to train a classifier under the assumption that training and test data are from the same distribution. To ease the above assumption, researchers have studied a more realistic setting: out-of-distribution (OOD) detection, where test data may come from classes that are unknown during training (i.e., OOD data). Due to the unavailability and diversity of OOD data, good generalization ability is crucial for effective OOD detection algorithms. To study the generalization of OOD detection, in this paper, we investigate the probably approximately correct (PAC) learning theory of OOD detection, which is proposed by researchers as an open problem. First, we find a necessary condition for the learnability of OOD detection. Then, using this condition, we prove several impossibility theorems for the learnability of OOD detection under some scenarios. Although the impossibility theorems are frustrating, we find that some conditions of these impossibility theorems may not hold in some practical scenarios. Based on this observation, we next give several necessary and sufficient conditions to characterize the learnability of OOD detection in some practical scenarios. Lastly, we also offer theoretical supports for several representative OOD detection works based on our OOD theory. ",
    "url": "https://arxiv.org/abs/2210.14707",
    "authors": [
      "Zhen Fang",
      "Yixuan Li",
      "Jie Lu",
      "Jiahua Dong",
      "Bo Han",
      "Feng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.14709",
    "title": "Learning on Large-scale Text-attributed Graphs via Variational Inference",
    "abstract": "This paper studies learning on text-attributed graphs (TAGs), where each node is associated with a text description. An ideal solution for such a problem would be integrating both the text and graph structure information with large language models and graph neural networks (GNNs). However, the problem becomes very challenging when graphs are large due to the high computational complexity brought by large language models and training GNNs on big graphs. In this paper, we propose an efficient and effective solution to learning on large text-attributed graphs by fusing graph structure and language learning with a variational Expectation-Maximization (EM) framework, called GLEM. Instead of simultaneously training large language models and GNNs on big graphs, GLEM proposes to alternatively update the two modules in the E-step and M-step. Such a procedure allows to separately train the two modules but at the same time allows the two modules to interact and mutually enhance each other. Extensive experiments on multiple data sets demonstrate the efficiency and effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2210.14709",
    "authors": [
      "Jianan Zhao",
      "Meng Qu",
      "Chaozhuo Li",
      "Hao Yan",
      "Qian Liu",
      "Rui Li",
      "Xing Xie",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14714",
    "title": "TAMFormer: Multi-Modal Transformer with Learned Attention Mask for Early  Intent Prediction",
    "abstract": "Human intention prediction is a growing area of research where an activity in a video has to be anticipated by a vision-based system. To this end, the model creates a representation of the past, and subsequently, it produces future hypotheses about upcoming scenarios. In this work, we focus on pedestrians' early intention prediction in which, from a current observation of an urban scene, the model predicts the future activity of pedestrians that approach the street. Our method is based on a multi-modal transformer that encodes past observations and produces multiple predictions at different anticipation times. Moreover, we propose to learn the attention masks of our transformer-based model (Temporal Adaptive Mask Transformer) in order to weigh differently present and past temporal dependencies. We investigate our method on several public benchmarks for early intention prediction, improving the prediction performances at different anticipation times compared to the previous works. ",
    "url": "https://arxiv.org/abs/2210.14714",
    "authors": [
      "Nada Osman",
      "Guglielmo Camporese",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.14716",
    "title": "Pretrained audio neural networks for Speech emotion recognition in  Portuguese",
    "abstract": "The goal of speech emotion recognition (SER) is to identify the emotional aspects of speech. The SER challenge for Brazilian Portuguese speech was proposed with short snippets of Portuguese which are classified as neutral, non-neutral female and non-neutral male according to paralinguistic elements (laughing, crying, etc). This dataset contains about $50$ minutes of Brazilian Portuguese speech. As the dataset leans on the small side, we investigate whether a combination of transfer learning and data augmentation techniques can produce positive results. Thus, by combining a data augmentation technique called SpecAugment, with the use of Pretrained Audio Neural Networks (PANNs) for transfer learning we are able to obtain interesting results. The PANNs (CNN6, CNN10 and CNN14) are pretrained on a large dataset called AudioSet containing more than $5000$ hours of audio. They were finetuned on the SER dataset and the best performing model (CNN10) on the validation set was submitted to the challenge, achieving an $F1$ score of $0.73$ up from $0.54$ from the baselines provided by the challenge. Moreover, we also tested the use of Transformer neural architecture, pretrained on about $600$ hours of Brazilian Portuguese audio data. Transformers, as well as more complex models of PANNs (CNN14), fail to generalize to the test set in the SER dataset and do not beat the baseline. Considering the limitation of the dataset sizes, currently the best approach for SER is using PANNs (specifically, CNN6 and CNN10). ",
    "url": "https://arxiv.org/abs/2210.14716",
    "authors": [
      "Marcelo Matheus Gauy",
      "Marcelo Finger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14725",
    "title": "Linguistic-Enhanced Transformer with CTC Embedding for Speech  Recognition",
    "abstract": "The recent emergence of joint CTC-Attention model shows significant improvement in automatic speech recognition (ASR). The improvement largely lies in the modeling of linguistic information by decoder. The decoder joint-optimized with an acoustic encoder renders the language model from ground-truth sequences in an auto-regressive manner during training. However, the training corpus of the decoder is limited to the speech transcriptions, which is far less than the corpus needed to train an acceptable language model. This leads to poor robustness of decoder. To alleviate this problem, we propose linguistic-enhanced transformer, which introduces refined CTC information to decoder during training process, so that the decoder can be more robust. Our experiments on AISHELL-1 speech corpus show that the character error rate (CER) is relatively reduced by up to 7%. We also find that in joint CTC-Attention ASR model, decoder is more sensitive to linguistic information than acoustic information. ",
    "url": "https://arxiv.org/abs/2210.14725",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Mengyuan Zhao",
      "Zhiyong Zhang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14743",
    "title": "DEEPFAKE CLI: Accelerated Deepfake Detection using FPGAs",
    "abstract": "Because of the availability of larger datasets and recent improvements in the generative model, more realistic Deepfake videos are being produced each day. People consume around one billion hours of video on social media platforms every day, and thats why it is very important to stop the spread of fake videos as they can be damaging, dangerous, and malicious. There has been a significant improvement in the field of deepfake classification, but deepfake detection and inference have remained a difficult task. To solve this problem in this paper, we propose a novel DEEPFAKE C-L-I (Classification-Localization-Inference) in which we have explored the idea of accelerating Quantized Deepfake Detection Models using FPGAs due to their ability of maximum parallelism and energy efficiency compared to generalized GPUs. In this paper, we have used light MesoNet with EFF-YNet structure and accelerated it on VCK5000 FPGA, powered by state-of-the-art VC1902 Versal Architecture which uses AI, DSP, and Adaptable Engines for acceleration. We have benchmarked our inference speed with other state-of-the-art inference nodes, got 316.8 FPS on VCK5000 while maintaining 93\\% Accuracy. ",
    "url": "https://arxiv.org/abs/2210.14743",
    "authors": [
      "Omkar Bhilare",
      "Rahul Singh",
      "Vedant Paranjape",
      "Sravan Chittupalli",
      "Shraddha Suratkar",
      "Faruk Kazi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14749",
    "title": "Hybrid HMM Decoder For Convolutional Codes By Joint Trellis-Like  Structure and Channel Prior",
    "abstract": "The anti-interference capability of wireless links is a physical layer problem for edge computing. Although convolutional codes have inherent error correction potential due to the redundancy introduced in the data, the performance of the convolutional code is drastically degraded due to multipath effects on the channel. In this paper, we propose the use of a Hidden Markov Model (HMM) for the reconstruction of convolutional codes and decoding by the Viterbi algorithm. Furthermore, to implement soft-decision decoding, the observation of HMM is replaced by Gaussian mixture models (GMM). Our method provides superior error correction potential than the standard method because the model parameters contain channel state information (CSI). We evaluated the performance of the method compared to standard Viterbi decoding by numerical simulation. In the multipath channel, the hybrid HMM decoder can achieve a performance gain of 4.7 dB and 2 dB when using hard-decision and soft-decision decoding, respectively. The HMM decoder also achieves significant performance gains for the RSC code, suggesting that the method could be extended to turbo codes. ",
    "url": "https://arxiv.org/abs/2210.14749",
    "authors": [
      "Haoyu Li",
      "Xuan Wang",
      "Tong Liu",
      "Dingyi Fang",
      "Baoying Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.14764",
    "title": "Towards a machine learning pipeline in reduced order modelling for  inverse problems: neural networks for boundary parametrization,  dimensionality reduction and solution manifold approximation",
    "abstract": "In this work, we propose a model order reduction framework to deal with inverse problems in a non-intrusive setting. Inverse problems, especially in a partial differential equation context, require a huge computational load due to the iterative optimization process. To accelerate such a procedure, we apply a numerical pipeline that involves artificial neural networks to parametrize the boundary conditions of the problem in hand, compress the dimensionality of the (full-order) snapshots, and approximate the parametric solution manifold. It derives a general framework capable to provide an ad-hoc parametrization of the inlet boundary and quickly converges to the optimal solution thanks to model order reduction. We present in this contribution the results obtained by applying such methods to two different CFD test cases. ",
    "url": "https://arxiv.org/abs/2210.14764",
    "authors": [
      "Anna Ivagnes",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14771",
    "title": "Rapid and robust endoscopic content area estimation: A lean GPU-based  pipeline and curated benchmark dataset",
    "abstract": "Endoscopic content area refers to the informative area enclosed by the dark, non-informative, border regions present in most endoscopic footage. The estimation of the content area is a common task in endoscopic image processing and computer vision pipelines. Despite the apparent simplicity of the problem, several factors make reliable real-time estimation surprisingly challenging. The lack of rigorous investigation into the topic combined with the lack of a common benchmark dataset for this task has been a long-lasting issue in the field. In this paper, we propose two variants of a lean GPU-based computational pipeline combining edge detection and circle fitting. The two variants differ by relying on handcrafted features, and learned features respectively to extract content area edge point candidates. We also present a first-of-its-kind dataset of manually annotated and pseudo-labelled content areas across a range of surgical indications. To encourage further developments, the curated dataset, and an implementation of both algorithms, has been made public (https://doi.org/10.7303/syn32148000, https://github.com/charliebudd/torch-content-area). We compare our proposed algorithm with a state-of-the-art U-Net-based approach and demonstrate significant improvement in terms of both accuracy (Hausdorff distance: 6.3 px versus 118.1 px) and computational time (Average runtime per frame: 0.13 ms versus 11.2 ms). ",
    "url": "https://arxiv.org/abs/2210.14771",
    "authors": [
      "Charlie Budd",
      "Luis C. Garcia-Peraza-Herrera",
      "Martin Huber",
      "Sebastien Ourselin",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14795",
    "title": "Enforcing Dirichlet boundary conditions in physics-informed neural  networks and variational physics-informed neural networks",
    "abstract": "In this paper, we present and compare four methods to enforce Dirichlet boundary conditions in Physics-Informed Neural Networks (PINNs) and Variational Physics-Informed Neural Networks (VPINNs). Such conditions are usually imposed by adding penalization terms in the loss function and properly choosing the corresponding scaling coefficients; however, in practice, this requires an expensive tuning phase. We show through several numerical tests that modifying the output of the neural network to exactly match the prescribed values leads to more efficient and accurate solvers. The best results are achieved by exactly enforcing the Dirichlet boundary conditions by means of an approximate distance function. We also show that variationally imposing the Dirichlet boundary conditions via Nitsche's method leads to suboptimal solvers. ",
    "url": "https://arxiv.org/abs/2210.14795",
    "authors": [
      "S. Berrone",
      "C. Canuto",
      "M. Pintore",
      "N. Sukumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.14796",
    "title": "AD-DMKDE: Anomaly Detection through Density Matrices and Fourier  Features",
    "abstract": "This paper presents a novel density estimation method for anomaly detection using density matrices (a powerful mathematical formalism from quantum mechanics) and Fourier features. The method can be seen as an efficient approximation of Kernel Density Estimation (KDE). A systematic comparison of the proposed method with eleven state-of-the-art anomaly detection methods on various data sets is presented, showing competitive performance on different benchmark data sets. The method is trained efficiently and it uses optimization to find the parameters of data embedding. The prediction phase complexity of the proposed algorithm is constant relative to the training data size, and it performs well in data sets with different anomaly rates. Its architecture allows vectorization and can be implemented on GPU/TPU hardware. ",
    "url": "https://arxiv.org/abs/2210.14796",
    "authors": [
      "Oscar Bustos-Brinez",
      "Joseph Gallego-Mejia",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14814",
    "title": "BioNLI: Generating a Biomedical NLI Dataset Using Lexico-semantic  Constraints for Adversarial Examples",
    "abstract": "Natural language inference (NLI) is critical for complex decision-making in biomedical domain. One key question, for example, is whether a given biomedical mechanism is supported by experimental evidence. This can be seen as an NLI problem but there are no directly usable datasets to address this. The main challenge is that manually creating informative negative examples for this task is difficult and expensive. We introduce a novel semi-supervised procedure that bootstraps an NLI dataset from existing biomedical dataset that pairs mechanisms with experimental evidence in abstracts. We generate a range of negative examples using nine strategies that manipulate the structure of the underlying mechanisms both with rules, e.g., flip the roles of the entities in the interaction, and, more importantly, as perturbations via logical constraints in a neuro-logical decoding system. We use this procedure to create a novel dataset for NLI in the biomedical domain, called BioNLI and benchmark two state-of-the-art biomedical classifiers. The best result we obtain is around mid 70s in F1, suggesting the difficulty of the task. Critically, the performance on the different classes of negative examples varies widely, from 97% F1 on the simple role change negative examples, to barely better than chance on the negative examples generated using neuro-logic decoding. ",
    "url": "https://arxiv.org/abs/2210.14814",
    "authors": [
      "Mohaddeseh Bastan",
      "Mihai Surdeanu",
      "Niranjan Balasubramanian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14819",
    "title": "Network Functional Compression for Control Applications",
    "abstract": "The trend of future communication systems is to aim for the steering and control of cyber physical systems. These systems can quickly become congested in environments like those presented in Industry 4.0. In these scenarios, a plethora of sensor data is transmitted wirelessly to multiple in network controllers that compute the control functions of the cyber physical systems. In this paper, we show an implementation of network Functional Compression (FC) as a proof of concept to drastically reduce the data traffic in these scenarios. FC is a form of goal-oriented communication scheme in which the objective of the sender receiver pair is to transmit the minimum amount of information to compute a function at the receiver end. In our scenario, the senders transmit an encoded and compressed version of the sensor data to a destination, an in-network controller interested in computing as its target function, a PID controller. We show that it is possible to achieve compression rates of over 50% in some cases by employing FC. We also show that using FC in a distributed cascade fashion can achieve more significant compression rates while reducing computational costs. ",
    "url": "https://arxiv.org/abs/2210.14819",
    "authors": [
      "Sifat Rezwan",
      "Juan A. Cabrera",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.14830",
    "title": "Personalized Federated Learning via Heterogeneous Modular Networks",
    "abstract": "Personalized Federated Learning (PFL) which collaboratively trains a federated model while considering local clients under privacy constraints has attracted much attention. Despite its popularity, it has been observed that existing PFL approaches result in sub-optimal solutions when the joint distribution among local clients diverges. To address this issue, we present Federated Modular Network (FedMN), a novel PFL approach that adaptively selects sub-modules from a module pool to assemble heterogeneous neural architectures for different clients. FedMN adopts a light-weighted routing hypernetwork to model the joint distribution on each client and produce the personalized selection of the module blocks for each client. To reduce the communication burden in existing FL, we develop an efficient way to interact between the clients and the server. We conduct extensive experiments on the real-world test beds and the results show both the effectiveness and efficiency of the proposed FedMN over the baselines. ",
    "url": "https://arxiv.org/abs/2210.14830",
    "authors": [
      "Tianchun Wan",
      "Wei Cheng",
      "Dongsheng Luo",
      "Wenchao Yu",
      "Jingchao Ni",
      "Liang Tong",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14833",
    "title": "Ballot stuffing and participation privacy in pollsite voting",
    "abstract": "We study the problem of simultaneously addressing both ballot stuffing and participation privacy for pollsite voting systems. Ballot stuffing is the attack where fake ballots (not cast by any eligible voter) are inserted into the system. Participation privacy is about hiding which eligible voters have actually cast their vote. So far, the combination of ballot stuffing and participation privacy has been mostly studied for internet voting, where voters are assumed to own trusted computing devices. Such approaches are inapplicable to pollsite voting where voters typically vote bare handed. We present an eligibility audit protocol to detect ballot stuffing in pollsite voting protocols. This is done while protecting participation privacy from a remote observer - one who does not physically observe voters during voting. Our protocol can be instantiated as an additional layer on top of most existing pollsite E2E-V voting protocols. To achieve our guarantees, we develop an efficient zero-knowledge proof (ZKP), that, given a value $v$ and a set $\\Phi$ of commitments, proves $v$ is committed by some commitment in $\\Phi$, without revealing which one. We call this a ZKP of reverse set membership because of its relationship to the popular ZKPs of set membership. This ZKP may be of independent interest. ",
    "url": "https://arxiv.org/abs/2210.14833",
    "authors": [
      "Prashant Agrawal",
      "Abhinav Nakarmi",
      "Mahabir Prasad Jhanwar",
      "Subodh Sharma",
      "Subhashis Banerjee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14846",
    "title": "ProVe: A Pipeline for Automated Provenance Verification of Knowledge  Graphs against Textual Sources",
    "abstract": "Knowledge Graphs are repositories of information that gather data from a multitude of domains and sources in the form of semantic triples, serving as a source of structured data for various crucial applications in the modern web landscape, from Wikipedia infoboxes to search engines. Such graphs mainly serve as secondary sources of information and depend on well-documented and verifiable provenance to ensure their trustworthiness and usability. However, their ability to systematically assess and assure the quality of this provenance, most crucially whether it properly supports the graph's information, relies mainly on manual processes that do not scale with size. ProVe aims at remedying this, consisting of a pipelined approach that automatically verifies whether a Knowledge Graph triple is supported by text extracted from its documented provenance. ProVe is intended to assist information curators and consists of four main steps involving rule-based methods and machine learning models: text extraction, triple verbalisation, sentence selection, and claim verification. ProVe is evaluated on a Wikidata dataset, achieving promising results overall and excellent performance on the binary classification task of detecting support from provenance, with 87.5% accuracy and 82.9% F1-macro on text-rich sources. The evaluation data and scripts used in this paper are available on GitHub and Figshare. ",
    "url": "https://arxiv.org/abs/2210.14846",
    "authors": [
      "Gabriel Amaral",
      "Odinaldo Rodrigues",
      "Elena Simperl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14852",
    "title": "Causality Detection using Multiple Annotation Decision",
    "abstract": "The paper describes the work that has been submitted to the 5th workshop on Challenges and Applications of Automated Extraction of socio-political events from text (CASE 2022). The work is associated with Subtask 1 of Shared Task 3 that aims to detect causality in protest news corpus. The authors used different large language models with customized cross-entropy loss functions that exploit annotation information. The experiments showed that bert-based-uncased with refined cross-entropy outperformed the others, achieving a F1 score of 0.8501 on the Causal News Corpus dataset. ",
    "url": "https://arxiv.org/abs/2210.14852",
    "authors": [
      "Quynh Anh Nguyen",
      "Arka Mitra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14855",
    "title": "Multi-level Data Representation For Training Deep Helmholtz Machines",
    "abstract": "A vast majority of the current research in the field of Machine Learning is done using algorithms with strong arguments pointing to their biological implausibility such as Backpropagation, deviating the field's focus from understanding its original organic inspiration to a compulsive search for optimal performance. Yet, there have been a few proposed models that respect most of the biological constraints present in the human brain and are valid candidates for mimicking some of its properties and mechanisms. In this paper, we will focus on guiding the learning of a biologically plausible generative model called the Helmholtz Machine in complex search spaces using a heuristic based on the Human Image Perception mechanism. We hypothesize that this model's learning algorithm is not fit for Deep Networks due to its Hebbian-like local update rule, rendering it incapable of taking full advantage of the compositional properties that multi-layer networks provide. We propose to overcome this problem, by providing the network's hidden layers with visual queues at different resolutions using a Multi-level Data representation. The results on several image datasets showed the model was able to not only obtain better overall quality but also a wider diversity in the generated images, corroborating our intuition that using our proposed heuristic allows the model to take more advantage of the network's depth growth. More importantly, they show the unexplored possibilities underlying brain-inspired models and techniques. ",
    "url": "https://arxiv.org/abs/2210.14855",
    "authors": [
      "Jose Miguel Ramos",
      "Luis Sa-Couto",
      "Andreas Wichert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14862",
    "title": "Visual Semantic Parsing: From Images to Abstract Meaning Representation",
    "abstract": "The success of scene graphs for visual scene understanding has brought attention to the benefits of abstracting a visual input (e.g., image) into a structured representation, where entities (people and objects) are nodes connected by edges specifying their relations. Building these representations, however, requires expensive manual annotation in the form of images paired with their scene graphs or frames. These formalisms remain limited in the nature of entities and relations they can capture. In this paper, we propose to leverage a widely-used meaning representation in the field of natural language processing, the Abstract Meaning Representation (AMR), to address these shortcomings. Compared to scene graphs, which largely emphasize spatial relationships, our visual AMR graphs are more linguistically informed, with a focus on higher-level semantic concepts extrapolated from visual input. Moreover, they allow us to generate meta-AMR graphs to unify information contained in multiple image descriptions under one representation. Through extensive experimentation and analysis, we demonstrate that we can re-purpose an existing text-to-AMR parser to parse images into AMRs. Our findings point to important future research directions for improved scene understanding. ",
    "url": "https://arxiv.org/abs/2210.14862",
    "authors": [
      "Mohamed Ashraf Abdelsalam",
      "Zhan Shi",
      "Federico Fancellu",
      "Kalliopi Basioti",
      "Dhaivat J. Bhatt",
      "vladimir pavlovic",
      "Afsaneh Fazly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14867",
    "title": "Beyond English-Centric Bitexts for Better Multilingual Language  Representation Learning",
    "abstract": "In this paper, we elaborate upon recipes for building multilingual representation models that are not only competitive with existing state-of-the-art models but are also more parameter efficient, thereby promoting better adoption in resource-constrained scenarios and practical applications. We show that going beyond English-centric bitexts, coupled with a novel sampling strategy aimed at reducing under-utilization of training data, substantially boosts performance across model sizes for both Electra and MLM pre-training objectives. We introduce XY-LENT: X-Y bitext enhanced Language ENcodings using Transformers which not only achieves state-of-the-art performance over 5 cross-lingual tasks within all model size bands, is also competitive across bands. Our XY-LENT XL variant outperforms XLM-RXXL and exhibits competitive performance with mT5 XXL while being 5x and 6x smaller respectively. We then show that our proposed method helps ameliorate the curse of multilinguality, with the XY-LENT XL achieving 99.3% GLUE performance and 98.5% SQuAD 2.0 performance compared to a SoTA English only model in the same size band. We then analyze our models performance on extremely low resource languages and posit that scaling alone may not be sufficient for improving the performance in this scenario ",
    "url": "https://arxiv.org/abs/2210.14867",
    "authors": [
      "Barun Patra",
      "Saksham Singhal",
      "Shaohan Huang",
      "Zewen Chi",
      "Li Dong",
      "Furu Wei",
      "Vishrav Chaudhary",
      "Xia Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14868",
    "title": "Multi-lingual Evaluation of Code Generation Models",
    "abstract": "We present MBXP, an execution-based code completion benchmark in 10+ programming languages. This collection of datasets is generated by our conversion framework that translates prompts and test cases from the original MBPP dataset to the corresponding data in a target language. Based on this benchmark, we are able to evaluate code generation models in a multi-lingual fashion, and in particular discover generalization ability of language models on out-of-domain languages, advantages of large multi-lingual models over mono-lingual, benefits of few-shot prompting, and zero-shot translation abilities. In addition, we use our code generation model to perform large-scale bootstrapping to obtain synthetic canonical solutions in several languages. These solutions can be used for other code-related evaluations such as insertion-based, summarization, or code translation tasks where we demonstrate results and release as part of our benchmark. ",
    "url": "https://arxiv.org/abs/2210.14868",
    "authors": [
      "Ben Athiwaratkun",
      "Sanjay Krishna Gouda",
      "Zijian Wang",
      "Xiaopeng Li",
      "Yuchen Tian",
      "Ming Tan",
      "Wasi Uddin Ahmad",
      "Shiqi Wang",
      "Qing Sun",
      "Mingyue Shang",
      "Sujan Kumar Gonugondla",
      "Hantian Ding",
      "Varun Kumar",
      "Nathan Fulton",
      "Arash Farahani",
      "Siddhartha Jain",
      "Robert Giaquinto",
      "Haifeng Qian",
      "Murali Krishna Ramanathan",
      "Ramesh Nallapati",
      "Baishakhi Ray",
      "Parminder Bhatia",
      "Sudipta Sengupta",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14874",
    "title": "Anisotropic multiresolution analyses for deep fake detection",
    "abstract": "Generative Adversarial Networks (GANs) have paved the path towards entirely new media generation capabilities at the forefront of image, video, and audio synthesis. However, they can also be misused and abused to fabricate elaborate lies, capable of stirring up the public debate. The threat posed by GANs has sparked the need to discern between genuine content and fabricated one. Previous studies have tackled this task by using classical machine learning techniques, such as k-nearest neighbours and eigenfaces, which unfortunately did not prove very effective. Subsequent methods have focused on leveraging on frequency decompositions, i.e., discrete cosine transform, wavelets, and wavelet packets, to preprocess the input features for classifiers. However, existing approaches only rely on isotropic transformations. We argue that, since GANs primarily utilize isotropic convolutions to generate their output, they leave clear traces, their fingerprint, in the coefficient distribution on sub-bands extracted by anisotropic transformations. We employ the fully separable wavelet transform and multiwavelets to obtain the anisotropic features to feed to standard CNN classifiers. Lastly, we find the fully separable transform capable of improving the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2210.14874",
    "authors": [
      "Wei Huang",
      "Michelangelo Valsecchi",
      "Michael Multerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14880",
    "title": "Integrated Sensing and Communication in Distributed Antenna Networks",
    "abstract": "In this paper, we investigate the resource allocation design for integrated sensing and communication (ISAC) in distributed antenna networks (DANs). In particular, coordinated by a central processor (CP), a set of remote radio heads (RRHs) provide communication services to multiple users and sense several target locations within an ISAC frame. To avoid the severe interference between the information transmission and the radar echo, we propose to divide the ISAC frame into a communication phase and a sensing phase. During the communication phase, the data signal is generated at the CP and then conveyed to the RRHs via fronthaul links. As for the sensing phase, based on pre-determined RRH-target pairings, each RRH senses a dedicated target location with a synthesized highly-directional beam and then transfers the samples of the received echo to the CP via its fronthaul link for further processing of the sensing information. Taking into account the limited fronthaul capacity and the quality-of-service requirements of both communication and sensing, we jointly optimize the durations of the two phases, the information beamforming, and the covariance matrix of the sensing signal for minimization of the total energy consumption over a given finite time horizon. To solve the formulated non-convex design problem, we develop a low-complexity alternating optimization algorithm which converges to a suboptimal solution. Simulation results show that the proposed scheme achieves significant energy savings compared to two baseline schemes. Moreover, our results reveal that for efficient ISAC in wireless networks, energy-focused short-duration pulses are favorable for sensing while low-power long-duration signals are preferable for communication. ",
    "url": "https://arxiv.org/abs/2210.14880",
    "authors": [
      "Dongfang Xu",
      "Ata Khalili",
      "Xianghao Yu",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": "We present a smoothly broken power law functional form that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, or training dataset size varies) for each task within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision and unsupervised language tasks, diffusion generative modeling of images, arithmetic, and reinforcement learning. When compared to other functional forms for neural scaling behavior, this functional form yields extrapolations of scaling behavior that often are considerably more accurate (root mean squared log error of its extrapolations are 0.86 times that of previous state-of-the-art on average) on this set. Moreover, this functional form accurately models and extrapolates scaling behavior that other functional forms are incapable of expressing such as the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Code is available at https://github.com/ethancaballero/broken_neural_scaling_laws ",
    "url": "https://arxiv.org/abs/2210.14891",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14899",
    "title": "Learning a Task-specific Descriptor for Robust Matching of 3D Point  Clouds",
    "abstract": "Existing learning-based point feature descriptors are usually task-agnostic, which pursue describing the individual 3D point clouds as accurate as possible. However, the matching task aims at describing the corresponding points consistently across different 3D point clouds. Therefore these too accurate features may play a counterproductive role due to the inconsistent point feature representations of correspondences caused by the unpredictable noise, partiality, deformation, \\etc, in the local geometry. In this paper, we propose to learn a robust task-specific feature descriptor to consistently describe the correct point correspondence under interference. Born with an Encoder and a Dynamic Fusion module, our method EDFNet develops from two aspects. First, we augment the matchability of correspondences by utilizing their repetitive local structure. To this end, a special encoder is designed to exploit two input point clouds jointly for each point descriptor. It not only captures the local geometry of each point in the current point cloud by convolution, but also exploits the repetitive structure from paired point cloud by Transformer. Second, we propose a dynamical fusion module to jointly use different scale features. There is an inevitable struggle between robustness and discriminativeness of the single scale feature. Specifically, the small scale feature is robust since little interference exists in this small receptive field. But it is not sufficiently discriminative as there are many repetitive local structures within a point cloud. Thus the resultant descriptors will lead to many incorrect matches. In contrast, the large scale feature is more discriminative by integrating more neighborhood information. ... ",
    "url": "https://arxiv.org/abs/2210.14899",
    "authors": [
      "Zhiyuan Zhang",
      "Yuchao Dai",
      "Bin Fan",
      "Jiadai Sun",
      "Mingyi He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11921",
    "title": "Data reconstruction of turbulent flows with Gappy POD, Extended POD and  Generative Adversarial Networks",
    "abstract": "Three methods are used to reconstruct two-dimensional instantaneous velocity fields in a turbulent flow under rotation. The first two methods both use the linear proper orthogonal decomposition (POD), which are Gappy POD (GPOD) and Extended POD (EPOD), while the third one reconstructs the flow using a fully non-linear Convolutional Neural Network embedded in a Generative Adversarial Network (GAN). First, we show that there is always an optimal number of modes regarding a specific gap for the GPOD with dimension reduction. Moreover, adopting a Lasso regularizer for GPOD provides comparable reconstruction results. In order to systematically compare the applicability of the three tools, we consider a square gap at changing the size. Results show that compared with POD-based methods, GAN reconstruction not only has a smaller $L_2$ error, but also better turbulent statistics of both the velocity module and the velocity module gradient. This can be attributed to the ability of nonlinearity expression of the network and the presence of adversarial loss during the GAN training. We also investigate effects of the adversarial ratio, which controls the compromising between the $L_2$ error and the statistical properties. Finally, we assess the reconstruction on random gappiness. All methods perform well for small- and medium-size gaps, while GAN works better when the gappiness is large. ",
    "url": "https://arxiv.org/abs/2210.11921",
    "authors": [
      "Tianyi Li",
      "Michele Buzzicotti",
      "Luca Biferale",
      "Fabio Bonaccorso",
      "Shiyi Chen",
      "Minping Wan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14231",
    "title": "NAS-PRNet: Neural Architecture Search generated Phase Retrieval Net for  Off-axis Quantitative Phase Imaging",
    "abstract": "Single neural networks have achieved simultaneous phase retrieval with aberration compensation and phase unwrapping in off-axis Quantitative Phase Imaging (QPI). However, when designing the phase retrieval neural network architecture, the trade-off between computation latency and accuracy has been largely neglected. Here, we propose Neural Architecture Search (NAS) generated Phase Retrieval Net (NAS-PRNet), which is an encoder-decoder style neural network, automatically found from a large neural network architecture search space. The NAS scheme in NAS-PRNet is modified from SparseMask, in which the learning of skip connections between the encoder and the decoder is formulated as a differentiable NAS problem, and the gradient decent is applied to efficiently search the optimal skip connections. Using MobileNet-v2 as the encoder and a synthesized loss that incorporates phase reconstruction and network sparsity losses, NAS-PRNet has realized fast and accurate phase retrieval of biological cells. When tested on a cell dataset, NAS-PRNet has achieved a Peak Signal-to-Noise Ratio (PSNR) of 36.1 dB, outperforming the widely used U-Net and original SparseMask-generated neural network. Notably, the computation latency of NAS-PRNet is only 31 ms which is 12 times less than U-Net. Moreover, the connectivity scheme in NAS-PRNet, identified from one off-axis QPI system, can be well fitted to another with different fringe patterns. ",
    "url": "https://arxiv.org/abs/2210.14231",
    "authors": [
      "Xin Shu",
      "Mengxuan Niu",
      "Yi Zhang",
      "Renjie Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14416",
    "title": "RBP-DIP: High-Quality CT Reconstruction Using an Untrained Neural  Network with Residual Back Projection and Deep Image Prior",
    "abstract": "Neural network related methods, due to their unprecedented success in image processing, have emerged as a new set of tools in CT reconstruction with the potential to change the field. However, the lack of high-quality training data and theoretical guarantees, together with increasingly complicated network structures, make its implementation impractical. In this paper, we present a new framework (RBP-DIP) based on Deep Image Prior (DIP) and a special residual back projection (RBP) connection to tackle these challenges. Comparing to other pre-trained neural network related algorithms, the proposed framework is closer to an iterative reconstruction (IR) algorithm as it requires no training data or training process. In that case, the proposed framework can be altered (e.g, different hyperparameters and constraints) on demand, adapting to different conditions (e.g, different imaged objects, imaging instruments, and noise levels) without retraining. Experiments show that the proposed framework has significant improvements over other state-of-the-art conventional methods, as well as pre-trained and untrained models with similar network structures, especially under sparse-view, limited-angle, and low-dose conditions. ",
    "url": "https://arxiv.org/abs/2210.14416",
    "authors": [
      "Ziyu Shu",
      "Alireza Entezari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14573",
    "title": "Learning Causal Graphs in Manufacturing Domains using Structural  Equation Models",
    "abstract": "Many production processes are characterized by numerous and complex cause-and-effect relationships. Since they are only partially known they pose a challenge to effective process control. In this work we present how Structural Equation Models can be used for deriving cause-and-effect relationships from the combination of prior knowledge and process data in the manufacturing domain. Compared to existing applications, we do not assume linear relationships leading to more informative results. ",
    "url": "https://arxiv.org/abs/2210.14573",
    "authors": [
      "Maximilian Kertel",
      "Stefan Harmeling",
      "Markus Pauly"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14629",
    "title": "Highly unbreakable graph with a fixed excluded minor are almost rigid",
    "abstract": "A set $X \\subseteq V(G)$ in a graph $G$ is $(q,k)$-unbreakable if every separation $(A,B)$ of order at most $k$ in $G$ satisfies $|A \\cap X| \\leq q$ or $|B \\cap X| \\leq q$. In this paper, we prove the following result: If a graph $G$ excludes a fixed complete graph $K_h$ as a minor and satisfies certain unbreakability guarantees, then $G$ is almost rigid in the following sense: the vertices of $G$ can be partitioned in an isomorphism-invariant way into a part inducing a graph of bounded treewidth and a part that admits a small isomorphism-invariant family of labelings. This result is the key ingredient in the fixed-parameter algorithm for Graph Isomorphism parameterized by the Hadwiger number of the graph, which is presented in a companion paper. ",
    "url": "https://arxiv.org/abs/2210.14629",
    "authors": [
      "Daniel Lokshtanov",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.14633",
    "title": "Graph Filter Transfer via Probability Density Ratio Weighting",
    "abstract": "The problem of recovering graph signals is one of the main topics in graph signal processing. A representative approach to this problem is the graph Wiener filter, which utilizes the statistical information of the target signal computed from historical data to construct an effective estimator. However, we often encounter situations where the current graph differs from that of historical data due to topology changes, leading to performance degradation of the estimator. This paper proposes a graph filter transfer method, which learns an effective estimator from historical data under topology changes. The proposed method leverages the probability density ratio of the current and historical observations and constructs an estimator that minimizes the reconstruction error in the current graph domain. The experiment on synthetic data demonstrates that the proposed method outperforms other methods. ",
    "url": "https://arxiv.org/abs/2210.14633",
    "authors": [
      "Koki Yamada"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14645",
    "title": "Super-Resolution Based Patch-Free 3D Medical Image Segmentation with  Self-Supervised Guidance",
    "abstract": "High resolution (HR) 3D medical image segmentation plays an important role in clinical diagnoses. However, HR images are difficult to be directly processed by mainstream graphical cards due to limited video memory. Therefore, most existing 3D medical image segmentation methods use patch-based models, which ignores global context information that is useful in accurate segmentation and has low inference efficiency. To address these problems, we propose a super-resolution (SR) guided patch-free 3D medical image segmentation framework that can realize HR segmentation with global information of low-resolution (LR) input. The framework contains two tasks: semantic segmentation (main task) and super resolution (auxiliary task). To balance the information loss with the LR input, we introduce a Self-Supervised Guidance Module (SGM), which employs a selective search method to crop a HR patch from the original image as restoration guidance. Multi-scale convolutional layers are used to mitigate the scale-inconsistency between the HR guidance features and the LR features. Moreover, we propose a Task-Fusion Module (TFM) to exploit the inter connections between segmentation and SR task. This module can also be used for Test Phase Fine-tuning (TPF), leading to a better model generalization ability. When predicting, only the main segmentation task is needed, while other modules can be removed to accelerate the inference. The experiments results on two different datasets show that our framework outperforms current patch-based and patch-free models. Our model also has a four times higher inference speed compared to traditional patch-based methods. Our codes are available at: https://github.com/Dootmaan/PFSeg-Full. ",
    "url": "https://arxiv.org/abs/2210.14645",
    "authors": [
      "Hongyi Wang",
      "Lanfen Lin",
      "Hongjie Hu",
      "Qingqing Chen",
      "Yinhao Li",
      "Yutaro Iwamoto",
      "Xian-Hua Han",
      "Yen-Wei Chen",
      "Ruofeng Tong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14648",
    "title": "Masked Modeling Duo: Learning Representations by Encouraging Both  Networks to Model the Input",
    "abstract": "Masked Autoencoders is a simple yet powerful self-supervised learning method. However, it learns representations indirectly by reconstructing masked input patches. Several methods learn representations directly by predicting representations of masked patches; however, we think using all patches to encode training signal representations is suboptimal. We propose a new method, Masked Modeling Duo (M2D), that learns representations directly while obtaining training signals using only masked patches. In the M2D, the online network encodes visible patches and predicts masked patch representations, and the target network, a momentum encoder, encodes masked patches. To better predict target representations, the online network should model the input well, while the target network should also model it well to agree with online predictions. Then the learned representations should better model the input. We validated the M2D by learning general-purpose audio representations, and M2D set new state-of-the-art performance on tasks such as UrbanSound8K, VoxCeleb1, AudioSet20K, GTZAN, and SpeechCommandsV2. ",
    "url": "https://arxiv.org/abs/2210.14648",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14666",
    "title": "Xiaoicesing 2: A High-Fidelity Singing Voice Synthesizer Based on  Generative Adversarial Network",
    "abstract": "XiaoiceSing is a singing voice synthesis (SVS) system that aims at generating 48kHz singing voices. However, the mel-spectrogram generated by it is over-smoothing in middle- and high-frequency areas due to no special design for modeling the details of these parts. In this paper, we propose XiaoiceSing2, which can generate the details of middle- and high-frequency parts to better construct the full-band mel-spectrogram. Specifically, in order to alleviate this problem, XiaoiceSing2 adopts a generative adversarial network (GAN), which consists of a FastSpeech-based generator and a multi-band discriminator. We improve the feed-forward Transformer (FFT) block by adding multiple residual convolutional blocks in parallel with the self-attention block to balance the local and global features. The multi-band discriminator contains three sub-discriminators responsible for low-, middle-, and high-frequency parts of the mel-spectrogram, respectively. Each sub-discriminator is composed of several segment discriminators (SD) and detail discriminators (DD) to distinguish the audio from different aspects. The experiment on our internal 48kHz singing voice dataset shows XiaoiceSing2 significantly improves the quality of the singing voice over XiaoiceSing. ",
    "url": "https://arxiv.org/abs/2210.14666",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14735",
    "title": "Distribution-Free Finite-Sample Guarantees and Split Conformal  Prediction",
    "abstract": "Modern black-box predictive models are often accompanied by weak performance guarantees that only hold asymptotically in the size of the dataset or require strong parametric assumptions. In response to this, split conformal prediction represents a promising avenue to obtain finite-sample guarantees under minimal distribution-free assumptions. Although prediction set validity most often concerns marginal coverage, we explore the related but different guarantee of tolerance regions, reformulating known results in the language of nested prediction sets and extending on the duality between marginal coverage and tolerance regions. Furthermore, we highlight the connection between split conformal prediction and classical tolerance predictors developed in the 1940s, as well as recent developments in distribution-free risk control. One result that transfers from classical tolerance predictors is that the coverage of a prediction set based on order statistics, conditional on the calibration set, is a random variable stochastically dominating the Beta distribution. We demonstrate the empirical effectiveness of our findings on synthetic and real datasets using a popular split conformal prediction procedure called conformalized quantile regression (CQR). ",
    "url": "https://arxiv.org/abs/2210.14735",
    "authors": [
      "Roel Hulsman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14737",
    "title": "Impact of network topology changes on information source localization",
    "abstract": "Well-established methods of locating the source of information in a complex network are usually derived with the assumption of complete and exact knowledge of network topology. We study the performance of three such algorithms (LPTVA, GMLA and Pearson correlation algorithm) in scenarios that do not fulfill this assumption by modifying the network prior to localization. This is done by adding superfluous new links, hiding existing ones, or reattaching links in accordance with the network's structural Hamiltonian. We find that GMLA is highly resilient to the addition of superfluous edges, as its precision falls by more than statistical uncertainty only when the number of links is approximately doubled. On the other hand, if the edge set is underestimated or reattachment has taken place, the performance of GMLA drops significantly. In such a scenario the Pearson algorithm is preferable, retaining most of its performance when other simulation parameters favor localization (high density of observers, highly deterministic propagation). It is also generally more accurate than LPTVA, as well as orders of magnitude faster. The aforementioned differences between localization algorithms can be intuitively explained, although a need for further theoretical research is noted. ",
    "url": "https://arxiv.org/abs/2210.14737",
    "authors": [
      "Piotr Machura",
      "Robert Paluch"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.14755",
    "title": "Multitask Detection of Speaker Changes, Overlapping Speech and Voice  Activity Using wav2vec 2.0",
    "abstract": "Self-supervised learning approaches have lately achieved great success on a broad spectrum of machine learning problems. In the field of speech processing, one of the most successful recent self-supervised models is wav2vec 2.0. In this paper, we explore the effectiveness of this model on three basic speech classification tasks: speaker change detection, overlapped speech detection, and voice activity detection. First, we concentrate on only one task -- speaker change detection -- where our proposed system surpasses the previously reported results on four different corpora, and achieves comparable performance even when trained on out-of-domain data from an artificially designed dataset. Then we expand our approach to tackle all three tasks in a single multitask system with state-of-the-art performance on the AMI corpus. The implementation of the algorithms in this paper is publicly available at https://github.com/mkunes/w2v2_audioFrameClassification. ",
    "url": "https://arxiv.org/abs/2210.14755",
    "authors": [
      "Marie Kune\u0161ov\u00e1",
      "Zbyn\u011bk Zaj\u00edc"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14843",
    "title": "TuneUp: A Training Strategy for Improving Generalization of Graph Neural  Networks",
    "abstract": "Despite many advances in Graph Neural Networks (GNNs), their training strategies simply focus on minimizing a loss over nodes in a graph. However, such simplistic training strategies may be sub-optimal as they neglect that certain nodes are much harder to make accurate predictions on than others. Here we present TuneUp, a curriculum learning strategy for better training GNNs. Crucially, TuneUp trains a GNN in two stages. The first stage aims to produce a strong base GNN. Such base GNNs tend to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). So, the second stage of TuneUp specifically focuses on improving prediction on tail nodes. Concretely, TuneUp synthesizes many additional supervised tail node data by dropping edges from head nodes and reusing the supervision on the original head nodes. TuneUp then minimizes the loss over the synthetic tail nodes to finetune the base GNN. TuneUp is a general training strategy that can be used with any GNN architecture and any loss, making TuneUp applicable to a wide range of prediction tasks. Extensive evaluation of TuneUp on two GNN architectures, three types of prediction tasks, and both inductive and transductive settings shows that TuneUp significantly improves the performance of the base GNN on tail nodes, while often even improving the performance on head nodes, which together leads up to 58.5% relative improvement in GNN predictive performance. Moreover, TuneUp significantly outperforms its variants without the two-stage curriculum learning, existing graph data augmentation techniques, as well as other specialized methods for tail nodes. ",
    "url": "https://arxiv.org/abs/2210.14843",
    "authors": [
      "Weihua Hu",
      "Kaidi Cao",
      "Kexin Huang",
      "Edward W Huang",
      "Karthik Subbian",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1706.00178",
    "title": "Network Capacity Bound for Personalized PageRank in Multimodal Networks",
    "abstract": " Comments: 21 pages. 2 tables, 30 bibliography positions ",
    "url": "https://arxiv.org/abs/1706.00178",
    "authors": [
      "M.A. K\u0142opotek",
      "S.T. Wierzcho\u0144",
      "R.A. K\u0142opotek"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2009.03717",
    "title": "Hierarchical Message-Passing Graph Neural Networks",
    "abstract": " Title: Hierarchical Message-Passing Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2009.03717",
    "authors": [
      "Zhiqiang Zhong",
      "Cheng-Te Li",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.08545",
    "title": "Asymptotic Performance Prediction for ADMM-Based Compressed Sensing",
    "abstract": " Comments: accepted to IEEE Transactions on Signal Processing ",
    "url": "https://arxiv.org/abs/2009.08545",
    "authors": [
      "Ryo Hayakawa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2010.16295",
    "title": "Sharp threshold for alignment of graph databases with Gaussian weights",
    "abstract": " Comments: 18 pages, 2 figures. Latest version: typos corrected ",
    "url": "https://arxiv.org/abs/2010.16295",
    "authors": [
      "Luca Ganassali"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2105.09611",
    "title": "Dependency Parsing with Bottom-up Hierarchical Pointer Networks",
    "abstract": " Comments: Final peer-reviewed manuscript accepted for publication in Information Fusion ",
    "url": "https://arxiv.org/abs/2105.09611",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2106.07044",
    "title": "Optimal detection of the feature matching map in presence of noise and  outliers",
    "abstract": " Comments: accepted to ejs ",
    "url": "https://arxiv.org/abs/2106.07044",
    "authors": [
      "Tigran Galstyan",
      "Arshak Minasyan",
      "Arnak Dalalyan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.04386",
    "title": "Joint Matrix Decomposition for Deep Convolutional Neural Networks  Compression",
    "abstract": " Comments: Code is publicly available at: this https URL ",
    "url": "https://arxiv.org/abs/2107.04386",
    "authors": [
      "Shaowu Chen",
      "Jiahao Zhou",
      "Weize Sun",
      "Lei Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.11415",
    "title": "A survey of Bayesian Network structure learning",
    "abstract": " Title: A survey of Bayesian Network structure learning ",
    "url": "https://arxiv.org/abs/2109.11415",
    "authors": [
      "Neville K. Kitson",
      "Anthony C. Constantinou",
      "Zhigao Guo",
      "Yang Liu",
      "Kiattikun Chobtham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.00637",
    "title": "ML4C: Seeing Causality Through Latent Vicinity",
    "abstract": " Comments: causal discovery, supervised causal learning, vicinity, identifiability, learnability ",
    "url": "https://arxiv.org/abs/2110.00637",
    "authors": [
      "Haoyue Dai",
      "Rui Ding",
      "Yuanyuan Jiang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.02776",
    "title": "SIRe-Networks: Convolutional Neural Networks Architectural Extension for  Information Preservation via Skip/Residual Connections and Interlaced  Auto-Encoders",
    "abstract": " Title: SIRe-Networks: Convolutional Neural Networks Architectural Extension for  Information Preservation via Skip/Residual Connections and Interlaced  Auto-Encoders ",
    "url": "https://arxiv.org/abs/2110.02776",
    "authors": [
      "Danilo Avola",
      "Luigi Cinque",
      "Alessio Fagioli",
      "Gian Luca Foresti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.05360",
    "title": "Towards Providing Connectivity When and Where It Counts: An Overview of  Deployable 5G Networks",
    "abstract": " Comments: 8 pages, 6 figures, accepted by IEEE Communications Standards Magazine ",
    "url": "https://arxiv.org/abs/2110.05360",
    "authors": [
      "Jingya Li",
      "Xingqin Lin",
      "Keerthi Kumar Nagalapur",
      "Zhiqiang Qi",
      "Adri\u00e1n Lahuerta-Lavieja",
      "Thomas Chapman",
      "Sam Agneessens",
      "Henrik Sahlin",
      "Daniel Guldbrand",
      "Joakim \u00c5kesson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.12717",
    "title": "Forward Composition Propagation for Explainable Neural Reasoning",
    "abstract": " Title: Forward Composition Propagation for Explainable Neural Reasoning ",
    "url": "https://arxiv.org/abs/2112.12717",
    "authors": [
      "Isel Grau",
      "Gonzalo N\u00e1poles",
      "Marilyn Bello",
      "Yamisleydi Salgueiro",
      "Agnieszka Jastrzebska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.09694",
    "title": "Scaling Up Knowledge Graph Creation to Large and Heterogeneous Data  Sources",
    "abstract": " Title: Scaling Up Knowledge Graph Creation to Large and Heterogeneous Data  Sources ",
    "url": "https://arxiv.org/abs/2201.09694",
    "authors": [
      "Enrique Iglesias",
      "Samaneh Jozashoori",
      "Maria-Esther Vidal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2201.10683",
    "title": "Promises and Challenges of Causality for Ethical Machine Learning",
    "abstract": " Title: Promises and Challenges of Causality for Ethical Machine Learning ",
    "url": "https://arxiv.org/abs/2201.10683",
    "authors": [
      "Aida Rahmattalabi",
      "Alice Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.10866",
    "title": "CodeRetriever: Unimodal and Bimodal Contrastive Learning for Code Search",
    "abstract": " Comments: Accepted to EMNLP 2022 (main conference) ",
    "url": "https://arxiv.org/abs/2201.10866",
    "authors": [
      "Xiaonan Li",
      "Yeyun Gong",
      "Yelong Shen",
      "Xipeng Qiu",
      "Hang Zhang",
      "Bolun Yao",
      "Weizhen Qi",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2202.02063",
    "title": "Color Image Inpainting via Robust Pure Quaternion Matrix Completion:  Error Bound and Weighted Loss",
    "abstract": " Title: Color Image Inpainting via Robust Pure Quaternion Matrix Completion:  Error Bound and Weighted Loss ",
    "url": "https://arxiv.org/abs/2202.02063",
    "authors": [
      "Junren Chen",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.03555",
    "title": "data2vec: A General Framework for Self-supervised Learning in Speech,  Vision and Language",
    "abstract": " Title: data2vec: A General Framework for Self-supervised Learning in Speech,  Vision and Language ",
    "url": "https://arxiv.org/abs/2202.03555",
    "authors": [
      "Alexei Baevski",
      "Wei-Ning Hsu",
      "Qiantong Xu",
      "Arun Babu",
      "Jiatao Gu",
      "Michael Auli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12459",
    "title": "APEACH: Attacking Pejorative Expressions with Analysis on  Crowd-Generated Hate Speech Evaluation Datasets",
    "abstract": " Comments: Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2202.12459",
    "authors": [
      "Kichang Yang",
      "Wonjun Jang",
      "Won Ik Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07172",
    "title": "RED-ACE: Robust Error Detection for ASR using Confidence Embeddings",
    "abstract": " Comments: Accepted as a short paper in EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2203.07172",
    "authors": [
      "Zorik Gekhman",
      "Dina Zverinski",
      "Jonathan Mallinson",
      "Genady Beryozkin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.11933",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models  with Adversarial Learning",
    "abstract": " Comments: 17 pages, 4 figures, 7 tables. For code and trained token embeddings, see this https URL; Changed to use ACL layout, added joint training with comparison figure, corrected spelling and formatting errors; This paper is accepted for publication at AACL 2022, the official version of record is in the ACL Anthology ",
    "url": "https://arxiv.org/abs/2203.11933",
    "authors": [
      "Hugo Berg",
      "Siobhan Mackenzie Hall",
      "Yash Bhalgat",
      "Wonsuk Yang",
      "Hannah Rose Kirk",
      "Aleksandar Shtedritski",
      "Max Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.13068",
    "title": "SIFT and SURF based feature extraction for the anomaly detection",
    "abstract": " Comments: 28th Conference STUDENT EEICT 2022, Brno University of Technology ",
    "url": "https://arxiv.org/abs/2203.13068",
    "authors": [
      "Simon Bilik",
      "Karel Horak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.04333",
    "title": "A Study of Using Cepstrogram for Countermeasure Against Replay Attacks",
    "abstract": " Comments: Submitted to SLT 2022 ",
    "url": "https://arxiv.org/abs/2204.04333",
    "authors": [
      "Shih-Kuang Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.04802",
    "title": "On the pragmatism of using binary classifiers over data intensive neural  network classifiers for detection of COVID-19 from voice",
    "abstract": " Comments: Submitted to ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2204.04802",
    "authors": [
      "Ankit Shah",
      "Hira Dhamyal",
      "Yang Gao",
      "Daniel Arancibia",
      "Mario Arancibia",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.11424",
    "title": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "abstract": " Title: It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers ",
    "url": "https://arxiv.org/abs/2204.11424",
    "authors": [
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.01493",
    "title": "On the uncertainty principle of neural networks",
    "abstract": " Comments: 8 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2205.01493",
    "authors": [
      "Jun-Jie Zhang",
      "Dong-Xiao Zhang",
      "Jian-Nan Chen",
      "Long-Gang Pang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2206.02535",
    "title": "Certified Robustness in Federated Learning",
    "abstract": " Comments: Accepted at Workshop on Federated Learning: Recent Advances and New Challenges, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.02535",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Egor Shulgin",
      "Peter Richt\u00e1rik",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04405",
    "title": "Conformal Off-Policy Prediction in Contextual Bandits",
    "abstract": " Comments: Proceedings of 36th Conference on Neural Information Processing System (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2206.04405",
    "authors": [
      "Muhammad Faaiz Taufiq",
      "Jean-Francois Ton",
      "Rob Cornish",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12100",
    "title": "zPROBE: Zero Peek Robustness Checks for Federated Learning",
    "abstract": " Title: zPROBE: Zero Peek Robustness Checks for Federated Learning ",
    "url": "https://arxiv.org/abs/2206.12100",
    "authors": [
      "Zahra Ghodsi",
      "Mojan Javaheripi",
      "Nojan Sheybani",
      "Xinqiao Zhang",
      "Ke Huang",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.14254",
    "title": "No imputation without representation",
    "abstract": " Title: No imputation without representation ",
    "url": "https://arxiv.org/abs/2206.14254",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.03105",
    "title": "Uncertainty-Aware Self-supervised Neural Network for Liver $T_{1\u03c1}$  Mapping with Relaxation Constraint",
    "abstract": " Comments: Provisionally accepted by Physics in Medicine and Biology ",
    "url": "https://arxiv.org/abs/2207.03105",
    "authors": [
      "Chaoxing Huang",
      "Yurui Qian",
      "Simon Chun Ho Yu",
      "Jian Hou",
      "Baiyan Jiang",
      "Queenie Chan",
      "Vincent Wai-Sun Wong",
      "Winnie Chiu-Wing Chu",
      "Weitian Chen"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2208.04813",
    "title": "The explosive value of the networks",
    "abstract": " Title: The explosive value of the networks ",
    "url": "https://arxiv.org/abs/2208.04813",
    "authors": [
      "Antonio Scala",
      "Marco Delmastro"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.05516",
    "title": "Quality Not Quantity: On the Interaction between Dataset Design and  Robustness of CLIP",
    "abstract": " Comments: Updated plots ",
    "url": "https://arxiv.org/abs/2208.05516",
    "authors": [
      "Thao Nguyen",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Sewoong Oh",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.14834",
    "title": "Deep Anomaly Detection and Search via Reinforcement Learning",
    "abstract": " Comments: We have changed the experiment in section 4 to achieve better performance ",
    "url": "https://arxiv.org/abs/2208.14834",
    "authors": [
      "Chao Chen",
      "Dawei Wang",
      "Feng Mao",
      "Zongzhang Zhang",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.00110",
    "title": "Complexity of diameter on AT-free graphs is linear",
    "abstract": " Title: Complexity of diameter on AT-free graphs is linear ",
    "url": "https://arxiv.org/abs/2209.00110",
    "authors": [
      "Oleksiy Al-Saadi",
      "Jitender Deogun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2209.00585",
    "title": "Adversarial Stain Transfer to Study the Effect of Color Variation on  Cell Instance Segmentation",
    "abstract": " Title: Adversarial Stain Transfer to Study the Effect of Color Variation on  Cell Instance Segmentation ",
    "url": "https://arxiv.org/abs/2209.00585",
    "authors": [
      "Huaqian Wu",
      "Nicolas Souedet",
      "Camille Mabillon",
      "Caroline Jan",
      "C\u00e9dric Clouchoux",
      "Thierry Delzescaux"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03834",
    "title": "Pre-Training a Graph Recurrent Network for Language Representation",
    "abstract": " Comments: NeurIPS Efficient Natural Language and Speech Processing (ENLSP) Workshop 2022 ",
    "url": "https://arxiv.org/abs/2209.03834",
    "authors": [
      "Yile Wang",
      "Linyi Yang",
      "Zhiyang Teng",
      "Ming Zhou",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.04093",
    "title": "Learning Audio-Visual embedding for Person Verification in the Wild",
    "abstract": " Title: Learning Audio-Visual embedding for Person Verification in the Wild ",
    "url": "https://arxiv.org/abs/2209.04093",
    "authors": [
      "Peiwen Sun",
      "Shanshan Zhang",
      "Zishan Liu",
      "Yougen Yuan",
      "Taotao Zhang",
      "Honggang Zhang",
      "Pengfei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.07699",
    "title": "Graph Contrastive Learning with Cross-view Reconstruction",
    "abstract": " Title: Graph Contrastive Learning with Cross-view Reconstruction ",
    "url": "https://arxiv.org/abs/2209.07699",
    "authors": [
      "Qianlong Wen",
      "Zhongyu Ouyang",
      "Chunhui Zhang",
      "Yiyue Qian",
      "Yanfang Ye",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11904",
    "title": "CryptoGCN: Fast and Scalable Homomorphically Encrypted Graph  Convolutional Network Inference",
    "abstract": " Comments: Accepted in Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2209.11904",
    "authors": [
      "Ran Ran",
      "Nuo Xu",
      "Wei Wang",
      "Gang Quan",
      "Jieming Yin",
      "Wujie Wen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13667",
    "title": "Robust MADER: Decentralized and Asynchronous Multiagent Trajectory  Planner Robust to Communication Delay",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2209.13667",
    "authors": [
      "Kota Kondo",
      "Jesus Tordesillas",
      "Reinaldo Figueroa",
      "Juan Rached",
      "Joseph Merkel",
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.00597",
    "title": "Composition of Differential Privacy & Privacy Amplification by  Subsampling",
    "abstract": " Title: Composition of Differential Privacy & Privacy Amplification by  Subsampling ",
    "url": "https://arxiv.org/abs/2210.00597",
    "authors": [
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00688",
    "title": "On the infinite-depth limit of finite-width neural networks",
    "abstract": " Comments: 71 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2210.00688",
    "authors": [
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.03515",
    "title": "Spiking neural networks for nonlinear regression",
    "abstract": " Title: Spiking neural networks for nonlinear regression ",
    "url": "https://arxiv.org/abs/2210.03515",
    "authors": [
      "Alexander Henkes",
      "Jason K. Eshraghian",
      "Henning Wessels"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06742",
    "title": "H2RBox: Horizontal Box Annotation is All You Need for Oriented Object  Detection",
    "abstract": " Comments: 14 pages, 6 figures, 6 tables, the source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.06742",
    "authors": [
      "Xue Yang",
      "Gefan Zhang",
      "Wentong Li",
      "Xuehui Wang",
      "Yue Zhou",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07185",
    "title": "On the Utility of Self-supervised Models for Prosody-related Tasks",
    "abstract": " Comments: Accepted to IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.07185",
    "authors": [
      "Guan-Ting Lin",
      "Chi-Luen Feng",
      "Wei-Ping Huang",
      "Yuan Tseng",
      "Tzu-Han Lin",
      "Chen-An Li",
      "Hung-yi Lee",
      "Nigel G. Ward"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.09521",
    "title": "A Practical, Progressively-Expressive GNN",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.09521",
    "authors": [
      "Lingxiao Zhao",
      "Louis H\u00e4rtel",
      "Neil Shah",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09597",
    "title": "Soft-Labeled Contrastive Pre-training for Function-level Code  Representation",
    "abstract": " Comments: Accepted to EMNLP 2022 (findings) ",
    "url": "https://arxiv.org/abs/2210.09597",
    "authors": [
      "Xiaonan Li",
      "Daya Guo",
      "Yeyun Gong",
      "Yun Lin",
      "Yelong Shen",
      "Xipeng Qiu",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.09900",
    "title": "SA-DNet: A on-demand semantic object registration network adapting to  non-rigid deformation",
    "abstract": " Comments: 15 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2210.09900",
    "authors": [
      "Housheng Xie",
      "Junhui Qiu",
      "Yuan Dai",
      "Yang Yang",
      "Changcheng Xiang",
      "Yukuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10983",
    "title": "PSA-Det3D: Pillar Set Abstraction for 3D object Detection",
    "abstract": " Title: PSA-Det3D: Pillar Set Abstraction for 3D object Detection ",
    "url": "https://arxiv.org/abs/2210.10983",
    "authors": [
      "Zhicong Huang",
      "Jingwen Zhao",
      "Zhijie Zheng",
      "Dihu Chena",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11723",
    "title": "Evidence of Vocal Tract Articulation in Self-Supervised Learning of  Speech",
    "abstract": " Title: Evidence of Vocal Tract Articulation in Self-Supervised Learning of  Speech ",
    "url": "https://arxiv.org/abs/2210.11723",
    "authors": [
      "Cheol Jun Cho",
      "Peter Wu",
      "Abdelrahman Mohamed",
      "Gopala K. Anumanchipalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.12606",
    "title": "Nash Equilibria and Pitfalls of Adversarial Training in Adversarial  Robustness Games",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2210.12606",
    "authors": [
      "Maria-Florina Balcan",
      "Rattana Pukdee",
      "Pradeep Ravikumar",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.12740",
    "title": "HiFi-WaveGAN: Generative Adversarial Network with Auxiliary  Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation",
    "abstract": " Comments: submitted to icassp2023 ",
    "url": "https://arxiv.org/abs/2210.12740",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.12852",
    "title": "1st Place Solution of The Robust Vision Challenge (RVC) 2022 Semantic  Segmentation Track",
    "abstract": " Comments: The Winning Solution to The Robust Vision Challenge 2022 Semantic Segmentation Track ",
    "url": "https://arxiv.org/abs/2210.12852",
    "authors": [
      "Junfei Xiao",
      "Zhichao Xu",
      "Shiyi Lan",
      "Zhiding Yu",
      "Alan Yuille",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12903",
    "title": "Gallery Filter Network for Person Search",
    "abstract": " Comments: WACV 2023; Code: this https URL ",
    "url": "https://arxiv.org/abs/2210.12903",
    "authors": [
      "Lucas Jaffe",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": " Comments: 5 pages, 13 figures, conference ",
    "url": "https://arxiv.org/abs/2210.13012",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13801",
    "title": "Deep Boosting Robustness of DNN-based Image Watermarking via DBMark",
    "abstract": " Title: Deep Boosting Robustness of DNN-based Image Watermarking via DBMark ",
    "url": "https://arxiv.org/abs/2210.13801",
    "authors": [
      "Guanhui Ye",
      "Jiashi Gao",
      "Wei Xie",
      "Bo Yin",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14056",
    "title": "Unsupervised Anomaly Detection for Auditing Data and Impact of  Categorical Encodings",
    "abstract": " Comments: This work has been accepted at Proceedings of the Neurips 2022 Workshop on Synthetic Data 4ML ",
    "url": "https://arxiv.org/abs/2210.14056",
    "authors": [
      "Ajay Chawda",
      "Stefanie Grimm",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14169",
    "title": "Weakly Supervised Data Augmentation Through Prompting for Dialogue  Understanding",
    "abstract": " Comments: To appear in SyntheticData4ML @ NeurIPS 2022. 16 pages, 10 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.14169",
    "authors": [
      "Maximillian Chen",
      "Alexandros Papangelis",
      "Chenyang Tao",
      "Andy Rosenbaum",
      "Seokhwan Kim",
      "Yang Liu",
      "Zhou Yu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]