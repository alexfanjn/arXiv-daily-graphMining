[
  {
    "id": "arXiv:2210.06469",
    "title": "Participatory Design for Mental Health Data Visualization on a Social  Robot",
    "abstract": "The intersection of data visualization and human-robot interaction (HRI) is a burgeoning field. Understanding, communicating, and processing different kinds of data for creating versatile visualizations can benefit HRI. Conversely, expressing different kinds of data generated from HRI through effective visualizations can provide interesting insights. Our work adds to the literature of this growing domain. In this paper, we present our exploratory work on visualizing mental health data on a social robot. Particularly, we discuss development of mental health data visualizations using a participatory design (PD) approach. As a first step with mental health data visualization on a social robot, this work paves the way for relevant further work and using social robots as data visualization tools. ",
    "url": "https://arxiv.org/abs/2210.06469",
    "authors": [
      "Raida Karim",
      "Edgar Lopez",
      "Elin A. Bj\u00f6rling",
      "Maya Cakmak"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06501",
    "title": "Robust Action Segmentation from Timestamp Supervision",
    "abstract": "Action segmentation is the task of predicting an action label for each frame of an untrimmed video. As obtaining annotations to train an approach for action segmentation in a fully supervised way is expensive, various approaches have been proposed to train action segmentation models using different forms of weak supervision, e.g., action transcripts, action sets, or more recently timestamps. Timestamp supervision is a promising type of weak supervision as obtaining one timestamp per action is less expensive than annotating all frames, but it provides more information than other forms of weak supervision. However, previous works assume that every action instance is annotated with a timestamp, which is a restrictive assumption since it assumes that annotators do not miss any action. In this work, we relax this restrictive assumption and take missing annotations for some action instances into account. We show that our approach is more robust to missing annotations compared to other approaches and various baselines. ",
    "url": "https://arxiv.org/abs/2210.06501",
    "authors": [
      "Yaser Souri",
      "Yazan Abu Farha",
      "Emad Bahrami",
      "Gianpiero Francesca",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06509",
    "title": "Understanding Impacts of Task Similarity on Backdoor Attack and  Detection",
    "abstract": "With extensive studies on backdoor attack and detection, still fundamental questions are left unanswered regarding the limits in the adversary's capability to attack and the defender's capability to detect. We believe that answers to these questions can be found through an in-depth understanding of the relations between the primary task that a benign model is supposed to accomplish and the backdoor task that a backdoored model actually performs. For this purpose, we leverage similarity metrics in multi-task learning to formally define the backdoor distance (similarity) between the primary task and the backdoor task, and analyze existing stealthy backdoor attacks, revealing that most of them fail to effectively reduce the backdoor distance and even for those that do, still much room is left to further improve their stealthiness. So we further design a new method, called TSA attack, to automatically generate a backdoor model under a given distance constraint, and demonstrate that our new attack indeed outperforms existing attacks, making a step closer to understanding the attacker's limits. Most importantly, we provide both theoretic results and experimental evidence on various datasets for the positive correlation between the backdoor distance and backdoor detectability, demonstrating that indeed our task similarity analysis help us better understand backdoor risks and has the potential to identify more effective mitigations. ",
    "url": "https://arxiv.org/abs/2210.06509",
    "authors": [
      "Di Tang",
      "Rui Zhu",
      "XiaoFeng Wang",
      "Haixu Tang",
      "Yi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06529",
    "title": "Prepended Domain Transformer: Heterogeneous Face Recognition without  Bells and Whistles",
    "abstract": "Heterogeneous Face Recognition (HFR) refers to matching face images captured in different domains, such as thermal to visible images (VIS), sketches to visible images, near-infrared to visible, and so on. This is particularly useful in matching visible spectrum images to images captured from other modalities. Though highly useful, HFR is challenging because of the domain gap between the source and target domain. Often, large-scale paired heterogeneous face image datasets are absent, preventing training models specifically for the heterogeneous task. In this work, we propose a surprisingly simple, yet, very effective method for matching face images across different sensing modalities. The core idea of the proposed approach is to add a novel neural network block called Prepended Domain Transformer (PDT) in front of a pre-trained face recognition (FR) model to address the domain gap. Retraining this new block with few paired samples in a contrastive learning setup was enough to achieve state-of-the-art performance in many HFR benchmarks. The PDT blocks can be retrained for several source-target combinations using the proposed general framework. The proposed approach is architecture agnostic, meaning they can be added to any pre-trained FR models. Further, the approach is modular and the new block can be trained with a minimal set of paired samples, making it much easier for practical deployment. The source code and protocols will be made available publicly. ",
    "url": "https://arxiv.org/abs/2210.06529",
    "authors": [
      "Anjith George",
      "Amir Mohammadi",
      "Sebastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.06553",
    "title": "Scenario-based Evaluation of Prediction Models for Automated Vehicles",
    "abstract": "To operate safely, an automated vehicle (AV) must anticipate how the environment around it will evolve. For that purpose, it is important to know which prediction models are most appropriate for every situation. Currently, assessment of prediction models is often performed over a set of trajectories without distinction of the type of movement they capture, resulting in the inability to determine the suitability of each model for different situations. In this work we illustrate how standardized evaluation methods result in wrong conclusions regarding a model's predictive capabilities, preventing a clear assessment of prediction models and potentially leading to dangerous on-road situations. We argue that following evaluation practices in safety assessment for AVs, assessment of prediction models should be performed in a scenario-based fashion. To encourage scenario-based assessment of prediction models and illustrate the dangers of improper assessment, we categorize trajectories of the Waymo Open Motion dataset according to the type of movement they capture. Next, three different models are thoroughly evaluated for different trajectory types and prediction horizons. Results show that common evaluation methods are insufficient and the assessment should be performed depending on the application in which the model will operate. ",
    "url": "https://arxiv.org/abs/2210.06553",
    "authors": [
      "Manuel Mu\u00f1oz S\u00e1nchez",
      "Jos Elfring",
      "Emilia Silvas",
      "Ren\u00e9 van de Molengraft"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06559",
    "title": "Exact and approximation algorithms for sensor placement against DDoS  attacks",
    "abstract": "In a DDoS attack (Distributed Denial of Service), an attacker gains control of many network users through a virus. Then the controlled users send many requests to a victim, leading to its resources being depleted. DDoS attacks are hard to defend because of their distributed nature, large scale and various attack techniques. One possible mode of defense is to place sensors in a network that can detect and stop an unwanted request. However, such sensors are expensive so there is a natural question as to the minimum number of sensors and the optimal placement required to get the necessary level of safety. Presented below are two mixed integer models for optimal sensor placement against DDoS attacks. Both models lead to a trade-off between the number of deployed sensors and the volume of uncontrolled flow. Since the above placement problems are NP-hard, two efficient heuristics are designed, implemented and compared experimentally with exact mixed integer linear programming solvers. ",
    "url": "https://arxiv.org/abs/2210.06559",
    "authors": [
      "Konstanty Junosza-Szaniawski",
      "Dariusz Nogalski",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.06575",
    "title": "GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and  Specular Objects Using Generalizable NeRF",
    "abstract": "In this work, we tackle 6-DoF grasp detection for transparent and specular objects, which is an important yet challenging problem in vision-based robotic systems, due to the failure of depth cameras in sensing their geometry. We, for the first time, propose a multiview RGB-based 6-DoF grasp detection network, GraspNeRF, that leverages the generalizable neural radiance field (NeRF) to achieve material-agnostic object grasping in clutter. Compared to the existing NeRF-based 3-DoF grasp detection methods that rely on densely captured input images and time-consuming per-scene optimization, our system can perform zero-shot NeRF construction with sparse RGB inputs and reliably detect 6-DoF grasps, both in real-time. The proposed framework jointly learns generalizable NeRF and grasp detection in an end-to-end manner, optimizing the scene representation construction for the grasping. For training data, we generate a large-scale photorealistic domain-randomized synthetic dataset of grasping in cluttered tabletop scenes that enables direct transfer to the real world. Our extensive experiments in synthetic and real-world environments demonstrate that our method significantly outperforms all the baselines in all the experiments while remaining in real-time. ",
    "url": "https://arxiv.org/abs/2210.06575",
    "authors": [
      "Qiyu Dai",
      "Yan Zhu",
      "Yiran Geng",
      "Ciyu Ruan",
      "Jiazhao Zhang",
      "He Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06578",
    "title": "FASTER-CE: Fast, Sparse, Transparent, and Robust Counterfactual  Explanations",
    "abstract": "Counterfactual explanations have substantially increased in popularity in the past few years as a useful human-centric way of understanding individual black-box model predictions. While several properties desired of high-quality counterfactuals have been identified in the literature, three crucial concerns: the speed of explanation generation, robustness/sensitivity and succinctness of explanations (sparsity) have been relatively unexplored. In this paper, we present FASTER-CE: a novel set of algorithms to generate fast, sparse, and robust counterfactual explanations. The key idea is to efficiently find promising search directions for counterfactuals in a latent space that is specified via an autoencoder. These directions are determined based on gradients with respect to each of the original input features as well as of the target, as estimated in the latent space. The ability to quickly examine combinations of the most promising gradient directions as well as to incorporate additional user-defined constraints allows us to generate multiple counterfactual explanations that are sparse, realistic, and robust to input manipulations. Through experiments on three datasets of varied complexities, we show that FASTER-CE is not only much faster than other state of the art methods for generating multiple explanations but also is significantly superior when considering a larger set of desirable (and often conflicting) properties. Specifically we present results across multiple performance metrics: sparsity, proximity, validity, speed of generation, and the robustness of explanations, to highlight the capabilities of the FASTER-CE family. ",
    "url": "https://arxiv.org/abs/2210.06578",
    "authors": [
      "Shubham Sharma",
      "Alan H. Gee",
      "Jette Henderson",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06589",
    "title": "Adversarial Attack Against Image-Based Localization Neural Networks",
    "abstract": "In this paper, we present a proof of concept for adversarially attacking the image-based localization module of an autonomous vehicle. This attack aims to cause the vehicle to perform a wrong navigational decisions and prevent it from reaching a desired predefined destination in a simulated urban environment. A database of rendered images allowed us to train a deep neural network that performs a localization task and implement, develop and assess the adversarial pattern. Our tests show that using this adversarial attack we can prevent the vehicle from turning at a given intersection. This is done by manipulating the vehicle's navigational module to falsely estimate its current position and thus fail to initialize the turning procedure until the vehicle misses the last opportunity to perform a safe turn in a given intersection. ",
    "url": "https://arxiv.org/abs/2210.06589",
    "authors": [
      "Meir Brand",
      "Itay Naeh",
      "Daniel Teitelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06596",
    "title": "Reducing The Mismatch Between Marginal and Learned Distributions in  Neural Video Compression",
    "abstract": "During the last four years, we have witnessed the success of end-to-end trainable models for image compression. Compared to decades of incremental work, these machine learning (ML) techniques learn all the components of the compression technique, which explains their actual superiority. However, end-to-end ML models have not yet reached the performance of traditional video codecs such as VVC. Possible explanations can be put forward: lack of data to account for the temporal redundancy, or inefficiency of latent's density estimation in the neural model. The latter problem can be defined by the discrepancy between the latent's marginal distribution and the learned prior distribution. This mismatch, known as amortization gap of entropy model, enlarges the file size of compressed data. In this paper, we propose to evaluate the amortization gap for three state-of-the-art ML video compression methods. Second, we propose an efficient and generic method to solve the amortization gap and show that it leads to an improvement between $2\\%$ to $5\\%$ without impacting reconstruction quality. ",
    "url": "https://arxiv.org/abs/2210.06596",
    "authors": [
      "Muhammet Balcilar",
      "Bharath Bhushan Damodaran",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06610",
    "title": "A Neural Mean Embedding Approach for Back-door and Front-door Adjustment",
    "abstract": "We consider the estimation of average and counterfactual treatment effects, under two settings: back-door adjustment and front-door adjustment. The goal in both cases is to recover the treatment effect without having an access to a hidden confounder. This objective is attained by first estimating the conditional mean of the desired outcome variable given relevant covariates (the \"first stage\" regression), and then taking the (conditional) expectation of this function as a \"second stage\" procedure. We propose to compute these conditional expectations directly using a regression function to the learned input features of the first stage, thus avoiding the need for sampling or density estimation. All functions and features (and in particular, the output features in the second stage) are neural networks learned adaptively from data, with the sole requirement that the final layer of the first stage should be linear. The proposed method is shown to converge to the true causal parameter, and outperforms the recent state-of-the-art methods on challenging causal benchmarks, including settings involving high-dimensional image data. ",
    "url": "https://arxiv.org/abs/2210.06610",
    "authors": [
      "Liyuan Xu",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.06614",
    "title": "Anomaly Detection via Federated Learning",
    "abstract": "Machine learning has helped advance the field of anomaly detection by incorporating classifiers and autoencoders to decipher between normal and anomalous behavior. Additionally, federated learning has provided a way for a global model to be trained with multiple clients' data without requiring the client to directly share their data. This paper proposes a novel anomaly detector via federated learning to detect malicious network activity on a client's server. In our experiments, we use an autoencoder with a classifier in a federated learning framework to determine if the network activity is benign or malicious. By using our novel min-max scalar and sampling technique, called FedSam, we determined federated learning allows the global model to learn from each client's data and, in turn, provide a means for each client to improve their intrusion detection system's defense against cyber-attacks. ",
    "url": "https://arxiv.org/abs/2210.06614",
    "authors": [
      "Marc Vucovich",
      "Amogh Tarcar",
      "Penjo Rebelo",
      "Narendra Gade",
      "Ruchi Porwal",
      "Abdul Rahman",
      "Christopher Redino",
      "Kevin Choi",
      "Dhruv Nandakumar",
      "Robert Schiller",
      "Edward Bowen",
      "Alex West",
      "Sanmitra Bhattacharya",
      "Balaji Veeramani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.06630",
    "title": "Fairness via Adversarial Attribute Neighbourhood Robust Learning",
    "abstract": "Improving fairness between privileged and less-privileged sensitive attribute groups (e.g, {race, gender}) has attracted lots of attention. To enhance the model performs uniformly well in different sensitive attributes, we propose a principled \\underline{R}obust \\underline{A}dversarial \\underline{A}ttribute \\underline{N}eighbourhood (RAAN) loss to debias the classification head and promote a fairer representation distribution across different sensitive attribute groups. The key idea of RAAN is to mitigate the differences of biased representations between different sensitive attribute groups by assigning each sample an adversarial robust weight, which is defined on the representations of adversarial attribute neighbors, i.e, the samples from different protected groups. To provide efficient optimization algorithms, we cast the RAAN into a sum of coupled compositional functions and propose a stochastic adaptive (Adam-style) and non-adaptive (SGD-style) algorithm framework SCRAAN with provable theoretical guarantee. Extensive empirical studies on fairness-related benchmark datasets verify the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.06630",
    "authors": [
      "Qi Qi",
      "Shervin Ardeshir",
      "Yi Xu",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06649",
    "title": "Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch  IoE in Wireless Network",
    "abstract": "Explainable artificial intelligence (XAI) twin systems will be a fundamental enabler of zero-touch network and service management (ZSM) for sixth-generation (6G) wireless networks. A reliable XAI twin system for ZSM requires two composites: an extreme analytical ability for discretizing the physical behavior of the Internet of Everything (IoE) and rigorous methods for characterizing the reasoning of such behavior. In this paper, a novel neuro-symbolic explainable artificial intelligence twin framework is proposed to enable trustworthy ZSM for a wireless IoE. The physical space of the XAI twin executes a neural-network-driven multivariate regression to capture the time-dependent wireless IoE environment while determining unconscious decisions of IoE service aggregation. Subsequently, the virtual space of the XAI twin constructs a directed acyclic graph (DAG)-based Bayesian network that can infer a symbolic reasoning score over unconscious decisions through a first-order probabilistic language model. Furthermore, a Bayesian multi-arm bandits-based learning problem is proposed for reducing the gap between the expected explained score and the current obtained score of the proposed neuro-symbolic XAI twin. To address the challenges of extensible, modular, and stateless management functions in ZSM, the proposed neuro-symbolic XAI twin framework consists of two learning systems: 1) an implicit learner that acts as an unconscious learner in physical space, and 2) an explicit leaner that can exploit symbolic reasoning based on implicit learner decisions and prior evidence. Experimental results show that the proposed neuro-symbolic XAI twin can achieve around 96.26% accuracy while guaranteeing from 18% to 44% more trust score in terms of reasoning and closed-loop automation. ",
    "url": "https://arxiv.org/abs/2210.06649",
    "authors": [
      "Md. Shirajum Munir",
      "Ki Tae Kim",
      "Apurba Adhikary",
      "Walid Saad",
      "Sachin Shetty",
      "Seong-Bae Park",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.06650",
    "title": "Interpreting Neural Policies with Disentangled Tree Representations",
    "abstract": "Compact neural networks used in policy learning and closed-loop end-to-end control learn representations from data that encapsulate agent dynamics and potentially the agent-environment's factors of variation. A formal and quantitative understanding and interpretation of these explanatory factors in neural representations is difficult to achieve due to the complex and intertwined correspondence of neural activities with emergent behaviors. In this paper, we design a new algorithm that programmatically extracts tree representations from compact neural policies, in the form of a set of logic programs grounded by the world state. To assess how well networks uncover the dynamics of the task and their factors of variation, we introduce interpretability metrics that measure the disentanglement of learned neural dynamics from a concentration of decisions, mutual information, and modularity perspectives. Moreover, our method allows us to quantify how accurate the extracted decision paths (explanations) are and computes cross-neuron logic conflict. We demonstrate the effectiveness of our approach with several types of compact network architectures on a series of end-to-end learning to control tasks. ",
    "url": "https://arxiv.org/abs/2210.06650",
    "authors": [
      "Tsun-Hsuan Wang",
      "Wei Xiao",
      "Tim Seyde",
      "Ramin Hasani",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06670",
    "title": "A Game Theoretical vulnerability analysis of Adversarial Attack",
    "abstract": "In recent times deep learning has been widely used for automating various security tasks in Cyber Domains. However, adversaries manipulate data in many situations and diminish the deployed deep learning model's accuracy. One notable example is fooling CAPTCHA data to access the CAPTCHA-based Classifier leading to the critical system being vulnerable to cybersecurity attacks. To alleviate this, we propose a computational framework of game theory to analyze the CAPTCHA-based Classifier's vulnerability, strategy, and outcomes by forming a simultaneous two-player game. We apply the Fast Gradient Symbol Method (FGSM) and One Pixel Attack on CAPTCHA Data to imitate real-life scenarios of possible cyber-attack. Subsequently, to interpret this scenario from a Game theoretical perspective, we represent the interaction in the Stackelberg Game in Kuhn tree to study players' possible behaviors and actions by applying our Classifier's actual predicted values. Thus, we interpret potential attacks in deep learning applications while representing viable defense strategies in the game theory prospect. ",
    "url": "https://arxiv.org/abs/2210.06670",
    "authors": [
      "Khondker Fariha Hossain",
      "Alireza Tavakkoli",
      "Shamik Sengupta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.06671",
    "title": "Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity  of Neural Networks",
    "abstract": "Based on the concepts of Wasserstein barycenter (WB) and Gromov-Wasserstein barycenter (GWB), we propose a unified mathematical framework for neural network (NN) model fusion and utilize it to reveal new insights about the linear mode connectivity of SGD solutions. In our framework, the fusion occurs in a layer-wise manner and builds on an interpretation of a node in a network as a function of the layer preceding it. The versatility of our mathematical framework allows us to talk about model fusion and linear mode connectivity for a broad class of NNs, including fully connected NN, CNN, ResNet, RNN, and LSTM, in each case exploiting the specific structure of the network architecture. We present extensive numerical experiments to: 1) illustrate the strengths of our approach in relation to other model fusion methodologies and 2) from a certain perspective, provide new empirical evidence for recent conjectures which say that two local minima found by gradient-based methods end up lying on the same basin of the loss landscape after a proper permutation of weights is applied to one of the models. ",
    "url": "https://arxiv.org/abs/2210.06671",
    "authors": [
      "Aditya Kumar Akash",
      "Sixu Li",
      "Nicol\u00e1s Garc\u00eda Trillos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06681",
    "title": "Brain Network Transformer",
    "abstract": "Human brains are commonly modeled as networks of Regions of Interest (ROIs) and their connections for the understanding of brain functions and mental disorders. Recently, Transformer-based models have been studied over different types of data, including graphs, shown to bring performance gains widely. In this work, we study Transformer-based models for brain network analysis. Driven by the unique properties of data, we model brain networks as graphs with nodes of fixed size and order, which allows us to (1) use connection profiles as node features to provide natural and low-cost positional information and (2) learn pair-wise connection strengths among ROIs with efficient attention weights across individuals that are predictive towards downstream analysis tasks. Moreover, we propose an Orthonormal Clustering Readout operation based on self-supervised soft clustering and orthonormal projection. This design accounts for the underlying functional modules that determine similar behaviors among groups of ROIs, leading to distinguishable cluster-aware node embeddings and informative graph embeddings. Finally, we re-standardize the evaluation pipeline on the only one publicly available large-scale brain network dataset of ABIDE, to enable meaningful comparison of different models. Experiment results show clear improvements of our proposed Brain Network Transformer on both the public ABIDE and our restricted ABCD datasets. The implementation is available at https://github.com/Wayfear/BrainNetworkTransformer. ",
    "url": "https://arxiv.org/abs/2210.06681",
    "authors": [
      "Xuan Kan",
      "Wei Dai",
      "Hejie Cui",
      "Zilong Zhang",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.06682",
    "title": "Application-Driven AI Paradigm for Hand-Held Action Detection",
    "abstract": "In practical applications especially with safety requirement, some hand-held actions need to be monitored closely, including smoking cigarettes, dialing, eating, etc. Taking smoking cigarettes as example, existing smoke detection algorithms usually detect the cigarette or cigarette with hand as the target object only, which leads to low accuracy. In this paper, we propose an application-driven AI paradigm for hand-held action detection based on hierarchical object detection. It is a coarse-to-fine hierarchical detection framework composed of two modules. The first one is a coarse detection module with the human pose consisting of the whole hand, cigarette and head as target object. The followed second one is a fine detection module with the fingers holding cigarette, mouth area and the whole cigarette as target. Some experiments are done with the dataset collected from real-world scenarios, and the results show that the proposed framework achieve higher detection rate with good adaptation and robustness in complex environments. ",
    "url": "https://arxiv.org/abs/2210.06682",
    "authors": [
      "Kohou Wang",
      "Zhaoxiang Liu",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06684",
    "title": "Connectivity-Aware Pheromone Mobility Model for Autonomous UAV Networks",
    "abstract": "UAV networks consisting of reduced size, weight, and power (low SWaP) fixed-wing UAVs are used for civilian and military applications such as search and rescue, surveillance, and tracking. To carry out these operations efficiently, there is a need to develop scalable, decentralized autonomous UAV network architectures with high network connectivity. However, the area coverage and the network connectivity requirements exhibit a fundamental trade-off. In this paper, a connectivity-aware pheromone mobility (CAP) model is designed for search and rescue operations, which is capable of maintaining connectivity among UAVs in the network. We use stigmergy-based digital pheromone maps along with distance-based local connectivity information to autonomously coordinate the UAV movements, in order to improve its map coverage efficiency while maintaining high network connectivity. ",
    "url": "https://arxiv.org/abs/2210.06684",
    "authors": [
      "Shreyas Devaraju",
      "Alexander Ihler",
      "Sunil Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.06686",
    "title": "Real Spike: Learning Real-valued Spikes for Spiking Neural Networks",
    "abstract": "Brain-inspired spiking neural networks (SNNs) have recently drawn more and more attention due to their event-driven and energy-efficient characteristics. The integration of storage and computation paradigm on neuromorphic hardwares makes SNNs much different from Deep Neural Networks (DNNs). In this paper, we argue that SNNs may not benefit from the weight-sharing mechanism, which can effectively reduce parameters and improve inference efficiency in DNNs, in some hardwares, and assume that an SNN with unshared convolution kernels could perform better. Motivated by this assumption, a training-inference decoupling method for SNNs named as Real Spike is proposed, which not only enjoys both unshared convolution kernels and binary spikes in inference-time but also maintains both shared convolution kernels and Real-valued Spikes during training. This decoupling mechanism of SNN is realized by a re-parameterization technique. Furthermore, based on the training-inference-decoupled idea, a series of different forms for implementing Real Spike on different levels are presented, which also enjoy shared convolutions in the inference and are friendly to both neuromorphic and non-neuromorphic hardware platforms. A theoretical proof is given to clarify that the Real Spike-based SNN network is superior to its vanilla counterpart. Experimental results show that all different Real Spike versions can consistently improve the SNN performance. Moreover, the proposed method outperforms the state-of-the-art models on both non-spiking static and neuromorphic datasets. ",
    "url": "https://arxiv.org/abs/2210.06686",
    "authors": [
      "Yufei Guo",
      "Liwen Zhang",
      "Yuanpei Chen",
      "Xinyi Tong",
      "Xiaode Liu",
      "YingLei Wang",
      "Xuhui Huang",
      "Zhe Ma"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06688",
    "title": "Overlooked Video Classification in Weakly Supervised Video Anomaly  Detection",
    "abstract": "Current weakly supervised video anomaly detection algorithms mostly use multiple instance learning (MIL) or their varieties. Almost all recent approaches focus on how to select the correct snippets for training to improve the performance. They overlook or do not realize the power of video classification in boosting the performance of anomaly detection. In this paper, we study explicitly the power of video classification supervision using a BERT or LSTM. With this BERT or LSTM, CNN features of all snippets of a video can be aggregated into a single feature which can be used for video classification. This simple yet powerful video classification supervision, combined into the MIL framework, brings extraordinary performance improvement on all three major video anomaly detection datasets. Particularly it improves the mean average precision (mAP) on the XD-Violence from SOTA 78.84\\% to new 82.10\\%. The source code is available at https://github.com/wjtan99/BERT_Anomaly_Video_Classification. ",
    "url": "https://arxiv.org/abs/2210.06688",
    "authors": [
      "Weijun Tan",
      "Qi Yao",
      "Jingfeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06698",
    "title": "A Near-Sensor Processing Accelerator for Approximate Local Binary  Pattern Networks",
    "abstract": "In this work, a high-speed and energy-efficient comparator-based Near-Sensor Local Binary Pattern accelerator architecture (NS-LBP) is proposed to execute a novel local binary pattern deep neural network. First, inspired by recent LBP networks, we design an approximate, hardware-oriented, and multiply-accumulate (MAC)-free network named Ap-LBP for efficient feature extraction, further reducing the computation complexity. Then, we develop NS-LBP as a processing-in-SRAM unit and a parallel in-memory LBP algorithm to process images near the sensor in a cache, remarkably reducing the power consumption of data transmission to an off-chip processor. Our circuit-to-application co-simulation results on MNIST and SVHN data-sets demonstrate minor accuracy degradation compared to baseline CNN and LBP-network models, while NS-LBP achieves 1.25 GHz and energy-efficiency of 37.4 TOPS/W. NS-LBP reduces energy consumption by 2.2x and execution time by a factor of 4x compared to the best recent LBP-based networks. ",
    "url": "https://arxiv.org/abs/2210.06698",
    "authors": [
      "Shaahin Angizi",
      "Mehrdad Morsali",
      "Sepehr Tabrizchi",
      "Arman Roohi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2210.06699",
    "title": "Parameter-Efficient Masking Networks",
    "abstract": "A deeper network structure generally handles more complicated non-linearity and performs more competitively. Nowadays, advanced network designs often contain a large number of repetitive structures (e.g., Transformer). They empower the network capacity to a new level but also increase the model size inevitably, which is unfriendly to either model restoring or transferring. In this study, we are the first to investigate the representative potential of fixed random weights with limited unique values by learning diverse masks and introduce the Parameter-Efficient Masking Networks (PEMN). It also naturally leads to a new paradigm for model compression to diminish the model size. Concretely, motivated by the repetitive structures in modern neural networks, we utilize one random initialized layer, accompanied with different masks, to convey different feature mappings and represent repetitive network modules. Therefore, the model can be expressed as \\textit{one-layer} with a bunch of masks, which significantly reduce the model storage cost. Furthermore, we enhance our strategy by learning masks for a model filled by padding a given random weights vector. In this way, our method can further lower the space complexity, especially for models without many repetitive architectures. We validate the potential of PEMN learning masks on random weights with limited unique values and test its effectiveness for a new compression paradigm based on different network architectures. Code is available at https://github.com/yueb17/PEMN ",
    "url": "https://arxiv.org/abs/2210.06699",
    "authors": [
      "Yue Bai",
      "Huan Wang",
      "Xu Ma",
      "Yitian Zhang",
      "Zhiqiang Tao",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06703",
    "title": "On the Minimum Cycle Cover problem on graphs with bounded co-degeneracy",
    "abstract": "In 2021, Duarte, Oliveira, and Souza [MFCS 2021] showed some problems that are FPT when parameterized by the treewidth of the complement graph (called co-treewidth). Since the degeneracy of a graph is at most its treewidth, they also introduced the study of co-degeneracy (the degeneracy of the complement graph) as a parameter. In 1976, Bondy and Chv\\'{a}tal [DM 1976] introduced the notion of closure of a graph: let $\\ell$ be an integer; the $(n+\\ell)$-closure, $\\operatorname{cl}_{n+\\ell}(G)$, of a graph $G$ with $n$ vertices is obtained from $G$ by recursively adding an edge between pairs of nonadjacent vertices whose degree sum is at least $n+\\ell$ until no such pair remains. A graph property $\\Upsilon$ defined on all graphs of order $n$ is said to be $(n+\\ell)$-stable if for any graph $G$ of order $n$ that does not satisfy $\\Upsilon$, the fact that $uv$ is not an edge of $G$ and that $G+uv$ satisfies $\\Upsilon$ implies $d(u)+d(v)< n+\\ell$. Duarte et al. [MFCS 2021] developed an algorithmic framework for co-degeneracy parameterization based on the notion of closures for solving problems that are $(n+\\ell)$-stable for some $\\ell$ bounded by a function of the co-degeneracy. In this paper, we first determine the stability of the property of having a bounded cycle cover. After that, combining the framework of Duarte et al. [MFCS 2021] with some results of Jansen, Kozma, and Nederlof [WG 2019], we obtain a $2^{\\mathcal{O}(k)}\\cdot n^{\\mathcal{O}(1)}$-time algorithm for Minimum Cycle Cover on graphs with co-degeneracy at most $k$, which generalizes Duarte et al. [MFCS 2021] and Jansen et al. [WG 2019] results concerning the Hamiltonian Cycle problem. ",
    "url": "https://arxiv.org/abs/2210.06703",
    "authors": [
      "Gabriel L. Duarte",
      "U\u00e9verton S. Souza"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.06704",
    "title": "COLLIDER: A Robust Training Framework for Backdoor Data",
    "abstract": "Deep neural network (DNN) classifiers are vulnerable to backdoor attacks. An adversary poisons some of the training data in such attacks by installing a trigger. The goal is to make the trained DNN output the attacker's desired class whenever the trigger is activated while performing as usual for clean data. Various approaches have recently been proposed to detect malicious backdoored DNNs. However, a robust, end-to-end training approach, like adversarial training, is yet to be discovered for backdoor poisoned data. In this paper, we take the first step toward such methods by developing a robust training framework, COLLIDER, that selects the most prominent samples by exploiting the underlying geometric structures of the data. Specifically, we effectively filter out candidate poisoned data at each training epoch by solving a geometrical coreset selection objective. We first argue how clean data samples exhibit (1) gradients similar to the clean majority of data and (2) low local intrinsic dimensionality (LID). Based on these criteria, we define a novel coreset selection objective to find such samples, which are used for training a DNN. We show the effectiveness of the proposed method for robust training of DNNs on various poisoned datasets, reducing the backdoor success rate significantly. ",
    "url": "https://arxiv.org/abs/2210.06704",
    "authors": [
      "Hadi M. Dolatabadi",
      "Sarah Erfani",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06709",
    "title": "Categorizing Semantic Representations for Neural Machine Translation",
    "abstract": "Modern neural machine translation (NMT) models have achieved competitive performance in standard benchmarks. However, they have recently been shown to suffer limitation in compositional generalization, failing to effectively learn the translation of atoms (e.g., words) and their semantic composition (e.g., modification) from seen compounds (e.g., phrases), and thus suffering from significantly weakened translation performance on unseen compounds during inference. We address this issue by introducing categorization to the source contextualized representations. The main idea is to enhance generalization by reducing sparsity and overfitting, which is achieved by finding prototypes of token representations over the training set and integrating their embeddings into the source encoding. Experiments on a dedicated MT dataset (i.e., CoGnition) show that our method reduces compositional generalization error rates by 24\\% error reduction. In addition, our conceptually simple method gives consistently better results than the Transformer baseline on a range of general MT datasets. ",
    "url": "https://arxiv.org/abs/2210.06709",
    "authors": [
      "Yongjing Yin",
      "Yafu Li",
      "Fandong Meng",
      "Jie Zhou",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06714",
    "title": "Perfect matching cuts partitioning a graph into complementary subgraphs",
    "abstract": "In Partition Into Complementary Subgraphs (Comp-Sub) we are given a graph $G=(V,E)$, and an edge set property $\\Pi$, and asked whether $G$ can be decomposed into two graphs, $H$ and its complement $\\overline{H}$, for some graph $H$, in such a way that the edge cut $[V(H),V(\\overline{H})]$ satisfies the property $\\Pi$. Motivated by previous work, we consider Comp-Sub($\\Pi$) when the property $\\Pi=\\mathcal{PM}$ specifies that the edge cut of the decomposition is a perfect matching. We prove that Comp-Sub($\\mathcal{PM}$) is GI-hard when the graph $G$ is $\\{C_{k\\geq 7}, \\overline{C}_{k\\geq 7} \\}$-free. On the other hand, we show that Comp-Sub($\\mathcal{PM}$) is polynomial-time solvable on $hole$-free graphs and on $P_5$-free graphs. Furthermore, we present characterizations of Comp-Sub($\\mathcal{PM}$) on chordal, distance-hereditary, and extended $P_4$-laden graphs. ",
    "url": "https://arxiv.org/abs/2210.06714",
    "authors": [
      "Diane Castonguay",
      "Erika M. M. Coelho",
      "Hebert Coelho",
      "Julliano R. Nascimento",
      "U\u00e9verton S. Souza"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.06716",
    "title": "Low-resource Neural Machine Translation with Cross-modal Alignment",
    "abstract": "How to achieve neural machine translation with limited parallel data? Existing techniques often rely on large-scale monolingual corpora, which is impractical for some low-resource languages. In this paper, we turn to connect several low-resource languages to a particular high-resource one by additional visual modality. Specifically, we propose a cross-modal contrastive learning method to learn a shared space for all languages, where both a coarse-grained sentence-level objective and a fine-grained token-level one are introduced. Experimental results and further analysis show that our method can effectively learn the cross-modal and cross-lingual alignment with a small amount of image-text pairs and achieves significant improvements over the text-only baseline under both zero-shot and few-shot scenarios. ",
    "url": "https://arxiv.org/abs/2210.06716",
    "authors": [
      "Zhe Yang",
      "Qingkai Fang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06729",
    "title": "A Stream Learning Approach for Real-Time Identification of False Data  Injection Attacks in Cyber-Physical Power Systems",
    "abstract": "This paper presents a novel data-driven framework to aid in system state estimation when the power system is under unobservable false data injection attacks. The proposed framework dynamically detects and classifies false data injection attacks. Then, it retrieves the control signal using the acquired information. This process is accomplished in three main modules, with novel designs, for detection, classification, and control signal retrieval. The detection module monitors historical changes in phasor measurements and captures any deviation pattern caused by an attack on a complex plane. This approach can help to reveal characteristics of the attacks including the direction, magnitude, and ratio of the injected false data. Using this information, the signal retrieval module can easily recover the original control signal and remove the injected false data. Further information regarding the attack type can be obtained through the classifier module. The proposed ensemble learner is compatible with harsh learning conditions including the lack of labeled data, concept drift, concept evolution, recurring classes, and independence from external updates. The proposed novel classifier can dynamically learn from data and classify attacks under all these harsh learning conditions. The introduced framework is evaluated w.r.t. real-world data captured from the Central New York Power System. The obtained results indicate the efficacy and stability of the proposed framework. ",
    "url": "https://arxiv.org/abs/2210.06729",
    "authors": [
      "Ehsan Hallaji",
      "Roozbeh Razavi-Far",
      "Meng Wang",
      "Mehrdad Saif",
      "Bruce Fardanesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.06742",
    "title": "H2RBox: Horizonal Box Annotation is All You Need for Oriented Object  Detection",
    "abstract": "Oriented object detection emerges in many applications from aerial images to autonomous driving, while many existing detection benchmarks are annotated with horizontal bounding box only which is also less costive than fine-grained rotated box, leading to a gap between the readily available training corpus and the rising demand for oriented object detection. This paper proposes a simple yet effective oriented object detection approach called H2RBox merely using horizontal box annotation for weakly-supervised training, which closes the above gap and shows competitive performance even against those trained with rotated boxes. The cores of our method are weakly- and self-supervised learning, which predicts the angle of the object by learning the consistency of two different views. To our best knowledge, H2RBox is the first horizontal box annotation-based oriented object detector. Compared to an alternative i.e. horizontal box-supervised instance segmentation with our post adaption to oriented object detection, our approach is not susceptible to the prediction quality of mask and can perform more robustly in complex scenes containing a large number of dense objects and outliers. Experimental results show that H2RBox has significant performance and speed advantages over horizontal box-supervised instance segmentation methods, as well as lower memory requirements. While compared to rotated box-supervised oriented object detectors, our method shows very close performance and speed, and even surpasses them in some cases. The source code is available at https://github.com/yangxue0827/h2rbox-mmrotate. ",
    "url": "https://arxiv.org/abs/2210.06742",
    "authors": [
      "Xue Yang",
      "Gefan Zhang",
      "Wentong Li",
      "Xuehui Wang",
      "Yue Zhou",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06746",
    "title": "PoliGraph: Automated Privacy Policy Analysis using Knowledge Graphs",
    "abstract": "Privacy policies disclose how an organization collects and handles personal information. Recent work has made progress in leveraging natural language processing (NLP) to automate privacy policy analysis and extract collection statements from different sentences, considered in isolation from each other. In this paper, we view and analyze, for the first time, the entire text of a privacy policy in an integrated way. In terms of methodology: (1) we define PoliGraph, a type of knowledge graph that captures different relations between different parts of the text in a privacy policy; and (2) we develop an NLP-based tool, PoliGraph-er, to automatically extract PoliGraph from the text. In addition, (3) we revisit the notion of ontologies, previously defined in heuristic ways, to capture subsumption relations between terms. We make a clear distinction between local and global ontologies to capture the context of individual privacy policies, application domains, and privacy laws. Using a public dataset for evaluation, we show that PoliGraph-er identifies 61% more collection statements than prior state-of-the-art, with over 90% precision. In terms of applications, PoliGraph enables automated analysis of a corpus of privacy policies and allows us to: (1) reveal common patterns in the texts across different privacy policies, and (2) assess the correctness of the terms as defined within a privacy policy. We also apply PoliGraph to: (3) detect contradictions in a privacy policy-we show false positives by prior work, and (4) analyze the consistency of privacy policies and network traffic, where we identify significantly more clear disclosures than prior work. ",
    "url": "https://arxiv.org/abs/2210.06746",
    "authors": [
      "Hao Cui",
      "Rahmadi Trimananda",
      "Athina Markopoulou",
      "Scott Jordan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.06756",
    "title": "Decoding Visual Neural Representations by Multimodal Learning of  Brain-Visual-Linguistic Features",
    "abstract": "Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowledge underlying the neural data and 2) the small number of paired (stimuli-responses) training data. To overcome these limitations, this paper presents a generic neural decoding method called BraVL that uses multimodal learning of brain-visual-linguistic features. We focus on modeling the relationships between brain, visual and linguistic features via multimodal deep generative models. Specifically, we leverage the mixture-of-product-of-experts formulation to infer a latent code that enables a coherent joint generation of all three modalities. To learn a more consistent joint representation and improve the data efficiency in the case of limited brain activity data, we exploit both intra- and inter-modality mutual information maximization regularization terms. In particular, our BraVL model can be trained under various semi-supervised scenarios to incorporate the visual and textual features obtained from the extra categories. Finally, we construct three trimodal matching datasets, and the extensive experiments lead to some interesting conclusions and cognitive insights: 1) decoding novel visual categories from human brain activity is practically possible with good accuracy; 2) decoding models using the combination of visual and linguistic features perform much better than those using either of them alone; 3) visual perception may be accompanied by linguistic influences to represent the semantics of visual stimuli. Code and data: https://github.com/ChangdeDu/BraVL. ",
    "url": "https://arxiv.org/abs/2210.06756",
    "authors": [
      "Changde Du",
      "Kaicheng Fu",
      "Jinpeng Li",
      "Huiguang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.06771",
    "title": "Feature Reconstruction Attacks and Countermeasures of DNN training in  Vertical Federated Learning",
    "abstract": "Federated learning (FL) has increasingly been deployed, in its vertical form, among organizations to facilitate secure collaborative training over siloed data. In vertical FL (VFL), participants hold disjoint features of the same set of sample instances. Among them, only one has labels. This participant, known as the active party, initiates the training and interacts with the other participants, known as the passive parties. Despite the increasing adoption of VFL, it remains largely unknown if and how the active party can extract feature data from the passive party, especially when training deep neural network (DNN) models. This paper makes the first attempt to study the feature security problem of DNN training in VFL. We consider a DNN model partitioned between active and passive parties, where the latter only holds a subset of the input layer and exhibits some categorical features of binary values. Using a reduction from the Exact Cover problem, we prove that reconstructing those binary features is NP-hard. Through analysis, we demonstrate that, unless the feature dimension is exceedingly large, it remains feasible, both theoretically and practically, to launch a reconstruction attack with an efficient search-based algorithm that prevails over current feature protection techniques. To address this problem, we develop a novel feature protection scheme against the reconstruction attack that effectively misleads the search to some pre-specified random values. With an extensive set of experiments, we show that our protection scheme sustains the feature reconstruction attack in various VFL applications at no expense of accuracy loss. ",
    "url": "https://arxiv.org/abs/2210.06771",
    "authors": [
      "Peng Ye",
      "Zhifeng Jiang",
      "Wei Wang",
      "Bo Li",
      "Baochun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06780",
    "title": "Intermediate Prototype Mining Transformer for Few-Shot Semantic  Segmentation",
    "abstract": "Few-shot semantic segmentation aims to segment the target objects in query under the condition of a few annotated support images. Most previous works strive to mine more effective category information from the support to match with the corresponding objects in query. However, they all ignored the category information gap between query and support images. If the objects in them show large intra-class diversity, forcibly migrating the category information from the support to the query is ineffective. To solve this problem, we are the first to introduce an intermediate prototype for mining both deterministic category information from the support and adaptive category knowledge from the query. Specifically, we design an Intermediate Prototype Mining Transformer (IPMT) to learn the prototype in an iterative way. In each IPMT layer, we propagate the object information in both support and query features to the prototype and then use it to activate the query feature map. By conducting this process iteratively, both the intermediate prototype and the query feature can be progressively improved. At last, the final query feature is used to yield precise segmentation prediction. Extensive experiments on both PASCAL-5i and COCO-20i datasets clearly verify the effectiveness of our IPMT and show that it outperforms previous state-of-the-art methods by a large margin. Code is available at https://github.com/LIUYUANWEI98/IPMT ",
    "url": "https://arxiv.org/abs/2210.06780",
    "authors": [
      "Yuanwei Liu",
      "Nian Liu",
      "Xiwen Yao",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06790",
    "title": "Deep Gesture Generation for Social Robots Using Type-Specific Libraries",
    "abstract": "Body language such as conversational gesture is a powerful way to ease communication. Conversational gestures do not only make a speech more lively but also contain semantic meaning that helps to stress important information in the discussion. In the field of robotics, giving conversational agents (humanoid robots or virtual avatars) the ability to properly use gestures is critical, yet remain a task of extraordinary difficulty. This is because given only a text as input, there are many possibilities and ambiguities to generate an appropriate gesture. Different to previous works we propose a new method that explicitly takes into account the gesture types to reduce these ambiguities and generate human-like conversational gestures. Key to our proposed system is a new gesture database built on the TED dataset that allows us to map a word to one of three types of gestures: \"Imagistic\" gestures, which express the content of the speech, \"Beat\" gestures, which emphasize words, and \"No gestures.\" We propose a system that first maps the words in the input text to their corresponding gesture type, generate type-specific gestures and combine the generated gestures into one final smooth gesture. In our comparative experiments, the effectiveness of the proposed method was confirmed in user studies for both avatar and humanoid robot. ",
    "url": "https://arxiv.org/abs/2210.06790",
    "authors": [
      "Hitoshi Teshima",
      "Naoki Wake",
      "Diego Thomas",
      "Yuta Nakashima",
      "Hiroshi Kawasaki",
      "Katsushi Ikeuchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.06801",
    "title": "Robust offset-free nonlinear model predictive control for systems  learned by neural nonlinear autoregressive exogenous models",
    "abstract": "This paper presents a robust Model Predictive Control (MPC) scheme that provides offset-free setpoint tracking for systems described by Neural Nonlinear AutoRegressive eXogenous (NNARX) models. The NNARX model learns the dynamics of the plant from input-output data, and during the training the Incremental Input-to-State Stability (${\\delta}$ISS) property is forced to guarantee stability. The trained NNARX model is then augmented with an explicit integral action on the output tracking error, which allows the control scheme to enjoy offset-free tracking ability. A tube-based MPC is finally designed, leveraging the unique structure of the model, to ensure robust stability and robust asymptotic zero error regulation for constant reference signals in the presence of model-plant mismatch or unknown disturbances. Numerical simulations on a water heating system show the effectiveness of the proposed control algorithm. ",
    "url": "https://arxiv.org/abs/2210.06801",
    "authors": [
      "Jing Xie",
      "Fabio Bonassi",
      "Marcello Farina",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.06807",
    "title": "Improving Out-of-Distribution Generalization by Adversarial Training  with Structured Priors",
    "abstract": "Deep models often fail to generalize well in test domains when the data distribution differs from that in the training domain. Among numerous approaches to address this Out-of-Distribution (OOD) generalization problem, there has been a growing surge of interest in exploiting Adversarial Training (AT) to improve OOD performance. Recent works have revealed that the robust model obtained by conducting sample-wise AT also retains transferability to biased test domains. In this paper, we empirically show that sample-wise AT has limited improvement on OOD performance. Specifically, we find that AT can only maintain performance at smaller scales of perturbation while Universal AT (UAT) is more robust to larger-scale perturbations. This provides us with clues that adversarial perturbations with universal (low dimensional) structures can enhance the robustness against large data distribution shifts that are common in OOD scenarios. Inspired by this, we propose two AT variants with low-rank structures to train OOD-robust models. Extensive experiments on DomainBed benchmark show that our proposed approaches outperform Empirical Risk Minimization (ERM) and sample-wise AT. Our code is available at https://github.com/NOVAglow646/NIPS22-MAT-and-LDAT-for-OOD. ",
    "url": "https://arxiv.org/abs/2210.06807",
    "authors": [
      "Qixun Wang",
      "Yifei Wang",
      "Hong Zhu",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06814",
    "title": "Accelerating the Evolutionary Algorithms by Gaussian Process Regression  with $\u03b5$-greedy acquisition function",
    "abstract": "In this paper, we propose a novel method to estimate the elite individual to accelerate the convergence of optimization. Inspired by the Bayesian Optimization Algorithm (BOA), the Gaussian Process Regression (GPR) is applied to approximate the fitness landscape of original problems based on every generation of optimization. And simple but efficient $\\epsilon$-greedy acquisition function is employed to find a promising solution in the surrogate model. Proximity Optimal Principle (POP) states that well-performed solutions have a similar structure, and there is a high probability of better solutions existing around the elite individual. Based on this hypothesis, in each generation of optimization, we replace the worst individual in Evolutionary Algorithms (EAs) with the elite individual to participate in the evolution process. To illustrate the scalability of our proposal, we combine our proposal with the Genetic Algorithm (GA), Differential Evolution (DE), and CMA-ES. Experimental results in CEC2013 benchmark functions show our proposal has a broad prospect to estimate the elite individual and accelerate the convergence of optimization. ",
    "url": "https://arxiv.org/abs/2210.06814",
    "authors": [
      "Rui Zhong",
      "Enzhi Zhang",
      "Masaharu Munetomo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.06820",
    "title": "Personalized Federated Hypernetworks for Privacy Preservation in  Multi-Task Reinforcement Learning",
    "abstract": "Multi-Agent Reinforcement Learning currently focuses on implementations where all data and training can be centralized to one machine. But what if local agents are split across multiple tasks, and need to keep data private between each? We develop the first application of Personalized Federated Hypernetworks (PFH) to Reinforcement Learning (RL). We then present a novel application of PFH to few-shot transfer, and demonstrate significant initial increases in learning. PFH has never been demonstrated beyond supervised learning benchmarks, so we apply PFH to an important domain: RL price-setting for energy demand response. We consider a general case across where agents are split across multiple microgrids, wherein energy consumption data must be kept private within each microgrid. Together, our work explores how the fields of personalized federated learning and RL can come together to make learning efficient across multiple tasks while keeping data secure. ",
    "url": "https://arxiv.org/abs/2210.06820",
    "authors": [
      "Doseok Jang",
      "Larry Yan",
      "Lucas Spangher",
      "Costas J. Spanos",
      "Selvaprabu Nadarajah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.06821",
    "title": "Conflict-free Charging and Real-time Control for an Electric Bus Network",
    "abstract": "The rapid adoption of electric buses by transit agencies around the world is leading to new challenges in the planning and operation of bus networks. In particular, the limited driving range of electric vehicles imposes operational constraints such as the need to charge buses during service. Research on this topic has mostly focused on the strategic and tactical planning aspects until now, and very little work has been done on the real-time operational aspect. To remedy this, we propose integrating the charging scheduling problem with a real-time speed control strategy in this paper. The control problem is formulated as a mixed-integer linear program and solved to optimality with the branch-and-bound method. Simulations are carried out by repeatedly solving the control problem in a receding horizon fashion over a full day of operation. The results show that the proposed controller manages to anticipate and avoid potential conflicts where the charging demand exceeds the charger capacity. This feature makes the controller achieve lower operational costs, both in terms of service regularity and energy consumption, compared to a standard first-come, first-served charging scheme. ",
    "url": "https://arxiv.org/abs/2210.06821",
    "authors": [
      "R\u00e9mi Lacombe",
      "Nikolce Murgovski",
      "S\u00e9bastien Gros",
      "Bal\u00e1zs Kulcs\u00e1r"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.06823",
    "title": "Scalable Neural Video Representations with Learnable Positional Features",
    "abstract": "Succinct representation of complex signals using coordinate-based neural representations (CNRs) has seen great progress, and several recent efforts focus on extending them for handling videos. Here, the main challenge is how to (a) alleviate a compute-inefficiency in training CNRs to (b) achieve high-quality video encoding while (c) maintaining the parameter-efficiency. To meet all requirements (a), (b), and (c) simultaneously, we propose neural video representations with learnable positional features (NVP), a novel CNR by introducing \"learnable positional features\" that effectively amortize a video as latent codes. Specifically, we first present a CNR architecture based on designing 2D latent keyframes to learn the common video contents across each spatio-temporal axis, which dramatically improves all of those three requirements. Then, we propose to utilize existing powerful image and video codecs as a compute-/memory-efficient compression procedure of latent codes. We demonstrate the superiority of NVP on the popular UVG benchmark; compared with prior arts, NVP not only trains 2 times faster (less than 5 minutes) but also exceeds their encoding quality as 34.07$\\rightarrow$34.57 (measured with the PSNR metric), even using $>$8 times fewer parameters. We also show intriguing properties of NVP, e.g., video inpainting, video frame interpolation, etc. ",
    "url": "https://arxiv.org/abs/2210.06823",
    "authors": [
      "Subin Kim",
      "Sihyun Yu",
      "Jaeho Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06845",
    "title": "The Fine-Grained Complexity of Graph Homomorphism Parameterized by  Clique-Width",
    "abstract": "The generic homomorphism problem, which asks whether an input graph $G$ admits a homomorphism into a fixed target graph $H$, has been widely studied in the literature. In this article, we provide a fine-grained complexity classification of the running time of the homomorphism problem with respect to the clique-width of $G$ (denoted $\\operatorname{cw}$) for virtually all choices of $H$ under the Strong Exponential Time Hypothesis. In particular, we identify a property of $H$ called the signature number $s(H)$ and show that for each $H$, the homomorphism problem can be solved in time $\\mathcal{O}^*(s(H)^{\\operatorname{cw}})$. Crucially, we then show that this algorithm can be used to obtain essentially tight upper bounds. Specifically, we provide a reduction that yields matching lower bounds for each $H$ that is either a projective core or a graph admitting a factorization with additional properties -- allowing us to cover all possible target graphs under long-standing conjectures. ",
    "url": "https://arxiv.org/abs/2210.06845",
    "authors": [
      "Robert Ganian",
      "Thekla Hamm",
      "Viktoriia Korchemna",
      "Karolina Okrasa",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2210.06846",
    "title": "An $\u03b1$-regret analysis of Adversarial Bilateral Trade",
    "abstract": "We study sequential bilateral trade where sellers and buyers valuations are completely arbitrary (i.e., determined by an adversary). Sellers and buyers are strategic agents with private valuations for the good and the goal is to design a mechanism that maximizes efficiency (or gain from trade) while being incentive compatible, individually rational and budget balanced. In this paper we consider gain from trade which is harder to approximate than social welfare. We consider a variety of feedback scenarios and distinguish the cases where the mechanism posts one price and when it can post different prices for buyer and seller. We show several surprising results about the separation between the different scenarios. In particular we show that (a) it is impossible to achieve sublinear $\\alpha$-regret for any $\\alpha<2$, (b) but with full feedback sublinear $2$-regret is achievable (c) with a single price and partial feedback one cannot get sublinear $\\alpha$ regret for any constant $\\alpha$ (d) nevertheless, posting two prices even with one-bit feedback achieves sublinear $2$-regret, and (e) there is a provable separation in the $2$-regret bounds between full and partial feedback. ",
    "url": "https://arxiv.org/abs/2210.06846",
    "authors": [
      "Yossi Azar",
      "Amos Fiat",
      "Federico Fusco"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06850",
    "title": "Sample-Then-Optimize Batch Neural Thompson Sampling",
    "abstract": "Bayesian optimization (BO), which uses a Gaussian process (GP) as a surrogate to model its objective function, is popular for black-box optimization. However, due to the limitations of GPs, BO underperforms in some problems such as those with categorical, high-dimensional or image inputs. To this end, recent works have used the highly expressive neural networks (NNs) as the surrogate model and derived theoretical guarantees using the theory of neural tangent kernel (NTK). However, these works suffer from the limitations of the requirement to invert an extremely large parameter matrix and the restriction to the sequential (rather than batch) setting. To overcome these limitations, we introduce two algorithms based on the Thompson sampling (TS) policy named Sample-Then-Optimize Batch Neural TS (STO-BNTS) and STO-BNTS-Linear. To choose an input query, we only need to train an NN (resp. a linear model) and then choose the query by maximizing the trained NN (resp. linear model), which is equivalently sampled from the GP posterior with the NTK as the kernel function. As a result, our algorithms sidestep the need to invert the large parameter matrix yet still preserve the validity of the TS policy. Next, we derive regret upper bounds for our algorithms with batch evaluations, and use insights from batch BO and NTK to show that they are asymptotically no-regret under certain conditions. Finally, we verify their empirical effectiveness using practical AutoML and reinforcement learning experiments. ",
    "url": "https://arxiv.org/abs/2210.06850",
    "authors": [
      "Zhongxiang Dai",
      "Yao Shu",
      "Bryan Kian Hsiang Low",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06853",
    "title": "NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor  Scene Reconstruction",
    "abstract": "We present a novel neural surface reconstruction method called NeuralRoom for reconstructing room-sized indoor scenes directly from a set of 2D images. Recently, implicit neural representations have become a promising way to reconstruct surfaces from multiview images due to their high-quality results and simplicity. However, implicit neural representations usually cannot reconstruct indoor scenes well because they suffer severe shape-radiance ambiguity. We assume that the indoor scene consists of texture-rich and flat texture-less regions. In texture-rich regions, the multiview stereo can obtain accurate results. In the flat area, normal estimation networks usually obtain a good normal estimation. Based on the above observations, we reduce the possible spatial variation range of implicit neural surfaces by reliable geometric priors to alleviate shape-radiance ambiguity. Specifically, we use multiview stereo results to limit the NeuralRoom optimization space and then use reliable geometric priors to guide NeuralRoom training. Then the NeuralRoom would produce a neural scene representation that can render an image consistent with the input training images. In addition, we propose a smoothing method called perturbation-residual restrictions to improve the accuracy and completeness of the flat region, which assumes that the sampling points in a local surface should have the same normal and similar distance to the observation center. Experiments on the ScanNet dataset show that our method can reconstruct the texture-less area of indoor scenes while maintaining the accuracy of detail. We also apply NeuralRoom to more advanced multiview reconstruction algorithms and significantly improve their reconstruction quality. ",
    "url": "https://arxiv.org/abs/2210.06853",
    "authors": [
      "Yusen Wang",
      "Zongcheng Li",
      "Yu Jiang",
      "Kaixuan Zhou",
      "Tuo Cao",
      "Yanping Fu",
      "Chunxia Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06856",
    "title": "Federated Learning for Tabular Data: Exploring Potential Risk to Privacy",
    "abstract": "Federated Learning (FL) has emerged as a potentially powerful privacy-preserving machine learning methodology, since it avoids exchanging data between participants, but instead exchanges model parameters. FL has traditionally been applied to image, voice and similar data, but recently it has started to draw attention from domains including financial services where the data is predominantly tabular. However, the work on tabular data has not yet considered potential attacks, in particular attacks using Generative Adversarial Networks (GANs), which have been successfully applied to FL for non-tabular data. This paper is the first to explore leakage of private data in Federated Learning systems that process tabular data. We design a Generative Adversarial Networks (GANs)-based attack model which can be deployed on a malicious client to reconstruct data and its properties from other participants. As a side-effect of considering tabular data, we are able to statistically assess the efficacy of the attack (without relying on human observation such as done for FL for images). We implement our attack model in a recently developed generic FL software framework for tabular data processing. The experimental results demonstrate the effectiveness of the proposed attack model, thus suggesting that further research is required to counter GAN-based privacy attacks. ",
    "url": "https://arxiv.org/abs/2210.06856",
    "authors": [
      "Han Wu",
      "Zilong Zhao",
      "Lydia Y. Chen",
      "Aad van Moorsel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.06871",
    "title": "Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face  Recognition",
    "abstract": "Deep learning models have shown their vulnerability when dealing with adversarial attacks. Existing attacks almost perform on low-level instances, such as pixels and super-pixels, and rarely exploit semantic clues. For face recognition attacks, existing methods typically generate the l_p-norm perturbations on pixels, however, resulting in low attack transferability and high vulnerability to denoising defense models. In this work, instead of performing perturbations on the low-level pixels, we propose to generate attacks through perturbing on the high-level semantics to improve attack transferability. Specifically, a unified flexible framework, Adversarial Attributes (Adv-Attribute), is designed to generate inconspicuous and transferable attacks on face recognition, which crafts the adversarial noise and adds it into different attributes based on the guidance of the difference in face recognition features from the target. Moreover, the importance-aware attribute selection and the multi-objective optimization strategy are introduced to further ensure the balance of stealthiness and attacking strength. Extensive experiments on the FFHQ and CelebA-HQ datasets show that the proposed Adv-Attribute method achieves the state-of-the-art attacking success rates while maintaining better visual effects against recent attack methods. ",
    "url": "https://arxiv.org/abs/2210.06871",
    "authors": [
      "Shuai Jia",
      "Bangjie Yin",
      "Taiping Yao",
      "Shouhong Ding",
      "Chunhua Shen",
      "Xiaokang Yang",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06873",
    "title": "Data augmentation on-the-fly and active learning in data stream  classification",
    "abstract": "There is an emerging need for predictive models to be trained on-the-fly, since in numerous machine learning applications data are arriving in an online fashion. A critical challenge encountered is that of limited availability of ground truth information (e.g., labels in classification tasks) as new data are observed one-by-one online, while another significant challenge is that of class imbalance. This work introduces the novel Augmented Queues method, which addresses the dual-problem by combining in a synergistic manner online active learning, data augmentation, and a multi-queue memory to maintain separate and balanced queues for each class. We perform an extensive experimental study using image and time-series augmentations, in which we examine the roles of the active learning budget, memory size, imbalance level, and neural network type. We demonstrate two major advantages of Augmented Queues. First, it does not reserve additional memory space as the generation of synthetic data occurs only at training times. Second, learning models have access to more labelled data without the need to increase the active learning budget and / or the original memory size. Learning on-the-fly poses major challenges which, typically, hinder the deployment of learning models. Augmented Queues significantly improves the performance in terms of learning quality and speed. Our code is made publicly available. ",
    "url": "https://arxiv.org/abs/2210.06873",
    "authors": [
      "Kleanthis Malialis",
      "Dimitris Papatheodoulou",
      "Stylianos Filippou",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06876",
    "title": "Learning Physical Dynamics with Subequivariant Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have become a prevailing tool for learning physical dynamics. However, they still encounter several challenges: 1) Physical laws abide by symmetry, which is a vital inductive bias accounting for model generalization and should be incorporated into the model design. Existing simulators either consider insufficient symmetry, or enforce excessive equivariance in practice when symmetry is partially broken by gravity. 2) Objects in the physical world possess diverse shapes, sizes, and properties, which should be appropriately processed by the model. To tackle these difficulties, we propose a novel backbone, Subequivariant Graph Neural Network, which 1) relaxes equivariance to subequivariance by considering external fields like gravity, where the universal approximation ability holds theoretically; 2) introduces a new subequivariant object-aware message passing for learning physical interactions between multiple objects of various shapes in the particle-based representation; 3) operates in a hierarchical fashion, allowing for modeling long-range and complex interactions. Our model achieves on average over 3% enhancement in contact prediction accuracy across 8 scenarios on Physion and 2X lower rollout MSE on RigidFall compared with state-of-the-art GNN simulators, while exhibiting strong generalization and data efficiency. ",
    "url": "https://arxiv.org/abs/2210.06876",
    "authors": [
      "Jiaqi Han",
      "Wenbing Huang",
      "Hengbo Ma",
      "Jiachen Li",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06888",
    "title": "AccelAT: A Framework for Accelerating the Adversarial Training of Deep  Neural Networks through Accuracy Gradient",
    "abstract": "Adversarial training is exploited to develop a robust Deep Neural Network (DNN) model against the malicious altered data. These attacks may have catastrophic effects on DNN models but are indistinguishable for a human being. For example, an external attack can modify an image adding noises invisible for a human eye, but a DNN model misclassified the image. A key objective for developing robust DNN models is to use a learning algorithm that is fast but can also give model that is robust against different types of adversarial attacks. Especially for adversarial training, enormously long training times are needed for obtaining high accuracy under many different types of adversarial samples generated using different adversarial attack techniques. This paper aims at accelerating the adversarial training to enable fast development of robust DNN models against adversarial attacks. The general method for improving the training performance is the hyperparameters fine-tuning, where the learning rate is one of the most crucial hyperparameters. By modifying its shape (the value over time) and value during the training, we can obtain a model robust to adversarial attacks faster than standard training. First, we conduct experiments on two different datasets (CIFAR10, CIFAR100), exploring various techniques. Then, this analysis is leveraged to develop a novel fast training methodology, AccelAT, which automatically adjusts the learning rate for different epochs based on the accuracy gradient. The experiments show comparable results with the related works, and in several experiments, the adversarial training of DNNs using our AccelAT framework is conducted up to 2 times faster than the existing techniques. Thus, our findings boost the speed of adversarial training in an era in which security and performance are fundamental optimization objectives in DNN-based applications. ",
    "url": "https://arxiv.org/abs/2210.06888",
    "authors": [
      "Farzad Nikfam",
      "Alberto Marchisio",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06909",
    "title": "HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial  Networks",
    "abstract": "The presence and density of specific types of immune cells are important to understand a patient's immune response to cancer. However, immunofluorescence staining required to identify T cell subtypes is expensive, timeconsuming, and rarely performed in clinical settings. We present a framework to virtually stain Hoechst images (which are cheap and widespread) with both CD3 and CD8 to identify T cell subtypes in clear cell renal cell carcinoma using generative adversarial networks. Our proposed method jointly learns both staining tasks, incentivising the network to incorporate mutually beneficial information from each task. We devise a novel metric to quantify the virtual staining quality, and use it to evaluate our method. ",
    "url": "https://arxiv.org/abs/2210.06909",
    "authors": [
      "Georg W\u00f6lflein",
      "In Hwa Um",
      "David J Harrison",
      "Ognjen Arandjelovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.06910",
    "title": "CNTN: Cyclic Noise-tolerant Network for Gait Recognition",
    "abstract": "Gait recognition aims to identify individuals by recognizing their walking patterns. However, an observation is made that most of the previous gait recognition methods degenerate significantly due to two memorization effects, namely appearance memorization and label noise memorization. To address the problem, for the first time noisy gait recognition is studied, and a cyclic noise-tolerant network (CNTN) is proposed with a cyclic training algorithm, which equips the two parallel networks with explicitly different abilities, namely one forgetting network and one memorizing network. The overall model will not memorize the pattern unless the two different networks both memorize it. Further, a more refined co-teaching constraint is imposed to help the model learn intrinsic patterns which are less influenced by memorization. Also, to address label noise memorization, an adaptive noise detection module is proposed to rule out the samples with high possibility to be noisy from updating the model. Experiments are conducted on the three most popular benchmarks and CNTN achieves state-of-the-art performances. We also reconstruct two noisy gait recognition datasets, and CNTN gains significant improvements (especially 6% improvements on CL setting). CNTN is also compatible with any off-the-shelf backbones and improves them consistently. ",
    "url": "https://arxiv.org/abs/2210.06910",
    "authors": [
      "Weichen Yu",
      "Hongyuan Yu",
      "Yan Huang",
      "Chunshui Cao",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06931",
    "title": "Masonry elements strengthened through Textile-Reinforced Mortar:  application of detailed level modelling with a free open-source  Finite-Element code",
    "abstract": "The paper concerns the modelling of masonry elements strengthened through Textile Reinforced Mortar (TRM), a near surface system made of fiber-based grids or textiles embedded in mortar layers. Recently, the author, focusing on the mechanical characterization of TRM composites, developed a detailed level modelling approach by using the free, open-source Finite-Element code OOFEM, for the simulation of experimental tests on TRM coupons (pull-out tests, tensile tests, shear bond tests and in-plane shear tests). The model was capable to account for the failure of single components (e.g. the fibers tensile failure, the mortar cracking and crushing), as well as of their interactions (the debonding of the fibers from the mortar and of the mortar from the masonry substrate). In this paper, the detailed-level modelling approach is applied to the simulation of TRM strengthened masonry elements subjected to diagonal compression, in-plane and out-of-plane bending tests, investigating on the typical failure modes of masonry. Non-linear static analyses are performed, with nonlinearities of materials and interfaces deduced from experimental evidences. The comparison with some experimental results and a parametric study allowed to evidence the reliability of the models and their sensitivity to the main components characteristics. ",
    "url": "https://arxiv.org/abs/2210.06931",
    "authors": [
      "Ingrid Boem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.06936",
    "title": "Multilingual Zero Resource Speech Recognition Base on Self-Supervise  Pre-Trained Acoustic Models",
    "abstract": "Labeled audio data is insufficient to build satisfying speech recognition systems for most of the languages in the world. There have been some zero-resource methods trying to perform phoneme or word-level speech recognition without labeled audio data of the target language, but the error rate of these methods is usually too high to be applied in real-world scenarios. Recently, the representation ability of self-supervise pre-trained models has been found to be extremely beneficial in zero-resource phoneme recognition. As far as we are concerned, this paper is the first attempt to extend the use of pre-trained models into word-level zero-resource speech recognition. This is done by fine-tuning the pre-trained models on IPA phoneme transcriptions and decoding with a language model trained on extra texts. Experiments on Wav2vec 2.0 and HuBERT models show that this method can achieve less than 20% word error rate on some languages, and the average error rate on 8 languages is 33.77%. ",
    "url": "https://arxiv.org/abs/2210.06936",
    "authors": [
      "Haoyu Wang",
      "Wei-Qiang Zhang",
      "Hongbin Suo",
      "Yulong Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.06943",
    "title": "Understand-Before-Talk (UBT): A Semantic Communication Approach to 6G  Networks",
    "abstract": "In Shannon theory, semantic aspects of communication were identified but considered irrelevant to the technical communication problems. Semantic communication (SC) techniques have recently attracted renewed research interests in (6G) wireless because they have the capability to support an efficient interpretation of the significance and meaning intended by a sender (or accomplishment of the goal) when dealing with multi-modal data such as videos, images, audio, text messages, and so on, which would be the case for various applications such as intelligent transportation systems where each autonomous vehicle needs to deal with real-time videos and data from a number of sensors including radars. A notable difficulty of existing SC frameworks lies in handling the discrete constraints imposed on the pursued semantic coding and its interaction with the independent knowledge base, which makes reliable semantic extraction extremely challenging. Therefore, we develop a new lightweight hashing-based semantic extraction approach to the SC framework, where our learning objective is to generate one-time signatures (hash codes) using supervised learning for low latency, secure and efficient management of the SC dynamics. We first evaluate the proposed semantic extraction framework over large image data sets, extend it with domain adaptive hashing and then demonstrate the effectiveness of \"semantics signature\" in bulk transmission and multi-modal data. ",
    "url": "https://arxiv.org/abs/2210.06943",
    "authors": [
      "Shiva Raj Pokhrel",
      "Jinho Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.06959",
    "title": "A Survey on Explainable Anomaly Detection",
    "abstract": "In the past two decades, most research on anomaly detection has focused on improving the accuracy of the detection, while largely ignoring the explainability of the corresponding methods and thus leaving the explanation of outcomes to practitioners. As anomaly detection algorithms are increasingly used in safety-critical domains, providing explanations for the high-stakes decisions made in those domains has become an ethical and regulatory requirement. Therefore, this work provides a comprehensive and structured survey on state-of-the-art explainable anomaly detection techniques. We propose a taxonomy based on the main aspects that characterize each explainable anomaly detection technique, aiming to help practitioners and researchers find the explainable anomaly detection method that best suits their needs. ",
    "url": "https://arxiv.org/abs/2210.06959",
    "authors": [
      "Zhong Li",
      "Yuxuan Zhu",
      "Matthijs van Leeuwen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06968",
    "title": "Behavioral graph fraud detection in E-commerce",
    "abstract": "In e-commerce industry, graph neural network methods are the new trends for transaction risk modeling.The power of graph algorithms lie in the capability to catch transaction linking network information, which is very hard to be captured by other algorithms.However, in most existing approaches, transaction or user connections are defined by hard link strategies on shared properties, such as same credit card, same device, same ip address, same shipping address, etc. Those types of strategies will result in sparse linkages by entities with strong identification characteristics (ie. device) and over-linkages by entities that could be widely shared (ie. ip address), making it more difficult to learn useful information from graph. To address aforementioned problems, we present a novel behavioral biometric based method to establish transaction linkings based on user behavioral similarities, then train an unsupervised GNN to extract embedding features for downstream fraud prediction tasks. To our knowledge, this is the first time similarity based soft link has been used in graph embedding applications. To speed up similarity calculation, we apply an in-house GPU based HDBSCAN clustering method to remove highly concentrated and isolated nodes before graph construction. Our experiments show that embedding features learned from similarity based behavioral graph have achieved significant performance increase to the baseline fraud detection model in various business scenarios. In new guest buyer transaction scenario, this segment is a challenge for traditional method, we can make precision increase from 0.82 to 0.86 at the same recall of 0.27, which means we can decrease false positive rate using this method. ",
    "url": "https://arxiv.org/abs/2210.06968",
    "authors": [
      "Hang Yin",
      "Zitao Zhang",
      "Zhurong Wang",
      "Yilmazcan Ozyurt",
      "Weiming Liang",
      "Wenyu Dong",
      "Yang Zhao",
      "Yinan Shan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06983",
    "title": "Denoising Masked AutoEncoders are Certifiable Robust Vision Learners",
    "abstract": "In this paper, we propose a new self-supervised method, which is called Denoising Masked AutoEncoders (DMAE), for learning certified robust classifiers of images. In DMAE, we corrupt each image by adding Gaussian noises to each pixel value and randomly masking several patches. A Transformer-based encoder-decoder model is then trained to reconstruct the original image from the corrupted one. In this learning paradigm, the encoder will learn to capture relevant semantics for the downstream tasks, which is also robust to Gaussian additive noises. We show that the pre-trained encoder can naturally be used as the base classifier in Gaussian smoothed models, where we can analytically compute the certified radius for any data point. Although the proposed method is simple, it yields significant performance improvement in downstream classification tasks. We show that the DMAE ViT-Base model, which just uses 1/10 parameters of the model developed in recent work arXiv:2206.10550, achieves competitive or better certified accuracy in various settings. The DMAE ViT-Large model significantly surpasses all previous results, establishing a new state-of-the-art on ImageNet dataset. We further demonstrate that the pre-trained model has good transferability to the CIFAR-10 dataset, suggesting its wide adaptability. Models and code are available at https://github.com/quanlin-wu/dmae. ",
    "url": "https://arxiv.org/abs/2210.06983",
    "authors": [
      "Quanlin Wu",
      "Hang Ye",
      "Yuntian Gu",
      "Huishuai Zhang",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06986",
    "title": "Tone prediction and orthographic conversion for Basaa",
    "abstract": "In this paper, we present a seq2seq approach for transliterating missionary Basaa orthographies into the official orthography. Our model uses pre-trained Basaa missionary and official orthography corpora using BERT. Since Basaa is a low-resource language, we have decided to use the mT5 model for our project. Before training our model, we pre-processed our corpora by eliminating one-to-one correspondences between spellings and unifying characters variably containing either one to two characters into single-character form. Our best mT5 model achieved a CER equal to 12.6747 and a WER equal to 40.1012. ",
    "url": "https://arxiv.org/abs/2210.06986",
    "authors": [
      "Ilya Nikitin",
      "Brian O'Connor",
      "Anastasia Safonova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06990",
    "title": "Exploring Segmentation Approaches for Neural Machine Translation of  Code-Switched Egyptian Arabic-English Text",
    "abstract": "Data sparsity is one of the main challenges posed by Code-switching (CS), which is further exacerbated in the case of morphologically rich languages. For the task of Machine Translation (MT), morphological segmentation has proven successful in alleviating data sparsity in monolingual contexts; however, it has not been investigated for CS settings. In this paper, we study the effectiveness of different segmentation approaches on MT performance, covering morphology-based and frequency-based segmentation techniques. We experiment on MT from code-switched Arabic-English to English. We provide detailed analysis, examining a variety of conditions, such as data size and sentences with different degrees in CS. Empirical results show that morphology-aware segmenters perform the best in segmentation tasks but under-perform in MT. Nevertheless, we find that the choice of the segmentation setup to use for MT is highly dependent on the data size. For extreme low-resource scenarios, a combination of frequency and morphology-based segmentations is shown to perform the best. For more resourced settings, such a combination does not bring significant improvements over the use of frequency-based segmentation. ",
    "url": "https://arxiv.org/abs/2210.06990",
    "authors": [
      "Marwa Gaser",
      "Manuel Mager",
      "Injy Hamed",
      "Nizar Habash",
      "Slim Abdennadher",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.06997",
    "title": "Two approaches to inpainting microstructure with deep convolutional  generative adversarial networks",
    "abstract": "Imaging is critical to the characterisation of materials. However, even with careful sample preparation and microscope calibration, imaging techniques are often prone to defects and unwanted artefacts. This is particularly problematic for applications where the micrograph is to be used for simulation or feature analysis, as defects are likely to lead to inaccurate results. Microstructural inpainting is a method to alleviate this problem by replacing occluded regions with synthetic microstructure with matching boundaries. In this paper we introduce two methods that use generative adversarial networks to generate contiguous inpainted regions of arbitrary shape and size by learning the microstructural distribution from the unoccluded data. We find that one benefits from high speed and simplicity, whilst the other gives smoother boundaries at the inpainting border. We also outline the development of a graphical user interface that allows users to utilise these machine learning methods in a 'no-code' environment. ",
    "url": "https://arxiv.org/abs/2210.06997",
    "authors": [
      "Isaac Squires",
      "Samuel J. Cooper",
      "Amir Dahari",
      "Steve Kench"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.06998",
    "title": "DE-FAKE: Detection and Attribution of Fake Images Generated by  Text-to-Image Diffusion Models",
    "abstract": "Diffusion models emerge to establish the new state of the art in the visual generation. In particular, text-to-image diffusion models that generate images based on caption descriptions have attracted increasing attention, impressed by their user controllability. Despite encouraging performance, they exaggerate concerns of fake image misuse and cast new pressures on fake image detection. In this work, we pioneer a systematic study of the authenticity of fake images generated by text-to-image diffusion models. In particular, we conduct comprehensive studies from two perspectives unique to the text-to-image model, namely, visual modality and linguistic modality. For visual modality, we propose universal detection that demonstrates fake images of these text-to-image diffusion models share common cues, which enable us to distinguish them apart from real images. We then propose source attribution that reveals the uniqueness of the fingerprints held by each diffusion model, which can be used to attribute each fake image to its model source. A variety of ablation and analysis studies further interpret the improvements from each of our proposed methods. For linguistic modality, we delve deeper to comprehensively analyze the impacts of text captions (called prompt analysis) on the image authenticity of text-to-image diffusion models, and reason the impacts to the detection and attribution performance of fake images. All findings contribute to the community's insight into the natural properties of text-to-image diffusion models, and we appeal to our community's consideration on the counterpart solutions, like ours, against the rapidly-evolving fake image generators. ",
    "url": "https://arxiv.org/abs/2210.06998",
    "authors": [
      "Zeyang Sha",
      "Zheng Li",
      "Ning Yu",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07002",
    "title": "Anonymizing Speech with Generative Adversarial Networks to Preserve  Speaker Privacy",
    "abstract": "In order to protect the privacy of speech data, speaker anonymization aims for hiding the identity of a speaker by changing the voice in speech recordings. This typically comes with a privacy-utility trade-off between protection of individuals and usability of the data for downstream applications. One of the challenges in this context is to create non-existent voices that sound as natural as possible. In this work, we propose to tackle this issue by generating speaker embeddings using a generative adversarial network with Wasserstein distance as cost function. By incorporating these artificial embeddings into a speech-to-text-to-speech pipeline, we outperform previous approaches in terms of privacy and utility. According to standard objective metrics and human evaluation, our approach generates intelligible and content-preserving yet privacy-protecting versions of the original recordings. ",
    "url": "https://arxiv.org/abs/2210.07002",
    "authors": [
      "Sarina Meyer",
      "Pascal Tilli",
      "Pavel Denisov",
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07011",
    "title": "Variational Graph Generator for Multi-View Graph Clustering",
    "abstract": "Multi-view graph clustering (MGC) methods are increasingly being studied due to the rising of multi-view data with graph structural information. The critical point of MGC is to better utilize the view-specific and view-common information in features and graphs of multiple views. However, existing works have an inherent limitation that they are unable to concurrently utilize the consensus graph information across multiple graphs and the view-specific feature information. To address this issue, we propose Variational Graph Generator for Multi-View Graph Clustering (VGMGC). Specifically, a novel variational graph generator is proposed to infer a reliable variational consensus graph based on a priori assumption over multiple graphs. Then a simple yet effective graph encoder in conjunction with the multi-view clustering objective is presented to learn the desired graph embeddings for clustering, which embeds the consensus and view-specific graphs together with features. Finally, theoretical results illustrate the rationality of VGMGC by analyzing the uncertainty of the inferred consensus graph with information bottleneck principle. Extensive experiments demonstrate the superior performance of our VGMGC over SOTAs. ",
    "url": "https://arxiv.org/abs/2210.07011",
    "authors": [
      "Jianpeng Chen",
      "Yawen Ling",
      "Jie Xu",
      "Yazhou Ren",
      "Shudong Huang",
      "Xiaorong Pu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07015",
    "title": "Augmentation for Learning From Demonstration with Environmental  Constraints",
    "abstract": "We introduce a Learning from Demonstration (LfD) approach for contact-rich manipulation tasks with articulated mechanisms. The extracted policy from a single human demonstration generalizes to different mechanisms of the same type and is robust against environmental variations. The key to achieving such generalization and robustness from a single human demonstration is to autonomously augment the initial demonstration to gather additional information through purposefully interacting with the environment. Our real-world experiments on complex mechanisms with multi-DOF demonstrate that our approach can reliably accomplish the task in a changing environment. Videos are available at the: https://sites.google.com/view/rbosalfdec/home ",
    "url": "https://arxiv.org/abs/2210.07015",
    "authors": [
      "Xing Li",
      "Manuel Baum",
      "Oliver Brock"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07032",
    "title": "Prompt-based Connective Prediction Method for Fine-grained Implicit  Discourse Relation Recognition",
    "abstract": "Due to the absence of connectives, implicit discourse relation recognition (IDRR) is still a challenging and crucial task in discourse analysis. Most of the current work adopted multitask learning to aid IDRR through explicit discourse relation recognition (EDRR) or utilized dependencies between discourse relation labels to constrain model predictions. But these methods still performed poorly on fine-grained IDRR and even utterly misidentified on most of the few-shot discourse relation classes. To address these problems, we propose a novel Prompt-based Connective Prediction (PCP) method for IDRR. Our method instructs large-scale pre-trained models to use knowledge relevant to discourse relation and utilizes the strong correlation between connectives and discourse relation to help the model recognize implicit discourse relations. Experimental results show that our method surpasses the current state-of-the-art model and achieves significant improvements on those fine-grained few-shot discourse relation. Moreover, our approach is able to be transferred to EDRR and obtain acceptable results. Our code is released in https://github.com/zh-i9/PCP-for-IDRR. ",
    "url": "https://arxiv.org/abs/2210.07032",
    "authors": [
      "Hao Zhou",
      "Man Lan",
      "Yuanbin Wu",
      "Yuefeng Chen",
      "Meirong Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07037",
    "title": "Self-Supervised Learning of Linear Precoders under Non-Linear PA  Distortion for Energy-Efficient Massive MIMO Systems",
    "abstract": "Massive multiple input multiple output (MIMO) systems are typically designed under the assumption of linear power amplifiers (PAs). However, PAs are typically most energy-efficient when operating close to their saturation point, where they cause non-linear distortion. Moreover, when using conventional precoders, this distortion coherently combines at the user locations, limiting performance. As such, when designing an energy-efficient massive MIMO system, this distortion has to be managed. In this work, we propose the use of a neural network (NN) to learn the mapping between the channel matrix and the precoding matrix, which maximizes the sum rate in the presence of this non-linear distortion. This is done for a third-order polynomial PA model for both the single and multi-user case. By learning this mapping a significant increase in energy efficiency is achieved as compared to conventional precoders and even as compared to perfect digital pre-distortion (DPD), in the saturation regime. ",
    "url": "https://arxiv.org/abs/2210.07037",
    "authors": [
      "Thomas Feys",
      "Xavier Mestre",
      "Fran\u00e7ois Rottenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.07049",
    "title": "Dimensionality of datasets in object detection networks",
    "abstract": "In recent years, convolutional neural networks (CNNs) are used in a large number of tasks in computer vision. One of them is object detection for autonomous driving. Although CNNs are used widely in many areas, what happens inside the network is still unexplained on many levels. Our goal is to determine the effect of Intrinsic dimension (i.e. minimum number of parameters required to represent data) in different layers on the accuracy of object detection network for augmented data sets. Our investigation determines that there is difference between the representation of normal and augmented data during feature extraction. ",
    "url": "https://arxiv.org/abs/2210.07049",
    "authors": [
      "Ajay Chawda",
      "Axel Vierling",
      "Karsten Berns"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07072",
    "title": "ConvTransSeg: A Multi-resolution Convolution-Transformer Network for  Medical Image Segmentation",
    "abstract": "Convolutional neural networks (CNNs) achieved the state-of-the-art performance in medical image segmentation due to their ability to extract highly complex feature representations. However, it is argued in recent studies that traditional CNNs lack the intelligence to capture long-term dependencies of different image regions. Following the success of applying Transformer models on natural language processing tasks, the medical image segmentation field has also witnessed growing interest in utilizing Transformers, due to their ability to capture long-range contextual information. However, unlike CNNs, Transformers lack the ability to learn local feature representations. Thus, to fully utilize the advantages of both CNNs and Transformers, we propose a hybrid encoder-decoder segmentation model (ConvTransSeg). It consists of a multi-layer CNN as the encoder for feature learning and the corresponding multi-level Transformer as the decoder for segmentation prediction. The encoder and decoder are interconnected in a multi-resolution manner. We compared our method with many other state-of-the-art hybrid CNN and Transformer segmentation models on binary and multiple class image segmentation tasks using several public medical image datasets, including skin lesion, polyp, cell and brain tissue. The experimental results show that our method achieves overall the best performance in terms of Dice coefficient and average symmetric surface distance measures with low model complexity and memory consumption. In contrast to most Transformer-based methods that we compared, our method does not require the use of pre-trained models to achieve similar or better performance. The code is freely available for research purposes on Github: (the link will be added upon acceptance). ",
    "url": "https://arxiv.org/abs/2210.07072",
    "authors": [
      "Zhendi Gong",
      "Andrew P. French",
      "Guoping Qiu",
      "Xin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07074",
    "title": "CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing",
    "abstract": "A bottleneck to developing Semantic Parsing (SP) models is the need for a large volume of human-labeled training data. Given the complexity and cost of human annotation for SP, labeled data is often scarce, particularly in multilingual settings. Large Language Models (LLMs) excel at SP given only a few examples, however LLMs are unsuitable for runtime systems which require low latency. In this work, we propose CLASP, a simple method to improve low-resource SP for moderate-sized models: we generate synthetic data from AlexaTM 20B to augment the training set for a model 40x smaller (500M parameters). We evaluate on two datasets in low-resource settings: English PIZZA, containing either 348 or 16 real examples, and mTOP cross-lingual zero-shot, where training data is available only in English, and the model must generalize to four new languages. On both datasets, we show significant improvements over strong baseline methods. ",
    "url": "https://arxiv.org/abs/2210.07074",
    "authors": [
      "Andy Rosenbaum",
      "Saleh Soltan",
      "Wael Hamza",
      "Amir Saffari",
      "Macro Damonte",
      "Isabel Groves"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07082",
    "title": "Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data",
    "abstract": "The implicit biases of gradient-based optimization algorithms are conjectured to be a major factor in the success of modern deep learning. In this work, we investigate the implicit bias of gradient flow and gradient descent in two-layer fully-connected neural networks with leaky ReLU activations when the training data are nearly-orthogonal, a common property of high-dimensional data. For gradient flow, we leverage recent work on the implicit bias for homogeneous neural networks to show that asymptotically, gradient flow produces a neural network with rank at most two. Moreover, this network is an $\\ell_2$-max-margin solution (in parameter space), and has a linear decision boundary that corresponds to an approximate-max-margin linear predictor. For gradient descent, provided the random initialization variance is small enough, we show that a single step of gradient descent suffices to drastically reduce the rank of the network, and that the rank remains small throughout training. We provide experiments which suggest that a small initialization scale is important for finding low-rank neural networks with gradient descent. ",
    "url": "https://arxiv.org/abs/2210.07082",
    "authors": [
      "Spencer Frei",
      "Gal Vardi",
      "Peter L. Bartlett",
      "Nathan Srebro",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.07098",
    "title": "Meta-learning Based Short-Term Passenger Flow Prediction for  Newly-Operated Urban Rail Transit Stations",
    "abstract": "Accurate short-term passenger flow prediction in urban rail transit stations has great benefits for reasonably allocating resources, easing congestion, and reducing operational risks. However, compared with data-rich stations, the passenger flow prediction in newly-operated stations is limited by passenger flow data volume, which would reduce the prediction accuracy and increase the difficulty for station management and operation. Hence, how accurately predicting passenger flow in newly-operated stations with limited data is an urgent problem to be solved. Existing passenger flow prediction approaches generally depend on sufficient data, which might be unsuitable for newly-operated stations. Therefore, we propose a meta-learning method named Meta Long Short-Term Memory Network (Meta-LSTM) to predict the passenger flow in newly-operated stations. The Meta-LSTM is to construct a framework that increases the generalization ability of long short-term memory network (LSTM) to various passenger flow characteristics by learning passenger flow characteristics from multiple data-rich stations and then applying the learned parameter to data-scarce stations by parameter initialization. The Meta-LSTM is applied to the subway network of Nanning, Hangzhou, and Beijing, China. The experiments on three real-world subway networks demonstrate the effectiveness of our proposed Meta-LSTM over several competitive baseline models. Results also show that our proposed Meta-LSTM has a good generalization ability to various passenger flow characteristics, which can provide a reference for passenger flow prediction in the stations with limited data. ",
    "url": "https://arxiv.org/abs/2210.07098",
    "authors": [
      "Kuo Han",
      "Jinlei Zhang",
      "Chunqi Zhu",
      "Lixing Yang",
      "Xiaoyu Huang",
      "Songsong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.07117",
    "title": "Graph-based Neural Modules to Inspect Attention-based Architectures: A  Position Paper",
    "abstract": "Encoder-decoder architectures are prominent building blocks of state-of-the-art solutions for tasks across multiple fields where deep learning (DL) or foundation models play a key role. Although there is a growing community working on the provision of interpretation for DL models as well as considerable work in the neuro-symbolic community seeking to integrate symbolic representations and DL, many open questions remain around the need for better tools for visualization of the inner workings of DL architectures. In particular, encoder-decoder models offer an exciting opportunity for visualization and editing by humans of the knowledge implicitly represented in model weights. In this work, we explore ways to create an abstraction for segments of the network as a two-way graph-based representation. Changes to this graph structure should be reflected directly in the underlying tensor representations. Such two-way graph representation enables new neuro-symbolic systems by leveraging the pattern recognition capabilities of the encoder-decoder along with symbolic reasoning carried out on the graphs. The approach is expected to produce new ways of interacting with DL models but also to improve performance as a result of the combination of learning and reasoning capabilities. ",
    "url": "https://arxiv.org/abs/2210.07117",
    "authors": [
      "Breno W. Carvalho",
      "Artur D'Avilla Garcez",
      "Luis C. Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07122",
    "title": "Deep Idempotent Network for Efficient Single Image Blind Deblurring",
    "abstract": "Single image blind deblurring is highly ill-posed as neither the latent sharp image nor the blur kernel is known. Even though considerable progress has been made, several major difficulties remain for blind deblurring, including the trade-off between high-performance deblurring and real-time processing. Besides, we observe that current single image blind deblurring networks cannot further improve or stabilize the performance but significantly degrades the performance when re-deblurring is repeatedly applied. This implies the limitation of these networks in modeling an ideal deblurring process. In this work, we make two contributions to tackle the above difficulties: (1) We introduce the idempotent constraint into the deblurring framework and present a deep idempotent network to achieve improved blind non-uniform deblurring performance with stable re-deblurring. (2) We propose a simple yet efficient deblurring network with lightweight encoder-decoder units and a recurrent structure that can deblur images in a progressive residual fashion. Extensive experiments on synthetic and realistic datasets prove the superiority of our proposed framework. Remarkably, our proposed network is nearly 6.5X smaller and 6.4X faster than the state-of-the-art while achieving comparable high performance. ",
    "url": "https://arxiv.org/abs/2210.07122",
    "authors": [
      "Yuxin Mao",
      "Zhexiong Wan",
      "Yuchao Dai",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07128",
    "title": "Language Models of Code are Few-Shot Commonsense Learners",
    "abstract": "We address the general task of structured commonsense reasoning: given a natural language input, the goal is to generate a graph such as an event -- or a reasoning-graph. To employ large language models (LMs) for this task, existing approaches ``serialize'' the output graph as a flat list of nodes and edges. Although feasible, these serialized graphs strongly deviate from the natural language corpora that LMs were pre-trained on, hindering LMs from generating them correctly. In this paper, we show that when we instead frame structured commonsense reasoning tasks as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than LMs of natural language, even when the downstream task does not involve source code at all. We demonstrate our approach across three diverse structured commonsense reasoning tasks. In all these natural language tasks, we show that using our approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task (e.g., T5) and other strong LMs such as GPT-3 in the few-shot setting. ",
    "url": "https://arxiv.org/abs/2210.07128",
    "authors": [
      "Aman Madaan",
      "Shuyan Zhou",
      "Uri Alon",
      "Yiming Yang",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07140",
    "title": "U-HRNet: Delving into Improving Semantic Representation of High  Resolution Network for Dense Prediction",
    "abstract": "High resolution and advanced semantic representation are both vital for dense prediction. Empirically, low-resolution feature maps often achieve stronger semantic representation, and high-resolution feature maps generally can better identify local features such as edges, but contains weaker semantic information. Existing state-of-the-art frameworks such as HRNet has kept low-resolution and high-resolution feature maps in parallel, and repeatedly exchange the information across different resolutions. However, we believe that the lowest-resolution feature map often contains the strongest semantic information, and it is necessary to go through more layers to merge with high-resolution feature maps, while for high-resolution feature maps, the computational cost of each convolutional layer is very large, and there is no need to go through so many layers. Therefore, we designed a U-shaped High-Resolution Network (U-HRNet), which adds more stages after the feature map with strongest semantic representation and relaxes the constraint in HRNet that all resolutions need to be calculated parallel for a newly added stage. More calculations are allocated to low-resolution feature maps, which significantly improves the overall semantic representation. U-HRNet is a substitute for the HRNet backbone and can achieve significant improvement on multiple semantic segmentation and depth prediction datasets, under the exactly same training and inference setting, with almost no increasing in the amount of calculation. Code is available at PaddleSeg: https://github.com/PaddlePaddle/PaddleSeg. ",
    "url": "https://arxiv.org/abs/2210.07140",
    "authors": [
      "Jian Wang",
      "Xiang Long",
      "Guowei Chen",
      "Zewu Wu",
      "Zeyu Chen",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07185",
    "title": "On the Utility of Self-supervised Models for Prosody-related Tasks",
    "abstract": "Self-Supervised Learning (SSL) from speech data has produced models that have achieved remarkable performance in many tasks, and that are known to implicitly represent many aspects of information latently present in speech signals. However, relatively little is known about the suitability of such models for prosody-related tasks or the extent to which they encode prosodic information. We present a new evaluation framework, SUPERB-prosody, consisting of three prosody-related downstream tasks and two pseudo tasks. We find that 13 of the 15 SSL models outperformed the baseline on all the prosody-related tasks. We also show good performance on two pseudo tasks: prosody reconstruction and future prosody prediction. We further analyze the layerwise contributions of the SSL models. Overall we conclude that SSL speech models are highly effective for prosody-related tasks. ",
    "url": "https://arxiv.org/abs/2210.07185",
    "authors": [
      "Guan-Ting Lin",
      "Chi-Luen Feng",
      "Wei-Ping Huang",
      "Yuan Tseng",
      "Tzu-Han Lin",
      "Chen-An Li",
      "Hung-yi Lee",
      "Nigel G. Ward"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07189",
    "title": "On Compressing Sequences for Self-Supervised Speech Models",
    "abstract": "Compressing self-supervised models has become increasingly necessary, as self-supervised models become larger. While previous approaches have primarily focused on compressing the model size, shortening sequences is also effective in reducing the computational cost. In this work, we study fixed-length and variable-length subsampling along the time axis in self-supervised learning. We explore how individual downstream tasks are sensitive to input frame rates. Subsampling while training self-supervised models not only improves the overall performance on downstream tasks under certain frame rates, but also brings significant speed-up in inference. Variable-length subsampling performs particularly well under low frame rates. In addition, if we have access to phonetic boundaries, we find no degradation in performance for an average frame rate as low as 10 Hz. ",
    "url": "https://arxiv.org/abs/2210.07189",
    "authors": [
      "Yen Meng",
      "Hsuan-Jui Chen",
      "Jiatong Shi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07199",
    "title": "Self-Supervised Geometric Correspondence for Category-Level 6D Object  Pose Estimation in the Wild",
    "abstract": "While 6D object pose estimation has wide applications across computer vision and robotics, it remains far from being solved due to the lack of annotations. The problem becomes even more challenging when moving to category-level 6D pose, which requires generalization to unseen instances. Current approaches are restricted by leveraging annotations from simulation or collected from humans. In this paper, we overcome this barrier by introducing a self-supervised learning approach trained directly on large-scale real-world object videos for category-level 6D pose estimation in the wild. Our framework reconstructs the canonical 3D shape of an object category and learns dense correspondences between input images and the canonical shape via surface embedding. For training, we propose novel geometrical cycle-consistency losses which construct cycles across 2D-3D spaces, across different instances and different time steps. The learned correspondence can be applied for 6D pose estimation and other downstream tasks such as keypoint transfer. Surprisingly, our method, without any human annotations or simulators, can achieve on-par or even better performance than previous supervised or semi-supervised methods on in-the-wild images. Our project page is: https://kywind.github.io/self-pose . ",
    "url": "https://arxiv.org/abs/2210.07199",
    "authors": [
      "Kaifeng Zhang",
      "Yang Fu",
      "Shubhankar Borse",
      "Hong Cai",
      "Fatih Porikli",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07213",
    "title": "FARE: Provably Fair Representation Learning",
    "abstract": "Fair representation learning (FRL) is a popular class of methods aiming to produce fair classifiers via data preprocessing. However, recent work has shown that prior methods achieve worse accuracy-fairness tradeoffs than originally suggested by their results. This dictates the need for FRL methods that provide provable upper bounds on unfairness of any downstream classifier, a challenge yet unsolved. In this work we address this challenge and propose Fairness with Restricted Encoders (FARE), the first FRL method with provable fairness guarantees. Our key insight is that restricting the representation space of the encoder enables us to derive suitable fairness guarantees, while allowing empirical accuracy-fairness tradeoffs comparable to prior work. FARE instantiates this idea with a tree-based encoder, a choice motivated by inherent advantages of decision trees when applied in our setting. Crucially, we develop and apply a practical statistical procedure that computes a high-confidence upper bound on the unfairness of any downstream classifier. In our experimental evaluation on several datasets and settings we demonstrate that FARE produces tight upper bounds, often comparable with empirical results of prior methods, which establishes the practical value of our approach. ",
    "url": "https://arxiv.org/abs/2210.07213",
    "authors": [
      "Nikola Jovanovi\u0107",
      "Mislav Balunovi\u0107",
      "Dimitar I. Dimitrov",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.07232",
    "title": "Decomposing User-APP Graph into Subgraphs for Effective APP and User  Embedding Learning",
    "abstract": "APP-installation information is helpful to describe the user's characteristics. The users with similar APPs installed might share several common interests and behave similarly in some scenarios. In this work, we learn a user embedding vector based on each user's APP-installation information. Since the user APP-installation embedding is learnable without dependency on the historical intra-APP behavioral data of the user, it complements the intra-APP embedding learned within each specific APP. Thus, they considerably help improve the effectiveness of the personalized advertising in each APP, and they are particularly beneficial for the cold start of the new users in the APP. In this paper, we formulate the APP-installation user embedding learning into a bipartite graph embedding problem. The main challenge in learning an effective APP-installation user embedding is the imbalanced data distribution. In this case, graph learning tends to be dominated by the popular APPs, which billions of users have installed. In other words, some niche/specialized APPs might have a marginal influence on graph learning. To effectively exploit the valuable information from the niche APPs, we decompose the APP-installation graph into a set of subgraphs. Each subgraph contains only one APP node and the users who install the APP. For each mini-batch, we only sample the users from the same subgraph in the training process. Thus, each APP can be involved in the training process in a more balanced manner. After integrating the learned APP-installation user embedding into our online personal advertising platform, we obtained a considerable boost in CTR, CVR, and revenue. ",
    "url": "https://arxiv.org/abs/2210.07232",
    "authors": [
      "Tan Yu",
      "Jun Zhi",
      "Yufei Zhang",
      "Jian Li",
      "Hongliang Fei",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.07233",
    "title": "Shape Preserving Facial Landmarks with Graph Attention Networks",
    "abstract": "Top-performing landmark estimation algorithms are based on exploiting the excellent ability of large convolutional neural networks (CNNs) to represent local appearance. However, it is well known that they can only learn weak spatial relationships. To address this problem, we propose a model based on the combination of a CNN with a cascade of Graph Attention Network regressors. To this end, we introduce an encoding that jointly represents the appearance and location of facial landmarks and an attention mechanism to weigh the information according to its reliability. This is combined with a multi-task approach to initialize the location of graph nodes and a coarse-to-fine landmark description scheme. Our experiments confirm that the proposed model learns a global representation of the structure of the face, achieving top performance in popular benchmarks on head pose and landmark estimation. The improvement provided by our model is most significant in situations involving large changes in the local appearance of landmarks. ",
    "url": "https://arxiv.org/abs/2210.07233",
    "authors": [
      "Andr\u00e9s Prados-Torreblanca",
      "Jos\u00e9 M. Buenaposada",
      "Luis Baumela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07236",
    "title": "Improved Bounds on Neural Complexity for Representing Piecewise Linear  Functions",
    "abstract": "A deep neural network using rectified linear units represents a continuous piecewise linear (CPWL) function and vice versa. Recent results in the literature estimated that the number of neurons needed to exactly represent any CPWL function grows exponentially with the number of pieces or exponentially in terms of the factorial of the number of distinct linear components. Moreover, such growth is amplified linearly with the input dimension. These existing results seem to indicate that the cost of representing a CPWL function is expensive. In this paper, we propose much tighter bounds and establish a polynomial time algorithm to find a network satisfying these bounds for any given CPWL function. We prove that the number of hidden neurons required to exactly represent any CPWL function is at most a quadratic function of the number of pieces. In contrast to all previous results, this upper bound is invariant to the input dimension. Besides the number of pieces, we also study the number of distinct linear components in CPWL functions. When such a number is also given, we prove that the quadratic complexity turns into bilinear, which implies a lower neural complexity because the number of distinct linear components is always not greater than the minimum number of pieces in a CPWL function. When the number of pieces is unknown, we prove that, in terms of the number of distinct linear components, the neural complexity of any CPWL function is at most polynomial growth for low-dimensional inputs and a factorial growth for the worst-case scenario, which are significantly better than existing results in the literature. ",
    "url": "https://arxiv.org/abs/2210.07236",
    "authors": [
      "Kuan-Lin Chen",
      "Harinath Garudadri",
      "Bhaskar D. Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.07239",
    "title": "Composite Learning for Robust and Effective Dense Predictions",
    "abstract": "Multi-task learning promises better model generalization on a target task by jointly optimizing it with an auxiliary task. However, the current practice requires additional labeling efforts for the auxiliary task, while not guaranteeing better model performance. In this paper, we find that jointly training a dense prediction (target) task with a self-supervised (auxiliary) task can consistently improve the performance of the target task, while eliminating the need for labeling auxiliary tasks. We refer to this joint training as Composite Learning (CompL). Experiments of CompL on monocular depth estimation, semantic segmentation, and boundary detection show consistent performance improvements in fully and partially labeled datasets. Further analysis on depth estimation reveals that joint training with self-supervision outperforms most labeled auxiliary tasks. We also find that CompL can improve model robustness when the models are evaluated in new domains. These results demonstrate the benefits of self-supervision as an auxiliary task, and establish the design of novel task-specific self-supervised methods as a new axis of investigation for future multi-task learning research. ",
    "url": "https://arxiv.org/abs/2210.07239",
    "authors": [
      "Menelaos Kanakis",
      "Thomas E. Huang",
      "David Bruggemann",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07241",
    "title": "Visual Reinforcement Learning with Self-Supervised 3D Representations",
    "abstract": "A prominent approach to visual Reinforcement Learning (RL) is to learn an internal state representation using self-supervised methods, which has the potential benefit of improved sample-efficiency and generalization through additional learning signal and inductive biases. However, while the real world is inherently 3D, prior efforts have largely been focused on leveraging 2D computer vision techniques as auxiliary self-supervision. In this work, we present a unified framework for self-supervised learning of 3D representations for motor control. Our proposed framework consists of two phases: a pretraining phase where a deep voxel-based 3D autoencoder is pretrained on a large object-centric dataset, and a finetuning phase where the representation is jointly finetuned together with RL on in-domain data. We empirically show that our method enjoys improved sample efficiency in simulated manipulation tasks compared to 2D representation learning methods. Additionally, our learned policies transfer zero-shot to a real robot setup with only approximate geometric correspondence, and successfully solve motor control tasks that involve grasping and lifting from a single, uncalibrated RGB camera. Code and videos are available at https://yanjieze.com/3d4rl/ . ",
    "url": "https://arxiv.org/abs/2210.07241",
    "authors": [
      "Yanjie Ze",
      "Nicklas Hansen",
      "Yinbo Chen",
      "Mohit Jain",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07242",
    "title": "OpenOOD: Benchmarking Generalized Out-of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection is vital to safety-critical machine learning applications and has thus been extensively studied, with a plethora of methods developed in the literature. However, the field currently lacks a unified, strictly formulated, and comprehensive benchmark, which often results in unfair comparisons and inconclusive results. From the problem setting perspective, OOD detection is closely related to neighboring fields including anomaly detection (AD), open set recognition (OSR), and model uncertainty, since methods developed for one domain are often applicable to each other. To help the community to improve the evaluation and advance, we build a unified, well-structured codebase called OpenOOD, which implements over 30 methods developed in relevant fields and provides a comprehensive benchmark under the recently proposed generalized OOD detection framework. With a comprehensive comparison of these methods, we are gratified that the field has progressed significantly over the past few years, where both preprocessing methods and the orthogonal post-hoc methods show strong potential. ",
    "url": "https://arxiv.org/abs/2210.07242",
    "authors": [
      "Jingkang Yang",
      "Pengyun Wang",
      "Dejian Zou",
      "Zitang Zhou",
      "Kunyuan Ding",
      "Wenxuan Peng",
      "Haoqi Wang",
      "Guangyao Chen",
      "Bo Li",
      "Yiyou Sun",
      "Xuefeng Du",
      "Kaiyang Zhou",
      "Wayne Zhang",
      "Dan Hendrycks",
      "Yixuan Li",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06478",
    "title": "Attention-Based Generative Neural Image Compression on Solar Dynamics  Observatory",
    "abstract": "NASA's Solar Dynamics Observatory (SDO) mission gathers 1.4 terabytes of data each day from its geosynchronous orbit in space. SDO data includes images of the Sun captured at different wavelengths, with the primary scientific goal of understanding the dynamic processes governing the Sun. Recently, end-to-end optimized artificial neural networks (ANN) have shown great potential in performing image compression. ANN-based compression schemes have outperformed conventional hand-engineered algorithms for lossy and lossless image compression. We have designed an ad-hoc ANN-based image compression scheme to reduce the amount of data needed to be stored and retrieved on space missions studying solar dynamics. In this work, we propose an attention module to make use of both local and non-local attention mechanisms in an adversarially trained neural image compression network. We have also demonstrated the superior perceptual quality of this neural image compressor. Our proposed algorithm for compressing images downloaded from the SDO spacecraft performs better in rate-distortion trade-off than the popular currently-in-use image compression codecs such as JPEG and JPEG2000. In addition we have shown that the proposed method outperforms state-of-the art lossy transform coding compression codec, i.e., BPG. ",
    "url": "https://arxiv.org/abs/2210.06478",
    "authors": [
      "Ali Zafari",
      "Atefeh Khoshkhahtinat",
      "Piyush M. Mehta",
      "Nasser M. Nasrabadi",
      "Barbara J. Thompson",
      "Daniel da Silva",
      "Michael S. F. Kirk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06564",
    "title": "Robust Neural Posterior Estimation and Statistical Model Criticism",
    "abstract": "Computer simulations have proven a valuable tool for understanding complex phenomena across the sciences. However, the utility of simulators for modelling and forecasting purposes is often restricted by low data quality, as well as practical limits to model fidelity. In order to circumvent these difficulties, we argue that modellers must treat simulators as idealistic representations of the true data generating process, and consequently should thoughtfully consider the risk of model misspecification. In this work we revisit neural posterior estimation (NPE), a class of algorithms that enable black-box parameter inference in simulation models, and consider the implication of a simulation-to-reality gap. While recent works have demonstrated reliable performance of these methods, the analyses have been performed using synthetic data generated by the simulator model itself, and have therefore only addressed the well-specified case. In this paper, we find that the presence of misspecification, in contrast, leads to unreliable inference when NPE is used naively. As a remedy we argue that principled scientific inquiry with simulators should incorporate a model criticism component, to facilitate interpretable identification of misspecification and a robust inference component, to fit 'wrong but useful' models. We propose robust neural posterior estimation (RNPE), an extension of NPE to simultaneously achieve both these aims, through explicitly modelling the discrepancies between simulations and the observed data. We assess the approach on a range of artificially misspecified examples, and find RNPE performs well across the tasks, whereas naively using NPE leads to misleading and erratic posteriors. ",
    "url": "https://arxiv.org/abs/2210.06564",
    "authors": [
      "Daniel Ward",
      "Patrick Cannon",
      "Mark Beaumont",
      "Matteo Fasiolo",
      "Sebastian M Schmon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.06672",
    "title": "Variance-Aware Estimation of Kernel Mean Embedding",
    "abstract": "An important feature of kernel mean embeddings (KME) is that the rate of convergence of the empirical KME to the true distribution KME can be bounded independently of the dimension of the space, properties of the distribution and smoothness features of the kernel. We show how to speed-up convergence by leveraging variance information in the RKHS. Furthermore, we show that even when such information is a priori unknown, we can efficiently estimate it from the data, recovering the desiderata of a distribution agnostic bound that enjoys acceleration in fortuitous settings. We illustrate our methods in the context of hypothesis testing and robust parametric estimation. ",
    "url": "https://arxiv.org/abs/2210.06672",
    "authors": [
      "Geoffrey Wolfer",
      "Pierre Alquier"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06786",
    "title": "Evaluating the Label Efficiency of Contrastive Self-Supervised Learning  for Multi-Resolution Satellite Imagery",
    "abstract": "The application of deep neural networks to remote sensing imagery is often constrained by the lack of ground-truth annotations. Adressing this issue requires models that generalize efficiently from limited amounts of labeled data, allowing us to tackle a wider range of Earth observation tasks. Another challenge in this domain is developing algorithms that operate at variable spatial resolutions, e.g., for the problem of classifying land use at different scales. Recently, self-supervised learning has been applied in the remote sensing domain to exploit readily-available unlabeled data, and was shown to reduce or even close the gap with supervised learning. In this paper, we study self-supervised visual representation learning through the lens of label efficiency, for the task of land use classification on multi-resolution/multi-scale satellite images. We benchmark two contrastive self-supervised methods adapted from Momentum Contrast (MoCo) and provide evidence that these methods can be perform effectively given little downstream supervision, where randomly initialized networks fail to generalize. Moreover, they outperform out-of-domain pretraining alternatives. We use the large-scale fMoW dataset to pretrain and evaluate the networks, and validate our observations with transfer to the RESISC45 dataset. ",
    "url": "https://arxiv.org/abs/2210.06786",
    "authors": [
      "Jules BOURCIER",
      "Gohar Dashyan",
      "Jocelyn Chanussot",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06818",
    "title": "Deepfake Detection System for the ADD Challenge Track 3.2 Based on Score  Fusion",
    "abstract": "This paper describes the deepfake audio detection system submitted to the Audio Deep Synthesis Detection (ADD) Challenge Track 3.2 and gives an analysis of score fusion. The proposed system is a score-level fusion of several light convolutional neural network (LCNN) based models. Various front-ends are used as input features, including low-frequency short-time Fourier transform and Constant Q transform. Due to the complex noise and rich synthesis algorithms, it is difficult to obtain the desired performance using the training set directly. Online data augmentation methods effectively improve the robustness of fake audio detection systems. In particular, the reasons for the poor improvement of score fusion are explored through visualization of the score distributions and comparison with score distribution on another dataset. The overfitting of the model to the training set leads to extreme values of the scores and low correlation of the score distributions, which makes score fusion difficult. Fusion with partially fake audio detection system improves system performance further. The submission on track 3.2 obtained the weighted equal error rate (WEER) of 11.04\\%, which is one of the best performing systems in the challenge. ",
    "url": "https://arxiv.org/abs/2210.06818",
    "authors": [
      "Yuxiang Zhang",
      "Jingze Lu",
      "Xingming Wang",
      "Zhuo Li",
      "Runqiu Xiao",
      "Wenchao Wang",
      "Ming Li",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.07145",
    "title": "Accurate, reliable and interpretable solubility prediction of druglike  molecules with attention pooling and Bayesian learning",
    "abstract": "In drug discovery, aqueous solubility is an important pharmacokinetic property which affects absorption and assay availability of drug. Thus, in silico prediction of solubility has been studied for its utility in virtual screening and lead optimization. Recently, machine learning (ML) methods using experimental data has been popular because physics-based methods like quantum mechanics and molecular dynamics are not suitable for high-throughput tasks due to its computational costs. However, ML method can exhibit over-fitting problem in a data-deficient condition, and this is the case for most chemical property datasets. In addition, ML methods are regarded as a black box function in that it is difficult to interpret contribution of hidden features to outputs, hindering analysis and modification of structure-activity relationship. To deal with mentioned issues, we developed Bayesian graph neural networks (GNNs) with the self-attention readout layer. Unlike most GNNs using self-attention in node updates, self-attention applied at readout layer enabled a model to improve prediction performance as well as to identify atom-wise importance, which can help lead optimization as exemplified for three FDA-approved drugs. Also, Bayesian inference enables us to separate more or less accurate results according to uncertainty in solubility prediction task We expect that our accurate, reliable and interpretable model can be used for more careful decision-making and various applications in the development of drugs. ",
    "url": "https://arxiv.org/abs/2210.07145",
    "authors": [
      "Seongok Ryu",
      "Sumin Lee"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1811.01394",
    "title": "A method to construct exponential families by representation theory",
    "abstract": " Title: A method to construct exponential families by representation theory ",
    "url": "https://arxiv.org/abs/1811.01394",
    "authors": [
      "Koichi Tojo",
      "Taro Yoshino"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2008.11921",
    "title": "Unsupervised MRI Super-Resolution Using Deep External Learning and  Guided Residual Dense Network with Multimodal Image Priors",
    "abstract": " Comments: 10 pages, 3 figures, Accepted by IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI) ",
    "url": "https://arxiv.org/abs/2008.11921",
    "authors": [
      "Yutaro Iwamoto",
      "Kyohei Takeda",
      "Yinhao Li",
      "Akihiko Shiino",
      "Yen-Wei Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2101.00694",
    "title": "Solving Cut-Problems in Quadratic Time for Graphs With Bounded Treewidth",
    "abstract": " Title: Solving Cut-Problems in Quadratic Time for Graphs With Bounded Treewidth ",
    "url": "https://arxiv.org/abs/2101.00694",
    "authors": [
      "Hauke Brinkop",
      "Klaus Jansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2101.07220",
    "title": "A Tensor-Based Formulation of Hetero-functional Graph Theory",
    "abstract": " Title: A Tensor-Based Formulation of Hetero-functional Graph Theory ",
    "url": "https://arxiv.org/abs/2101.07220",
    "authors": [
      "Amro M. Farid",
      "Dakota Thompson",
      "Wester Schoonenberg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.08928",
    "title": "RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent  Neural Networks",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.08928",
    "authors": [
      "Leo Kozachkov",
      "Michaela Ennis",
      "Jean-Jacques Slotine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.08970",
    "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks  Trained from Scratch",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.08970",
    "authors": [
      "Hossein Souri",
      "Liam Fowl",
      "Rama Chellappa",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.11180",
    "title": "Generalization Bounds with Minimal Dependency on Hypothesis Class via  Distributionally Robust Optimization",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2106.11180",
    "authors": [
      "Yibo Zeng",
      "Henry Lam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2108.07682",
    "title": "Fully Convolutional Networks for Panoptic Segmentation with Point-based  Supervision",
    "abstract": " Comments: Accepted to TPAMI. arXiv admin note: substantial text overlap with arXiv:2012.00720 ",
    "url": "https://arxiv.org/abs/2108.07682",
    "authors": [
      "Yanwei Li",
      "Hengshuang Zhao",
      "Xiaojuan Qi",
      "Yukang Chen",
      "Lu Qi",
      "Liwei Wang",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.08213",
    "title": "Reliable Neural Networks for Regression Uncertainty Estimation",
    "abstract": " Title: Reliable Neural Networks for Regression Uncertainty Estimation ",
    "url": "https://arxiv.org/abs/2109.08213",
    "authors": [
      "Tony Tohme",
      "Kevin Vanslette",
      "Kamal Youcef-Toumi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.03922",
    "title": "The Eigenlearning Framework: A Conservation Law Perspective on Kernel  Regression and Wide Neural Networks",
    "abstract": " Title: The Eigenlearning Framework: A Conservation Law Perspective on Kernel  Regression and Wide Neural Networks ",
    "url": "https://arxiv.org/abs/2110.03922",
    "authors": [
      "James B. Simon",
      "Madeline Dickens",
      "Dhruva Karkada",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08452",
    "title": "On minimizers and convolutional filters: a partial justification for the  effectiveness of CNNs in categorical sequence analysis",
    "abstract": " Comments: 13 pages, 2 figures, submitted to a conference ",
    "url": "https://arxiv.org/abs/2111.08452",
    "authors": [
      "Yun William Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2112.11628",
    "title": "SkipNode: On Alleviating Performance Degradation for Deep Graph  Convolutional Networks",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2112.11628",
    "authors": [
      "Weigang Lu",
      "Yibing Zhan",
      "Binbin Lin",
      "Ziyu Guan",
      "Liu Liu",
      "Baosheng Yu",
      "Wei Zhao",
      "Yaming Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14337",
    "title": "Closer Look at the Transferability of Adversarial Examples: How They  Fool Different Models Differently",
    "abstract": " Comments: 25 pages, 13 figures, Accepted at the IEEE Winter Conference on Applications of Computer Vision, WACV 2023 ",
    "url": "https://arxiv.org/abs/2112.14337",
    "authors": [
      "Futa Waseda",
      "Sosuke Nishikawa",
      "Trung-Nghia Le",
      "Huy H. Nguyen",
      "Isao Echizen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03169",
    "title": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks",
    "abstract": " Title: FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2201.03169",
    "authors": [
      "Zhenyuan Zhang",
      "Tao Shen",
      "Jie Zhang",
      "Tao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12380",
    "title": "Explaining Graph Neural Networks with Structure-Aware Cooperative Games",
    "abstract": " Title: Explaining Graph Neural Networks with Structure-Aware Cooperative Games ",
    "url": "https://arxiv.org/abs/2201.12380",
    "authors": [
      "Shichang Zhang",
      "Yozen Liu",
      "Neil Shah",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06727",
    "title": "STG-GAN: A spatiotemporal graph generative adversarial networks for  short-term passenger flow prediction in urban rail transit systems",
    "abstract": " Comments: 13 pages, 10 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2202.06727",
    "authors": [
      "Jinlei Zhang",
      "Hua Li",
      "Lixing Yang",
      "Guangyin Jin",
      "Jianguo Qi",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.10638",
    "title": "Invariance Learning in Deep Neural Networks with Differentiable Laplace  Approximations",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.10638",
    "authors": [
      "Alexander Immer",
      "Tycho F.A. van der Ouderaa",
      "Gunnar R\u00e4tsch",
      "Vincent Fortuin",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12921",
    "title": "Refining Self-Supervised Learning in Imaging: Beyond Linear Metric",
    "abstract": " Title: Refining Self-Supervised Learning in Imaging: Beyond Linear Metric ",
    "url": "https://arxiv.org/abs/2202.12921",
    "authors": [
      "Bo Jiang",
      "Hamid Krim",
      "Tianfu Wu",
      "Derya Cansever"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01707",
    "title": "Testing Stationarity and Change Point Detection in Reinforcement  Learning",
    "abstract": " Title: Testing Stationarity and Change Point Detection in Reinforcement  Learning ",
    "url": "https://arxiv.org/abs/2203.01707",
    "authors": [
      "Mengbing Li",
      "Chengchun Shi",
      "Zhenke Wu",
      "Piotr Fryzlewicz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.02018",
    "title": "Zero-shot Transfer Learning within a Heterogeneous Graph via Knowledge  Transfer Networks",
    "abstract": " Title: Zero-shot Transfer Learning within a Heterogeneous Graph via Knowledge  Transfer Networks ",
    "url": "https://arxiv.org/abs/2203.02018",
    "authors": [
      "Minji Yoon",
      "John Palowitch",
      "Dustin Zelle",
      "Ziniu Hu",
      "Ruslan Salakhutdinov",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03959",
    "title": "Enhancing Door-Status Detection for Autonomous Mobile Robots during  Environment-Specific Operational Use",
    "abstract": " Comments: Preprint submitted for revision at ICRA 2023 ",
    "url": "https://arxiv.org/abs/2203.03959",
    "authors": [
      "Michele Antonazzi",
      "Matteo Luperto",
      "Nicola Basilico",
      "N. Alberto Borghese"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.00618",
    "title": "ASR data augmentation using cross-lingual multi-speaker TTS and  cross-lingual voice conversion",
    "abstract": " Comments: The paper is under consideration at the 48th IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP) ",
    "url": "https://arxiv.org/abs/2204.00618",
    "authors": [
      "Edresson Casanova",
      "Christopher Shulby",
      "Alexander Korolev",
      "Arnaldo Candido Junior",
      "Anderson da Silva Soares",
      "Sandra Alu\u00edsio",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.00943",
    "title": "Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification",
    "abstract": " Title: Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification ",
    "url": "https://arxiv.org/abs/2204.00943",
    "authors": [
      "Rui-Yang Ju",
      "Jen-Shiun Chiang",
      "Jia-Hao Jian",
      "Ting-Yu Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01105",
    "title": "Better Lattice Quantizers Constructed from Complex Integers",
    "abstract": " Comments: To appear in IEEE Transactions on Communications. 10 pages ",
    "url": "https://arxiv.org/abs/2204.01105",
    "authors": [
      "Shanxiang Lyu",
      "Zheng Wang",
      "Cong Ling",
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.01499",
    "title": "FedRecAttack: Model Poisoning Attack to Federated Recommendation",
    "abstract": " Comments: This paper has been accepted by IEEE International Conference on Data Engineering 2022 (Second Research Round) ",
    "url": "https://arxiv.org/abs/2204.01499",
    "authors": [
      "Dazhong Rong",
      "Shuai Ye",
      "Ruoyan Zhao",
      "Hon Ning Yuen",
      "Jianhai Chen",
      "Qinming He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.06386",
    "title": "Efficient Deep Neural Network Accelerator Using Controlled Ferroelectric  Domain Dynamics",
    "abstract": " Title: Efficient Deep Neural Network Accelerator Using Controlled Ferroelectric  Domain Dynamics ",
    "url": "https://arxiv.org/abs/2204.06386",
    "authors": [
      "Sayani Majumdar"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2204.13806",
    "title": "Practical Considerations in Direct Detection Under Tukey Signalling",
    "abstract": " Comments: Submitted to J. Lightwave Techn. on March 3rd, 2022, revised on October 5th, 2022 ",
    "url": "https://arxiv.org/abs/2204.13806",
    "authors": [
      "Amir Tasbihi",
      "Frank R. Kschischang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2205.04892",
    "title": "GRU-TV: Time- and velocity-aware GRU for patient representation on  multivariate clinical time-series data",
    "abstract": " Title: GRU-TV: Time- and velocity-aware GRU for patient representation on  multivariate clinical time-series data ",
    "url": "https://arxiv.org/abs/2205.04892",
    "authors": [
      "Ningtao Liu",
      "Ruoxi Gao",
      "Jing Yuan",
      "Calire Park",
      "Shuwei Xing",
      "Shuiping Gou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.05040",
    "title": "A Communication-Efficient Distributed Gradient Clipping Algorithm for  Training Deep Neural Networks",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.05040",
    "authors": [
      "Mingrui Liu",
      "Zhenxun Zhuang",
      "Yunwei Lei",
      "Chunyang Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09459",
    "title": "Neural Network Architecture Beyond Width and Depth",
    "abstract": " Title: Neural Network Architecture Beyond Width and Depth ",
    "url": "https://arxiv.org/abs/2205.09459",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.09921",
    "title": "KERPLE: Kernelized Relative Positional Embedding for Length  Extrapolation",
    "abstract": " Comments: Accepted at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022). The first two authors contributed equally to this work ",
    "url": "https://arxiv.org/abs/2205.09921",
    "authors": [
      "Ta-Chung Chi",
      "Ting-Han Fan",
      "Peter J. Ramadge",
      "Alexander I. Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11490",
    "title": "Local Byte Fusion for Neural Machine Translation",
    "abstract": " Title: Local Byte Fusion for Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2205.11490",
    "authors": [
      "Makesh Narsimhan Sreedhar",
      "Xiangpeng Wan",
      "Yu Cheng",
      "Junjie Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12006",
    "title": "Neur2SP: Neural Two-Stage Stochastic Programming",
    "abstract": " Comments: To appear in the proceedings of NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.12006",
    "authors": [
      "Justin Dumouchelle",
      "Rahul Patel",
      "Elias B. Khalil",
      "Merve Bodur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12586",
    "title": "Perturbation Augmentation for Fairer NLP",
    "abstract": " Title: Perturbation Augmentation for Fairer NLP ",
    "url": "https://arxiv.org/abs/2205.12586",
    "authors": [
      "Rebecca Qian",
      "Candace Ross",
      "Jude Fernandes",
      "Eric Smith",
      "Douwe Kiela",
      "Adina Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13371",
    "title": "A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical  Representation Learning",
    "abstract": " Comments: 23 pages, Thirty-sixth Conference on Neural Information Processing Systems, 2022 ",
    "url": "https://arxiv.org/abs/2205.13371",
    "authors": [
      "Seunghyuk Cho",
      "Juyong Lee",
      "Jaesik Park",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14819",
    "title": "Universality of Group Convolutional Neural Networks Based on Ridgelet  Analysis on Groups",
    "abstract": " Comments: replaced with the published version (NeurIPS2022) ",
    "url": "https://arxiv.org/abs/2205.14819",
    "authors": [
      "Sho Sonoda",
      "Isao Ishikawa",
      "Masahiro Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ]
  },
  {
    "id": "arXiv:2205.15156",
    "title": "Towards Efficient 3D Object Detection with Knowledge Distillation",
    "abstract": " Title: Towards Efficient 3D Object Detection with Knowledge Distillation ",
    "url": "https://arxiv.org/abs/2205.15156",
    "authors": [
      "Jihan Yang",
      "Shaoshuai Shi",
      "Runyu Ding",
      "Zhe Wang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00241",
    "title": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "abstract": " Title: Asymptotic Properties for Bayesian Neural Network in Besov Space ",
    "url": "https://arxiv.org/abs/2206.00241",
    "authors": [
      "Kyeongwon Lee",
      "Jaeyong Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2206.00481",
    "title": "Where are my Neighbors? Exploiting Patches Relations in Self-Supervised  Vision Transformer",
    "abstract": " Comments: Accepted to BMVC 2022 ",
    "url": "https://arxiv.org/abs/2206.00481",
    "authors": [
      "Guglielmo Camporese",
      "Elena Izzo",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00630",
    "title": "Unifying Voxel-based Representation with Transformer for 3D Object  Detection",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.00630",
    "authors": [
      "Yanwei Li",
      "Yilun Chen",
      "Xiaojuan Qi",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.04754",
    "title": "AFIA: ATPG-Guided Fault Injection Attack on Secure Logic Locking",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2007.10512 ",
    "url": "https://arxiv.org/abs/2206.04754",
    "authors": [
      "Yadi Zhong",
      "Ayush Jain",
      "M. Tanjidur Rahman",
      "Navid Asadizanjani",
      "Jiafeng Xie",
      "Ujjwal Guin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.05266",
    "title": "Does Self-supervised Learning Really Improve Reinforcement Learning from  Pixels?",
    "abstract": " Comments: To appear at NeurIPS 2022. Code for ELo-SACv3 is at this https URL and code for ELo-Rainbow is at this https URL ",
    "url": "https://arxiv.org/abs/2206.05266",
    "authors": [
      "Xiang Li",
      "Jinghuan Shang",
      "Srijan Das",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.06126",
    "title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform",
    "abstract": " Comments: 15 pages, 13 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2206.06126",
    "authors": [
      "Gaetan Frusque",
      "Olga Fink"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.12139",
    "title": "HARU: Haptic Augmented Reality-Assisted User-Centric Industrial Network  Planning",
    "abstract": " Title: HARU: Haptic Augmented Reality-Assisted User-Centric Industrial Network  Planning ",
    "url": "https://arxiv.org/abs/2206.12139",
    "authors": [
      "Qi Liao",
      "Tianlun Hu",
      "Nikolaj Marchenko",
      "Peter Kulics",
      "Lutz Ewe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03482",
    "title": "Bridging the Gap between Object and Image-level Representations for  Open-Vocabulary Detection",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.03482",
    "authors": [
      "Hanoona Rasheed",
      "Muhammad Maaz",
      "Muhammad Uzair Khattak",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04892",
    "title": "Adversarial Style Augmentation for Domain Generalized Urban-Scene  Segmentation",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.04892",
    "authors": [
      "Zhun Zhong",
      "Yuyang Zhao",
      "Gim Hee Lee",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.14676",
    "title": "Global-Local Self-Distillation for Visual Representation Learning",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2207.14676",
    "authors": [
      "Tim Lebailly",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01582",
    "title": "ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries",
    "abstract": " Comments: Project page is at this https URL ",
    "url": "https://arxiv.org/abs/2208.01582",
    "authors": [
      "Junru Gu",
      "Chenxu Hu",
      "Tianyuan Zhang",
      "Xuanyao Chen",
      "Yilun Wang",
      "Yue Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.05408",
    "title": "Pikachu: Securing PoS Blockchains from Long-Range Attacks by  Checkpointing into Bitcoin PoW using Taproot",
    "abstract": " Comments: To appear at ConsensusDay 22 (ACM CCS 2022 Workshop) ",
    "url": "https://arxiv.org/abs/2208.05408",
    "authors": [
      "Sarah Azouvi",
      "Marko Vukoli\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.07282",
    "title": "Differentiable WORLD Synthesizer-based Neural Vocoder With Application  To End-To-End Audio Style Transfer",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2208.07282",
    "authors": [
      "Shahan Nercessian"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2209.00653",
    "title": "Effective Class-Imbalance learning based on SMOTE and Convolutional  Neural Networks",
    "abstract": " Title: Effective Class-Imbalance learning based on SMOTE and Convolutional  Neural Networks ",
    "url": "https://arxiv.org/abs/2209.00653",
    "authors": [
      "Javad Hassannataj Joloudari",
      "Abdolreza Marefat",
      "Mohammad Ali Nematollahi",
      "Solomon Sunday Oyelere",
      "Sadiq Hussain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.01814",
    "title": "RLIP: Relational Language-Image Pre-training for Human-Object  Interaction Detection",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.01814",
    "authors": [
      "Hangjie Yuan",
      "Jianwen Jiang",
      "Samuel Albanie",
      "Tao Feng",
      "Ziyuan Huang",
      "Dong Ni",
      "Mingqian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03299",
    "title": "Geometric multimodal representation learning",
    "abstract": " Comments: 28 pages, 5 figures, 2 boxes ",
    "url": "https://arxiv.org/abs/2209.03299",
    "authors": [
      "Yasha Ektefaie",
      "George Dasoulas",
      "Ayush Noori",
      "Maha Farhat",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.04692",
    "title": "Distributed Learning over a Wireless Network with Non-coherent Majority  Vote Computation",
    "abstract": " Comments: 15 pages, 9 figures. arXiv admin note: text overlap with arXiv:2111.01850 ",
    "url": "https://arxiv.org/abs/2209.04692",
    "authors": [
      "Alphan Sahin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.07519",
    "title": "Multi-Modal Beam Prediction Challenge 2022: Towards Generalization",
    "abstract": " Comments: The dataset is available on the ML competition page: this https URL ",
    "url": "https://arxiv.org/abs/2209.07519",
    "authors": [
      "Gouranga Charan",
      "Umut Demirhan",
      "Jo\u00e3o Morais",
      "Arash Behboodi",
      "Hamed Pezeshki",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.10299",
    "title": "DPCN: Towards Deadline-aware Payment Channel Networks",
    "abstract": " Title: DPCN: Towards Deadline-aware Payment Channel Networks ",
    "url": "https://arxiv.org/abs/2209.10299",
    "authors": [
      "Wenhui Wang",
      "Ke Mu",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.14842",
    "title": "Classification of Vocal Bursts for ACII 2022 A-VB-Type Competition using  Convolutional Neural Networks and Deep Acoustic Embeddings",
    "abstract": " Comments: Report for our submission to the ACII 2022 Affective Vocal Bursts (A-VB) Competition ",
    "url": "https://arxiv.org/abs/2209.14842",
    "authors": [
      "Muhammad Shehram Shah Syed",
      "Zafi Sherhan Syed",
      "Abbas Syed"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.15236",
    "title": "Language-Family Adapters for Multilingual Neural Machine Translation",
    "abstract": " Comments: Minor updates ",
    "url": "https://arxiv.org/abs/2209.15236",
    "authors": [
      "Alexandra Chronopoulou",
      "Dario Stojanovski",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.01437",
    "title": "Shielding Federated Learning: Mitigating Byzantine Attacks with Less  Constraints",
    "abstract": " Comments: This paper has been accepted by the 18th International Conference on Mobility, Sensing and Networking (MSN 2022) ",
    "url": "https://arxiv.org/abs/2210.01437",
    "authors": [
      "Minghui Li",
      "Wei Wan",
      "Jianrong Lu",
      "Shengshan Hu",
      "Junyu Shi",
      "Leo Yu Zhang",
      "Man Zhou",
      "Yifeng Zheng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.02271",
    "title": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "abstract": " Title: Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains ",
    "url": "https://arxiv.org/abs/2210.02271",
    "authors": [
      "Buddhika Nettasinghe",
      "Samrat Chatterjee",
      "Ramakrishna Tipireddy",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.03919",
    "title": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "abstract": " Title: CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation ",
    "url": "https://arxiv.org/abs/2210.03919",
    "authors": [
      "Chenliang Zhou",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04574",
    "title": "ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object  Detection",
    "abstract": " Title: ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object  Detection ",
    "url": "https://arxiv.org/abs/2210.04574",
    "authors": [
      "Rebbapragada V C Sairam",
      "Monish Keswani",
      "Uttaran Sinha",
      "Nishit Shah",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04797",
    "title": "DeepVol: Volatility Forecasting from High-Frequency Data with Dilated  Causal Convolutions",
    "abstract": " Comments: typos corrected ",
    "url": "https://arxiv.org/abs/2210.04797",
    "authors": [
      "Fernando Moreno-Pino",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2210.04958",
    "title": "Mining Causality from Continuous-time Dynamics Models: An Application to  Tsunami Forecasting",
    "abstract": " Title: Mining Causality from Continuous-time Dynamics Models: An Application to  Tsunami Forecasting ",
    "url": "https://arxiv.org/abs/2210.04958",
    "authors": [
      "Fan Wu",
      "Sanghyun Hong",
      "Donsub Rim",
      "Noseong Park",
      "Kookjin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.05769",
    "title": "Vote'n'Rank: Revision of Benchmarking with Social Choice Theory",
    "abstract": " Title: Vote'n'Rank: Revision of Benchmarking with Social Choice Theory ",
    "url": "https://arxiv.org/abs/2210.05769",
    "authors": [
      "Mark Rofin",
      "Vladislav Mikhailov",
      "Mikhail Florinskiy",
      "Andrey Kravchenko",
      "Elena Tutubalina",
      "Tatiana Shavrina",
      "Daniel Karabekyan",
      "Ekaterina Artemova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.05992",
    "title": "Fast Convergence to Unanimity in Dense Erd\u0151s-R\u00e9nyi Graphs",
    "abstract": " Comments: The introduction has been edited. arXiv admin note: text overlap with arXiv:2104.04996 ",
    "url": "https://arxiv.org/abs/2210.05992",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.06418",
    "title": "Relational Graph Convolutional Neural Networks for Multihop Reasoning: A  Comparative Study",
    "abstract": " Comments: 8 pages + 2 pages references, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.06418",
    "authors": [
      "Ieva Stali\u016bnait\u0117",
      "Philip John Gorinski",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06464",
    "title": "Predictive Querying for Autoregressive Neural Sequence Models",
    "abstract": " Comments: Presented at the Conference on Neural Information Processing Systems (NeurIPs 2022) ",
    "url": "https://arxiv.org/abs/2210.06464",
    "authors": [
      "Alex Boyd",
      "Sam Showalter",
      "Stephan Mandt",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]