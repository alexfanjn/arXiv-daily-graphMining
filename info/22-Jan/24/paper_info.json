[
  {
    "id": "arXiv:2201.08413",
    "title": "Unicorn: Reasoning about Configurable System Performance through the  lens of Causality",
    "abstract": "Modern computer systems are highly configurable, with the variability space sometimes larger than the number of atoms in the universe. Understanding and reasoning about the performance behavior of highly configurable systems, due to a vast variability space, is challenging. State-of-the-art methods for performance modeling and analyses rely on predictive machine learning models, therefore, they become (i) unreliable in unseen environments (e.g., different hardware, workloads), and (ii) produce incorrect explanations. To this end, we propose a new method, called Unicorn, which (a) captures intricate interactions between configuration options across the software-hardware stack and (b) describes how such interactions impact performance variations via causal inference. We evaluated Unicorn on six highly configurable systems, including three on-device machine learning systems, a video encoder, a database management system, and a data analytics pipeline. The experimental results indicate that Unicorn outperforms state-of-the-art performance optimization and debugging methods. Furthermore, unlike the existing methods, the learned causal performance models reliably predict performance for new environments. ",
    "url": "https://arxiv.org/abs/2201.08413",
    "authors": [
      "Md Shahriar Iqbal",
      "Rahul Krishna",
      "Mohammad Ali Javidian",
      "Baishakhi Ray",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2201.08441",
    "title": "VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase  for Python",
    "abstract": "Context: Identifying potential vulnerable code is important to improve the security of our software systems. However, the manual detection of software vulnerabilities requires expert knowledge and is time-consuming, and must be supported by automated techniques. Objective: Such automated vulnerability detection techniques should achieve a high accuracy, point developers directly to the vulnerable code fragments, scale to real-world software, generalize across the boundaries of a specific software project, and require no or only moderate setup or configuration effort. Method: In this article, we present VUDENC (Vulnerability Detection with Deep Learning on a Natural Codebase), a deep learning-based vulnerability detection tool that automatically learns features of vulnerable code from a large and real-world Python codebase. VUDENC applies a word2vec model to identify semantically similar code tokens and to provide a vector representation. A network of long-short-term memory cells (LSTM) is then used to classify vulnerable code token sequences at a fine-grained level, highlight the specific areas in the source code that are likely to contain vulnerabilities, and provide confidence levels for its predictions. Results: To evaluate VUDENC, we used 1,009 vulnerability-fixing commits from different GitHub repositories that contain seven different types of vulnerabilities (SQL injection, XSS, Command injection, XSRF, Remote code execution, Path disclosure, Open redirect) for training. In the experimental evaluation, VUDENC achieves a recall of 78%-87%, a precision of 82%-96%, and an F1 score of 80%-90%. VUDENC's code, the datasets for the vulnerabilities, and the Python corpus for the word2vec model are available for reproduction. Conclusions: Our experimental results suggest... ",
    "url": "https://arxiv.org/abs/2201.08441",
    "authors": [
      "Laura Wartschinski",
      "Yannic Noller",
      "Thomas Vogel",
      "Timo Kehrer",
      "Lars Grunske"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.08442",
    "title": "Neural Network Quantization with AI Model Efficiency Toolkit (AIMET)",
    "abstract": "While neural networks have advanced the frontiers in many machine learning applications, they often come at a high computational cost. Reducing the power and latency of neural network inference is vital to integrating modern networks into edge devices with strict power and compute requirements. Neural network quantization is one of the most effective ways of achieving these savings, but the additional noise it induces can lead to accuracy degradation. In this white paper, we present an overview of neural network quantization using AI Model Efficiency Toolkit (AIMET). AIMET is a library of state-of-the-art quantization and compression algorithms designed to ease the effort required for model optimization and thus drive the broader AI ecosystem towards low latency and energy-efficient inference. AIMET provides users with the ability to simulate as well as optimize PyTorch and TensorFlow models. Specifically for quantization, AIMET includes various post-training quantization (PTQ, cf. chapter 4) and quantization-aware training (QAT, cf. chapter 5) techniques that guarantee near floating-point accuracy for 8-bit fixed-point inference. We provide a practical guide to quantization via AIMET by covering PTQ and QAT workflows, code examples and practical tips that enable users to efficiently and effectively quantize models using AIMET and reap the benefits of low-bit integer inference. ",
    "url": "https://arxiv.org/abs/2201.08442",
    "authors": [
      "Sangeetha Siddegowda",
      "Marios Fournarakis",
      "Markus Nagel",
      "Tijmen Blankevoort",
      "Chirag Patel",
      "Abhijit Khobare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.08452",
    "title": "npm-filter: Automating the mining of dynamic information from npm  packages",
    "abstract": "The static properties of code repositories, e.g., lines of code, dependents, dependencies, etc. can be readily scraped from code hosting platforms such as GitHub, and from package management systems such as npm for JavaScript; Although no less important, information related to the dynamic properties of programs, e.g., number of tests in a test suite that pass or fail is less readily available. This dynamic information could be immensely useful to researchers conducting corpus analyses, as it would give them the ability to differentiate projects based on properties of the projects that can only be observed by running them. In this paper, we present npm-filter, an automated tool that can download, install, build, test, and run custom user scripts over the source code of JavaScript projects available on npm, the most popular JavaScript package manager. We outline this tool, describe its implementation, and show that npm-filter has already been useful in developing evaluation suites for multiple JavaScript tools. ",
    "url": "https://arxiv.org/abs/2201.08452",
    "authors": [
      "Ellen Arteca",
      "Alexi Turcotte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.08455",
    "title": "Hybrid Graph Models for Logic Optimization via Spatio-Temporal  Information",
    "abstract": "Despite the stride made by machine learning (ML) based performance modeling, two major concerns that may impede production-ready ML applications in EDA are stringent accuracy requirements and generalization capability. To this end, we propose hybrid graph neural network (GNN) based approaches towards highly accurate quality-of-result (QoR) estimations with great generalization capability, specifically targeting logic synthesis optimization. The key idea is to simultaneously leverage spatio-temporal information from hardware designs and logic synthesis flows to forecast performance (i.e., delay/area) of various synthesis flows on different designs. The structural characteristics inside hardware designs are distilled and represented by GNNs; the temporal knowledge (i.e., relative ordering of logic transformations) in synthesis flows can be imposed on hardware designs by combining a virtually added supernode or a sequence processing model with conventional GNN models. Evaluation on 3.3 million data points shows that the testing mean absolute percentage error (MAPE) on designs seen and unseen during training are no more than 1.2% and 3.1%, respectively, which are 7-15X lower than existing studies. ",
    "url": "https://arxiv.org/abs/2201.08455",
    "authors": [
      "Nan Wu",
      "Jiwon Lee",
      "Yuan Xie",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2201.08459",
    "title": "Federated Learning with Heterogeneous Architectures using Graph  HyperNetworks",
    "abstract": "Standard Federated Learning (FL) techniques are limited to clients with identical network architectures. This restricts potential use-cases like cross-platform training or inter-organizational collaboration when both data privacy and architectural proprietary are required. We propose a new FL framework that accommodates heterogeneous client architecture by adopting a graph hypernetwork for parameter sharing. A property of the graph hyper network is that it can adapt to various computational graphs, thereby allowing meaningful parameter sharing across models. Unlike existing solutions, our framework does not limit the clients to share the same architecture type, makes no use of external data and does not require clients to disclose their model architecture. Compared with distillation-based and non-graph hypernetwork baselines, our method performs notably better on standard benchmarks. We additionally show encouraging generalization performance to unseen architectures. ",
    "url": "https://arxiv.org/abs/2201.08459",
    "authors": [
      "Or Litany",
      "Haggai Maron",
      "David Acuna",
      "Jan Kautz",
      "Gal Chechik",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08460",
    "title": "Your Tweets Matter: How Social Media Sentiments Associate with COVID-19  Vaccination Rates in the US",
    "abstract": "Objective: The aims of the study were to examine the association between social media sentiments surrounding COVID-19 vaccination and the effects on vaccination rates in the United States (US), as well as other contributing factors to the COVID-19 vaccine hesitancy. Method: The dataset used in this study consists of vaccine-related English tweets collected in real-time from January 4 - May 11, 2021, posted within the US, as well as health literacy (HL), social vulnerability index (SVI), and vaccination rates at the state level. Results: The findings presented in this study demonstrate a significant correlation between the sentiments of the tweets and the vaccination rate in the US. The results also suggest a significant negative association between HL and SVI and that the state demographics correlate with both HL and SVI. Discussion: Social media activity provides insights into public opinion about vaccinations and helps determine the required public health interventions to increase the vaccination rate in the US. Conclusion: Health literacy, social vulnerability index and monitoring of social media sentiments need to be considered in public health interventions as part of vaccination campaigns. ",
    "url": "https://arxiv.org/abs/2201.08460",
    "authors": [
      "Ana Aleksandric",
      "Mercy Jesuloluwa Obasanya",
      "Sarah Melcher",
      "Shirin Nilizadeh",
      "Gabriela Mustata Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2201.08465",
    "title": "An Empirical Investigation of Model-to-Model Distribution Shifts in  Trained Convolutional Filters",
    "abstract": "We present first empirical results from our ongoing investigation of distribution shifts in image data used for various computer vision tasks. Instead of analyzing the original training and test data, we propose to study shifts in the learned weights of trained models. In this work, we focus on the properties of the distributions of dominantly used 3x3 convolution filter kernels. We collected and publicly provide a data set with over half a billion filters from hundreds of trained CNNs, using a wide range of data sets, architectures, and vision tasks. Our analysis shows interesting distribution shifts (or the lack thereof) between trained filters along different axes of meta-parameters, like data type, task, architecture, or layer depth. We argue, that the observed properties are a valuable source for further investigation into a better understanding of the impact of shifts in the input data to the generalization abilities of CNN models and novel methods for more robust transfer-learning in this domain. Data available at: https://github.com/paulgavrikov/CNN-Filter-DB/. ",
    "url": "https://arxiv.org/abs/2201.08465",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08468",
    "title": "Android Malware Detection using Feature Ranking of Permissions",
    "abstract": "We investigate the use of Android permissions as the vehicle to allow for quick and effective differentiation between benign and malware apps. To this end, we extract all Android permissions, eliminating those that have zero impact, and apply two feature ranking algorithms namely Chi-Square test and Fisher's Exact test to rank and additionally filter them, resulting in a comparatively small set of relevant permissions. Then we use Decision Tree, Support Vector Machine, and Random Forest Classifier algorithms to detect malware apps. Our analysis indicates that this approach can result in better accuracy and F-score value than other reported approaches. In particular, when random forest is used as the classifier with the combination of Fisher's Exact test, we achieve 99.34\\% in accuracy and 92.17\\% in F-score with the false positive rate of 0.56\\% for the dataset in question, with results improving to 99.82\\% in accuracy and 95.28\\% in F-score with the false positive rate as low as 0.05\\% when only malware from three most popular malware families are considered. ",
    "url": "https://arxiv.org/abs/2201.08468",
    "authors": [
      "Muhammad Suleman Saleem",
      "Jelena Mi\u0161i\u0107",
      "Vojislav B. Mi\u0161i\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08470",
    "title": "RoboMal: Malware Detection for Robot Network Systems",
    "abstract": "Robot systems are increasingly integrating into numerous avenues of modern life. From cleaning houses to providing guidance and emotional support, robots now work directly with humans. Due to their far-reaching applications and progressively complex architecture, they are being targeted by adversarial attacks such as sensor-actuator attacks, data spoofing, malware, and network intrusion. Therefore, security for robotic systems has become crucial. In this paper, we address the underserved area of malware detection in robotic software. Since robots work in close proximity to humans, often with direct interactions, malware could have life-threatening impacts. Hence, we propose the RoboMal framework of static malware detection on binary executables to detect malware before it gets a chance to execute. Additionally, we address the great paucity of data in this space by providing the RoboMal dataset comprising controller executables of a small-scale autonomous car. The performance of the framework is compared against widely used supervised learning models: GRU, CNN, and ANN. Notably, the LSTM-based RoboMal model outperforms the other models with an accuracy of 85% and precision of 87% in 10-fold cross-validation, hence proving the effectiveness of the proposed framework. ",
    "url": "https://arxiv.org/abs/2201.08470",
    "authors": [
      "Upinder Kaur",
      "Haozhe Zhou",
      "Xiaxin Shen",
      "Byung-Cheol Min",
      "Richard M. Voyles"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08474",
    "title": "Post-Training Detection of Backdoor Attacks for Two-Class and  Multi-Attack Scenarios",
    "abstract": "Backdoor attacks (BAs) are an emerging threat to deep neural network classifiers. A victim classifier will predict to an attacker-desired target class whenever a test sample is embedded with the same backdoor pattern (BP) that was used to poison the classifier's training set. Detecting whether a classifier is backdoor attacked is not easy in practice, especially when the defender is, e.g., a downstream user without access to the classifier's training set. This challenge is addressed here by a reverse-engineering defense (RED), which has been shown to yield state-of-the-art performance in several domains. However, existing REDs are not applicable when there are only {\\it two classes} or when {\\it multiple attacks} are present. These scenarios are first studied in the current paper, under the practical constraints that the defender neither has access to the classifier's training set nor to supervision from clean reference classifiers trained for the same domain. We propose a detection framework based on BP reverse-engineering and a novel {\\it expected transferability} (ET) statistic. We show that our ET statistic is effective {\\it using the same detection threshold}, irrespective of the classification domain, the attack configuration, and the BP reverse-engineering algorithm that is used. The excellent performance of our method is demonstrated on six benchmark datasets. Notably, our detection framework is also applicable to multi-class scenarios with multiple attacks. ",
    "url": "https://arxiv.org/abs/2201.08474",
    "authors": [
      "Zhen Xiang",
      "David J. Miller",
      "George Kesidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08475",
    "title": "GenGNN: A Generic FPGA Framework for Graph Neural Network Acceleration",
    "abstract": "Graph neural networks (GNNs) have recently exploded in popularity thanks to their broad applicability to ubiquitous graph-related problems such as quantum chemistry, drug discovery, and high energy physics. However, meeting demand for novel GNN models and fast inference simultaneously is challenging because of the gap between the difficulty in developing efficient FPGA accelerators and the rapid pace of creation of new GNN models. Prior art focuses on the acceleration of specific classes of GNNs but lacks the generality to work across existing models or to extend to new and emerging GNN models. In this work, we propose a generic GNN acceleration framework using High-Level Synthesis (HLS), named GenGNN, with two-fold goals. First, we aim to deliver ultra-fast GNN inference without any graph pre-processing for real-time requirements. Second, we aim to support a diverse set of GNN models with the extensibility to flexibly adapt to new models. The framework features an optimized message-passing structure applicable to all models, combined with a rich library of model-specific components. We verify our implementation on-board on the Xilinx Alveo U50 FPGA and observe a speed-up of up to 25x against CPU (6226R) baseline and 13x against GPU (A6000) baseline. Our HLS code will be open-source on GitHub upon acceptance. ",
    "url": "https://arxiv.org/abs/2201.08475",
    "authors": [
      "Stefan Abi-Karam",
      "Yuqi He",
      "Rishov Sarkar",
      "Lakshmi Sathidevi",
      "Zihang Qiao",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.08481",
    "title": "Classic Graph Structural Features Outperform Factorization-Based Graph  Embedding Methods on Community Labeling",
    "abstract": "Graph representation learning (also called graph embeddings) is a popular technique for incorporating network structure into machine learning models. Unsupervised graph embedding methods aim to capture graph structure by learning a low-dimensional vector representation (the embedding) for each node. Despite the widespread use of these embeddings for a variety of downstream transductive machine learning tasks, there is little principled analysis of the effectiveness of this approach for common tasks. In this work, we provide an empirical and theoretical analysis for the performance of a class of embeddings on the common task of pairwise community labeling. This is a binary variant of the classic community detection problem, which seeks to build a classifier to determine whether a pair of vertices participate in a community. In line with our goal of foundational understanding, we focus on a popular class of unsupervised embedding techniques that learn low rank factorizations of a vertex proximity matrix (this class includes methods like GraRep, DeepWalk, node2vec, NetMF). We perform detailed empirical analysis for community labeling over a variety of real and synthetic graphs with ground truth. In all cases we studied, the models trained from embedding features perform poorly on community labeling. In constrast, a simple logistic model with classic graph structural features handily outperforms the embedding models. For a more principled understanding, we provide a theoretical analysis for the (in)effectiveness of these embeddings in capturing the community structure. We formally prove that popular low-dimensional factorization methods either cannot produce community structure, or can only produce ``unstable\" communities. These communities are inherently unstable under small perturbations. ",
    "url": "https://arxiv.org/abs/2201.08481",
    "authors": [
      "Andrew Stolman",
      "Caleb Levy",
      "C. Seshadhri",
      "Aneesh Sharma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2201.08549",
    "title": "Fair Node Representation Learning via Adaptive Data Augmentation",
    "abstract": "Node representation learning has demonstrated its efficacy for various applications on graphs, which leads to increasing attention towards the area. However, fairness is a largely under-explored territory within the field, which may lead to biased results towards underrepresented groups in ensuing tasks. To this end, this work theoretically explains the sources of bias in node representations obtained via Graph Neural Networks (GNNs). Our analysis reveals that both nodal features and graph structure lead to bias in the obtained representations. Building upon the analysis, fairness-aware data augmentation frameworks on nodal features and graph structure are developed to reduce the intrinsic bias. Our analysis and proposed schemes can be readily employed to enhance the fairness of various GNN-based learning mechanisms. Extensive experiments on node classification and link prediction are carried out over real networks in the context of graph contrastive learning. Comparison with multiple benchmarks demonstrates that the proposed augmentation strategies can improve fairness in terms of statistical parity and equal opportunity, while providing comparable utility to state-of-the-art contrastive methods. ",
    "url": "https://arxiv.org/abs/2201.08549",
    "authors": [
      "O. Deniz Kose",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08551",
    "title": "Blockchain-based Collaborated Federated Learning for Improved Security,  Privacy and Reliability",
    "abstract": "Federated Learning (FL) provides privacy preservation by allowing the model training at edge devices without the need of sending the data from edge to a centralized server. FL has distributed the implementation of ML. Another variant of FL which is well suited for the Internet of Things (IoT) is known as Collaborated Federated Learning (CFL), which does not require an edge device to have a direct link to the model aggregator. Instead, the devices can connect to the central model aggregator via other devices using them as relays. Although, FL and CFL protect the privacy of edge devices but raises security challenges for a centralized server that performs model aggregation. The centralized server is prone to malfunction, backdoor attacks, model corruption, adversarial attacks and external attacks. Moreover, edge device to centralized server data exchange is not required in FL and CFL, but model parameters are sent from the model aggregator (global model) to edge devices (local model), which is still prone to cyber-attacks. These security and privacy concerns can be potentially addressed by Blockchain technology. The blockchain is a decentralized and consensus-based chain where devices can share consensus ledgers with increased reliability and security, thus significantly reducing the cyberattacks on an exchange of information. In this work, we will investigate the efficacy of blockchain-based decentralized exchange of model parameters and relevant information among edge devices and from a centralized server to edge devices. Moreover, we will be conducting the feasibility analysis for blockchain-based CFL models for different application scenarios like the internet of vehicles, and the internet of things. The proposed study aims to improve the security, reliability and privacy preservation by the use of blockchain-powered CFL. ",
    "url": "https://arxiv.org/abs/2201.08551",
    "authors": [
      "Amir Afaq",
      "Zeeshan Ahmed",
      "Noman Haider",
      "Muhammad Imran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.08554",
    "title": "Enhancing Hyperbolic Graph Embeddings via Contrastive Learning",
    "abstract": "Recently, hyperbolic space has risen as a promising alternative for semi-supervised graph representation learning. Many efforts have been made to design hyperbolic versions of neural network operations. However, the inspiring geometric properties of this unique geometry have not been fully explored yet. The potency of graph models powered by the hyperbolic space is still largely underestimated. Besides, the rich information carried by abundant unlabelled samples is also not well utilized. Inspired by the recently active and emerging self-supervised learning, in this study, we attempt to enhance the representation power of hyperbolic graph models by drawing upon the advantages of contrastive learning. More specifically, we put forward a novel Hyperbolic Graph Contrastive Learning (HGCL) framework which learns node representations through multiple hyperbolic spaces to implicitly capture the hierarchical structure shared between different views. Then, we design a hyperbolic position consistency (HPC) constraint based on hyperbolic distance and the homophily assumption to make contrastive learning fit into hyperbolic space. Experimental results on multiple real-world datasets demonstrate the superiority of the proposed HGCL as it consistently outperforms competing methods by considerable margins for the node classification task. ",
    "url": "https://arxiv.org/abs/2201.08554",
    "authors": [
      "Jiahong Liu",
      "Menglin Yang",
      "Min Zhou",
      "Shanshan Feng",
      "Philippe Fournier-Viger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08555",
    "title": "Identifying Adversarial Attacks on Text Classifiers",
    "abstract": "The landscape of adversarial attacks against text classifiers continues to grow, with new attacks developed every year and many of them available in standard toolkits, such as TextAttack and OpenAttack. In response, there is a growing body of work on robust learning, which reduces vulnerability to these attacks, though sometimes at a high cost in compute time or accuracy. In this paper, we take an alternate approach -- we attempt to understand the attacker by analyzing adversarial text to determine which methods were used to create it. Our first contribution is an extensive dataset for attack detection and labeling: 1.5~million attack instances, generated by twelve adversarial attacks targeting three classifiers trained on six source datasets for sentiment analysis and abuse detection in English. As our second contribution, we use this dataset to develop and benchmark a number of classifiers for attack identification -- determining if a given text has been adversarially manipulated and by which attack. As a third contribution, we demonstrate the effectiveness of three classes of features for these tasks: text properties, capturing content and presentation of text; language model properties, determining which tokens are more or less probable throughout the input; and target model properties, representing how the text classifier is influenced by the attack, including internal node activations. Overall, this represents a first step towards forensics for adversarial attacks against text classifiers. ",
    "url": "https://arxiv.org/abs/2201.08555",
    "authors": [
      "Zhouhang Xie",
      "Jonathan Brophy",
      "Adam Noack",
      "Wencong You",
      "Kalyani Asthana",
      "Carter Perkins",
      "Sabrina Reis",
      "Sameer Singh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08557",
    "title": "Robust Unsupervised Graph Representation Learning via Mutual Information  Maximization",
    "abstract": "Recent studies have shown that GNNs are vulnerable to adversarial attack. Thus, many approaches are proposed to improve the robustness of GNNs against adversarial attacks. Nevertheless, most of these methods measure the model robustness based on label information and thus become infeasible when labels information is not available. Therefore, this paper focuses on robust unsupervised graph representation learning. In particular, to quantify the robustness of GNNs without label information, we propose a robustness measure, named graph representation robustness (GRR), to evaluate the mutual information between adversarially perturbed node representations and the original graph. There are mainly two challenges to estimate GRR: 1) mutual information estimation upon adversarially attacked graphs; 2) high complexity of adversarial attack to perturb node features and graph structure jointly in the training procedure. To tackle these problems, we further propose an effective mutual information estimator with subgraph-level summary and an efficient adversarial training strategy with only feature perturbations. Moreover, we theoretically establish a connection between our proposed GRR measure and the robustness of downstream classifiers, which reveals that GRR can provide a lower bound to the adversarial risk of downstream classifiers. Extensive experiments over several benchmarks demonstrate the effectiveness and superiority of our proposed method. ",
    "url": "https://arxiv.org/abs/2201.08557",
    "authors": [
      "Jihong Wang",
      "Minnan Luo",
      "Jundong Li",
      "Ziqi Liu",
      "Jun Zhou",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08559",
    "title": "Individual Treatment Effect Estimation Through Controlled Neural Network  Training in Two Stages",
    "abstract": "We develop a Causal-Deep Neural Network (CDNN) model trained in two stages to infer causal impact estimates at an individual unit level. Using only the pre-treatment features in stage 1 in the absence of any treatment information, we learn an encoding for the covariates that best represents the outcome. In the $2^{nd}$ stage we further seek to predict the unexplained outcome from stage 1, by introducing the treatment indicator variables alongside the encoded covariates. We prove that even without explicitly computing the treatment residual, our method still satisfies the desirable local Neyman orthogonality, making it robust to small perturbations in the nuisance parameters. Furthermore, by establishing connections with the representation learning approaches, we create a framework from which multiple variants of our algorithm can be derived. We perform initial experiments on the publicly available data sets to compare these variants and get guidance in selecting the best variant of our CDNN method. On evaluating CDNN against the state-of-the-art approaches on three benchmarking datasets, we observe that CDNN is highly competitive and often yields the most accurate individual treatment effect estimates. We highlight the strong merits of CDNN in terms of its extensibility to multiple use cases. ",
    "url": "https://arxiv.org/abs/2201.08559",
    "authors": [
      "Naveen Nair",
      "Karthik S. Gurumoorthy",
      "Dinesh Mandalapu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08560",
    "title": "Bit-GraphBLAS: Bit-Level Optimizations of Matrix-Centric Graph  Processing on GPU",
    "abstract": "In a general graph data structure like an adjacency matrix, when edges are homogeneous, the connectivity of two nodes can be sufficiently represented using a single bit. This insight has, however, not yet been adequately exploited by the existing matrix-centric graph processing frameworks. This work fills the void by systematically exploring the bit-level representation of graphs and the corresponding optimizations to the graph operations. It proposes a two-level representation named Bit-Block Compressed Sparse Row (B2SR) and presents a series of optimizations to the graph operations on B2SR by leveraging the intrinsics of modern GPUs. Evaluations on NVIDIA Pascal and Volta GPUs show that the optimizations bring up to $40\\times$ and $6555\\times$ for essential GraphBLAS kernels SpMV and SpGEMM, respectively, making GraphBLAS-based BFS accelerate up to $433\\times$, SSSP, PR, and CC up to $35\\times$, and TC up to $52\\times$. ",
    "url": "https://arxiv.org/abs/2201.08560",
    "authors": [
      "Jou-An Chen",
      "Hsin-Hsuan Sung",
      "Nathan Tallent",
      "Kevin Barker",
      "Xipeng Shen",
      "Ang Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.08580",
    "title": "Trustworthy Knowledge Graph Completion Based on Multi-sourced Noisy Data",
    "abstract": "Knowledge graphs (KGs) have become a valuable asset for many AI applications. Although some KGs contain plenty of facts, they are widely acknowledged as incomplete. To address this issue, many KG completion methods are proposed. Among them, open KG completion methods leverage the Web to find missing facts. However, noisy data collected from diverse sources may damage the completion accuracy. In this paper, we propose a new trustworthy method that exploits facts for a KG based on multi-sourced noisy data and existing facts in the KG. Specifically, we introduce a graph neural network with a holistic scoring function to judge the plausibility of facts with various value types. We design value alignment networks to resolve the heterogeneity between values and map them to entities even outside the KG. Furthermore, we present a truth inference model that incorporates data source qualities into the fact scoring function, and design a semi-supervised learning way to infer the truths from heterogeneous values. We conduct extensive experiments to compare our method with the state-of-the-arts. The results show that our method achieves superior accuracy not only in completing missing facts but also in discovering new facts. ",
    "url": "https://arxiv.org/abs/2201.08580",
    "authors": [
      "Jiacheng Huang",
      "Yao Zhao",
      "Wei Hu",
      "Zhen Ning",
      "Qijin Chen",
      "Xiaoxia Qiu",
      "Chengfu Huo",
      "Weijun Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2201.08598",
    "title": "Taxonomy Enrichment with Text and Graph Vector Representations",
    "abstract": "Knowledge graphs such as DBpedia, Freebase or Wikidata always contain a taxonomic backbone that allows the arrangement and structuring of various concepts in accordance with the hypo-hypernym (\"class-subclass\") relationship. With the rapid growth of lexical resources for specific domains, the problem of automatic extension of the existing knowledge bases with new words is becoming more and more widespread. In this paper, we address the problem of taxonomy enrichment which aims at adding new words to the existing taxonomy. We present a new method that allows achieving high results on this task with little effort. It uses the resources which exist for the majority of languages, making the method universal. We extend our method by incorporating deep representations of graph structures like node2vec, Poincar\\'e embeddings, GCN etc. that have recently demonstrated promising results on various NLP tasks. Furthermore, combining these representations with word embeddings allows us to beat the state of the art. We conduct a comprehensive study of the existing approaches to taxonomy enrichment based on word and graph vector representations and their fusion approaches. We also explore the ways of using deep learning architectures to extend the taxonomic backbones of knowledge graphs. We create a number of datasets for taxonomy extension for English and Russian. We achieve state-of-the-art results across different datasets and provide an in-depth error analysis of mistakes. ",
    "url": "https://arxiv.org/abs/2201.08598",
    "authors": [
      "Irina Nikishina",
      "Mikhail Tikhomirov",
      "Varvara Logacheva",
      "Yuriy Nazarov",
      "Alexander Panchenko",
      "Natalia Loukachevitch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.08605",
    "title": "Seamless and Energy Efficient Maritime Coverage in Coordinated 6G  Space-Air-Sea Non-Terrestrial Networks",
    "abstract": "Non-terrestrial networks (NTNs), which integrate space and aerial networks with terrestrial systems, are a key area in the emerging sixth-generation (6G) wireless networks. As part of 6G, NTNs must provide pervasive connectivity to a wide range of devices, including smartphones, vehicles, sensors, robots, and maritime users. However, due to the high mobility and deployment of NTNs, managing the space-air-sea (SAS) NTN resources, i.e., energy, power, and channel allocation, is a major challenge. The design of a SAS-NTN for energy-efficient resource allocation is investigated in this study. The goal is to maximize system energy efficiency (EE) by collaboratively optimizing user equipment (UE) association, power control, and unmanned aerial vehicle (UAV) deployment. Given the limited payloads of UAVs, this work focuses on minimizing the total energy cost of UAVs (trajectory and transmission) while meeting EE requirements. A mixed-integer nonlinear programming problem is proposed, followed by the development of an algorithm to decompose, and solve each problem distributedly. The binary (UE association) and continuous (power, deployment) variables are separated using the Bender decomposition (BD), and then the Dinkelbach algorithm (DA) is used to convert fractional programming into an equivalent solvable form in the subproblem. A standard optimization solver is utilized to deal with the complexity of the master problem for binary variables. The alternating direction method of multipliers (ADMM) algorithm is used to solve the subproblem for the continuous variables. Our proposed algorithm provides a suboptimal solution, and simulation results demonstrate that the proposed algorithm achieves better EE than baselines. ",
    "url": "https://arxiv.org/abs/2201.08605",
    "authors": [
      "Sheikh Salman Hassan",
      "Do Hyeon Kim",
      "Yan Kyaw Tun",
      "Nguyen H. Tran",
      "Walid Saad",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.08610",
    "title": "Deep Q-learning: a robust control approach",
    "abstract": "In this paper, we place deep Q-learning into a control-oriented perspective and study its learning dynamics with well-established techniques from robust control. We formulate an uncertain linear time-invariant model by means of the neural tangent kernel to describe learning. We show the instability of learning and analyze the agent's behavior in frequency-domain. Then, we ensure convergence via robust controllers acting as dynamical rewards in the loss function. We synthesize three controllers: state-feedback gain scheduling $\\mathcal{H}_2$, dynamic $\\mathcal{H}_\\infty$, and constant gain $\\mathcal{H}_\\infty$ controllers. Setting up the learning agent with a control-oriented tuning methodology is more transparent and has well-established literature compared to the heuristics in reinforcement learning. In addition, our approach does not use a target network and randomized replay memory. The role of the target network is overtaken by the control input, which also exploits the temporal dependency of samples (opposed to a randomized memory buffer). Numerical simulations in different OpenAI Gym environments suggest that the $\\mathcal{H}_\\infty$ controlled learning performs slightly better than Double deep Q-learning. ",
    "url": "https://arxiv.org/abs/2201.08610",
    "authors": [
      "Bal\u00e1zs Varga",
      "Bal\u00e1zs Kulcs\u00e1r",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08619",
    "title": "Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object  Detectors in the Physical World",
    "abstract": "Deep learning models have been shown to be vulnerable to recent backdoor attacks. A backdoored model behaves normally for inputs containing no attacker-secretly-chosen trigger and maliciously for inputs with the trigger. To date, backdoor attacks and countermeasures mainly focus on image classification tasks. And most of them are implemented in the digital world with digital triggers. Besides the classification tasks, object detection systems are also considered as one of the basic foundations of computer vision tasks. However, there is no investigation and understanding of the backdoor vulnerability of the object detector, even in the digital world with digital triggers. For the first time, this work demonstrates that existing object detectors are inherently susceptible to physical backdoor attacks. We use a natural T-shirt bought from a market as a trigger to enable the cloaking effect--the person bounding-box disappears in front of the object detector. We show that such a backdoor can be implanted from two exploitable attack scenarios into the object detector, which is outsourced or fine-tuned through a pretrained model. We have extensively evaluated three popular object detection algorithms: anchor-based Yolo-V3, Yolo-V4, and anchor-free CenterNet. Building upon 19 videos shot in real-world scenes, we confirm that the backdoor attack is robust against various factors: movement, distance, angle, non-rigid deformation, and lighting. Specifically, the attack success rate (ASR) in most videos is 100% or close to it, while the clean data accuracy of the backdoored model is the same as its clean counterpart. The latter implies that it is infeasible to detect the backdoor behavior merely through a validation set. The averaged ASR still remains sufficiently high to be 78% in the transfer learning attack scenarios evaluated on CenterNet. See the demo video on https://youtu.be/Q3HOF4OobbY. ",
    "url": "https://arxiv.org/abs/2201.08619",
    "authors": [
      "Hua Ma",
      "Yinshan Li",
      "Yansong Gao",
      "Alsharif Abuadbba",
      "Zhi Zhang",
      "Anmin Fu",
      "Hyoungshick Kim",
      "Said F. Al-Sarawi",
      "Nepal Surya",
      "Derek Abbott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.08633",
    "title": "Multi-view Monocular Depth and Uncertainty Prediction with Deep SfM in  Dynamic Environments",
    "abstract": "3D reconstruction of depth and motion from monocular video in dynamic environments is a highly ill-posed problem due to scale ambiguities when projecting to the 2D image domain. In this work, we investigate the performance of the current State-of-the-Art (SotA) deep multi-view systems in such environments. We find that current supervised methods work surprisingly well despite not modelling individual object motions, but make systematic errors due to a lack of dense ground truth data. To detect such errors during usage, we extend the cost volume based Deep Video to Depth (DeepV2D) framework \\cite{teed2018deepv2d} with a learned uncertainty. Our Deep Video to certain Depth (DeepV2cD) model allows i) to perform en par or better with current SotA and ii) achieve a better uncertainty measure than the naive Shannon entropy. Our experiments show that a simple filter strategy based on the uncertainty can significantly reduce systematic errors. This results in cleaner reconstructions both on static and dynamic parts of the scene. ",
    "url": "https://arxiv.org/abs/2201.08633",
    "authors": [
      "Christian Homeyer",
      "Oliver Lange",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08641",
    "title": "Robust a posteriori estimates for the stochastic Cahn-Hilliard equation",
    "abstract": "We derive a posteriori error estimates for a fully discrete finite element approximation of the stochastic Cahn-Hilliard equation. The a posteriori bound is obtained by a splitting of the equation into a linear stochastic partial differential equation (SPDE) and a nonlinear random partial differential equation (RPDE). The resulting estimate is robust with respect to the interfacial width parameter and is computable since it involves the discrete principal eigenvalue of a linearized (stochastic) Cahn-Hilliard operator. Furthermore, the estimate is robust with respect to topological changes as well as the intensity of the stochastic noise. We provide numerical simulations to demonstrate the practicability of the proposed adaptive algorithm. ",
    "url": "https://arxiv.org/abs/2201.08641",
    "authors": [
      "\u013dubom\u00edr Ba\u0148as",
      "Christian Vieth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.08659",
    "title": "Unity Smoothing for Handling Inconsistent Evidence in Bayesian Networks  and Unity Propagation for Faster Inference",
    "abstract": "We propose Unity Smoothing (US) for handling inconsistencies between a Bayesian network model and new unseen observations. We show that prediction accuracy, using the junction tree algorithm with US is comparable to that of Laplace smoothing. Moreover, in applications were sparsity of the data structures is utilized, US outperforms Laplace smoothing in terms of memory usage. Furthermore, we detail how to avoid redundant calculations that must otherwise be performed during the message passing scheme in the junction tree algorithm which we refer to as Unity Propagation (UP). Experimental results shows that it is always faster to exploit UP on top of the Lauritzen-Spigelhalter message passing scheme for the junction tree algorithm. ",
    "url": "https://arxiv.org/abs/2201.08659",
    "authors": [
      "Mads Lindskou",
      "Torben Tvedebrink",
      "Poul Svante Eriksen",
      "S\u00f8ren H\u00f8jsgaard",
      "Niels Morling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2201.08660",
    "title": "On the adaptation of recurrent neural networks for system identification",
    "abstract": "This paper presents a transfer learning approach which enables fast and efficient adaptation of Recurrent Neural Network (RNN) models of dynamical systems. A nominal RNN model is first identified using available measurements. The system dynamics are then assumed to change, leading to an unacceptable degradation of the nominal model performance on the perturbed system. To cope with the mismatch, the model is augmented with an additive correction term trained on fresh data from the new dynamic regime. The correction term is learned through a Jacobian Feature Regression (JFR) method defined in terms of the features spanned by the model's Jacobian with respect to its nominal parameters. A non-parametric view of the approach is also proposed, which extends recent work on Gaussian Process (GP) with Neural Tangent Kernel (NTK-GP) to the RNN case (RNTK-GP). This can be more efficient for very large networks or when only few data points are available. Implementation aspects for fast and efficient computation of the correction term, as well as the initial state estimation for the RNN model are described. Numerical examples show the effectiveness of the proposed methodology in presence of significant system variations. ",
    "url": "https://arxiv.org/abs/2201.08660",
    "authors": [
      "Marco Forgione",
      "Aneri Muni",
      "Dario Piga",
      "Marco Gallieri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.08669",
    "title": "Dynamic Deep Convolutional Candlestick Learner",
    "abstract": "Candlestick pattern is one of the most fundamental and valuable graphical tools in financial trading that supports traders observing the current market conditions to make the proper decision. This task has a long history and, most of the time, human experts. Recently, efforts have been made to automatically classify these patterns with the deep learning models. The GAF-CNN model is a well-suited way to imitate how human traders capture the candlestick pattern by integrating spatial features visually. However, with the great potential of the GAF encoding, this classification task can be extended to a more complicated object detection level. This work presents an innovative integration of modern object detection techniques and GAF time-series encoding on candlestick pattern tasks. We make crucial modifications to the representative yet straightforward YOLO version 1 model based on our time-series encoding method and the property of such data type. Powered by the deep neural networks and the unique architectural design, the proposed model performs pretty well in candlestick classification and location recognition. The results show tremendous potential in applying modern object detection techniques on time-series tasks in a real-time manner. ",
    "url": "https://arxiv.org/abs/2201.08669",
    "authors": [
      "Jun-Hao Chen",
      "Yun-Cheng Tsai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08678",
    "title": "Attack of the Clones: Measuring the Maintainability, Originality and  Security of Bitcoin 'Forks' in the Wild",
    "abstract": "Since Bitcoin appeared in 2009, over 6,000 different cryptocurrency projects have followed. The cryptocurrency world may be the only technology where a massive number of competitors offer similar services yet claim unique benefits, including scalability, fast transactions, and security. But are these projects really offering unique features and significant enhancements over their competitors? To answer this question, we conducted a large-scale empirical analysis of code maintenance activities, originality and security across 592 crypto projects. We found that about half of these projects have not been updated for the last six months; over two years, about three-quarters of them disappeared, or were reported as scams or inactive. We also investigated whether 11 security vulnerabilities patched in Bitcoin were also patched in other projects. We found that about 80% of 510 C-language-based cryptocurrency projects have at least one unpatched vulnerability, and the mean time taken to fix the vulnerability is 237.8 days. Among those 510 altcoins, we found that at least 157 altcoins are likely to have been forked from Bitcoin, about a third of them containing only slight changes from the Bitcoin version from which they were forked. As case studies, we did a deep dive into 20 altcoins (e.g., Litecoin, FujiCoin, and Feathercoin) similar to the version of Bitcoin used for the fork. About half of them did not make any technically meaningful change - failing to comply with the promises (e.g., about using Proof of Stake) made in their whitepapers. ",
    "url": "https://arxiv.org/abs/2201.08678",
    "authors": [
      "Jusop Choi",
      "Wonseok Choi",
      "William Aiken",
      "Hyoungshick Kim",
      "Jun Ho Huh",
      "Taesoo Kim",
      "Yongdae Kim",
      "Ross Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.08680",
    "title": "Minrank of Embedded Index Coding Problems and its Relation to  Connectedness of a Bipartite Graph",
    "abstract": "This paper deals with embedded index coding problem (EICP), introduced by A. Porter and M. Wootters, which is a decentralized communication problem among users with side information. An alternate definition of the parameter minrank of an EICP, which has reduced computational complexity compared to the existing definition, is presented. A graphical representation for an EICP is given using directed bipartite graphs, called bipartite problem graph, and the side information alone is represented using an undirected bipartite graph called the side information bipartite graph. Inspired by the well-studied single unicast index coding problem (SUICP), graphical structures, similar to cycles and cliques in the side information graph of an SUICP, are identified in the side information bipartite graph of a single unicast embedded index coding problem (SUEICP). Transmission schemes based on these graphical structures, called tree cover scheme and bi-clique cover scheme are also presented for an SUEICP. Also, a relation between connectedness of the side information bipartite graph and the number of transmissions required in a scalar linear solution of an EICP is established. ",
    "url": "https://arxiv.org/abs/2201.08680",
    "authors": [
      "Anjana A Mahesh",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.08683",
    "title": "A Comprehensive Study of Vision Transformers on Dense Prediction Tasks",
    "abstract": "Convolutional Neural Networks (CNNs), architectures consisting of convolutional layers, have been the standard choice in vision tasks. Recent studies have shown that Vision Transformers (VTs), architectures based on self-attention modules, achieve comparable performance in challenging tasks such as object detection and semantic segmentation. However, the image processing mechanism of VTs is different from that of conventional CNNs. This poses several questions about their generalizability, robustness, reliability, and texture bias when used to extract features for complex tasks. To address these questions, we study and compare VT and CNN architectures as feature extractors in object detection and semantic segmentation. Our extensive empirical results show that the features generated by VTs are more robust to distribution shifts, natural corruptions, and adversarial attacks in both tasks, whereas CNNs perform better at higher image resolutions in object detection. Furthermore, our results demonstrate that VTs in dense prediction tasks produce more reliable and less texture-biased predictions. ",
    "url": "https://arxiv.org/abs/2201.08683",
    "authors": [
      "Kishaan Jeeveswaran",
      "Senthilkumar Kathiresan",
      "Arnav Varma",
      "Omar Magdy",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08686",
    "title": "Modelling Agent-Skipping Attacks in Message Forwarding Protocols",
    "abstract": "Message forwarding protocols are protocols in which a chain of agents handles transmission of a message. Each agent forwards the received message to the next agent in the chain. For example, TLS middleboxes act as intermediary agents in TLS, adding functionality such as filtering or compressing data. In such protocols, an attacker may attempt to bypass one or more intermediary agents. Such an agent-skipping attack can the violate security requirements of the protocol. Using the multiset rewriting model in the symbolic setting, we construct a comprehensive framework of such path protocols. In particular, we introduce a set of security goals related to path integrity: the notion that a message faithfully travels through participants in the order intended by the initiating agent. We perform a security analysis of several such protocols, highlighting key attacks on modern protocols. ",
    "url": "https://arxiv.org/abs/2201.08686",
    "authors": [
      "Zach Smith",
      "Hugo Jonker",
      "Sjouke Mauw",
      "Hyunwoo Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.08698",
    "title": "Natural Attack for Pre-trained Models of Code",
    "abstract": "Pre-trained models of code have achieved success in many important software engineering tasks. However, these powerful models are vulnerable to adversarial attacks that slightly perturb model inputs to make a victim model produce wrong outputs. Current works mainly attack models of code with examples that preserve operational program semantics but ignore a fundamental requirement for adversarial example generation: perturbations should be natural to human judges, which we refer to as naturalness requirement. In this paper, we propose ALERT (nAturaLnEss AwaRe ATtack), a black-box attack that adversarially transforms inputs to make victim models produce wrong outputs. Different from prior works, this paper considers the natural semantic of generated examples at the same time as preserving the operational semantic of original inputs. Our user study demonstrates that human developers consistently consider that adversarial examples generated by ALERT are more natural than those generated by the state-of-the-art work by Zhang et al. that ignores the naturalness requirement. On attacking CodeBERT, our approach can achieve attack success rates of 53.62%, 27.79%, and 35.78% across three downstream tasks: vulnerability prediction, clone detection and code authorship attribution. On GraphCodeBERT, our approach can achieve average success rates of 76.95%, 7.96% and 61.47% on the three tasks. The above outperforms the baseline by 14.07% and 18.56% on the two pre-trained models on average. Finally, we investigated the value of the generated adversarial examples to harden victim models through an adversarial fine-tuning procedure and demonstrated the accuracy of CodeBERT and GraphCodeBERT against ALERT-generated adversarial examples increased by 87.59% and 92.32%, respectively. ",
    "url": "https://arxiv.org/abs/2201.08698",
    "authors": [
      "Zhou Yang",
      "Jieke Shi",
      "Junda He",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.08702",
    "title": "Dual Contrastive Learning: Text Classification via Label-Aware Data  Augmentation",
    "abstract": "Contrastive learning has achieved remarkable success in representation learning via self-supervision in unsupervised settings. However, effectively adapting contrastive learning to supervised learning tasks remains as a challenge in practice. In this work, we introduce a dual contrastive learning (DualCL) framework that simultaneously learns the features of input samples and the parameters of classifiers in the same space. Specifically, DualCL regards the parameters of the classifiers as augmented samples associating to different labels and then exploits the contrastive learning between the input samples and the augmented samples. Empirical studies on five benchmark text classification datasets and their low-resource version demonstrate the improvement in classification accuracy and confirm the capability of learning discriminative representations of DualCL. ",
    "url": "https://arxiv.org/abs/2201.08702",
    "authors": [
      "Qianben Chen",
      "Richong Zhang",
      "Yaowei Zheng",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08731",
    "title": "Low-Interception Waveform: To Prevent the Recognition of Spectrum  Waveform Modulation via Adversarial Examples",
    "abstract": "Deep learning is applied to many complex tasks in the field of wireless communication, such as modulation recognition of spectrum waveforms, because of its convenience and efficiency. This leads to the problem of a malicious third party using a deep learning model to easily recognize the modulation format of the transmitted waveform. Some existing works address this problem directly using the concept of adversarial examples in the image domain without fully considering the characteristics of the waveform transmission in the physical world. Therefore, we propose a low-intercept waveform~(LIW) generation method that can reduce the probability of the modulation being recognized by a third party without affecting the reliable communication of the friendly party. Our LIW exhibits significant low-interception performance even in the physical hardware experiment, decreasing the accuracy of the state of the art model to approximately $15\\%$ with small perturbations. ",
    "url": "https://arxiv.org/abs/2201.08731",
    "authors": [
      "Haidong Xie",
      "Jia Tan",
      "Xiaoying Zhang",
      "Nan Ji",
      "Haihua Liao",
      "Zuguo Yu",
      "Xueshuang Xiang",
      "Naijin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.08739",
    "title": "Privacy Policies Across the Ages: Content and Readability of Privacy  Policies 1996--2021",
    "abstract": "It is well-known that most users do not read privacy policies, but almost all users tick the box to agree with them. In this paper, we analyze the 25-year history of privacy policies using methods from transparency research, machine learning, and natural language processing. Specifically, we collect a large-scale longitudinal corpus of privacy policies from 1996 to 2021 and analyze the length and readability of privacy policies as well as their content in terms of the data practices they describe, the rights they grant to users, and the rights they reserve for their organizations. We pay particular attention to changes in response to recent privacy regulations such as the GDPR and CCPA. Our results show that policies are getting longer and harder to read, especially after new regulations take effect, and we find a range of concerning data practices. Our results allow us to speculate why privacy policies are rarely read and propose changes that would make privacy policies serve their readers instead of their writers. ",
    "url": "https://arxiv.org/abs/2201.08739",
    "authors": [
      "Isabel Wagner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08763",
    "title": "Object Detection in Aerial Images: What Improves the Accuracy?",
    "abstract": "Object detection is a challenging and popular computer vision problem. The problem is even more challenging in aerial images due to significant variation in scale and viewpoint in a diverse set of object categories. Recently, deep learning-based object detection approaches have been actively explored for the problem of object detection in aerial images. In this work, we investigate the impact of Faster R-CNN for aerial object detection and explore numerous strategies to improve its performance for aerial images. We conduct extensive experiments on the challenging iSAID dataset. The resulting adapted Faster R-CNN obtains a significant mAP gain of 4.96% over its vanilla baseline counterpart on the iSAID validation set, demonstrating the impact of different strategies investigated in this work. ",
    "url": "https://arxiv.org/abs/2201.08763",
    "authors": [
      "Hashmat Shadab Malik",
      "Ikboljon Sobirov",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08768",
    "title": "On probability-raising causality in Markov decision processes",
    "abstract": "The purpose of this paper is to introduce a notion of causality in Markov decision processes based on the probability-raising principle and to analyze its algorithmic properties. The latter includes algorithms for checking cause-effect relationships and the existence of probability-raising causes for given effect scenarios. Inspired by concepts of statistical analysis, we study quality measures (recall, coverage ratio and f-score) for causes and develop algorithms for their computation. Finally, the computational complexity for finding optimal causes with respect to these measures is analyzed. ",
    "url": "https://arxiv.org/abs/2201.08768",
    "authors": [
      "Christel Baier",
      "Florian Funke",
      "Jakob Piribauer",
      "Robin Ziemek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2201.08778",
    "title": "Mitigating Smart Jammers in MU-MIMO via Joint Channel Estimation and  Data Detection",
    "abstract": "Wireless systems must be resilient to jamming attacks. Existing mitigation methods require knowledge of the jammer's transmit characteristics. However, this knowledge may be difficult to acquire, especially for smart jammers that attack only specific instants during transmission in order to evade mitigation. We propose a novel method that mitigates attacks by smart jammers on massive multi-user multiple-input multiple-output (MU-MIMO) basestations (BSs). Our approach builds on recent progress in joint channel estimation and data detection (JED) and exploits the fact that a jammer cannot change its subspace within a coherence interval. Our method, called MAED (short for MitigAtion, Estimation, and Detection), uses a novel problem formulation that combines jammer estimation and mitigation, channel estimation, and data detection, instead of separating these tasks. We solve the problem approximately with an efficient iterative algorithm. Our results show that MAED effectively mitigates a wide range of smart jamming attacks without having any a priori knowledge about the attack type. ",
    "url": "https://arxiv.org/abs/2201.08778",
    "authors": [
      "Gian Marti",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.08780",
    "title": "Real-Time Seizure Detection using EEG: A Comprehensive Comparison of  Recent Approaches under a Realistic Setting",
    "abstract": "Electroencephalogram (EEG) is an important diagnostic test that physicians use to record brain activity and detect seizures by monitoring the signals. There have been several attempts to detect seizures and abnormalities in EEG signals with modern deep learning models to reduce the clinical burden. However, they cannot be fairly compared against each other as they were tested in distinct experimental settings. Also, some of them are not trained in real-time seizure detection tasks, making it hard for on-device applications. Therefore in this work, for the first time, we extensively compare multiple state-of-the-art models and signal feature extractors in a real-time seizure detection framework suitable for real-world application, using various evaluation metrics including a new one we propose to evaluate more practical aspects of seizure detection models. Our code is available at https://github.com/AITRICS/EEG_real_time_seizure_detection. ",
    "url": "https://arxiv.org/abs/2201.08780",
    "authors": [
      "Kwanhyung Lee",
      "Hyewon Jeong",
      "Seyun Kim",
      "Donghwa Yang",
      "Hoon-Chul Kang",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08796",
    "title": "Harmonic structures of Beethoven quartets: a complex network approach",
    "abstract": "We propose a complex network approach to the harmonic structure underpinning western tonal music. From a database of Beethoven's string quartets, we construct a directed network whose nodes are musical chords and edges connect chords following each other. We show that the network is scale-free and has specific properties when ranking algorithms are applied. We explore its community structure and its musical interpretation, and propose statistical measures stemming from network theory allowing to distinguish stylistically between periods of composition. Our work opens the way to a network approach of structural properties of tonal harmony. ",
    "url": "https://arxiv.org/abs/2201.08796",
    "authors": [
      "Th\u00e9o Frottier",
      "Bertrand Georgeot",
      "Olivier Giraud"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2201.08802",
    "title": "Deconfounding to Explanation Evaluation in Graph Neural Networks",
    "abstract": "Explainability of graph neural networks (GNNs) aims to answer ``Why the GNN made a certain prediction?'', which is crucial to interpret the model prediction. The feature attribution framework distributes a GNN's prediction to its input features (e.g., edges), identifying an influential subgraph as the explanation. When evaluating the explanation (i.e., subgraph importance), a standard way is to audit the model prediction based on the subgraph solely. However, we argue that a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. Furthermore, with an in-depth causal analysis, we find the OOD effect acts as the confounder, which brings spurious associations between the subgraph importance and model prediction, making the evaluation less reliable. In this work, we propose Deconfounded Subgraph Evaluation (DSE) which assesses the causal effect of an explanatory subgraph on the model prediction. While the distribution shift is generally intractable, we employ the front-door adjustment and introduce a surrogate variable of the subgraphs. Specifically, we devise a generative model to generate the plausible surrogates that conform to the data distribution, thus approaching the unbiased estimation of subgraph importance. Empirical results demonstrate the effectiveness of DSE in terms of explanation fidelity. ",
    "url": "https://arxiv.org/abs/2201.08802",
    "authors": [
      "Ying-Xin",
      "Xiang Wang",
      "An Zhang",
      "Xia Hu",
      "Fuli Feng",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08810",
    "title": "GAP-Gen: Guided Automatic Python Code Generation",
    "abstract": "Automatic code generation from natural language descriptions can be highly beneficial during the process of software development. In this work, we propose GAP-Gen, an automatic code generation method guided by Python syntactic constraints and semantic constraints. We first introduce Python syntactic constraints in the form of Syntax-Flow, which is a simplified version of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract Syntax Tree but maintaining the crucial syn-tactic information of Python code. In addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable and function names consistently throughout the code. In our work, rather than pre-training, we focus on modifying the fine-tuning process which reduces computational requirements but retains high generation performance on automatic Python code generation task. GAP-Gen fine-tunes the transformer-based language models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet, CodeSearchNet AdvTest, and Code-Docstring-Corpus from EdinburghNLP. Our experiments show that GAP-Gen achieves better results on automatic Python code generation task than previous works ",
    "url": "https://arxiv.org/abs/2201.08810",
    "authors": [
      "Junchen Zhao",
      "Yurun Song",
      "Junlin Wang",
      "Ian G. Harris"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.08812",
    "title": "Realtime 3D Object Detection for Headsets",
    "abstract": "Mobile headsets should be capable of understanding 3D physical environments to offer a truly immersive experience for augmented/mixed reality (AR/MR). However, their small form-factor and limited computation resources make it extremely challenging to execute in real-time 3D vision algorithms, which are known to be more compute-intensive than their 2D counterparts. In this paper, we propose DeepMix, a mobility-aware, lightweight, and hybrid3D object detection framework for improving the user experience of AR/MR on mobile headsets. Motivated by our analysis and evaluation of state-of-the-art 3D object detection models, DeepMix intelligently combines edge-assisted 2D object detection and novel, on-device 3D bounding box estimations that leverage depth data captured by headsets. This leads to low end-to-end latency and significantly boosts detection accuracy in mobile scenarios. ",
    "url": "https://arxiv.org/abs/2201.08812",
    "authors": [
      "Yongjie Guan",
      "Xueyu Hou",
      "Nan Wu",
      "Bo Han",
      "Tao Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08813",
    "title": "Active Predictive Coding Networks: A Neural Solution to the Problem of  Learning Reference Frames and Part-Whole Hierarchies",
    "abstract": "We introduce Active Predictive Coding Networks (APCNs), a new class of neural networks that solve a major problem posed by Hinton and others in the fields of artificial intelligence and brain modeling: how can neural networks learn intrinsic reference frames for objects and parse visual scenes into part-whole hierarchies by dynamically allocating nodes in a parse tree? APCNs address this problem by using a novel combination of ideas: (1) hypernetworks are used for dynamically generating recurrent neural networks that predict parts and their locations within intrinsic reference frames conditioned on higher object-level embedding vectors, and (2) reinforcement learning is used in conjunction with backpropagation for end-to-end learning of model parameters. The APCN architecture lends itself naturally to multi-level hierarchical learning and is closely related to predictive coding models of cortical function. Using the MNIST, Fashion-MNIST and Omniglot datasets, we demonstrate that APCNs can (a) learn to parse images into part-whole hierarchies, (b) learn compositional representations, and (c) transfer their knowledge to unseen classes of objects. With their ability to dynamically generate parse trees with part locations for objects, APCNs offer a new framework for explainable AI that leverages advances in deep learning while retaining interpretability and compositionality. ",
    "url": "https://arxiv.org/abs/2201.08813",
    "authors": [
      "Dimitrios C. Gklezakos",
      "Rajesh P. N. Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08821",
    "title": "Representing Long-Range Context for Graph Neural Networks with Global  Attention",
    "abstract": "Graph neural networks are powerful architectures for structured datasets. However, current methods struggle to represent long-range dependencies. Scaling the depth or width of GNNs is insufficient to broaden receptive fields as larger GNNs encounter optimization instabilities such as vanishing gradients and representation oversmoothing, while pooling-based approaches have yet to become as universally useful as in computer vision. In this work, we propose the use of Transformer-based self-attention to learn long-range pairwise relationships, with a novel \"readout\" mechanism to obtain a global graph embedding. Inspired by recent computer vision results that find position-invariant attention performant in learning long-range relationships, our method, which we call GraphTrans, applies a permutation-invariant Transformer module after a standard GNN module. This simple architecture leads to state-of-the-art results on several graph classification tasks, outperforming methods that explicitly encode graph structure. Our results suggest that purely-learning-based approaches without graph structure may be suitable for learning high-level, long-range relationships on graphs. Code for GraphTrans is available at https://github.com/ucbrise/graphtrans. ",
    "url": "https://arxiv.org/abs/2201.08821",
    "authors": [
      "Zhanghao Wu",
      "Paras Jain",
      "Matthew A. Wright",
      "Azalia Mirhoseini",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08831",
    "title": "Reliable Detection of Doppelg\u00e4ngers based on Deep Face Representations",
    "abstract": "Doppelg\\\"angers (or lookalikes) usually yield an increased probability of false matches in a facial recognition system, as opposed to random face image pairs selected for non-mated comparison trials. In this work, we assess the impact of doppelg\\\"angers on the HDA Doppelg\\\"anger and Disguised Faces in The Wild databases using a state-of-the-art face recognition system. It is found that doppelg\\\"anger image pairs yield very high similarity scores resulting in a significant increase of false match rates. Further, we propose a doppelg\\\"anger detection method which distinguishes doppelg\\\"angers from mated comparison trials by analysing differences in deep representations obtained from face image pairs. The proposed detection system employs a machine learning-based classifier, which is trained with generated doppelg\\\"anger image pairs utilising face morphing techniques. Experimental evaluations conducted on the HDA Doppelg\\\"anger and Look-Alike Face databases reveal a detection equal error rate of approximately 2.7% for the task of separating mated authentication attempts from doppelg\\\"angers. ",
    "url": "https://arxiv.org/abs/2201.08831",
    "authors": [
      "Christian Rathgeb",
      "Daniel Fischer",
      "Pawel Drozdowski",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08837",
    "title": "Marginal Effects for Non-Linear Prediction Functions",
    "abstract": "Beta coefficients for linear regression models represent the ideal form of an interpretable feature effect. However, for non-linear models and especially generalized linear models, the estimated coefficients cannot be interpreted as a direct feature effect on the predicted outcome. Hence, marginal effects are typically used as approximations for feature effects, either in the shape of derivatives of the prediction function or forward differences in prediction due to a change in a feature value. While marginal effects are commonly used in many scientific fields, they have not yet been adopted as a model-agnostic interpretation method for machine learning models. This may stem from their inflexibility as a univariate feature effect and their inability to deal with the non-linearities found in black box models. We introduce a new class of marginal effects termed forward marginal effects. We argue to abandon derivatives in favor of better-interpretable forward differences. Furthermore, we generalize marginal effects based on forward differences to multivariate changes in feature values. To account for the non-linearity of prediction functions, we introduce a non-linearity measure for marginal effects. We argue against summarizing feature effects of a non-linear prediction function in a single metric such as the average marginal effect. Instead, we propose to partition the feature space to compute conditional average marginal effects on feature subspaces, which serve as conditional feature effect estimates. ",
    "url": "https://arxiv.org/abs/2201.08837",
    "authors": [
      "Christian A. Scholbeck",
      "Giuseppe Casalicchio",
      "Christoph Molnar",
      "Bernd Bischl",
      "Christian Heumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": "Volumetric neural rendering methods like NeRF generate high-quality view synthesis results but are optimized per-scene leading to prohibitive reconstruction time. On the other hand, deep multi-view stereo methods can quickly reconstruct scene geometry via direct network inference. Point-NeRF combines the advantages of these two approaches by using neural 3D point clouds, with associated neural features, to model a radiance field. Point-NeRF can be rendered efficiently by aggregating neural point features near scene surfaces, in a ray marching-based rendering pipeline. Moreover, Point-NeRF can be initialized via direct inference of a pre-trained deep network to produce a neural point cloud; this point cloud can be finetuned to surpass the visual quality of NeRF with 30X faster training time. Point-NeRF can be combined with other 3D reconstruction methods and handles the errors and outliers in such methods via a novel pruning and growing mechanism. ",
    "url": "https://arxiv.org/abs/2201.08845",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08388",
    "title": "Steerable Pyramid Transform Enables Robust Left Ventricle Quantification",
    "abstract": "Although multifarious variants of convolutional neural networks (CNNs) have proved successful in cardiac index quantification, they seem vulnerable to mild input perturbations, e.g., spatial transformations, image distortions, and adversarial attacks. Such brittleness erodes our trust in CNN-based automated diagnosis of various cardiovascular diseases. In this work, we describe a simple and effective method to learn robust CNNs for left ventricle (LV) quantification, including cavity and myocardium areas, directional dimensions, and regional wall thicknesses. The key to the success of our approach is the use of the biologically-inspired steerable pyramid transform (SPT) as fixed front-end processing, which brings three computational advantages to LV quantification. First, the basis functions of SPT match the anatomical structure of the LV as well as the geometric characteristics of the estimated indices. Second, SPT enables sharing a CNN across different orientations as a form of parameter regularization, and explicitly captures the scale variations of the LV in a natural way. Third, the residual highpass subband can be conveniently discarded to further encourage robust feature learning. A concise and effective metric, named Robustness Ratio, is proposed to evaluate the robustness under various input perturbations. Extensive experiments on 145 cardiac sequences show that our SPT-augmented method performs favorably against state-of-the-art algorithms in terms of prediction accuracy, but is significantly more robust under input perturbations. ",
    "url": "https://arxiv.org/abs/2201.08388",
    "authors": [
      "Xiangyang Zhu",
      "Kede Ma",
      "Wufeng Xue"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08418",
    "title": "SoftDropConnect (SDC) -- Effective and Efficient Quantification of the  Network Uncertainty in Deep MR Image Analysis",
    "abstract": "Recently, deep learning has achieved remarkable successes in medical image analysis. Although deep neural networks generate clinically important predictions, they have inherent uncertainty. Such uncertainty is a major barrier to report these predictions with confidence. In this paper, we propose a novel yet simple Bayesian inference approach called SoftDropConnect (SDC) to quantify the network uncertainty in medical imaging tasks with gliomas segmentation and metastases classification as initial examples. Our key idea is that during training and testing SDC modulates network parameters continuously so as to allow affected information processing channels still in operation, instead of disabling them as Dropout or DropConnet does. When compared with three popular Bayesian inference methods including Bayes By Backprop, Dropout, and DropConnect, our SDC method (SDC-W after optimization) outperforms the three competing methods with a substantial margin. Quantitatively, our proposed method generates results withsubstantially improved prediction accuracy (by 10.0%, 5.4% and 3.7% respectively for segmentation in terms of dice score; by 11.7%, 3.9%, 8.7% on classification in terms of test accuracy) and greatly reduced uncertainty in terms of mutual information (by 64%, 33% and 70% on segmentation; 98%, 88%, and 88% on classification). Our approach promises to deliver better diagnostic performance and make medical AI imaging more explainable and trustworthy. ",
    "url": "https://arxiv.org/abs/2201.08418",
    "authors": [
      "Qing Lyu",
      "Christopher T. Whitlow",
      "Ge Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2201.08443",
    "title": "Diversifying the Genomic Data Science Research Community",
    "abstract": "Over the last 20 years, there has been an explosion of genomic data collected for disease association, functional analyses, and other large-scale discoveries. At the same time, there have been revolutions in cloud computing that enable computational and data science research, while making data accessible to anyone with a web browser and an internet connection. However, students at institutions with limited resources have received relatively little exposure to curricula or professional development opportunities that lead to careers in genomic data science. To broaden participation in genomics research, the scientific community needs to support students, faculty, and administrators at Underserved Institutions (UIs) including Community Colleges, Historically Black Colleges and Universities, Hispanic-Serving Institutions, and Tribal Colleges and Universities in taking advantage of these tools in local educational and research programs. We have formed the Genomic Data Science Community Network (this http URL) to identify opportunities and support broadening access to cloud-enabled genomic data science. Here, we provide a summary of the priorities for faculty members at UIs, as well as administrators, funders, and R1 researchers to consider as we create a more diverse genomic data science community. ",
    "url": "https://arxiv.org/abs/2201.08443",
    "authors": [
      "Genomic Data Science Community Network",
      "Rosa Alcazar",
      "Maria Alvarez",
      "Rachel Arnold",
      "Mentewab Ayalew",
      "Lyle G. Best",
      "Michael C. Campbell",
      "Kamal Chowdhury",
      "Katherine E. L. Cox",
      "Christina Daulton",
      "Youping Deng",
      "Carla Easter",
      "Karla Fuller",
      "Shazia Tabassum Hakim",
      "Ava M. Hoffman",
      "Natalie Kucher",
      "Andrew Lee",
      "Joslynn Lee",
      "Jeffrey T. Leek",
      "Robert Meller",
      "Loyda B. M\u00e9ndez",
      "Miguel P. M\u00e9ndez-Gonz\u00e1lez",
      "Stephen Mosher",
      "Michele Nishiguchi",
      "Siddharth Pratap",
      "Tiffany Rolle",
      "Sourav Roy",
      "Rachel Saidi",
      "Michael C. Schatz",
      "Shurjo Sen",
      "James Sniezek",
      "Edu Suarez Martinez",
      "Frederick Tan",
      "Jennifer Vessio",
      "Karriem Watson",
      "Wendy Westbroek"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.08596",
    "title": "Nilpotent dynamics on signed interaction graphs and weak converses of  Thomas' rules",
    "abstract": "A finite dynamical system with $n$ components is a function $f:X\\to X$ where $X=X_1\\times\\dots\\times X_n$ is a product of $n$ finite intervals of integers. The structure of such a system $f$ is represented by a signed digraph $G$, called interaction graph: there are $n$ vertices, one per component, and the signed arcs describe the positive and negative influences between them. Finite dynamical systems are usual models for gene networks. In this context, it is often assumed that $f$ is {\\em degree-bounded}, that is, the size of each $X_i$ is at most the out-degree of $i$ in $G$ plus one. Assuming that $G$ is connected and that $f$ is degree-bounded, we prove the following: if $G$ is not a cycle, then $f^{n+1}$ may be a constant. In that case, $f$ describes a very simple dynamics: a global convergence toward a unique fixed point in $n+1$ iterations. This shows that, in the degree-bounded case, the fact that $f$ describes a complex dynamics {\\em cannot} be deduced from its interaction graph. We then widely generalize the above result, obtaining, as immediate consequences, other limits on what can be deduced from the interaction graph only, as the following weak converses of Thomas' rules: if $G$ is connected and has a positive (negative) cycle, then $f$ may have two (no) fixed points. ",
    "url": "https://arxiv.org/abs/2201.08596",
    "authors": [
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2201.08600",
    "title": "Positive and negative cycles in Boolean networks",
    "abstract": "We review and discuss some results about the influence of positive and negative feedback cycles in asynchronous Boolean networks. These results merge several ideas of Thomas: positive and negative feedback cycles have been largely emphasized by Thomas, through the so called Thomas' rules, and asynchronous Boolean networks have been introduced by Thomas as a model for the dynamics of gene networks, which is nowadays very popular. ",
    "url": "https://arxiv.org/abs/2201.08600",
    "authors": [
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2201.08652",
    "title": "A phase transition for finding needles in nonlinear haystacks with LASSO  artificial neural networks",
    "abstract": "To fit sparse linear associations, a LASSO sparsity inducing penalty with a single hyperparameter provably allows to recover the important features (needles) with high probability in certain regimes even if the sample size is smaller than the dimension of the input vector (haystack). More recently learners known as artificial neural networks (ANN) have shown great successes in many machine learning tasks, in particular fitting nonlinear associations. Small learning rate, stochastic gradient descent algorithm and large training set help to cope with the explosion in the number of parameters present in deep neural networks. Yet few ANN learners have been developed and studied to find needles in nonlinear haystacks. Driven by a single hyperparameter, our ANN learner, like for sparse linear associations, exhibits a phase transition in the probability of retrieving the needles, which we do not observe with other ANN learners. To select our penalty parameter, we generalize the universal threshold of Donoho and Johnstone (1994) which is a better rule than the conservative (too many false detections) and expensive cross-validation. In the spirit of simulated annealing, we propose a warm-start sparsity inducing algorithm to solve the high-dimensional, non-convex and non-differentiable optimization problem. We perform precise Monte Carlo simulations to show the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2201.08652",
    "authors": [
      "Xiaoyu Ma",
      "Sylvain Sardy",
      "Nick Hengartner",
      "Nikolai Bobenko",
      "Yen Ting Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08668",
    "title": "Clipped DeepControl: deep neural network two-dimensional pulse design  with an amplitude constraint layer",
    "abstract": "Advanced radio-frequency pulse design used in magnetic resonance imaging has recently been demonstrated with deep learning of (convolutional) neural networks and reinforcement learning. For two-dimensionally selective radio-frequency pulses, the (convolutional) neural network pulse prediction time (few milliseconds) was in comparison more than three orders of magnitude faster than the conventional optimal control computation. The network pulses were from the supervised training capable of compensating scan-subject dependent inhomogeneities of B0 and B+1 fields. Unfortunately, the network presented with a non-negligible percentage of pulse amplitude overshoots in the test subset, despite the optimal control pulses used in training were fully constrained. Here, we have extended the convolutional neural network with a custom-made clipping layer that completely eliminates the risk of pulse amplitude overshoots, while preserving the ability to compensate the inhomogeneous field conditions. ",
    "url": "https://arxiv.org/abs/2201.08668",
    "authors": [
      "Mads Sloth Vinding",
      "Torben Ellegaard Lund"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.08747",
    "title": "Inferring Brain Dynamics via Multimodal Joint Graph Representation  EEG-fMRI",
    "abstract": "Recent studies have shown that multi-modeling methods can provide new insights into the analysis of brain components that are not possible when each modality is acquired separately. The joint representations of different modalities is a robust model to analyze simultaneously acquired electroencephalography and functional magnetic resonance imaging (EEG-fMRI). Advances in precision instruments have given us the ability to observe the spatiotemporal neural dynamics of the human brain through non-invasive neuroimaging techniques such as EEG & fMRI. Nonlinear fusion methods of streams can extract effective brain components in different dimensions of temporal and spatial. Graph-based analyzes, which have many similarities to brain structure, can overcome the complexities of brain mapping analysis. Throughout, we outline the correlations of several different media in time shifts from one source with graph-based and deep learning methods. Determining overlaps can provide a new perspective for diagnosing functional changes in neuroplasticity studies. ",
    "url": "https://arxiv.org/abs/2201.08747",
    "authors": [
      "Jalal Mirakhorli"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08825",
    "title": "Short-Range Microwave Networks to Scale Superconducting Quantum  Computation",
    "abstract": "A core challenge for superconducting quantum computers is to scale up the number of qubits in each processor without increasing noise or cross-talk. Distributing a quantum computer across nearby small qubit arrays, known as chiplets, could solve many problems associated with size. We propose a chiplet architecture over microwave links with potential to exceed monolithic performance on near-term hardware. We model and evaluate the chiplet architecture in a way that bridges the physical and network layers. We find concrete evidence that distributed quantum computing may accelerate the path toward useful and ultimately scalable quantum computers. In the long-term, short-range networks may underlie quantum computers just as local area networks underlie classical datacenters and supercomputers today. ",
    "url": "https://arxiv.org/abs/2201.08825",
    "authors": [
      "Nicholas LaRacuente",
      "Kaitlin N. Smith",
      "Poolad Imany",
      "Kevin L. Silverman",
      "Frederic T. Chong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:1901.05031",
    "title": "Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs",
    "abstract": " Title: Analysis and algorithms for $\\ell_p$-based semi-supervised learning on  graphs ",
    "url": "https://arxiv.org/abs/1901.05031",
    "authors": [
      "Mauricio Flores Rios",
      "Jeff Calder",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:1904.05269",
    "title": "Planar graphs have bounded nonrepetitive chromatic number",
    "abstract": " Title: Planar graphs have bounded nonrepetitive chromatic number ",
    "url": "https://arxiv.org/abs/1904.05269",
    "authors": [
      "Vida Dujmovi\u0107",
      "Louis Esperet",
      "Gwena\u00ebl Joret",
      "Bartosz Walczak",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1906.00398",
    "title": "Cost-sensitive Boosting Pruning Trees for depression detection on  Twitter",
    "abstract": " Comments: 15 pages, 7 figures, Accepted by IEEE transactions on Affective Computing ",
    "url": "https://arxiv.org/abs/1906.00398",
    "authors": [
      "Lei Tong",
      "Zhihua Liu",
      "Zheheng Jiang",
      "Feixiang Zhou",
      "Long Chen",
      "Jialin Lyu",
      "Xiangrong Zhang",
      "Qianni Zhang",
      "Abdul Sadka Senior",
      "Yinhai Wang",
      "Ling Li",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.13823",
    "title": "Preventing Value Function Collapse in Ensemble {Q}-Learning by  Maximizing Representation Diversity",
    "abstract": " Comments: Accepted in Deep Reinforcement Learning Workshop at NeurIPS 2020 ",
    "url": "https://arxiv.org/abs/2006.13823",
    "authors": [
      "Hassam Ullah Sheikh",
      "Ladislau B\u00f6l\u00f6ni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.12808",
    "title": "Pairwise Representation Learning for Event Coreference",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2010.12808",
    "authors": [
      "Xiaodong Yu",
      "Wenpeng Yin",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2012.00489",
    "title": "Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information",
    "abstract": " Title: Deep Gravity: enhancing mobility flows generation with deep neural  networks and geographic information ",
    "url": "https://arxiv.org/abs/2012.00489",
    "authors": [
      "Filippo Simini",
      "Gianni Barlacchi",
      "Massimiliano Luca",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2012.08752",
    "title": "Graph Neural Networks: Taxonomy, Advances and Trends",
    "abstract": " Comments: 42 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2012.08752",
    "authors": [
      "Yu Zhou",
      "Haixia Zheng",
      "Xin Huang",
      "Shufeng Hao",
      "Dengao Li",
      "Jumin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.01466",
    "title": "Individual dynamic prediction of clinical endpoint from large  dimensional longitudinal biomarker history: a landmark approach",
    "abstract": " Title: Individual dynamic prediction of clinical endpoint from large  dimensional longitudinal biomarker history: a landmark approach ",
    "url": "https://arxiv.org/abs/2102.01466",
    "authors": [
      "Anthony Devaux",
      "Robin Genuer",
      "Karine P\u00e9r\u00e8s",
      "C\u00e9cile Proust-Lima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11535",
    "title": "Particle Cloud Generation with Message Passing Generative Adversarial  Networks",
    "abstract": " Comments: 14 pages, 4 figures, 2 tables, and an 8 page appendix. Accepted to the Thirty-fifth Conference on Neural Information Processing Systems ",
    "url": "https://arxiv.org/abs/2106.11535",
    "authors": [
      "Raghav Kansal",
      "Javier Duarte",
      "Hao Su",
      "Breno Orzari",
      "Thiago Tomei",
      "Maurizio Pierini",
      "Mary Touranakou",
      "Jean-Roch Vlimant",
      "Dimitrios Gunopulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2107.00068",
    "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning  (With Outliers) Problems",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2107.00068",
    "authors": [
      "Zixiu Wang",
      "Yiwen Guo",
      "Hu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.09139",
    "title": "Constrained Policy Gradient Method for Safe and Fast Reinforcement  Learning: a Neural Tangent Kernel Based Approach",
    "abstract": " Title: Constrained Policy Gradient Method for Safe and Fast Reinforcement  Learning: a Neural Tangent Kernel Based Approach ",
    "url": "https://arxiv.org/abs/2107.09139",
    "authors": [
      "Bal\u00e1zs Varga",
      "Bal\u00e1zs Kulcs\u00e1r",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.06040",
    "title": "Knowledge Graph Reasoning with Relational Digraph",
    "abstract": " Title: Knowledge Graph Reasoning with Relational Digraph ",
    "url": "https://arxiv.org/abs/2108.06040",
    "authors": [
      "Yongqi Zhang",
      "Quanming Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.00161",
    "title": "Simultaneous Neural Network Approximation for Smooth Functions",
    "abstract": " Title: Simultaneous Neural Network Approximation for Smooth Functions ",
    "url": "https://arxiv.org/abs/2109.00161",
    "authors": [
      "Sean Hon",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.08009",
    "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without  Retraining",
    "abstract": " Comments: ICLR Accepted version, 28 pages, 23 figures ",
    "url": "https://arxiv.org/abs/2110.08009",
    "authors": [
      "Ahmed Imtiaz Humayun",
      "Randall Balestriero",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.08743",
    "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
    "abstract": " Comments: To appear at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.08743",
    "authors": [
      "Yuxian Meng",
      "Shi Zong",
      "Xiaoya Li",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.14300",
    "title": "Multi-Agent Reinforcement Learning for Active Voltage Control on Power  Distribution Networks",
    "abstract": " Comments: Published on NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2110.14300",
    "authors": [
      "Jianhong Wang",
      "Wangkun Xu",
      "Yunjie Gu",
      "Wenbin Song",
      "Tim C. Green"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2111.04718",
    "title": "Directional Message Passing on Molecular Graphs via Synthetic  Coordinates",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2111.04718",
    "authors": [
      "Johannes Klicpera",
      "Chandan Yeshwanth",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2112.01218",
    "title": "GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence  Analyses",
    "abstract": " Title: GraphCode2Vec: Generic Code Embedding via Lexical and Program Dependence  Analyses ",
    "url": "https://arxiv.org/abs/2112.01218",
    "authors": [
      "Wei Ma",
      "Mengjie Zhao",
      "Ezekiel Soremekun",
      "Qiang Hu",
      "Jie Zhang",
      "Mike Papadakis",
      "Maxime Cordy",
      "Xiaofei Xie",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.09245",
    "title": "Automated Deep Learning: Neural Architecture Search Is Not the End",
    "abstract": " Comments: 65 pages, 9 tables, 4 figures ",
    "url": "https://arxiv.org/abs/2112.09245",
    "authors": [
      "Xuanyi Dong",
      "David Jacob Kedziora",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12268",
    "title": "An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG",
    "abstract": " Title: An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG ",
    "url": "https://arxiv.org/abs/2112.12268",
    "authors": [
      "Carla Mascia",
      "Enrico Piccione",
      "Massimiliano Sala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2201.01391",
    "title": "Self-Supervised Approach to Addressing Zero-Shot Learning Problem",
    "abstract": " Title: Self-Supervised Approach to Addressing Zero-Shot Learning Problem ",
    "url": "https://arxiv.org/abs/2201.01391",
    "authors": [
      "Ademola Okerinde",
      "Sam Hoggatt",
      "Divya Vani Lakkireddy",
      "Nolan Brubaker",
      "William Hsu",
      "Lior Shamir",
      "Brian Spiesman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04122",
    "title": "In Defense of the Unitary Scalarization for Deep Multi-Task Learning",
    "abstract": " Title: In Defense of the Unitary Scalarization for Deep Multi-Task Learning ",
    "url": "https://arxiv.org/abs/2201.04122",
    "authors": [
      "Vitaly Kurin",
      "Alessandro De Palma",
      "Ilya Kostrikov",
      "Shimon Whiteson",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05624",
    "title": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "abstract": " Title: Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next ",
    "url": "https://arxiv.org/abs/2201.05624",
    "authors": [
      "Salvatore Cuomo",
      "Vincenzo Schiano di Cola",
      "Fabio Giampaolo",
      "Gianluigi Rozza",
      "Maizar Raissi",
      "Francesco Piccialli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2201.05809",
    "title": "Weighting and Pruning based Ensemble Deep Random Vector Functional Link  Network for Tabular Data Classification",
    "abstract": " Comments: 8 tables, 8 figures, 31 pages ",
    "url": "https://arxiv.org/abs/2201.05809",
    "authors": [
      "Qiushi Shi",
      "Ponnuthurai Nagaratnam Suganthan",
      "Rakesh Katuwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.05810",
    "title": "Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for  Flexible Video Compressive Sensing",
    "abstract": " Title: Two-Stage is Enough: A Concise Deep Unfolding Reconstruction Network for  Flexible Video Compressive Sensing ",
    "url": "https://arxiv.org/abs/2201.05810",
    "authors": [
      "Siming Zheng",
      "Xiaoyu Yang",
      "Xin Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.07341",
    "title": "Learning grammar with a divide-and-concur neural network",
    "abstract": " Title: Learning grammar with a divide-and-concur neural network ",
    "url": "https://arxiv.org/abs/2201.07341",
    "authors": [
      "Sean Deyo",
      "Veit Elser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ]
  },
  {
    "id": "arXiv:2201.07989",
    "title": "Self-supervised Video Representation Learning with Cascade Positive  Retrieval",
    "abstract": " Title: Self-supervised Video Representation Learning with Cascade Positive  Retrieval ",
    "url": "https://arxiv.org/abs/2201.07989",
    "authors": [
      "Cheng-En Wu",
      "Farley Lai",
      "Yu Hen Hu",
      "Asim Kadav"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08022",
    "title": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks",
    "abstract": " Title: HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks ",
    "url": "https://arxiv.org/abs/2201.08022",
    "authors": [
      "Su Zheng",
      "Zhen Li",
      "Yao Lu",
      "Jingbo Gao",
      "Jide Zhang",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08281",
    "title": "Symplectic Momentum Neural Networks -- Using Discrete Variational  Mechanics as a prior in Deep Learning",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2201.08281",
    "authors": [
      "Saul Santos",
      "Monica Ekal",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08321",
    "title": "TOAST: Trajectory Optimization and Simultaneous Tracking using Shared  Neural Network Dynamics",
    "abstract": " Comments: Our video can be found at this https URL ",
    "url": "https://arxiv.org/abs/2201.08321",
    "authors": [
      "Taekyung Kim",
      "Hojin Lee",
      "Seongil Hong",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  }
]