[
  {
    "id": "arXiv:2201.10609",
    "title": "Exploiting Hybrid Models of Tensor-Train Networks for Spoken Command  Recognition",
    "abstract": "This work aims to design a low complexity spoken command recognition (SCR) system by considering different trade-offs between the number of model parameters and classification accuracy. More specifically, we exploit a deep hybrid architecture of a tensor-train (TT) network to build an end-to-end SRC pipeline. Our command recognition system, namely CNN+(TT-DNN), is composed of convolutional layers at the bottom for spectral feature extraction and TT layers at the top for command classification. Compared with a traditional end-to-end CNN baseline for SCR, our proposed CNN+(TT-DNN) model replaces fully connected (FC) layers with TT ones and it can substantially reduce the number of model parameters while maintaining the baseline performance of the CNN model. We initialize the CNN+(TT-DNN) model in a randomized manner or based on a well-trained CNN+DNN, and assess the CNN+(TT-DNN) models on the Google Speech Command Dataset. Our experimental results show that the proposed CNN+(TT-DNN) model attains a competitive accuracy of 96.31% with 4 times fewer model parameters than the CNN model. Furthermore, the CNN+(TT-DNN) model can obtain a 97.2% accuracy when the number of parameters is increased. ",
    "url": "https://arxiv.org/abs/2201.10609",
    "authors": [
      "Jun Qi",
      "Javier Tejedor"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.10620",
    "title": "Structural importance and evolution: an application to financial  transaction networks",
    "abstract": "A fundamental problem in the study of networks is the identification of important nodes. This is typically achieved using centrality metrics, which rank nodes in terms of their position in the network. This approach works well for static networks, that do not change over time, but does not consider the dynamics of the network. Here we propose instead to measure the importance of a node based on how much a change to its strength will impact the global structure of the network, which we measure in terms of the spectrum of its adjacency matrix. We apply our method to the identification of important nodes in equity transaction networks, and we show that, while it can still be computed from a static network, our measure is a good predictor of nodes subsequently transacting. This implies that static representations of temporal networks can contain information about their dynamics. ",
    "url": "https://arxiv.org/abs/2201.10620",
    "authors": [
      "Isobel Seabrook",
      "Paolo Barucca",
      "Fabio Caccioli"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2201.10642",
    "title": "An Efficient Deep CNN Design for EH Short-Packet Communications in  Multihop Cognitive IoT Networks",
    "abstract": "In this paper, we design an efficient deep convolutional neural network (CNN) to improve and predict the performance of energy harvesting (EH) short-packet communications in multi-hop cognitive Internet-of-Things (IoT) networks. Specifically, we propose a Sum-EH scheme that allows IoT nodes to harvest energy from either a power beacon or primary transmitters to improve not only packet transmissions but also energy harvesting capabilities. We then build a novel deep CNN framework with feature enhancement-collection blocks based on the proposed Sum-EH scheme to simultaneously estimate the block error rate (BLER) and throughput with high accuracy and low execution time. Simulation results show that the proposed CNN framework achieves almost exactly the BLER and throughput of Sum-EH one, while it considerably reduces computational complexity, suggesting a real-time setting for IoT systems under complex scenarios. Moreover, the designed CNN model achieves the root-mean-square-error (RMSE) of ${1.33\\times10^{-2}}$ on the considered dataset, which exhibits the lowest RMSE compared to the deep neural network and state-of-the-art machine learning approaches. ",
    "url": "https://arxiv.org/abs/2201.10642",
    "authors": [
      "Toan-Van Nguyen",
      "Thien Huynh-The",
      "Van-Dinh Nguyen",
      "Daniel Benevides da Costa",
      "Rose Qingyang Hu",
      "Beongku An"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.10646",
    "title": "Coded Caching with Heterogeneous User Profiles",
    "abstract": "Coded caching utilizes pre-fetching during off-peak hours and multi-casting for delivery in order to balance the traffic load in communication networks. Several works have studied the achievable peak and average rates under different conditions: variable file lengths or popularities, variable cache sizes, decentralized networks, etc. However, very few have considered the possibility of heterogeneous user profiles, despite modern content providers are investing heavily in categorizing users according to their habits and preferences. This paper proposes three coded caching schemes with uncoded pre-fetching for scenarios where end users are grouped into classes with different file demand sets (FDS). One scheme ignores the difference between the classes, another ignores the intersection between them and the third decouples the delivery of files common to all FDS from those unique to a single class. The transmission rates of the three schemes are compared with a lower bound to evaluate their gap to optimality, and with each other to show that each scheme can outperform the other two when certain conditions are met. ",
    "url": "https://arxiv.org/abs/2201.10646",
    "authors": [
      "Ciyuan Zhang",
      "Su Wang",
      "Vaneet Aggarwal",
      "Borja Peleato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.10649",
    "title": "Attentive Task Interaction Network for Multi-Task Learning",
    "abstract": "Multitask learning (MTL) has recently gained a lot of popularity as a learning paradigm that can lead to improved per-task performance while also using fewer per-task model parameters compared to single task learning. One of the biggest challenges regarding MTL networks involves how to share features across tasks. To address this challenge, we propose the Attentive Task Interaction Network (ATI-Net). ATI-Net employs knowledge distillation of the latent features for each task, then combines the feature maps to provide improved contextualized information to the decoder. This novel approach to introducing knowledge distillation into an attention based multitask network outperforms state of the art MTL baselines such as the standalone MTAN and PAD-Net, with roughly the same number of model parameters. ",
    "url": "https://arxiv.org/abs/2201.10649",
    "authors": [
      "Dimitrios Sinodinos",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10655",
    "title": "From an Authentication Question to a Public Social Event: Characterizing  Birthday Sharing on Twitter",
    "abstract": "Date of birth (DOB) has historically been considered as private information and safe to use for authentication, but recent years have seen a shift towards wide public sharing. In this work we characterize how modern social media users are approaching the sharing of birthday wishes publicly online. Over 45 days, we collected over 2.8M tweets wishing happy birthday to 724K Twitter accounts. For 50K accounts, their age was likely mentioned revealing their DOB, and 10% were protected accounts. Our findings show that the majority of both public and protected accounts seem to be accepting of their birthdays and DOB being revealed online by their friends even when they do not have it listed on their profiles. We further complemented our findings through a survey to measure awareness of DOB disclosure issues and how people think about sharing different types of birthday-related information. Our analysis shows that giving birthday wishes to others online is considered a celebration and many users are quite comfortable with it. This view matches the trend also seen in security where the use of DOB in authentication process is no longer considered best practice. ",
    "url": "https://arxiv.org/abs/2201.10655",
    "authors": [
      "Dilara Kek\u00fcll\u00fco\u011flu",
      "Walid Magdy",
      "Kami Vaniea"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2201.10661",
    "title": "$P_1$--Nonconforming Quadrilateral Finite Element Space with Periodic  Boundary Conditions: Part II. Application to the Nonconforming Heterogeneous  Multiscale Method",
    "abstract": "A homogenization approach is one of effective strategies to solve multiscale elliptic problems approximately. The finite element heterogeneous multiscale method (FEHMM) which is based on the finite element makes possible to simulate such process numerically. In this paper we introduce a FEHMM scheme for multiscale elliptic problems based on nonconforming spaces. In particular we use the noconforming element with the periodic boundary condition introduced in the companion paper. Theoretical analysis derives a priori error estimates in the standard Sobolev norms. Several numerical results which confirm our analysis are provided. ",
    "url": "https://arxiv.org/abs/2201.10661",
    "authors": [
      "Jaeryun Yim",
      "Dongwoo Sheen",
      "Imbo Sim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.10664",
    "title": "Do Neural Networks for Segmentation Understand Insideness?",
    "abstract": "The insideness problem is an aspect of image segmentation that consists of determining which pixels are inside and outside a region. Deep Neural Networks (DNNs) excel in segmentation benchmarks, but it is unclear if they have the ability to solve the insideness problem as it requires evaluating long-range spatial dependencies. In this paper, the insideness problem is analysed in isolation, without texture or semantic cues, such that other aspects of segmentation do not interfere in the analysis. We demonstrate that DNNs for segmentation with few units have sufficient complexity to solve insideness for any curve. Yet, such DNNs have severe problems with learning general solutions. Only recurrent networks trained with small images learn solutions that generalize well to almost any curve. Recurrent networks can decompose the evaluation of long-range dependencies into a sequence of local operations, and learning with small images alleviates the common difficulties of training recurrent networks with a large number of unrolling steps. ",
    "url": "https://arxiv.org/abs/2201.10664",
    "authors": [
      "Kimberly Villalobos",
      "Vilim \u0160tih",
      "Amineh Ahmadinejad",
      "Shobhita Sundaram",
      "Jamell Dozier",
      "Andrew Francl",
      "Frederico Azevedo",
      "Tomotake Sasaki",
      "Xavier Boix"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2201.10675",
    "title": "Virtual Adversarial Training for Semi-supervised Breast Mass  Classification",
    "abstract": "This study aims to develop a novel computer-aided diagnosis (CAD) scheme for mammographic breast mass classification using semi-supervised learning. Although supervised deep learning has achieved huge success across various medical image analysis tasks, its success relies on large amounts of high-quality annotations, which can be challenging to acquire in practice. To overcome this limitation, we propose employing a semi-supervised method, i.e., virtual adversarial training (VAT), to leverage and learn useful information underlying in unlabeled data for better classification of breast masses. Accordingly, our VAT-based models have two types of losses, namely supervised and virtual adversarial losses. The former loss acts as in supervised classification, while the latter loss aims at enhancing model robustness against virtual adversarial perturbation, thus improving model generalizability. To evaluate the performance of our VAT-based CAD scheme, we retrospectively assembled a total of 1024 breast mass images, with equal number of benign and malignant masses. A large CNN and a small CNN were used in this investigation, and both were trained with and without the adversarial loss. When the labeled ratios were 40% and 80%, VAT-based CNNs delivered the highest classification accuracy of 0.740 and 0.760, respectively. The experimental results suggest that the VAT-based CAD scheme can effectively utilize meaningful knowledge from unlabeled data to better classify mammographic breast mass images. ",
    "url": "https://arxiv.org/abs/2201.10675",
    "authors": [
      "Xuxin Chen",
      "Ximin Wang",
      "Ke Zhang",
      "Kar-Ming Fung",
      "Theresa C. Thai",
      "Kathleen Moore",
      "Robert S. Mannel",
      "Hong Liu",
      "Bin Zheng",
      "Yuchen Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.10683",
    "title": "Promises and Challenges of Causality for Ethical Machine Learning",
    "abstract": "In recent years, there has been increasing interest in causal reasoning for designing fair decision-making systems due to its compatibility with legal frameworks, interpretability for human stakeholders, and robustness to spurious correlations inherent in observational data, among other factors. The recent attention to causal fairness, however, has been accompanied with great skepticism due to practical and epistemological challenges with applying current causal fairness approaches in the literature. Motivated by the long-standing empirical work on causality in econometrics, social sciences, and biomedical sciences, in this paper we lay out the conditions for appropriate application of causal fairness under the \"potential outcomes framework.\" We highlight key aspects of causal inference that are often ignored in the causal fairness literature. In particular, we discuss the importance of specifying the nature and timing of interventions on social categories such as race or gender. Precisely, instead of postulating an intervention on immutable attributes, we propose a shift in focus to their perceptions and discuss the implications for fairness evaluation. We argue that such conceptualization of the intervention is key in evaluating the validity of causal assumptions and conducting sound causal analysis including avoiding post-treatment bias. Subsequently, we illustrate how causality can address the limitations of existing fairness metrics, including those that depend upon statistical correlations. Specifically, we introduce causal variants of common statistical notions of fairness, and we make a novel observation that under the causal framework there is no fundamental disagreement between different notions of fairness. Finally, we conduct extensive experiments where we demonstrate our approach for evaluating and mitigating unfairness, specially when post-treatment variables are present. ",
    "url": "https://arxiv.org/abs/2201.10683",
    "authors": [
      "Aida Rahmattalabi",
      "Alice Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.10693",
    "title": "Noise-robust voice conversion with domain adversarial training",
    "abstract": "Voice conversion has made great progress in the past few years under the studio-quality test scenario in terms of speech quality and speaker similarity. However, in real applications, test speech from source speaker or target speaker can be corrupted by various environment noises, which seriously degrade the speech quality and speaker similarity. In this paper, we propose a novel encoder-decoder based noise-robust voice conversion framework, which consists of a speaker encoder, a content encoder, a decoder, and two domain adversarial neural networks. Specifically, we integrate disentangling speaker and content representation technique with domain adversarial training technique. Domain adversarial training makes speaker representations and content representations extracted by speaker encoder and content encoder from clean speech and noisy speech in the same space, respectively. In this way, the learned speaker and content representations are noise-invariant. Therefore, the two noise-invariant representations can be taken as input by the decoder to predict the clean converted spectrum. The experimental results demonstrate that our proposed method can synthesize clean converted speech under noisy test scenarios, where the source speech and target speech can be corrupted by seen or unseen noise types during the training process. Additionally, both speech quality and speaker similarity are improved. ",
    "url": "https://arxiv.org/abs/2201.10693",
    "authors": [
      "Hongqiang Du",
      "Lei Xie",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.10703",
    "title": "Anomaly Detection via Reverse Distillation from One-Class Embedding",
    "abstract": "Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD).The representation discrepancy of anomalies in the teacher-student (T-S) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel T-S model consisting of a teacher encoder and a student decoder and introduce a simple yet effective \"reverse distillation\" paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multiscale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our T-S model. The obtained compact embedding effectively preserves essential information on normal patterns, but abandons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability. ",
    "url": "https://arxiv.org/abs/2201.10703",
    "authors": [
      "Hanqiu Deng",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10716",
    "title": "Neural Grapheme-to-Phoneme Conversion with Pre-trained Grapheme Models",
    "abstract": "Neural network models have achieved state-of-the-art performance on grapheme-to-phoneme (G2P) conversion. However, their performance relies on large-scale pronunciation dictionaries, which may not be available for a lot of languages. Inspired by the success of the pre-trained language model BERT, this paper proposes a pre-trained grapheme model called grapheme BERT (GBERT), which is built by self-supervised training on a large, language-specific word list with only grapheme information. Furthermore, two approaches are developed to incorporate GBERT into the state-of-the-art Transformer-based G2P model, i.e., fine-tuning GBERT or fusing GBERT into the Transformer model by attention. Experimental results on the Dutch, Serbo-Croatian, Bulgarian and Korean datasets of the SIGMORPHON 2021 G2P task confirm the effectiveness of our GBERT-based G2P models under both medium-resource and low-resource data conditions. ",
    "url": "https://arxiv.org/abs/2201.10716",
    "authors": [
      "Lu Dong",
      "Zhi-Qiang Guo",
      "Chao-Hong Tan",
      "Ya-Jun Hu",
      "Yuan Jiang",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.10734",
    "title": "Mitigating the Mutual Error Amplification for Semi-Supervised Object  Detection",
    "abstract": "Semi-supervised object detection (SSOD) has achieved substantial progress in recent years. However, it is observed that the performances of self-labeling SSOD methods remain limited. Based on our experimental analysis, we reveal that the reason behind such phenomenon lies in the mutual error amplification between the pseudo labels and the trained detector. In this study, we propose a Cross Teaching (CT) method, aiming to mitigate the mutual error amplification by introducing a rectification mechanism of pseudo labels. CT simultaneously trains multiple detectors with an identical structure but different parameter initialization. In contrast to existing mutual teaching methods that directly treat predictions from other detectors as pseudo labels, we propose the Label Rectification Module (LRM), where the bounding boxes predicted by one detector are rectified by using the corresponding boxes predicted by all other detectors with higher confidence scores. In this way, CT can enhance the pseudo label quality compared with self-labeling and existing mutual teaching methods, and reasonably mitigate the mutual error amplification. Over two popular detector structures, i.e., SSD300 and Faster-RCNN-FPN, the proposed CT method obtains consistent improvements and outperforms the state-of-the-art SSOD methods by 2.2% absolute mAP improvements on the Pascal VOC and MS-COCO benchmarks. The code is available at github.com/machengcheng2016/CrossTeaching-SSOD. ",
    "url": "https://arxiv.org/abs/2201.10734",
    "authors": [
      "Chengcheng Ma",
      "Xingjia Pan",
      "Qixiang Ye",
      "Fan Tang",
      "Yunhang Shen",
      "Ke Yan",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10736",
    "title": "A Joint Convolution Auto-encoder Network for Infrared and Visible Image  Fusion",
    "abstract": "Background: Leaning redundant and complementary relationships is a critical step in the human visual system. Inspired by the infrared cognition ability of crotalinae animals, we design a joint convolution auto-encoder (JCAE) network for infrared and visible image fusion. Methods: Our key insight is to feed infrared and visible pair images into the network simultaneously and separate an encoder stream into two private branches and one common branch, the private branch works for complementary features learning and the common branch does for redundant features learning. We also build two fusion rules to integrate redundant and complementary features into their fused feature which are then fed into the decoder layer to produce the final fused image. We detail the structure, fusion rule and explain its multi-task loss function. Results: Our JCAE network achieves good results in terms of both subjective effect and objective evaluation metrics. ",
    "url": "https://arxiv.org/abs/2201.10736",
    "authors": [
      "Zhancheng Zhang",
      "Yuanhao Gao",
      "Mengyu Xiong",
      "Xiaoqing Luo",
      "Xiao-Jun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "abstract": "Transformers have made remarkable progress towards modeling long-range dependencies within the medical image analysis domain. However, current transformer-based models suffer from several disadvantages: 1) existing methods fail to capture the important features of the images due to the naive tokenization scheme; 2) the models suffer from information loss because they only consider single-scale feature representations; and 3) the segmentation label maps generated by the models are not accurate enough without considering rich semantic contexts and anatomical textures. In this work, we present CA-GANformer, a novel type of generative adversarial transformers, for medical image segmentation. First, we take advantage of the pyramid structure to construct multi-scale representations and handle multi-scale variations. We then design a novel class-aware transformer module to better learn the discriminative regions of objects with semantic structures. Lastly, we utilize an adversarial training strategy that boosts segmentation accuracy and correspondingly allows a transformer-based discriminator to capture high-level semantically correlated contents and low-level anatomical features. Our experiments demonstrate that CA-GANformer dramatically outperforms previous state-of-the-art transformer-based approaches on three benchmarks, obtaining absolute 2.54%-5.88% improvements in Dice over previous models. Further qualitative experiments provide a more detailed picture of the model's inner workings, shed light on the challenges in improved transparency, and demonstrate that transfer learning can greatly improve performance and reduce the size of medical image datasets in training, making CA-GANformer a strong starting point for downstream medical image analysis tasks. Codes and models will be available to the public. ",
    "url": "https://arxiv.org/abs/2201.10737",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.10749",
    "title": "Robust Disturbance Rejection for Robotic Bipedal Walking:  System-Level-Synthesis with Step-to-step Dynamics Approximation",
    "abstract": "We present a stepping stabilization control that addresses external push disturbances on bipedal walking robots. The stepping control is synthesized based on the step-to-step (S2S) dynamics of the robot that is controlled to have an approximately constant center of mass (COM) height. We first learn a linear S2S dynamics with bounded model discrepancy from the undisturbed walking behaviors of the robot, where the walking step size is taken as the control input to the S2S dynamics. External pushes are then considered as disturbances to the learned S2S (L-S2S) dynamics. We then apply the system-level-synthesis (SLS) approach on the disturbed L-S2S dynamics to robustly stabilize the robot to the desired walking while satisfying the kinematic constraints of the robot. We successfully realize the proposed approach on the walking of the bipedal robot AMBER and Cassie subject to push disturbances, showing that the approach is general, effective, and computationally-efficient for robust disturbance rejection. ",
    "url": "https://arxiv.org/abs/2201.10749",
    "authors": [
      "Xiaobin Xiong",
      "Yuxiao Chen",
      "Aaron Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.10751",
    "title": "Graph Neural Networks with Dynamic and Static Representations for Social  Recommendation",
    "abstract": "Recommender systems based on graph neural networks receive increasing research interest due to their excellent ability to learn a variety of side information including social networks. However, previous works usually focus on modeling users, not much attention is paid to items. Moreover, the possible changes in the attraction of items over time, which is like the dynamic interest of users are rarely considered, and neither do the correlations among items. To overcome these limitations, this paper proposes graph neural networks with dynamic and static representations for social recommendation (GNN-DSR), which considers both dynamic and static representations of users and items and incorporates their relational influence. GNN-DSR models the short-term dynamic and long-term static interactional representations of the user's interest and the item's attraction, respectively. Furthermore, the attention mechanism is used to aggregate the social influence of users on the target user and the correlative items' influence on a given item. The final latent factors of user and item are combined to make a prediction. Experiments on three real-world recommender system datasets validate the effectiveness of GNN-DSR. ",
    "url": "https://arxiv.org/abs/2201.10751",
    "authors": [
      "Junfa Lin",
      "Siyuan Chen",
      "Jiahai Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.10752",
    "title": "Phishing Attacks Detection -- A Machine Learning-Based Approach",
    "abstract": "Phishing attacks are one of the most common social engineering attacks targeting users emails to fraudulently steal confidential and sensitive information. They can be used as a part of more massive attacks launched to gain a foothold in corporate or government networks. Over the last decade, a number of anti-phishing techniques have been proposed to detect and mitigate these attacks. However, they are still inefficient and inaccurate. Thus, there is a great need for efficient and accurate detection techniques to cope with these attacks. In this paper, we proposed a phishing attack detection technique based on machine learning. We collected and analyzed more than 4000 phishing emails targeting the email service of the University of North Dakota. We modeled these attacks by selecting 10 relevant features and building a large dataset. This dataset was used to train, validate, and test the machine learning algorithms. For performance evaluation, four metrics have been used, namely probability of detection, probability of miss-detection, probability of false alarm, and accuracy. The experimental results show that better detection can be achieved using an artificial neural network. ",
    "url": "https://arxiv.org/abs/2201.10752",
    "authors": [
      "Fatima Salahdine",
      "Zakaria El Mrabet",
      "Naima Kaabouch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10761",
    "title": "An Efficient and Robust System for Vertically Federated Random Forest",
    "abstract": "As there is a growing interest in utilizing data across multiple resources to build better machine learning models, many vertically federated learning algorithms have been proposed to preserve the data privacy of the participating organizations. However, the efficiency of existing vertically federated learning algorithms remains to be a big problem, especially when applied to large-scale real-world datasets. In this paper, we present a fast, accurate, scalable and yet robust system for vertically federated random forest. With extensive optimization, we achieved $5\\times$ and $83\\times$ speed up over the SOTA SecureBoost model \\cite{cheng2019secureboost} for training and serving tasks. Moreover, the proposed system can achieve similar accuracy but with favorable scalability and partition tolerance. Our code has been made public to facilitate the development of the community and the protection of user data privacy. ",
    "url": "https://arxiv.org/abs/2201.10761",
    "authors": [
      "Houpu Yao",
      "Jiazhou Wang",
      "Peng Dai",
      "Liefeng Bo",
      "Yanqing Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.10777",
    "title": "Meta-learning Spiking Neural Networks with Surrogate Gradient Descent",
    "abstract": "Adaptive \"life-long\" learning at the edge and during online task performance is an aspirational goal of AI research. Neuromorphic hardware implementing Spiking Neural Networks (SNNs) are particularly attractive in this regard, as their real-time, event-based, local computing paradigm makes them suitable for edge implementations and fast learning. However, the long and iterative learning that characterizes state-of-the-art SNN training is incompatible with the physical nature and real-time operation of neuromorphic hardware. Bi-level learning, such as meta-learning is increasingly used in deep learning to overcome these limitations. In this work, we demonstrate gradient-based meta-learning in SNNs using the surrogate gradient method that approximates the spiking threshold function for gradient estimations. Because surrogate gradients can be made twice differentiable, well-established, and effective second-order gradient meta-learning methods such as Model Agnostic Meta Learning (MAML) can be used. We show that SNNs meta-trained using MAML match or exceed the performance of conventional ANNs meta-trained with MAML on event-based meta-datasets. Furthermore, we demonstrate the specific advantages that accrue from meta-learning: fast learning without the requirement of high precision weights or gradients. Our results emphasize how meta-learning techniques can become instrumental for deploying neuromorphic learning technologies on real-world problems. ",
    "url": "https://arxiv.org/abs/2201.10777",
    "authors": [
      "Kenneth Stewart",
      "Emre Neftci"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10782",
    "title": "Causality and Correlation Graph Modeling for Effective and Explainable  Session-based Recommendation",
    "abstract": "Session-based recommendation which has been witnessed a booming interest recently, focuses on predicting a user's next interested item(s) based on an anonymous session. Most existing studies adopt complex deep learning techniques (e.g., graph neural networks) for effective session-based recommendation. However, they merely address \\emph{co-occurrence} between items, but fail to well distinguish \\emph{causality} and \\emph{correlation} relationship. Considering the varied interpretations and characteristics of causality and correlation relationship between items, in this study, we propose a novel method denoted as CGSR by jointly modeling causality and correlation relationship between items. In particular, we construct cause, effect and correlation graphs from sessions by simultaneously considering the false causality problem. We further design a graph neural network-based method for session-based recommendation. Extensive experiments on three datasets show that our model outperforms other state-of-the-art methods in terms of recommendation accuracy. Moreover, we further propose an explainable framework on CGSR, and demonstrate the explainability of our model via case studies on Amazon dataset. ",
    "url": "https://arxiv.org/abs/2201.10782",
    "authors": [
      "Cong Geng",
      "Huizi Wu",
      "Hui Fang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.10787",
    "title": "Variational Model Inversion Attacks",
    "abstract": "Given the ubiquity of deep neural networks, it is important that these models do not reveal information about sensitive data that they have been trained on. In model inversion attacks, a malicious user attempts to recover the private dataset used to train a supervised neural network. A successful model inversion attack should generate realistic and diverse samples that accurately describe each of the classes in the private dataset. In this work, we provide a probabilistic interpretation of model inversion attacks, and formulate a variational objective that accounts for both diversity and accuracy. In order to optimize this variational objective, we choose a variational family defined in the code space of a deep generative model, trained on a public auxiliary dataset that shares some structural similarity with the target dataset. Empirically, our method substantially improves performance in terms of target attack accuracy, sample realism, and diversity on datasets of faces and chest X-ray images. ",
    "url": "https://arxiv.org/abs/2201.10787",
    "authors": [
      "Kuan-Chieh Wang",
      "Yan Fu",
      "Ke Li",
      "Ashish Khisti",
      "Richard Zemel",
      "Alireza Makhzani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.10788",
    "title": "Self-supervised 3D Semantic Representation Learning for  Vision-and-Language Navigation",
    "abstract": "In the Vision-and-Language Navigation task, the embodied agent follows linguistic instructions and navigates to a specific goal. It is important in many practical scenarios and has attracted extensive attention from both computer vision and robotics communities. However, most existing works only use RGB images but neglect the 3D semantic information of the scene. To this end, we develop a novel self-supervised training framework to encode the voxel-level 3D semantic reconstruction into a 3D semantic representation. Specifically, a region query task is designed as the pretext task, which predicts the presence or absence of objects of a particular class in a specific 3D region. Then, we construct an LSTM-based navigation model and train it with the proposed 3D semantic representations and BERT language features on vision-language pairs. Experiments show that the proposed approach achieves success rates of 68% and 66% on the validation unseen and test unseen splits of the R2R dataset respectively, which are superior to most of RGB-based methods utilizing vision-language transformers. ",
    "url": "https://arxiv.org/abs/2201.10788",
    "authors": [
      "Sinan Tan",
      "Mengmeng Ge",
      "Di Guo",
      "Huaping Liu",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.10830",
    "title": "MonoDistill: Learning Spatial Features for Monocular 3D Object Detection",
    "abstract": "3D object detection is a fundamental and challenging task for 3D scene understanding, and the monocular-based methods can serve as an economical alternative to the stereo-based or LiDAR-based methods. However, accurately detecting objects in the 3D space from a single image is extremely difficult due to the lack of spatial cues. To mitigate this issue, we propose a simple and effective scheme to introduce the spatial information from LiDAR signals to the monocular 3D detectors, without introducing any extra cost in the inference phase. In particular, we first project the LiDAR signals into the image plane and align them with the RGB images. After that, we use the resulting data to train a 3D detector (LiDAR Net) with the same architecture as the baseline model. Finally, this LiDAR Net can serve as the teacher to transfer the learned knowledge to the baseline model. Experimental results show that the proposed method can significantly boost the performance of the baseline model and ranks the $1^{st}$ place among all monocular-based methods on the KITTI benchmark. Besides, extensive ablation studies are conducted, which further prove the effectiveness of each part of our designs and illustrate what the baseline model has learned from the LiDAR Net. Our code will be released at \\url{https://github.com/monster-ghost/MonoDistill}. ",
    "url": "https://arxiv.org/abs/2201.10830",
    "authors": [
      "Zhiyu Chong",
      "Xinzhu Ma",
      "Hong Zhang",
      "Yuxin Yue",
      "Haojie Li",
      "Zhihui Wang",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10833",
    "title": "Automatic detection of access control vulnerabilities via API  specification processing",
    "abstract": "Objective. Insecure Direct Object Reference (IDOR) or Broken Object Level Authorization (BOLA) are one of the critical type of access control vulnerabilities for modern applications. As a result, an attacker can bypass authorization checks leading to information leakage, account takeover. Our main research goal was to help an application security architect to optimize security design and testing process by giving an algorithm and tool that allows to automatically analyze system API specifications and generate list of possible vulnerabilities and attack vector ready to be used as security non-functional requirements. Method. We conducted a multivocal review of research and conference papers, bug bounty program reports and other grey sources of literature to outline patterns of attacks against IDOR vulnerability. These attacks are collected in groups proceeding with further analysis common attributes between these groups and what features compose the group. Endpoint properties and attack techniques comprise a group of attacks. Mapping between group features and existing OpenAPI specifications is performed to implement a tool for automatic discovery of potentially vulnerable endpoints. Results and practical relevance. In this work, we provide systematization of IDOR/BOLA attack techniques based on literature review, real cases analysis and derive IDOR/BOLA attack groups. We proposed an approach to describe IDOR/BOLA attacks based on OpenAPI specifications properties. We develop an algorithm of potential IDOR/BOLA vulnerabilities detection based on OpenAPI specification processing. We implemented our novel algorithm using Python and evaluated it. The results show that algorithm is resilient and can be used in practice to detect potential IDOR/BOLA vulnerabilities. ",
    "url": "https://arxiv.org/abs/2201.10833",
    "authors": [
      "Alexander Barabanov",
      "Denis Dergunov",
      "Denis Makrushin",
      "Aleksey Teplov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.10835",
    "title": "Perfect Matching in Random Graphs is as Hard as Tseitin",
    "abstract": "We study the complexity of proving that a sparse random regular graph on an odd number of vertices does not have a perfect matching, and related problems involving each vertex being matched some pre-specified number of times. We show that this requires proofs of degree $\\Omega(n / \\log n)$ in the Polynomial Calculus (over fields of characteristic $\\ne 2$) and Sum-of-Squares proof systems, and exponential size in the bounded-depth Frege proof system. This resolves a question by Razborov asking whether the Lov\\'asz-Schrijver proof system requires $n^\\delta$ rounds to refute these formulas for some $\\delta > 0$. The results are obtained by a worst-case to average-case reduction of these formulas relying on a topological embedding theorem which may be of independent interest. ",
    "url": "https://arxiv.org/abs/2201.10835",
    "authors": [
      "Per Austrin",
      "Kilian Risse"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2201.10836",
    "title": "PARS: Pseudo-Label Aware Robust Sample Selection for Learning with Noisy  Labels",
    "abstract": "Acquiring accurate labels on large-scale datasets is both time consuming and expensive. To reduce the dependency of deep learning models on learning from clean labeled data, several recent research efforts are focused on learning with noisy labels. These methods typically fall into three design categories to learn a noise robust model: sample selection approaches, noise robust loss functions, or label correction methods. In this paper, we propose PARS: Pseudo-Label Aware Robust Sample Selection, a hybrid approach that combines the best from all three worlds in a joint-training framework to achieve robustness to noisy labels. Specifically, PARS exploits all training samples using both the raw/noisy labels and estimated/refurbished pseudo-labels via self-training, divides samples into an ambiguous and a noisy subset via loss analysis, and designs label-dependent noise-aware loss functions for both sets of filtered labels. Results show that PARS significantly outperforms the state of the art on extensive studies on the noisy CIFAR-10 and CIFAR-100 datasets, particularly on challenging high-noise and low-resource settings. In particular, PARS achieved an absolute 12% improvement in test accuracy on the CIFAR-100 dataset with 90% symmetric label noise, and an absolute 27% improvement in test accuracy when only 1/5 of the noisy labels are available during training as an additional restriction. On a real-world noisy dataset, Clothing1M, PARS achieves competitive results to the state of the art. ",
    "url": "https://arxiv.org/abs/2201.10836",
    "authors": [
      "Arushi Goel",
      "Yunlong Jiao",
      "Jordan Massiah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10859",
    "title": "Visualizing the diversity of representations learned by Bayesian neural  networks",
    "abstract": "Explainable artificial intelligence (XAI) aims to make learning machines less opaque, and offers researchers and practitioners various tools to reveal the decision-making strategies of neural networks. In this work, we investigate how XAI methods can be used for exploring and visualizing the diversity of feature representations learned by Bayesian neural networks (BNNs). Our goal is to provide a global understanding of BNNs by making their decision-making strategies a) visible and tangible through feature visualizations and b) quantitatively measurable with a distance measure learned by contrastive learning. Our work provides new insights into the posterior distribution in terms of human-understandable feature information with regard to the underlying decision-making strategies. Our main findings are the following: 1) global XAI methods can be applied to explain the diversity of decision-making strategies of BNN instances, 2) Monte Carlo dropout exhibits increased diversity in feature representations compared to the multimodal posterior approximation of MultiSWAG, 3) the diversity of learned feature representations highly correlates with the uncertainty estimates, and 4) the inter-mode diversity of the multimodal posterior decreases as the network width increases, while the intra-mode diversity increases. Our findings are consistent with the recent deep neural networks theory, providing additional intuitions about what the theory implies in terms of humanly understandable concepts. ",
    "url": "https://arxiv.org/abs/2201.10859",
    "authors": [
      "Dennis Grinwald",
      "Kirill Bykov",
      "Shinichi Nakajima",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.10879",
    "title": "S$^2$NN: Time Step Reduction of Spiking Surrogate Gradients for Training  Energy Efficient Single-Step Neural Networks",
    "abstract": "As the scales of neural networks increase, techniques that enable them to run with low computational cost and energy efficiency are required. From such demands, various efficient neural network paradigms, such as spiking neural networks (SNNs) or binary neural networks (BNNs), have been proposed. However, they have sticky drawbacks, such as degraded inference accuracy and latency. To solve these problems, we propose a single-step neural network (S$^2$NN), an energy-efficient neural network with low computational cost and high precision. The proposed S$^2$NN processes the information between hidden layers by spikes as SNNs. Nevertheless, it has no temporal dimension so that there is no latency within training and inference phases as BNNs. Thus, the proposed S$^2$NN has a lower computational cost than SNNs that require time-series processing. However, S$^2$NN cannot adopt na\\\"{i}ve backpropagation algorithms due to the non-differentiability nature of spikes. We deduce a suitable neuron model by reducing the surrogate gradient for multi-time step SNNs to a single-time step. We experimentally demonstrated that the obtained neuron model enables S$^2$NN to train more accurately and energy-efficiently than existing neuron models for SNNs and BNNs. We also showed that the proposed S$^2$NN could achieve comparable accuracy to full-precision networks while being highly energy-efficient. ",
    "url": "https://arxiv.org/abs/2201.10879",
    "authors": [
      "Kazuma Suetake",
      "Shin-ichi Ikegawa",
      "Ryuji Saiin",
      "Yoshihide Sawada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.10887",
    "title": "An Attempt of Adaptive Heightfield Rendering with Complex Interpolants  Using Ray Casting",
    "abstract": "In this technical report, we document our attempt to visualize adaptive heightfields with smooth interpolation using ray casting in real time. The performance of ray casting depends strongly on the used interpolant and its efficient evaluation. Unfortunately, analytical solutions for ray-surface intersections are only given in the literature for very few simple, piece-wise polynomial surfaces. In our use case, we approximate the heightfield with radial basis functions defined on an adaptive grid, for which we propose a two-step solution: First, we reconstruct and discretize the currently visible portion of the surface with smooth approximation into a set of off-screen buffers. In a second step, we interpret these off-screen buffers as regular heightfields that can be rendered efficiently with ray casting using a simple bilinear interpolant. While our approach works, our quantitative evaluation shows that the performance depends strongly on the complexity and size of the heightfield. Real-time performance cannot be achieved for arbitrary heightfields, which is why we report our findings as a failed attempt to use ray casting for practical geospatial visualization in real time. ",
    "url": "https://arxiv.org/abs/2201.10887",
    "authors": [
      "Daniel Cornel",
      "Zsolt Horv\u00e1th",
      "J\u00fcrgen Waser"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2201.10899",
    "title": "Speeding up Heterogeneous Federated Learning with Sequentially Trained  Superclients",
    "abstract": "Federated Learning (FL) allows training machine learning models in privacy-constrained scenarios by enabling the cooperation of edge devices without requiring local data sharing. This approach raises several challenges due to the different statistical distribution of the local datasets and the clients' computational heterogeneity. In particular, the presence of highly non-i.i.d. data severely impairs both the performance of the trained neural network and its convergence rate, increasing the number of communication rounds requested to reach a performance comparable to that of the centralized scenario. As a solution, we propose FedSeq, a novel framework leveraging the sequential training of subgroups of heterogeneous clients, i.e. superclients, to emulate the centralized paradigm in a privacy-compliant way. Given a fixed budget of communication rounds, we show that FedSeq outperforms or match several state-of-the-art federated algorithms in terms of final performance and speed of convergence. Finally, our method can be easily integrated with other approaches available in the literature. Empirical results show that combining existing algorithms with FedSeq further improves its final performance and convergence speed. We test our method on CIFAR-10 and CIFAR-100 and prove its effectiveness in both i.i.d. and non-i.i.d. scenarios. ",
    "url": "https://arxiv.org/abs/2201.10899",
    "authors": [
      "Riccardo Zaccone",
      "Andrea Rizzardi",
      "Debora Caldarola",
      "Marco Ciccone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10908",
    "title": "Improving robustness and calibration in ensembles with diversity  regularization",
    "abstract": "Calibration and uncertainty estimation are crucial topics in high-risk environments. We introduce a new diversity regularizer for classification tasks that uses out-of-distribution samples and increases the overall accuracy, calibration and out-of-distribution detection capabilities of ensembles. Following the recent interest in the diversity of ensembles, we systematically evaluate the viability of explicitly regularizing ensemble diversity to improve calibration on in-distribution data as well as under dataset shift. We demonstrate that diversity regularization is highly beneficial in architectures, where weights are partially shared between the individual members and even allows to use fewer ensemble members to reach the same level of robustness. Experiments on CIFAR-10, CIFAR-100, and SVHN show that regularizing diversity can have a significant impact on calibration and robustness, as well as out-of-distribution detection. ",
    "url": "https://arxiv.org/abs/2201.10908",
    "authors": [
      "Hendrik Alexander Mehrtens",
      "Camila Gonz\u00e1lez",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.10937",
    "title": "Boosting 3D Adversarial Attacks with Attacking On Frequency",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks. Recently, 3D adversarial attacks, especially adversarial attacks on point clouds, have elicited mounting interest. However, adversarial point clouds obtained by previous methods show weak transferability and are easy to defend. To address these problems, in this paper we propose a novel point cloud attack (dubbed AOF) that pays more attention on the low-frequency component of point clouds. We combine the losses from point cloud and its low-frequency component to craft adversarial samples. Extensive experiments validate that AOF can improve the transferability significantly compared to state-of-the-art (SOTA) attacks, and is more robust to SOTA 3D defense methods. Otherwise, compared to clean point clouds, adversarial point clouds obtained by AOF contain more deformation than outlier. ",
    "url": "https://arxiv.org/abs/2201.10937",
    "authors": [
      "Binbin Liu",
      "Jinlai Zhang",
      "Lyujie Chen",
      "Jihong Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10943",
    "title": "Event-based Video Reconstruction via Potential-assisted Spiking Neural  Network",
    "abstract": "Neuromorphic vision sensor is a new bio-inspired imaging paradigm that reports asynchronous, continuously per-pixel brightness changes called `events' with high temporal resolution and high dynamic range. So far, the event-based image reconstruction methods are based on artificial neural networks (ANN) or hand-crafted spatiotemporal smoothing techniques. In this paper, we first implement the image reconstruction work via fully spiking neural network (SNN) architecture. As the bio-inspired neural networks, SNNs operating with asynchronous binary spikes distributed over time, can potentially lead to greater computational efficiency on event-driven hardware. We propose a novel Event-based Video reconstruction framework based on a fully Spiking Neural Network (EVSNN), which utilizes Leaky-Integrate-and-Fire (LIF) neuron and Membrane Potential (MP) neuron. We find that the spiking neurons have the potential to store useful temporal information (memory) to complete such time-dependent tasks. Furthermore, to better utilize the temporal information, we propose a hybrid potential-assisted framework (PA-EVSNN) using the membrane potential of spiking neuron. The proposed neuron is referred as Adaptive Membrane Potential (AMP) neuron, which adaptively updates the membrane potential according to the input spikes. The experimental results demonstrate that our models achieve comparable performance to ANN-based models on IJRR, MVSEC, and HQF datasets. The energy consumptions of EVSNN and PA-EVSNN are 19.36$\\times$ and 7.75$\\times$ more computationally efficient than their ANN architectures, respectively. ",
    "url": "https://arxiv.org/abs/2201.10943",
    "authors": [
      "Lin Zhu",
      "Xiao Wang",
      "Yi Chang",
      "Jianing Li",
      "Tiejun Huang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10945",
    "title": "On the Power of Gradual Network Alignment Using Dual-Perception  Similarities",
    "abstract": "Network alignment (NA) is the task of finding the correspondence of nodes between two networks based on the network structure and node attributes. Our study is motivated by the fact that, since most of existing NA methods have attempted to discover all node pairs at once, they do not harness information enriched through interim discovery of node correspondences to more accurately find the next correspondences during the node matching. To tackle this challenge, we propose Grad-Align, a new NA method that gradually discovers node pairs by making full use of node pairs exhibiting strong consistency, which are easy to be discovered in the early stage of gradual matching. Specifically, Grad-Align first generates node embeddings of the two networks based on graph neural networks along with our layer-wise reconstruction loss, a loss built upon capturing the first-order and higher-order neighborhood structures. Then, nodes are gradually aligned by computing dual-perception similarity measures including the multi-layer embedding similarity as well as the Tversky similarity, an asymmetric set similarity using the Tversky index applicable to networks with different scales. Additionally, we incorporate an edge augmentation module into Grad-Align to reinforce the structural consistency. Through comprehensive experiments using real-world and synthetic datasets, we empirically demonstrate that Grad-Align consistently outperforms state-of-the-art NA methods. ",
    "url": "https://arxiv.org/abs/2201.10945",
    "authors": [
      "Jin-Duk Park",
      "Cong Tran",
      "Won-Yong Shin",
      "Xin Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.10957",
    "title": "Social Learning under Randomized Collaborations",
    "abstract": "We study a social learning scheme where at every time instant, each agent chooses to receive information from one of its neighbors at random. We show that under this sparser communication scheme, the agents learn the truth eventually and the asymptotic convergence rate remains the same as the standard algorithms which use more communication resources. We also derive large deviation estimates of the log-belief ratios for a special case where each agent replaces its belief with that of the chosen neighbor. ",
    "url": "https://arxiv.org/abs/2201.10957",
    "authors": [
      "Yunus Inan",
      "Mert Kayaalp",
      "Emre Telatar",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.10967",
    "title": "Physics-informed ConvNet: Learning Physical Field from a Shallow Neural  Network",
    "abstract": "Big-data-based artificial intelligence (AI) supports profound evolution in almost all of science and technology. However, modeling and forecasting multi-physical systems remain a challenge due to unavoidable data scarcity and noise. Improving the generalization ability of neural networks by \"teaching\" domain knowledge and developing a new generation of models combined with the physical laws have become promising areas of machine learning research. Different from \"deep\" fully-connected neural networks embedded with physical information (PINN), a novel shallow framework named physics-informed convolutional network (PICN) is recommended from a CNN perspective, in which the physical field is generated by a deconvolution layer and a single convolution layer. The difference fields forming the physical operator are constructed using the pre-trained shallow convolution layer. An efficient linear interpolation network calculates the loss function involving boundary conditions and the physical constraints in irregular geometry domains. The effectiveness of the current development is illustrated through some numerical cases involving the solving (and estimation) of nonlinear physical operator equations and recovering physical information from noisy observations. Its potential advantage in approximating physical fields with multi-frequency components indicates that PICN may become an alternative neural network solver in physics-informed machine learning. ",
    "url": "https://arxiv.org/abs/2201.10967",
    "authors": [
      "Pengpeng Shi",
      "Zhi Zeng",
      "Tianshou Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.10972",
    "title": "How Robust are Discriminatively Trained Zero-Shot Learning Models?",
    "abstract": "Data shift robustness is an active research topic, however, it has been primarily investigated from a fully supervised perspective, and robustness of zero-shot learning (ZSL) models have been largely neglected. In this paper, we present a novel analysis on the robustness of discriminative ZSL to image corruptions. We leverage the well-known label embedding model and subject it to a large set of common corruptions and defenses. In order to realize the corruption analysis, we curate and release the first ZSL corruption robustness datasets SUN-C, CUB-C and AWA2-C. We analyse our results by taking into account the dataset characteristics, class imbalance, class transition trends between seen and unseen classes and the discrepancies between ZSL and GZSL performances. Our results show that discriminative ZSL suffer from corruptions and this trend is further exacerbated by the severe class imbalance and model weakness inherent in ZSL methods. We then combine our findings with those based on adversarial attacks in ZSL, and highlight the different effects of corruptions and adversarial examples, such as the pseudo-robustness effect present under adversarial attacks. We also obtain new strong baselines for the label embedding model with certain corruption robustness enhancement methods. Finally, our experiments show that although existing methods to improve robustness somewhat work for ZSL models, they do not produce a tangible effect. ",
    "url": "https://arxiv.org/abs/2201.10972",
    "authors": [
      "Mehmet Kerim Yucel",
      "Ramazan Gokberk Cinbis",
      "Pinar Duygulu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.10980",
    "title": "Alleviating Cold-start Problem in CTR Prediction with A Variational  Embedding Learning Framework",
    "abstract": "We propose a general Variational Embedding Learning Framework (VELF) for alleviating the severe cold-start problem in CTR prediction. VELF addresses the cold start problem via alleviating over-fits caused by data-sparsity in two ways: learning probabilistic embedding, and incorporating trainable and regularized priors which utilize the rich side information of cold start users and advertisements (Ads). The two techniques are naturally integrated into a variational inference framework, forming an end-to-end training process. Abundant empirical tests on benchmark datasets well demonstrate the advantages of our proposed VELF. Besides, extended experiments confirmed that our parameterized and regularized priors provide more generalization capability than traditional fixed priors. ",
    "url": "https://arxiv.org/abs/2201.10980",
    "authors": [
      "Xiaoxiao Xu",
      "Chen Yang",
      "Qian Yu",
      "Zhiwei Fang",
      "Jiaxing Wang",
      "Chaosheng Fan",
      "Yang He",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11028",
    "title": "Exploring the Social Context of Collaborative Driving",
    "abstract": "The automation of the driving task affects both the primary driving task and the automotive user interfaces. The liberation of user interface space and cognitive load on the driver allows for new ways to think about driving. Related work showed that activities such as sleeping, watching TV, or working will become more prevalent in the future. However, social aspects according to Maslow's hierarchy of needs have not yet been accounted for. We provide insights of a focus group with N=5 experts in automotive user experience revealing current practices such as social need fulfillment on journeys and sharing practices via messengers and a user study with N=12 participants of a first prototype supporting these needs in various automation levels showing good usability and high potential to improve user experience. ",
    "url": "https://arxiv.org/abs/2201.11028",
    "authors": [
      "Mark Colley",
      "Sebastian Pickl",
      "Frank Uhlig",
      "Enrico Rukzio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2201.11082",
    "title": "Treelike decompositions for transductions of sparse graphs",
    "abstract": "We give new decomposition theorems for classes of graphs that can be transduced in first-order logic from classes of sparse graphs -- more precisely, from classes of bounded expansion and from nowhere dense classes. In both cases, the decomposition takes the form of a single colored rooted tree of bounded depth where, in addition, there can be links between nodes that are not related in the tree. The constraint is that the structure formed by the tree and the links has to be sparse. Using the decomposition theorem for transductions of nowhere dense classes, we show that they admit low-shrubdepth covers of size $O(n^\\varepsilon)$, where $n$ is the vertex count and $\\varepsilon>0$ is any fixed~real. This solves an open problem posed by Gajarsk\\'y et al. (ACM TOCL '20) and also by Bria\\'nski et al. (SIDMA '21). ",
    "url": "https://arxiv.org/abs/2201.11082",
    "authors": [
      "Jan Dreier",
      "Jakub Gajarsk\u00fd",
      "Sandra Kiefer",
      "Micha\u0142 Pilipczuk",
      "Szymon Toru\u0144czyk"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2201.11086",
    "title": "Can Old TREC Collections Reliably Evaluate Modern Neural Retrieval  Models?",
    "abstract": "Neural retrieval models are generally regarded as fundamentally different from the retrieval techniques used in the late 1990's when the TREC ad hoc test collections were constructed. They thus provide the opportunity to empirically test the claim that pooling-built test collections can reliably evaluate retrieval systems that did not contribute to the construction of the collection (in other words, that such collections can be reusable). To test the reusability claim, we asked TREC assessors to judge new pools created from new search results for the TREC-8 ad hoc collection. These new search results consisted of five new runs (one each from three transformer-based models and two baseline runs that use BM25) plus the set of TREC-8 submissions that did not previously contribute to pools. The new runs did retrieve previously unseen documents, but the vast majority of those documents were not relevant. The ranking of all runs by mean evaluation score when evaluated using the official TREC-8 relevance judgment set and the newly expanded relevance set are almost identical, with Kendall's tau correlations greater than 0.99. Correlations for individual topics are also high. The TREC-8 ad hoc collection was originally constructed using deep pools over a diverse set of runs, including several effective manual runs. Its judgment budget, and hence construction cost, was relatively large. However, it does appear that the expense was well-spent: even with the advent of neural techniques, the collection has stood the test of time and remains a reliable evaluation instrument as retrieval techniques have advanced. ",
    "url": "https://arxiv.org/abs/2201.11086",
    "authors": [
      "Ellen M. Voorhees",
      "Ian Soboroff",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.11091",
    "title": "Momentum Capsule Networks",
    "abstract": "Capsule networks are a class of neural networks that achieved promising results on many computer vision tasks. However, baseline capsule networks have failed to reach state-of-the-art results on more complex datasets due to the high computation and memory requirements. We tackle this problem by proposing a new network architecture, called Momentum Capsule Network (MoCapsNet). MoCapsNets are inspired by Momentum ResNets, a type of network that applies reversible residual building blocks. Reversible networks allow for recalculating activations of the forward pass in the backpropagation algorithm, so those memory requirements can be drastically reduced. In this paper, we provide a framework on how invertible residual building blocks can be applied to capsule networks. We will show that MoCapsNet beats the accuracy of baseline capsule networks on MNIST, SVHN and CIFAR-10 while using considerably less memory. The source code is available on https://github.com/moejoe95/MoCapsNet. ",
    "url": "https://arxiv.org/abs/2201.11091",
    "authors": [
      "Josef Gugglberger",
      "David Peer",
      "Antonio Rodr\u00edguez-S\u00e1nchez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11092",
    "title": "Self-Attention Neural Bag-of-Features",
    "abstract": "In this work, we propose several attention formulations for multivariate sequence data. We build on top of the recently introduced 2D-Attention and reformulate the attention learning methodology by quantifying the relevance of feature/temporal dimensions through latent spaces based on self-attention rather than learning them directly. In addition, we propose a joint feature-temporal attention mechanism that learns a joint 2D attention mask highlighting relevant information without treating feature and temporal representations independently. The proposed approaches can be used in various architectures and we specifically evaluate their application together with Neural Bag of Features feature extraction module. Experiments on several sequence data analysis tasks show the improved performance yielded by our approach compared to standard methods. ",
    "url": "https://arxiv.org/abs/2201.11092",
    "authors": [
      "Kateryna Chumachenko",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11097",
    "title": "Adaptive Instance Distillation for Object Detection in Autonomous  Driving",
    "abstract": "In recent years, knowledge distillation (KD) has been widely used as an effective way to derive efficient models. Through imitating a large teacher model, a lightweight student model can achieve comparable performance with more efficiency. However, most existing knowledge distillation methods are focused on classification tasks. Only a limited number of studies have applied knowledge distillation to object detection, especially in time-sensitive autonomous driving scenarios. We propose the Adaptive Instance Distillation (AID) method to selectively impart knowledge from the teacher to the student for improving the performance of knowledge distillation. Unlike previous KD methods that treat all instances equally, our AID can attentively adjust the distillation weights of instances based on the teacher model's prediction loss. We verified the effectiveness of our AID method through experiments on the KITTI and the COCO traffic datasets. The results show that our method improves the performance of existing state-of-the-art attention-guided and non-local distillation methods and achieves better distillation results on both single-stage and two-stage detectors. Compared to the baseline, our AID led to an average of 2.7% and 2.05% mAP increases for single-stage and two-stage detectors, respectively. Furthermore, our AID is also shown to be useful for self-distillation to improve the teacher model's performance. ",
    "url": "https://arxiv.org/abs/2201.11097",
    "authors": [
      "Qizhen Lan",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11104",
    "title": "Combining optimal path search with task-dependent learning in a neural  network",
    "abstract": "Finding optimal paths in connected graphs requires determining the smallest total cost for traveling along the graph's edges. This problem can be solved by several classical algorithms where, usually, costs are predefined for all edges. Conventional planning methods can, thus, normally not be used when wanting to change costs in an adaptive way following the requirements of some task. Here we show that one can define a neural network representation of path finding problems by transforming cost values into synaptic weights, which allows for online weight adaptation using network learning mechanisms. When starting with an initial activity value of one, activity propagation in this network will lead to solutions, which are identical to those found by the Bellman Ford algorithm. The neural network has the same algorithmic complexity as Bellman Ford and, in addition, we can show that network learning mechanisms (such as Hebbian learning) can adapt the weights in the network augmenting the resulting paths according to some task at hand. We demonstrate this by learning to navigate in an environment with obstacles as well as by learning to follow certain sequences of path nodes. Hence, the here-presented novel algorithm may open up a different regime of applications where path-augmentation (by learning) is directly coupled with path finding in a natural way. ",
    "url": "https://arxiv.org/abs/2201.11104",
    "authors": [
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11113",
    "title": "Post-training Quantization for Neural Networks with Provable Guarantees",
    "abstract": "While neural networks have been remarkably successful in a wide array of applications, implementing them in resource-constrained hardware remains an area of intense research. By replacing the weights of a neural network with quantized (e.g., 4-bit, or binary) counterparts, massive savings in computation cost, memory, and power consumption are attained. We modify a post-training neural-network quantization method, GPFQ, that is based on a greedy path-following mechanism, and rigorously analyze its error. We prove that for quantizing a single-layer network, the relative square error essentially decays linearly in the number of weights -- i.e., level of over-parametrization. Our result holds across a range of input distributions and for both fully-connected and convolutional architectures. To empirically evaluate the method, we quantize several common architectures with few bits per weight, and test them on ImageNet, showing only minor loss of accuracy. We also demonstrate that standard modifications, such as bias correction and mixed precision quantization, further improve accuracy. ",
    "url": "https://arxiv.org/abs/2201.11113",
    "authors": [
      "Jinjie Zhang",
      "Yixuan Zhou",
      "Rayan Saab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.10595",
    "title": "Complex matter field universal models with optimal scaling for solving  combinatorial optimization problems",
    "abstract": "We develop a universal model based on the classical complex matter fields that allow the optimal mapping of many real-life NP-hard combinatorial optimisation problems into the problem of minimising a spin Hamiltonian. We explicitly formulate one-to-one mapping for three famous problems: graph colouring, the travelling salesman, and the modular N-queens problem. We show that such a formulation allows for several orders of magnitude improvement in the search for the global minimum compared to the standard Ising formulation. At the same time, the amplitude dynamics escape from the local minima. ",
    "url": "https://arxiv.org/abs/2201.10595",
    "authors": [
      "Natalia G. Berloff"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computational Complexity (cs.CC)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2201.10610",
    "title": "Extending compositional data analysis from a graph signal processing  perspective",
    "abstract": "Traditional methods for the analysis of compositional data consider the log-ratios between all different pairs of variables with equal weight, typically in the form of aggregated contributions. This is not meaningful in contexts where it is known that a relationship only exists between very specific variables (e.g.~for metabolomic pathways), while for other pairs a relationship does not exist. Modeling absence or presence of relationships is done in graph theory, where the vertices represent the variables, and the connections refer to relations. This paper links compositional data analysis with graph signal processing, and it extends the Aitchison geometry to a setting where only selected log-ratios can be considered. The presented framework retains the desirable properties of scale invariance and compositional coherence. An additional extension to include absolute information is readily made. Examples from bioinformatics and geochemistry underline the usefulness of thisapproach in comparison to standard methods for compositional data analysis. ",
    "url": "https://arxiv.org/abs/2201.10610",
    "authors": [
      "Christopher Rieser",
      "Peter Filzmoser"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ]
  },
  {
    "id": "arXiv:2201.10776",
    "title": "DSFormer: A Dual-domain Self-supervised Transformer for Accelerated  Multi-contrast MRI Reconstruction",
    "abstract": "Multi-contrast MRI (MC-MRI) captures multiple complementary imaging modalities to aid in radiological decision-making. Given the need for lowering the time cost of multiple acquisitions, current deep accelerated MRI reconstruction networks focus on exploiting the redundancy between multiple contrasts. However, existing works are largely supervised with paired data and/or prohibitively expensive fully-sampled MRI sequences. Further, reconstruction networks typically rely on convolutional architectures which are limited in their capacity to model long-range interactions and may lead to suboptimal recovery of fine anatomical detail. To these ends, we present a dual-domain self-supervised transformer (DSFormer) for accelerated MC-MRI reconstruction. DSFormer develops a deep conditional cascade transformer (DCCT) consisting of several cascaded Swin transformer reconstruction networks (SwinRN) trained under two deep conditioning strategies to enable MC-MRI information sharing. We further present a dual-domain (image and k-space) self-supervised learning strategy for DCCT to alleviate the costs of acquiring fully sampled training data. DSFormer generates high-fidelity reconstructions which experimentally outperform current fully-supervised baselines. Moreover, we find that DSFormer achieves nearly the same performance when trained either with full supervision or with our proposed dual-domain self-supervision. ",
    "url": "https://arxiv.org/abs/2201.10776",
    "authors": [
      "Bo Zhou",
      "Jo Schlemper",
      "Neel Dey",
      "Seyed Sadegh Mohseni Salehi",
      "Chi Liu",
      "James S. Duncan",
      "Michal Sofka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10808",
    "title": "Speed, Quality, and the Optimal Timing of Complex Decisions: Field  Evidence",
    "abstract": "This paper presents an empirical investigation of the relation between decision speed and decision quality for a real-world setting of cognitively-demanding decisions in which the timing of decisions is endogenous: professional chess. Move-by-move data provide exceptionally detailed and precise information about decision times and decision quality, based on a comparison of actual decisions to a computational benchmark of best moves constructed using the artificial intelligence of a chess engine. The results reveal that faster decisions are associated with better performance. The findings are consistent with the predictions of procedural decision models like drift-diffusion-models in which decision makers sequentially acquire information about decision alternatives with uncertain valuations. ",
    "url": "https://arxiv.org/abs/2201.10808",
    "authors": [
      "Uwe Sunde",
      "Dainis Zegners",
      "Anthony Strittmatter"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2201.10827",
    "title": "Incorporate Day-ahead Robustness and Real-time Incentives for  Electricity Market Design",
    "abstract": "In this paper, we propose a two-stage electricity market framework to explore the participation of distributed energy resources (DERs) in a day-ahead (DA) market and a real-time (RT) market. The objective is to determine the optimal bidding strategies of the aggregated DERs in the DA market and generate online incentive signals for DER-owners to optimize the social welfare taking into account network operational constraints. Distributionally robust optimization is used to explicitly incorporate data-based statistical information of renewable forecasts into the supply/demand decisions in the DA market. We evaluate the conservativeness of bidding strategies distinguished by different risk aversion settings. In the RT market, a bi-level time-varying optimization problem is proposed to design the online incentive signals to tradeoff the RT imbalance penalty for distribution system operators (DSOs) and the costs of individual DER-owners. This enables tracking their optimal dispatch to provide fast balancing services, in the presence of time-varying network states while satisfying the voltage regulation requirement. Simulation results on both DA wholesale market and RT balancing market demonstrate the necessity of this two-stage design, and its robustness to uncertainties, the performance of convergence, the tracking ability, and the feasibility of the resulting network operations. ",
    "url": "https://arxiv.org/abs/2201.10827",
    "authors": [
      "Yi Guo",
      "Xuejiao Han",
      "Xinyang Zhou",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.10913",
    "title": "Constructing games on networks for controlling the inequalities in the  capital distribution",
    "abstract": "The inequality in capital or resource distribution is among the important phenomena observed in populations. The sources of inequality and methods for controlling it are of practical interest. To study this phenomenon, we introduce a model of interaction between agents in the network designed for reducing the inequality in the distribution of capital. To achieve the effect of inequality reduction, we interpret the outcome of the elementary game played in the network such that the wining of the game is translated into the reduction of the inequality. We study different interpretations of the introduced scheme and their impact on the behaviour of agents in the terms of the capital distribution, and we provide examples based on the capital dependent Parrondo's paradox. The results presented in this study provide insight into the mechanics of the inequality formation in the society. ",
    "url": "https://arxiv.org/abs/2201.10913",
    "authors": [
      "Jaros\u0142aw Adam Miszczak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2201.11037",
    "title": "RTNet: Relation Transformer Network for Diabetic Retinopathy  Multi-lesion Segmentation",
    "abstract": "Automatic diabetic retinopathy (DR) lesions segmentation makes great sense of assisting ophthalmologists in diagnosis. Although many researches have been conducted on this task, most prior works paid too much attention to the designs of networks instead of considering the pathological association for lesions. Through investigating the pathogenic causes of DR lesions in advance, we found that certain lesions are closed to specific vessels and present relative patterns to each other. Motivated by the observation, we propose a relation transformer block (RTB) to incorporate attention mechanisms at two main levels: a self-attention transformer exploits global dependencies among lesion features, while a cross-attention transformer allows interactions between lesion and vessel features by integrating valuable vascular information to alleviate ambiguity in lesion detection caused by complex fundus structures. In addition, to capture the small lesion patterns first, we propose a global transformer block (GTB) which preserves detailed information in deep network. By integrating the above blocks of dual-branches, our network segments the four kinds of lesions simultaneously. Comprehensive experiments on IDRiD and DDR datasets well demonstrate the superiority of our approach, which achieves competitive performance compared to state-of-the-arts. ",
    "url": "https://arxiv.org/abs/2201.11037",
    "authors": [
      "Shiqi Huang",
      "Jianan Li",
      "Yuze Xiao",
      "Ning Shen",
      "Tingfa Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1812.10085",
    "title": "A Data-driven Adversarial Examples Recognition Framework via Adversarial  Feature Genome",
    "abstract": " Comments: 27 pages, 9 figures, 13 tables ",
    "url": "https://arxiv.org/abs/1812.10085",
    "authors": [
      "Li Chen",
      "Qi Li",
      "Weiye Chen",
      "Zeyu Wang",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1910.11950",
    "title": "Probabilistic Surrogate Networks for Simulators with Unbounded  Randomness",
    "abstract": " Title: Probabilistic Surrogate Networks for Simulators with Unbounded  Randomness ",
    "url": "https://arxiv.org/abs/1910.11950",
    "authors": [
      "Andreas Munk",
      "Berend Zwartsenberg",
      "Adam \u015acibior",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin",
      "Andrew Stewart",
      "Goran Fernlund",
      "Anoush Poursartip",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.09877",
    "title": "Graph Neural Network for Video Relocalization",
    "abstract": " Title: Graph Neural Network for Video Relocalization ",
    "url": "https://arxiv.org/abs/2007.09877",
    "authors": [
      "Yuan Zhou",
      "Mingfei Wang",
      "Ruolin Wang",
      "Shuwei Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2009.09560",
    "title": "ES Attack: Model Stealing against Deep Neural Networks without Data  Hurdles",
    "abstract": " Comments: accepted to IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI) ",
    "url": "https://arxiv.org/abs/2009.09560",
    "authors": [
      "Xiaoyong Yuan",
      "Leah Ding",
      "Lan Zhang",
      "Xiaolin Li",
      "Dapeng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2009.13018",
    "title": "De-anonymisation attacks on Tor: A Survey",
    "abstract": " Comments: This work is published in IEEE Communications Surveys & Tutorials and is licensed under a Creative Commons Attribution 4.0 License. For more information, see this https URL Link to the article this https URL ",
    "url": "https://arxiv.org/abs/2009.13018",
    "authors": [
      "Ishan Karunanayake",
      "Nadeem Ahmed",
      "Robert Malaney",
      "Rafiqul Islam",
      "Sanjay Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2011.12649",
    "title": "Neural Representations for Modeling Variation in Speech",
    "abstract": " Comments: Submitted to Journal of Phonetics ",
    "url": "https://arxiv.org/abs/2011.12649",
    "authors": [
      "Martijn Bartelds",
      "Wietse de Vries",
      "Faraz Sanal",
      "Caitlin Richter",
      "Mark Liberman",
      "Martijn Wieling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2012.09804",
    "title": "Maximum cut on interval graphs of interval count four is NP-complete",
    "abstract": " Title: Maximum cut on interval graphs of interval count four is NP-complete ",
    "url": "https://arxiv.org/abs/2012.09804",
    "authors": [
      "Celina M. H. de Figueiredo",
      "Alexsander A. de Melo",
      "Fabiano S. Oliveira",
      "Ana Silva"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2103.09660",
    "title": "Scalable Hypergraph Embedding System",
    "abstract": " Comments: Accepted for publication at NetSciX 2022 ",
    "url": "https://arxiv.org/abs/2103.09660",
    "authors": [
      "Sepideh Maleki",
      "Donya Saless",
      "Dennis P. Wall",
      "Keshav Pingali"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.03413",
    "title": "Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective",
    "abstract": " Title: Rethinking the Backdoor Attacks' Triggers: A Frequency Perspective ",
    "url": "https://arxiv.org/abs/2104.03413",
    "authors": [
      "Yi Zeng",
      "Won Park",
      "Z. Morley Mao",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2104.10127",
    "title": "Generative Transformer for Accurate and Reliable Salient Object  Detection",
    "abstract": " Comments: Technical report, 18 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2104.10127",
    "authors": [
      "Yuxin Mao",
      "Jing Zhang",
      "Zhexiong Wan",
      "Yuchao Dai",
      "Aixuan Li",
      "Yunqiu Lv",
      "Xinyu Tian",
      "Deng-Ping Fan",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.00327",
    "title": "AirCode: A Robust Object Encoding Method",
    "abstract": " Comments: IEEE Robotics and Automation Letters (RA-L), 2022 ",
    "url": "https://arxiv.org/abs/2105.00327",
    "authors": [
      "Kuan Xu",
      "Chen Wang",
      "Chao Chen",
      "Wei Wu",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.03803",
    "title": "Mis-spoke or mis-lead: Achieving Robustness in Multi-Agent Communicative  Reinforcement Learning",
    "abstract": " Comments: Published as a conference paper in AAMAS 2022 ",
    "url": "https://arxiv.org/abs/2108.03803",
    "authors": [
      "Wanqi Xue",
      "Wei Qiu",
      "Bo An",
      "Zinovi Rabinovich",
      "Svetlana Obraztsova",
      "Chai Kiat Yeo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2108.11845",
    "title": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "abstract": " Title: Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2108.11845",
    "authors": [
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.12211",
    "title": "Enel: Context-Aware Dynamic Scaling of Distributed Dataflow Jobs using  Graph Propagation",
    "abstract": " Comments: 8 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2108.12211",
    "authors": [
      "Dominik Scheinert",
      "Houkun Zhu",
      "Lauritz Thamsen",
      "Morgan K. Geldenhuys",
      "Jonathan Will",
      "Alexander Acker",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.13332",
    "title": "Overcoming Data Availability Attacks in Blockchain Systems: LDPC Code  Design for Coded Merkle Tree",
    "abstract": " Comments: 32 pages, 7 figures, 3 tables, submitted to IEEE Transactions on Communications (TCOM). This version reflects comments from reviewers at TCOM ",
    "url": "https://arxiv.org/abs/2108.13332",
    "authors": [
      "Debarnab Mitra",
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.13247",
    "title": "The edge of chaos: quantum field theory and deep neural networks",
    "abstract": " Comments: Matches published version. Added appendix on NN-QFT dictionary. Various minor edits & improvements ",
    "url": "https://arxiv.org/abs/2109.13247",
    "authors": [
      "Kevin T. Grosvenor",
      "Ro Jefferson"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.14142",
    "title": "On the Provable Generalization of Recurrent Neural Networks",
    "abstract": " Comments: Accepted to Neurips 2021 ",
    "url": "https://arxiv.org/abs/2109.14142",
    "authors": [
      "Lifu Wang",
      "Bo Shen",
      "Bo Hu",
      "Xing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.00407",
    "title": "Evaluating Susceptibility of VPN Implementations to DoS Attacks Using  Adversarial Testing",
    "abstract": " Comments: Major update has been made and will be published at a later point in time ",
    "url": "https://arxiv.org/abs/2110.00407",
    "authors": [
      "Fabio Streun",
      "Joel Wanner",
      "Adrian Perrig"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.01174",
    "title": "Deep Kernel Representation for Image Reconstruction in PET",
    "abstract": " Title: Deep Kernel Representation for Image Reconstruction in PET ",
    "url": "https://arxiv.org/abs/2110.01174",
    "authors": [
      "Siqi Li",
      "Guobao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.04934",
    "title": "Wav2vec-Switch: Contrastive Learning from Original-noisy Speech Pairs  for Robust Speech Recognition",
    "abstract": " Comments: Accepted at IEEE ICASSP 2022. 5 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2110.04934",
    "authors": [
      "Yiming Wang",
      "Jinyu Li",
      "Heming Wang",
      "Yao Qian",
      "Chengyi Wang",
      "Yu Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.06800",
    "title": "SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue  Systems",
    "abstract": " Comments: To appear at AAAI 2022 ",
    "url": "https://arxiv.org/abs/2110.06800",
    "authors": [
      "Harrison Lee",
      "Raghav Gupta",
      "Abhinav Rastogi",
      "Yuan Cao",
      "Bin Zhang",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.03253",
    "title": "Dynamic Data Augmentation with Gating Networks",
    "abstract": " Comments: submitted to ICPR2022 ",
    "url": "https://arxiv.org/abs/2111.03253",
    "authors": [
      "Daisuke Oba",
      "Shinnosuke Matsuo",
      "Brian Kenji Iwana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08481",
    "title": "PySINDy: A comprehensive Python package for robust sparse system  identification",
    "abstract": " Title: PySINDy: A comprehensive Python package for robust sparse system  identification ",
    "url": "https://arxiv.org/abs/2111.08481",
    "authors": [
      "Alan A. Kaptanoglu",
      "Brian M. de Silva",
      "Urban Fasel",
      "Kadierdan Kaheman",
      "Andy J. Goldschmidt",
      "Jared L. Callaham",
      "Charles B. Delahunt",
      "Zachary G. Nicolaou",
      "Kathleen Champion",
      "Jean-Christophe Loiseau",
      "J. Nathan Kutz",
      "Steven L. Brunton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2112.02048",
    "title": "Graph Neural Networks for Charged Particle Tracking on FPGAs",
    "abstract": " Comments: 27 pages, 17 figures, 1 table, revision ",
    "url": "https://arxiv.org/abs/2112.02048",
    "authors": [
      "Abdelrahman Elabd",
      "Vesal Razavimaleki",
      "Shi-Yu Huang",
      "Javier Duarte",
      "Markus Atkinson",
      "Gage DeZoort",
      "Peter Elmer",
      "Scott Hauck",
      "Jin-Xuan Hu",
      "Shih-Chieh Hsu",
      "Bo-Cheng Lai",
      "Mark Neubauer",
      "Isobel Ojalvo",
      "Savannah Thais",
      "Matthew Trahms"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.05261",
    "title": "Equivariant Quantum Graph Circuits",
    "abstract": " Comments: reported new experiment ",
    "url": "https://arxiv.org/abs/2112.05261",
    "authors": [
      "P\u00e9ter Mernyei",
      "Konstantinos Meichanetzidis",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2201.01628",
    "title": "Bridging Adversarial and Nonstationary Multi-armed Bandit",
    "abstract": " Title: Bridging Adversarial and Nonstationary Multi-armed Bandit ",
    "url": "https://arxiv.org/abs/2201.01628",
    "authors": [
      "Ningyuan Chen",
      "Shuoguang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.05861",
    "title": "Deep Unified Representation for Heterogeneous Recommendation",
    "abstract": " Comments: 12 pages, 4 figures, accepted by the ACM Web Conference 2022 (WWW '22) ",
    "url": "https://arxiv.org/abs/2201.05861",
    "authors": [
      "Chengqiang Lu",
      "Mingyang Yin",
      "Shuheng Shen",
      "Luo Ji",
      "Qi Liu",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06626",
    "title": "Neural Network Compression of ACAS Xu is Unsafe: Closed-Loop  Verification through Quantized State Backreachability",
    "abstract": " Title: Neural Network Compression of ACAS Xu is Unsafe: Closed-Loop  Verification through Quantized State Backreachability ",
    "url": "https://arxiv.org/abs/2201.06626",
    "authors": [
      "Stanley Bak",
      "Hoang-Dung Tran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2201.07070",
    "title": "Attention-based Proposals Refinement for 3D Object Detection",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2201.07070",
    "authors": [
      "Minh-Quan Dao",
      "Elwan H\u00e9ry",
      "Vincent Fr\u00e9mont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.07537",
    "title": "Graph Neural Network-based Android Malware Classification with Jumping  Knowledge",
    "abstract": " Comments: 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2201.07537",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Mohanad Sarhan",
      "Marcus Gallagher",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.07708",
    "title": "Debiased Graph Neural Networks with Agnostic Label Selection Bias",
    "abstract": " Comments: Accepted by TNNLS;12 pages ",
    "url": "https://arxiv.org/abs/2201.07708",
    "authors": [
      "Shaohua Fan",
      "Xiao Wang",
      "Chuan Shi",
      "Kun Kuang",
      "Nian Liu",
      "Bai Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08005",
    "title": "FreSCo: Mining Frequent Patterns in Simplicial Complexes",
    "abstract": " Comments: To appear at The Web Conference 2022 ",
    "url": "https://arxiv.org/abs/2201.08005",
    "authors": [
      "Giulia Preti",
      "Gianmarco De Francisci Morales",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.10085",
    "title": "Dissipative Hamiltonian Neural Networks: Learning Dissipative and  Conservative Dynamics Separately",
    "abstract": " Comments: 8 pages, 5 figures, first upload ",
    "url": "https://arxiv.org/abs/2201.10085",
    "authors": [
      "Andrew Sosanya",
      "Sam Greydanus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.10092",
    "title": "Stochastic Coded Federated Learning with Convergence and Privacy  Guarantees",
    "abstract": " Title: Stochastic Coded Federated Learning with Convergence and Privacy  Guarantees ",
    "url": "https://arxiv.org/abs/2201.10092",
    "authors": [
      "Yuchang Sun",
      "Jiawei Shao",
      "Songze Li",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.10294",
    "title": "S2MS: Self-Supervised Learning Driven Multi-Spectral CT Image  Enhancement",
    "abstract": " Title: S2MS: Self-Supervised Learning Driven Multi-Spectral CT Image  Enhancement ",
    "url": "https://arxiv.org/abs/2201.10294",
    "authors": [
      "Chaoyang Zhang",
      "Shaojie Chang",
      "Ti Bai",
      "Xi Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]