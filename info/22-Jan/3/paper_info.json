[
  {
    "id": "arXiv:2112.14769",
    "title": "Frame invariance and scalability of neural operators for partial  differential equations",
    "abstract": "Partial differential equations (PDEs) play a dominant role in the mathematical modeling of many complex dynamical processes. Solving these PDEs often requires prohibitively high computational costs, especially when multiple evaluations must be made for different parameters or conditions. After training, neural operators can provide PDEs solutions significantly faster than traditional PDE solvers. In this work, invariance properties and computational complexity of two neural operators are examined for transport PDE of a scalar quantity. Neural operator based on graph kernel network (GKN) operates on graph-structured data to incorporate nonlocal dependencies. Here we propose a modified formulation of GKN to achieve frame invariance. Vector cloud neural network (VCNN) is an alternate neural operator with embedded frame invariance which operates on point cloud data. GKN-based neural operator demonstrates slightly better predictive performance compared to VCNN. However, GKN requires an excessively high computational cost that increases quadratically with the increasing number of discretized objects as compared to a linear increase for VCNN. ",
    "url": "https://arxiv.org/abs/2112.14769",
    "authors": [
      "Muhammad I. Zafar",
      "Jiequn Han",
      "Xu-Hui Zhou",
      "Heng Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14772",
    "title": "Deep Graph Clustering via Dual Correlation Reduction",
    "abstract": "Deep graph clustering, which aims to reveal the underlying graph structure and divide the nodes into different groups, has attracted intensive attention in recent years. However, we observe that, in the process of node encoding, existing methods suffer from representation collapse which tends to map all data into the same representation. Consequently, the discriminative capability of the node representation is limited, leading to unsatisfied clustering performance. To address this issue, we propose a novel self-supervised deep graph clustering method termed Dual Correlation Reduction Network (DCRN) by reducing information correlation in a dual manner. Specifically, in our method, we first design a siamese network to encode samples. Then by forcing the cross-view sample correlation matrix and cross-view feature correlation matrix to approximate two identity matrices, respectively, we reduce the information correlation in the dual-level, thus improving the discriminative capability of the resulting features. Moreover, in order to alleviate representation collapse caused by over-smoothing in GCN, we introduce a propagation regularization term to enable the network to gain long-distance information with the shallow network structure. Extensive experimental results on six benchmark datasets demonstrate the effectiveness of the proposed DCRN against the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2112.14772",
    "authors": [
      "Yue Liu",
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Linxuan Song",
      "Xihong Yang",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.14792",
    "title": "Graph Neural Networks for Communication Networks: Context, Use Cases and  Opportunities",
    "abstract": "Graph neural networks (GNN) have shown outstanding applications in many fields where data is fundamentally represented as graphs (e.g., chemistry, biology, recommendation systems). In this vein, communication networks comprise many fundamental components that are naturally represented in a graph-structured manner (e.g., topology, configurations, traffic flows). This position article presents GNNs as a fundamental tool for modeling, control and management of communication networks. GNNs represent a new generation of data-driven models that can accurately learn and reproduce the complex behaviors behind real networks. As a result, such models can be applied to a wide variety of networking use cases, such as planning, online optimization, or troubleshooting. The main advantage of GNNs over traditional neural networks lies in its unprecedented generalization capabilities when applied to other networks and configurations unseen during training, which is a critical feature for achieving practical data-driven solutions for networking. This article comprises a brief tutorial on GNNs and their possible applications to communication networks. To showcase the potential of this technology, we present two use cases with state-of-the-art GNN models respectively applied to wired and wireless networks. Lastly, we delve into the key open challenges and opportunities yet to be explored in this novel research area. ",
    "url": "https://arxiv.org/abs/2112.14792",
    "authors": [
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Paul Almasan",
      "Miquel Ferriol-Galm\u00e9s",
      "Krzysztof Rusek",
      "Fabien Geyer",
      "Xiangle Cheng",
      "Xiang Shi",
      "Shihan Xiao",
      "Franco Scarselli",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.14821",
    "title": "Anomaly Detection in Cyber-Physical Systems: Reconstruction of a  Prediction Error Feature Space",
    "abstract": "Cyber-physical systems are infrastructures that use digital information such as network communications and sensor readings to control entities in the physical world. Many cyber-physical systems in airports, hospitals and nuclear power plants are regarded as critical infrastructures since a disruption of its normal functionality can result in negative consequences for the society. In the last few years, some security solutions for cyber-physical systems based on artificial intelligence have been proposed. Nevertheless, knowledge domain is required to properly setup and train artificial intelligence algorithms. Our work proposes a novel anomaly detection framework based on error space reconstruction, where genetic algorithms are used to perform hyperparameter optimization of machine learning methods. The proposed method achieved an F1-score of 87.89% in the SWaT dataset. ",
    "url": "https://arxiv.org/abs/2112.14821",
    "authors": [
      "Nuno Oliveira",
      "Norberto Sousa",
      "Jorge Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.14822",
    "title": "UCoDe: Unified Community Detection with Graph Convolutional Networks",
    "abstract": "Community detection is the unsupervised task of finding groups of nodes in a graph based on mutual similarity. Existing approaches for community detection either partition the graph in disjoint, non-overlapping, communities, or return overlapping communities. Currently, no method satisfactorily detects both overlapping and non-overlapping communities. We propose UCoDe, a unified method for unsupervised community detection in attributed graphs. It leverages recent developments in Graph Neural Networks (GNNs) for representation learning. So far, GNN methods for community detection provide competitive results in either overlapping or non-overlapping community detection tasks, but have had little success in both. UCoDe overcomes these issues by introducing a new loss that captures node similarity on a macro-scale. We provide theoretical justification for our approach's validity in the task of community detection and show that it can be applied in both the overlapping and non-overlapping settings. As our experiments demonstrate on several real benchmark graphs, UCoDe consistently provides high quality results in both overlapping and non-overlapping settings in an easy to apply fashion. ",
    "url": "https://arxiv.org/abs/2112.14822",
    "authors": [
      "Atefeh Moradan",
      "Andrew Draganov",
      "Davide Mottin",
      "Ira Assent"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.14834",
    "title": "Training Quantized Deep Neural Networks via Cooperative Coevolution",
    "abstract": "Quantizing deep neural networks (DNNs) has been a promising solution for deploying deep neural networks on embedded devices. However, most of the existing methods do not quantize gradients, and the process of quantizing DNNs still has a lot of floating-point operations, which hinders the further applications of quantized DNNs. To solve this problem, we propose a new heuristic method based on cooperative coevolution for quantizing DNNs. Under the framework of cooperative coevolution, we use the estimation of distribution algorithm to search for the low-bits weights. Specifically, we first construct an initial quantized network from a pre-trained network instead of random initialization and then start searching from it by restricting the search space. So far, the problem is the largest discrete problem known to be solved by evolutionary algorithms. Experiments show that our method can train 4 bit ResNet-20 on the Cifar-10 dataset without sacrificing accuracy. ",
    "url": "https://arxiv.org/abs/2112.14834",
    "authors": [
      "Fu Peng",
      "Shengcai Liu",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14839",
    "title": "An overview of the quantitative causality analysis and causal graph  reconstruction based on a rigorous formalism of information flow",
    "abstract": "Inference of causal relations from data now has become an important field in artificial intelligence. During the past 16 years, causality analysis (in a quantitative sense) has been developed independently in physics from first principles. This short note is a brief summary of this line of work, including part of the theory and several representative applications. ",
    "url": "https://arxiv.org/abs/2112.14839",
    "authors": [
      "X. San Liang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2112.14840",
    "title": "K-Core Decomposition on Super Large Graphs with Limited Resources",
    "abstract": "K-core decomposition is a commonly used metric to analyze graph structure or study the relative importance of nodes in complex graphs. Recent years have seen rapid growth in the scale of the graph, especially in industrial settings. For example, our industrial partner runs popular social applications with billions of users and is able to gather a rich set of user data. As a result, applying K-core decomposition on large graphs has attracted more and more attention from academics and the industry. A simple but effective method to deal with large graphs is to train them in the distributed settings, and some distributed K-core decomposition algorithms are also proposed. Despite their effectiveness, we experimentally and theoretically observe that these algorithms consume too many resources and become unstable on super-large-scale graphs, especially when the given resources are limited. In this paper, we deal with those super-large-scale graphs and propose a divide-and-conquer strategy on top of the distributed K-core decomposition algorithm. We evaluate our approach on three large graphs. The experimental results show that the consumption of resources can be significantly reduced, and the calculation on large-scale graphs becomes more stable than the existing methods. For example, the distributed K-core decomposition algorithm can scale to a large graph with 136 billion edges without losing correctness with our divide-and-conquer technique. ",
    "url": "https://arxiv.org/abs/2112.14840",
    "authors": [
      "Shicheng Gao",
      "Jie Xu",
      "Xiaosen Li",
      "Fangcheng Fu",
      "Wentao Zhang",
      "Wen Ouyang",
      "Yangyu Tao",
      "Bin Cui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14843",
    "title": "A Graph Attention Learning Approach to Antenna Tilt Optimization",
    "abstract": "6G will move mobile networks towards increasing levels of complexity. To deal with this complexity, optimization of network parameters is key to ensure high performance and timely adaptivity to dynamic network environments. The optimization of the antenna tilt provides a practical and cost-efficient method to improve coverage and capacity in the network. Previous methods based on Reinforcement Learning (RL) have shown great promise for tilt optimization by learning adaptive policies outperforming traditional tilt optimization methods. However, most existing RL methods are based on single-cell features representation, which fails to fully characterize the agent state, resulting in suboptimal performance. Also, most of such methods lack scalability, due to state-action explosion, and generalization ability. In this paper, we propose a Graph Attention Q-learning (GAQ) algorithm for tilt optimization. GAQ relies on a graph attention mechanism to select relevant neighbors information, improve the agent state representation, and update the tilt control policy based on a history of observations using a Deep Q-Network (DQN). We show that GAQ efficiently captures important network information and outperforms standard DQN with local information by a large margin. In addition, we demonstrate its ability to generalize to network deployments of different sizes and densities. ",
    "url": "https://arxiv.org/abs/2112.14843",
    "authors": [
      "Yifei Jin",
      "Filippo Vannella",
      "Maxime Bouton",
      "Jaeseong Jeong",
      "Ezeddin Al Hakim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.14853",
    "title": "Effects of Plasticity Functions on Neural Assemblies",
    "abstract": "We explore the effects of various plasticity functions on assemblies of neurons. To bridge the gap between experimental and computational theories we make use of a conceptual framework, the Assembly Calculus, which is a formal system for the description of brain function based on assemblies of neurons. The Assembly Calculus includes operations for projecting, associating, and merging assemblies of neurons. Our research is focused on simulating different plasticity functions with Assembly Calculus. Our main contribution is the modification and evaluation of the projection operation. We experiment with Oja's and Spike Time-Dependent Plasticity (STDP) rules and test the effect of various hyper-parameters. ",
    "url": "https://arxiv.org/abs/2112.14853",
    "authors": [
      "Christodoulos Constantinides",
      "Kareem Nassar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2112.14877",
    "title": "A Unified and Constructive Framework for the Universality of Neural  Networks",
    "abstract": "One of the reasons that many neural networks are capable of replicating complicated tasks or functions is their universality property. The past few decades have seen many attempts in providing constructive proofs for single or class of neural networks. This paper is an effort to provide a unified and constructive framework for the universality of a large class of activations including most of existing activations and beyond. At the heart of the framework is the concept of neural network approximate identity. It turns out that most of existing activations are neural network approximate identity, and thus universal in the space of continuous of functions on compacta. The framework induces several advantages. First, it is constructive with elementary means from functional analysis, probability theory, and numerical analysis. Second, it is the first unified attempt that is valid for most of existing activations. Third, as a by product, the framework provides the first university proof for some of the existing activation functions including Mish, SiLU, ELU, GELU, and etc. Fourth, it discovers new activations with guaranteed universality property. Indeed, any activation\\textemdash whose $\\k$th derivative, with $\\k$ being an integer, is integrable and essentially bounded\\textemdash is universal. Fifth, for a given activation and error tolerance, the framework provides precisely the architecture of the corresponding one-hidden neural network with predetermined number of neuron, and the values of weights/biases. ",
    "url": "https://arxiv.org/abs/2112.14877",
    "authors": [
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.14889",
    "title": "Few-shot Backdoor Defense Using Shapley Estimation",
    "abstract": "Deep neural networks have achieved impressive performance in a variety of tasks over the last decade, such as autonomous driving, face recognition, and medical diagnosis. However, prior works show that deep neural networks are easily manipulated into specific, attacker-decided behaviors in the inference stage by backdoor attacks which inject malicious small hidden triggers into model training, raising serious security threats. To determine the triggered neurons and protect against backdoor attacks, we exploit Shapley value and develop a new approach called Shapley Pruning (ShapPruning) that successfully mitigates backdoor attacks from models in a data-insufficient situation (1 image per class or even free of data). Considering the interaction between neurons, ShapPruning identifies the few infected neurons (under 1% of all neurons) and manages to protect the model's structure and accuracy after pruning as many infected neurons as possible. To accelerate ShapPruning, we further propose discarding threshold and $\\epsilon$-greedy strategy to accelerate Shapley estimation, making it possible to repair poisoned models with only several minutes. Experiments demonstrate the effectiveness and robustness of our method against various attacks and tasks compared to existing methods. ",
    "url": "https://arxiv.org/abs/2112.14889",
    "authors": [
      "Jiyang Guan",
      "Zhuozhuo Tu",
      "Ran He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.14900",
    "title": "Motif Graph Neural Network",
    "abstract": "Graphs can model complicated interactions between entities, which naturally emerge in many important applications. These applications can often be cast into standard graph learning tasks, in which a crucial step is to learn low-dimensional graph representations. Graph neural networks (GNNs) are currently the most popular model in graph embedding approaches. However, standard GNNs in the neighborhood aggregation paradigm suffer from limited discriminative power in distinguishing \\emph{high-order} graph structures as opposed to \\emph{low-order} structures. To capture high-order structures, researchers have resorted to motifs and developed motif-based GNNs. However, existing motif-based GNNs still often suffer from less discriminative power on high-order structures. To overcome the above limitations, we propose Motif Graph Neural Network (MGNN), a novel framework to better capture high-order structures, hinging on our proposed motif redundancy minimization operator and injective motif combination. First, MGNN produces a set of node representations w.r.t. each motif. The next phase is our proposed redundancy minimization among motifs which compares the motifs with each other and distills the features unique to each motif. Finally, MGNN performs the updating of node representations by combining multiple representations from different motifs. In particular, to enhance the discriminative power, MGNN utilizes an injective function to combine the representations w.r.t. different motifs. We further show that our proposed architecture increases the expressive power of GNNs with a theoretical analysis. We demonstrate that MGNN outperforms state-of-the-art methods on seven public benchmarks on both node classification and graph classification tasks. ",
    "url": "https://arxiv.org/abs/2112.14900",
    "authors": [
      "Xuexin Chen",
      "Ruichu Cai",
      "Yuan Fang",
      "Min Wu",
      "Zijian Li",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14901",
    "title": "On-Policy Robust Adaptive Discrete-Time Regulator for Passive  Unidirectional System using Stochastic Hill-climbing Algorithm and Associated  Search Element",
    "abstract": "Non-linear discrete-time state-feedback regulators are widely used in passive unidirectional systems. Offline system identification is required for tuning parameters of these regulators. However, offline system identification is challenging in some applications. Furthermore, the parameters of a system may be slowly changing over time, which makes the system identification less effective. Many adaptive regulators have been proposed to tune the parameters online when the offline information is neither accessible nor time-invariant. Stability and convergence of these adaptive regulators are challenging, especially in unidirectional systems. In this paper, a novel adaptive regulator is proposed for first-order unidirectional passive systems. In this method, an associated search element checks the eligibility of the update law. Then, a stochastic hill-climbing algorithm updates the parameters of the discrete-time state-feedback regulator. Simulation results demonstrate the effectiveness of the proposed method. The experiments on regulating of two passive systems show the ability of the method in regulating of passive unidirectional system in the presence of noise and disturbance. ",
    "url": "https://arxiv.org/abs/2112.14901",
    "authors": [
      "Mohsen Jafarzadeh",
      "Nicholas Gans",
      "Yonas Tadesse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.14911",
    "title": "A Survey of Deep Learning Techniques for Dynamic Branch Prediction",
    "abstract": "Branch prediction is an architectural feature that speeds up the execution of branch instruction on pipeline processors and reduces the cost of branching. Recent advancements of Deep Learning (DL) in the post Moore's Law era is accelerating areas of automated chip design, low-power computer architectures, and much more. Traditional computer architecture design and algorithms could benefit from dynamic predictors based on deep learning algorithms which learns from experience by optimizing its parameters on large number of data. In this survey paper, we focus on traditional branch prediction algorithms, analyzes its limitations, and presents a literature survey of how deep learning techniques can be applied to create dynamic branch predictors capable of predicting conditional branch instructions. Prior surveys in this field focus on dynamic branch prediction techniques based on neural network perceptrons. We plan to improve the survey based on latest research in DL and advanced Machine Learning (ML) based branch predictors. ",
    "url": "https://arxiv.org/abs/2112.14911",
    "authors": [
      "Rinu Joseph"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14916",
    "title": "INTCP: Information-centric TCP for Satellite Network",
    "abstract": "Satellite networks are booming to provide high-speed and low latency Internet access, but the transport layer becomes one of the main obstacles. Legacy end-to-end TCP is designed for terrestrial networks, not suitable for error-prone, propagation delay varying, and intermittent satellite links. It is necessary to make a clean-slate design for the satellite transport layer. This paper introduces a novel Information-centric Hop-by-Hop transport layer design, INTCP. It carries out hop-by-hop packets retransmission and hop-by-hop congestion control with the help of cache and request-response model. Hop-by-hop retransmission recovers lost packets on hop, reduces retransmission delay. INTCP controls traffic and congestion also by hop. Each hop tries its best to maximize its bandwidth utilization and improves end-to-end throughput. The capability of caching enables asynchronous multicast in transport layer. This would save precious spectrum resources in the satellite network. The performance of INTCP is evaluated with the simulated Starlink constellation. Long-distance communication with more than 1000km is carried out. The results demonstrate that, for the unicast scenario INTCP could reduce 42% one-way delay, 53% delay jitters, and improve 60% throughput compared with the legacy TCP. In multicast scenario, INTCP could achieve more than 6X throughput. ",
    "url": "https://arxiv.org/abs/2112.14916",
    "authors": [
      "Jinyu Yin",
      "Li Jiang",
      "Xinggong Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.14933",
    "title": "RheFrameDetect: A Text Classification System for Automatic Detection of  Rhetorical Frames in AI from Open Sources",
    "abstract": "Rhetorical Frames in AI can be thought of as expressions that describe AI development as a competition between two or more actors, such as governments or companies. Examples of such Frames include robotic arms race, AI rivalry, technological supremacy, cyberwarfare dominance and 5G race. Detection of Rhetorical Frames from open sources can help us track the attitudes of governments or companies towards AI, specifically whether attitudes are becoming more cooperative or competitive over time. Given the rapidly increasing volumes of open sources (online news media, twitter, blogs), it is difficult for subject matter experts to identify Rhetorical Frames in (near) real-time. Moreover, these sources are in general unstructured (noisy) and therefore, detecting Frames from these sources will require state-of-the-art text classification techniques. In this paper, we develop RheFrameDetect, a text classification system for (near) real-time capture of Rhetorical Frames from open sources. Given an input document, RheFrameDetect employs text classification techniques at multiple levels (document level and paragraph level) to identify all occurrences of Frames used in the discussion of AI. We performed extensive evaluation of the text classification techniques used in RheFrameDetect against human annotated Frames from multiple news sources. To further demonstrate the effectiveness of RheFrameDetect, we show multiple case studies depicting the Frames identified by RheFrameDetect compared against human annotated Frames. ",
    "url": "https://arxiv.org/abs/2112.14933",
    "authors": [
      "Saurav Ghosh",
      "Philippe Loustaunau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14936",
    "title": "Are we really making much progress? Revisiting, benchmarking, and  refining heterogeneous graph neural networks",
    "abstract": "Heterogeneous graph neural networks (HGNNs) have been blossoming in recent years, but the unique data processing and evaluation setups used by each work obstruct a full understanding of their advancements. In this work, we present a systematical reproduction of 12 recent HGNNs by using their official codes, datasets, settings, and hyperparameters, revealing surprising findings about the progress of HGNNs. We find that the simple homogeneous GNNs, e.g., GCN and GAT, are largely underestimated due to improper settings. GAT with proper inputs can generally match or outperform all existing HGNNs across various scenarios. To facilitate robust and reproducible HGNN research, we construct the Heterogeneous Graph Benchmark (HGB), consisting of 11 diverse datasets with three tasks. HGB standardizes the process of heterogeneous graph data splits, feature processing, and performance evaluation. Finally, we introduce a simple but very strong baseline Simple-HGN--which significantly outperforms all previous models on HGB--to accelerate the advancement of HGNNs in the future. ",
    "url": "https://arxiv.org/abs/2112.14936",
    "authors": [
      "Qingsong Lv",
      "Ming Ding",
      "Qiang Liu",
      "Yuxiang Chen",
      "Wenzheng Feng",
      "Siming He",
      "Chang Zhou",
      "Jianguo Jiang",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.14944",
    "title": "PPRviz: Effective and Efficient Graph Visualization based on  Personalized PageRank",
    "abstract": "Graph visualization is an important problem that finds applications in various domains, e.g., social network analysis, traffic planning, and bioinformatics. Existing solutions for graph visualization, however, fail to scale to large graphs with millions of nodes, as they either provide inferior visualization results or incur significant computational cost. To address the deficiencies of prior works, we propose PPRviz, a multi-level visualization method for large graphs. Lying in the core of PPRviz is a new measure of graph node distance, PDist, that is specifically designed for visualization. In particular, PDist is formulated based on personalized PageRank, and it provides non-trivial theoretical guarantees for two well-adopted aesthetic measures. We present efficient algorithms for estimating PDist with provable accuracy and time complexity, while incurring small preprocessing costs. Extensive experiments show that PPRviz significantly outperforms 13 state-of-the-art competitors on 12 real-world graphs in terms of both effectiveness and efficiency, and that PPRviz provides interactive visualizations within one second on billion-edge graphs. ",
    "url": "https://arxiv.org/abs/2112.14944",
    "authors": [
      "Shiqi Zhang",
      "Renchi Yang",
      "Xiaokui Xiao",
      "Xiao Yan",
      "Bo Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.14971",
    "title": "Contrastive Fine-grained Class Clustering via Generative Adversarial  Networks",
    "abstract": "Unsupervised fine-grained class clustering is practical yet challenging task due to the difficulty of feature representations learning of subtle object details. We introduce C3-GAN, a method that leverages the categorical inference power of InfoGAN by applying contrastive learning. We aim to learn feature representations that encourage the data to form distinct cluster boundaries in the embedding space, while also maximizing the mutual information between the latent code and its observation. Our approach is to train the discriminator, which is used for inferring clusters, to optimize the contrastive loss, where the image-latent pairs that maximize the mutual information are considered as positive pairs and the rest as negative pairs. Specifically, we map the input of the generator, which has sampled from the categorical distribution, to the embedding space of the discriminator and let them act as a cluster centroid. In this way, C3-GAN achieved to learn a clustering-friendly embedding space where each cluster is distinctively separable. Experimental results show that C3-GAN achieved state-of-the-art clustering performance on four fine-grained benchmark datasets, while also alleviating the mode collapse phenomenon. ",
    "url": "https://arxiv.org/abs/2112.14971",
    "authors": [
      "Yunji Kim",
      "Jung-Woo Ha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.14983",
    "title": "Exploring the pattern of Emotion in children with ASD as an early  biomarker through Recurring-Convolution Neural Network (R-CNN)",
    "abstract": "Autism Spectrum Disorder (ASD) is found to be a major concern among various occupational therapists. The foremost challenge of this neurodevelopmental disorder lies in the fact of analyzing and exploring various symptoms of the children at their early stage of development. Such early identification could prop up the therapists and clinicians to provide proper assistive support to make the children lead an independent life. Facial expressions and emotions perceived by the children could contribute to such early intervention of autism. In this regard, the paper implements in identifying basic facial expression and exploring their emotions upon a time variant factor. The emotions are analyzed by incorporating the facial expression identified through CNN using 68 landmark points plotted on the frontal face with a prediction network formed by RNN known as RCNN-FER system. The paper adopts R-CNN to take the advantage of increased accuracy and performance with decreased time complexity in predicting emotion as a textual network analysis. The papers proves better accuracy in identifying the emotion in autistic children when compared over simple machine learning models built for such identifications contributing to autistic society. ",
    "url": "https://arxiv.org/abs/2112.14983",
    "authors": [
      "Abirami S P",
      "Kousalya G",
      "Karthick R"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.14985",
    "title": "THE Benchmark: Transferable Representation Learning for Monocular Height  Estimation",
    "abstract": "Generating 3D city models rapidly is crucial for many applications. Monocular height estimation is one of the most efficient and timely ways to obtain large-scale geometric information. However, existing works focus primarily on training and testing models using unbiased datasets, which don't align well with real-world applications. Therefore, we propose a new benchmark dataset to study the transferability of height estimation models in a cross-dataset setting. To this end, we first design and construct a large-scale benchmark dataset for cross-dataset transfer learning on the height estimation task. This benchmark dataset includes a newly proposed large-scale synthetic dataset, a newly collected real-world dataset, and four existing datasets from different cities. Next, two new experimental protocols, zero-shot and few-shot cross-dataset transfer, are designed. For few-shot cross-dataset transfer, we enhance the window-based Transformer with the proposed scale-deformable convolution module to handle the severe scale-variation problem. To improve the generalizability of deep models in the zero-shot cross-dataset setting, a max-normalization-based Transformer network is designed to decouple the relative height map from the absolute heights. Experimental results have demonstrated the effectiveness of the proposed methods in both the traditional and cross-dataset transfer settings. The datasets and codes are publicly available at https://thebenchmarkh.github.io/. ",
    "url": "https://arxiv.org/abs/2112.14985",
    "authors": [
      "Zhitong Xiong",
      "Wei Huang",
      "Jingtao Hu",
      "Yilei Shi",
      "Qi Wang",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15012",
    "title": "Investigating Pose Representations and Motion Contexts Modeling for 3D  Motion Prediction",
    "abstract": "Predicting human motion from historical pose sequence is crucial for a machine to succeed in intelligent interactions with humans. One aspect that has been obviated so far, is the fact that how we represent the skeletal pose has a critical impact on the prediction results. Yet there is no effort that investigates across different pose representation schemes. We conduct an indepth study on various pose representations with a focus on their effects on the motion prediction task. Moreover, recent approaches build upon off-the-shelf RNN units for motion prediction. These approaches process input pose sequence sequentially and inherently have difficulties in capturing long-term dependencies. In this paper, we propose a novel RNN architecture termed AHMR (Attentive Hierarchical Motion Recurrent network) for motion prediction which simultaneously models local motion contexts and a global context. We further explore a geodesic loss and a forward kinematics loss for the motion prediction task, which have more geometric significance than the widely employed L2 loss. Interestingly, we applied our method to a range of articulate objects including human, fish, and mouse. Empirical results show that our approach outperforms the state-of-the-art methods in short-term prediction and achieves much enhanced long-term prediction proficiency, such as retaining natural human-like motions over 50 seconds predictions. Our codes are released. ",
    "url": "https://arxiv.org/abs/2112.15012",
    "authors": [
      "Zhenguang Liu",
      "Shuang Wu",
      "Shuyuan Jin",
      "Shouling Ji",
      "Qi Liu",
      "Shijian Lu",
      "Li Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15015",
    "title": "Measuring and Sampling: A Metric-guided Subgraph Learning Framework for  Graph Neural Network",
    "abstract": "Graph neural network (GNN) has shown convincing performance in learning powerful node representations that preserve both node attributes and graph structural information. However, many GNNs encounter problems in effectiveness and efficiency when they are designed with a deeper network structure or handle large-sized graphs. Several sampling algorithms have been proposed for improving and accelerating the training of GNNs, yet they ignore understanding the source of GNN performance gain. The measurement of information within graph data can help the sampling algorithms to keep high-value information while removing redundant information and even noise. In this paper, we propose a Metric-Guided (MeGuide) subgraph learning framework for GNNs. MeGuide employs two novel metrics: Feature Smoothness and Connection Failure Distance to guide the subgraph sampling and mini-batch based training. Feature Smoothness is designed for analyzing the feature of nodes in order to retain the most valuable information, while Connection Failure Distance can measure the structural information to control the size of subgraphs. We demonstrate the effectiveness and efficiency of MeGuide in training various GNNs on multiple datasets. ",
    "url": "https://arxiv.org/abs/2112.15015",
    "authors": [
      "Jiyang Bai",
      "Yuxiang Ren",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15022",
    "title": "Continually Learning Self-Supervised Representations with Projected  Functional Regularization",
    "abstract": "Recent self-supervised learning methods are able to learn high-quality image representations and are closing the gap with supervised methods. However, these methods are unable to acquire new knowledge incrementally -- they are, in fact, mostly used only as a pre-training phase with IID data. In this work we investigate self-supervised methods in continual learning regimes without additional memory or replay. To prevent forgetting of previous knowledge, we propose the usage of functional regularization. We will show that naive functional regularization, also known as feature distillation, leads to low plasticity and therefore seriously limits continual learning performance. To address this problem, we propose Projected Functional Regularization where a separate projection network ensures that the newly learned feature space preserves information of the previous feature space, while allowing for the learning of new features. This allows us to prevent forgetting while maintaining the plasticity of the learner. Evaluation against other incremental learning approaches applied to self-supervision demonstrates that our method obtains competitive performance in different scenarios and on multiple datasets. ",
    "url": "https://arxiv.org/abs/2112.15022",
    "authors": [
      "Alex Gomez-Villa",
      "Bartlomiej Twardowski",
      "Lu Yu",
      "Andrew D. Bagdanov",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15026",
    "title": "Two Instances of Interpretable Neural Network for Universal  Approximations",
    "abstract": "This paper proposes two bottom-up interpretable neural network (NN) constructions for universal approximation, namely Triangularly-constructed NN (TNN) and Semi-Quantized Activation NN (SQANN). The notable properties are (1) resistance to catastrophic forgetting (2) existence of proof for arbitrarily high accuracies on training dataset (3) for an input \\(x\\), users can identify specific samples of training data whose activation ``fingerprints\" are similar to that of \\(x\\)'s activations. Users can also identify samples that are out of distribution. ",
    "url": "https://arxiv.org/abs/2112.15026",
    "authors": [
      "Erico Tjoa",
      "Guan Cuntai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15031",
    "title": "Development of a face mask detection pipeline for mask-wearing  monitoring in the era of the COVID-19 pandemic: A modular approach",
    "abstract": "During the SARS-Cov-2 pandemic, mask-wearing became an effective tool to prevent spreading and contracting the virus. The ability to monitor the mask-wearing rate in the population would be useful for determining public health strategies against the virus. However, artificial intelligence technologies for detecting face masks have not been deployed at a large scale in real-life to measure the mask-wearing rate in public. In this paper, we present a two-step face mask detection approach consisting of two separate modules: 1) face detection and alignment and 2) face mask classification. This approach allowed us to experiment with different combinations of face detection and face mask classification modules. More specifically, we experimented with PyramidKey and RetinaFace as face detectors while maintaining a lightweight backbone for the face mask classification module. Moreover, we also provide a relabeled annotation of the test set of the AIZOO dataset, where we rectified the incorrect labels for some face images. The evaluation results on the AIZOO and Moxa 3K datasets showed that the proposed face mask detection pipeline surpassed the state-of-the-art methods. The proposed pipeline also yielded a higher mAP on the relabeled test set of the AIZOO dataset than the original test set. Since we trained the proposed model using in-the-wild face images, we can successfully deploy our model to monitor the mask-wearing rate using public CCTV images. ",
    "url": "https://arxiv.org/abs/2112.15031",
    "authors": [
      "Benjaphan Sommana",
      "Ukrit Watchareeruetai",
      "Ankush Ganguly",
      "Samuel W.F. Earp",
      "Taya Kitiyakara",
      "Suparee Boonmanunt",
      "Ratchainant Thammasudjarit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15060",
    "title": "TextRGNN: Residual Graph Neural Networks for Text Classification",
    "abstract": "Recently, text classification model based on graph neural network (GNN) has attracted more and more attention. Most of these models adopt a similar network paradigm, that is, using pre-training node embedding initialization and two-layer graph convolution. In this work, we propose TextRGNN, an improved GNN structure that introduces residual connection to deepen the convolution network depth. Our structure can obtain a wider node receptive field and effectively suppress the over-smoothing of node features. In addition, we integrate the probabilistic language model into the initialization of graph node embedding, so that the non-graph semantic information of can be better extracted. The experimental results show that our model is general and efficient. It can significantly improve the classification accuracy whether in corpus level or text level, and achieve SOTA performance on a wide range of text classification datasets. ",
    "url": "https://arxiv.org/abs/2112.15060",
    "authors": [
      "Jiayuan Chen",
      "Boyu Zhang",
      "Yinfei Xu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15065",
    "title": "V2V-Based Task Offloading and Resource Allocation in Vehicular Edge  Computing Networks",
    "abstract": "In the research and application of vehicle ad hoc networks (VANETs), it is often assumed that vehicles obtain cloud computing services by accessing to roadside units (RSUs). However, due to the problems of insufficient construction quantity, limited communication range and overload of calculation load of roadside units, the calculation mode relying only on vehicle to roadside units is difficult to deal with complex and changeable calculation tasks. In this paper, when the roadside unit is missing, the vehicle mobile unit is regarded as a natural edge computing node to make full use of the excess computing power of mobile vehicles and perform the offloading task of surrounding mobile vehicles in time. In this paper, the OPFTO framework is designed, an improved task allocation algorithm HGSA is proposed, and the pre-filtering process is designed with full consideration of the moving characteristics of vehicles. In addition, vehicle simulation experiments show that the proposed strategy has the advantages of low delay and high accuracy compared with other task scheduling strategies, which provides a reference scheme for the construction of Urban Intelligent Transportation in the future. ",
    "url": "https://arxiv.org/abs/2112.15065",
    "authors": [
      "Junjin He",
      "Yujie Wang",
      "Xin Du",
      "Zhihui Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.15085",
    "title": "Feature Extraction and Prediction for Hand Hygiene Gestures with KNN  Algorithm",
    "abstract": "This work focuses upon the analysis of hand gestures involved in the process of hand washing. There are six standard hand hygiene gestures for washing hands as provided by World Health Organisation hand hygiene guidelines. In this paper, hand features such as contours of hands, the centroid of the hands, and extreme hand points along the largest contour are extracted with the use of the computer vision library, OpenCV. These hand features are extracted for each data frame in a hand hygiene video. A robust hand hygiene dataset of video recordings was created in the project. A subset of this dataset is used in this work. Extracted hand features are further grouped into classes based on the KNN algorithm with a cross-fold validation technique for the classification and prediction of the unlabelled data. A mean accuracy score of >95% is achieved and proves that the KNN algorithm with an appropriate input value of K=5 is efficient for classification. A complete dataset with six distinct hand hygiene classes will be used with the KNN classifier for future work. ",
    "url": "https://arxiv.org/abs/2112.15085",
    "authors": [
      "Rashmi Bakshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15089",
    "title": "Deconfounded Training for Graph Neural Networks",
    "abstract": "Learning powerful representations is one central theme of graph neural networks (GNNs). It requires refining the critical information from the input graph, instead of the trivial patterns, to enrich the representations. Towards this end, graph attention and pooling methods prevail. They mostly follow the paradigm of \"learning to attend\". It maximizes the mutual information between the attended subgraph and the ground-truth label. However, this training paradigm is prone to capture the spurious correlations between the trivial subgraph and the label. Such spurious correlations are beneficial to in-distribution (ID) test evaluations, but cause poor generalization in the out-of-distribution (OOD) test data. In this work, we revisit the GNN modeling from the causal perspective. On the top of our causal assumption, the trivial information serves as a confounder between the critical information and the label, which opens a backdoor path between them and makes them spuriously correlated. Hence, we present a new paradigm of deconfounded training (DTP) that better mitigates the confounding effect and latches on the critical information, to enhance the representation and generalization ability. Specifically, we adopt the attention modules to disentangle the critical subgraph and trivial subgraph. Then we make each critical subgraph fairly interact with diverse trivial subgraphs to achieve a stable prediction. It allows GNNs to capture a more reliable subgraph whose relation with the label is robust across different distributions. We conduct extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness. ",
    "url": "https://arxiv.org/abs/2112.15089",
    "authors": [
      "Yongduo Sui",
      "Xiang Wang",
      "Jiancan Wu",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15110",
    "title": "Audio-to-symbolic Arrangement via Cross-modal Music Representation  Learning",
    "abstract": "Could we automatically derive the score of a piano accompaniment based on the audio of a pop song? This is the audio-to-symbolic arrangement problem we tackle in this paper. A good arrangement model should not only consider the audio content but also have prior knowledge of piano composition (so that the generation \"sounds like\" the audio and meanwhile maintains musicality.) To this end, we contribute a cross-modal representation-learning model, which 1) extracts chord and melodic information from the audio, and 2) learns texture representation from both audio and a corrupted ground truth arrangement. We further introduce a tailored training strategy that gradually shifts the source of texture information from corrupted score to audio. In the end, the score-based texture posterior is reduced to a standard normal distribution, and only audio is needed for inference. Experiments show that our model captures major audio information and outperforms baselines in generation quality. ",
    "url": "https://arxiv.org/abs/2112.15110",
    "authors": [
      "Ziyu Wang",
      "Dejing Xu",
      "Gus Xia",
      "Ying Shan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.15121",
    "title": "On the Role of Neural Collapse in Transfer Learning",
    "abstract": "We study the ability of foundation models to learn representations for classification that are transferable to new, unseen classes. Recent results in the literature show that representations learned by a single classifier over many classes are competitive on few-shot learning problems with representations learned by special-purpose algorithms designed for such problems. In this paper we provide an explanation for this behavior based on the recently observed phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. We demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and -- more importantly -- to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting. ",
    "url": "https://arxiv.org/abs/2112.15121",
    "authors": [
      "Tomer Galanti",
      "Andr\u00e1s Gy\u00f6rgy",
      "Marcus Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15124",
    "title": "Utilizing Wordnets for Cognate Detection among Indian Languages",
    "abstract": "Automatic Cognate Detection (ACD) is a challenging task which has been utilized to help NLP applications like Machine Translation, Information Retrieval and Computational Phylogenetics. Unidentified cognate pairs can pose a challenge to these applications and result in a degradation of performance. In this paper, we detect cognate word pairs among ten Indian languages with Hindi and use deep learning methodologies to predict whether a word pair is cognate or not. We identify IndoWordnet as a potential resource to detect cognate word pairs based on orthographic similarity-based methods and train neural network models using the data obtained from it. We identify parallel corpora as another potential resource and perform the same experiments for them. We also validate the contribution of Wordnets through further experimentation and report improved performance of up to 26%. We discuss the nuances of cognate detection among closely related Indian languages and release the lists of detected cognates as a dataset. We also observe the behaviour of, to an extent, unrelated Indian language pairs and release the lists of detected cognates among them as well. ",
    "url": "https://arxiv.org/abs/2112.15124",
    "authors": [
      "Diptesh Kanojia",
      "Kevin Patel",
      "Pushpak Bhattacharyya",
      "Malhar Kulkarni",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.15139",
    "title": "Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural  Networks",
    "abstract": "Quantized neural networks typically require smaller memory footprints and lower computation complexity, which is crucial for efficient deployment. However, quantization inevitably leads to a distribution divergence from the original network, which generally degrades the performance. To tackle this issue, massive efforts have been made, but most existing approaches lack statistical considerations and depend on several manual configurations. In this paper, we present an adaptive-mapping quantization method to learn an optimal latent sub-distribution that is inherent within models and smoothly approximated with a concrete Gaussian Mixture (GM). In particular, the network weights are projected in compliance with the GM-approximated sub-distribution. This sub-distribution evolves along with the weight update in a co-tuning schema guided by the direct task-objective optimization. Sufficient experiments on image classification and object detection over various modern architectures demonstrate the effectiveness, generalization property, and transferability of the proposed method. Besides, an efficient deployment flow for the mobile CPU is developed, achieving up to 7.46$\\times$ inference acceleration on an octa-core ARM CPU. Codes are publicly released at https://github.com/RunpeiDong/DGMS. ",
    "url": "https://arxiv.org/abs/2112.15139",
    "authors": [
      "Runpei Dong",
      "Zhanhong Tan",
      "Mengdi Wu",
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15156",
    "title": "Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal  Difference and Successor Representation",
    "abstract": "Distributed Multi-Agent Reinforcement Learning (MARL) algorithms has attracted a surge of interest lately mainly due to the recent advancements of Deep Neural Networks (DNNs). Conventional Model-Based (MB) or Model-Free (MF) RL algorithms are not directly applicable to the MARL problems due to utilization of a fixed reward model for learning the underlying value function. While DNN-based solutions perform utterly well when a single agent is involved, such methods fail to fully generalize to the complexities of MARL problems. In other words, although recently developed approaches based on DNNs for multi-agent environments have achieved superior performance, they are still prone to overfiting, high sensitivity to parameter selection, and sample inefficiency. The paper proposes the Multi-Agent Adaptive Kalman Temporal Difference (MAK-TD) framework and its Successor Representation-based variant, referred to as the MAK-SR. Intuitively speaking, the main objective is to capitalize on unique characteristics of Kalman Filtering (KF) such as uncertainty modeling and online second order learning. The proposed MAK-TD/SR frameworks consider the continuous nature of the action-space that is associated with high dimensional multi-agent environments and exploit Kalman Temporal Difference (KTD) to address the parameter uncertainty. By leveraging the KTD framework, SR learning procedure is modeled into a filtering problem, where Radial Basis Function (RBF) estimators are used to encode the continuous space into feature vectors. On the other hand, for learning localized reward functions, we resort to Multiple Model Adaptive Estimation (MMAE), to deal with the lack of prior knowledge on the observation noise covariance and observation mapping function. The proposed MAK-TD/SR frameworks are evaluated via several experiments, which are implemented through the OpenAI Gym MARL benchmarks. ",
    "url": "https://arxiv.org/abs/2112.15156",
    "authors": [
      "Mohammad Salimibeni",
      "Arash Mohammadi",
      "Parvin Malekzadeh",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.15188",
    "title": "Towards Robustness of Neural Networks",
    "abstract": "We introduce several new datasets namely ImageNet-A/O and ImageNet-R as well as a synthetic environment and testing suite we called CAOS. ImageNet-A/O allow researchers to focus in on the blind spots remaining in ImageNet. ImageNet-R was specifically created with the intention of tracking robust representation as the representations are no longer simply natural but include artistic, and other renditions. The CAOS suite is built off of CARLA simulator which allows for the inclusion of anomalous objects and can create reproducible synthetic environment and scenes for testing robustness. All of the datasets were created for testing robustness and measuring progress in robustness. The datasets have been used in various other works to measure their own progress in robustness and allowing for tangential progress that does not focus exclusively on natural accuracy. Given these datasets, we created several novel methods that aim to advance robustness research. We build off of simple baselines in the form of Maximum Logit, and Typicality Score as well as create a novel data augmentation method in the form of DeepAugment that improves on the aforementioned benchmarks. Maximum Logit considers the logit values instead of the values after the softmax operation, while a small change produces noticeable improvements. The Typicality Score compares the output distribution to a posterior distribution over classes. We show that this improves performance over the baseline in all but the segmentation task. Speculating that perhaps at the pixel level the semantic information of a pixel is less meaningful than that of class level information. Finally the new augmentation technique of DeepAugment utilizes neural networks to create augmentations on images that are radically different than the traditional geometric and camera based transformations used previously. ",
    "url": "https://arxiv.org/abs/2112.15188",
    "authors": [
      "Steven Basart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15230",
    "title": "AntiCopyPaster: Extracting Code Duplicates As Soon As They Are  Introduced in the IDE",
    "abstract": "We have developed a plugin for IntelliJ IDEA called AntiCopyPaster that tracks the pasting of code inside the IDE and suggests appropriate Extract Method refactorings to combat the propagation of duplicates. To implement the plugin, we gathered a dataset of code fragments that should and should not be extracted, compiled a list of metrics of code that can influence the decision, and trained several popular classifying machine learning models, of which a gradient boosting classifier showed the best results. When a developer pastes a code fragment, the plugin searches for duplicates in the currently opened file. If there are any, it waits for a short period of time to allow the developer to edit the code. If the code duplicates are still present after a delay, AntiCopyPaster calculates the metrics for the fragment and inferences the decision: if the fragment should be extracted, the plugin suggests to refactor it. This can help the developers to keep their code clean and save them future maintenance time by providing the possibility to refactor code timely and without losing the context. You can find the plugin and its source code on GitHub at https://github.com/JetBrains-Research/anti-copy-paster. ",
    "url": "https://arxiv.org/abs/2112.15230",
    "authors": [
      "Anton Ivanov",
      "Zarina Kurbatova",
      "Yaroslav Golubev",
      "Andrey Kirilenko",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.15250",
    "title": "Benign Overfitting in Adversarially Robust Linear Classification",
    "abstract": "\"Benign overfitting\", where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification in over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting still occurs in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under $\\ell_p$ adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2112.15250",
    "authors": [
      "Jinghui Chen",
      "Yuan Cao",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.15270",
    "title": "Echo state graph neural networks with analogue random resistor arrays",
    "abstract": "Recent years have witnessed an unprecedented surge of interest, from social networks to drug discovery, in learning representations of graph-structured data. However, graph neural networks, the machine learning models for handling graph-structured data, face significant challenges when running on conventional digital hardware, including von Neumann bottleneck incurred by physically separated memory and processing units, slowdown of Moore's law due to transistor scaling limit, and expensive training cost. Here we present a novel hardware-software co-design, the random resistor array-based echo state graph neural network, which addresses these challenges. The random resistor arrays not only harness low-cost, nanoscale and stackable resistors for highly efficient in-memory computing using simple physical laws, but also leverage the intrinsic stochasticity of dielectric breakdown to implement random projections in hardware for an echo state network that effectively minimizes the training cost thanks to its fixed and random weights. The system demonstrates state-of-the-art performance on both graph classification using the MUTAG and COLLAB datasets and node classification using the CORA dataset, achieving 34.2x, 93.2x, and 570.4x improvement of energy efficiency and 98.27%, 99.46%, and 95.12% reduction of training cost compared to conventional graph learning on digital hardware, respectively, which may pave the way for the next generation AI system for graph learning. ",
    "url": "https://arxiv.org/abs/2112.15270",
    "authors": [
      "Shaocong Wang",
      "Yi Li",
      "Dingchen Wang",
      "Woyu Zhang",
      "Xi Chen",
      "Danian Dong",
      "Songqi Wang",
      "Xumeng Zhang",
      "Peng Lin",
      "Claudio Gallicchio",
      "Xiaoxin Xu",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Zhongrui Wang",
      "Dashan Shang",
      "Ming Liu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2112.15271",
    "title": "BP-Net: Cuff-less, Calibration-free, and Non-invasive Blood Pressure  Estimation via a Generic Deep Convolutional Architecture",
    "abstract": "Objective: The paper focuses on development of robust and accurate processing solutions for continuous and cuff-less blood pressure (BP) monitoring. In this regard, a robust deep learning-based framework is proposed for computation of low latency, continuous, and calibration-free upper and lower bounds on the systolic and diastolic BP. Method: Referred to as the BP-Net, the proposed framework is a novel convolutional architecture that provides longer effective memory while achieving superior performance due to incorporation of casual dialated convolutions and residual connections. To utilize the real potential of deep learning in extraction of intrinsic features (deep features) and enhance the long-term robustness, the BP-Net uses raw Electrocardiograph (ECG) and Photoplethysmograph (PPG) signals without extraction of any form of hand-crafted features as it is common in existing solutions. Results: By capitalizing on the fact that datasets used in recent literature are not unified and properly defined, a benchmark dataset is constructed from the MIMIC-I and MIMIC-III databases obtained from PhysioNet. The proposed BP-Net is evaluated based on this benchmark dataset demonstrating promising performance and shows superior generalizable capacity. Conclusion: The proposed BP-Net architecture is more accurate than canonical recurrent networks and enhances the long-term robustness of the BP estimation task. Significance: The proposed BP-Net architecture addresses key drawbacks of existing BP estimation solutions, i.e., relying heavily on extraction of hand-crafted features, such as pulse arrival time (PAT), and; Lack of robustness. Finally, the constructed BP-Net dataset provides a unified base for evaluation and comparison of deep learning-based BP estimation algorithms. ",
    "url": "https://arxiv.org/abs/2112.15271",
    "authors": [
      "Soheil Zabihi",
      "Elahe Rahimian",
      "Fatemeh Marefat",
      "Amir Asif",
      "Pedram Mohseni",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.15272",
    "title": "ViNMT: Neural Machine Translation Tookit",
    "abstract": "We present an open-source toolkit for neural machine translation (NMT). The new toolkit is mainly based on vaulted Transformer (Vaswani et al., 2017) along with many other improvements detailed below, in order to create a self-contained, simple to use, consistent and comprehensive framework for Machine Translation tasks of various domains. It is tooled to support both bilingual and multilingual translation tasks, starting from building the model from respective corpora, to inferring new predictions or packaging the model to serving-capable JIT format. ",
    "url": "https://arxiv.org/abs/2112.15272",
    "authors": [
      "Nguyen Hoang Quan",
      "Nguyen Thanh Dat",
      "Nguyen Hoang Minh Cong",
      "Nguyen Van Vinh",
      "Ngo Thi Vinh",
      "Nguyen Phuong Thai",
      "Tran Hong Viet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15290",
    "title": "Domain Adaptation with Category Attention Network for Deep Sentiment  Analysis",
    "abstract": "Domain adaptation tasks such as cross-domain sentiment classification aim to utilize existing labeled data in the source domain and unlabeled or few labeled data in the target domain to improve the performance in the target domain via reducing the shift between the data distributions. Existing cross-domain sentiment classification methods need to distinguish pivots, i.e., the domain-shared sentiment words, and non-pivots, i.e., the domain-specific sentiment words, for excellent adaptation performance. In this paper, we first design a Category Attention Network (CAN), and then propose a model named CAN-CNN to integrate CAN and a Convolutional Neural Network (CNN). On the one hand, the model regards pivots and non-pivots as unified category attribute words and can automatically capture them to improve the domain adaptation performance; on the other hand, the model makes an attempt at interpretability to learn the transferred category attribute words. Specifically, the optimization objective of our model has three different components: 1) the supervised classification loss; 2) the distributions loss of category feature weights; 3) the domain invariance loss. Finally, the proposed model is evaluated on three public sentiment analysis datasets and the results demonstrate that CAN-CNN can outperform other various baseline methods. ",
    "url": "https://arxiv.org/abs/2112.15290",
    "authors": [
      "Dongbo Xi",
      "Fuzhen Zhuang",
      "Ganbin Zhou",
      "Xiaohu Cheng",
      "Fen Lin",
      "Qing He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15292",
    "title": "Neural Hierarchical Factorization Machines for User's Event Sequence  Analysis",
    "abstract": "Many prediction tasks of real-world applications need to model multi-order feature interactions in user's event sequence for better detection performance. However, existing popular solutions usually suffer two key issues: 1) only focusing on feature interactions and failing to capture the sequence influence; 2) only focusing on sequence information, but ignoring internal feature relations of each event, thus failing to extract a better event representation. In this paper, we consider a two-level structure for capturing the hierarchical information over user's event sequence: 1) learning effective feature interactions based event representation; 2) modeling the sequence representation of user's historical events. Experimental results on both industrial and public datasets clearly demonstrate that our model achieves significantly better performance compared with state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2112.15292",
    "authors": [
      "Dongbo Xi",
      "Fuzhen Zhuang",
      "Bowen Song",
      "Yongchun Zhu",
      "Shuai Chen",
      "Dan Hong",
      "Tao Chen",
      "Xi Gu",
      "Qing He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15303",
    "title": "SimSR: Simple Distance-based State Representation for Deep Reinforcement  Learning",
    "abstract": "This work explores how to learn robust and generalizable state representation from image-based observations with deep reinforcement learning methods. Addressing the computational complexity, stringent assumptions, and representation collapse challenges in the existing work of bisimulation metric, we devise Simple State Representation (SimSR) operator, which achieves equivalent functionality while reducing the complexity by an order in comparison with bisimulation metric. SimSR enables us to design a stochastic-approximation-based method that can practically learn the mapping functions (encoders) from observations to latent representation space. Besides the theoretical analysis, we experimented and compared our work with recent state-of-the-art solutions in visual MuJoCo tasks. The results show that our model generally achieves better performance and has better robustness and good generalization. ",
    "url": "https://arxiv.org/abs/2112.15303",
    "authors": [
      "Hongyu Zang",
      "Xin Li",
      "Mingzhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15311",
    "title": "Bayesian Optimization of Function Networks",
    "abstract": "We consider Bayesian optimization of the output of a network of functions, where each function takes as input the output of its parent nodes, and where the network takes significant time to evaluate. Such problems arise, for example, in reinforcement learning, engineering design, and manufacturing. While the standard Bayesian optimization approach observes only the final output, our approach delivers greater query efficiency by leveraging information that the former ignores: intermediate output within the network. This is achieved by modeling the nodes of the network using Gaussian processes and choosing the points to evaluate using, as our acquisition function, the expected improvement computed with respect to the implied posterior on the objective. Although the non-Gaussian nature of this posterior prevents computing our acquisition function in closed form, we show that it can be efficiently maximized via sample average approximation. In addition, we prove that our method is asymptotically consistent, meaning that it finds a globally optimal solution as the number of evaluations grows to infinity, thus generalizing previously known convergence results for the expected improvement. Notably, this holds even though our method might not evaluate the domain densely, instead leveraging problem structure to leave regions unexplored. Finally, we show that our approach dramatically outperforms standard Bayesian optimization methods in several synthetic and real-world problems. ",
    "url": "https://arxiv.org/abs/2112.15311",
    "authors": [
      "Raul Astudillo",
      "Peter I. Frazier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.15320",
    "title": "InverseMV: Composing Piano Scores with a Convolutional Video-Music  Transformer",
    "abstract": "Many social media users prefer consuming content in the form of videos rather than text. However, in order for content creators to produce videos with a high click-through rate, much editing is needed to match the footage to the music. This posts additional challenges for more amateur video makers. Therefore, we propose a novel attention-based model VMT (Video-Music Transformer) that automatically generates piano scores from video frames. Using music generated from models also prevent potential copyright infringements that often come with using existing music. To the best of our knowledge, there is no work besides the proposed VMT that aims to compose music for video. Additionally, there lacks a dataset with aligned video and symbolic music. We release a new dataset composed of over 7 hours of piano scores with fine alignment between pop music videos and MIDI files. We conduct experiments with human evaluation on VMT, SeqSeq model (our baseline), and the original piano version soundtrack. VMT achieves consistent improvements over the baseline on music smoothness and video relevance. In particular, with the relevance scores and our case study, our model has shown the capability of multimodality on frame-level actors' movement for music generation. Our VMT model, along with the new dataset, presents a promising research direction toward composing the matching soundtrack for videos. We have released our code at https://github.com/linchintung/VMT ",
    "url": "https://arxiv.org/abs/2112.15320",
    "authors": [
      "Chin-Tung Lin",
      "Mu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2112.15322",
    "title": "An Efficient and Robust Committee Structure for Sharding Blockchain",
    "abstract": "Nowadays, sharding is deemed as a promising way to save traditional blockchain protocols from their low scalability. However, such technique also brings several potential risks and huge communication overheads. An improper design may give rise to the inconsistent state among different committees. Further, the communication overheads arising from cross-shard transactions unfortunately reduce the system's performance. In this paper, we first summarize five essential issues that all sharding blockchain designers face. For each issue, we discuss its key challenge and propose our suggested solutions. In order to break the performance bottlenecks, we propose a reputation mechanism for selecting leaders. The term of reputation in our design reflects each node's honest computation resources. In addition, we introduce a referee committee and partial sets in each committee, and design a recovery procedure in case the leader is malicious. Under the design, we prove that malicious leaders will not hurt the system and will be evicted. Furthermore, we conduct a series of simulations to evaluate our design. The results show that selecting leaders by the reputation can dramatically improve the system performance. ",
    "url": "https://arxiv.org/abs/2112.15322",
    "authors": [
      "Mengqian Zhang",
      "Jichen Li",
      "Zhaohua Chen",
      "Hongyin Chen",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.15328",
    "title": "Temporal aware Multi-Interest Graph Neural Network For Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) is a challenging task, which aims at recommending next items based on anonymous interaction sequences. Despite the superior performance of existing methods for SBR, there are still several limitations: (i) Almost all existing works concentrate on single interest extraction and fail to disentangle multiple interests of user, which easily results in suboptimal representations for SBR. (ii) Furthermore, previous methods also ignore the multi-form temporal information, which is significant signal to obtain current intention for SBR. To address the limitations mentioned above, we propose a novel method, called \\emph{Temporal aware Multi-Interest Graph Neural Network} (TMI-GNN) to disentangle multi-interest and yield refined intention representations with the injection of two level temporal information. Specifically, by appending multiple interest nodes, we construct a multi-interest graph for current session, and adopt the GNNs to model the item-item relation to capture adjacent item transitions, item-interest relation to disentangle the multi-interests, and interest-item relation to refine the item representation. Meanwhile, we incorporate item-level time interval signals to guide the item information propagation, and interest-level time distribution information to assist the scattering of interest information. Experiments on three benchmark datasets demonstrate that TMI-GNN outperforms other state-of-the-art methods consistently. ",
    "url": "https://arxiv.org/abs/2112.15328",
    "authors": [
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.15336",
    "title": "Improved Algorithm for the Network Alignment Problem with Application to  Binary Diffing",
    "abstract": "In this paper, we present a novel algorithm to address the Network Alignment problem. It is inspired from a previous message passing framework of Bayati et al. [2] and includes several modifications designed to significantly speed up the message updates as well as to enforce their convergence. Experiments show that our proposed model outperforms other state-of-the-art solvers. Finally, we propose an application of our method in order to address the Binary Diffing problem. We show that our solution provides better assignment than the reference differs in almost all submitted instances and outline the importance of leveraging the graphical structure of binary programs. ",
    "url": "https://arxiv.org/abs/2112.15336",
    "authors": [
      "Elie Mengin",
      "Fabrice Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.15337",
    "title": "Binary Diffing as a Network Alignment Problem via Belief Propagation",
    "abstract": "In this paper, we address the problem of finding a correspondence, or matching, between the functions of two programs in binary form, which is one of the most common task in binary diffing. We introduce a new formulation of this problem as a particular instance of a graph edit problem over the call graphs of the programs. In this formulation, the quality of a mapping is evaluated simultaneously with respect to both function content and call graph similarities. We show that this formulation is equivalent to a network alignment problem. We propose a solving strategy for this problem based on max-product belief propagation. Finally, we implement a prototype of our method, called QBinDiff, and propose an extensive evaluation which shows that our approach outperforms state of the art diffing tools. ",
    "url": "https://arxiv.org/abs/2112.15337",
    "authors": [
      "Elie Mengin",
      "Fabrice Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.15345",
    "title": "Distributed Hybrid CPU and GPU training for Graph Neural Networks on  Billion-Scale Graphs",
    "abstract": "Graph neural networks (GNN) have shown great success in learning from graph-structured data. They are widely used in various applications, such as recommendation, fraud detection, and search. In these domains, the graphs are typically large, containing hundreds of millions or billions of nodes. To tackle this challenge, we develop DistDGLv2, a system that extends DistDGL for training GNNs in a mini-batch fashion, using distributed hybrid CPU/GPU training to scale to large graphs. DistDGLv2 places graph data in distributed CPU memory and performs mini-batch computation in GPUs. DistDGLv2 distributes the graph and its associated data (initial features) across the machines and uses this distribution to derive a computational decomposition by following an owner-compute rule. DistDGLv2 follows a synchronous training approach and allows ego-networks forming mini-batches to include non-local nodes. To minimize the overheads associated with distributed computations, DistDGLv2 uses a multi-level graph partitioning algorithm with min-edge cut along with multiple balancing constraints. This localizes computation in both machine level and GPU level and statically balance the computations. DistDGLv2 deploys an asynchronous mini-batch generation pipeline that makes all computation and data access asynchronous to fully utilize all hardware (CPU, GPU, network, PCIe). The combination allows DistDGLv2 to train high-quality models while achieving high parallel efficiency and memory scalability. We demonstrate DistDGLv2 on various GNN workloads. Our results show that DistDGLv2 achieves 2-3X speedup over DistDGL and 18X speedup over Euler. It takes only 5-10 seconds to complete an epoch on graphs with 100s millions of nodes on a cluster with 64 GPUs. ",
    "url": "https://arxiv.org/abs/2112.15345",
    "authors": [
      "Da Zheng",
      "Xiang Song",
      "Chengru Yang",
      "Dominique LaSalle",
      "Qidong Su",
      "Minjie Wang",
      "Chao Ma",
      "George Karypis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.15347",
    "title": "Complex contraction on trees without proof of correlation decay",
    "abstract": "We prove complex contraction for zero-free regions of counting weighted set cover problem in which an element can appear in an unbounded number of sets, thus obtaining fully polynomial-time approximation schemes(FPTAS) via Barvinok's algorithmic paradigm\\cite{barvinok2016combinatorics}. Relying on the computation tree expansion, our approach does not need proof of correlation decay in the real axis. We directly look in the complex plane for a region that contracts into its interior as the tree recursion procedure goes from leaves to the root. For the class of problems under the framework of weighted set covers, we are able to give a general approach for describing the contraction regions and draw a unified algorithmic conclusion. Several previous results, including counting (weighted-)edge covers, counting bipartite independent sets and counting monotone CNFs can be completely or partially covered by our main theorem. In contrast to the correlation decay method which also depends on tree expansions and needs different potential functions for different problems, our approach is more generic in the sense that our contraction region for different problems shares a common shape in the complex plane. ",
    "url": "https://arxiv.org/abs/2112.15347",
    "authors": [
      "Liang Li",
      "Guangzeng Xie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.15348",
    "title": "Training Recurrent Neural Networks by Sequential Least Squares and the  Alternating Direction Method of Multipliers",
    "abstract": "For training recurrent neural network models of nonlinear dynamical systems from an input/output training dataset based on rather arbitrary convex and twice-differentiable loss functions and regularization terms, we propose the use of sequential least squares for determining the optimal network parameters and hidden states. In addition, to handle non-smooth regularization terms such as L1, L0, and group-Lasso regularizers, as well as to impose possibly non-convex constraints such as integer and mixed-integer constraints, we combine sequential least squares with the alternating direction method of multipliers (ADMM). The performance of the resulting algorithm, that we call NAILS (Nonconvex ADMM Iterations and Least Squares), is tested in a nonlinear system identification benchmark. ",
    "url": "https://arxiv.org/abs/2112.15348",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.15352",
    "title": "Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation",
    "abstract": "Session-based recommendation (SBR) is proposed to recommend items within short sessions given that user profiles are invisible in various scenarios nowadays, such as e-commerce and short video recommendation. There is a common scenario that user specifies a target category of items as a global filter, however previous SBR settings mainly consider the item sequence and overlook the rich target category information in this scenario. Therefore, we define a new task called Category-aware Session-Based Recommendation (CSBR), focusing on the above scenario, in which the user-specified category can be efficiently utilized by the recommendation system. To address the challenges of the proposed task, we develop a novel method called Intention Adaptive Graph Neural Network (IAGNN), which takes advantage of relationship between items and their categories to achieve an accurate recommendation result. Specifically, we construct a category-aware graph with both item and category nodes to represent the complex transition information in the session. An intention-adaptive graph neural network on the category-aware graph is utilized to capture user intention by transferring the historical interaction information to the user-specified category domain. Extensive experiments on three real-world datasets are conducted to show our IAGNN outperforms the state-of-the-art baselines in the new task. ",
    "url": "https://arxiv.org/abs/2112.15352",
    "authors": [
      "Chuan Cui",
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Zhenwei Dong",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.15354",
    "title": "Statistical Device Activity Detection for OFDM-based Massive Grant-Free  Access",
    "abstract": "Existing works on grant-free access, proposed to support massive machine-type communication (mMTC) for the Internet of things (IoT), mainly concentrate on narrow band systems under flat fading. However, little is known about massive grant-free access for wideband systems under frequency-selective fading. This paper investigates massive grant-free access in a wideband system under frequency-selective fading. First, we present an orthogonal frequency division multiplexing (OFDM)-based massive grant-free access scheme. Then, we propose two different but equivalent models for the received pilot signal, which are essential for designing various device activity detection and channel estimation methods for OFDM-based massive grant-free access. One directly models the received signal for actual devices, whereas the other can be interpreted as a signal model for virtual devices. Next, we investigate statistical device activity detection under frequency-selective Rayleigh fading based on the two signal models. We first model device activities as unknown deterministic quantities and propose three maximum likelihood (ML) estimation-based device activity detection methods with different detection accuracies and computation times. We also model device activities as random variables with a known joint distribution and propose three maximum a posterior probability (MAP) estimation-based device activity methods, which further enhance the accuracies of the corresponding ML estimation-based methods. Optimization techniques and matrix analysis are applied in designing and analyzing these methods. Finally, numerical results show that the proposed statistical device activity detection methods outperform existing state-of-the-art device activity detection methods under frequency-selective Rayleigh fading. ",
    "url": "https://arxiv.org/abs/2112.15354",
    "authors": [
      "Yuhang Jia",
      "Ying Cui",
      "Wuyang Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.15355",
    "title": "Sparse LiDAR Assisted Self-supervised Stereo Disparity Estimation",
    "abstract": "Deep stereo matching has made significant progress in recent years. However, state-of-the-art methods are based on expensive 4D cost volume, which limits their use in real-world applications. To address this issue, 3D correlation maps and iterative disparity updates have been proposed. Regarding that in real-world platforms, such as self-driving cars and robots, the Lidar is usually installed. Thus we further introduce the sparse Lidar point into the iterative updates, which alleviates the burden of network updating the disparity from zero states. Furthermore, we propose training the network in a self-supervised way so that it can be trained on any captured data for better generalization ability. Experiments and comparisons show that the presented method is effective and achieves comparable results with related methods. ",
    "url": "https://arxiv.org/abs/2112.15355",
    "authors": [
      "Xiaoming Zhao",
      "Weihai Chen",
      "Xingming Wu",
      "Peter C. Y. Chen",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15364",
    "title": "Robust Entropy-regularized Markov Decision Processes",
    "abstract": "Stochastic and soft optimal policies resulting from entropy-regularized Markov decision processes (ER-MDP) are desirable for exploration and imitation learning applications. Motivated by the fact that such policies are sensitive with respect to the state transition probabilities, and the estimation of these probabilities may be inaccurate, we study a robust version of the ER-MDP model, where the stochastic optimal policies are required to be robust with respect to the ambiguity in the underlying transition probabilities. Our work is at the crossroads of two important schemes in reinforcement learning (RL), namely, robust MDP and entropy regularized MDP. We show that essential properties that hold for the non-robust ER-MDP and robust unregularized MDP models also hold in our settings, making the robust ER-MDP problem tractable. We show how our framework and results can be integrated into different algorithmic schemes including value or (modified) policy iteration, which would lead to new robust RL and inverse RL algorithms to handle uncertainties. Analyses on computational complexity and error propagation under conventional uncertainty settings are also provided. ",
    "url": "https://arxiv.org/abs/2112.15364",
    "authors": [
      "Tien Mai",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15399",
    "title": "InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering",
    "abstract": "We present an information-theoretic regularization technique for few-shot novel view synthesis based on neural implicit representation. The proposed approach minimizes potential reconstruction inconsistency that happens due to insufficient viewpoints by imposing the entropy constraint of the density in each ray. In addition, to alleviate the potential degenerate issue when all training images are acquired from almost redundant viewpoints, we further incorporate the spatially smoothness constraint into the estimated images by restricting information gains from a pair of rays with slightly different viewpoints. The main idea of our algorithm is to make reconstructed scenes compact along individual rays and consistent across rays in the neighborhood. The proposed regularizers can be plugged into most of existing neural volume rendering techniques based on NeRF in a straightforward way. Despite its simplicity, we achieve consistently improved performance compared to existing neural view synthesis methods by large margins on multiple standard benchmarks. Our project website is available at \\url{this http URL}. ",
    "url": "https://arxiv.org/abs/2112.15399",
    "authors": [
      "Mijeong Kim",
      "Seonguk Seo",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.15403",
    "title": "Fast Graph Subset Selection Based on G-optimal Design",
    "abstract": "Graph sampling theory extends the traditional sampling theory to graphs with topological structures. As a key part of the graph sampling theory, subset selection chooses nodes on graphs as samples to reconstruct the original signal. Due to the eigen-decomposition operation for Laplacian matrices of graphs, however, existing subset selection methods usually require high-complexity calculations. In this paper, with an aim of enhancing the computational efficiency of subset selection on graphs, we propose a novel objective function based on the optimal experimental design. Theoretical analysis shows that this function enjoys an $\\alpha$-supermodular property with a provable lower bound on $\\alpha$. The objective function, together with an approximate of the low-pass filter on graphs, suggests a fast subset selection method that does not require any eigen-decomposition operation. Experimental results show that the proposed method exhibits high computational efficiency, while having competitive results compared to the state-of-the-art ones, especially when the sampling rate is low. ",
    "url": "https://arxiv.org/abs/2112.15403",
    "authors": [
      "Zhengpin Li",
      "Zheng Wei",
      "Jian Wang",
      "Yun Lin",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.15421",
    "title": "Representation Learning via Consistent Assignment of Views to Clusters",
    "abstract": "We introduce Consistent Assignment for Representation Learning (CARL), an unsupervised learning method to learn visual representations by combining ideas from self-supervised contrastive learning and deep clustering. By viewing contrastive learning from a clustering perspective, CARL learns unsupervised representations by learning a set of general prototypes that serve as energy anchors to enforce different views of a given image to be assigned to the same prototype. Unlike contemporary work on contrastive learning with deep clustering, CARL proposes to learn the set of general prototypes in an online fashion, using gradient descent without the necessity of using non-differentiable algorithms or K-Means to solve the cluster assignment problem. CARL surpasses its competitors in many representations learning benchmarks, including linear evaluation, semi-supervised learning, and transfer learning. ",
    "url": "https://arxiv.org/abs/2112.15421",
    "authors": [
      "Thalles Silva",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15430",
    "title": "Robustness and risk management via distributional dynamic programming",
    "abstract": "In dynamic programming (DP) and reinforcement learning (RL), an agent learns to act optimally in terms of expected long-term return by sequentially interacting with its environment modeled by a Markov decision process (MDP). More generally in distributional reinforcement learning (DRL), the focus is on the whole distribution of the return, not just its expectation. Although DRL-based methods produced state-of-the-art performance in RL with function approximation, they involve additional quantities (compared to the non-distributional setting) that are still not well understood. As a first contribution, we introduce a new class of distributional operators, together with a practical DP algorithm for policy evaluation, that come with a robust MDP interpretation. Indeed, our approach reformulates through an augmented state space where each state is split into a worst-case substate and a best-case substate, whose values are maximized by safe and risky policies respectively. Finally, we derive distributional operators and DP algorithms solving a new control task: How to distinguish safe from risky optimal actions in order to break ties in the space of optimal policies? ",
    "url": "https://arxiv.org/abs/2112.15430",
    "authors": [
      "Mastane Achab",
      "Gergely Neu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.15434",
    "title": "Adversarial Learning for Incentive Optimization in Mobile Payment  Marketing",
    "abstract": "Many payment platforms hold large-scale marketing campaigns, which allocate incentives to encourage users to pay through their applications. To maximize the return on investment, incentive allocations are commonly solved in a two-stage procedure. After training a response estimation model to estimate the users' mobile payment probabilities (MPP), a linear programming process is applied to obtain the optimal incentive allocation. However, the large amount of biased data in the training set, generated by the previous biased allocation policy, causes a biased estimation. This bias deteriorates the performance of the response model and misleads the linear programming process, dramatically degrading the performance of the resulting allocation policy. To overcome this obstacle, we propose a bias correction adversarial network. Our method leverages the small set of unbiased data obtained under a full-randomized allocation policy to train an unbiased model and then uses it to reduce the bias with adversarial learning. Offline and online experimental results demonstrate that our method outperforms state-of-the-art approaches and significantly improves the performance of the resulting allocation policy in a real-world marketing campaign. ",
    "url": "https://arxiv.org/abs/2112.15434",
    "authors": [
      "Xuanying Chen",
      "Zhining Liu",
      "Li Yu",
      "Sen Li",
      "Lihong Gu",
      "Xiaodong Zeng",
      "Yize Tan",
      "Jinjie Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15443",
    "title": "FPGA Based Accelerator for Neural Networks Computation with Flexible  Pipelining",
    "abstract": "FPGA is appropriate for fix-point neural networks computing due to high power efficiency and configurability. However, its design must be intensively refined to achieve high performance using limited hardware resources. We present an FPGA-based neural networks accelerator and its optimization framework, which can achieve optimal efficiency for various CNN models and FPGA resources. Targeting high throughput, we adopt layer-wise pipeline architecture for higher DSP utilization. To get the optimal performance, a flexible algorithm to allocate balanced hardware resources to each layer is also proposed, supported by activation buffer design. Through our well-balanced implementation of four CNN models on ZC706, the DSP utilization and efficiency are over 90%. For VGG16 on ZC706, the proposed accelerator achieves the performance of 2.58x, 1.53x and 1.35x better than the referenced non-pipeline architecture [1], pipeline architecture [2] and [3], respectively. ",
    "url": "https://arxiv.org/abs/2112.15443",
    "authors": [
      "Qingyang Yi",
      "Heming Sun",
      "Masahiro Fujita"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2112.15454",
    "title": "Advanced Smart Drone Swarm Security Network by Using Strategic Alliance  for Blockchain Governance Game",
    "abstract": "This paper deals with the design of the secure network of the Advanced Smart Drone Swarm security network by using the Strategic Alliance for Blockchain Governance Game (SABGG). The SABGG is the system model of the stochastic game to find best strategies towards preparation for preventing a network malfunction by an attacker and the newly proposed adapts this innovative game model into the artificial drone swarm security. Analytically tractable solutions enable to estimate the moment of safety modes and to deliver the optimal accountability of ally drones for preventing attacks. This research helps for whom considers the advanced secure drone swarm architecture with the SABGG within a decentralized network. ",
    "url": "https://arxiv.org/abs/2112.15454",
    "authors": [
      "Song-Kyoo Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2112.15458",
    "title": "PiFeNet: Pillar-Feature Network for Real-Time 3D Pedestrian Detection  from Point Cloud",
    "abstract": "We present PiFeNet, an efficient and accurate real-time 3D detector for pedestrian detection from point clouds. We address two challenges that 3D object detection frameworks encounter when detecting pedestrians: low expressiveness of pillar features and small occupation areas of pedestrians in point clouds. Firstly, we introduce a stackable Pillar Aware Attention (PAA) module for enhanced pillar features extraction while suppressing noises in the point clouds. By integrating multi-point-aware-pooling, point-wise, channel-wise, and task-aware attention into a simple module, the representation capabilities are boosted while requiring little additional computing resources. We also present Mini-BiFPN, a small yet effective feature network that creates bidirectional information flow and multi-level cross-scale feature fusion to better integrate multi-resolution features. Our approach is ranked 1st in KITTI pedestrian BEV and 3D leaderboards while running at 26 frames per second (FPS), and achieves state-of-the-art performance on Nuscenes detection benchmark. ",
    "url": "https://arxiv.org/abs/2112.15458",
    "authors": [
      "Duy-Tho Le",
      "Hengcan Shi",
      "Hamid Rezatofighi",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15459",
    "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
    "abstract": "We are making the case that empirical results from social psychology and social neuroscience along with the framework of dynamics can be of inspiration to the development of more intelligent artificial agents. We specifically argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. In the first section, we aim at demonstrating that social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and investigating the abilities that various animals have at learning from others; we also explore findings from social neuroscience that examine human brains during social interaction and learning. Then, we discuss three proposed lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by the powerful framework offered by dynamics. Third, social embodiment has been demonstrated to provide social interactions between virtual agents and humans with a more sophisticated array of communicative signals. To conclude, we provide a new perspective on the field of multiagent robot systems, exploring how it can advance by following the aforementioned three axes. ",
    "url": "https://arxiv.org/abs/2112.15459",
    "authors": [
      "Samuele Bolotta",
      "Guillaume Dumas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.15466",
    "title": "Polynomial-Time Key Recovery Attack on the Lau-Tan Cryptosystem Based on  Gabidulin Codes",
    "abstract": "This paper presents a key recovery attack on the cryptosystem proposed by Lau and Tan in a talk at ACISP 2018. The Lau-Tan cryptosystem uses Gabidulin codes as the underlying decodable code. To hide the algebraic structure of Gabidulin codes, the authors chose a matrix of column rank $n$ to mix with a generator matrix of the secret Gabidulin code. The other part of the public key, however, reveals crucial information about the private key. Our analysis shows that the problem of recovering the private key can be reduced to solving a multivariate linear system, rather than solving a multivariate quadratic system as claimed by the authors. Apparently, this attack costs polynomial time, and therefore completely breaks the cryptosystem. ",
    "url": "https://arxiv.org/abs/2112.15466",
    "authors": [
      "Wenshuo Guo",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.15486",
    "title": "Efficient and Reliable Overlay Networks for Decentralized Federated  Learning",
    "abstract": "We propose near-optimal overlay networks based on $d$-regular expander graphs to accelerate decentralized federated learning (DFL) and improve its generalization. In DFL a massive number of clients are connected by an overlay network, and they solve machine learning problems collaboratively without sharing raw data. Our overlay network design integrates spectral graph theory and the theoretical convergence and generalization bounds for DFL. As such, our proposed overlay networks accelerate convergence, improve generalization, and enhance robustness to clients failures in DFL with theoretical guarantees. Also, we present an efficient algorithm to convert a given graph to a practical overlay network and maintaining the network topology after potential client failures. We numerically verify the advantages of DFL with our proposed networks on various benchmark tasks, ranging from image classification to language modeling using hundreds of clients. ",
    "url": "https://arxiv.org/abs/2112.15486",
    "authors": [
      "Yifan Hua",
      "Kevin Miller",
      "Andrea L. Bertozzi",
      "Chen Qian",
      "Bao Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.15488",
    "title": "Multi-relation Graph Summarization",
    "abstract": "Graph summarization is beneficial in a wide range of applications, such as visualization, interactive and exploratory analysis, approximate query processing, reducing the on-disk storage footprint, and graph processing in modern hardware. However, the bulk of the literature on graph summarization surprisingly overlooks the possibility of having edges of different types. In this paper, we study the novel problem of producing summaries of multi-relation networks, i.e., graphs where multiple edges of different types may exist between any pair of nodes. Multi-relation graphs are an expressive model of real-world activities, in which a relation can be a topic in social networks, an interaction type in genetic networks, or a snapshot in temporal graphs. The first approach that we consider for multi-relation graph summarization is a two-step method based on summarizing each relation in isolation, and then aggregating the resulting summaries in some clever way to produce a final unique summary. In doing this, as a side contribution, we provide the first polynomial-time approximation algorithm based on the k-Median clustering for the classic problem of lossless single-relation graph summarization. Then, we demonstrate the shortcomings of these two-step methods, and propose holistic approaches, both approximate and heuristic algorithms, to compute a summary directly for multi-relation graphs. In particular, we prove that the approximation bound of k-Median clustering for the single relation solution can be maintained in a multi-relation graph with proper aggregation operation over adjacency matrices corresponding to its multiple relations. Experimental results and case studies (on co-authorship networks and brain networks) validate the effectiveness and efficiency of the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2112.15488",
    "authors": [
      "Xiangyu Ke",
      "Arijit Khan",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.15491",
    "title": "Semantics-Recovering Decompilation through Neural Machine Translation",
    "abstract": "Decompilation transforms low-level program languages (PL) (e.g., binary code) into high-level PLs (e.g., C/C++). It has been widely used when analysts perform security analysis on software (systems) whose source code is unavailable, such as vulnerability search and malware analysis. However, current decompilation tools usually need lots of experts' efforts, even for years, to generate the rules for decompilation, which also requires long-term maintenance as the syntax of high-level PL or low-level PL changes. Also, an ideal decompiler should concisely generate high-level PL with similar functionality to the source low-level PL and semantic information (e.g., meaningful variable names), just like human-written code. Unfortunately, existing manually-defined rule-based decompilation techniques only functionally restore the low-level PL to a similar high-level PL and are still powerless to recover semantic information. In this paper, we propose a novel neural decompilation approach to translate low-level PL into accurate and user-friendly high-level PL, effectively improving its readability and understandability. Furthermore, we implement the proposed approaches called SEAM. Evaluations on four real-world applications show that SEAM has an average accuracy of 94.41%, which is much better than prior neural machine translation (NMT) models. Finally, we evaluate the effectiveness of semantic information recovery through a questionnaire survey, and the average accuracy is 92.64%, which is comparable or superior to the state-of-the-art compilers. ",
    "url": "https://arxiv.org/abs/2112.15491",
    "authors": [
      "Ruigang Liang",
      "Ying Cao",
      "Peiwei Hu",
      "Jinwen He",
      "Kai Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.15498",
    "title": "State Selection Algorithms and Their Impact on The Performance of  Stateful Network Protocol Fuzzing",
    "abstract": "The statefulness property of network protocol implementations poses a unique challenge for testing and verification techniques, including Fuzzing. Stateful fuzzers tackle this challenge by leveraging state models to partition the state space and assist the test generation process. Since not all states are equally important and fuzzing campaigns have time limits, fuzzers need effective state selection algorithms to prioritize progressive states over others. Several state selection algorithms have been proposed but they were implemented and evaluated separately on different platforms, making it hard to achieve conclusive findings. In this work, we evaluate an extensive set of state selection algorithms on the same fuzzing platform that is AFLNet, a state-of-the-art fuzzer for network servers. The algorithm set includes existing ones supported by AFLNet and our novel and principled algorithm called AFLNetLegion. The experimental results on the ProFuzzBench benchmark show that (i) the existing state selection algorithms of AFLNet achieve very similar code coverage, (ii) AFLNetLegion clearly outperforms these algorithms in selected case studies, but (iii) the overall improvement appears insignificant. These are unexpected yet interesting findings. We identify problems and share insights that could open opportunities for future research on this topic. ",
    "url": "https://arxiv.org/abs/2112.15498",
    "authors": [
      "Dongge Liu",
      "Van-Thuan Pham",
      "Gidon Ernst",
      "Toby Murray",
      "Benjamin I.P. Rubinstein"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15509",
    "title": "Scene-Adaptive Attention Network for Crowd Counting",
    "abstract": "In recent years, significant progress has been made on the research of crowd counting. However, as the challenging scale variations and complex scenes existed in crowds, neither traditional convolution networks nor recent Transformer architectures with fixed-size attention could handle the task well. To address this problem, this paper proposes a scene-adaptive attention network, termed SAANet. First of all, we design a deformable attention in-built Transformer backbone, which learns adaptive feature representations with deformable sampling locations and dynamic attention weights. Then we propose the multi-level feature fusion and count-attentive feature enhancement modules further, to strengthen feature representation under the global image context. The learned representations could attend to the foreground and are adaptive to different scales of crowds. We conduct extensive experiments on four challenging crowd counting benchmarks, demonstrating that our method achieves state-of-the-art performance. Especially, our method currently ranks No.1 on the public leaderboard of the NWPU-Crowd benchmark. We hope our method could be a strong baseline to support future research in crowd counting. The source code will be released to the community. ",
    "url": "https://arxiv.org/abs/2112.15509",
    "authors": [
      "Xing Wei",
      "Yuanrui Kang",
      "Jihao Yang",
      "Yunfeng Qiu",
      "Dahu Shi",
      "Wenming Tan",
      "Yihong Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15530",
    "title": "Scalable Deep Graph Clustering with Random-walk based Self-supervised  Learning",
    "abstract": "Web-based interactions can be frequently represented by an attributed graph, and node clustering in such graphs has received much attention lately. Multiple efforts have successfully applied Graph Convolutional Networks (GCN), though with some limits on accuracy as GCNs have been shown to suffer from over-smoothing issues. Though other methods (particularly those based on Laplacian Smoothing) have reported better accuracy, a fundamental limitation of all the work is a lack of scalability. This paper addresses this open problem by relating the Laplacian smoothing to the Generalized PageRank and applying a random-walk based algorithm as a scalable graph filter. This forms the basis for our scalable deep clustering algorithm, RwSL, where through a self-supervised mini-batch training mechanism, we simultaneously optimize a deep neural network for sample-cluster assignment distribution and an autoencoder for a clustering-oriented embedding. Using 6 real-world datasets and 6 clustering metrics, we show that RwSL achieved improved results over several recent baselines. Most notably, we show that RwSL, unlike all other deep clustering frameworks, can continue to scale beyond graphs with more than one million nodes, i.e., handle web-scale. We also demonstrate how RwSL could perform node clustering on a graph with 1.8 billion edges using only a single GPU. ",
    "url": "https://arxiv.org/abs/2112.15530",
    "authors": [
      "Xiang Li",
      "Dong Li",
      "Ruoming Jin",
      "Gagan Agrawal",
      "Rajiv Ramnath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.15541",
    "title": "on the effectiveness of generative adversarial network on anomaly  detection",
    "abstract": "Identifying anomalies refers to detecting samples that do not resemble the training data distribution. Many generative models have been used to find anomalies, and among them, generative adversarial network (GAN)-based approaches are currently very popular. GANs mainly rely on the rich contextual information of these models to identify the actual training distribution. Following this analogy, we suggested a new unsupervised model based on GANs --a combination of an autoencoder and a GAN. Further, a new scoring function was introduced to target anomalies where a linear combination of the internal representation of the discriminator and the generator's visual representation, plus the encoded representation of the autoencoder, come together to define the proposed anomaly score. The model was further evaluated on benchmark datasets such as SVHN, CIFAR10, and MNIST, as well as a public medical dataset of leukemia images. In all the experiments, our model outperformed its existing counterparts while slightly improving the inference time. ",
    "url": "https://arxiv.org/abs/2112.15541",
    "authors": [
      "Laya Rafiee Sevyeri",
      "Thomas Fevens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15545",
    "title": "Training and Generating Neural Networks in Compressed Weight Space",
    "abstract": "The inputs and/or outputs of some neural nets are weight matrices of other neural nets. Indirect encodings or end-to-end compression of weight matrices could help to scale such approaches. Our goal is to open a discussion on this topic, starting with recurrent neural networks for character-level language modelling whose weight matrices are encoded by the discrete cosine transform. Our fast weight version thereof uses a recurrent neural network to parameterise the compressed weights. We present experimental results on the enwik8 dataset. ",
    "url": "https://arxiv.org/abs/2112.15545",
    "authors": [
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.15555",
    "title": "An Unsupervised Domain Adaptation Model based on Dual-module Adversarial  Training",
    "abstract": "In this paper, we propose a dual-module network architecture that employs a domain discriminative feature module to encourage the domain invariant feature module to learn more domain invariant features. The proposed architecture can be applied to any model that utilizes domain invariant features for unsupervised domain adaptation to improve its ability to extract domain invariant features. We conduct experiments with the Domain-Adversarial Training of Neural Networks (DANN) model as a representative algorithm. In the training process, we supply the same input to the two modules and then extract their feature distribution and prediction results respectively. We propose a discrepancy loss to find the discrepancy of the prediction results and the feature distribution between the two modules. Through the adversarial training by maximizing the loss of their feature distribution and minimizing the discrepancy of their prediction results, the two modules are encouraged to learn more domain discriminative and domain invariant features respectively. Extensive comparative evaluations are conducted and the proposed approach outperforms the state-of-the-art in most unsupervised domain adaptation tasks. ",
    "url": "https://arxiv.org/abs/2112.15555",
    "authors": [
      "Yiju Yang",
      "Tianxiao Zhang",
      "Guanyu Li",
      "Taejoon Kim",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15575",
    "title": "Fast Learning of MNL Model from General Partial Rankings with  Application to Network Formation Modeling",
    "abstract": "Multinomial Logit (MNL) is one of the most popular discrete choice models and has been widely used to model ranking data. However, there is a long-standing technical challenge of learning MNL from many real-world ranking data: exact calculation of the MNL likelihood of \\emph{partial rankings} is generally intractable. In this work, we develop a scalable method for approximating the MNL likelihood of general partial rankings in polynomial time complexity. We also extend the proposed method to learn mixture of MNL. We demonstrate that the proposed methods are particularly helpful for applications to choice-based network formation modeling, where the formation of new edges in a network is viewed as individuals making choices of their friends over a candidate set. The problem of learning mixture of MNL models from partial rankings naturally arises in such applications. And the proposed methods can be used to learn MNL models from network data without the strong assumption that temporal orders of all the edge formation are available. We conduct experiments on both synthetic and real-world network data to demonstrate that the proposed methods achieve more accurate parameter estimation and better fitness of data compared to conventional methods. ",
    "url": "https://arxiv.org/abs/2112.15575",
    "authors": [
      "Jiaqi Ma",
      "Xingjian Zhang",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.15577",
    "title": "Infinite wide (finite depth) Neural Networks benefit from multi-task  learning unlike shallow Gaussian Processes -- an exact quantitative  macroscopic characterization",
    "abstract": "We prove in this paper that wide ReLU neural networks (NNs) with at least one hidden layer optimized with l2-regularization on the parameters enforces multi-task learning due to representation-learning - also in the limit width to infinity. This is in contrast to multiple other idealized settings discussed in the literature where wide (ReLU)-NNs loose their ability to benefit from multi-task learning in the limit width to infinity. We deduce the multi-task learning ability from proving an exact quantitative macroscopic characterization of the learned NN in function space. ",
    "url": "https://arxiv.org/abs/2112.15577",
    "authors": [
      "Jakob Heiss",
      "Josef Teichmann",
      "Hanna Wutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.15589",
    "title": "3-D Material Style Transfer for Reconstructing Unknown Appearance in  Complex Natural Materials",
    "abstract": "We propose a 3-D material style transfer framework for reconstructing invisible (or faded) appearance properties in complex natural materials. Our algorithm addresses the technical challenge of transferring appearance properties from one object to another of the same material when both objects have intricate, noncorresponding color patterns. Eggshells, exoskeletons, and minerals, for example, have patterns composed of highly randomized layers of organic and inorganic compounds. These materials pose a challenge as the distribution of compounds that determine surface color changes from object to object and within local pattern regions. Our solution adapts appearance observations from a material property distribution in an exemplar to the material property distribution of a target object to reconstruct its unknown appearance. We use measured reflectance in 3-D bispectral textures to record changing material property distributions. Our novel implementation of spherical harmonics uses principles from chemistry and biology to learn relationships between color (hue and saturation) and material composition and concentration in an exemplar. The encoded relationships are transformed to the property distribution of a target for color recovery and material assignment. Quantitative and qualitative evaluation methods show that we replicate color patterns more accurately than methods that only rely on shape correspondences and coarse-level perceptual differences. We demonstrate applications of our work for reconstructing color in extinct fossils, restoring faded artifacts and generating synthetic textures. ",
    "url": "https://arxiv.org/abs/2112.15589",
    "authors": [
      "Shashank Ranjan",
      "Corey Toler-Franklin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15594",
    "title": "A Neural Network Solves and Generates Mathematics Problems by Program  Synthesis: Calculus, Differential Equations, Linear Algebra, and More",
    "abstract": "We demonstrate that a neural network pre-trained on text and fine-tuned on code solves Mathematics problems by program synthesis. We turn questions into programming tasks, automatically generate programs, and then execute them, perfectly solving university-level problems from MIT's large Mathematics courses (Single Variable Calculus 18.01, Multivariable Calculus 18.02, Differential Equations 18.03, Introduction to Probability and Statistics 18.05, Linear Algebra 18.06, and Mathematics for Computer Science 6.042) as well as questions from a MATH dataset (on Prealgebra, Algebra, Counting and Probability, Number Theory, and Precalculus), the latest benchmark of advanced mathematics problems specifically designed to assess mathematical reasoning. We explore prompt generation methods that enable Transformers to generate question solving programs for these subjects, including solutions with plots. We generate correct answers for a random sample of questions in each topic. We quantify the gap between the original and transformed questions and perform a survey to evaluate the quality and difficulty of generated questions. This is the first work to automatically solve, grade, and generate university-level Mathematics course questions at scale which represents a milestone for higher education. ",
    "url": "https://arxiv.org/abs/2112.15594",
    "authors": [
      "Iddo Drori",
      "Sunny Tran",
      "Roman Wang",
      "Newman Cheng",
      "Kevin Liu",
      "Leonard Tang",
      "Elizabeth Ke",
      "Nikhil Singh",
      "Taylor L. Patti",
      "Jayson Lynch",
      "Avi Shporer",
      "Nakul Verma",
      "Eugene Wu",
      "Gilbert Strang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.14838",
    "title": "Facial Input Decompositions for Robust Peak and Reachable Set Estimation  under Polyhedral Uncertainty",
    "abstract": "This work bounds extreme values of state functions and approximates reachable sets for a class of input-affine continuous-time systems that are affected by polyhedral-bounded uncertainty. Instances of these systems may arise in data-driven peak estimation, in which the state function must be bounded for all systems that are that are consistent with a set of state-derivative data records corrupted under L-infinity bounded noise. Existing occupation measure-based methods form a convergent sequence of outer approximations to the true peak value or reachable set volume, given an initial set, by solving a hierarchy of semidefinite programs in increasing size. These techniques scale combinatorially in the number of state variables and uncertain parameters. We present tractable algorithms for peak and reachable set estimation that scale linearly in the number of faces of the uncertainty-bounding polytope rather than combinatorially in the number of uncertain parameters by leveraging convex duality and a theorem of alternatives (facial decomposition). The sequence of decomposed semidefinite programs will converge to the true optimal value under mild assumptions (convergence and smoothness of dynamics). ",
    "url": "https://arxiv.org/abs/2112.14838",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.14888",
    "title": "Parallel Network Flow Allocation in Repeated Routing Games via LQR  Optimal Control",
    "abstract": "In this article, we study the repeated routing game problem on a parallel network with affine latency functions on each edge. We cast the game setup in a LQR control theoretic framework, leveraging the Rosenthal potential formulation. We use control techniques to analyze the convergence of the game dynamics with specific cases that lend themselves to optimal control. We design proper dynamics parameters so that the conservation of flow is guaranteed. We provide an algorithmic solution for the general optimal control setup using a multiparametric quadratic programming approach (explicit MPC). Finally we illustrate with numerics the impact of varying system parameters on the solutions. ",
    "url": "https://arxiv.org/abs/2112.14888",
    "authors": [
      "Marsalis Gibson",
      "Yiling You",
      "Alexandre Bayen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.15287",
    "title": "Distributed Random Reshuffling over Networks",
    "abstract": "In this paper, we consider the distributed optimization problem where $n$ agents, each possessing a local cost function, collaboratively minimize the average of the local cost functions over a connected network. To solve the problem, we propose a distributed random reshuffling (D-RR) algorithm that combines the classical distributed gradient descent (DGD) method and Random Reshuffling (RR). We show that D-RR inherits the superiority of RR for both smooth strongly convex and smooth nonconvex objective functions. In particular, for smooth strongly convex objective functions, D-RR achieves $\\mathcal{O}(1/T^2)$ rate of convergence (here, $T$ counts the total number of iterations) in terms of the squared distance between the iterate and the unique minimizer. When the objective function is assumed to be smooth nonconvex and has Lipschitz continuous component functions, we show that D-RR drives the squared norm of gradient to $0$ at a rate of $\\mathcal{O}(1/T^{2/3})$. These convergence results match those of centralized RR (up to constant factors). ",
    "url": "https://arxiv.org/abs/2112.15287",
    "authors": [
      "Kun Huang",
      "Xiao Li",
      "Andre Milzarek",
      "Shi Pu",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.15362",
    "title": "Calibrated Hyperspectral Image Reconstruction via Graph-based  Self-Tuning Network",
    "abstract": "Recently, hyperspectral imaging (HSI) has attracted increasing research attention, especially for the ones based on a coded aperture snapshot spectral imaging (CASSI) system. Existing deep HSI reconstruction models are generally trained on paired data to retrieve original signals upon 2D compressed measurements given by a particular optical hardware mask in CASSI, during which the mask largely impacts the reconstruction performance and could work as a \"model hyperparameter\" governing on data augmentations. This mask-specific training style will lead to a hardware miscalibration issue, which sets up barriers to deploying deep HSI models among different hardware and noisy environments. To address this challenge, we introduce mask uncertainty for HSI with a complete variational Bayesian learning treatment and explicitly model it through a mask decomposition inspired by real hardware. Specifically, we propose a novel Graph-based Self-Tuning (GST) network to reason uncertainties adapting to varying spatial structures of masks among different hardware. Moreover, we develop a bilevel optimization framework to balance HSI reconstruction and uncertainty estimation, accounting for the hyperparameter property of masks. Extensive experimental results and model discussions validate the effectiveness (over 33/30 dB) of the proposed GST method under two miscalibration scenarios and demonstrate a highly competitive performance compared with the state-of-the-art well-calibrated methods. Our code and pre-trained model are available at https://github.com/Jiamian Wang/mask_uncertainty_spectral_SCI ",
    "url": "https://arxiv.org/abs/2112.15362",
    "authors": [
      "Jiamian Wang",
      "Yulun Zhang",
      "Xin Yuan",
      "Ziyi Meng",
      "Zhiqiang Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15367",
    "title": "Weakly Supervised Change Detection Using Guided Anisotropic Difusion",
    "abstract": "Large scale datasets created from crowdsourced labels or openly available data have become crucial to provide training data for large scale learning algorithms. While these datasets are easier to acquire, the data are frequently noisy and unreliable, which is motivating research on weakly supervised learning techniques. In this paper we propose original ideas that help us to leverage such datasets in the context of change detection. First, we propose the guided anisotropic diffusion (GAD) algorithm, which improves semantic segmentation results using the input images as guides to perform edge preserving filtering. We then show its potential in two weakly-supervised learning strategies tailored for change detection. The first strategy is an iterative learning method that combines model optimisation and data cleansing using GAD to extract the useful information from a large scale change detection dataset generated from open vector data. The second one incorporates GAD within a novel spatial attention layer that increases the accuracy of weakly supervised networks trained to perform pixel-level predictions from image-level labels. Improvements with respect to state-of-the-art are demonstrated on 4 different public datasets. ",
    "url": "https://arxiv.org/abs/2112.15367",
    "authors": [
      "Rodrigo Caye Daudt",
      "Bertrand Le Saux",
      "Alexandre Boulch",
      "Yann Gousseau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15382",
    "title": "Processing Images from Multiple IACTs in the TAIGA Experiment with  Convolutional Neural Networks",
    "abstract": "Extensive air showers created by high-energy particles interacting with the Earth atmosphere can be detected using imaging atmospheric Cherenkov telescopes (IACTs). The IACT images can be analyzed to distinguish between the events caused by gamma rays and by hadrons and to infer the parameters of the event such as the energy of the primary particle. We use convolutional neural networks (CNNs) to analyze Monte Carlo-simulated images from the telescopes of the TAIGA experiment. The analysis includes selection of the images corresponding to the showers caused by gamma rays and estimating the energy of the gamma rays. We compare performance of the CNNs using images from a single telescope and the CNNs using images from two telescopes as inputs. ",
    "url": "https://arxiv.org/abs/2112.15382",
    "authors": [
      "Stanislav Polyakov",
      "Andrey Demichev",
      "Alexander Kryukov",
      "Evgeny Postnikov"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15389",
    "title": "$H^2$-Optimal Reduction of Positive Networks using Riemannian Augmented  Lagrangian Method",
    "abstract": "In this study, we formulate the model reduction problem of a stable and positive network system as a constrained Riemannian optimization problem with the $H^2$-error objective function of the original and reduced network systems. We improve the reduction performance of the clustering-based method, which is one of the most known methods for model reduction of positive network systems, by using the output of the clustering-based method as the initial point for the proposed method. The proposed method reduces the dimension of the network system while preserving the properties of stability, positivity, and interconnection structure by applying the Riemannian augmented Lagrangian method (RALM) and deriving the Riemannian gradient of the Lagrangian. To check the efficiency of our method, we conduct a numerical experiment and compare it with the clustering-based method in the sense of $H^2$-error and $H^\\infty$-error. ",
    "url": "https://arxiv.org/abs/2112.15389",
    "authors": [
      "Sota Misawa",
      "Kazuhiro Sato"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2002.01711",
    "title": "Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement  Learning Framework",
    "abstract": " Title: Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement  Learning Framework ",
    "url": "https://arxiv.org/abs/2002.01711",
    "authors": [
      "Chengchun Shi",
      "Xiaoyu Wang",
      "Shikai Luo",
      "Hongtu Zhu",
      "Jieping Ye",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2004.01365",
    "title": "Coloring of ($P_5$, $4$-wheel)-free graphs",
    "abstract": " Comments: Revised compact version; Accepted for publication in Discrete Mathematics ",
    "url": "https://arxiv.org/abs/2004.01365",
    "authors": [
      "Arnab Char",
      "T. Karthick"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2005.11203",
    "title": "Towards a Neural Model for Serial Order in Frontal Cortex: a Brain  Theory from Memory Development to Higher-Level Cognition",
    "abstract": " Title: Towards a Neural Model for Serial Order in Frontal Cortex: a Brain  Theory from Memory Development to Higher-Level Cognition ",
    "url": "https://arxiv.org/abs/2005.11203",
    "authors": [
      "Alexandre Pitti",
      "Mathias Quoy",
      "Catherine Lavandier",
      "Sofiane Boucenna",
      "Wassim Swaileh",
      "Claudio Weidmann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2009.13794",
    "title": "From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction  Using Social Media Data",
    "abstract": " Title: From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction  Using Social Media Data ",
    "url": "https://arxiv.org/abs/2009.13794",
    "authors": [
      "Weiran Yao",
      "Sean Qian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.00827",
    "title": "Neural Thompson Sampling",
    "abstract": " Comments: 26 pages, 2 tables, 5 figures. In ICLR 2021 ",
    "url": "https://arxiv.org/abs/2010.00827",
    "authors": [
      "Weitong Zhang",
      "Dongruo Zhou",
      "Lihong Li",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.01278",
    "title": "Efficient Robust Training via Backward Smoothing",
    "abstract": " Comments: 12 pages, 15 tables, 6 figures. In AAAI 2022 ",
    "url": "https://arxiv.org/abs/2010.01278",
    "authors": [
      "Jinghui Chen",
      "Yu Cheng",
      "Zhe Gan",
      "Quanquan Gu",
      "Jingjing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.07370",
    "title": "A Comparison of Reduced-Order Modeling Approaches Using Artificial  Neural Networks for PDEs with Bifurcating Solutions",
    "abstract": " Title: A Comparison of Reduced-Order Modeling Approaches Using Artificial  Neural Networks for PDEs with Bifurcating Solutions ",
    "url": "https://arxiv.org/abs/2010.07370",
    "authors": [
      "Martin W. Hess",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2101.01041",
    "title": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity",
    "abstract": " Title: Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust  Control Design: Implicit Regularization and Sample Complexity ",
    "url": "https://arxiv.org/abs/2101.01041",
    "authors": [
      "Kaiqing Zhang",
      "Xiangyuan Zhang",
      "Bin Hu",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2102.00654",
    "title": "Regionalized location obfuscation mechanism with personalized privacy  levels",
    "abstract": " Comments: 12 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2102.00654",
    "authors": [
      "Shun Zhang",
      "Benfei Duan",
      "Zhili Chen",
      "Tianjiao Ni",
      "Hong Zhong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2102.12834",
    "title": "On a Network SIS Epidemic Model with Cooperative and Antagonistic  Opinion Dynamics",
    "abstract": " Title: On a Network SIS Epidemic Model with Cooperative and Antagonistic  Opinion Dynamics ",
    "url": "https://arxiv.org/abs/2102.12834",
    "authors": [
      "Baike She",
      "Ji Liu",
      "Shreyas Sundaram",
      "Philip E. Par\u00e9"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2103.08077",
    "title": "Distribution Privacy Under Function Recoverability",
    "abstract": " Title: Distribution Privacy Under Function Recoverability ",
    "url": "https://arxiv.org/abs/2103.08077",
    "authors": [
      "Ajaykrishnan Nageswaran",
      "Prakash Narayan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2103.11569",
    "title": "Convex Parameterization and Optimization for Robust Tracking of a  Magnetically Levitated Planar Positioning System",
    "abstract": " Comments: 11 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2103.11569",
    "authors": [
      "Jun Ma",
      "Zilong Cheng",
      "Haiyue Zhu",
      "Xiaocong Li",
      "Masayoshi Tomizuka",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2103.12360",
    "title": "Discovering Emotion and Reasoning its Flip in Multi-Party Conversations  using Masked Memory Network and Transformer",
    "abstract": " Comments: Accepted in Knowledge-Based Systems; 34 pages, 4 figures, 15 tables ",
    "url": "https://arxiv.org/abs/2103.12360",
    "authors": [
      "Shivani Kumar",
      "Anubhav Shrimal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2104.03043",
    "title": "Two-Stage Robust Optimization Problems with Two-Stage Uncertainty",
    "abstract": " Title: Two-Stage Robust Optimization Problems with Two-Stage Uncertainty ",
    "url": "https://arxiv.org/abs/2104.03043",
    "authors": [
      "Marc Goerigk",
      "Stefan Lendl",
      "Lasse Wulf"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2105.10766",
    "title": "Embedding Information onto a Dynamical System",
    "abstract": " Title: Embedding Information onto a Dynamical System ",
    "url": "https://arxiv.org/abs/2105.10766",
    "authors": [
      "G Manjunath"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.11082",
    "title": "Simplifying Software Defect Prediction (via the \"early bird\" Heuristic)",
    "abstract": " Comments: 41 pages (Under Review) ",
    "url": "https://arxiv.org/abs/2105.11082",
    "authors": [
      "N.C. Shrikanth",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: Attack by Multi-Identity Surrogates",
    "abstract": " Comments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks ",
    "url": "https://arxiv.org/abs/2105.15010",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.00168",
    "title": "Rethinking Pseudo Labels for Semi-Supervised Object Detection",
    "abstract": " Comments: AAAI 2022 ",
    "url": "https://arxiv.org/abs/2106.00168",
    "authors": [
      "Hengduo Li",
      "Zuxuan Wu",
      "Abhinav Shrivastava",
      "Larry S. Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.11644",
    "title": "NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial  Perturbations",
    "abstract": " Comments: Preprint version ",
    "url": "https://arxiv.org/abs/2106.11644",
    "authors": [
      "Sungmin Cha",
      "Naeun Ko",
      "Youngjoon Yoo",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.13543",
    "title": "Louvain-like Methods for Community Detection in Multiplex Networks",
    "abstract": " Title: Louvain-like Methods for Community Detection in Multiplex Networks ",
    "url": "https://arxiv.org/abs/2106.13543",
    "authors": [
      "Sara Venturini",
      "Andrea Cristofari",
      "Francesco Rinaldi",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.04094",
    "title": "Robust Control Barrier Functions under High Relative Degree and Input  Constraints for Satellite Trajectories",
    "abstract": " Comments: 19 pages, extended version. Submitted to Automatica, v2 ",
    "url": "https://arxiv.org/abs/2107.04094",
    "authors": [
      "Joseph Breeden",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2107.11960",
    "title": "Temporal Alignment Prediction for Few-Shot Video Classification",
    "abstract": " Title: Temporal Alignment Prediction for Few-Shot Video Classification ",
    "url": "https://arxiv.org/abs/2107.11960",
    "authors": [
      "Fei Pan",
      "Chunlei Xu",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.01183",
    "title": "roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs",
    "abstract": " Title: roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs ",
    "url": "https://arxiv.org/abs/2109.01183",
    "authors": [
      "Arnav Vaibhav Malawade",
      "Shih-Yuan Yu",
      "Brandon Hsu",
      "Harsimrat Kaeley",
      "Anurag Karra",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.04453",
    "title": "Tube-Certified Trajectory Tracking for Nonlinear Systems With Robust  Control Contraction Metrics",
    "abstract": " Comments: Shorter version submitted to IEEE Robotics and Automation Letters ",
    "url": "https://arxiv.org/abs/2109.04453",
    "authors": [
      "Pan Zhao",
      "Arun Lakshmanan",
      "Kasey Ackerman",
      "Aditya Gahlawat",
      "Marco Pavone",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.10563",
    "title": "Improving 360 Monocular Depth Estimation via Non-local Dense Prediction  Transformer and Joint Supervised and Self-supervised Learning",
    "abstract": " Comments: 14 pages, Accepted to AAAI22, conference preprint version ",
    "url": "https://arxiv.org/abs/2109.10563",
    "authors": [
      "Ilwi Yun",
      "Hyuk-Jae Lee",
      "Chae Eun Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12271",
    "title": "BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor  Segmentation",
    "abstract": " Comments: Accepted by MICCAI BrainLes 2021 ",
    "url": "https://arxiv.org/abs/2109.12271",
    "authors": [
      "Qiran Jia",
      "Hai Shu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.13811",
    "title": "An Efficient Epileptic Seizure Detection Technique using Discrete  Wavelet Transform and Machine Learning Classifiers",
    "abstract": " Comments: Accepted in International Conference on Smart Technologies for Sustainable Development (ICSTSD2021) ",
    "url": "https://arxiv.org/abs/2109.13811",
    "authors": [
      "Rabel Guharoy",
      "Nanda Dulal Jana",
      "Suparna Biswas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.05977",
    "title": "Datasets are not Enough: Challenges in Labeling Network Traffic",
    "abstract": " Title: Datasets are not Enough: Challenges in Labeling Network Traffic ",
    "url": "https://arxiv.org/abs/2110.05977",
    "authors": [
      "Jorge Guerra",
      "Carlos Catania",
      "Eduardo Veas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.08012",
    "title": "A Survey on State-of-the-art Techniques for Knowledge Graphs  Construction and Challenges ahead",
    "abstract": " Title: A Survey on State-of-the-art Techniques for Knowledge Graphs  Construction and Challenges ahead ",
    "url": "https://arxiv.org/abs/2110.08012",
    "authors": [
      "Ali Hur",
      "Naeem Janjua",
      "Mohiuddin Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2110.09344",
    "title": "ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification",
    "abstract": " Title: ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification ",
    "url": "https://arxiv.org/abs/2110.09344",
    "authors": [
      "Hongyu Guo",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.03048",
    "title": "Imagine Networks",
    "abstract": " Comments: This paper is the part of the artificial association neural networks series we are studying ",
    "url": "https://arxiv.org/abs/2111.03048",
    "authors": [
      "Seokjun Kim",
      "Jaeeun Jang",
      "Hyeoncheol Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.06521",
    "title": "Refinement for community structures of bipartite networks",
    "abstract": " Comments: 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2111.06521",
    "authors": [
      "Sang Hoon Lee"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.09547",
    "title": "QGTC: Accelerating Quantized Graph Neural Networks via GPU Tensor Core",
    "abstract": " Title: QGTC: Accelerating Quantized Graph Neural Networks via GPU Tensor Core ",
    "url": "https://arxiv.org/abs/2111.09547",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Yufei Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.01177",
    "title": "MutualFormer: Multi-Modality Representation Learning via Mutual  Transformer",
    "abstract": " Title: MutualFormer: Multi-Modality Representation Learning via Mutual  Transformer ",
    "url": "https://arxiv.org/abs/2112.01177",
    "authors": [
      "Xixi Wang",
      "Bo Jiang",
      "Xiao Wang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.07918",
    "title": "M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search",
    "abstract": " Title: M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2112.07918",
    "authors": [
      "Huiyu Kuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11632",
    "title": "Diformer: Directional Transformer for Neural Machine Translation",
    "abstract": " Title: Diformer: Directional Transformer for Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2112.11632",
    "authors": [
      "Minghan Wang",
      "Jiaxin Guo",
      "Yuxia Wang",
      "Daimeng Wei",
      "Hengchao Shang",
      "Chang Su",
      "Yimeng Chen",
      "Yinglu Li",
      "Min Zhang",
      "Shimin Tao",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12833",
    "title": "Dense anomaly detection by robust learning on synthetic negative data",
    "abstract": " Title: Dense anomaly detection by robust learning on synthetic negative data ",
    "url": "https://arxiv.org/abs/2112.12833",
    "authors": [
      "Matej Grci\u0107",
      "Petra Bevandi\u0107",
      "Zoran Kalafati\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12970",
    "title": "SGTR: End-to-end Scene Graph Generation with Transformer",
    "abstract": " Title: SGTR: End-to-end Scene Graph Generation with Transformer ",
    "url": "https://arxiv.org/abs/2112.12970",
    "authors": [
      "Rongjie Li",
      "Songyang Zhang",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14075",
    "title": "Financial Vision Based Differential Privacy Applications",
    "abstract": " Comments: 11 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2112.14075",
    "authors": [
      "Jun-Hao Chen",
      "Yi-Jen Wang",
      "Yun-Cheng Tsai",
      "Samuel Yen-Chi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.14714",
    "title": "Automated Code Optimization with E-Graphs",
    "abstract": " Comments: Bachelor Thesis in Computer Science, University of Pisa ",
    "url": "https://arxiv.org/abs/2112.14714",
    "authors": [
      "Alessandro Cheli",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ]
  }
]