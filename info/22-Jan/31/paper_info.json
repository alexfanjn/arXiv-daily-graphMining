[
  {
    "id": "arXiv:2201.11745",
    "title": "Exploring Graph Representation of Chorales",
    "abstract": "This work explores areas overlapping music, graph theory, and machine learning. An embedding representation of a node, in a weighted undirected graph $\\mathcal{G}$, is a representation that captures the meaning of nodes in an embedding space. In this work, 383 Bach chorales were compiled and represented as a graph. Two application cases were investigated in this paper (i) learning node embedding representation using \\emph{Continuous Bag of Words (CBOW), skip-gram}, and \\emph{node2vec} algorithms, and (ii) learning node labels from neighboring nodes based on a collective classification approach. The results of this exploratory study ascertains many salient features of the graph-based representation approach applicable to music applications. ",
    "url": "https://arxiv.org/abs/2201.11745",
    "authors": [
      "Somnuk Phon-Amnuaisuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.11764",
    "title": "A TOCTOU Attack on DICE Attestation",
    "abstract": "A major security challenge for modern Internet of Things (IoT) deployments is to ensure that the devices run legitimate firmware free from malware. This challenge can be addressed through a security primitive called attestation which allows a remote backend to verify the firmware integrity of the devices it manages. In order to accelerate broad attestation adoption in the IoT domain the Trusted Computing Group (TCG) has introduced the Device Identifier Composition Engine (DICE) series of specifications. DICE is a hardware-software architecture for constrained, e.g., microcontroller-based IoT devices where the firmware is divided into successively executed layers. In this paper, we demonstrate a remote Time-Of-Check Time-Of-Use (TOCTOU) attack on DICE-based attestation. We demonstrate that it is possible to install persistent malware in the flash memory of a constrained microcontroller that cannot be detected through DICE-based attestation. The main idea of our attack is to install malware during runtime of application logic in the top firmware layer. The malware reads the valid attestation key and stores it on the device's flash memory. After reboot, the malware uses the previously stored key for all subsequent attestations to the backend. We conduct the installation of malware and copying of the key through Return-Oriented Programming (ROP). As a platform for our demonstration, we use the Cortex-M-based nRF52840 microcontroller. We provide a discussion of several possible countermeasures which can mitigate the shortcomings of the DICE specifications. ",
    "url": "https://arxiv.org/abs/2201.11764",
    "authors": [
      "Stefan Hristozov",
      "Moritz Wettermann",
      "Manuel Huber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.11779",
    "title": "Convolutional Self-Attention-Based Multi-User MIMO Demapper",
    "abstract": "In orthogonal frequency division multiplexing (OFDM)-based wireless communication systems, the bit error rate (BER) performance is heavily dependent on the accuracy of channel estimation. It is important for a good channel estimator to be capable of handling the changes in the wireless channel conditions that occur due to the mobility of the users. In recent years, the focus has been on developing complex neural network (NN)- based channel estimators that enable an error performance close to that of a genie-aided channel estimator. This work considers the other alternative which is to have a simple channel estimator but a more complex NN-based demapper for the generation of soft information for each transmitted bit. In particular, the problem of reversing the adverse effects of an imperfect channel estimator is addressed, and a convolutional self-attention-based neural demapper that significantly outperforms the baseline is proposed. ",
    "url": "https://arxiv.org/abs/2201.11779",
    "authors": [
      "Athur Michon",
      "Fay\u00e7al Ait Aoudia",
      "K. Pavan Srinath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.11782",
    "title": "An Empirical Analysis of Recurrent Learning Algorithms In Neural Lossy  Image Compression Systems",
    "abstract": "Recent advances in deep learning have resulted in image compression algorithms that outperform JPEG and JPEG 2000 on the standard Kodak benchmark. However, they are slow to train (due to backprop-through-time) and, to the best of our knowledge, have not been systematically evaluated on a large variety of datasets. In this paper, we perform the first large-scale comparison of recent state-of-the-art hybrid neural compression algorithms, while exploring the effects of alternative training strategies (when applicable). The hybrid recurrent neural decoder is a former state-of-the-art model (recently overtaken by a Google model) that can be trained using backprop-through-time (BPTT) or with alternative algorithms like sparse attentive backtracking (SAB), unbiased online recurrent optimization (UORO), and real-time recurrent learning (RTRL). We compare these training alternatives along with the Google models (GOOG and E2E) on 6 benchmark datasets. Surprisingly, we found that the model trained with SAB performs better (outperforming even BPTT), resulting in faster convergence and a better peak signal-to-noise ratio. ",
    "url": "https://arxiv.org/abs/2201.11782",
    "authors": [
      "Ankur Mali",
      "Alexander Ororbia",
      "Daniel Kifer",
      "Lee Giles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11783",
    "title": "Rethinking Learning Dynamics in RL using Adversarial Networks",
    "abstract": "We present a learning mechanism for reinforcement learning of closely related skills parameterized via a skill embedding space. Our approach is grounded on the intuition that nothing makes you learn better than a coevolving adversary. The main contribution of our work is to formulate an adversarial training regime for reinforcement learning with the help of entropy-regularized policy gradient formulation. We also adapt existing measures of causal attribution to draw insights from the skills learned. Our experiments demonstrate that the adversarial process leads to a better exploration of multiple solutions and understanding the minimum number of different skills necessary to solve a given set of tasks. ",
    "url": "https://arxiv.org/abs/2201.11783",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11794",
    "title": "A Survey on Visual Transfer Learning using Knowledge Graphs",
    "abstract": "Recent approaches of computer vision utilize deep learning methods as they perform quite well if training and testing domains follow the same underlying data distribution. However, it has been shown that minor variations in the images that occur when using these methods in the real world can lead to unpredictable errors. Transfer learning is the area of machine learning that tries to prevent these errors. Especially, approaches that augment image data using auxiliary knowledge encoded in language embeddings or knowledge graphs (KGs) have achieved promising results in recent years. This survey focuses on visual transfer learning approaches using KGs. KGs can represent auxiliary knowledge either in an underlying graph-structured schema or in a vector-based knowledge graph embedding. Intending to enable the reader to solve visual transfer learning problems with the help of specific KG-DL configurations we start with a description of relevant modeling structures of a KG of various expressions, such as directed labeled graphs, hypergraphs, and hyper-relational graphs. We explain the notion of feature extractor, while specifically referring to visual and semantic features. We provide a broad overview of knowledge graph embedding methods and describe several joint training objectives suitable to combine them with high dimensional visual embeddings. The main section introduces four different categories on how a KG can be combined with a DL pipeline: 1) Knowledge Graph as a Reviewer; 2) Knowledge Graph as a Trainee; 3) Knowledge Graph as a Trainer; and 4) Knowledge Graph as a Peer. To help researchers find evaluation benchmarks, we provide an overview of generic KGs and a set of image processing datasets and benchmarks including various types of auxiliary knowledge. Last, we summarize related surveys and give an outlook about challenges and open issues for future research. ",
    "url": "https://arxiv.org/abs/2201.11794",
    "authors": [
      "Sebastian Monka",
      "Lavdim Halilaj",
      "Achim Rettinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11799",
    "title": "Graph-based Algorithm Unfolding for Energy-aware Power Allocation in  Wireless Networks",
    "abstract": "We develop a novel graph-based trainable framework to maximize the weighted sum energy efficiency (WSEE) for power allocation in wireless communication networks. To address the non-convex nature of the problem, the proposed method consists of modular structures inspired by a classical iterative suboptimal approach and enhanced with learnable components. More precisely, we propose a deep unfolding of the successive concave approximation (SCA) method. In our unfolded SCA (USCA) framework, the originally preset parameters are now learnable via graph convolutional neural networks (GCNs) that directly exploit multi-user channel state information as the underlying graph adjacency matrix. We show the permutation equivariance of the proposed architecture, which promotes generalizability across different network topologies of varying size, density, and channel distribution. The USCA framework is trained through a stochastic gradient descent approach using a progressive training strategy. The unsupervised loss is carefully devised to feature the monotonic property of the objective under maximum power constraints. Comprehensive numerical results demonstrate outstanding performance and robustness of USCA over state-of-the-art benchmarks. ",
    "url": "https://arxiv.org/abs/2201.11799",
    "authors": [
      "Boning Li",
      "Gunjan Verma",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11803",
    "title": "On the Convergence of Heterogeneous Federated Learning with Arbitrary  Adaptive Online Model Pruning",
    "abstract": "One of the biggest challenges in Federated Learning (FL) is that client devices often have drastically different computation and communication resources for local updates. To this end, recent research efforts have focused on training heterogeneous local models obtained by pruning a shared global model. Despite empirical success, theoretical guarantees on convergence remain an open question. In this paper, we present a unifying framework for heterogeneous FL algorithms with {\\em arbitrary} adaptive online model pruning and provide a general convergence analysis. In particular, we prove that under certain sufficient conditions and on both IID and non-IID data, these algorithms converges to a stationary point of standard FL for general smooth cost functions, with a convergence rate of $O(\\frac{1}{\\sqrt{Q}})$. Moreover, we illuminate two key factors impacting convergence: pruning-induced noise and minimum coverage index, advocating a joint design of local pruning masks for efficient training. ",
    "url": "https://arxiv.org/abs/2201.11803",
    "authors": [
      "Hanhan Zhou",
      "Tian Lan",
      "Guru Venkataramani",
      "Wenbo Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "abstract": "Despite the state-of-the-art performance of deep convolutional neural networks, they are susceptible to bias and malfunction in unseen situations. The complex computation behind their reasoning is not sufficiently human-understandable to develop trust. External explainer methods have tried to interpret the network decisions in a human-understandable way, but they are accused of fallacies due to their assumptions and simplifications. On the other side, the inherent self-interpretability of models, while being more robust to the mentioned fallacies, cannot be applied to the already trained models. In this work, we propose a new attention-based pooling layer, called Local Attention Pooling (LAP), that accomplishes self-interpretability and the possibility for knowledge injection while improving the model's performance. Moreover, several weakly-supervised knowledge injection methodologies are provided to enhance the process of training. We verified our claims by evaluating several LAP-extended models on three different datasets, including Imagenet. The proposed framework offers more valid human-understandable and more faithful-to-the-model interpretations than the commonly used white-box explainer methods. ",
    "url": "https://arxiv.org/abs/2201.11808",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11811",
    "title": "Porting OpenACC to OpenMP on heterogeneous systems",
    "abstract": "This documentation is designed for beginners in Graphics Processing Unit (GPU)-programming and who want to get familiar with OpenACC and OpenMP offloading models. Here we present an overview of these two programming models as well as of the GPU-architectures. Specifically, we provide some insights into the functionality of these models and perform experiments involving different directives and discuss their performance. This is achieved through the use of a mini-application based on solving numerically the Laplace equation. Such experiments reveal the benefit of the use of GPU, which in our case manifests by an increase of the performance by almost a factor of 52. We further carry out a comparative study between the OpenACC and OpenMP models in the aim of converting OpenACC to OpenMP on heterogeneous systems. In this context, we present a short overview of the open-source OpenACC compiler Clacc, which is designed based on translating OpenACC to OpenMP in Clang. ",
    "url": "https://arxiv.org/abs/2201.11811",
    "authors": [
      "Hichan Agueny"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2201.11812",
    "title": "A Transfer Learning and Optimized CNN Based Intrusion Detection System  for Internet of Vehicles",
    "abstract": "Modern vehicles, including autonomous vehicles and connected vehicles, are increasingly connected to the external world, which enables various functionalities and services. However, the improving connectivity also increases the attack surfaces of the Internet of Vehicles (IoV), causing its vulnerabilities to cyber-threats. Due to the lack of authentication and encryption procedures in vehicular networks, Intrusion Detection Systems (IDSs) are essential approaches to protect modern vehicle systems from network attacks. In this paper, a transfer learning and ensemble learning-based IDS is proposed for IoV systems using convolutional neural networks (CNNs) and hyper-parameter optimization techniques. In the experiments, the proposed IDS has demonstrated over 99.25% detection rates and F1-scores on two well-known public benchmark IoV security datasets: the Car-Hacking dataset and the CICIDS2017 dataset. This shows the effectiveness of the proposed IDS for cyber-attack detection in both intra-vehicle and external vehicular networks. ",
    "url": "https://arxiv.org/abs/2201.11812",
    "authors": [
      "Li Yang",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.11825",
    "title": "Adam-based Augmented Random Search for Control Policies for Distributed  Energy Resource Cyber Attack Mitigation",
    "abstract": "Volt-VAR and Volt-Watt control functions are mechanisms that are included in distributed energy resource (DER) power electronic inverters to mitigate excessively high or low voltages in distribution systems. In the event that a subset of DER have had their Volt-VAR and Volt-Watt settings compromised as part of a cyber-attack, we propose a mechanism to control the remaining set of non-compromised DER to ameliorate large oscillations in system voltages and large voltage imbalances in real time. To do so, we construct control policies for individual non-compromised DER, directly searching the policy space using an Adam-based augmented random search (ARS). In this paper we show that, compared to previous efforts aimed at training policies for DER cybersecurity using deep reinforcement learning (DRL), the proposed approach is able to learn optimal (and sometimes linear) policies an order of magnitude faster than conventional DRL techniques (e.g., Proximal Policy Optimization). ",
    "url": "https://arxiv.org/abs/2201.11825",
    "authors": [
      "Daniel Arnold",
      "Sy-Toan Ngo",
      "Ciaran Roberts",
      "Yize Chen",
      "Anna Scaglione",
      "Sean Peisert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.11829",
    "title": "A Resources Representation For Resource Allocation In Fog Computing  Networks",
    "abstract": "Fog computing is emerging as a new paradigm to deal with latency-sensitive applications, by making data processing and analysis close to their source. Due to the heterogeneity of devices in the fog, it is important to devise novel solutions which take into account the diverse physical resources available in each device to efficiently and dynamically distribute the processing. In this paper, we propose a resource representation scheme which allows exposing the resources of each device through Mobile Edge Computing Application Programming Interfaces (MEC APIs) in order to optimize resource allocation by the supervising entity in the fog. Then, we formulate the resource allocation problem as a Lyapunov optimization and we discuss the impact of our proposed approach on latency. Simulation results show that our proposed approach can minimize latency and improve the performance of the system. ",
    "url": "https://arxiv.org/abs/2201.11829",
    "authors": [
      "Amine Abouaomar",
      "Soumaya Cherkaoui",
      "Abdellatif Kobbane",
      "Oussama Abderrahmane Dambri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.11831",
    "title": "A Deep Reinforcement Learning Approach for Service Migration in  MEC-enabled Vehicular Networks",
    "abstract": "Multi-access edge computing (MEC) is a key enabler to reduce the latency of vehicular network. Due to the vehicles mobility, their requested services (e.g., infotainment services) should frequently be migrated across different MEC servers to guarantee their stringent quality of service requirements. In this paper, we study the problem of service migration in a MEC-enabled vehicular network in order to minimize the total service latency and migration cost. This problem is formulated as a nonlinear integer program and is linearized to help obtaining the optimal solution using off-the-shelf solvers. Then, to obtain an efficient solution, it is modeled as a multi-agent Markov decision process and solved by leveraging deep Q learning (DQL) algorithm. The proposed DQL scheme performs a proactive services migration while ensuring their continuity under high mobility constraints. Finally, simulations results show that the proposed DQL scheme achieves close-to-optimal performance. ",
    "url": "https://arxiv.org/abs/2201.11831",
    "authors": [
      "Amine Abouaomar",
      "Zoubeir Mlika",
      "Abderrahime Filali",
      "Soumaya Cherkaoui",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.11853",
    "title": "Prediction of GPU Failures Under Deep Learning Workloads",
    "abstract": "Graphics processing units (GPUs) are the de facto standard for processing deep learning (DL) tasks. Meanwhile, GPU failures, which are inevitable, cause severe consequences in DL tasks: they disrupt distributed trainings, crash inference services, and result in service level agreement violations. To mitigate the problem caused by GPU failures, we propose to predict failures by using ML models. This paper is the first to study prediction models of GPU failures under large-scale production deep learning workloads. As a starting point, we evaluate classic prediction models and observe that predictions of these models are both inaccurate and unstable. To improve the precision and stability of predictions, we propose several techniques, including parallel and cascade model-ensemble mechanisms and a sliding training method. We evaluate the performances of our various techniques on a four-month production dataset including 350 million entries. The results show that our proposed techniques improve the prediction precision from 46.3\\% to 84.0\\%. ",
    "url": "https://arxiv.org/abs/2201.11853",
    "authors": [
      "Heting Liu",
      "Zhichao Li",
      "Cheng Tan",
      "Rongqiu Yang",
      "Guohong Cao",
      "Zherui Liu",
      "Chuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11860",
    "title": "On the Anonymity of Peer-To-Peer Network Anonymity Schemes Used by  Cryptocurrencies",
    "abstract": "Cryptocurrency systems can be subject to deanonymization attacks by exploiting the network-level communication on their peer-to-peer network. Adversaries who control a set of colluding node(s) within the peer-to-peer network can observe transactions being exchanged and infer the parties involved. Thus, various network anonymity schemes have been proposed to mitigate this problem, with some solutions providing theoretical anonymity guarantees. In this work, we model such peer-to-peer network anonymity solutions and evaluate their anonymity guarantees. To do so, we propose a novel framework that uses Bayesian inference to obtain the probability distributions linking transactions to their possible originators. We characterize transaction anonymity with those distributions, using entropy as metric of adversarial uncertainty on the originator's identity. In particular, we model Dandelion, Dandelion++ and Lightning Network. We study different configurations and demonstrate that none of them offers acceptable anonymity to their users. For instance, our analysis reveals that in the widely deployed Lightning Network, with just 5 strategically chosen colluding nodes the adversary can uniquely determine the originator for 67% of the transactions. In Dandelion, an adversary that controls 15% of the nodes has on average uncertainty among only 4 possible originators. Moreover, we observe that due to the way Dandelion and Dandelion++ are designed, increasing the network size does not correspond to an increase in the anonymity set of potential originators, highlighting the limitations of existing proposals. ",
    "url": "https://arxiv.org/abs/2201.11860",
    "authors": [
      "Piyush Kumar Sharma",
      "Devashish Gosain",
      "Claudia Diaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.11871",
    "title": "Infrastructure-Based Object Detection and Tracking for Cooperative  Driving Automation: A Survey",
    "abstract": "Object detection plays a fundamental role in enabling Cooperative Driving Automation (CDA), which is regarded as the revolutionary solution to addressing safety, mobility, and sustainability issues of contemporary transportation systems. Although current computer vision technologies could provide satisfactory object detection results in occlusion-free scenarios, the perception performance of onboard sensors could be inevitably limited by the range and occlusion. Owing to flexible position and pose for sensor installation, infrastructure-based detection and tracking systems can enhance the perception capability for connected vehicles and thus quickly become one of the most popular research topics. In this paper, we review the research progress for infrastructure-based object detection and tracking systems. Architectures of roadside perception systems based on different types of sensors are reviewed to show a high-level description of the workflows for infrastructure-based perception systems. Roadside sensors and different perception methodologies are reviewed and analyzed with detailed literature to provide a low-level explanation for specific methods followed by Datasets and Simulators to draw an overall landscape of infrastructure-based object detection and tracking methods. Discussions are conducted to point out current opportunities, open problems, and anticipated future trends. ",
    "url": "https://arxiv.org/abs/2201.11871",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Xuewei Qi",
      "Yongkang Liu",
      "Kentaro Oguchi",
      "Matthew J. Barth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.11885",
    "title": "Boosting Entity Mention Detection for Targetted Twitter Streams with  Global Contextual Embeddings",
    "abstract": "Microblogging sites, like Twitter, have emerged as ubiquitous sources of information. Two important tasks related to the automatic extraction and analysis of information in Microblogs are Entity Mention Detection (EMD) and Entity Detection (ED). The state-of-the-art EMD systems aim to model the non-literary nature of microblog text by training upon offline static datasets. They extract a combination of surface-level features -- orthographic, lexical, and semantic -- from individual messages for noisy text modeling and entity extraction. But given the constantly evolving nature of microblog streams, detecting all entity mentions from such varying yet limited context of short messages remains a difficult problem. To this end, we propose a framework named EMD Globalizer, better suited for the execution of EMD learners on microblog streams. It deviates from the processing of isolated microblog messages by existing EMD systems, where learned knowledge from the immediate context of a message is used to suggest entities. After an initial extraction of entity candidates by an EMD system, the proposed framework leverages occurrence mining to find additional candidate mentions that are missed during this first detection. Aggregating the local contextual representations of these mentions, a global embedding is drawn from the collective context of an entity candidate within a stream. The global embeddings are then utilized to separate entities within the candidates from false positives. All mentions of said entities from the stream are produced in the framework's final outputs. Our experiments show that EMD Globalizer can enhance the effectiveness of all existing EMD systems that we tested (on average by 25.61%) with a small additional computational overhead. ",
    "url": "https://arxiv.org/abs/2201.11885",
    "authors": [
      "Satadisha Saha Bhowmick",
      "Eduard C. Dragut",
      "Weiyi Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.11895",
    "title": "The CARE Dataset for Affective Response Detection",
    "abstract": "Social media plays an increasing role in our communication with friends and family, and our consumption of information and entertainment. Hence, to design effective ranking functions for posts on social media, it would be useful to predict the affective response to a post (e.g., whether the user is likely to be humored, inspired, angered, informed). Similar to work on emotion recognition (which focuses on the affect of the publisher of the post), the traditional approach to recognizing affective response would involve an expensive investment in human annotation of training data. We introduce CARE$_{db}$, a dataset of 230k social media posts annotated according to 7 affective responses using the Common Affective Response Expression (CARE) method. The CARE method is a means of leveraging the signal that is present in comments that are posted in response to a post, providing high-precision evidence about the affective response of the readers to the post without human annotation. Unlike human annotation, the annotation process we describe here can be iterated upon to expand the coverage of the method, particularly for new affective responses. We present experiments that demonstrate that the CARE annotations compare favorably with crowd-sourced annotations. Finally, we use CARE$_{db}$ to train competitive BERT-based models for predicting affective response as well as emotion detection, demonstrating the utility of the dataset for related tasks. ",
    "url": "https://arxiv.org/abs/2201.11895",
    "authors": [
      "Jane A. Yu",
      "Alon Y. Halevy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.11915",
    "title": "The fine line between dead neurons and sparsity in binarized spiking  neural networks",
    "abstract": "Spiking neural networks can compensate for quantization error by encoding information either in the temporal domain, or by processing discretized quantities in hidden states of higher precision. In theory, a wide dynamic range state-space enables multiple binarized inputs to be accumulated together, thus improving the representational capacity of individual neurons. This may be achieved by increasing the firing threshold, but make it too high and sparse spike activity turns into no spike emission. In this paper, we propose the use of `threshold annealing' as a warm-up method for firing thresholds. We show it enables the propagation of spikes across multiple layers where neurons would otherwise cease to fire, and in doing so, achieve highly competitive results on four diverse datasets, despite using binarized weights. Source code is available at https://github.com/jeshraghian/snn-tha/ ",
    "url": "https://arxiv.org/abs/2201.11915",
    "authors": [
      "Jason K. Eshraghian",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2201.11917",
    "title": "Task-Aware Network Coding Over Butterfly Network",
    "abstract": "Network coding allows distributed information sources such as sensors to efficiently compress and transmit data to distributed receivers across a bandwidth-limited network. Classical network coding is largely task-agnostic -- the coding schemes mainly aim to faithfully reconstruct data at the receivers, regardless of what ultimate task the received data is used for. In this paper, we analyze a new task-driven network coding problem, where distributed receivers pass transmitted data through machine learning (ML) tasks, which provides an opportunity to improve efficiency by transmitting salient task-relevant data representations. Specifically, we formulate a task-aware network coding problem over a butterfly network in real-coordinate space, where lossy analog compression through principal component analysis (PCA) can be applied. A lower bound for the total loss function for the formulated problem is given, and necessary and sufficient conditions for achieving this lower bound are also provided. We introduce ML algorithms to solve the problem in the general case, and our evaluation demonstrates the effectiveness of task-aware network coding. ",
    "url": "https://arxiv.org/abs/2201.11917",
    "authors": [
      "Jiangnan Cheng",
      "Sandeep Chinchali",
      "Ao Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11929",
    "title": "Positive Rate Binary Interactive Error Correcting Codes Resilient to  $>\\frac12$ Adversarial Erasures",
    "abstract": "An interactive error correcting code ($\\mathsf{iECC}$) is an interactive protocol with the guarantee that the receiver can correctly determine the sender's message, even in the presence of noise. This generalizes the concept of an error correcting code ($\\mathsf{ECC}$), which is a non-interactive $\\mathsf{iECC}$ that is known to have erasure resilience capped at $\\frac12$. The work of \\cite{GuptaTZ21} constructed the first $\\mathsf{iECC}$ resilient to $> \\frac12$ adversarial erasures. However, their $\\mathsf{iECC}$ has communication complexity quadratic in the message size. In our work, we construct the first positive rate $\\mathsf{iECC}$ resilient to $> \\frac12$ adversarial erasures. For any $\\epsilon > 0$, our $\\mathsf{iECC}$ is resilient to $\\frac6{11} - \\epsilon$ adversarial erasures and has size $O_\\epsilon(n)$. ",
    "url": "https://arxiv.org/abs/2201.11929",
    "authors": [
      "Meghal Gupta",
      "Rachel Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.11932",
    "title": "Deep Generative Model for Periodic Graphs",
    "abstract": "Periodic graphs are graphs consisting of repetitive local structures, such as crystal nets and polygon mesh. Their generative modeling has great potential in real-world applications such as material design and graphics synthesis. Classical models either rely on domain-specific predefined generation principles (e.g., in crystal net design), or follow geometry-based prescribed rules. Recently, deep generative models has shown great promise in automatically generating general graphs. However, their advancement into periodic graphs have not been well explored due to several key challenges in 1) maintaining graph periodicity; 2) disentangling local and global patterns; and 3) efficiency in learning repetitive patterns. To address them, this paper proposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a new deep generative models for periodic graphs that can automatically learn, disentangle, and generate local and global graph patterns. Specifically, we develop a new periodic graph encoder consisting of global-pattern encoder and local-pattern encoder that ensures to disentangle the representation into global and local semantics. We then propose a new periodic graph decoder consisting of local structure decoder, neighborhood decoder, and global structure decoder, as well as the assembler of their outputs that guarantees periodicity. Moreover, we design a new model learning objective that helps ensure the invariance of local-semantic representations for the graphs with the same local structure. Comprehensive experimental evaluations have been conducted to demonstrate the effectiveness of the proposed method. The code of proposed PGD-VAE is availabe at https://github.com/shi-yu-wang/PGD-VAE. ",
    "url": "https://arxiv.org/abs/2201.11932",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11935",
    "title": "Sequential Decoding of Convolutional Codes for Synchronization Errors",
    "abstract": "In this work, a sequential decoder for convolutional codes over channels that are vulnerable to insertion, deletion, and substitution errors, is described and analyzed. The decoder expands the code trellis by introducing a new channel state variable, called drift state, as proposed by Davey-MacKay. A suitable decoding metric on that trellis for sequential decoding is derived, in a manner that generalizes the original Fano metric. Under low-noise environments, this approach reduces the decoding complexity by a couple orders of magnitude in comparison to Viterbi's algorithm, albeit at relatively higher frame error rates. An analytical method to determine the computational cutoff rate is also suggested. This analysis is supported with numerical evaluations of frame error rates and computational complexity, which are compared with respect to optimal Viterbi decoding. ",
    "url": "https://arxiv.org/abs/2201.11935",
    "authors": [
      "Anisha Banerjee",
      "Andreas Lenz",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.11940",
    "title": "Wassersplines for Stylized Neural Animation",
    "abstract": "Much of computer-generated animation is created by manipulating meshes with rigs. While this approach works well for animating articulated objects like animals, it has limited flexibility for animating less structured creatures such as the Drunn in \"Raya and the Last Dragon.\" We introduce Wassersplines, a novel trajectory inference method for animating unstructured densities based on recent advances in continuous normalizing flows and optimal transport. The key idea is to train a neurally-parameterized velocity field that represents the motion between keyframes. Trajectories are then computed by pushing keyframes through the velocity field. We solve an additional Wasserstein barycenter interpolation problem to guarantee strict adherence to keyframes. Our tool can stylize trajectories through a variety of PDE-based regularizers to create different visual effects. We demonstrate our tool on various keyframe interpolation problems to produce temporally-coherent animations without meshing or rigging. ",
    "url": "https://arxiv.org/abs/2201.11940",
    "authors": [
      "Paul Zhang",
      "Dmitriy Smirnov",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11950",
    "title": "Time-Series Anomaly Detection with Implicit Neural Representation",
    "abstract": "Detecting anomalies in multivariate time-series data is essential in many real-world applications. Recently, various deep learning-based approaches have shown considerable improvements in time-series anomaly detection. However, existing methods still have several limitations, such as long training time due to their complex model designs or costly tuning procedures to find optimal hyperparameters (e.g., sliding window length) for a given dataset. In our paper, we propose a novel method called Implicit Neural Representation-based Anomaly Detection (INRAD). Specifically, we train a simple multi-layer perceptron that takes time as input and outputs corresponding values at that time. Then we utilize the representation error as an anomaly score for detecting anomalies. Experiments on five real-world datasets demonstrate that our proposed method outperforms other state-of-the-art methods in performance, training speed, and robustness. ",
    "url": "https://arxiv.org/abs/2201.11950",
    "authors": [
      "Kyeong-Joong Jeong",
      "Yong-Min Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11963",
    "title": "Shuffle Augmentation of Features from Unlabeled Data for Unsupervised  Domain Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA), a branch of transfer learning where labels for target samples are unavailable, has been widely researched and developed in recent years with the help of adversarially trained models. Although existing UDA algorithms are able to guide neural networks to extract transferable and discriminative features, classifiers are merely trained under the supervision of labeled source data. Given the inevitable discrepancy between source and target domains, the classifiers can hardly be aware of the target classification boundaries. In this paper, Shuffle Augmentation of Features (SAF), a novel UDA framework, is proposed to address the problem by providing the classifier with supervisory signals from target feature representations. SAF learns from the target samples, adaptively distills class-aware target features, and implicitly guides the classifier to find comprehensive class borders. Demonstrated by extensive experiments, the SAF module can be integrated into any existing adversarial UDA models to achieve performance improvements. ",
    "url": "https://arxiv.org/abs/2201.11963",
    "authors": [
      "Changwei Xu",
      "Jianfei Yang",
      "Haoran Tang",
      "Han Zou",
      "Cheng Lu",
      "Tianshuo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11968",
    "title": "Training invariances and the low-rank phenomenon: beyond linear networks",
    "abstract": "The implicit bias induced by the training of neural networks has become a topic of rigorous study. In the limit of gradient flow and gradient descent with appropriate step size, it has been shown that when one trains a deep linear network with logistic or exponential loss on linearly separable data, the weights converge to rank-$1$ matrices. In this paper, we extend this theoretical result to the much wider class of nonlinear ReLU-activated feedforward networks containing fully-connected layers and skip connections. To the best of our knowledge, this is the first time a low-rank phenomenon is proven rigorously for these architectures, and it reflects empirical results in the literature. The proof relies on specific local training invariances, sometimes referred to as alignment, which we show to hold for a wide set of ReLU architectures. Our proof relies on a specific decomposition of the network into a multilinear function and another ReLU network whose weights are constant under a certain parameter directional convergence. ",
    "url": "https://arxiv.org/abs/2201.11968",
    "authors": [
      "Thien Le",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.11969",
    "title": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "abstract": "Incorporating symmetry as an inductive bias into neural network architecture has led to improvements in generalization, data efficiency, and physical consistency in dynamics modeling. Methods such as CNN or equivariant neural networks use weight tying to enforce symmetries such as shift invariance or rotational equivariance. However, despite the fact that physical laws obey many symmetries, real-world dynamical data rarely conforms to strict mathematical symmetry either due to noisy or incomplete data or to symmetry breaking features in the underlying dynamical system. We explore approximately equivariant networks which are biased towards preserving symmetry but are not strictly constrained to do so. By relaxing equivariance constraints, we find that our models can outperform both baselines with no symmetry bias and baselines with overly strict symmetry in both simulated turbulence domains and real-world multi-stream jet flow. ",
    "url": "https://arxiv.org/abs/2201.11969",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11976",
    "title": "Learning to Simulate Unseen Physical Systems with Graph Neural Networks",
    "abstract": "Simulation of the dynamics of physical systems is essential to the development of both science and engineering. Recently there is an increasing interest in learning to simulate the dynamics of physical systems using neural networks. However, existing approaches fail to generalize to physical substances not in the training set, such as liquids with different viscosities or elastomers with different elasticities. Here we present a machine learning method embedded with physical priors and material parameters, which we term as \"Graph-based Physics Engine\" (GPE), to efficiently model the physical dynamics of different substances in a wide variety of scenarios. We demonstrate that GPE can generalize to materials with different properties not seen in the training set and perform well from single-step predictions to multi-step roll-out simulations. In addition, introducing the law of momentum conservation in the model significantly improves the efficiency and stability of learning, allowing convergence to better models with fewer training steps. ",
    "url": "https://arxiv.org/abs/2201.11976",
    "authors": [
      "Ce Yang",
      "Weihao Gao",
      "Di Wu",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11989",
    "title": "Using Constant Learning Rate of Two Time-Scale Update Rule for Training  Generative Adversarial Networks",
    "abstract": "Previous numerical results have shown that a two time-scale update rule (TTUR) using constant learning rates is practically useful for training generative adversarial networks (GANs). Meanwhile, a theoretical analysis of TTUR to find a stationary local Nash equilibrium of a Nash equilibrium problem with two players, a discriminator and a generator, has been given using decaying learning rates. In this paper, we give a theoretical analysis of TTUR using constant learning rates to bridge the gap between theory and practice. In particular, we show that, for TTUR using constant learning rates, the number of steps needed to find a stationary local Nash equilibrium decreases as the batch size increases. We also provide numerical results to support our theoretical analyzes. ",
    "url": "https://arxiv.org/abs/2201.11989",
    "authors": [
      "Naoki Sato",
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.12005",
    "title": "GTac: A Biomimetic Tactile Sensor with Skin-like Heterogeneous Force  Feedback for Robots",
    "abstract": "The tactile sensing capabilities of human hands are essential in performing daily activities. Simultaneously perceiving normal and shear forces via the mechanoreceptors integrated into the hands enables humans to achieve daily tasks like grasping delicate objects. In this paper, we design and fabricate a novel biomimetic tactile sensor with skin-like heterogeneity that perceives normal and shear contact forces simultaneously. It mimics the multilayers of mechanoreceptors by combining an extrinsic layer (piezoresistive sensors) and an intrinsic layer (a Hall sensor) so that it can perform estimation of contact force directions, locations, and joint-level torque. By integrating our sensors, a robotic gripper can obtain contact force feedback at fingertips; accordingly, robots can perform challenging tasks, such as tweezers usage, and egg grasping. This insightful sensor design can be customized and applied in different areas of robots and provide them with heterogeneous force sensing, potentially supporting robotics in acquiring skin-like tactile feedback. ",
    "url": "https://arxiv.org/abs/2201.12005",
    "authors": [
      "Zeyu Lu",
      "Xingyu Gao",
      "Haoyong Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.12006",
    "title": "Provably Improving Expert Predictions with Conformal Prediction",
    "abstract": "Automated decision support systems promise to help human experts solve tasks more efficiently and accurately. However, existing systems typically require experts to understand when to cede agency to the system or when to exercise their own agency. Moreover, if the experts develop a misplaced trust in the system, their performance may worsen. In this work, we lift the above requirement and develop automated decision support systems that, by design, do not require experts to understand when to trust them to provably improve their performance. To this end, we focus on multiclass classification tasks and consider automated decision support systems that, for each data sample, use a classifier to recommend a subset of labels to a human expert. We first show that, by looking at the design of such systems from the perspective of conformal prediction, we can ensure that the probability that the recommended subset of labels contains the true label matches almost exactly a target probability value. Then, we identify the set of target probability values under which the human expert is provably better off predicting a label among those in the recommended subset and develop an efficient practical method to find a near-optimal target probability value. Experiments on synthetic and real data demonstrate that our system can help the experts make more accurate predictions and is robust to the accuracy of the classifier it relies on. ",
    "url": "https://arxiv.org/abs/2201.12006",
    "authors": [
      "Eleni Straitouri",
      "Lequng Wang",
      "Nastaran Okati",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12011",
    "title": "A MADM method for network selection in heterogeneous wireless networks",
    "abstract": "The coexistence of different Radio Access Technologies (RATs) in the same area has enabled the researchers to get profit from the available networks by the selection of the best RAT at each moment to satisfy the user requirements. The challenge is to achieve the Always Best Connected (ABC) concept; the main issue is the automatic choice of the suitable Radio Access Technology (RAT) from the list of the available RATs. This decision is called network selection (NS). In this paper, we propose a modified Simple Additive Weigh (modified-SAW) function to deal with the drawbacks of the existing solutions. Indeed, the existing Multiple Attribute Decision Making (MADM) methods suffer mainly from the famous problem of rank reversal once an alternative is added or removed, other problems occur in the legacy MADMs. We modify the SAW method intelligently and we use it to solve the NS problem. Finally, we compare the performance of our solution with the previous works in different scenarios; the simulations show that our proposal outperforms the other existing methods ",
    "url": "https://arxiv.org/abs/2201.12011",
    "authors": [
      "Bendaoud Fayssal",
      "Abdennebi Marwen",
      "Didi Fedoua"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.12021",
    "title": "Network Selection schemes in Heterogeneous Wireless Networks",
    "abstract": "Heterogeneous Wireless Networks HWNs are combined networks made of different Radio Access Technologies RAT. Next-Generation Networks NGN will provide high bandwidth connectivity and high data throughput with smooth support for the user's QoS requirements, in this context, users with multi-interface terminals will be able to connect to different wireless technologies such as 802.16, 802.11 families and cellular families UMTS, HSPA and LTE in the same time. The idea of NGN is that users will not be tied with a contract with one single operator but, users will be able to choose the Radio Access Network RAT considering the user's QoS requested. This paper focuses on the network selection strategies and the inter technologies Handoff, we will present a description of the existed methods of network selection, we will discuss the merits and the weakness of such method and we will give our point of view. ",
    "url": "https://arxiv.org/abs/2201.12021",
    "authors": [
      "Bendaoud Fayssal",
      "Abdennebi Marwen",
      "Didi Fedoua"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.12032",
    "title": "Neural Approximation of Extended Persistent Homology on Graphs",
    "abstract": "Persistent homology is a widely used theory in topological data analysis. In the context of graph learning, topological features based on persistent homology have been used to capture potentially high-order structural information so as to augment existing graph neural network methods. However, computing extended persistent homology summaries remains slow for large and dense graphs, especially since in learning applications one has to carry out this computation potentially many times. Inspired by recent success in neural algorithmic reasoning, we propose a novel learning method to compute extended persistence diagrams on graphs. The proposed neural network aims to simulate a specific algorithm and learns to compute extended persistence diagrams for new graphs efficiently. Experiments on approximating extended persistence diagrams and several downstream graph representation learning tasks demonstrate the effectiveness of our method. Our method is also efficient; on large and dense graphs, we accelerate the computation by nearly 100 times. ",
    "url": "https://arxiv.org/abs/2201.12032",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12046",
    "title": "TSSB-3M: Mining single statement bugs at massive scale",
    "abstract": "Single statement bugs are one of the most important ingredients in the evaluation of modern bug detection and automatic program repair methods. By affecting only a single statement, single statement bugs represent a type of bug often overlooked by developers, while still being small enough to be detected and fixed by automatic methods. With the rise of data-driven automatic repair the availability of single statement bugs at the scale of millionth of examples is more important than ever; not only for testing these methods but also for providing sufficient real world examples for training. To provide access to bug fix datasets of this scale, we are releasing two datasets called SSB-9M and TSSB-3M. While SSB-9M provides access to a collection of over 9M general single statement bug fixes from over 500K open source Python projects , TSSB-3M focuses on over 3M single statement bugs which can be fixed solely by a single statement change. To facilitate future research and empirical investigations, we annotated each bug fix with one of 20 single statement bug (SStuB) patterns typical for Python together with a characterization of the code change as a sequence of AST modifications. Our initial investigation shows that at least 40% of all single statement bug fixes mined fit at least one SStuB pattern, and that the majority of 72% of all bugs can be fixed with the same syntactic modifications as needed for fixing SStuBs. ",
    "url": "https://arxiv.org/abs/2201.12046",
    "authors": [
      "Cedric Richter",
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2201.12051",
    "title": "Detection of fake faces in videos",
    "abstract": ": Deep learning methodologies have been used to create applications that can cause threats to privacy, democracy and national security and could be used to further amplify malicious activities. One of those deep learning-powered applications in recent times is synthesized videos of famous personalities. According to Forbes, Generative Adversarial Networks(GANs) generated fake videos growing exponentially every year and the organization known as Deeptrace had estimated an increase of deepfakes by 84% from the year 2018 to 2019. They are used to generate and modify human faces, where most of the existing fake videos are of prurient non-consensual nature, of which its estimates to be around 96% and some carried out impersonating personalities for cyber crime. In this paper, available video datasets are identified and a pretrained model BlazeFace is used to detect faces, and a ResNet and Xception ensembled architectured neural network trained on the dataset to achieve the goal of detection of fake faces in videos. The model is optimized over a loss value and log loss values and evaluated over its F1 score. Over a sample of data, it is observed that focal loss provides better accuracy, F1 score and loss as the gamma of the focal loss becomes a hyper parameter. This provides a k-folded accuracy of around 91% at its peak in a training cycle with the real world accuracy subjected to change over time as the model decays. ",
    "url": "https://arxiv.org/abs/2201.12051",
    "authors": [
      "M. Shamanth",
      "Russel Mathias",
      "Dr Vijayalakshmi MN"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12052",
    "title": "Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks",
    "abstract": "We study the overparametrization bounds required for the global convergence of stochastic gradient descent algorithm for a class of one hidden layer feed-forward neural networks, considering most of the activation functions used in practice, including ReLU. We improve the existing state-of-the-art results in terms of the required hidden layer width. We introduce a new proof technique combining nonlinear analysis with properties of random initializations of the network. First, we establish the global convergence of continuous solutions of the differential inclusion being a nonsmooth analogue of the gradient flow for the MSE loss. Second, we provide a technical result (working also for general approximators) relating solutions of the aforementioned differential inclusion to the (discrete) stochastic gradient descent sequences, hence establishing linear convergence towards zero loss for the stochastic gradient descent iterations. ",
    "url": "https://arxiv.org/abs/2201.12052",
    "authors": [
      "Bart\u0142omiej Polaczyk",
      "Jacek Cyranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.12078",
    "title": "You Only Cut Once: Boosting Data Augmentation with a Single Cut",
    "abstract": "We present You Only Cut Once (YOCO) for performing data augmentations. YOCO cuts one image into two pieces and performs data augmentations individually within each piece. Applying YOCO improves the diversity of the augmentation per sample and encourages neural networks to recognize objects from partial information. YOCO enjoys the properties of parameter-free, easy usage, and boosting almost all augmentations for free. Thorough experiments are conducted to evaluate its effectiveness. We first demonstrate that YOCO can be seamlessly applied to varying data augmentations, neural network architectures, and brings performance gains on CIFAR and ImageNet classification tasks, sometimes surpassing conventional image-level augmentation by large margins. Moreover, we show YOCO benefits contrastive pre-training toward a more powerful representation that can be better transferred to multiple downstream tasks. Finally, we study a number of variants of YOCO and empirically analyze the performance for respective settings. Code is available at GitHub. ",
    "url": "https://arxiv.org/abs/2201.12078",
    "authors": [
      "Junlin Han",
      "Pengfei Fang",
      "Weihao Li",
      "Jie Hong",
      "Mohammad Ali Armin",
      "Ian Reid",
      "Lars Petersson",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12082",
    "title": "Interplay between depth of neural networks and locality of target  functions",
    "abstract": "It has been recognized that heavily overparameterized deep neural networks (DNNs) exhibit surprisingly good generalization performance in various machine-learning tasks. Although benefits of depth have been investigated from different perspectives such as the approximation theory and the statistical learning theory, existing theories do not adequately explain the empirical success of overparameterized DNNs. In this work, we report a remarkable interplay between depth and locality of a target function. We introduce $k$-local and $k$-global functions, and find that depth is beneficial for learning local functions but detrimental to learning global functions. This interplay is not properly captured by the neural tangent kernel, which describes an infinitely wide neural network within the lazy learning regime. ",
    "url": "https://arxiv.org/abs/2201.12082",
    "authors": [
      "Takashi Mori",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12088",
    "title": "On feedforward control using physics-guided neural networks: Training  cost regularization and optimized initialization",
    "abstract": "Performance of model-based feedforward controllers is typically limited by the accuracy of the inverse system dynamics model. Physics-guided neural networks (PGNN), where a known physical model cooperates in parallel with a neural network, were recently proposed as a method to achieve high accuracy of the identified inverse dynamics. However, the flexible nature of neural networks can create overparameterization when employed in parallel with a physical model, which results in a parameter drift during training. This drift may result in parameters of the physical model not corresponding to their physical values, which increases vulnerability of the PGNN to operating conditions not present in the training data. To address this problem, this paper proposes a regularization method via identified physical parameters, in combination with an optimized training initialization that improves training convergence. The regularized PGNN framework is validated on a real-life industrial linear motor, where it delivers better tracking accuracy and extrapolation. ",
    "url": "https://arxiv.org/abs/2201.12088",
    "authors": [
      "Max Bolderman",
      "Mircea Lazar",
      "Hans Butler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": "Modern neural models trained on textual data rely on pre-trained representations that emerge without direct supervision. As these representations are increasingly being used in real-world applications, the inability to \\emph{control} their content becomes an increasingly important problem. We formulate the problem of identifying and erasing a linear subspace that corresponds to a given concept, in order to prevent linear predictors from recovering the concept. We model this problem as a constrained, linear minimax game, and show that existing solutions are generally not optimal for this task. We derive a closed-form solution for certain objectives, and propose a convex relaxation, R-LACE, that works well for others. When evaluated in the context of binary gender removal, the method recovers a low-dimensional subspace whose removal mitigates bias by intrinsic and extrinsic evaluation. We show that the method -- despite being linear -- is highly expressive, effectively mitigating bias in deep nonlinear classifiers while maintaining tractability and interpretability. ",
    "url": "https://arxiv.org/abs/2201.12091",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.12094",
    "title": "Neighborhood-aware Geometric Encoding Network for Point Cloud  Registration",
    "abstract": "The distinguishing geometric features determine the success of point cloud registration. However, most point clouds are partially overlapping, corrupted by noise, and comprised of indistinguishable surfaces, which makes it a challenge to extract discriminative features. Here, we propose the Neighborhood-aware Geometric Encoding Network (NgeNet) for accurate point cloud registration. NgeNet utilizes a geometric guided encoding module to take geometric characteristics into consideration, a multi-scale architecture to focus on the semantically rich regions in different scales, and a consistent voting strategy to select features with proper neighborhood size and reject the specious features. The awareness of adaptive neighborhood points is obtained through the multi-scale architecture accompanied by voting. Specifically, the proposed techniques in NgeNet are model-agnostic, which could be easily migrated to other networks. Comprehensive experiments on indoor, outdoor and object-centric synthetic datasets demonstrate that NgeNet surpasses all of the published state-of-the-art methods. The code will be available at https://github.com/zhulf0804/NgeNet. ",
    "url": "https://arxiv.org/abs/2201.12094",
    "authors": [
      "Lifa Zhu",
      "Haining Guan",
      "Changwei Lin",
      "Renmin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12099",
    "title": "Detecting Owner-member Relationship with Graph Convolution Network in  Fisheye Camera System",
    "abstract": "The owner-member relationship between wheels and vehicles contributes significantly to the 3D perception of vehicles, especially in embedded environments. However, to leverage this relationship we must face two major challenges: i) Traditional IoU-based heuristics have difficulty handling occluded traffic congestion scenarios. ii) The effectiveness and applicability of the solution in a vehicle-mounted system is difficult. To address these issues, we propose an innovative relationship prediction method, DeepWORD, by designing a graph convolutional network (GCN). Specifically, to improve the information richness, we use feature maps with local correlation as input to the nodes. Subsequently, we introduce a graph attention network (GAT) to dynamically correct the a priori estimation bias. Finally, we designed a dataset as a large-scale benchmark which has annotated owner-member relationship, called WORD. In the experiments we learned that the proposed method achieved state-of-the-art accuracy and real-time performance. The WORD dataset is made publicly available at https://github.com/NamespaceMain/ownermember-relationship-dataset. ",
    "url": "https://arxiv.org/abs/2201.12099",
    "authors": [
      "Zizhang Wu",
      "Jason Wang",
      "Tianhao Xu",
      "Fan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12105",
    "title": "Improving End-to-End Models for Set Prediction in Spoken Language  Understanding",
    "abstract": "The goal of spoken language understanding (SLU) systems is to determine the meaning of the input speech signal, unlike speech recognition which aims to produce verbatim transcripts. Advances in end-to-end (E2E) speech modeling have made it possible to train solely on semantic entities, which are far cheaper to collect than verbatim transcripts. We focus on this set prediction problem, where entity order is unspecified. Using two classes of E2E models, RNN transducers and attention based encoder-decoders, we show that these models work best when the training entity sequence is arranged in spoken order. To improve E2E SLU models when entity spoken order is unknown, we propose a novel data augmentation technique along with an implicit attention based alignment method to infer the spoken order. F1 scores significantly increased by more than 11% for RNN-T and about 2% for attention based encoder-decoder SLU models, outperforming previously reported results. ",
    "url": "https://arxiv.org/abs/2201.12105",
    "authors": [
      "Hong-Kwang J. Kuo",
      "Zoltan Tuske",
      "Samuel Thomas",
      "Brian Kingsbury",
      "George Saon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.12113",
    "title": "HEAT: Hyperedge Attention Networks",
    "abstract": "Learning from structured data is a core machine learning task. Commonly, such data is represented as graphs, which normally only consider (typed) binary relationships between pairs of nodes. This is a substantial limitation for many domains with highly-structured data. One important such domain is source code, where hypergraph-based representations can better capture the semantically rich and structured nature of code. In this work, we present HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes contribute. It can be viewed as a generalization of both message passing neural networks and Transformers. We evaluate HEAT on knowledge base completion and on bug detection and repair using a novel hypergraph representation of programs. In both settings, it outperforms strong baselines, indicating its power and generality. ",
    "url": "https://arxiv.org/abs/2201.12113",
    "authors": [
      "Dobrik Georgiev",
      "Marc Brockschmidt",
      "Miltiadis Allamanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.12129",
    "title": "Impact of Phase-Noise and Spatial Correlation on Double-RIS-Assisted  Multiuser MISO Networks",
    "abstract": "We study the performance of a phase-noise impaired double reconfigurable intelligent surface (RIS)-aided multiuser (MU) multiple-input single-output (MISO) system under spatial correlation at both RISs and base-station (BS). The downlink achievable rate is derived in closed-form under maximum ratio transmission (MRT) precoding. In addition, we obtain the optimal phase-shift design at both RISs in closed-form for the considered channel and phase-noise models. Numerical results validate the analytical expressions, and highlight the effects of different system parameters on the achievable rate. In particular, it is demonstrated that while phase-noise at RISs and spatial correlation at BS are capacity limiting factors, the spatial correlation at both RISs is essential to obtain high achievable rates. ",
    "url": "https://arxiv.org/abs/2201.12129",
    "authors": [
      "Zaid Abdullah",
      "Anastasios Papazafeiropoulos",
      "Steven Kisseleff",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.12153",
    "title": "Improving Pre-movement Pattern Detection with Filter Bank Selection",
    "abstract": "Pre-movement decoding plays an important role in movement detection and is able to detect movement onset with low-frequency electroencephalogram (EEG) signals before the limb moves. In related studies, pre-movement decoding with standard task-related component analysis (STRCA) has been demonstrated to be efficient for classification between movement state and resting state. However, the accuracies of STRCA differ among subbands in the frequency domain. Due to individual differences, the best subband differs among subjects and is difficult to be determined. This study aims to improve the performance of the STRCA method by a feature selection on multiple subbands and avoid the selection of best subbands. This study first compares three frequency range settings ($M_1$: subbands with equally spaced bandwidths; $M_2$: subbands whose high cut-off frequencies are twice the low cut-off frequencies; $M_3$: subbands that start at some specific fixed frequencies and end at the frequencies in an arithmetic sequence.). Then, we develop a mutual information based technique to select the features in these subbands. A binary support vector machine classifier is used to classify the selected essential features. The results show that $M_3$ is a better setting than the other two settings. With the filter banks in $M_3$, the classification accuracy of the proposed FBTRCA achieves 0.8700$\\pm$0.1022, which means a significantly improved performance compared to STRCA (0.8287$\\pm$0.1101) as well as to the cross validation and testing method (0.8431$\\pm$0.1078). ",
    "url": "https://arxiv.org/abs/2201.12153",
    "authors": [
      "Hao Jia",
      "Zhe Sun",
      "Feng Duan",
      "Yu Zhang",
      "Cesar F. Caiafa",
      "Jordi Sol\u00e9-Casals"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2201.12158",
    "title": "Stagnation Detection meets Fast Mutation",
    "abstract": "Two mechanisms have recently been proposed that can significantly speed up finding distant improving solutions via mutation, namely using a random mutation rate drawn from a heavy-tailed distribution (\"fast mutation\", Doerr et al. (2017)) and increasing the mutation strength based on stagnation detection (Rajabi and Witt (2020)). Whereas the latter can obtain the asymptotically best probability of finding a single desired solution in a given distance, the former is more robust and performs much better when many improving solutions in some distance exist. In this work, we propose a mutation strategy that combines ideas of both mechanisms. We show that it can also obtain the best possible probability of finding a single distant solution. However, when several improving solutions exist, it can outperform both the stagnation-detection approach and fast mutation. The new operator is more than an interleaving of the two previous mechanisms and it also outperforms any such interleaving. ",
    "url": "https://arxiv.org/abs/2201.12158",
    "authors": [
      "Benjamin Doerr",
      "Amirhossein Rajabi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.12165",
    "title": "Graph autoencoder with constant dimensional latent space",
    "abstract": "Invertible transformation of large graphs into constant dimensional vectors (embeddings) remains a challenge. In this paper we address it with recursive neural networks: The encoder and the decoder. The encoder network transforms embeddings of subgraphs into embeddings of larger subgraphs, and eventually into the embedding of the input graph. The decoder does the opposite. The dimension of the embeddings is constant regardless of the size of the (sub)graphs. Simulation experiments presented in this paper confirm that our proposed graph autoencoder can handle graphs with even thousands of vertices. ",
    "url": "https://arxiv.org/abs/2201.12165",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": "Model inversion attacks (MIAs) aim to create synthetic images that reflect the class-wise characteristics from a target classifier's training data by exploiting the model's learned knowledge. Previous research has developed generative MIAs using generative adversarial networks (GANs) as image priors that are tailored to a specific target model. This makes the attacks time- and resource-consuming, inflexible, and susceptible to distributional shifts between datasets. To overcome these drawbacks, we present Plug & Play Attacks that loosen the dependency between the target model and image prior and enable the use of a single trained GAN to attack a broad range of targets with only minor attack adjustments needed. Moreover, we show that powerful MIAs are possible even with publicly available pre-trained GANs and under strong distributional shifts, whereas previous approaches fail to produce meaningful results. Our extensive evaluation confirms the improved robustness and flexibility of Plug & Play Attacks and their ability to create high-quality images revealing sensitive class characteristics. ",
    "url": "https://arxiv.org/abs/2201.12179",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12184",
    "title": "A tomographic workflow to enable deep learning for X-ray based foreign  object detection",
    "abstract": "Detection of unwanted (`foreign') objects within products is a common procedure in many branches of industry for maintaining production quality. X-ray imaging is a fast, non-invasive and widely applicable method for foreign object detection. Deep learning has recently emerged as a powerful approach for recognizing patterns in radiographs (i.e., X-ray images), enabling automated X-ray based foreign object detection. However, these methods require a large number of training examples and manual annotation of these examples is a subjective and laborious task. In this work, we propose a Computed Tomography (CT) based method for producing training data for supervised learning of foreign object detection, with minimal labour requirements. In our approach, a few representative objects are CT scanned and reconstructed in 3D. The radiographs that have been acquired as part of the CT-scan data serve as input for the machine learning method. High-quality ground truth locations of the foreign objects are obtained through accurate 3D reconstructions and segmentations. Using these segmented volumes, corresponding 2D segmentations are obtained by creating virtual projections. We outline the benefits of objectively and reproducibly generating training data in this way compared to conventional radiograph annotation. In addition, we show how the accuracy depends on the number of objects used for the CT reconstructions. The results show that in this workflow generally only a relatively small number of representative objects (i.e., fewer than 10) are needed to achieve adequate detection performance in an industrial setting. Moreover, for real experimental data we show that the workflow leads to higher foreign object detection accuracies than with standard radiograph annotation. ",
    "url": "https://arxiv.org/abs/2201.12184",
    "authors": [
      "Math\u00e9 T. Zeegers",
      "Tristan van Leeuwen",
      "Dani\u00ebl M. Pelt",
      "Sophia Bethany Coban",
      "Robert van Liere",
      "Kees Joost Batenburg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.12191",
    "title": "Adversarial Concept Erasure in Kernel Space",
    "abstract": "The representation space of neural models for textual data emerges in an unsupervised manner during training. Understanding how human-interpretable concepts, such as gender, are encoded in these representations would improve the ability of users to \\emph{control} the content of these representations and analyze the working of the models that rely on them. One prominent approach to the control problem is the identification and removal of linear concept subspaces -- subspaces in the representation space that correspond to a given concept. While those are tractable and interpretable, neural network do not necessarily represent concepts in linear subspaces. We propose a kernalization of the linear concept-removal objective of [Ravfogel et al. 2022], and show that it is effective in guarding against the ability of certain nonlinear adversaries to recover the concept. Interestingly, our findings suggest that the division between linear and nonlinear models is overly simplistic: when considering the concept of binary gender and its neutralization, we do not find a single kernel space that exclusively contains all the concept-related information. It is therefore challenging to protect against \\emph{all} nonlinear adversaries at once. ",
    "url": "https://arxiv.org/abs/2201.12191",
    "authors": [
      "Shauli Ravfogel",
      "Francisco Vargas",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.12211",
    "title": "Backdoors Stuck At The Frontdoor: Multi-Agent Backdoor Attacks That  Backfire",
    "abstract": "Malicious agents in collaborative learning and outsourced data collection threaten the training of clean models. Backdoor attacks, where an attacker poisons a model during training to successfully achieve targeted misclassification, are a major concern to train-time robustness. In this paper, we investigate a multi-agent backdoor attack scenario, where multiple attackers attempt to backdoor a victim model simultaneously. A consistent backfiring phenomenon is observed across a wide range of games, where agents suffer from a low collective attack success rate. We examine different modes of backdoor attack configurations, non-cooperation / cooperation, joint distribution shifts, and game setups to return an equilibrium attack success rate at the lower bound. The results motivate the re-evaluation of backdoor defense research for practical environments. ",
    "url": "https://arxiv.org/abs/2201.12211",
    "authors": [
      "Siddhartha Datta",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2201.12216",
    "title": "Self-paced learning to improve text row detection in historical  documents with missing lables",
    "abstract": "An important preliminary step of optical character recognition systems is the detection of text rows. To address this task in the context of historical data with missing labels, we propose a self-paced learning algorithm capable of improving the row detection performance. We conjecture that pages with more ground-truth bounding boxes are less likely to have missing annotations. Based on this hypothesis, we sort the training examples in descending order with respect to the number of ground-truth bounding boxes, and organize them into k batches. Using our self-paced learning method, we train a row detector over k iterations, progressively adding batches with less ground-truth annotations. At each iteration, we combine the ground-truth bounding boxes with pseudo-bounding boxes (bounding boxes predicted by the model itself) using non-maximum suppression, and we include the resulting annotations at the next training iteration. We demonstrate that our self-paced learning strategy brings significant performance gains on two data sets of historical documents, improving the average precision of YOLOv4 with more than 12% on one data set and 39% on the other. ",
    "url": "https://arxiv.org/abs/2201.12216",
    "authors": [
      "Mihaela Gaman",
      "Lida Ghadamiyan",
      "Radu Tudor Ionescu",
      "Marius Popescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12220",
    "title": "Neural Optimal Transport",
    "abstract": "We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the performance of our optimal transport algorithm on toy examples and on the unpaired image-to-image style translation task. ",
    "url": "https://arxiv.org/abs/2201.12220",
    "authors": [
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12230",
    "title": "Agent-based modeling and simulation for malware spreading in D2D  networks",
    "abstract": "This paper presents a new multi-agent model for simulating malware propagation in device-to-device (D2D) 5G networks. This model allows to understand and analyze mobile malware-spreading dynamics in such highly dynamical networks. Additionally, we present a theoretical study to validate and benchmark our proposed approach for some basic scenarios that are less complicated to model mathematically and also to highlight the key parameters of the model. Our simulations identify critical thresholds for \"no propagation\" and for \"maximum malware propagation\" and make predictions on the malware-spread velocity as well as device-infection rates. To the best of our knowledge, this paper is the first study applying agent-based simulations for malware propagation in D2D. ",
    "url": "https://arxiv.org/abs/2201.12230",
    "authors": [
      "Ziyad Benomar",
      "Chaima Ghribi",
      "Elie Cali",
      "Alexander Hinsen",
      "Benedikt Jahnel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2201.12231",
    "title": "Overcoming Exploration: Deep Reinforcement Learning in Complex  Environments from Temporal Logic Specifications",
    "abstract": "We present a Deep Reinforcement Learning (DRL) algorithm for a task-guided robot with unknown continuous-time dynamics deployed in a large-scale complex environment. Linear Temporal Logic (LTL) is applied to express a rich robotic specification. To overcome the environmental challenge, we propose a novel path planning-guided reward scheme that is dense over the state space, and crucially, robust to infeasibility of computed geometric paths due to the unknown robot dynamics. To facilitate LTL satisfaction, our approach decomposes the LTL mission into sub-tasks that are solved using distributed DRL, where the sub-tasks are trained in parallel, using Deep Policy Gradient algorithms. Our framework is shown to significantly improve performance (effectiveness, efficiency) and exploration of robots tasked with complex missions in large-scale complex environments. ",
    "url": "https://arxiv.org/abs/2201.12231",
    "authors": [
      "Mingyu Cai",
      "Erfan Aasi",
      "Calin Belta",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12240",
    "title": "Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs)",
    "abstract": "Implicit deep learning architectures, like Neural ODEs and Deep Equilibrium Models (DEQs), separate the definition of a layer from the description of its solution process. While implicit layers allow features such as depth to adapt to new scenarios and inputs automatically, this adaptivity makes its computational expense challenging to predict. Numerous authors have noted that implicit layer techniques can be more computationally intensive than explicit layer methods. In this manuscript, we address the question: is there a way to simultaneously achieve the robustness of implicit layers while allowing the reduced computational expense of an explicit layer? To solve this we develop Skip DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an explicit prediction followed by an implicit correction. We show that training this explicit layer is free and even decreases the training time by 2.5x and prediction time by 3.4x. We then further increase the \"implicitness\" of the DEQ by redefining the method in terms of an infinite time neural ODE which paradoxically decreases the training cost over a standard neural ODE by not requiring backpropagation through time. We demonstrate how the resulting Continuous Skip DEQ architecture trains more robustly than the original DEQ while achieving faster training and prediction times. Together, this manuscript shows how bridging the dichotomy of implicit and explicit deep learning can combine the advantages of both techniques. ",
    "url": "https://arxiv.org/abs/2201.12240",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2201.12245",
    "title": "Wasserstein Iterative Networks for Barycenter Estimation",
    "abstract": "Wasserstein barycenters have become popular due to their ability to represent the average of probability measures in a geometrically meaningful way. In this paper, we present an algorithm to approximate the Wasserstein-2 barycenters of continuous measures via a generative model. Previous approaches rely on regularization (entropic/quadratic) which introduces bias or on input convex neural networks which are not expressive enough for large-scale tasks. In contrast, our algorithm does not introduce bias and allows using arbitrary neural networks. In addition, based on the celebrity faces dataset, we construct Ave, celeba! dataset which can be used for quantitative evaluation of barycenter algorithms by using standard metrics of generative models such as FID. ",
    "url": "https://arxiv.org/abs/2201.12245",
    "authors": [
      "Alexander Korotin",
      "Vage Egiazarian",
      "Lingxiao Li",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12249",
    "title": "Agent-based simulations for coverage extensions in 5G networks and  beyond",
    "abstract": "Device-to-device (D2D) communications is one of the key emerging technologies for the fifth generation (5G) networks and beyond. It enables direct communication between mobile users and thereby extends coverage for devices lacking direct access to the cellular infrastructure and hence enhances network capacity. D2D networks are complex, highly dynamic and will be strongly augmented by intelligence for decision making at both the edge and core of the network, which makes them particularly difficult to predict and analyze. Conventionally, D2D systems are evaluated, investigated and analyzed using analytical and probabilistic models (e.g., from stochastic geometry). However, applying classical simulation and analytical tools to such a complex system is often hard to track and inaccurate. In this paper, we present a modeling and simulation framework from the perspective of complex-systems science and exhibit an agent-based model for the simulation of D2D coverage extensions. We also present a theoretical study to benchmark our proposed approach for a basic scenario that is less complicated to model mathematically. Our simulation results show that we are indeed able to predict coverage extensions for multi-hop scenarios and quantify the effects of street-system characteristics and pedestrian mobility on the connection time of devices to the base station (BS). To our knowledge, this is the first study that applies agent-based simulations for coverage extensions in D2D. ",
    "url": "https://arxiv.org/abs/2201.12249",
    "authors": [
      "Chaima Ghribi",
      "Elie Cali",
      "Christian Hirsch",
      "Benedikt Jahnel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2201.12250",
    "title": "Gradient Descent on Neurons and its Link to Approximate Second-Order  Optimization",
    "abstract": "Second-order optimizers are thought to hold the potential to speed up neural network training, but due to the enormous size of the curvature matrix, they typically require approximations to be computationally tractable. The most successful family of approximations are Kronecker-Factored, block-diagonal curvature estimates (KFAC). Here, we combine tools from prior work to evaluate exact second-order updates with careful ablations to establish a surprising result: Due to its approximations, KFAC is not closely related to second-order updates, and in particular, it significantly outperforms true second-order updates. This challenges widely held believes and immediately raises the question why KFAC performs so well. We answer this question by showing that KFAC approximates a first-order algorithm, which performs gradient descent on neurons rather than weights. Finally, we show that this optimizer often improves over KFAC in terms of computational cost and data-efficiency. ",
    "url": "https://arxiv.org/abs/2201.12250",
    "authors": [
      "Frederik Benzing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12263",
    "title": "RiskNet: Neural Risk Assessment in Networks of Unreliable Resources",
    "abstract": "We propose a graph neural network (GNN)-based method to predict the distribution of penalties induced by outages in communication networks, where connections are protected by resources shared between working and backup paths. The GNN-based algorithm is trained only with random graphs generated with the Barab\\'asi-Albert model. Even though, the obtained test results show that we can precisely model the penalties in a wide range of various existing topologies. GNNs eliminate the need to simulate complex outage scenarios for the network topologies under study. In practice, the whole design operation is limited by 4ms on modern hardware. This way, we can gain as much as over 12,000 times in the speed improvement. ",
    "url": "https://arxiv.org/abs/2201.12263",
    "authors": [
      "Krzysztof Rusek",
      "Piotr Bory\u0142o",
      "Piotr Jaglarz",
      "Fabien Geyer",
      "Albert Cabellos",
      "Piotr Cho\u0142da"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12265",
    "title": "3D-FlowNet: Event-based optical flow estimation with 3D representation",
    "abstract": "Event-based cameras can overpass frame-based cameras limitations for important tasks such as high-speed motion detection during self-driving cars navigation in low illumination conditions. The event cameras' high temporal resolution and high dynamic range, allow them to work in fast motion and extreme light scenarios. However, conventional computer vision methods, such as Deep Neural Networks, are not well adapted to work with event data as they are asynchronous and discrete. Moreover, the traditional 2D-encoding representation methods for event data, sacrifice the time resolution. In this paper, we first improve the 2D-encoding representation by expanding it into three dimensions to better preserve the temporal distribution of the events. We then propose 3D-FlowNet, a novel network architecture that can process the 3D input representation and output optical flow estimations according to the new encoding methods. A self-supervised training strategy is adopted to compensate the lack of labeled datasets for the event-based camera. Finally, the proposed network is trained and evaluated with the Multi-Vehicle Stereo Event Camera (MVSEC) dataset. The results show that our 3D-FlowNet outperforms state-of-the-art approaches with less training epoch (30 compared to 100 of Spike-FlowNet). ",
    "url": "https://arxiv.org/abs/2201.12265",
    "authors": [
      "Haixin Sun",
      "Minh-Quan Dao",
      "Vincent Fremont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12285",
    "title": "Benchmarking Conventional Vision Models on Neuromorphic Fall Detection  and Action Recognition Dataset",
    "abstract": "Neuromorphic vision-based sensors are gaining popularity in recent years with their ability to capture Spatio-temporal events with low power sensing. These sensors record events or spikes over traditional cameras which helps in preserving the privacy of the subject being recorded. These events are captured as per-pixel brightness changes and the output data stream is encoded with time, location, and pixel intensity change information. This paper proposes and benchmarks the performance of fine-tuned conventional vision models on neuromorphic human action recognition and fall detection datasets. The Spatio-temporal event streams from the Dynamic Vision Sensing cameras are encoded into a standard sequence image frames. These video frames are used for benchmarking conventional deep learning-based architectures. In this proposed approach, we fine-tuned the state-of-the-art vision models for this Dynamic Vision Sensing (DVS) application and named these models as DVS-R2+1D, DVS-CSN, DVS-C2D, DVS-SlowFast, DVS-X3D, and DVS-MViT. Upon comparing the performance of these models, we see the current state-of-the-art MViT based architecture DVS-MViT outperforms all the other models with an accuracy of 0.958 and an F-1 score of 0.958. The second best is the DVS-C2D with an accuracy of 0.916 and an F-1 score of 0.916. Third and Fourth are DVS-R2+1D and DVS-SlowFast with an accuracy of 0.875 and 0.833 and F-1 score of 0.875 and 0.861 respectively. DVS-CSN and DVS-X3D were the least performing models with an accuracy of 0.708 and 0.625 and an F1 score of 0.722 and 0.625 respectively. ",
    "url": "https://arxiv.org/abs/2201.12285",
    "authors": [
      "Karthik Sivarama Krishnan",
      "Koushik Sivarama Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.12296",
    "title": "Benchmarking Robustness of 3D Point Cloud Recognition Against Common  Corruptions",
    "abstract": "Deep neural networks on 3D point cloud data have been widely used in the real world, especially in safety-critical applications. However, their robustness against corruptions is less studied. In this paper, we present ModelNet40-C, the first comprehensive benchmark on 3D point cloud corruption robustness, consisting of 15 common and realistic corruptions. Our evaluation shows a significant gap between the performances on ModelNet40 and ModelNet40-C for state-of-the-art (SOTA) models. To reduce the gap, we propose a simple but effective method by combining PointCutMix-R and TENT after evaluating a wide range of augmentation and test-time adaptation strategies. We identify a number of critical insights for future studies on corruption robustness in point cloud recognition. For instance, we unveil that Transformer-based architectures with proper training recipes achieve the strongest robustness. We hope our in-depth analysis will motivate the development of robust training strategies or architecture designs in the 3D point cloud domain. Our codebase and dataset are included in https://github.com/jiachens/ModelNet40-C ",
    "url": "https://arxiv.org/abs/2201.12296",
    "authors": [
      "Jiachen Sun",
      "Qingzhao Zhang",
      "Bhavya Kailkhura",
      "Zhiding Yu",
      "Chaowei Xiao",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12300",
    "title": "Efficient Embedding of Semantic Similarity in Control Policies via  Entangled Bisimulation",
    "abstract": "Learning generalizeable policies from visual input in the presence of visual distractions is a challenging problem in reinforcement learning. Recently, there has been renewed interest in bisimulation metrics as a tool to address this issue; these metrics can be used to learn representations that are, in principle, invariant to irrelevant distractions by measuring behavioural similarity between states. An accurate, unbiased, and scalable estimation of these metrics has proved elusive in continuous state and action scenarios. We propose entangled bisimulation, a bisimulation metric that allows the specification of the distance function between states, and can be estimated without bias in continuous state and action spaces. We show how entangled bisimulation can meaningfully improve over previous methods on the Distracting Control Suite (DCS), even when added on top of data augmentation techniques. ",
    "url": "https://arxiv.org/abs/2201.12300",
    "authors": [
      "Martin Bertran",
      "Walter Talbott",
      "Nitish Srivastava",
      "Joshua Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.12311",
    "title": "REET: Robustness Evaluation and Enhancement Toolbox for Computational  Pathology",
    "abstract": "Motivation: Digitization of pathology laboratories through digital slide scanners and advances in deep learning approaches for objective histological assessment have resulted in rapid progress in the field of computational pathology (CPath) with wide-ranging applications in medical and pharmaceutical research as well as clinical workflows. However, the estimation of robustness of CPath models to variations in input images is an open problem with a significant impact on the down-stream practical applicability, deployment and acceptability of these approaches. Furthermore, development of domain-specific strategies for enhancement of robustness of such models is of prime importance as well. Implementation and Availability: In this work, we propose the first domain-specific Robustness Evaluation and Enhancement Toolbox (REET) for computational pathology applications. It provides a suite of algorithmic strategies for enabling robustness assessment of predictive models with respect to specialized image transformations such as staining, compression, focusing, blurring, changes in spatial resolution, brightness variations, geometric changes as well as pixel-level adversarial perturbations. Furthermore, REET also enables efficient and robust training of deep learning pipelines in computational pathology. REET is implemented in Python and is available at the following URL: https://github.com/alexjfoote/reetoolbox. Contact: Fayyaz.minhas@warwick.ac.uk ",
    "url": "https://arxiv.org/abs/2201.12311",
    "authors": [
      "Alex Foote",
      "Amina Asif",
      "Nasir Rajpoot",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12320",
    "title": "Generative Cooperative Networks for Natural Language Generation",
    "abstract": "Generative Adversarial Networks (GANs) have known a tremendous success for many continuous generation tasks, especially in the field of image generation. However, for discrete outputs such as language, optimizing GANs remains an open problem with many instabilities, as no gradient can be properly back-propagated from the discriminator output to the generator parameters. An alternative is to learn the generator network via reinforcement learning, using the discriminator signal as a reward, but such a technique suffers from moving rewards and vanishing gradient problems. Finally, it often falls short compared to direct maximum-likelihood approaches. In this paper, we introduce Generative Cooperative Networks, in which the discriminator architecture is cooperatively used along with the generation policy to output samples of realistic texts for the task at hand. We give theoretical guarantees of convergence for our approach, and study various efficient decoding schemes to empirically achieve state-of-the-art results in two main NLG tasks. ",
    "url": "https://arxiv.org/abs/2201.12320",
    "authors": [
      "Sylvain Lamprier",
      "Thomas Scialom",
      "Antoine Chaffin",
      "Vincent Claveau",
      "Ewa Kijak",
      "Jacopo Staiano",
      "Benjamin Piwowarski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.12328",
    "title": "Toward Training at ImageNet Scale with Differential Privacy",
    "abstract": "Differential privacy (DP) is the de facto standard for training machine learning (ML) models, including neural networks, while ensuring the privacy of individual examples in the training set. Despite a rich literature on how to train ML models with differential privacy, it remains extremely challenging to train real-life, large neural networks with both reasonable accuracy and privacy. We set out to investigate how to do this, using ImageNet image classification as a poster example of an ML task that is very challenging to resolve accurately with DP right now. This paper shares initial lessons from our effort, in the hope that it will inspire and inform other researchers to explore DP training at scale. We show approaches which help to make DP training faster, as well as model types and settings of the training process that tend to work better for DP. Combined, the methods we discuss let us train a Resnet-18 with differential privacy to 47.9% accuracy and privacy parameters $\\epsilon = 10, \\delta = 10^{-6}$, a significant improvement over \"naive\" DP-SGD training of Imagenet models but a far cry from the $75\\%$ accuracy that can be obtained by the same network without privacy. We share our code at https://github.com/google-research/dp-imagenet calling for others to join us in moving the needle further on DP at scale. ",
    "url": "https://arxiv.org/abs/2201.12328",
    "authors": [
      "Alexey Kurakin",
      "Steve Chien",
      "Shuang Song",
      "Roxana Geambasu",
      "Andreas Terzis",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.14092",
    "title": "Network utility maximization by updating individual transmission rates",
    "abstract": "This paper discusses the problem of maximizing the total data transmission utility of the computer network. The total utility is defined as the sum of the individual (corresponding to each node in the network) utilities that are concave functions of the data transmission rate. For the case of non-strongly concave utilities, we propose an approach based on the use of a fast gradient method to optimize a dually smoothed objective function. As an alternative approach, we introduce stochastic oracles for the problem under consideration and interpret them as the messages on the state of some individual node to use randomized switching mirror descent to solve the problem above. We propose interpretations of both described approaches allowing the effective implementation of the protocols of their operation in the real-life computer networks environment, taking into account the distributed information storage and the restricted communication capabilities. The numerical experiments were carried out to compare the proposed approaches on sythetic examples of network architectures. ",
    "url": "https://arxiv.org/abs/2106.14092",
    "authors": [
      "Dmitry Pasechnyuk"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.11795",
    "title": "Neural JPEG: End-to-End Image Compression Leveraging a Standard JPEG  Encoder-Decoder",
    "abstract": "Recent advances in deep learning have led to superhuman performance across a variety of applications. Recently, these methods have been successfully employed to improve the rate-distortion performance in the task of image compression. However, current methods either use additional post-processing blocks on the decoder end to improve compression or propose an end-to-end compression scheme based on heuristics. For the majority of these, the trained deep neural networks (DNNs) are not compatible with standard encoders and would be difficult to deply on personal computers and cellphones. In light of this, we propose a system that learns to improve the encoding performance by enhancing its internal neural representations on both the encoder and decoder ends, an approach we call Neural JPEG. We propose frequency domain pre-editing and post-editing methods to optimize the distribution of the DCT coefficients at both encoder and decoder ends in order to improve the standard compression (JPEG) method. Moreover, we design and integrate a scheme for jointly learning quantization tables within this hybrid neural compression framework.Experiments demonstrate that our approach successfully improves the rate-distortion performance over JPEG across various quality metrics, such as PSNR and MS-SSIM, and generates visually appealing images with better color retention quality. ",
    "url": "https://arxiv.org/abs/2201.11795",
    "authors": [
      "Ankur Mali",
      "Alexander Ororbia",
      "Daniel Kifer",
      "Lee Giles"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11941",
    "title": "Unifying Pairwise Interactions in Complex Dynamics",
    "abstract": "Scientists have developed hundreds of techniques to measure the interactions between pairs of processes in complex systems. But these computational methods -- from correlation coefficients to causal inference -- rely on distinct quantitative theories that remain largely disconnected. Here we introduce a library of 249 statistics for pairwise interactions and assess their behavior on 1053 multivariate time series from a wide range of real-world and model-generated systems. Our analysis highlights new commonalities between different mathematical formulations, providing a unified picture of a rich, interdisciplinary literature. We then show that leveraging many methods from across science can uncover those most suitable for addressing a given problem, yielding high accuracy and interpretable understanding. Our framework is provided in extendable open software, enabling comprehensive data-driven analysis by integrating decades of methodological advances. ",
    "url": "https://arxiv.org/abs/2201.11941",
    "authors": [
      "Oliver M. Cliff",
      "Joseph T. Lizier",
      "Naotsugu Tsuchiya",
      "Ben D. Fulcher"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11954",
    "title": "Sharp Threshold for the Frechet Mean (or Median) of Inhomogeneous  Erdos-Renyi Random Graphs",
    "abstract": "We address the following foundational question: what is the population, and sample, Frechet mean (or median) graph of an ensemble of inhomogeneous Erdos-Renyi random graphs? We prove that if we use the Hamming distance to compute distances between graphs, then the Frechet mean (or median) graph of an ensemble of inhomogeneous random graphs is obtained by thresholding the expected adjacency matrix of the ensemble. We show that the result also holds for the sample mean (or median) when the population expected adjacency matrix is replaced with the sample mean adjacency matrix. Consequently, the Frechet mean (or median) graph of inhomogeneous Erdos-Renyi random graphs exhibits a sharp threshold: it is either the empty graph, or the complete graph. This novel theoretical result has some significant practical consequences; for instance, the Frechet mean of an ensemble of sparse inhomogeneous random graphs is always the empty graph. ",
    "url": "https://arxiv.org/abs/2201.11954",
    "authors": [
      "Francois G. Meyer"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.11980",
    "title": "Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics",
    "abstract": "We analyse the privacy leakage of noisy stochastic gradient descent by modeling R\\'enyi divergence dynamics with Langevin diffusions. Inspired by recent work on non-stochastic algorithms, we derive similar desirable properties in the stochastic setting. In particular, we prove that the privacy loss converges exponentially fast for smooth and strongly convex objectives under constant step size, which is a significant improvement over previous DP-SGD analyses. We also extend our analysis to arbitrary sequences of varying step sizes and derive new utility bounds. Last, we propose an implementation and our experiments show the practical utility of our approach compared to classical DP-SGD libraries. ",
    "url": "https://arxiv.org/abs/2201.11980",
    "authors": [
      "Th\u00e9o Ryffel",
      "Francis Bach",
      "David Pointcheval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11996",
    "title": "Deep Networks for Image and Video Super-Resolution",
    "abstract": "Efficiency of gradient propagation in intermediate layers of convolutional neural networks is of key importance for super-resolution task. To this end, we propose a deep architecture for single image super-resolution (SISR), which is built using efficient convolutional units we refer to as mixed-dense connection blocks (MDCB). The design of MDCB combines the strengths of both residual and dense connection strategies, while overcoming their limitations. To enable super-resolution for multiple factors, we propose a scale-recurrent framework which reutilizes the filters learnt for lower scale factors recursively for higher factors. This leads to improved performance and promotes parametric efficiency for higher factors. We train two versions of our network to enhance complementary image qualities using different loss configurations. We further employ our network for video super-resolution task, where our network learns to aggregate information from multiple frames and maintain spatio-temporal consistency. The proposed networks lead to qualitative and quantitative improvements over state-of-the-art techniques on image and video super-resolution benchmarks. ",
    "url": "https://arxiv.org/abs/2201.11996",
    "authors": [
      "Kuldeep Purohit",
      "Srimanta Mandal",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.11998",
    "title": "Image Superresolution using Scale-Recurrent Dense Network",
    "abstract": "Recent advances in the design of convolutional neural network (CNN) have yielded significant improvements in the performance of image super-resolution (SR). The boost in performance can be attributed to the presence of residual or dense connections within the intermediate layers of these networks. The efficient combination of such connections can reduce the number of parameters drastically while maintaining the restoration quality. In this paper, we propose a scale recurrent SR architecture built upon units containing series of dense connections within a residual block (Residual Dense Blocks (RDBs)) that allow extraction of abundant local features from the image. Our scale recurrent design delivers competitive performance for higher scale factors while being parametrically more efficient as compared to current state-of-the-art approaches. To further improve the performance of our network, we employ multiple residual connections in intermediate layers (referred to as Multi-Residual Dense Blocks), which improves gradient propagation in existing layers. Recent works have discovered that conventional loss functions can guide a network to produce results which have high PSNRs but are perceptually inferior. We mitigate this issue by utilizing a Generative Adversarial Network (GAN) based framework and deep feature (VGG) losses to train our network. We experimentally demonstrate that different weighted combinations of the VGG loss and the adversarial loss enable our network outputs to traverse along the perception-distortion curve. The proposed networks perform favorably against existing methods, both perceptually and objectively (PSNR-based) with fewer parameters. ",
    "url": "https://arxiv.org/abs/2201.11998",
    "authors": [
      "Kuldeep Purohit",
      "Srimanta Mandal",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12003",
    "title": "BCDAG: An R package for Bayesian structure and Causal learning of  Gaussian DAGs",
    "abstract": "Directed Acyclic Graphs (DAGs) provide a powerful framework to model causal relationships among variables in multivariate settings; in addition, through the do-calculus theory, they allow for the identification and estimation of causal effects between variables also from pure observational data. In this setting, the process of inferring the DAG structure from the data is referred to as causal structure learning or causal discovery. We introduce BCDAG, an R package for Bayesian causal discovery and causal effect estimation from Gaussian observational data, implementing the Markov chain Monte Carlo (MCMC) scheme proposed by Castelletti & Mascaro (2021). Our implementation scales efficiently with the number of observations and, whenever the DAGs are sufficiently sparse, with the number of variables in the dataset. The package also provides functions for convergence diagnostics and for visualizing and summarizing posterior inference. In this paper, we present the key features of the underlying methodology along with its implementation in BCDAG. We then illustrate the main functions and algorithms on both real and simulated datasets. ",
    "url": "https://arxiv.org/abs/2201.12003",
    "authors": [
      "Federico Castelletti",
      "Alessandro Mascaro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2201.12020",
    "title": "A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data",
    "abstract": "This paper tackles the problem of missing data imputation for noisy and non-Gaussian data. A classical imputation method, the Expectation Maximization (EM) algorithm for Gaussian mixture models, has shown interesting properties when compared to other popular approaches such as those based on k-nearest neighbors or on multiple imputations by chained equations. However, Gaussian mixture models are known to be not robust to heterogeneous data, which can lead to poor estimation performance when the data is contaminated by outliers or come from a non-Gaussian distributions. To overcome this issue, a new expectation maximization algorithm is investigated for mixtures of elliptical distributions with the nice property of handling potential missing data. The complete-data likelihood associated with mixtures of elliptical distributions is well adapted to the EM framework thanks to its conditional distribution, which is shown to be a Student distribution. Experimental results on synthetic data demonstrate that the proposed algorithm is robust to outliers and can be used with non-Gaussian data. Furthermore, experiments conducted on real-world datasets show that this algorithm is very competitive when compared to other classical imputation methods. ",
    "url": "https://arxiv.org/abs/2201.12020",
    "authors": [
      "Florian Mouret",
      "Alexandre Hippert-Ferrer",
      "Fr\u00e9d\u00e9ric Pascal",
      "Jean-Yves Tourneret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12064",
    "title": "Multiscale Graph Comparison via the Embedded Laplacian Distance",
    "abstract": "We introduce a simple and fast method for comparing graphs of different sizes. Existing approaches are often either limited to comparing graphs with the same number of vertices or are computationally unscalable. We propose the Embedded Laplacian Distance (ELD) for comparing graphs of potentially vastly different sizes. Our approach first projects the graphs onto a common, low-dimensional Laplacian embedding space that respects graphical structure. This reduces the problem to that of comparing point clouds in a Euclidean space. A distance can then be computed efficiently via a natural sliced Wasserstein approach. We show that the ELD is a pseudo-metric and is invariant under graph isomorphism. We provide intuitive interpretations of the ELD using tools from spectral graph theory. We test the efficacy of the ELD approach extensively on both simulated and real data. Results obtained are excellent. ",
    "url": "https://arxiv.org/abs/2201.12064",
    "authors": [
      "Edric Tam",
      "David Dunson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12152",
    "title": "Carotid artery wall segmentation in ultrasound image sequences using a  deep convolutional neural network",
    "abstract": "The objective of this study is the segmentation of the intima-media complex of the common carotid artery, on longitudinal ultrasound images, to measure its thickness. We propose a fully automatic region-based segmentation method, involving a supervised region-based deep-learning approach based on a dilated U-net network. It was trained and evaluated using a 5-fold cross-validation on a multicenter database composed of 2176 images annotated by two experts. The resulting mean absolute difference (<120 um) compared to reference annotations was less than the inter-observer variability (180 um). With a 98.7% success rate, i.e., only 1.3% cases requiring manual correction, the proposed method has been shown to be robust and thus may be recommended for use in clinical practice. ",
    "url": "https://arxiv.org/abs/2201.12152",
    "authors": [
      "Nolann Lain\u00e9",
      "Guillaume Zahnd",
      "Herv \u00e9 Liebgott",
      "Maciej Orkisz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12248",
    "title": "Graphs with $G^p$-connected medians",
    "abstract": "The median of a graph $G$ with weighted vertices is the set of all vertices $x$ minimizing the sum of weighted distances from $x$ to the vertices of $G$. For any integer $p\\ge 2$, we characterize the graphs in which, with respect to any non-negative weights, median sets always induce connected subgraphs in the $p$th power $G^p$ of $G$. This extends some characterizations of graphs with connected medians (case $p=1$) provided by Bandelt and Chepoi (2002). The characteristic conditions can be tested in polynomial time for any $p$. We also show that several important classes of graphs in metric graph theory, including bridged graphs (and thus chordal graphs), graphs with convex balls, bucolic graphs, and bipartite absolute retracts, have $G^2$-connected medians. Extending the result of Bandelt and Chepoi that basis graphs of matroids are graphs with connected medians, we characterize the isometric subgraphs of Johnson graphs and of halved-cubes with connected medians. ",
    "url": "https://arxiv.org/abs/2201.12248",
    "authors": [
      "Laurine B\u00e9n\u00e9teau",
      "J\u00e9r\u00e9mie Chalopin",
      "Victor Chepoi",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:1802.01268",
    "title": "ASMCNN: An Efficient Brain Extraction Using Active Shape Model and  Convolutional Neural Networks",
    "abstract": " Comments: 47 pages, 20 figures ",
    "url": "https://arxiv.org/abs/1802.01268",
    "authors": [
      "Duy H. M. Nguyen",
      "Duy M. Nguyen",
      "Mai T. N. Truong",
      "Thu Nguyen",
      "Khanh T. Tran",
      "Nguyen A. Triet",
      "Pham T. Bao",
      "Binh T. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1909.07533",
    "title": "Analog Subspace Coding: A New Approach to Coding for Non-Coherent  Wireless Networks",
    "abstract": " Title: Analog Subspace Coding: A New Approach to Coding for Non-Coherent  Wireless Networks ",
    "url": "https://arxiv.org/abs/1909.07533",
    "authors": [
      "Mahdi Soleymani",
      "Hessam Mahdavifar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2010.05997",
    "title": "Look It Up: Bilingual Dictionaries Improve Neural Machine Translation",
    "abstract": " Title: Look It Up: Bilingual Dictionaries Improve Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2010.05997",
    "authors": [
      "Xing Jie Zhong",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.10050",
    "title": "Learning Parametrised Graph Shift Operators",
    "abstract": " Comments: 17 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2101.10050",
    "authors": [
      "George Dasoulas",
      "Johannes Lutzeyer",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.00473",
    "title": "Information fusion between knowledge and data in Bayesian network  structure learning",
    "abstract": " Title: Information fusion between knowledge and data in Bayesian network  structure learning ",
    "url": "https://arxiv.org/abs/2102.00473",
    "authors": [
      "Anthony C. Constantinou",
      "Zhigao Guo",
      "Neville K. Kitson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.04046",
    "title": "Simplicial Complex Representation Learning",
    "abstract": " Comments: MACHINE LEARNING ON GRAPHS, MLoG Workshop at WSDM'22 ",
    "url": "https://arxiv.org/abs/2103.04046",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Vasileios Maroulas",
      "Theodore Papamarkou",
      "Xuanting Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.15552",
    "title": "Energy Decay Network (EDeN)",
    "abstract": " Title: Energy Decay Network (EDeN) ",
    "url": "https://arxiv.org/abs/2103.15552",
    "authors": [
      "Jamie Nicholas Shelley",
      "Optishell Consultancy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.01641",
    "title": "TATL: Task Agnostic Transfer Learning for Skin Attributes Detection",
    "abstract": " Comments: This version has been accepted at Medical Image Analysis ",
    "url": "https://arxiv.org/abs/2104.01641",
    "authors": [
      "Duy M. H. Nguyen",
      "Thu T. Nguyen",
      "Huong Vu",
      "Quang Pham",
      "Manh-Duy Nguyen",
      "Binh T. Nguyen",
      "Daniel Sonntag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.05488",
    "title": "CNN Encoding of Acoustic Parameters for Prominence Detection",
    "abstract": " Comments: 5 pages, 2 figures, 6 tables, Submitted to INTERSPEECH 2021 ",
    "url": "https://arxiv.org/abs/2104.05488",
    "authors": [
      "Kamini Sabu",
      "Mithilesh Vaidya",
      "Preeti Rao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2105.04906",
    "title": "VICReg: Variance-Invariance-Covariance Regularization for  Self-Supervised Learning",
    "abstract": " Comments: Accepted at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2105.04906",
    "authors": [
      "Adrien Bardes",
      "Jean Ponce",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05658",
    "title": "Conditional COT-GAN for Video Prediction with Kernel Smoothing",
    "abstract": " Title: Conditional COT-GAN for Video Prediction with Kernel Smoothing ",
    "url": "https://arxiv.org/abs/2106.05658",
    "authors": [
      "Tianlin Xu",
      "Beatrice Acciaio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07967",
    "title": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "abstract": " Title: Incorporating Word Sense Disambiguation in Neural Language Models ",
    "url": "https://arxiv.org/abs/2106.07967",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.10800",
    "title": "Lossy Compression for Lossless Prediction",
    "abstract": " Comments: Accepted at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2106.10800",
    "authors": [
      "Yann Dubois",
      "Benjamin Bloem-Reddy",
      "Karen Ullrich",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.02220",
    "title": "Graph Convolution for Re-ranking in Person Re-identification",
    "abstract": " Title: Graph Convolution for Re-ranking in Person Re-identification ",
    "url": "https://arxiv.org/abs/2107.02220",
    "authors": [
      "Yuqi Zhang",
      "Qian Qi",
      "Chong Liu",
      "Weihua Chen",
      "Fan Wang",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.08842",
    "title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for  Federated Learning",
    "abstract": " Title: EDEN: Communication-Efficient and Robust Distributed Mean Estimation for  Federated Learning ",
    "url": "https://arxiv.org/abs/2108.08842",
    "authors": [
      "Shay Vargaftik",
      "Ran Ben Basat",
      "Amit Portnoy",
      "Gal Mendelson",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2108.11845",
    "title": "Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks",
    "abstract": " Title: Consistent Relative Confidence and Label-Free Model Selection for  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2108.11845",
    "authors": [
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09705",
    "title": "Neural forecasting at scale",
    "abstract": " Title: Neural forecasting at scale ",
    "url": "https://arxiv.org/abs/2109.09705",
    "authors": [
      "Philippe Chatigny",
      "Shengrui Wang",
      "Jean-Marc Patenaude",
      "Boris N. Oreshkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.12769",
    "title": "Heterogeneous Treatment Effect Estimation using machine learning for  Healthcare application: tutorial and benchmark",
    "abstract": " Comments: 52 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.12769",
    "authors": [
      "Yaobin Ling",
      "Pulakesh Upadhyaya",
      "Luyao Chen",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2109.15273",
    "title": "DAAS: Differentiable Architecture and Augmentation Policy Search",
    "abstract": " Title: DAAS: Differentiable Architecture and Augmentation Policy Search ",
    "url": "https://arxiv.org/abs/2109.15273",
    "authors": [
      "Xiaoxing Wang",
      "Xiangxiang Chu",
      "Junchi Yan",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.01664",
    "title": "Estimating Potential Outcome Distributions with Collaborating Causal  Networks",
    "abstract": " Comments: 21 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2110.01664",
    "authors": [
      "Tianhui Zhou",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01984",
    "title": "Differential Privacy of Dirichlet Posterior Sampling",
    "abstract": " Comments: The privacy guarantees have been rewritten in terms of R\\'enyi Differential Privacy ",
    "url": "https://arxiv.org/abs/2110.01984",
    "authors": [
      "Donlapark Ponnoprat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.02510",
    "title": "Cycle Representation Learning for Inductive Relation Prediction",
    "abstract": " Title: Cycle Representation Learning for Inductive Relation Prediction ",
    "url": "https://arxiv.org/abs/2110.02510",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03605",
    "title": "One Thing to Fool them All: Generating Interpretable, Universal, and  Physically-Realizable Adversarial Features",
    "abstract": " Comments: Code available at: this https URL ",
    "url": "https://arxiv.org/abs/2110.03605",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.03681",
    "title": "Neural Tangent Kernel Empowered Federated Learning",
    "abstract": " Title: Neural Tangent Kernel Empowered Federated Learning ",
    "url": "https://arxiv.org/abs/2110.03681",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Ryan Pilgrim",
      "Chau-Wai Wong",
      "Dror Baron",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.04624",
    "title": "Iterative Refinement Graph Neural Network for Antibody  Sequence-Structure Co-design",
    "abstract": " Comments: Accepted to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.04624",
    "authors": [
      "Wengong Jin",
      "Jeremy Wohlwend",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.05792",
    "title": "Aspect-driven User Preference and News Representation Learning for News  Recommendation",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2110.05792",
    "authors": [
      "Rongyao Wang",
      "Wenpeng Lu",
      "Shoujin Wang",
      "Xueping Peng",
      "Hao Wu",
      "Qian Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.06485",
    "title": "Communication-Efficient Triangle Counting under Local Differential  Privacy",
    "abstract": " Comments: Full version of the paper accepted at USENIX Security 2022; The first and second authors made equal contribution ",
    "url": "https://arxiv.org/abs/2110.06485",
    "authors": [
      "Jacob Imola",
      "Takao Murakami",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2110.10249",
    "title": "Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics",
    "abstract": " Title: Neural Stochastic Partial Differential Equations: Resolution-Invariant  Learning of Continuous Spatiotemporal Dynamics ",
    "url": "https://arxiv.org/abs/2110.10249",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier",
      "Andris Gerasimovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.06150",
    "title": "Improving Novelty Detection using the Reconstructions of Nearest  Neighbours",
    "abstract": " Title: Improving Novelty Detection using the Reconstructions of Nearest  Neighbours ",
    "url": "https://arxiv.org/abs/2111.06150",
    "authors": [
      "Michael Mesarcik",
      "Elena Ranguelova",
      "Albert-Jan Boonstra",
      "Rob V. van Nieuwpoort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08851",
    "title": "Deep Neural Networks for Rank-Consistent Ordinal Regression Based On  Conditional Probabilities",
    "abstract": " Comments: This paper is currently under consideration at Pattern Recognition Letters ",
    "url": "https://arxiv.org/abs/2111.08851",
    "authors": [
      "Xintong Shi",
      "Wenzhi Cao",
      "Sebastian Raschka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.15068",
    "title": "MISS: Multi-Interest Self-Supervised Learning Framework for  Click-Through Rate Prediction",
    "abstract": " Comments: Accepted by ICDE2022 ",
    "url": "https://arxiv.org/abs/2111.15068",
    "authors": [
      "Wei Guo",
      "Can Zhang",
      "Zhicheng He",
      "Jiarui Qin",
      "Huifeng Guo",
      "Bo Chen",
      "Ruiming Tang",
      "Xiuqiang He",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.06024",
    "title": "Towards automated optimisation of residual convolutional neural networks  for electrocardiogram classification",
    "abstract": " Title: Towards automated optimisation of residual convolutional neural networks  for electrocardiogram classification ",
    "url": "https://arxiv.org/abs/2112.06024",
    "authors": [
      "Zeineb Fki",
      "Boudour Ammar",
      "Mounir Ben Ayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09161",
    "title": "Constraint-based graph network simulator",
    "abstract": " Title: Constraint-based graph network simulator ",
    "url": "https://arxiv.org/abs/2112.09161",
    "authors": [
      "Yulia Rubanova",
      "Alvaro Sanchez-Gonzalez",
      "Tobias Pfaff",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.02711",
    "title": "Block Walsh-Hadamard Transform Based Binary Layers in Deep Neural  Networks",
    "abstract": " Comments: This paper has been accepted by ACM Transactions on Embedded Computing Systems ",
    "url": "https://arxiv.org/abs/2201.02711",
    "authors": [
      "Hongyi Pan",
      "Diaa Badawi",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.02771",
    "title": "A Sneak Attack on Segmentation of Medical Images Using Deep Neural  Network Classifiers",
    "abstract": " Comments: 8 pages, 10 figures. Accepted by IEEE AIPR 2021 (Oral) ",
    "url": "https://arxiv.org/abs/2201.02771",
    "authors": [
      "Shuyue Guan",
      "Murray Loew"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10410",
    "title": "Comparison of Evaluation Metrics for Landmark Detection in CMR Images",
    "abstract": " Comments: Accepted at Bildverarbeitung f\\\"ur die Medizin (BVM), Informatik aktuell. Springer Vieweg, Wiesbaden 2022 ",
    "url": "https://arxiv.org/abs/2201.10410",
    "authors": [
      "Sven Koehler",
      "Lalith Sharan",
      "Julian Kuhm",
      "Arman Ghanaat",
      "Jelizaveta Gordejeva",
      "Nike K. Simon",
      "Niko M. Grell",
      "Florian Andr\u00e9",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "abstract": " Title: Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation ",
    "url": "https://arxiv.org/abs/2201.10737",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]