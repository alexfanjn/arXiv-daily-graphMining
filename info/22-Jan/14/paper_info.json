[
  {
    "id": "arXiv:2201.04630",
    "title": "Generative time series models using Neural ODE in Variational  Autoencoders",
    "abstract": "In this paper, we implement Neural Ordinary Differential Equations in a Variational Autoencoder setting for generative time series modeling. An object-oriented approach to the code was taken to allow for easier development and research and all code used in the paper can be found here: https://github.com/simonmoesorensen/neural-ode-project The results were initially recreated and the reconstructions compared to a baseline Long-Short Term Memory AutoEncoder. The model was then extended with a LSTM encoder and challenged by more complex data consisting of time series in the form of spring oscillations. The model showed promise, and was able to reconstruct true trajectories for all complexities of data with a smaller RMSE than the baseline model. However, it was able to capture the dynamic behavior of the time series for known data in the decoder but was not able to produce extrapolations following the true trajectory very well for any of the complexities of spring data. A final experiment was carried out where the model was also presented with 68 days of solar power production data, and was able to reconstruct just as well as the baseline, even when very little data is available. Finally, the models training time was compared to the baseline. It was found that for small amounts of data the NODE method was significantly slower at training than the baseline, while for larger amounts of data the NODE method would be equal or faster at training. The paper is ended with a future work section which describes the many natural extensions to the work presented in this paper, with examples being investigating further the importance of input data, including extrapolation in the baseline model or testing more specific model setups. ",
    "url": "https://arxiv.org/abs/2201.04630",
    "authors": [
      "M. L. Garsdal",
      "V. S\u00f8gaard",
      "S. M. S\u00f8rensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04654",
    "title": "Real-Time Monitoring and Control of Water Networks",
    "abstract": "Water networks are used in numerous applications, all of which have the essential task of real-time monitoring and control of water states. A framework for the generation of efficient models of water networks suitable for real-time monitoring and control purposes is proposed. The proposed models preserve the distributed parameter character of the network local elements. Hence, the spatial resolution of the property under consideration is recovered. The real-time feasibility of the network model is ensured by means of reduced-order modeling of the models constituting components. A novel model order reduction procedure that preserves the model parametric dependency is introduced. The proposed concept is evaluated with the water temperature as the property under consideration. The formulated model is applied for the prediction of the water temperature within an experimental test bench of a 60-meter exemplary circulation network at the company VIEGA. A reduced-order model (ROM) with a 50 mm spatial resolution, i.e. 1200 discretization points, is constructed and utilized as the identification model for a single path of the test bench. Afterward, the ROM is evaluated in a Hardware in the Loop experiment for the prediction of the downstream temperature showing high prediction accuracy with mean relative error below 3.5\\%. The ROM single step computation time stayed below 2 msec highlighting the real-time potential of the method. Moreover, full network model validation experiments featuring both diffusion and transport-dominated parts were conducted. The network model could predict the temperature evolution, flow rate, and pressure accurately at the different paths of the network with mean relative errors below 4\\%, 2\\%, and 2\\%, respectively. ",
    "url": "https://arxiv.org/abs/2201.04654",
    "authors": [
      "Ahmed Elkhashap",
      "Daniel R\u00fcschen",
      "Dirk Abel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.04672",
    "title": "How Can Graph Neural Networks Help Document Retrieval: A Case Study on  CORD19 with Concept Map Generation",
    "abstract": "Graph neural networks (GNNs), as a group of powerful tools for representation learning on irregular data, have manifested superiority in various downstream tasks. With unstructured texts represented as concept maps, GNNs can be exploited for tasks like document retrieval. Intrigued by how can GNNs help document retrieval, we conduct an empirical study on a large-scale multi-discipline dataset CORD-19. Results show that instead of the complex structure-oriented GNNs such as GINs and GATs, our proposed semantics-oriented graph functions achieve better and more stable performance based on the BM25 retrieved candidates. Our insights in this case study can serve as a guideline for future work to develop effective GNNs with appropriate semantics-oriented inductive biases for textual reasoning tasks like document retrieval and classification. All code for this case study is available at https://github.com/HennyJie/GNN-DocRetrieval. ",
    "url": "https://arxiv.org/abs/2201.04672",
    "authors": [
      "Hejie Cui",
      "Jiaying Lu",
      "Yao Ge",
      "Carl Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04676",
    "title": "Uniformer: Unified Transformer for Efficient Spatiotemporal  Representation Learning",
    "abstract": "It is a challenging task to learn rich and multi-scale spatiotemporal semantics from high-dimensional videos, due to large local redundancy and complex global dependency between video frames. The recent advances in this research have been mainly driven by 3D convolutional neural networks and vision transformers. Although 3D convolution can efficiently aggregate local context to suppress local redundancy from a small 3D neighborhood, it lacks the capability to capture global dependency because of the limited receptive field. Alternatively, vision transformers can effectively capture long-range dependency by self-attention mechanism, while having the limitation on reducing local redundancy with blind similarity comparison among all the tokens in each layer. Based on these observations, we propose a novel Unified transFormer (UniFormer) which seamlessly integrates merits of 3D convolution and spatiotemporal self-attention in a concise transformer format, and achieves a preferable balance between computation and accuracy. Different from traditional transformers, our relation aggregator can tackle both spatiotemporal redundancy and dependency, by learning local and global token affinity respectively in shallow and deep layers. We conduct extensive experiments on the popular video benchmarks, e.g., Kinetics-400, Kinetics-600, and Something-Something V1&V2. With only ImageNet-1K pretraining, our UniFormer achieves 82.9%/84.8% top-1 accuracy on Kinetics-400/Kinetics-600, while requiring 10x fewer GFLOPs than other state-of-the-art methods. For Something-Something V1 and V2, our UniFormer achieves new state-of-the-art performances of 60.9% and 71.2% top-1 accuracy respectively. Code is available at https://github.com/Sense-X/UniFormer. ",
    "url": "https://arxiv.org/abs/2201.04676",
    "authors": [
      "Kunchang Li",
      "Yali Wang",
      "Peng Gao",
      "Guanglu Song",
      "Yu Liu",
      "Hongsheng Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04678",
    "title": "Polynomial Turing Compressions for Some Graph Problems Parameterized by  Modular-Width",
    "abstract": "In this paper we investigate the parameterized complexity for NP-hard graph problems parameterized by a structural parameter modular-width. We develop a recipe that is able to simplify the process of obtaining polynomial Turing compressions for a class of graph problems parameterized by modular-width. Moreover, we prove that several problems, which include \\textsc{chromatic number, independent set}, \\textsc{Hamiltonian cycle}, etc. have polynomial Turing compressions parameterized by modular-width. In addition, under the assumption that P $\\neq$ NP, we provide tight kernels for a few problems such as \\textsc{Steiner tree} parameterized by modular-width. Meanwhile, we demonstrate that some problems, which includes \\textsc{dominating set}, \\textsc{odd cycle transversal}, \\textsc{connected vertex cover}, etc. are fixed-parameter tractable parameterized by modular-width. ",
    "url": "https://arxiv.org/abs/2201.04678",
    "authors": [
      "Weidong Luo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2201.04712",
    "title": "Deep Learning on Multimodal Sensor Data at the Wireless Edge for  Vehicular Network",
    "abstract": "Beam selection for millimeter-wave links in a vehicular scenario is a challenging problem, as an exhaustive search among all candidate beam pairs cannot be assuredly completed within short contact times. We solve this problem via a novel expediting beam selection by leveraging multimodal data collected from sensors like LiDAR, camera images, and GPS. We propose individual modality and distributed fusion-based deep learning (F-DL) architectures that can execute locally as well as at a mobile edge computing center (MEC), with a study on associated tradeoffs. We also formulate and solve an optimization problem that considers practical beam-searching, MEC processing and sensor-to-MEC data delivery latency overheads for determining the output dimensions of the above F-DL architectures. Results from extensive evaluations conducted on publicly available synthetic and home-grown real-world datasets reveal 95% and 96% improvement in beam selection speed over classical RF-only beam sweeping, respectively. F-DL also outperforms the state-of-the-art techniques by 20-22% in predicting top-10 best beam pairs. ",
    "url": "https://arxiv.org/abs/2201.04712",
    "authors": [
      "Batool Salehi",
      "Guillem Reus-Muns",
      "Debashri Roy",
      "Zifeng Wang",
      "Tong Jian",
      "Jennifer Dy",
      "Stratis Ioannidis",
      "Kaushik Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.04728",
    "title": "Quasi-Framelets: Another Improvement to GraphNeural Networks",
    "abstract": "This paper aims to provide a novel design of a multiscale framelets convolution for spectral graph neural networks. In the spectral paradigm, spectral GNNs improve graph learning task performance via proposing various spectral filters in spectral domain to capture both global and local graph structure information. Although the existing spectral approaches show superior performance in some graphs, they suffer from lack of flexibility and being fragile when graph information are incomplete or perturbated. Our new framelets convolution incorporates the filtering func-tions directly designed in the spectral domain to overcome these limitations. The proposed convolution shows a great flexibility in cutting-off spectral information and effectively mitigate the negative effect of noisy graph signals. Besides, to exploit the heterogeneity in real-world graph data, the heterogeneous graph neural network with our new framelet convolution provides a solution for embedding the intrinsic topological information of meta-path with a multi-level graph analysis.Extensive experiments have been conducted on real-world heterogeneous graphs and homogeneous graphs under settings with noisy node features and superior performance results are achieved. ",
    "url": "https://arxiv.org/abs/2201.04728",
    "authors": [
      "Mengxi Yang",
      "Xuebin Zheng",
      "Jie Yin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.04729",
    "title": "Local2Global: A distributed approach for scaling representation learning  on graphs",
    "abstract": "We propose a decentralised \"local2global\"' approach to graph representation learning, that one can a-priori use to scale any embedding technique. Our local2global approach proceeds by first dividing the input graph into overlapping subgraphs (or \"patches\") and training local representations for each patch independently. In a second step, we combine the local representations into a globally consistent representation by estimating the set of rigid motions that best align the local representations using information from the patch overlaps, via group synchronization. A key distinguishing feature of local2global relative to existing work is that patches are trained independently without the need for the often costly parameter synchronization during distributed training. This allows local2global to scale to large-scale industrial applications, where the input graph may not even fit into memory and may be stored in a distributed manner. We apply local2global on data sets of different sizes and show that our approach achieves a good trade-off between scale and accuracy on edge reconstruction and semi-supervised classification. We also consider the downstream task of anomaly detection and show how one can use local2global to highlight anomalies in cybersecurity networks. ",
    "url": "https://arxiv.org/abs/2201.04729",
    "authors": [
      "Lucas G. S. Jeub",
      "Giovanni Colavizza",
      "Xiaowen Dong",
      "Marya Bazzi",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04733",
    "title": "Adversarially Robust Classification by Conditional Generative Model  Inversion",
    "abstract": "Most adversarial attack defense methods rely on obfuscating gradients. These methods are successful in defending against gradient-based attacks; however, they are easily circumvented by attacks which either do not use the gradient or by attacks which approximate and use the corrected gradient. Defenses that do not obfuscate gradients such as adversarial training exist, but these approaches generally make assumptions about the attack such as its magnitude. We propose a classification model that does not obfuscate gradients and is robust by construction without assuming prior knowledge about the attack. Our method casts classification as an optimization problem where we \"invert\" a conditional generator trained on unperturbed, natural images to find the class that generates the closest sample to the query image. We hypothesize that a potential source of brittleness against adversarial attacks is the high-to-low-dimensional nature of feed-forward classifiers which allows an adversary to find small perturbations in the input space that lead to large changes in the output space. On the other hand, a generative model is typically a low-to-high-dimensional mapping. While the method is related to Defense-GAN, the use of a conditional generative model and inversion in our model instead of the feed-forward classifier is a critical difference. Unlike Defense-GAN, which was shown to generate obfuscated gradients that are easily circumvented, we show that our method does not obfuscate gradients. We demonstrate that our model is extremely robust against black-box attacks and has improved robustness against white-box attacks compared to naturally trained, feed-forward classifiers. ",
    "url": "https://arxiv.org/abs/2201.04733",
    "authors": [
      "Mitra Alirezaei",
      "Tolga Tasdizen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04746",
    "title": "An Overview of Uncertainty Quantification Methods for Infinite Neural  Networks",
    "abstract": "To better understand the theoretical behavior of large neural networks, several works have analyzed the case where a network's width tends to infinity. In this regime, the effect of random initialization and the process of training a neural network can be formally expressed with analytical tools like Gaussian processes and neural tangent kernels. In this paper, we review methods for quantifying uncertainty in such infinite-width neural networks and compare their relationship to Gaussian processes in the Bayesian inference framework. We make use of several equivalence results along the way to obtain exact closed-form solutions for predictive uncertainty. ",
    "url": "https://arxiv.org/abs/2201.04746",
    "authors": [
      "Florian Juengermann",
      "Maxime Laasri",
      "Marius Merkle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04755",
    "title": "Spatial-Temporal Map Vehicle Trajectory Detection Using Dynamic Mode  Decomposition and Res-UNet+ Neural Networks",
    "abstract": "This paper presents a machine-learning-enhanced longitudinal scanline method to extract vehicle trajectories from high-angle traffic cameras. The Dynamic Mode Decomposition (DMD) method is applied to extract vehicle strands by decomposing the Spatial-Temporal Map (STMap) into the sparse foreground and low-rank background. A deep neural network named Res-UNet+ was designed for the semantic segmentation task by adapting two prevalent deep learning architectures. The Res-UNet+ neural networks significantly improve the performance of the STMap-based vehicle detection, and the DMD model provides many interesting insights for understanding the evolution of underlying spatial-temporal structures preserved by STMap. The model outputs were compared with the previous image processing model and mainstream semantic segmentation deep neural networks. After a thorough evaluation, the model is proved to be accurate and robust against many challenging factors. Last but not least, this paper fundamentally addressed many quality issues found in NGSIM trajectory data. The cleaned high-quality trajectory data are published to support future theoretical and modeling research on traffic flow and microscopic vehicle control. This method is a reliable solution for video-based trajectory extraction and has wide applicability. ",
    "url": "https://arxiv.org/abs/2201.04755",
    "authors": [
      "Tianya T. Zhang",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04756",
    "title": "Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction",
    "abstract": "In this paper, we present the solution of roadside LiDAR object detection using a combination of two unsupervised learning algorithms. The 3D point clouds data are firstly converted into spherical coordinates and filled into the azimuth grid matrix using a hash function. After that, the raw LiDAR data were rearranged into spatial-temporal data structures to store the information of range, azimuth, and intensity. Dynamic Mode Decomposition method is applied for decomposing the point cloud data into low-rank backgrounds and sparse foregrounds based on intensity channel pattern recognition. The Triangle Algorithm automatically finds the dividing value to separate the moving targets from static background according to range information. After intensity and range background subtraction, the foreground moving objects will be detected using a density-based detector and encoded into the state-space model for tracking. The output of the proposed model includes vehicle trajectories that can enable many mobility and safety applications. The method was validated against a commercial traffic data collection platform and demonstrated to be an efficient and reliable solution for infrastructure LiDAR object detection. In contrast to the previous methods that process directly on the scattered and discrete point clouds, the proposed method can establish the less sophisticated linear relationship of the 3D measurement data, which captures the spatial-temporal structure that we often desire. ",
    "url": "https://arxiv.org/abs/2201.04756",
    "authors": [
      "Tianya Zhang",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.04762",
    "title": "Privacy Amplification by Subsampling in Time Domain",
    "abstract": "Aggregate time-series data like traffic flow and site occupancy repeatedly sample statistics from a population across time. Such data can be profoundly useful for understanding trends within a given population, but also pose a significant privacy risk, potentially revealing e.g., who spends time where. Producing a private version of a time-series satisfying the standard definition of Differential Privacy (DP) is challenging due to the large influence a single participant can have on the sequence: if an individual can contribute to each time step, the amount of additive noise needed to satisfy privacy increases linearly with the number of time steps sampled. As such, if a signal spans a long duration or is oversampled, an excessive amount of noise must be added, drowning out underlying trends. However, in many applications an individual realistically cannot participate at every time step. When this is the case, we observe that the influence of a single participant (sensitivity) can be reduced by subsampling and/or filtering in time, while still meeting privacy requirements. Using a novel analysis, we show this significant reduction in sensitivity and propose a corresponding class of privacy mechanisms. We demonstrate the utility benefits of these techniques empirically with real-world and synthetic time-series data. ",
    "url": "https://arxiv.org/abs/2201.04762",
    "authors": [
      "Tatsuki Koga",
      "Casey Meehan",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04770",
    "title": "Certifiable Robustness for Nearest Neighbor Classifiers",
    "abstract": "ML models are typically trained using large datasets of high quality. However, training datasets often contain inconsistent or incomplete data. To tackle this issue, one solution is to develop algorithms that can check whether a prediction of a model is certifiably robust. Given a learning algorithm that produces a classifier and given an example at test time, a classification outcome is certifiably robust if it is predicted by every model trained across all possible worlds (repairs) of the uncertain (inconsistent) dataset. This notion of robustness falls naturally under the framework of certain answers. In this paper, we study the complexity of certifying robustness for a simple but widely deployed classification algorithm, $k$-Nearest Neighbors ($k$-NN). Our main focus is on inconsistent datasets when the integrity constraints are functional dependencies (FDs). For this setting, we establish a dichotomy in the complexity of certifying robustness w.r.t. the set of FDs: the problem either admits a polynomial time algorithm, or it is coNP-hard. Additionally, we exhibit a similar dichotomy for the counting version of the problem, where the goal is to count the number of possible worlds that predict a certain label. As a byproduct of our study, we also establish the complexity of a problem related to finding an optimal subset repair that may be of independent interest. ",
    "url": "https://arxiv.org/abs/2201.04770",
    "authors": [
      "Austen Z. Fan",
      "Paraschos Koutris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2201.04777",
    "title": "A Survey on Masked Facial Detection Methods and Datasets for Fighting  Against COVID-19",
    "abstract": "Coronavirus disease 2019 (COVID-19) continues to pose a great challenge to the world since its outbreak. To fight against the disease, a series of artificial intelligence (AI) techniques are developed and applied to real-world scenarios such as safety monitoring, disease diagnosis, infection risk assessment, lesion segmentation of COVID-19 CT scans,etc. The coronavirus epidemics have forced people wear masks to counteract the transmission of virus, which also brings difficulties to monitor large groups of people wearing masks. In this paper, we primarily focus on the AI techniques of masked facial detection and related datasets. We survey the recent advances, beginning with the descriptions of masked facial detection datasets. Thirteen available datasets are described and discussed in details. Then, the methods are roughly categorized into two classes: conventional methods and neural network-based methods. Conventional methods are usually trained by boosting algorithms with hand-crafted features, which accounts for a small proportion. Neural network-based methods are further classified as three parts according to the number of processing stages. Representative algorithms are described in detail, coupled with some typical techniques that are described briefly. Finally, we summarize the recent benchmarking results, give the discussions on the limitations of datasets and methods, and expand future research directions. To our knowledge, this is the first survey about masked facial detection methods and datasets. Hopefully our survey could provide some help to fight against epidemics. ",
    "url": "https://arxiv.org/abs/2201.04777",
    "authors": [
      "Bingshu Wang",
      "Jiangbin Zheng",
      "C.L. Philip Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04781",
    "title": "Recursive Least Squares Policy Control with Echo State Network",
    "abstract": "The echo state network (ESN) is a special type of recurrent neural networks for processing the time-series dataset. However, limited by the strong correlation among sequential samples of the agent, ESN-based policy control algorithms are difficult to use the recursive least squares (RLS) algorithm to update the ESN's parameters. To solve this problem, we propose two novel policy control algorithms, ESNRLS-Q and ESNRLS-Sarsa. Firstly, to reduce the correlation of training samples, we use the leaky integrator ESN and the mini-batch learning mode. Secondly, to make RLS suitable for training ESN in mini-batch mode, we present a new mean-approximation method for updating the RLS correlation matrix. Thirdly, to prevent ESN from over-fitting, we use the L1 regularization technique. Lastly, to prevent the target state-action value from overestimation, we employ the Mellowmax method. Simulation results show that our algorithms have good convergence performance. ",
    "url": "https://arxiv.org/abs/2201.04781",
    "authors": [
      "Chunyuan Zhang",
      "Chao Liu",
      "Qi Song",
      "Jie Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04792",
    "title": "Forecast-based Multi-aspect Framework for Multivariate Time-series  Anomaly Detection",
    "abstract": "Today's cyber-world is vastly multivariate. Metrics collected at extreme varieties demand multivariate algorithms to properly detect anomalies. However, forecast-based algorithms, as widely proven approaches, often perform sub-optimally or inconsistently across datasets. A key common issue is they strive to be one-size-fits-all but anomalies are distinctive in nature. We propose a method that tailors to such distinction. Presenting FMUAD - a Forecast-based, Multi-aspect, Unsupervised Anomaly Detection framework. FMUAD explicitly and separately captures the signature traits of anomaly types - spatial change, temporal change and correlation change - with independent modules. The modules then jointly learn an optimal feature representation, which is highly flexible and intuitive, unlike most other models in the category. Extensive experiments show our FMUAD framework consistently outperforms other state-of-the-art forecast-based anomaly detectors. ",
    "url": "https://arxiv.org/abs/2201.04792",
    "authors": [
      "Lan Wang",
      "Yusan Lin",
      "Yuhang Wu",
      "Huiyuan Chen",
      "Fei Wang",
      "Hao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04797",
    "title": "Scalable Cluster-Consistency Statistics for Robust Multi-Object Matching",
    "abstract": "We develop new statistics for robustly filtering corrupted keypoint matches in the structure from motion pipeline. The statistics are based on consistency constraints that arise within the clustered structure of the graph of keypoint matches. The statistics are designed to give smaller values to corrupted matches and than uncorrupted matches. These new statistics are combined with an iterative reweighting scheme to filter keypoints, which can then be fed into any standard structure from motion pipeline. This filtering method can be efficiently implemented and scaled to massive datasets as it only requires sparse matrix multiplication. We demonstrate the efficacy of this method on synthetic and real structure from motion datasets and show that it achieves state-of-the-art accuracy and speed in these tasks. ",
    "url": "https://arxiv.org/abs/2201.04797",
    "authors": [
      "Yunpeng Shi",
      "Shaohan Li",
      "Tyler Maunu",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04803",
    "title": "A Comprehensive Survey on the Applications of Blockchain for Securing  Vehicular Networks",
    "abstract": "Vehicular networks promise features such as traffic management, route scheduling, data exchange, entertainment, and much more. With any large-scale technological integration comes the challenge of providing security. Blockchain technology has been a popular choice of many studies for making the vehicular network more secure. Its characteristics meet some of the essential security requirements such as decentralization, transparency, tamper-proof nature, and public audit. This study catalogues some of the notable efforts in this direction over the last few years. We analyze around 75 blockchain-based security schemes for vehicular networks from an application, security, and blockchain perspective. The application perspective focuses on various applications which use secure blockchain-based vehicular networks such as transportation, parking, data sharing/ trading, and resource sharing. The security perspective focuses on security requirements and attacks. The blockchain perspective focuses on blockchain platforms, blockchain types, and consensus mechanisms used in blockchain implementation. We also compile the popular simulation tools used for simulating blockchain and for simulating vehicular networks. Additionally, to give the readers a broader perspective of the research area, we discuss the role of various state-of-the-art emerging technologies in blockchain-based vehicular networks. Lastly, we summarize the survey by listing out some common challenges and the future research directions in this field. ",
    "url": "https://arxiv.org/abs/2201.04803",
    "authors": [
      "Tejasvi Alladi",
      "Vinay Chamola",
      "Nishad Sahu",
      "Vishnu Venkatesh",
      "Adit Goyal",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.04805",
    "title": "Non-Stationary Representation Learning in Sequential Linear Bandits",
    "abstract": "In this paper, we study representation learning for multi-task decision-making in non-stationary environments. We consider the framework of sequential linear bandits, where the agent performs a series of tasks drawn from distinct sets associated with different environments. The embeddings of tasks in each set share a low-dimensional feature extractor called representation, and representations are different across sets. We propose an online algorithm that facilitates efficient decision-making by learning and transferring non-stationary representations in an adaptive fashion. We prove that our algorithm significantly outperforms the existing ones that treat tasks independently. We also conduct experiments using both synthetic and real data to validate our theoretical insights and demonstrate the efficacy of our algorithm. ",
    "url": "https://arxiv.org/abs/2201.04805",
    "authors": [
      "Yuzhen Qin",
      "Tommaso Menara",
      "Samet Oymak",
      "ShiNung Ching",
      "Fabio Pasqualetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.04809",
    "title": "Conditional Variational Autoencoder with Balanced Pre-training for  Generative Adversarial Networks",
    "abstract": "Class imbalance occurs in many real-world applications, including image classification, where the number of images in each class differs significantly. With imbalanced data, the generative adversarial networks (GANs) leans to majority class samples. The two recent methods, Balancing GAN (BAGAN) and improved BAGAN (BAGAN-GP), are proposed as an augmentation tool to handle this problem and restore the balance to the data. The former pre-trains the autoencoder weights in an unsupervised manner. However, it is unstable when the images from different categories have similar features. The latter is improved based on BAGAN by facilitating supervised autoencoder training, but the pre-training is biased towards the majority classes. In this work, we propose a novel Conditional Variational Autoencoder with Balanced Pre-training for Generative Adversarial Networks (CAPGAN) as an augmentation tool to generate realistic synthetic images. In particular, we utilize a conditional convolutional variational autoencoder with supervised and balanced pre-training for the GAN initialization and training with gradient penalty. Our proposed method presents a superior performance of other state-of-the-art methods on the highly imbalanced version of MNIST, Fashion-MNIST, CIFAR-10, and two medical imaging datasets. Our method can synthesize high-quality minority samples in terms of Fr\\'echet inception distance, structural similarity index measure and perceptual quality. ",
    "url": "https://arxiv.org/abs/2201.04809",
    "authors": [
      "Yuchong Yao",
      "Xiaohui Wangr",
      "Yuanbang Ma",
      "Han Fang",
      "Jiaying Wei",
      "Liyuan Chen",
      "Ali Anaissi",
      "Ali Braytee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.04813",
    "title": "Recursive Least Squares for Training and Pruning Convolutional Neural  Networks",
    "abstract": "Convolutional neural networks (CNNs) have succeeded in many practical applications. However, their high computation and storage requirements often make them difficult to deploy on resource-constrained devices. In order to tackle this issue, many pruning algorithms have been proposed for CNNs, but most of them can't prune CNNs to a reasonable level. In this paper, we propose a novel algorithm for training and pruning CNNs based on the recursive least squares (RLS) optimization. After training a CNN for some epochs, our algorithm combines inverse input autocorrelation matrices and weight matrices to evaluate and prune unimportant input channels or nodes layer by layer. Then, our algorithm will continue to train the pruned network, and won't do the next pruning until the pruned network recovers the full performance of the old network. Besides for CNNs, the proposed algorithm can be used for feedforward neural networks (FNNs). Three experiments on MNIST, CIFAR-10 and SVHN datasets show that our algorithm can achieve the more reasonable pruning and have higher learning efficiency than other four popular pruning algorithms. ",
    "url": "https://arxiv.org/abs/2201.04813",
    "authors": [
      "Tianzong Yu",
      "Chunyuan Zhang",
      "Yuan Wang",
      "Meng Ma",
      "Qi Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04818",
    "title": "Convolutional dual graph Laplacian sparse coding",
    "abstract": "In recent years, graph signal processing (GSP) technology has become popular in various fields, and graph Laplacian regularizers have also been introduced into convolutional sparse representation. This paper proposes a convolutional sparse representation model based on the dual graph Laplacian regularizer to ensure effective application of a dual graph signal smoothing prior on the rows and columns of input images.The graph Laplacian matrix contains the gradient information of the image and the similarity information between pixels, and can also describe the degree of change of the graph, so the image can be smoothed. Compared with the single graph smoothing prior, the dual graph has a simple structure, relaxes the conditions, and is more conducive to image restoration using the image signal prior. In this paper, this paper formulated the corresponding minimization problem using the proposed model, and subsequently used the alternating direction method of multiplication (ADMM) algorithm to solve it in the Fourier domain.Finally, using random Gaussian white noise for the denoising experiments. Compared with the single graph smoothing prior,the denoising results of the model with dual graph smoothing prior proposed in this paper has fewer noise points and clearer texture. ",
    "url": "https://arxiv.org/abs/2201.04818",
    "authors": [
      "Xuefeng Peng",
      "Fei Chen",
      "Hang Cheng",
      "Meiqing Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2201.04819",
    "title": "S$^2$FPR: Crowd Counting via Self-Supervised Coarse to Fine Feature  Pyramid Ranking",
    "abstract": "Most conventional crowd counting methods utilize a fully-supervised learning framework to learn a mapping between scene images and crowd density maps. Under the circumstances of such fully-supervised training settings, a large quantity of expensive and time-consuming pixel-level annotations are required to generate density maps as the supervision. One way to reduce costly labeling is to exploit self-structural information and inner-relations among unlabeled images. Unlike the previous methods utilizing these relations and structural information from the original image level, we explore such self-relations from the latent feature spaces because it can extract more abundant relations and structural information. Specifically, we propose S$^2$FPR which can extract structural information and learn partial orders of coarse-to-fine pyramid features in the latent space for better crowd counting with massive unlabeled images. In addition, we collect a new unlabeled crowd counting dataset (FUDAN-UCC) with 4,000 images in total for training. One by-product is that our proposed S$^2$FPR method can leverage numerous partial orders in the latent space among unlabeled images to strengthen the model representation capability and reduce the estimation errors for the crowd counting task. Extensive experiments on four benchmark datasets, i.e. the UCF-QNRF, the ShanghaiTech PartA and PartB, and the UCF-CC-50, show the effectiveness of our method compared with previous semi-supervised methods. The source code and dataset are available at https://github.com/bridgeqiqi/S2FPR. ",
    "url": "https://arxiv.org/abs/2201.04819",
    "authors": [
      "Jiaqi Gao",
      "Zhizhong Huang",
      "Yiming Lei",
      "James Z. Wang",
      "Fei-Yue Wang",
      "Junping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04828",
    "title": "Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series  Forecasting",
    "abstract": "Multivariate time series (MTS) forecasting plays an important role in the automation and optimization of intelligent applications. It is a challenging task, as we need to consider both complex intra-variable dependencies and inter-variable dependencies. Existing works only learn temporal patterns with the help of single inter-variable dependencies. However, there are multi-scale temporal patterns in many real-world MTS. Single inter-variable dependencies make the model prefer to learn one type of prominent and shared temporal patterns. In this paper, we propose a multi-scale adaptive graph neural network (MAGNN) to address the above issue. MAGNN exploits a multi-scale pyramid network to preserve the underlying temporal dependencies at different time scales. Since the inter-variable dependencies may be different under distinct time scales, an adaptive graph learning module is designed to infer the scale-specific inter-variable dependencies without pre-defined priors. Given the multi-scale feature representations and scale-specific inter-variable dependencies, a multi-scale temporal graph neural network is introduced to jointly model intra-variable dependencies and inter-variable dependencies. After that, we develop a scale-wise fusion module to effectively promote the collaboration across different time scales, and automatically capture the importance of contributed temporal patterns. Experiments on four real-world datasets demonstrate that MAGNN outperforms the state-of-the-art methods across various settings. ",
    "url": "https://arxiv.org/abs/2201.04828",
    "authors": [
      "Ling Chen",
      "Donghui Chen",
      "Zongjiang Shang",
      "Youdong Zhang",
      "Bo Wen",
      "Chenghu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04830",
    "title": "Experimental Design Networks: A Paradigm for Serving Heterogeneous  Learners under Networking Constraints",
    "abstract": "Significant advances in edge computing capabilities enable learning to occur at geographically diverse locations. In general, the training data needed in those learning tasks are not only heterogeneous but also not fully generated locally. In this paper, we propose an experimental design network paradigm, wherein learner nodes train possibly different Bayesian linear regression models via consuming data streams generated by data source nodes over a network. We formulate this problem as a social welfare optimization problem in which the global objective is defined as the sum of experimental design objectives of individual learners, and the decision variables are the data transmission strategies subject to network constraints. We first show that, assuming Poisson data streams, the global objective is a continuous DR-submodular function. We then propose a Frank-Wolfe type algorithm that outputs a solution within a 1-1/e factor from the optimal. Our algorithm contains a novel gradient estimation component which is carefully designed based on Poisson tail bounds and sampling. Finally, we complement our theoretical findings through extensive experiments. Our numerical evaluation shows that the proposed algorithm outperforms several baseline algorithms both in maximizing the global objective and in the quality of the trained models. ",
    "url": "https://arxiv.org/abs/2201.04830",
    "authors": [
      "Yuezhou Liu",
      "Yuanyuan Li",
      "Lili Su",
      "Edmund Yeh",
      "Stratis Ioannidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.04831",
    "title": "Knowledge Graph Augmented Network Towards Multiview Representation  Learning for Aspect-based Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained task of sentiment analysis. To better comprehend long complicated sentences and obtain accurate aspect-specific information, linguistic and commonsense knowledge are generally required in this task. However, most methods employ complicated and inefficient approaches to incorporate external knowledge, e.g., directly searching the graph nodes. Additionally, the complementarity between external knowledge and linguistic information has not been thoroughly studied. To this end, we propose a knowledge graph augmented network (KGAN), which aims to effectively incorporate external knowledge with explicitly syntactic and contextual information. In particular, KGAN captures the sentiment feature representations from multiple different perspectives, i.e., context-, syntax- and knowledge-based. First, KGAN learns the contextual and syntactic representations in parallel to fully extract the semantic features. Then, KGAN integrates the knowledge graphs into the embedding space, based on which the aspect-specific knowledge representations are further obtained via an attention mechanism. Last, we propose a hierarchical fusion module to complement these multiview representations in a local-to-global manner. Extensive experiments on three popular ABSA benchmarks demonstrate the effectiveness and robustness of our KGAN. Notably, with the help of the pretrained model of RoBERTa, KGAN achieves a new record of state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2201.04831",
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Juhua Liu",
      "Bo Du",
      "Hua Jin",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04833",
    "title": "SnapshotNet: Self-supervised Feature Learning for Point Cloud Data  Segmentation Using Minimal Labeled Data",
    "abstract": "Manually annotating complex scene point cloud datasets is both costly and error-prone. To reduce the reliance on labeled data, a new model called SnapshotNet is proposed as a self-supervised feature learning approach, which directly works on the unlabeled point cloud data of a complex 3D scene. The SnapshotNet pipeline includes three stages. In the snapshot capturing stage, snapshots, which are defined as local collections of points, are sampled from the point cloud scene. A snapshot could be a view of a local 3D scan directly captured from the real scene, or a virtual view of such from a large 3D point cloud dataset. Snapshots could also be sampled at different sampling rates or fields of view (FOVs), thus multi-FOV snapshots, to capture scale information from the scene. In the feature learning stage, a new pre-text task called multi-FOV contrasting is proposed to recognize whether two snapshots are from the same object or not, within the same FOV or across different FOVs. Snapshots go through two self-supervised learning steps: the contrastive learning step with both part and scale contrasting, followed by a snapshot clustering step to extract higher level semantic features. Then a weakly-supervised segmentation stage is implemented by first training a standard SVM classifier on the learned features with a small fraction of labeled snapshots. The trained SVM is used to predict labels for input snapshots and predicted labels are converted into point-wise label assignments for semantic segmentation of the entire scene using a voting procedure. The experiments are conducted on the Semantic3D dataset and the results have shown that the proposed method is capable of learning effective features from snapshots of complex scene data without any labels. Moreover, the proposed method has shown advantages when comparing to the SOA method on weakly-supervised point cloud semantic segmentation. ",
    "url": "https://arxiv.org/abs/2201.04833",
    "authors": [
      "Xingye Li",
      "Ling Zhang",
      "Zhigang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04841",
    "title": "Transforming UNL graphs in OWL representations",
    "abstract": "Extracting formal knowledge (ontologies) from natural language is a challenge that can benefit from a (semi-) formal linguistic representation of texts, at the semantic level. We propose to achieve such a representation by implementing the Universal Networking Language (UNL) specifications on top of RDF. Thus, the meaning of a statement in any language will be soundly expressed as a RDF-UNL graph that constitutes a middle ground between natural language and formal knowledge. In particular, we show that RDF-UNL graphs can support content extraction using generic SHACL rules and that reasoning on the extracted facts allows detecting incoherence in the original texts. This approach is experimented in the UNseL project that aims at extracting ontological representations from system requirements/specifications in order to check that they are consistent, complete and unambiguous. Our RDF-UNL implementation and all code for the working examples of this paper are publicly available under the CeCILL-B license at https://gitlab.tetras-libre.fr/unl/rdf-unl ",
    "url": "https://arxiv.org/abs/2201.04841",
    "authors": [
      "David Rouquet",
      "Val\u00e9rie Bellynck",
      "Christian Boitet",
      "Vincent Berment"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04843",
    "title": "LP-BERT: Multi-task Pre-training Knowledge Graph BERT for Link  Prediction",
    "abstract": "Link prediction plays an significant role in knowledge graph, which is an important resource for many artificial intelligence tasks, but it is often limited by incompleteness. In this paper, we propose knowledge graph BERT for link prediction, named LP-BERT, which contains two training stages: multi-task pre-training and knowledge graph fine-tuning. The pre-training strategy not only uses Mask Language Model (MLM) to learn the knowledge of context corpus, but also introduces Mask Entity Model (MEM) and Mask Relation Model (MRM), which can learn the relationship information from triples by predicting semantic based entity and relation elements. Structured triple relation information can be transformed into unstructured semantic information, which can be integrated into the pre-training model together with context corpus information. In the fine-tuning phase, inspired by contrastive learning, we carry out a triple-style negative sampling in sample batch, which greatly increased the proportion of negative sampling while keeping the training time almost unchanged. Furthermore, we propose a data augmentation method based on the inverse relationship of triples to further increase the sample diversity. We achieve state-of-the-art results on WN18RR and UMLS datasets, especially the Hits@10 indicator improved by 5\\% from the previous state-of-the-art result on WN18RR dataset. ",
    "url": "https://arxiv.org/abs/2201.04843",
    "authors": [
      "Da Li",
      "Ming Yi",
      "Yukai He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04853",
    "title": "FuzzingDriver: the Missing Dictionary to Increase Code Coverage in  Fuzzers",
    "abstract": "We propose a tool, called FuzzingDriver, to generate dictionary tokens for coverage-based greybox fuzzers (CGF) from the codebase of any target program. FuzzingDriver does not add any overhead to the fuzzing job as it is run beforehand. We compared FuzzingDriver to Google dictionaries by fuzzing six open-source targets, and we found that FuzzingDriver consistently achieves higher code coverage in all tests. We also executed eight benchmarks on FuzzBench to demonstrate how utilizing FuzzingDriver's dictionaries can outperform six widely-used CGF fuzzers. In future work, investigating the impact of FuzzingDriver's dictionaries on improving bug coverage might prove important. Video demonstration: https://www.youtube.com/watch?v=Y8j_KvfRrI8 ",
    "url": "https://arxiv.org/abs/2201.04853",
    "authors": [
      "Arash Ale Ebrahim",
      "Mohammadreza Hazhirpasand",
      "Oscar Nierstrasz",
      "Mohammad Ghafari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.04866",
    "title": "Weakly Supervised Scene Text Detection using Deep Reinforcement Learning",
    "abstract": "The challenging field of scene text detection requires complex data annotation, which is time-consuming and expensive. Techniques, such as weak supervision, can reduce the amount of data needed. In this paper we propose a weak supervision method for scene text detection, which makes use of reinforcement learning (RL). The reward received by the RL agent is estimated by a neural network, instead of being inferred from ground-truth labels. First, we enhance an existing supervised RL approach to text detection with several training optimizations, allowing us to close the performance gap to regression-based algorithms. We then use our proposed system in a weakly- and semi-supervised training on real-world data. Our results show that training in a weakly supervised setting is feasible. However, we find that using our model in a semi-supervised setting , e.g. when combining labeled synthetic data with unannotated real-world data, produces the best results. ",
    "url": "https://arxiv.org/abs/2201.04866",
    "authors": [
      "Emanuel Metzenthin",
      "Christian Bartz",
      "Christoph Meinel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04883",
    "title": "Ontological model identification based on data from heterogeneous  sources",
    "abstract": "The development of a company often entails the emergence of autonomous data sources with different structural and technological organization. This can lead to the inability of data analysis at a high level and a violation of the integrity and reliability of data within the organization, hindering the adoption of high-quality decisions and further development of the company. This problem can be solved by implementing a higher abstraction, representing heterogeneous organization data in a single space by combining them into a single knowledge graph. We propose a framework capable of autonomous construction of an organization's knowledge graph based on semi-structured data from various sources by finding links between sources based on data with an arbitrary structure, and combining document collections into single entities. The results of tests show the applicability of the developed approach for constructing a knowledge graph based on partially-structured data from various sources and the high efficiency of the approach based on the metrics of completeness of data storage subsystems coverage (11 out of 11) and filtering false connections (there are only 2.5 connections of collections with neighbors on average in the final graph). ",
    "url": "https://arxiv.org/abs/2201.04883",
    "authors": [
      "A. Kalinin",
      "E. Shikov",
      "D. Vaganov",
      "A. Lysenko"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2201.04895",
    "title": "Solving Dynamic Graph Problems with Multi-Attention Deep Reinforcement  Learning",
    "abstract": "Graph problems such as traveling salesman problem, or finding minimal Steiner trees are widely studied and used in data engineering and computer science. Typically, in real-world applications, the features of the graph tend to change over time, thus, finding a solution to the problem becomes challenging. The dynamic version of many graph problems are the key for a plethora of real-world problems in transportation, telecommunication, and social networks. In recent years, using deep learning techniques to find heuristic solutions for NP-hard graph combinatorial problems has gained much interest as these learned heuristics can find near-optimal solutions efficiently. However, most of the existing methods for learning heuristics focus on static graph problems. The dynamic nature makes NP-hard graph problems much more challenging to learn, and the existing methods fail to find reasonable solutions. In this paper, we propose a novel architecture named Graph Temporal Attention with Reinforcement Learning (GTA-RL) to learn heuristic solutions for graph-based dynamic combinatorial optimization problems. The GTA-RL architecture consists of an encoder capable of embedding temporal features of a combinatorial problem instance and a decoder capable of dynamically focusing on the embedded features to find a solution to a given combinatorial problem instance. We then extend our architecture to learn heuristics for the real-time version of combinatorial optimization problems where all input features of a problem are not known a prior, but rather learned in real-time. Our experimental results against several state-of-the-art learning-based algorithms and optimal solvers demonstrate that our approach outperforms the state-of-the-art learning-based approaches in terms of effectiveness and optimal solvers in terms of efficiency on dynamic and real-time graph combinatorial optimization. ",
    "url": "https://arxiv.org/abs/2201.04895",
    "authors": [
      "Udesh Gunarathna",
      "Renata Borovica-Gajic",
      "Shanika Karunasekara",
      "Egemen Tanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04922",
    "title": "Uplink-Downlink Duality and Precoding Strategies with Partial CSI in  Cell-Free Wireless Networks",
    "abstract": "We consider a scalable user-centric wireless network with dynamic cluster formation as defined by Bj\\\"ornsson and Sanguinetti. After having shown the importance of dominant channel subspace information for uplink (UL) pilot decontamination and having examined different UL combining schemes in our previous work, here we investigate precoding strategies for the downlink (DL). Distributed scalable DL precoding and power allocation methods are evaluated for different antenna distributions, user densities and UL pilot dimensions. We compare distributed power allocation methods to a scheme based on a particular form of UL-DL duality which is computable by a central processor based on the available partial channel state information. The new duality method achieves almost symmetric \"optimistic ergodic rates\" for UL and DL while saving considerable computational complexity since the UL combining vectors are reused as DL precoders. ",
    "url": "https://arxiv.org/abs/2201.04922",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.04929",
    "title": "Improving VAE based molecular representations for compound property  prediction",
    "abstract": "Collecting labeled data for many important tasks in chemoinformatics is time consuming and requires expensive experiments. In recent years, machine learning has been used to learn rich representations of molecules using large scale unlabeled molecular datasets and transfer the knowledge to solve the more challenging tasks with limited datasets. Variational autoencoders are one of the tools that have been proposed to perform the transfer for both chemical property prediction and molecular generation tasks. In this work we propose a simple method to improve chemical property prediction performance of machine learning models by incorporating additional information on correlated molecular descriptors in the representations learned by variational autoencoders. We verify the method on three property prediction asks. We explore the impact of the number of incorporated descriptors, correlation between the descriptors and the target properties, sizes of the datasets etc. Finally, we show the relation between the performance of property prediction models and the distance between property prediction dataset and the larger unlabeled dataset in the representation space. ",
    "url": "https://arxiv.org/abs/2201.04929",
    "authors": [
      "A. Tevosyan",
      "L. Khondkaryan",
      "H. Khachatrian",
      "G. Tadevosyan",
      "L. Apresyan",
      "N. Babayan",
      "H. Stopper",
      "Z. Navoyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04952",
    "title": "REST: Debiased Social Recommendation via Reconstructing Exposure  Strategies",
    "abstract": "The recommendation system, relying on historical observational data to model the complex relationships among the users and items, has achieved great success in real-world applications. Selection bias is one of the most important issues of the existing observational data based approaches, which is actually caused by multiple types of unobserved exposure strategies (e.g. promotions and holiday effects). Though various methods have been proposed to address this problem, they are mainly relying on the implicit debiasing techniques but not explicitly modeling the unobserved exposure strategies. By explicitly Reconstructing Exposure STrategies (REST in short), we formalize the recommendation problem as the counterfactual reasoning and propose the debiased social recommendation method. In REST, we assume that the exposure of an item is controlled by the latent exposure strategies, the user, and the item. Based on the above generation process, we first provide the theoretical guarantee of our method via identification analysis. Second, we employ a variational auto-encoder to reconstruct the latent exposure strategies, with the help of the social networks and the items. Third, we devise a counterfactual reasoning based recommendation algorithm by leveraging the recovered exposure strategies. Experiments on four real-world datasets, including three published datasets and one private WeChat Official Account dataset, demonstrate significant improvements over several state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2201.04952",
    "authors": [
      "Ruichu Cai",
      "Fengzhu Wu",
      "Zijian Li",
      "Jie Qiao",
      "Wei Chen",
      "Yuexing Hao",
      "Hao Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04962",
    "title": "Distributed Cooperative Multi-Agent Reinforcement Learning with Directed  Coordination Graph",
    "abstract": "Existing distributed cooperative multi-agent reinforcement learning (MARL) frameworks usually assume undirected coordination graphs and communication graphs while estimating a global reward via consensus algorithms for policy evaluation. Such a framework may induce expensive communication costs and exhibit poor scalability due to requirement of global consensus. In this work, we study MARLs with directed coordination graphs, and propose a distributed RL algorithm where the local policy evaluations are based on local value functions. The local value function of each agent is obtained by local communication with its neighbors through a directed learning-induced communication graph, without using any consensus algorithm. A zeroth-order optimization (ZOO) approach based on parameter perturbation is employed to achieve gradient estimation. By comparing with existing ZOO-based RL algorithms, we show that our proposed distributed RL algorithm guarantees high scalability. A distributed resource allocation example is shown to illustrate the effectiveness of our algorithm. ",
    "url": "https://arxiv.org/abs/2201.04962",
    "authors": [
      "Gangshan Jing",
      "He Bai",
      "Jemin George",
      "Aranya Chakrabortty",
      "Piyush. K. Sharma"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.04968",
    "title": "On the Design of Graph Embeddings for the Sensorless Estimation of Road  Traffic Profiles",
    "abstract": "Traffic forecasting models rely on data that needs to be sensed, processed, and stored. This requires the deployment and maintenance of traffic sensing infrastructure, often leading to unaffordable monetary costs. The lack of sensed locations can be complemented with synthetic data simulations that further lower the economical investment needed for traffic monitoring. One of the most common data generative approaches consists of producing real-like traffic patterns, according to data distributions from analogous roads. The process of detecting roads with similar traffic is the key point of these systems. However, without collecting data at the target location no flow metrics can be employed for this similarity-based search. We present a method to discover locations among those with available traffic data by inspecting topological features of road segments. Relevant topological features are extracted as numerical representations (embeddings) to compare different locations and eventually find the most similar roads based on the similarity between their embeddings. The performance of this novel selection system is examined and compared to simpler traffic estimation approaches. After finding a similar source of data, a generative method is used to synthesize traffic profiles. Depending on the resemblance of the traffic behavior at the sensed road, the generation method can be fed with data from one road only. Several generation approaches are analyzed in terms of the precision of the synthesized samples. Above all, this work intends to stimulate further research efforts towards enhancing the quality of synthetic traffic samples and thereby, reducing the need for sensing infrastructure. ",
    "url": "https://arxiv.org/abs/2201.04968",
    "authors": [
      "Eric L. Manibardo",
      "Ibai La\u00f1a",
      "Esther Villar",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.05001",
    "title": "Evaluation of Four Black-box Adversarial Attacks and Some  Query-efficient Improvement Analysis",
    "abstract": "With the fast development of machine learning technologies, deep learning models have been deployed in almost every aspect of everyday life. However, the privacy and security of these models are threatened by adversarial attacks. Among which black-box attack is closer to reality, where limited knowledge can be acquired from the model. In this paper, we provided basic background knowledge about adversarial attack and analyzed four black-box attack algorithms: Bandits, NES, Square Attack and ZOsignSGD comprehensively. We also explored the newly proposed Square Attack method with respect to square size, hoping to improve its query efficiency. ",
    "url": "https://arxiv.org/abs/2201.05001",
    "authors": [
      "Rui Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05020",
    "title": "Automatic Sparse Connectivity Learning for Neural Networks",
    "abstract": "Since sparse neural networks usually contain many zero weights, these unnecessary network connections can potentially be eliminated without degrading network performance. Therefore, well-designed sparse neural networks have the potential to significantly reduce FLOPs and computational resources. In this work, we propose a new automatic pruning method - Sparse Connectivity Learning (SCL). Specifically, a weight is re-parameterized as an element-wise multiplication of a trainable weight variable and a binary mask. Thus, network connectivity is fully described by the binary mask, which is modulated by a unit step function. We theoretically prove the fundamental principle of using a straight-through estimator (STE) for network pruning. This principle is that the proxy gradients of STE should be positive, ensuring that mask variables converge at their minima. After finding Leaky ReLU, Softplus, and Identity STEs can satisfy this principle, we propose to adopt Identity STE in SCL for discrete mask relaxation. We find that mask gradients of different features are very unbalanced, hence, we propose to normalize mask gradients of each feature to optimize mask variable training. In order to automatically train sparse masks, we include the total number of network connections as a regularization term in our objective function. As SCL does not require pruning criteria or hyper-parameters defined by designers for network layers, the network is explored in a larger hypothesis space to achieve optimized sparse connectivity for the best performance. SCL overcomes the limitations of existing automatic pruning methods. Experimental results demonstrate that SCL can automatically learn and select important network connections for various baseline network structures. Deep learning models trained by SCL outperform the SOTA human-designed and automatic pruning methods in sparsity, accuracy, and FLOPs reduction. ",
    "url": "https://arxiv.org/abs/2201.05020",
    "authors": [
      "Zhimin Tang",
      "Linkai Luo",
      "Bike Xie",
      "Yiyu Zhu",
      "Rujie Zhao",
      "Lvqing Bi",
      "Chao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05021",
    "title": "Robustness against Read Committed for Transaction Templates with  Functional Constraints",
    "abstract": "The popular isolation level Multiversion Read Committed (RC) trades some of the strong guarantees of serializability for increased transaction throughput. Sometimes, transaction workloads can be safely executed under RC obtaining serializability at the lower cost of RC. Such workloads are said to be robust against RC. Previous work has yielded a tractable procedure for deciding robustness against RC for workloads generated by transaction programs modeled as transaction templates. An important insight of that work is that, by more accurately modeling transaction programs, we are able to recognize larger sets of workloads as robust. In this work, we increase the modeling power of transaction templates by extending them with functional constraints, which are useful for capturing data dependencies like foreign keys. We show that the incorporation of functional constraints can identify more workloads as robust that otherwise would not be. Even though we establish that the robustness problem becomes undecidable in its most general form, we show that various restrictions on functional constraints lead to decidable and even tractable fragments that can be used to model and test for robustness against RC for realistic scenarios. ",
    "url": "https://arxiv.org/abs/2201.05021",
    "authors": [
      "Brecht Vandevoort",
      "Bas Ketsman",
      "Christoph Koch",
      "Frank Neven"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2201.05046",
    "title": "Flood Prediction and Analysis on the Relevance of Features using  Explainable Artificial Intelligence",
    "abstract": "This paper presents flood prediction models for the state of Kerala in India by analyzing the monthly rainfall data and applying machine learning algorithms including Logistic Regression, K-Nearest Neighbors, Decision Trees, Random Forests, and Support Vector Machine. Although these models have shown high accuracy prediction of the occurrence of flood in a particular year, they do not quantitatively and qualitatively explain the prediction decision. This paper shows how the background features are learned that contributed to the prediction decision and further extended to explain the inner workings with the development of explainable artificial intelligence modules. The obtained results have confirmed the validity of the findings uncovered by the explainer modules basing on the historical flood monthly rainfall data in Kerala. ",
    "url": "https://arxiv.org/abs/2201.05046",
    "authors": [
      "Sai Prasanth Kadiyala",
      "Wai Lok Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05047",
    "title": "TransVOD: End-to-end Video Object Detection with Spatial-Temporal  Transformers",
    "abstract": "Detection Transformer (DETR) and Deformable DETR have been proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance as previous complex hand-crafted detectors. However, their performance on Video Object Detection (VOD) has not been well explored. In this paper, we present TransVOD, the first end-to-end video object detection system based on spatial-temporal Transformer architectures. The first goal of this paper is to streamline the pipeline of VOD, effectively removing the need for many hand-crafted components for feature aggregation, e.g., optical flow model, relation networks. Besides, benefited from the object query design in DETR, our method does not need complicated post-processing methods such as Seq-NMS. In particular, we present a temporal Transformer to aggregate both the spatial object queries and the feature memories of each frame. Our temporal transformer consists of two components: Temporal Query Encoder (TQE) to fuse object queries, and Temporal Deformable Transformer Decoder (TDTD) to obtain current frame detection results. These designs boost the strong baseline deformable DETR by a significant margin (3%-4% mAP) on the ImageNet VID dataset. Then, we present two improved versions of TransVOD including TransVOD++ and TransVOD Lite. The former fuses object-level information into object query via dynamic convolution while the latter models the entire video clips as the output to speed up the inference time. We give detailed analysis of all three models in the experiment part. In particular, our proposed TransVOD++ sets a new state-of-the-art record in terms of accuracy on ImageNet VID with 90.0% mAP. Our proposed TransVOD Lite also achieves the best speed and accuracy trade-off with 83.7% mAP while running at around 30 FPS on a single V100 GPU device. Code and models will be available for further research. ",
    "url": "https://arxiv.org/abs/2201.05047",
    "authors": [
      "Qianyu Zhou",
      "Xiangtai Li",
      "Lu He",
      "Yibo Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Lizhuang Ma",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05057",
    "title": "On Adversarial Robustness of Trajectory Prediction for Autonomous  Vehicles",
    "abstract": "Trajectory prediction is a critical component for autonomous vehicles (AVs) to perform safe planning and navigation. However, few studies have analyzed the adversarial robustness of trajectory prediction or investigated whether the worst-case prediction can still lead to safe planning. To bridge this gap, we study the adversarial robustness of trajectory prediction models by proposing a new adversarial attack that perturbs normal vehicle trajectories to maximize the prediction error. Our experiments on three models and three datasets show that the adversarial prediction increases the prediction error by more than 150%. Our case studies show that if an adversary drives a vehicle close to the target AV following the adversarial trajectory, the AV may make an inaccurate prediction and even make unsafe driving decisions. We also explore possible mitigation techniques via data augmentation and trajectory smoothing. ",
    "url": "https://arxiv.org/abs/2201.05057",
    "authors": [
      "Qingzhao Zhang",
      "Shengtuo Hu",
      "Jiachen Sun",
      "Qi Alfred Chen",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.05058",
    "title": "Motion Planning in Dynamic Environments Using Context-Aware Human  Trajectory Prediction",
    "abstract": "Over the years, the separate fields of motion planning, mapping, and human trajectory prediction have advanced considerably. However, the literature is still sparse in providing practical frameworks that enable mobile manipulators to perform whole-body movements and account for the predicted motion of moving obstacles. Previous optimisation-based motion planning approaches that use distance fields have suffered from the high computational cost required to update the environment representation. We demonstrate that GPU-accelerated predicted composite distance fields significantly reduce the computation time compared to calculating distance fields from scratch. We integrate this technique with a complete motion planning and perception framework that accounts for the predicted motion of humans in dynamic environments, enabling reactive and pre-emptive motion planning that incorporates predicted motions. To achieve this, we propose and implement a novel human trajectory prediction method that combines intention recognition with trajectory optimisation-based motion planning. We validate our resultant framework on a real-world Toyota Human Support Robot (HSR) using live RGB-D sensor data from the onboard camera. In addition to providing analysis on a publicly available dataset, we release the Oxford Indoor Human Motion (Oxford-IHM) dataset and demonstrate state-of-the-art performance in human trajectory prediction. The Oxford-IHM dataset is a human trajectory prediction dataset in which people walk between regions of interest in an indoor environment. Both static and robot-mounted RGB-D cameras observe the people while tracked with a motion-capture system. ",
    "url": "https://arxiv.org/abs/2201.05058",
    "authors": [
      "Mark Nicholas Finean",
      "Luka Petrovi\u0107",
      "Wolfgang Merkt",
      "Ivan Markovi\u0107",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.05061",
    "title": "Feature-rich multiplex lexical networks reveal mental strategies of  early language learning",
    "abstract": "Knowledge in the human mind exhibits a dualistic vector/network nature. Modelling words as vectors is key to natural language processing, whereas networks of word associations can map the nature of semantic memory. We reconcile these paradigms - fragmented across linguistics, psychology and computer science - by introducing FEature-Rich MUltiplex LEXical (FERMULEX) networks. This novel framework merges structural similarities in networks and vector features of words, which can be combined or explored independently. Similarities model heterogenous word associations across semantic/syntactic/phonological aspects of knowledge. Words are enriched with multi-dimensional feature embeddings including frequency, age of acquisition, length and polysemy. These aspects enable unprecedented explorations of cognitive knowledge. Through CHILDES data, we use FERMULEX networks to model normative language acquisition by 1000 toddlers between 18 and 30 months. Similarities and embeddings capture word homophily via conformity, which measures assortative mixing via distance and features. Conformity unearths a language kernel of frequent/polysemous/short nouns and verbs key for basic sentence production, supporting recent evidence of children's syntactic constructs emerging at 30 months. This kernel is invisible to network core-detection and feature-only clustering: It emerges from the dual vector/network nature of words. Our quantitative analysis reveals two key strategies in early word learning. Modelling word acquisition as random walks on FERMULEX topology, we highlight non-uniform filling of communicative developmental inventories (CDIs). Conformity-based walkers lead to accurate (75%), precise (55%) and partially well-recalled (34%) predictions of early word learning in CDIs, providing quantitative support to previous empirical findings and developmental theories. ",
    "url": "https://arxiv.org/abs/2201.05061",
    "authors": [
      "Salvatore Citraro",
      "Michael S. Vitevitch",
      "Massimo Stella",
      "Giulio Rossetti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.05071",
    "title": "Evaluation of Neural Networks Defenses and Attacks using NDCG and  Reciprocal Rank Metrics",
    "abstract": "The problem of attacks on neural networks through input modification (i.e., adversarial examples) has attracted much attention recently. Being relatively easy to generate and hard to detect, these attacks pose a security breach that many suggested defenses try to mitigate. However, the evaluation of the effect of attacks and defenses commonly relies on traditional classification metrics, without adequate adaptation to adversarial scenarios. Most of these metrics are accuracy-based, and therefore may have a limited scope and low distinctive power. Other metrics do not consider the unique characteristics of neural networks functionality, or measure the effect of the attacks indirectly (e.g., through the complexity of their generation). In this paper, we present two metrics which are specifically designed to measure the effect of attacks, or the recovery effect of defenses, on the output of neural networks in multiclass classification tasks. Inspired by the normalized discounted cumulative gain and the reciprocal rank metrics used in information retrieval literature, we treat the neural network predictions as ranked lists of results. Using additional information about the probability of the rank enabled us to define novel metrics that are suited to the task at hand. We evaluate our metrics using various attacks and defenses on a pretrained VGG19 model and the ImageNet dataset. Compared to the common classification metrics, our proposed metrics demonstrate superior informativeness and distinctiveness. ",
    "url": "https://arxiv.org/abs/2201.05071",
    "authors": [
      "Haya Brama",
      "Lihi Dery",
      "Tal Grinshpoun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.05098",
    "title": "Neural Koopman Lyapunov Control",
    "abstract": "Learning and synthesizing stabilizing controllers for unknown nonlinear systems is a challenging problem for real-world and industrial applications. Koopman operator theory allow one to analyze nonlinear systems through the lens of linear systems and nonlinear control systems through the lens of bilinear control systems. The key idea of these methods, lies in the transformation of the coordinates of the nonlinear system into the Koopman observables, which are coordinates that allow the representation of the original system (control system) as a higher dimensional linear (bilinear control) system. However, for nonlinear control systems, the bilinear control model obtained by applying Koopman operator based learning methods is not necessarily stabilizable and therefore, the existence of a stabilizing feedback control is not guaranteed which is crucial for many real world applications. Simultaneous identification of these stabilizable Koopman based bilinear control systems as well as the associated Koopman observables is still an open problem. In this paper, we propose a framework to identify and construct these stabilizable bilinear models and its associated observables from data by simultaneously learning a bilinear Koopman embedding for the underlying unknown nonlinear control system as well as a Control Lyapunov Function (CLF) for the Koopman based bilinear model using a learner and falsifier. Our proposed approach thereby provides provable guarantees of global asymptotic stability for the nonlinear control systems with unknown dynamics. Numerical simulations are provided to validate the efficacy of our proposed class of stabilizing feedback controllers for unknown nonlinear systems. ",
    "url": "https://arxiv.org/abs/2201.05098",
    "authors": [
      "Vrushabh Zinage",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.05119",
    "title": "Pushing the limits of self-supervised ResNets: Can we outperform  supervised learning without labels on ImageNet?",
    "abstract": "Despite recent progress made by self-supervised methods in representation learning with residual networks, they still underperform supervised learning on the ImageNet classification benchmark, limiting their applicability in performance-critical settings. Building on prior theoretical insights from Mitrovic et al., 2021, we propose ReLICv2 which combines an explicit invariance loss with a contrastive objective over a varied set of appropriately constructed data views. ReLICv2 achieves 77.1% top-1 classification accuracy on ImageNet using linear evaluation with a ResNet50 architecture and 80.6% with larger ResNet models, outperforming previous state-of-the-art self-supervised approaches by a wide margin. Most notably, ReLICv2 is the first representation learning method to consistently outperform the supervised baseline in a like-for-like comparison using a range of standard ResNet architectures. Finally we show that despite using ResNet encoders, ReLICv2 is comparable to state-of-the-art self-supervised vision transformers. ",
    "url": "https://arxiv.org/abs/2201.05119",
    "authors": [
      "Nenad Tomasev",
      "Ioana Bica",
      "Brian McWilliams",
      "Lars Buesing",
      "Razvan Pascanu",
      "Charles Blundell",
      "Jovana Mitrovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.05120",
    "title": "SeamlessGAN: Self-Supervised Synthesis of Tileable Texture Maps",
    "abstract": "We present SeamlessGAN, a method capable of automatically generating tileable texture maps from a single input exemplar. In contrast to most existing methods, focused solely on solving the synthesis problem, our work tackles both problems, synthesis and tileability, simultaneously. Our key idea is to realize that tiling a latent space within a generative network trained using adversarial expansion techniques produces outputs with continuity at the seam intersection that can be then be turned into tileable images by cropping the central area. Since not every value of the latent space is valid to produce high-quality outputs, we leverage the discriminator as a perceptual error metric capable of identifying artifact-free textures during a sampling process. Further, in contrast to previous work on deep texture synthesis, our model is designed and optimized to work with multi-layered texture representations, enabling textures composed of multiple maps such as albedo, normals, etc. We extensively test our design choices for the network architecture, loss function and sampling parameters. We show qualitatively and quantitatively that our approach outperforms previous methods and works for textures of different types. ",
    "url": "https://arxiv.org/abs/2201.05120",
    "authors": [
      "Carlos Rodriguez-Pardo",
      "Elena Garces"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2201.05121",
    "title": "STEdge: Self-training Edge Detection with Multi-layer Teaching and  Regularization",
    "abstract": "Learning-based edge detection has hereunto been strongly supervised with pixel-wise annotations which are tedious to obtain manually. We study the problem of self-training edge detection, leveraging the untapped wealth of large-scale unlabeled image datasets. We design a self-supervised framework with multi-layer regularization and self-teaching. In particular, we impose a consistency regularization which enforces the outputs from each of the multiple layers to be consistent for the input image and its perturbed counterpart. We adopt L0-smoothing as the 'perturbation' to encourage edge prediction lying on salient boundaries following the cluster assumption in self-supervised learning. Meanwhile, the network is trained with multi-layer supervision by pseudo labels which are initialized with Canny edges and then iteratively refined by the network as the training proceeds. The regularization and self-teaching together attain a good balance of precision and recall, leading to a significant performance boost over supervised methods, with lightweight refinement on the target dataset. Furthermore, our method demonstrates strong cross-dataset generality. For example, it attains 4.8% improvement for ODS and 5.8% for OIS when tested on the unseen BIPED dataset, compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2201.05121",
    "authors": [
      "Yunfan Ye",
      "Renjiao Yi",
      "Zhiping Cai",
      "Kai Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05125",
    "title": "GradMax: Growing Neural Networks using Gradient Information",
    "abstract": "The architecture and the parameters of neural networks are often optimized independently, which requires costly retraining of the parameters whenever the architecture is modified. In this work we instead focus on growing the architecture without requiring costly retraining. We present a method that adds new neurons during training without impacting what is already learned, while improving the training dynamics. We achieve the latter by maximizing the gradients of the new weights and find the optimal initialization efficiently by means of the singular value decomposition (SVD). We call this technique Gradient Maximizing Growth (GradMax) and demonstrate its effectiveness in variety of vision tasks and architectures. ",
    "url": "https://arxiv.org/abs/2201.05125",
    "authors": [
      "Utku Evci",
      "Max Vladymyrov",
      "Thomas Unterthiner",
      "Bart van Merri\u00ebnboer",
      "Fabian Pedregosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05131",
    "title": "SimReg: Regression as a Simple Yet Effective Tool for Self-supervised  Knowledge Distillation",
    "abstract": "Feature regression is a simple way to distill large neural network models to smaller ones. We show that with simple changes to the network architecture, regression can outperform more complex state-of-the-art approaches for knowledge distillation from self-supervised models. Surprisingly, the addition of a multi-layer perceptron head to the CNN backbone is beneficial even if used only during distillation and discarded in the downstream task. Deeper non-linear projections can thus be used to accurately mimic the teacher without changing inference architecture and time. Moreover, we utilize independent projection heads to simultaneously distill multiple teacher networks. We also find that using the same weakly augmented image as input for both teacher and student networks aids distillation. Experiments on ImageNet dataset demonstrate the efficacy of the proposed changes in various self-supervised distillation settings. ",
    "url": "https://arxiv.org/abs/2201.05131",
    "authors": [
      "K L Navaneet",
      "Soroush Abbasi Koohpayegani",
      "Ajinkya Tejankar",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05149",
    "title": "The curse of overparametrization in adversarial training: Precise  analysis of robust generalization for random features regression",
    "abstract": "Successful deep learning models often involve training neural network architectures that contain more parameters than the number of training samples. Such overparametrized models have been extensively studied in recent years, and the virtues of overparametrization have been established from both the statistical perspective, via the double-descent phenomenon, and the computational perspective via the structural properties of the optimization landscape. Despite the remarkable success of deep learning architectures in the overparametrized regime, it is also well known that these models are highly vulnerable to small adversarial perturbations in their inputs. Even when adversarially trained, their performance on perturbed inputs (robust generalization) is considerably worse than their best attainable performance on benign inputs (standard generalization). It is thus imperative to understand how overparametrization fundamentally affects robustness. In this paper, we will provide a precise characterization of the role of overparametrization on robustness by focusing on random features regression models (two-layer neural networks with random first layer weights). We consider a regime where the sample size, the input dimension and the number of parameters grow in proportion to each other, and derive an asymptotically exact formula for the robust generalization error when the model is adversarially trained. Our developed theory reveals the nontrivial effect of overparametrization on robustness and indicates that for adversarially trained random features models, high overparametrization can hurt robust generalization. ",
    "url": "https://arxiv.org/abs/2201.05149",
    "authors": [
      "Hamed Hassani",
      "Adel Javanmard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.04626",
    "title": "Learning Without a Global Clock: Asynchronous Learning in a  Physics-Driven Learning Network",
    "abstract": "In a neuron network, synapses update individually using local information, allowing for entirely decentralized learning. In contrast, elements in an artificial neural network (ANN) are typically updated simultaneously using a central processor. Here we investigate the feasibility and effect of asynchronous learning in a recently introduced decentralized, physics-driven learning network. We show that desynchronizing the learning process does not degrade performance for a variety of tasks in an idealized simulation. In experiment, desynchronization actually improves performance by allowing the system to better explore the discretized state space of solutions. We draw an analogy between asynchronicity and mini-batching in stochastic gradient descent, and show that they have similar effects on the learning process. Desynchronizing the learning process establishes physics-driven learning networks as truly fully distributed learning machines, promoting better performance and scalability in deployment. ",
    "url": "https://arxiv.org/abs/2201.04626",
    "authors": [
      "Jacob F Wycoff",
      "Sam Dillavou",
      "Menachem Stern",
      "Andrea J Liu",
      "Douglas J Durian"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.04669",
    "title": "On neural network kernels and the storage capacity problem",
    "abstract": "In this short note, we reify the connection between work on the storage capacity problem in wide two-layer treelike neural networks and the rapidly-growing body of literature on kernel limits of wide neural networks. Concretely, we observe that the \"effective order parameter\" studied in the statistical mechanics literature is exactly equivalent to the infinite-width Neural Network Gaussian Process Kernel. This correspondence connects the expressivity and trainability of wide two-layer neural networks. ",
    "url": "https://arxiv.org/abs/2201.04669",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04703",
    "title": "Detection of brain tumors using machine learning algorithms",
    "abstract": "An algorithm capable of processing NMR images was developed for analysis using machine learning techniques to detect the presence of brain tumors. ",
    "url": "https://arxiv.org/abs/2201.04703",
    "authors": [
      "Horacio Corral",
      "Javier Melchor",
      "Balam Sotelo",
      "Jorge Vera"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04714",
    "title": "Partial-Attribution Instance Segmentation for Astronomical Source  Detection and Deblending",
    "abstract": "Astronomical source deblending is the process of separating the contribution of individual stars or galaxies (sources) to an image comprised of multiple, possibly overlapping sources. Astronomical sources display a wide range of sizes and brightnesses and may show substantial overlap in images. Astronomical imaging data can further challenge off-the-shelf computer vision algorithms owing to its high dynamic range, low signal-to-noise ratio, and unconventional image format. These challenges make source deblending an open area of astronomical research, and in this work, we introduce a new approach called Partial-Attribution Instance Segmentation that enables source detection and deblending in a manner tractable for deep learning models. We provide a novel neural network implementation as a demonstration of the method. ",
    "url": "https://arxiv.org/abs/2201.04714",
    "authors": [
      "Ryan Hausen",
      "Brant Robertson"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04738",
    "title": "Implicit Bias of MSE Gradient Optimization in Underparameterized Neural  Networks",
    "abstract": "We study the dynamics of a neural network in function space when optimizing the mean squared error via gradient flow. We show that in the underparameterized regime the network learns eigenfunctions of an integral operator $T_{K^\\infty}$ determined by the Neural Tangent Kernel (NTK) at rates corresponding to their eigenvalues. For example, for uniformly distributed data on the sphere $S^{d - 1}$ and rotation invariant weight distributions, the eigenfunctions of $T_{K^\\infty}$ are the spherical harmonics. Our results can be understood as describing a spectral bias in the underparameterized regime. The proofs use the concept of \"Damped Deviations\", where deviations of the NTK matter less for eigendirections with large eigenvalues due to the occurence of a damping factor. Aside from the underparameterized regime, the damped deviations point-of-view can be used to track the dynamics of the empirical risk in the overparameterized setting, allowing us to extend certain results in the literature. We conclude that damped deviations offers a simple and unifying perspective of the dynamics when optimizing the squared error. ",
    "url": "https://arxiv.org/abs/2201.04738",
    "authors": [
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04753",
    "title": "Largest Eigenvalues of the Conjugate Kernel of Single-Layered Neural  Networks",
    "abstract": "This paper is concerned with the asymptotic distribution of the largest eigenvalues for some nonlinear random matrix ensemble stemming from the study of neural networks. More precisely we consider $M= \\frac{1}{m} YY^\\top$ with $Y=f(WX)$ where $W$ and $X$ are random rectangular matrices with i.i.d. centered entries. This models the data covariance matrix or the Conjugate Kernel of a single layered random Feed-Forward Neural Network. The function $f$ is applied entrywise and can be seen as the activation function of the neural network. We show that the largest eigenvalue has the same limit (in probability) as that of some well-known linear random matrix ensembles. In particular, we relate the asymptotic limit of the largest eigenvalue for the nonlinear model to that of an information-plus-noise random matrix, establishing a possible phase transition depending on the function $f$ and the distribution of $W$ and $X$. This may be of interest for applications to machine learning. ",
    "url": "https://arxiv.org/abs/2201.04753",
    "authors": [
      "Lucas Benigni",
      "Sandrine P\u00e9ch\u00e9"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04795",
    "title": "EMT-NET: Efficient multitask network for computer-aided diagnosis of  breast cancer",
    "abstract": "Deep learning-based computer-aided diagnosis has achieved unprecedented performance in breast cancer detection. However, most approaches are computationally intensive, which impedes their broader dissemination in real-world applications. In this work, we propose an efficient and light-weighted multitask learning architecture to classify and segment breast tumors simultaneously. We incorporate a segmentation task into a tumor classification network, which makes the backbone network learn representations focused on tumor regions. Moreover, we propose a new numerically stable loss function that easily controls the balance between the sensitivity and specificity of cancer detection. The proposed approach is evaluated using a breast ultrasound dataset with 1,511 images. The accuracy, sensitivity, and specificity of tumor classification is 88.6%, 94.1%, and 85.3%, respectively. We validate the model using a virtual mobile device, and the average inference time is 0.35 seconds per image. ",
    "url": "https://arxiv.org/abs/2201.04795",
    "authors": [
      "Jiaqiao Shi",
      "Aleksandar Vakanski",
      "Min Xian",
      "Jianrui Ding",
      "Chunping Ning"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04812",
    "title": "Unsupervised Domain Adaptation for Cross-Modality Retinal Vessel  Segmentation via Disentangling Representation Style Transfer and  Collaborative Consistency Learning",
    "abstract": "Various deep learning models have been developed to segment anatomical structures from medical images, but they typically have poor performance when tested on another target domain with different data distribution. Recently, unsupervised domain adaptation methods have been proposed to alleviate this so-called domain shift issue, but most of them are designed for scenarios with relatively small domain shifts and are likely to fail when encountering a large domain gap. In this paper, we propose DCDA, a novel cross-modality unsupervised domain adaptation framework for tasks with large domain shifts, e.g., segmenting retinal vessels from OCTA and OCT images. DCDA mainly consists of a disentangling representation style transfer (DRST) module and a collaborative consistency learning (CCL) module. DRST decomposes images into content components and style codes and performs style transfer and image reconstruction. CCL contains two segmentation models, one for source domain and the other for target domain. The two models use labeled data (together with the corresponding transferred images) for supervised learning and perform collaborative consistency learning on unlabeled data. Each model focuses on the corresponding single domain and aims to yield an expertized domain-specific segmentation model. Through extensive experiments on retinal vessel segmentation, our framework achieves Dice scores close to target-trained oracle both from OCTA to OCT and from OCT to OCTA, significantly outperforming other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2201.04812",
    "authors": [
      "Linkai Peng",
      "Li Lin",
      "Pujin Cheng",
      "Ziqi Huang",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04872",
    "title": "Comparison of Classification Algorithms for COVID19 Detection using  Cough Acoustic Signals",
    "abstract": "The epidemic disease, called the new coronavirus (COVID19), firstly occurred in Wuhan, China in December 2019. COVID19 was announced as an epidemic by World Health Organization soon after. Some of the symptoms of this disease are fever, cough, shortness of breath and difficulty in breathing. In more severe cases, death may occur as a result of infection. The most significant question in fighting the pandemic and controlling the epidemic is the early diagnosis of COVID19(+) patients and the follow-up of these patients. Therefore, various diagnostic mechanisms are used. Additionally to the RT-PCR test, medical imaging methods have been utilized, especially in the detection of COVID19(+) patients. In this study, an alternative approach was proposed by using cough data, which is one of the most prominent symptoms of COVID19(+) patients. The cough acoustic public dataset on the Virufy website was used. The entire data was normalized using z-normalization technique. The performance of the features obtained via the 5-layer empirical mode decomposition method and the performances of different classifiers has been compared. As the classifier algorithm, 5 different algorithms were used. The highest accuracy and F1-score performances were obtained by using Ensemble-Bagged-Trees algorithm as 90.6% and 90.5%, respectively. On the other hand, other classification algorithms used in the study are Support Vector Machines, Logistic Regression, Linear Discriminant Analysis and k-Nearest Neigbors, respectively. According to the results obtained, choosing the right classifier algorithm provides high results. Thus, it is clear that using cough acoustic data, those with COVID19(+) can be detected easily and effectively. ",
    "url": "https://arxiv.org/abs/2201.04872",
    "authors": [
      "Yunus Emre Erdo\u011fan",
      "Ali Narin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2201.04965",
    "title": "Stock Movement Prediction Based on Bi-typed and Hybrid-relational Market  Knowledge Graph via Dual Attention Networks",
    "abstract": "Stock Movement Prediction (SMP) aims at predicting listed companies' stock future price trend, which is a challenging task due to the volatile nature of financial markets. Recent financial studies show that the momentum spillover effect plays a significant role in stock fluctuation. However, previous studies typically only learn the simple connection information among related companies, which inevitably fail to model complex relations of listed companies in the real financial market. To address this issue, we first construct a more comprehensive Market Knowledge Graph (MKG) which contains bi-typed entities including listed companies and their associated executives, and hybrid-relations including the explicit relations and implicit relations. Afterward, we propose DanSmp, a novel Dual Attention Networks to learn the momentum spillover signals based upon the constructed MKG for stock prediction. The empirical experiments on our constructed datasets against nine SOTA baselines demonstrate that the proposed DanSmp is capable of improving stock prediction with the constructed MKG. ",
    "url": "https://arxiv.org/abs/2201.04965",
    "authors": [
      "Yu Zhao",
      "Huaming Du",
      "Ying Liu",
      "Shaopeng Wei",
      "Xingyan Chen",
      "Huali Feng",
      "Qinghong Shuai",
      "Qing Li",
      "Fuzhen Zhuang",
      "Gang Kou"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04972",
    "title": "Decomposition of admissible functions in weighted coupled cell networks",
    "abstract": "This work makes explicit the degrees of freedom involved in modeling the dynamics of a network, or some other first-order property of a network, such as a measurement function. Currently, the concept of an admissible function is defined through a very high-level description, with the shortcoming of being difficult to verify or design such a function. We introduce two decompositions in order to have a low-level representation of the underlying mathematical object. The first one is the more intuitive one and it solves the verification problem. More importantly, it provides us with essential definitions that prove crucial in order to define the second decomposition. The second decomposition is both verification and design friendly. Although this second decomposition only gives an equivalent representation under certain assumptions, it still proves to be a valid design tool even when they do not apply. ",
    "url": "https://arxiv.org/abs/2201.04972",
    "authors": [
      "Pedro Sequeira",
      "Jo\u00e3o P. Hespanha",
      "A. Pedro Aguiar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2201.04976",
    "title": "Data-Driven Modeling and Prediction of Non-Linearizable Dynamics via  Spectral Submanifolds",
    "abstract": "We develop a methodology to construct low-dimensional predictive models from data sets representing essentially nonlinear (or non-linearizable) dynamical systems with a hyperbolic linear part that are subject to external forcing with finitely many frequencies. Our data-driven, sparse, nonlinear models are obtained as extended normal forms of the reduced dynamics on low-dimensional, attracting spectral submanifolds (SSMs) of the dynamical system. We illustrate the power of data-driven SSM reduction on high-dimensional numerical data sets and experimental measurements involving beam oscillations, vortex shedding and sloshing in a water tank. We find that SSM reduction trained on unforced data also predicts nonlinear response accurately under additional external forcing. ",
    "url": "https://arxiv.org/abs/2201.04976",
    "authors": [
      "Mattia Cenedese",
      "Joar Ax\u00e5s",
      "Bastian B\u00e4uerlein",
      "Kerstin Avila",
      "George Haller"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2201.04985",
    "title": "Benchmarking Problems for Robust Discrete Optimization",
    "abstract": "Robust discrete optimization is a highly active field of research where a plenitude of combinations between decision criteria, uncertainty sets and underlying nominal problems are considered. Usually, a robust problem becomes harder to solve than its nominal counterpart, even if it remains in the same complexity class. For this reason, specialized solution algorithms have been developed. To further drive the development of stronger solution algorithms and to facilitate the comparison between methods, a set of benchmark instances is necessary but so far missing. In this paper we propose a further step towards this goal by proposing several instance generation procedures for combinations of min-max, min-max regret, two-stage and recoverable robustness with interval, discrete or budgeted uncertainty sets. Besides sampling methods that go beyond the simple uniform sampling method that is the de-facto standard to produce instances, also optimization models to construct hard instances are considered. Using a selection problem for the nominal ground problem, we are able to generate instances that are several orders of magnitudes harder to solve than uniformly sampled instances when solving them with a general mixed-integer programming solver. All instances and generator codes are made available online. ",
    "url": "https://arxiv.org/abs/2201.04985",
    "authors": [
      "Marc Goerigk",
      "Mohammad Khosravi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2201.05024",
    "title": "Real-Time GPU-Accelerated Machine Learning Based Multiuser Detection for  5G and Beyond",
    "abstract": "Adaptive partial linear beamforming meets the need of 5G and future 6G applications for high flexibility and adaptability. Choosing an appropriate tradeoff between conflicting goals opens the recently proposed multiuser (MU) detection method. Due to their high spatial resolution, nonlinear beamforming filters can significantly outperform linear approaches in stationary scenarios with massive connectivity. However, a dramatic decrease in performance can be expected in high mobility scenarios because they are very susceptible to changes in the wireless channel. The robustness of linear filters is required, considering these changes. One way to respond appropriately is to use online machine learning algorithms. The theory of algorithms based on the adaptive projected subgradient method (APSM) is rich, and they promise accurate tracking capabilities in dynamic wireless environments. However, one of the main challenges comes from the real-time implementation of these algorithms, which involve projections on time-varying closed convex sets. While the projection operations are relatively simple, their vast number poses a challenge in ultralow latency (ULL) applications where latency constraints must be satisfied in every radio frame. Taking non-orthogonal multiple access (NOMA) systems as an example, this paper explores the acceleration of APSM-based algorithms through massive parallelization. The result is a GPU-accelerated real-time implementation of an orthogonal frequency-division multiplexing (OFDM)-based transceiver that enables detection latency of less than one millisecond and therefore complies with the requirements of 5G and beyond. To meet the stringent physical layer latency requirements, careful co-design of hardware and software is essential, especially in virtualized wireless systems with hardware accelerators. ",
    "url": "https://arxiv.org/abs/2201.05024",
    "authors": [
      "Matthias Mehlhose",
      "Daniel Sch\u00e4ufele",
      "Daniyal Amir Awan",
      "Guillermo Marcus",
      "Nikolaus Binder",
      "Martin Kasparick",
      "Renato L. G. Cavalcante",
      "S\u0142awomir Sta\u0144czak",
      "Alexander Keller"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.05060",
    "title": "A robust kernel machine regression towards biomarker selection in  multi-omics datasets of osteoporosis for drug discovery",
    "abstract": "Many statistical machine approaches could ultimately highlight novel features of the etiology of complex diseases by analyzing multi-omics data. However, they are sensitive to some deviations in distribution when the observed samples are potentially contaminated with adversarial corrupted outliers (e.g., a fictional data distribution). Likewise, statistical advances lag in supporting comprehensive data-driven analyses of complex multi-omics data integration. We propose a novel non-linear M-estimator-based approach, \"robust kernel machine regression (RobKMR),\" to improve the robustness of statistical machine regression and the diversity of fictional data to examine the higher-order composite effect of multi-omics datasets. We address a robust kernel-centered Gram matrix to estimate the model parameters accurately. We also propose a robust score test to assess the marginal and joint Hadamard product of features from multi-omics data. We apply our proposed approach to a multi-omics dataset of osteoporosis (OP) from Caucasian females. Experiments demonstrate that the proposed approach effectively identifies the inter-related risk factors of OP. With solid evidence (p-value = 0.00001), biological validations, network-based analysis, causal inference, and drug repurposing, the selected three triplets ((DKK1, SMTN, DRGX), (MTND5, FASTKD2, CSMD3), (MTND5, COG3, CSMD3)) are significant biomarkers and directly relate to BMD. Overall, the top three selected genes (DKK1, MTND5, FASTKD2) and one gene (SIDT1 at p-value= 0.001) significantly bond with four drugs- Tacrolimus, Ibandronate, Alendronate, and Bazedoxifene out of 30 candidates for drug repurposing in OP. Further, the proposed approach can be applied to any disease model where multi-omics datasets are available. ",
    "url": "https://arxiv.org/abs/2201.05060",
    "authors": [
      "Md Ashad Alam",
      "Hui Shen",
      "Hong-Wen Deng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2201.05139",
    "title": "Generalized Kernel Ridge Regression for Long Term Causal Inference:  Treatment Effects, Dose Responses, and Counterfactual Distributions",
    "abstract": "I propose kernel ridge regression estimators for long term causal inference, where a short term experimental data set containing randomized treatment and short term surrogates is fused with a long term observational data set containing short term surrogates and long term outcomes. I propose estimators of treatment effects, dose responses, and counterfactual distributions with closed form solutions in terms of kernel matrix operations. I allow covariates, treatment, and surrogates to be discrete or continuous, and low, high, or infinite dimensional. For long term treatment effects, I prove $\\sqrt{n}$ consistency, Gaussian approximation, and semiparametric efficiency. For long term dose responses, I prove uniform consistency with finite sample rates. For long term counterfactual distributions, I prove convergence in distribution. ",
    "url": "https://arxiv.org/abs/2201.05139",
    "authors": [
      "Rahul Singh"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1905.13736",
    "title": "Unlabeled Data Improves Adversarial Robustness",
    "abstract": " Comments: Corrected some math typos in the proof of Lemma 1 ",
    "url": "https://arxiv.org/abs/1905.13736",
    "authors": [
      "Yair Carmon",
      "Aditi Raghunathan",
      "Ludwig Schmidt",
      "Percy Liang",
      "John C. Duchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.11425",
    "title": "Carbide: Highly Reliable Networks Through Real-Time Multiple Control  Plane Composition",
    "abstract": " Comments: 12 pages + References + Appendices, 14 figures ",
    "url": "https://arxiv.org/abs/2005.11425",
    "authors": [
      "Shenshen Chen",
      "Geng Li",
      "Dennis Duan",
      "Kerim Gokarslan",
      "Bin Li",
      "Qiao Xiang",
      "Haitao Yu",
      "Franck Le",
      "Richard Yang",
      "Ying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2007.00533",
    "title": "Partial Recovery in the Graph Alignment Problem",
    "abstract": " Title: Partial Recovery in the Graph Alignment Problem ",
    "url": "https://arxiv.org/abs/2007.00533",
    "authors": [
      "Georgina Hall",
      "Laurent Massouli\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2007.03298",
    "title": "DS-Sync: Addressing Network Bottlenecks with Divide-and-Shuffle  Synchronization for Distributed DNN Training",
    "abstract": " Comments: Infocom 2022 ",
    "url": "https://arxiv.org/abs/2007.03298",
    "authors": [
      "Weiyan Wang",
      "Cengguang Zhang",
      "Liu Yang",
      "Kai Chen",
      "Kun Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.09511",
    "title": "Multi-Stage Hybrid Federated Learning over Large-Scale D2D-Enabled Fog  Networks",
    "abstract": " Comments: This paper is accepted for publication in IEEE/ACM Transactions on Networking ",
    "url": "https://arxiv.org/abs/2007.09511",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Sheikh Shams Azam",
      "Christopher G. Brinton",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "David J. Love",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.03038",
    "title": "Fractal Gaussian Networks: A sparse random graph model based on Gaussian  Multiplicative Chaos",
    "abstract": " Comments: Accepted for publication at IEEE Transactions on Information Theory. A shorter version of this work appeared at the International Conference on Machine Learning (ICML 2020) ",
    "url": "https://arxiv.org/abs/2008.03038",
    "authors": [
      "Subhroshekhar Ghosh",
      "Krishnakumar Balasubramanian",
      "Xiaochuan Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2009.04077",
    "title": "1-Dimensional polynomial neural networks for audio signal related  problems",
    "abstract": " Title: 1-Dimensional polynomial neural networks for audio signal related  problems ",
    "url": "https://arxiv.org/abs/2009.04077",
    "authors": [
      "Habib Ben Abdallah",
      "Christopher J. Henry",
      "Sheela Ramanna"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2010.15785",
    "title": "Quickest detection of false data injection attack in remote state  estimation",
    "abstract": " Title: Quickest detection of false data injection attack in remote state  estimation ",
    "url": "https://arxiv.org/abs/2010.15785",
    "authors": [
      "Akanshu Gupta",
      "Abhinava Sikdar",
      "Arpan Chattopadhyay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2011.02959",
    "title": "Joint optimisation of privacy and cost of in-app mobile user profiling  and targeted ads",
    "abstract": " Comments: I will upload this paper later on; I will have to do some changes to the paper's contents and to the metadata ",
    "url": "https://arxiv.org/abs/2011.02959",
    "authors": [
      "Imdad Ullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2101.07512",
    "title": "Attention-Guided Black-box Adversarial Attacks with Large-Scale  Multiobjective Evolutionary Optimization",
    "abstract": " Title: Attention-Guided Black-box Adversarial Attacks with Large-Scale  Multiobjective Evolutionary Optimization ",
    "url": "https://arxiv.org/abs/2101.07512",
    "authors": [
      "Jie Wang",
      "Zhaoxia Yin",
      "Jing Jiang",
      "Yang Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.10751",
    "title": "Using a Cognitive Network Model of Moral and Social Beliefs to Explain  Belief Change",
    "abstract": " Comments: 33 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2102.10751",
    "authors": [
      "Jonas Dalege",
      "Tamara van der Does"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2103.04786",
    "title": "Combining Interventional and Observational Data Using Causal Reductions",
    "abstract": " Title: Combining Interventional and Observational Data Using Causal Reductions ",
    "url": "https://arxiv.org/abs/2103.04786",
    "authors": [
      "Maximilian Ilse",
      "Patrick Forr\u00e9",
      "Max Welling",
      "Joris M. Mooij"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2103.07666",
    "title": "GraphIQA:Learning Distortion Graph Representations for Blind Image  Quality Assessment",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2103.07666",
    "authors": [
      "Simeng Sun",
      "Tao Yu",
      "Jiahua Xu",
      "Wei Zhou",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2104.05171",
    "title": "Deep Recursive Embedding for High-Dimensional Data",
    "abstract": " Comments: Dear arXiv, We would like to withdraw this version, because it is in conflict with a later version uploaded and approved (arXiv:2111.00622). This version also contains some error: in Section 3.3, Eqn 1, a term p_{ij} is missing before log. We sincerely apologize and would like to withdraw to avoid any reader confusion. Sincerely, Zixia Zhou, Yuanyuan Wang, Boudewijn P.F. Lelieveldt, Qian Tao ",
    "url": "https://arxiv.org/abs/2104.05171",
    "authors": [
      "Zixia Zhou",
      "Yuanyuan Wang",
      "Boudewijn P.F. Lelieveldt",
      "Qian Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.05432",
    "title": "Discrete-time Contraction-based Control of Nonlinear Systems with  Parametric Uncertainties using Neural Networks",
    "abstract": " Comments: This work has been submitted to IEEE Transactions on Cybernetics for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2105.05432",
    "authors": [
      "Lai Wei",
      "Ryan McCloy",
      "Jie Bao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2106.12954",
    "title": "Rate Distortion Characteristic Modeling for Neural Image Compression",
    "abstract": " Comments: 10 pages, accepted by DCC 2022 as full paper ",
    "url": "https://arxiv.org/abs/2106.12954",
    "authors": [
      "Chuanmin Jia",
      "Ziqing Ge",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.13217",
    "title": "Exploring Depth Contribution for Camouflaged Object Detection",
    "abstract": " Comments: The first work in RGB-D Camouflaged object detection (COD) ",
    "url": "https://arxiv.org/abs/2106.13217",
    "authors": [
      "Mochu Xiang",
      "Jing Zhang",
      "Yunqiu Lv",
      "Aixuan Li",
      "Yiran Zhong",
      "Yuchao Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.00992",
    "title": "Multimodal Representation for Neural Code Search",
    "abstract": " Comments: 12 pages, 9 figures, 7 tables, accepted by ICSME 2021, the camera-ready version ",
    "url": "https://arxiv.org/abs/2107.00992",
    "authors": [
      "Jian Gu",
      "Zimin Chen",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05556",
    "title": "DebiasedDTA: Model Debiasing to Boost Drug-Target Affinity Prediction",
    "abstract": " Title: DebiasedDTA: Model Debiasing to Boost Drug-Target Affinity Prediction ",
    "url": "https://arxiv.org/abs/2107.05556",
    "authors": [
      "R\u0131za \u00d6z\u00e7elik",
      "Alperen Ba\u011f",
      "Berk At\u0131l",
      "Arzucan \u00d6zg\u00fcr",
      "Elif \u00d6zk\u0131r\u0131ml\u0131"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05884",
    "title": "Auto IV: Counterfactual Prediction via Automatic Instrumental Variable  Decomposition",
    "abstract": " Comments: Accepted by ACM Transactions on Knowledge Discovery from Data (TKDD) 2022 ",
    "url": "https://arxiv.org/abs/2107.05884",
    "authors": [
      "Junkun Yuan",
      "Anpeng Wu",
      "Kun Kuang",
      "Bo Li",
      "Runze Wu",
      "Fei Wu",
      "Lanfen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.08399",
    "title": "A Method for Estimating the Entropy of Time Series Using Artificial  Neural Networks",
    "abstract": " Comments: 15 pages, 14 figures, 1 table ",
    "url": "https://arxiv.org/abs/2107.08399",
    "authors": [
      "Andrei Velichko",
      "Hanif Heidari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2108.03288",
    "title": "Ensemble Augmentation for Deep Neural Networks Using 1-D Time Series  Vibration Data",
    "abstract": " Comments: The paper has severe scientific errors and needs significant modifications ",
    "url": "https://arxiv.org/abs/2108.03288",
    "authors": [
      "Atik Faysal",
      "Ngui Wai Keng",
      "M. H. Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.06817",
    "title": "Learning from Images: Proactive Caching with Parallel Convolutional  Neural Networks",
    "abstract": " Comments: 30 pages, 6 tables, 8 figures; typos corrected ",
    "url": "https://arxiv.org/abs/2108.06817",
    "authors": [
      "Yantong Wang",
      "Ye Hu",
      "Zhaohui Yang",
      "Walid Saad",
      "Kai-Kit Wong",
      "Vasilis Friderikos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.08422",
    "title": "Generating Smooth Pose Sequences for Diverse Human Motion Prediction",
    "abstract": " Comments: ICCV21(oral) (v3: update the threshold for pesudo GT in supplementary material) ",
    "url": "https://arxiv.org/abs/2108.08422",
    "authors": [
      "Wei Mao",
      "Miaomiao Liu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.11269",
    "title": "Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis  DOmain Generalization Challenge",
    "abstract": " Comments: This is the long version of the original pre-print. Due to a bug in our automatic threshold computation the detection threshold of our model changed from 0.62 to 0.64. This value was not optimized on any other images but the validation split of the MIDOG training set. 9 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2108.11269",
    "authors": [
      "Frauke Wilm",
      "Christian Marzahl",
      "Katharina Breininger",
      "Marc Aubreville"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05090",
    "title": "Enhancing Self-Disclosure In Neural Dialog Models By Candidate  Re-ranking",
    "abstract": " Comments: 10 pages, 3 figures, 2 table ",
    "url": "https://arxiv.org/abs/2109.05090",
    "authors": [
      "Mayank Soni",
      "Benjamin Cowan",
      "Vincent Wade"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.03011",
    "title": "Empirical Analysis of Bi-directional Wi-Fi Network Performance on Mobile  Robots in Indoor Environments",
    "abstract": " Title: Empirical Analysis of Bi-directional Wi-Fi Network Performance on Mobile  Robots in Indoor Environments ",
    "url": "https://arxiv.org/abs/2110.03011",
    "authors": [
      "Pranav Pandey",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2110.05518",
    "title": "Global Optimality Beyond Two Layers: Training Deep ReLU Networks via  Convex Programs",
    "abstract": " Comments: Accepted to ICML 2021 ",
    "url": "https://arxiv.org/abs/2110.05518",
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.12509",
    "title": "Per-Pixel Lung Thickness and Lung Capacity Estimation on Chest X-Rays  using Convolutional Neural Networks",
    "abstract": " Comments: v3: test set with patient inclusion diagram and various smaller changes ",
    "url": "https://arxiv.org/abs/2110.12509",
    "authors": [
      "Manuel Schultheiss",
      "Philipp Schmette",
      "Thorsten Sellerer",
      "Rafael Schick",
      "Kirsten Taphorn",
      "Korbinian Mechlem",
      "Lorenz Birnbacher",
      "Bernhard Renger",
      "Marcus R. Makowski",
      "Franz Pfeiffer",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.14739",
    "title": "Generalized Shape Metrics on Neural Representations",
    "abstract": " Comments: 26 pages, 7 figures, NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2110.14739",
    "authors": [
      "Alex H. Williams",
      "Erin Kunz",
      "Simon Kornblith",
      "Scott W. Linderman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.15949",
    "title": "Sparsely Changing Latent States for Prediction and Planning in Partially  Observable Domains",
    "abstract": " Comments: Accepted at NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2110.15949",
    "authors": [
      "Christian Gumbsch",
      "Martin V. Butz",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.03422",
    "title": "Transferable Time-Series Forecasting under Causal Conditional Shift",
    "abstract": " Title: Transferable Time-Series Forecasting under Causal Conditional Shift ",
    "url": "https://arxiv.org/abs/2111.03422",
    "authors": [
      "Zijian Li",
      "Ruichu Cai",
      "Tom Z.J Fu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.00396",
    "title": "Dyadic Human Motion Prediction",
    "abstract": " Comments: added reference for section 2 ",
    "url": "https://arxiv.org/abs/2112.00396",
    "authors": [
      "Isinsu Katircioglu",
      "Costa Georgantas",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03728",
    "title": "Flexible Networks for Learning Physical Dynamics of Deformable Objects",
    "abstract": " Title: Flexible Networks for Learning Physical Dynamics of Deformable Objects ",
    "url": "https://arxiv.org/abs/2112.03728",
    "authors": [
      "Jinhyung Park",
      "DoHae Lee",
      "In-Kwon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.15139",
    "title": "Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural  Networks",
    "abstract": " Comments: Tech report, 17 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2112.15139",
    "authors": [
      "Runpei Dong",
      "Zhanhong Tan",
      "Mengdi Wu",
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01293",
    "title": "A Transformer-Based Siamese Network for Change Detection",
    "abstract": " Comments: Submitted to International Geoscience and Remote Sensing Symposium (IGARSS), 2022. 4 pages, 2 figures. Code & trained models are available at this https URL ",
    "url": "https://arxiv.org/abs/2201.01293",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.02121",
    "title": "On the Discrete Fr\u00e9chet Distance in a Graph",
    "abstract": " Title: On the Discrete Fr\u00e9chet Distance in a Graph ",
    "url": "https://arxiv.org/abs/2201.02121",
    "authors": [
      "Anne Driemel",
      "Ivor van der Hoog",
      "Eva Rotenberg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2201.02302",
    "title": "Extending One-Stage Detection with Open-World Proposals",
    "abstract": " Title: Extending One-Stage Detection with Open-World Proposals ",
    "url": "https://arxiv.org/abs/2201.02302",
    "authors": [
      "Sachin Konan",
      "Kevin J Liang",
      "Li Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03110",
    "title": "Towards the Next 1000 Languages in Multilingual Machine Translation:  Exploring the Synergy Between Supervised and Self-Supervised Learning",
    "abstract": " Title: Towards the Next 1000 Languages in Multilingual Machine Translation:  Exploring the Synergy Between Supervised and Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2201.03110",
    "authors": [
      "Aditya Siddhant",
      "Ankur Bapna",
      "Orhan Firat",
      "Yuan Cao",
      "Mia Xu Chen",
      "Isaac Caswell",
      "Xavier Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04397",
    "title": "Towards Adversarially Robust Deep Image Denoising",
    "abstract": " Title: Towards Adversarially Robust Deep Image Denoising ",
    "url": "https://arxiv.org/abs/2201.04397",
    "authors": [
      "Hanshu Yan",
      "Jingfeng Zhang",
      "Jiashi Feng",
      "Masashi Sugiyama",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.04604",
    "title": "Fine-grained Graph Learning for Multi-view Subspace Clustering",
    "abstract": " Title: Fine-grained Graph Learning for Multi-view Subspace Clustering ",
    "url": "https://arxiv.org/abs/2201.04604",
    "authors": [
      "Yidi Wang",
      "Xiaobing Pei",
      "Haoxi Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]