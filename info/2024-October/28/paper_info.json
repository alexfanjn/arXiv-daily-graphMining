[
  {
    "id": "arXiv:2410.18983",
    "title": "Smart Navigation System for Parking Assignment at Large Events: Incorporating Heterogeneous Driver Characteristics",
    "abstract": "           Parking challenges escalate significantly during large events such as concerts and sports games, yet few studies address dynamic parking lot assignments in these occasions. This paper introduces a smart navigation system designed to optimize parking assignments efficiently during major events, employing a mixed search algorithm that considers diverse drivers characteristics. We validated our system through simulations conducted in Berkeley, CA during the \"Big Game\" showcasing the advantages of our novel parking assignment approach.         ",
    "url": "https://arxiv.org/abs/2410.18983",
    "authors": [
      "Xi Cheng",
      "Tong Liu",
      "Gaofeng Su",
      "Chang Che",
      "Chen Zhu",
      "Ke Liu",
      "Binze Cai",
      "Xin Hu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2410.18995",
    "title": "Enhancing Management of Large-Scale Optical Networks through RFID Technology Integration",
    "abstract": "           Managing large-scale optical distribution networks is a daunting task. This paper introduces a novel solution using radio frequency identification (RFID) technology to transform the procedure we monitor and manage the complex optical network dumb resources (ONDR). By implementing and deploying removable RFID tag pairing based on the serial peripheral interface (SPI) communication protocol, the system identifies 30 pairs of tags within one second, even at densities of up to 5.1 tagged components per square inch of patch panel surface area. The integration of light-emitting diode (LED) navigation aids in indicating correctly matched interfaces, effectively addressing the complexities associated with large-scale fiber matching.         ",
    "url": "https://arxiv.org/abs/2410.18995",
    "authors": [
      "Xiaoying Zheng",
      "Xingqi Xuan",
      "Shilie Zheng",
      "Xiaonan Hui",
      "Xianmin Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2410.19022",
    "title": "Heterogeneous Random Forest",
    "abstract": "           Random forest (RF) stands out as a highly favored machine learning approach for classification problems. The effectiveness of RF hinges on two key factors: the accuracy of individual trees and the diversity among them. In this study, we introduce a novel approach called heterogeneous RF (HRF), designed to enhance tree diversity in a meaningful way. This diversification is achieved by deliberately introducing heterogeneity during the tree construction. Specifically, features used for splitting near the root node of previous trees are assigned lower weights when constructing the feature sub-space of the subsequent trees. As a result, dominant features in the prior trees are less likely to be employed in the next iteration, leading to a more diverse set of splitting features at the nodes. Through simulation studies, it was confirmed that the HRF method effectively mitigates the selection bias of trees within the ensemble, increases the diversity of the ensemble, and demonstrates superior performance on datasets with fewer noise features. To assess the comparative performance of HRF against other widely adopted ensemble methods, we conducted tests on 52 datasets, comprising both real-world and synthetic data. HRF consistently outperformed other ensemble methods in terms of accuracy across the majority of datasets.         ",
    "url": "https://arxiv.org/abs/2410.19022",
    "authors": [
      "Ye-eun Kim",
      "Seoung Yun Kim",
      "Hyunjoong Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.19063",
    "title": "An Investigation on Machine Learning Predictive Accuracy Improvement and Uncertainty Reduction using VAE-based Data Augmentation",
    "abstract": "           The confluence of ultrafast computers with large memory, rapid progress in Machine Learning (ML) algorithms, and the availability of large datasets place multiple engineering fields at the threshold of dramatic progress. However, a unique challenge in nuclear engineering is data scarcity because experimentation on nuclear systems is usually more expensive and time-consuming than most other disciplines. One potential way to resolve the data scarcity issue is deep generative learning, which uses certain ML models to learn the underlying distribution of existing data and generate synthetic samples that resemble the real data. In this way, one can significantly expand the dataset to train more accurate predictive ML models. In this study, our objective is to evaluate the effectiveness of data augmentation using variational autoencoder (VAE)-based deep generative models. We investigated whether the data augmentation leads to improved accuracy in the predictions of a deep neural network (DNN) model trained using the augmented data. Additionally, the DNN prediction uncertainties are quantified using Bayesian Neural Networks (BNN) and conformal prediction (CP) to assess the impact on predictive uncertainty reduction. To test the proposed methodology, we used TRACE simulations of steady-state void fraction data based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark. We found that augmenting the training dataset using VAEs has improved the DNN model's predictive accuracy, improved the prediction confidence intervals, and reduced the prediction uncertainties.         ",
    "url": "https://arxiv.org/abs/2410.19063",
    "authors": [
      "Farah Alsafadi",
      "Mahmoud Yaseen",
      "Xu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19077",
    "title": "Target Strangeness: A Novel Conformal Prediction Difficulty Estimator",
    "abstract": "           This paper introduces Target Strangeness, a novel difficulty estimator for conformal prediction (CP) that offers an alternative approach for normalizing prediction intervals (PIs). By assessing how atypical a prediction is within the context of its nearest neighbours' target distribution, Target Strangeness can surpass the current state-of-the-art performance. This novel difficulty estimator is evaluated against others in the context of several conformal regression experiments.         ",
    "url": "https://arxiv.org/abs/2410.19077",
    "authors": [
      "Alexis Bose",
      "Jonathan Ethier",
      "Paul Guinand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19084",
    "title": "GCoder: Improving Large Language Model for Generalized Graph Problem Solving",
    "abstract": "           Large Language Models (LLMs) have demonstrated strong reasoning abilities, making them suitable for complex tasks such as graph computation. Traditional reasoning steps paradigm for graph problems is hindered by unverifiable steps, limited long-term reasoning, and poor generalization to graph variations. To overcome these limitations, we introduce GCoder, a code-based LLM designed to enhance problem-solving in generalized graph computation problems. Our method involves constructing an extensive training dataset, GraphWild, featuring diverse graph formats and algorithms. We employ a multi-stage training process, including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid retrieval technique is used to augment performance. Experiments demonstrate that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42% across various graph computational problems. Furthermore, GCoder efficiently manages large-scale graphs with millions of nodes and diverse input formats, overcoming the limitations of previous models focused on the reasoning steps paradigm. This advancement paves the way for more intuitive and effective graph problem-solving using LLMs. Code and data are available at here: this https URL.         ",
    "url": "https://arxiv.org/abs/2410.19084",
    "authors": [
      "Qifan Zhang",
      "Xiaobin Hong",
      "Jianheng Tang",
      "Nuo Chen",
      "Yuhan Li",
      "Wenzhong Li",
      "Jing Tang",
      "Jia Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.19119",
    "title": "Tera-Scale Multilevel Graph Partitioning",
    "abstract": "           We present TeraPart, a memory-efficient multilevel graph partitioning method that is designed to scale to extremely large graphs. In balanced graph partitioning, the goal is to divide the vertices into $k$ blocks with balanced size while cutting as few edges as possible. Due to its NP-hard nature, heuristics are prevalent in this field, with the multilevel framework as the state-of-the-art method. Recent work has seen tremendous progress in speeding up partitioning algorithms through parallelism. The current obstacle in scaling to larger graphs is the high memory usage due to auxiliary data structures and storing the graph itself in memory. In this paper, we present and study several optimizations to significantly reduce their memory footprint. We devise parallel label propagation clustering and graph contraction algorithms that use $O(n)$ auxiliary space instead of $O(np)$, where $p$ is the number of processors. Moreover, we employ an existing compressed graph representation that enables iterating over a neighborhood by on-the-fly decoding at speeds close to the uncompressed graph. Combining these optimizations yields up to a 16-fold reduction in peak memory, while retaining the same solution quality and similar speed. This configuration can partition a graph with one trillion edges in under 8 minutes \\emph{on a single machine} using around 900\\,GiB of RAM. This is the first work to employ the multilevel framework at this scale, which is vital to achieving low edge cuts. Moreover, our distributed memory implementation handles graphs of up to 16 trillion edges on 128 machines with 256\\,GiB each in just under 10 minutes. Finally, we present a version of shared-memory parallel FM local search that uses $O(m)$ space instead of $O(nk)$, reducing peak memory by factor 5.8 on medium-sized graphs without affecting running time.         ",
    "url": "https://arxiv.org/abs/2410.19119",
    "authors": [
      "Daniel Salwasser",
      "Daniel Seemaier",
      "Lars Gottesb\u00fcren",
      "Peter Sanders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2410.19122",
    "title": "Greedy Algorithm for Neural Networks for Indefinite Elliptic Problems",
    "abstract": "           The paper presents a priori error analysis of the shallow neural network approximation to the solution to the indefinite elliptic equation and and cutting-edge implementation of the Orthogonal Greedy Algorithm (OGA) tailored to overcome the challenges of indefinite elliptic problems, which is a domain where conventional approaches often struggle due to nontraditional difficulties due to the lack of coerciveness. A rigorous a priori error analysis that shows the neural networks ability to approximate indefinite problems is confirmed numerically by OGA methods. We also present a discretization error analysis of the relevant numerical quadrature. In particular, massive numerical implementations are conducted to justify the theory, some of which showcase the OGAs superior performance in comparison to the traditional finite element method. This advancement illustrates the potential of neural networks enhanced by OGA to solve intricate computational problems more efficiently, thereby marking a significant leap forward in the application of machine learning techniques to mathematical problem-solving.         ",
    "url": "https://arxiv.org/abs/2410.19122",
    "authors": [
      "Qingguo Hong",
      "Jiwei Jia",
      "Young Ju Lee",
      "Ziqian Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2410.19136",
    "title": "Context-Aware Trajectory Anomaly Detection",
    "abstract": "           Trajectory anomaly detection is crucial for effective decision-making in urban and human mobility management. Existing methods of trajectory anomaly detection generally focus on training a trajectory generative model and evaluating the likelihood of reconstructing a given trajectory. However, previous work often lacks important contextual information on the trajectory, such as the agent's information (e.g., agent ID) or geographic information (e.g., Points of Interest (POI)), which could provide additional information on accurately capturing anomalous behaviors. To fill this gap, we propose a context-aware anomaly detection approach that models contextual information related to trajectories. The proposed method is based on a trajectory reconstruction framework guided by contextual factors such as agent ID and contextual POI embedding. The injection of contextual information aims to improve the performance of anomaly detection. We conducted experiments in two cities and demonstrated that the proposed approach significantly outperformed existing methods by effectively modeling contextual information. Overall, this paper paves a new direction for advancing trajectory anomaly detection.         ",
    "url": "https://arxiv.org/abs/2410.19136",
    "authors": [
      "Haoji Hu",
      "Jina Kim",
      "Jinwei Zhou",
      "Sofia Kirsanova",
      "JangHyeon Lee",
      "Yao-Yi Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19160",
    "title": "Adversarial Attacks on Large Language Models Using Regularized Relaxation",
    "abstract": "           As powerful Large Language Models (LLMs) are now widely used for numerous practical applications, their safety is of critical importance. While alignment techniques have significantly improved overall safety, LLMs remain vulnerable to carefully crafted adversarial inputs. Consequently, adversarial attack methods are extensively used to study and understand these vulnerabilities. However, current attack methods face significant limitations. Those relying on optimizing discrete tokens suffer from limited efficiency, while continuous optimization techniques fail to generate valid tokens from the model's vocabulary, rendering them impractical for real-world applications. In this paper, we propose a novel technique for adversarial attacks that overcomes these limitations by leveraging regularized gradients with continuous optimization methods. Our approach is two orders of magnitude faster than the state-of-the-art greedy coordinate gradient-based method, significantly improving the attack success rate on aligned language models. Moreover, it generates valid tokens, addressing a fundamental limitation of existing continuous optimization methods. We demonstrate the effectiveness of our attack on five state-of-the-art LLMs using four datasets.         ",
    "url": "https://arxiv.org/abs/2410.19160",
    "authors": [
      "Samuel Jacob Chacko",
      "Sajib Biswas",
      "Chashi Mahiul Islam",
      "Fatema Tabassum Liza",
      "Xiuwen Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.19174",
    "title": "Indication Finding: a novel use case for representation learning",
    "abstract": "           Many therapies are effective in treating multiple diseases. We present an approach that leverages methods developed in natural language processing and real-world data to prioritize potential, new indications for a mechanism of action (MoA). We specifically use representation learning to generate embeddings of indications and prioritize them based on their proximity to the indications with the strongest available evidence for the MoA. We demonstrate the successful deployment of our approach for anti-IL-17A using embeddings generated with SPPMI and present an evaluation framework to determine the quality of indication finding results and the derived embeddings.         ",
    "url": "https://arxiv.org/abs/2410.19174",
    "authors": [
      "Maren Eckhoff",
      "Valmir Selimi",
      "Alexander Aranovitch",
      "Ian Lyons",
      "Emily Briggs",
      "Jennifer Hou",
      "Alex Devereson",
      "Matej Macak",
      "David Champagne",
      "Chris Anagnostopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.19176",
    "title": "Perturbation-based Graph Active Learning for Weakly-Supervised Belief Representation Learning",
    "abstract": "           This paper addresses the problem of optimizing the allocation of labeling resources for semi-supervised belief representation learning in social networks. The objective is to strategically identify valuable messages on social media graphs that are worth labeling within a constrained budget, ultimately maximizing the task's performance. Despite the progress in unsupervised or semi-supervised methods in advancing belief and ideology representation learning on social networks and the remarkable efficacy of graph learning techniques, the availability of high-quality curated labeled social data can greatly benefit and further improve performances. Consequently, allocating labeling efforts is a critical research problem in scenarios where labeling resources are limited. This paper proposes a graph data augmentation-inspired perturbation-based active learning strategy (PerbALGraph) that progressively selects messages for labeling according to an automatic estimator, obviating human guidance. This estimator is based on the principle that messages in the network that exhibit heightened sensitivity to structural features of the observational data indicate landmark quality that significantly influences semi-supervision processes. We design the estimator to be the prediction variance under a set of designed graph perturbations, which is model-agnostic and application-independent. Extensive experiment results demonstrate the effectiveness of the proposed strategy for belief representation learning tasks.         ",
    "url": "https://arxiv.org/abs/2410.19176",
    "authors": [
      "Dachun Sun",
      "Ruijie Wang",
      "Jinning Li",
      "Ruipeng Han",
      "Xinyi Liu",
      "You Lyu",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19177",
    "title": "Sentiment-Driven Community Detection in a Network of Perfume Preferences",
    "abstract": "           Network analysis is increasingly important across various fields, including the fragrance industry, where perfumes are represented as nodes and shared user preferences as edges in perfume networks. Community detection can uncover clusters of similar perfumes, providing insights into consumer preferences, enhancing recommendation systems, and informing targeted marketing strategies. This study aims to apply community detection techniques to group perfumes favored by users into relevant clusters for better recommendations. We constructed a bipartite network from user reviews on the Persian retail platform \"Atrafshan,\" with nodes representing users and perfumes, and edges formed by positive comments. This network was transformed into a Perfume Co-Preference Network, connecting perfumes liked by the same users. By applying community detection algorithms, we identified clusters based on shared preferences, enhancing our understanding of user sentiment in the fragrance market. To improve sentiment analysis, we integrated emojis and a user voting system for greater accuracy. Emojis, aligned with their Persian counterparts, captured the emotional tone of reviews, while user ratings for scent, longevity, and sillage refined sentiment classification. Edge weights were adjusted by combining adjacency values with user ratings in a 60:40 ratio, reflecting both connection strength and user preferences. These enhancements led to improved modularity of detected communities, resulting in more accurate perfume groupings. This research pioneers the use of community detection in perfume networks, offering new insights into consumer preferences. Our advancements in sentiment analysis and edge weight refinement provide actionable insights for optimizing product recommendations and marketing strategies in the fragrance industry.         ",
    "url": "https://arxiv.org/abs/2410.19177",
    "authors": [
      "Kamand Kalashi",
      "Sajjad Saed",
      "Babak Teimourpour"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2410.19179",
    "title": "Cascading Failure Prediction via Causal Inference",
    "abstract": "           Causal inference provides an analytical framework to identify and quantify cause-and-effect relationships among a network of interacting agents. This paper offers a novel framework for analyzing cascading failures in power transmission networks. This framework generates a directed latent graph in which the nodes represent the transmission lines and the directed edges encode the cause-effect relationships. This graph has a structure distinct from the system's topology, signifying the intricate fact that both local and non-local interdependencies exist among transmission lines, which are more general than only the local interdependencies that topological graphs can present. This paper formalizes a causal inference framework for predicting how an emerging anomaly propagates throughout the system. Using this framework, two algorithms are designed, providing an analytical framework to identify the most likely and most costly cascading scenarios. The framework's effectiveness is evaluated compared to the pertinent literature on the IEEE 14-bus, 39-bus, and 118-bus systems.         ",
    "url": "https://arxiv.org/abs/2410.19179",
    "authors": [
      "Shiuli Subhra Ghosh",
      "Anmol Dwivedi",
      "Ali Tajer",
      "Kyongmin Yeo",
      "Wesley M. Gifford"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19180",
    "title": "Noise Adaption Network for Morse Code Image Classification",
    "abstract": "           The escalating significance of information security has underscored the per-vasive role of encryption technology in safeguarding communication con-tent. Morse code, a well-established and effective encryption method, has found widespread application in telegraph communication and various do-mains. However, the transmission of Morse code images faces challenges due to diverse noises and distortions, thereby hindering comprehensive clas-sification outcomes. Existing methodologies predominantly concentrate on categorizing Morse code images affected by a single type of noise, neglecting the multitude of scenarios that noise pollution can generate. To overcome this limitation, we propose a novel two-stage approach, termed the Noise Adaptation Network (NANet), for Morse code image classification. Our method involves exclusive training on pristine images while adapting to noisy ones through the extraction of critical information unaffected by noise. In the initial stage, we introduce a U-shaped network structure designed to learn representative features and denoise images. Subsequently, the second stage employs a deep convolutional neural network for classification. By leveraging the denoising module from the first stage, our approach achieves enhanced accuracy and robustness in the subsequent classification phase. We conducted an evaluation of our approach on a diverse dataset, encom-passing Gaussian, salt-and-pepper, and uniform noise variations. The results convincingly demonstrate the superiority of our methodology over existing approaches. The datasets are available on this https URL ",
    "url": "https://arxiv.org/abs/2410.19180",
    "authors": [
      "Xiaxia Wang",
      "XueSong Leng",
      "Guoping Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19183",
    "title": "Can Self Supervision Rejuvenate Similarity-Based Link Prediction?",
    "abstract": "           Although recent advancements in end-to-end learning-based link prediction (LP) methods have shown remarkable capabilities, the significance of traditional similarity-based LP methods persists in unsupervised scenarios where there are no known link labels. However, the selection of node features for similarity computation in similarity-based LP can be challenging. Less informative node features can result in suboptimal LP performance. To address these challenges, we integrate self-supervised graph learning techniques into similarity-based LP and propose a novel method: Self-Supervised Similarity-based LP (3SLP). 3SLP is suitable for the unsupervised condition of similarity-based LP without the assistance of known link labels. Specifically, 3SLP introduces a dual-view contrastive node representation learning (DCNRL) with crafted data augmentation and node representation learning. DCNRL is dedicated to developing more informative node representations, replacing the node attributes as inputs in the similarity-based LP backbone. Extensive experiments over benchmark datasets demonstrate the salient improvement of 3SLP, outperforming the baseline of traditional similarity-based LP by up to 21.2% (AUC).         ",
    "url": "https://arxiv.org/abs/2410.19183",
    "authors": [
      "Chenhan Zhang",
      "Weiqi Wang",
      "Zhiyi Tian",
      "James Jianqiao Yu",
      "Mohamed Ali Kaafar",
      "An Liu",
      "Shui Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19193",
    "title": "Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media",
    "abstract": "           Disinformation on social media poses both societal and technical challenges. While previous studies have integrated textual information into propagation networks, they have yet to fully leverage the advancements in Transformer-based language models for high-quality contextual text representations. This work investigates the impact of incorporating textual features into Graph Neural Networks (GNNs) for fake news detection. Our experiments demonstrate that contextual representations improve performance by 9.3% in Macro F1 over static ones and 33.8% over GNNs without textual features. However, noisy data augmentation degrades performance and increases instability. We expect our methodology to open avenues for further research, and all code is made publicly available.         ",
    "url": "https://arxiv.org/abs/2410.19193",
    "authors": [
      "Bruno Croso Cunha da Silva",
      "Thomas Palmeira Ferraz",
      "Roseli De Deus Lopes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.19199",
    "title": "Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis",
    "abstract": "           Recent studies have outlined the accessibility challenges faced by blind or visually impaired, and less-literate people, in interacting with social networks, in-spite of facilitating technologies such as monotone text-to-speech (TTS) screen readers and audio narration of visual elements such as emojis. Emotional speech generation traditionally relies on human input of the expected emotion together with the text to synthesise, with additional challenges around data simplification (causing information loss) and duration inaccuracy, leading to lack of expressive emotional rendering. In real-life communications, the duration of phonemes can vary since the same sentence might be spoken in a variety of ways depending on the speakers' emotional states or accents (referred to as the one-to-many problem of text to speech generation). As a result, an advanced voice synthesis system is required to account for this unpredictability. We propose an end-to-end context-aware Text-to-Speech (TTS) synthesis system that derives the conveyed emotion from text input and synthesises audio that focuses on emotions and speaker features for natural and expressive speech, integrating advanced natural language processing (NLP) and speech synthesis techniques for real-time applications. Our system also showcases competitive inference time performance when benchmarked against the state-of-the-art TTS models, making it suitable for real-time accessibility applications.         ",
    "url": "https://arxiv.org/abs/2410.19199",
    "authors": [
      "Suparna De",
      "Ionut Bostan",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2410.19203",
    "title": "An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm Based on Decomposition",
    "abstract": "           This paper introduces the inverse modeling constrained multi-objective evolutionary algorithm based on decomposition (IM-C-MOEA/D) for addressing constrained real-world optimization problems. Our research builds upon the advancements made in evolutionary computing-based inverse modeling, and it strategically bridges the gaps in applying inverse models based on decomposition to problem domains with constraints. The proposed approach is experimentally evaluated on diverse real-world problems (RWMOP1-35), showing superior performance to state-of-the-art constrained multi-objective evolutionary algorithms (CMOEAs). The experimental results highlight the robustness of the algorithm and its applicability in real-world constrained optimization scenarios.         ",
    "url": "https://arxiv.org/abs/2410.19203",
    "authors": [
      "Lucas R. C. Farias",
      "Aluizio F. R. Ara\u00fajo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19205",
    "title": "Overcoming Non-Submodularity: Constant Approximation for Network Immunization",
    "abstract": "           Given a network with an ongoing epidemic, the network immunization problem seeks to identify a fixed number of nodes to immunize in order to maximize the number of infections prevented. One of the fundamental computational challenges in network immunization is that the objective function is generally neither submodular nor supermodular. As a result, no efficient algorithm is known to consistently find a solution with a constant approximation guarantee. Traditionally, this problem is addressed using proxy objectives, which offer better approximation properties. However, converting to these indirect optimizations often introduces losses in effectiveness. In this paper, we overcome these fundamental barriers by utilizing the underlying stochastic structures of the diffusion process. Similar to the traditional influence objective, the immunization objective is an expectation that can be expressed as the sum of objectives over deterministic instances. However, unlike the former, some of these terms are not submodular. The key step is proving that this sum has a bounded deviation from submodularity, thereby enabling the greedy algorithm to achieve constant factor approximation. We show that this approximation still stands considering a variety of immunization settings and spread models.         ",
    "url": "https://arxiv.org/abs/2410.19205",
    "authors": [
      "Ajitesh Srivastava",
      "Shang-Hua Teng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19214",
    "title": "A Comprehensive Analysis of Social Tie Strength: Definitions, Prediction Methods, and Future Directions",
    "abstract": "           The rapid growth of online social networks has underscored the importance of understanding the intensity of user relationships, referred to as \"tie strength.\" Over the past few decades, extensive efforts have been made to assess tie strength in networks. However, the lack of ground-truth tie strength labels and the differing perspectives on tie strength among researchers have complicated the development of effective prediction methods for real-world applications. In our study, we first categorize mainstream understandings of tie strength into seven standardized definitions and verify their effectiveness by investigating the class distributions and correlations across these definitions. We also draw key insights into tie resilience from the perspective of tie dissolution that (1) stronger ties are more resilient than weaker ones, and (2) this tie resiliency ratio increases as the network evolves. We then conduct extensive experiments to evaluate existing tie strength prediction methods under these definitions, revealing that (1) neural network methods capable of learning from semantic features hold great potential for high performance, (2) models struggle under definitions that offer limited understandings of tie strength in the network, (3) existing models face imbalance issues that cannot be addressed by traditional quantity imbalance techniques, and (4) different definitions of tie strength allow for the inference of not only the current state but also the future state of a tie. Building on these findings, we propose strategies to improve existing methods and suggest several promising directions for future research.         ",
    "url": "https://arxiv.org/abs/2410.19214",
    "authors": [
      "Xueqi Cheng",
      "Catherine Yang",
      "Yuying Zhao",
      "Yu Wang",
      "Hamid Karimi",
      "Tyler Derr"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19230",
    "title": "Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors",
    "abstract": "           The advent of large language models (LLMs) has revolutionized the field of text generation, producing outputs that closely mimic human-like writing. Although academic and industrial institutions have developed detectors to prevent the malicious usage of LLM-generated texts, other research has doubt about the robustness of these systems. To stress test these detectors, we introduce a proxy-attack strategy that effortlessly compromises LLMs, causing them to produce outputs that align with human-written text and mislead detection systems. Our method attacks the source model by leveraging a reinforcement learning (RL) fine-tuned humanized small language model (SLM) in the decoding phase. Through an in-depth analysis, we demonstrate that our attack strategy is capable of generating responses that are indistinguishable to detectors, preventing them from differentiating between machine-generated and human-written text. We conduct systematic evaluations on extensive datasets using proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and Mixtral-8*7B in both white- and black-box settings. Our findings show that the proxy-attack strategy effectively deceives the leading detectors, resulting in an average AUROC drop of 70.4% across multiple datasets, with a maximum drop of 90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our strategy also bypasses these detectors, leading to a significant relative decrease of up to 90.9%, while in cross-language scenario, the drop reaches 91.3%. Despite our proxy-attack strategy successfully bypassing the detectors with such significant relative drops, we find that the generation quality of the attacked models remains preserved, even within a modest utility budget, when compared to the text produced by the original, unattacked source model.         ",
    "url": "https://arxiv.org/abs/2410.19230",
    "authors": [
      "Tianchun Wang",
      "Yuanzhou Chen",
      "Zichuan Liu",
      "Zhanwen Chen",
      "Haifeng Chen",
      "Xiang Zhang",
      "Wei Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.19256",
    "title": "Spatioformer: A Geo-encoded Transformer for Large-Scale Plant Species Richness Prediction",
    "abstract": "           Earth observation data have shown promise in predicting species richness of vascular plants ($\\alpha$-diversity), but extending this approach to large spatial scales is challenging because geographically distant regions may exhibit different compositions of plant species ($\\beta$-diversity), resulting in a location-dependent relationship between richness and spectral measurements. In order to handle such geolocation dependency, we propose Spatioformer, where a novel geolocation encoder is coupled with the transformer model to encode geolocation context into remote sensing imagery. The Spatioformer model compares favourably to state-of-the-art models in richness predictions on a large-scale ground-truth richness dataset (HAVPlot) that consists of 68,170 in-situ richness samples covering diverse landscapes across Australia. The results demonstrate that geolocational information is advantageous in predicting species richness from satellite observations over large spatial scales. With Spatioformer, plant species richness maps over Australia are compiled from Landsat archive for the years from 2015 to 2023. The richness maps produced in this study reveal the spatiotemporal dynamics of plant species richness in Australia, providing supporting evidence to inform effective planning and policy development for plant diversity conservation. Regions of high richness prediction uncertainties are identified, highlighting the need for future in-situ surveys to be conducted in these areas to enhance the prediction accuracy.         ",
    "url": "https://arxiv.org/abs/2410.19256",
    "authors": [
      "Yiqing Guo",
      "Karel Mokany",
      "Shaun R. Levick",
      "Jinyan Yang",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19265",
    "title": "A Survey of Deep Graph Learning under Distribution Shifts: from Graph Out-of-Distribution Generalization to Adaptation",
    "abstract": "           Distribution shifts on graphs -- the discrepancies in data distribution between training and employing a graph machine learning model -- are ubiquitous and often unavoidable in real-world scenarios. These shifts may severely deteriorate model performance, posing significant challenges for reliable graph machine learning. Consequently, there has been a surge in research on graph machine learning under distribution shifts, aiming to train models to achieve satisfactory performance on out-of-distribution (OOD) test data. In our survey, we provide an up-to-date and forward-looking review of deep graph learning under distribution shifts. Specifically, we cover three primary scenarios: graph OOD generalization, training-time graph OOD adaptation, and test-time graph OOD adaptation. We begin by formally formulating the problems and discussing various types of distribution shifts that can affect graph learning, such as covariate shifts and concept shifts. To provide a better understanding of the literature, we systematically categorize the existing models based on our proposed taxonomy and investigate the adopted techniques behind. We also summarize commonly used datasets in this research area to facilitate further investigation. Finally, we point out promising research directions and the corresponding challenges to encourage further study in this vital domain. Additionally, we provide a continuously updated reading list at this https URL.         ",
    "url": "https://arxiv.org/abs/2410.19265",
    "authors": [
      "Kexin Zhang",
      "Shuhan Liu",
      "Song Wang",
      "Weili Shi",
      "Chen Chen",
      "Pan Li",
      "Sheng Li",
      "Jundong Li",
      "Kaize Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19272",
    "title": "Coordinated Reply Attacks in Influence Operations: Characterization and Detection",
    "abstract": "           Coordinated reply attacks are a tactic observed in online influence operations and other coordinated campaigns to support or harass targeted individuals, or influence them or their followers. Despite its potential to influence the public, past studies have yet to analyze or provide a methodology to detect this tactic. In this study, we characterize coordinated reply attacks in the context of influence operations on Twitter. Our analysis reveals that the primary targets of these attacks are influential people such as journalists, news media, state officials, and politicians. We propose two supervised machine-learning models, one to classify tweets to determine whether they are targeted by a reply attack, and one to classify accounts that reply to a targeted tweet to determine whether they are part of a coordinated attack. The classifiers achieve AUC scores of 0.88 and 0.97, respectively. These results indicate that accounts involved in reply attacks can be detected, and the targeted accounts themselves can serve as sensors for influence operation detection.         ",
    "url": "https://arxiv.org/abs/2410.19272",
    "authors": [
      "Manita Pote",
      "Tu\u011frulcan Elmas",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19276",
    "title": "Learning ID-free Item Representation with Token Crossing for Multimodal Recommendation",
    "abstract": "           Current multimodal recommendation models have extensively explored the effective utilization of multimodal information; however, their reliance on ID embeddings remains a performance bottleneck. Even with the assistance of multimodal information, optimizing ID embeddings remains challenging for ID-based Multimodal Recommender when interaction data is sparse. Furthermore, the unique nature of item-specific ID embeddings hinders the information exchange among related items and the spatial requirement of ID embeddings increases with the scale of item. Based on these limitations, we propose an ID-free MultimOdal TOken Representation scheme named MOTOR that represents each item using learnable multimodal tokens and connects them through shared tokens. Specifically, we first employ product quantization to discretize each item's multimodal features (e.g., images, text) into discrete token IDs. We then interpret the token embeddings corresponding to these token IDs as implicit item features, introducing a new Token Cross Network to capture the implicit interaction patterns among these tokens. The resulting representations can replace the original ID embeddings and transform the original ID-based multimodal recommender into ID-free system, without introducing any additional loss design. MOTOR reduces the overall space requirements of these models, facilitating information interaction among related items, while also significantly enhancing the model's recommendation capability. Extensive experiments on nine mainstream models demonstrate the significant performance improvement achieved by MOTOR, highlighting its effectiveness in enhancing multimodal recommendation systems.         ",
    "url": "https://arxiv.org/abs/2410.19276",
    "authors": [
      "Kangning Zhang",
      "Jiarui Jin",
      "Yingjie Qin",
      "Ruilong Su",
      "Jianghao Lin",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2410.19282",
    "title": "Stopping Set Analysis for Concatenated Polar Code Architectures",
    "abstract": "           This paper investigates properties of concatenated polar codes and their potential applications. We start with reviewing previous work on stopping set analysis for conventional polar codes, which we extend in this paper to concatenated architectures. Specifically, we present a stopping set analysis for the factor graph of concatenated polar codes, deriving an upper bound on the size of the minimum stopping set. To achieve this bound, we propose new bounds on the size of the minimum stopping set for conventional polar code factor graphs. The tightness of these proposed bounds is investigated empirically and analytically. We show that, in some special cases, the exact value of the minimum stopping set can be determined with a time complexity of $O(N)$, where $N$ is the codeword length. The stopping set analysis motivates a novel construction method for concatenated polar codes. This method is used to design outer polar codes for two previously proposed concatenated polar code architectures: augmented polar codes and local-global polar codes. Simulation results demonstrate the advantage of the proposed codes over previously proposed constructions based on density evolution (DE).         ",
    "url": "https://arxiv.org/abs/2410.19282",
    "authors": [
      "Ziyuan Zhu",
      "Paul H. Siegel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2410.19291",
    "title": "A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images",
    "abstract": "           Stock price fluctuations are influenced by a variety of factors, including macroeconomic conditions, government policies, and market sentiment, which together make price movements complex and difficult to predict. Despite many studies aimed at enhancing stock price prediction models, challenges such as data noise, model overfitting, and lack of interpretability are still encountered. To address these issues and improve prediction accuracy, this paper proposes a novel method, named Sequence-based Multiscale Fusion Regression Convolutional Neural Network (SMSFR-CNN), for predicting stock price movements in the China A-share market. By utilizing CNN to learn sequential features and combining them with image features, we improve the accuracy of stock trend prediction on the A-share market stock dataset. This approach reduces the search space for image features, stabilizes, and accelerates the training process. Extensive comparative experiments on 4,454 A-share stocks show that the proposed model achieves 61.15% for positive predictive value and 63.37% for negative predictive value of the stock price trend over the next 5 days, resulting in a total profit of 165.09%.         ",
    "url": "https://arxiv.org/abs/2410.19291",
    "authors": [
      "Zhiyuan Pei",
      "Jianqi Yan",
      "Jin Yan",
      "Bailing Yang",
      "Ziyuan Li",
      "Lin Zhang",
      "Xin Liu",
      "Yang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2410.19297",
    "title": "MambaCPU: Enhanced Correlation Mining with State Space Models for CPU Performance Prediction",
    "abstract": "           CPU performance prediction, which involves forecasting the performance scores of a CPU based on its hardware characteristics during the operation process, is a critical technology for computational system design and resource management. However, this research field currently faces two significant challenges. First, collecting real-world data is challenging due to the wide variety of CPU products on the market and the highly specialized nature of relevant hardware characteristics. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles, low prediction accuracy, and the ignoration of characteristic correlations. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel Xeon Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a novel network MambaCPU (MaC) as the baseline for the PerfCastDB dataset. This model leverages the mamba structure to mine the global dependencies and correlations between multiple characteristics. The intra- and inter-group attention mechanisms are subsequently utilized to refine the correlations within and across the characteristic type groups. These techniques enhance the analysis and mining capability of Mac for the complex multivariate correlations. Comparative experiments on the PerfCastDB dataset demonstrate that MaC achieves superior results compared to existing methods, validating its effectiveness. Furthermore, we have open-sourced part of the dataset and the MaC code at \\url{this https URL} to facilitate the subsequent research.         ",
    "url": "https://arxiv.org/abs/2410.19297",
    "authors": [
      "Xiaoman Liu"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2410.19307",
    "title": "Semi-supervised Chinese Poem-to-Painting Generation via Cycle-consistent Adversarial Networks",
    "abstract": "           Classical Chinese poetry and painting represent the epitome of artistic expression, but the abstract and symbolic nature of their relationship poses a significant challenge for computational translation. Most existing methods rely on large-scale paired datasets, which are scarce in this domain. In this work, we propose a semi-supervised approach using cycle-consistent adversarial networks to leverage the limited paired data and large unpaired corpus of poems and paintings. The key insight is to learn bidirectional mappings that enforce semantic alignment between the visual and textual modalities. We introduce novel evaluation metrics to assess the quality, diversity, and consistency of the generated poems and paintings. Extensive experiments are conducted on a new Chinese Painting Description Dataset (CPDD). The proposed model outperforms previous methods, showing promise in capturing the symbolic essence of artistic expression. Codes are available online \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2410.19307",
    "authors": [
      "Zhengyang Lu",
      "Tianhao Guo",
      "Feng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2410.19346",
    "title": "AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios",
    "abstract": "           Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning.         ",
    "url": "https://arxiv.org/abs/2410.19346",
    "authors": [
      "Xinyi Mou",
      "Jingcong Liang",
      "Jiayu Lin",
      "Xinnong Zhang",
      "Xiawei Liu",
      "Shiyue Yang",
      "Rong Ye",
      "Lei Chen",
      "Haoyu Kuang",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2410.19349",
    "title": "pEBR: A Probabilistic Approach to Embedding Based Retrieval",
    "abstract": "           Embedding retrieval aims to learn a shared semantic representation space for both queries and items, thus enabling efficient and effective item retrieval using approximate nearest neighbor (ANN) algorithms. In current industrial practice, retrieval systems typically retrieve a fixed number of items for different queries, which actually leads to insufficient retrieval (low recall) for head queries and irrelevant retrieval (low precision) for tail queries. Mostly due to the trend of frequentist approach to loss function designs, till now there is no satisfactory solution to holistically address this challenge in the industry. In this paper, we move away from the frequentist approach, and take a novel \\textbf{p}robabilistic approach to \\textbf{e}mbedding \\textbf{b}ased \\textbf{r}etrieval (namely \\textbf{pEBR}) by learning the item distribution for different queries, which enables a dynamic cosine similarity threshold calculated by the probabilistic cumulative distribution function (CDF) value. The experimental results show that our approach improves both the retrieval precision and recall significantly. Ablation studies also illustrate how the probabilistic approach is able to capture the differences between head and tail queries.         ",
    "url": "https://arxiv.org/abs/2410.19349",
    "authors": [
      "Han Zhang",
      "Yunjing Jiang",
      "Mingming Li",
      "Haowei Yuan",
      "Wen-Yun Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19352",
    "title": "Interpreting Neural Networks through Mahalanobis Distance",
    "abstract": "           This paper introduces a theoretical framework that connects neural network linear layers with the Mahalanobis distance, offering a new perspective on neural network interpretability. While previous studies have explored activation functions primarily for performance optimization, our work interprets these functions through statistical distance measures, a less explored area in neural network research. By establishing this connection, we provide a foundation for developing more interpretable neural network models, which is crucial for applications requiring transparency. Although this work is theoretical and does not include empirical data, the proposed distance-based interpretation has the potential to enhance model robustness, improve generalization, and provide more intuitive explanations of neural network decisions.         ",
    "url": "https://arxiv.org/abs/2410.19352",
    "authors": [
      "Alan Oursland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.19360",
    "title": "LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function",
    "abstract": "           This paper proposes a novel approach for designing Single-Parameterized Kolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function (SFunc) constructed from trigonometric functions. Three new SKAN variants are developed: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on the MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and computational efficiency. Specifically, LArctan-SKAN significantly improves test set accuracy over existing models, outperforming all pure KAN variants compared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed MLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore, LArctan-SKAN exhibits remarkable computational efficiency, with a training speed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN, respectively. These results confirm the effectiveness and potential of SKANs constructed with trigonometric functions. The experiment code is available at this https URL .         ",
    "url": "https://arxiv.org/abs/2410.19360",
    "authors": [
      "Zhijie Chen",
      "Xinglin Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19364",
    "title": "The Impact of Train-Test Leakage on Machine Learning-based Android Malware Detection",
    "abstract": "           When machine learning is used for Android malware detection, an app needs to be represented in a numerical format for training and testing. We identify a widespread occurrence of distinct Android apps that have identical or nearly identical app representations. In particular, among app samples in the testing dataset, there can be a significant percentage of apps that have an identical or nearly identical representation to an app in the training dataset. This will lead to a data leakage problem that inflates a machine learning model's performance as measured on the testing dataset. The data leakage not only could lead to overly optimistic perceptions on the machine learning models' ability to generalize beyond the data on which they are trained, in some cases it could also lead to qualitatively different conclusions being drawn from the research. We present two case studies to illustrate this impact. In the first case study, the data leakage inflated the performance results but did not impact the overall conclusions made by the researchers in a qualitative way. In the second case study, the data leakage problem would have led to qualitatively different conclusions being drawn from the research. We further propose a leak-aware scheme to construct a machine learning-based Android malware detector, and show that it can improve upon the overall detection performance.         ",
    "url": "https://arxiv.org/abs/2410.19364",
    "authors": [
      "Guojun Liu",
      "Doina Caragea",
      "Xinming Ou",
      "Sankardas Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.19374",
    "title": "Gaze estimation learning architecture as support to affective, social and cognitive studies in natural human-robot interaction",
    "abstract": "           Gaze is a crucial social cue in any interacting scenario and drives many mechanisms of social cognition (joint and shared attention, predicting human intention, coordination tasks). Gaze direction is an indication of social and emotional functions affecting the way the emotions are perceived. Evidence shows that embodied humanoid robots endowing social abilities can be seen as sophisticated stimuli to unravel many mechanisms of human social cognition while increasing engagement and ecological validity. In this context, building a robotic perception system to automatically estimate the human gaze only relying on robot's sensors is still demanding. Main goal of the paper is to propose a learning robotic architecture estimating the human gaze direction in table-top scenarios without any external hardware. Table-top tasks are largely used in many studies in experimental psychology because they are suitable to implement numerous scenarios allowing agents to collaborate while maintaining a face-to-face interaction. Such an architecture can provide a valuable support in studies where external hardware might represent an obstacle to spontaneous human behaviour, especially in environments less controlled than the laboratory (e.g., in clinical settings). A novel dataset was also collected with the humanoid robot iCub, including images annotated from 24 participants in different gaze conditions.         ",
    "url": "https://arxiv.org/abs/2410.19374",
    "authors": [
      "Maria Lombardi",
      "Elisa Maiettini",
      "Agnieszka Wykowska",
      "Lorenzo Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2410.19375",
    "title": "COMSPLIT: A Communication-Aware Split Learning Design for Heterogeneous IoT Platforms",
    "abstract": "           The significance of distributed learning and inference algorithms in Internet of Things (IoT) network is growing since they flexibly distribute computation load between IoT devices and the infrastructure, enhance data privacy, and minimize latency. However, a notable challenge stems from the influence of communication channel conditions on their performance. In this work, we introduce COMSPLIT: a novel communication-aware design for split learning (SL) and inference paradigm tailored to processing time series data in IoT networks. COMSPLIT provides a versatile framework for deploying adaptable SL in IoT networks affected by diverse channel conditions. In conjunction with the integration of an early-exit strategy, and addressing IoT scenarios containing devices with heterogeneous computational capabilities, COMSPLIT represents a comprehensive design solution for communication-aware SL in IoT networks. Numerical results show superior performance of COMSPLIT compared to vanilla SL approaches (that assume ideal communication channel), demonstrating its ability to offer both design simplicity and adaptability to different channel conditions.         ",
    "url": "https://arxiv.org/abs/2410.19375",
    "authors": [
      "Vukan Ninkovic",
      "Dejan Vukobratovic",
      "Dragisa Miskovic",
      "Marco Zennaro"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19384",
    "title": "Learning Neural Strategy-Proof Matching Mechanism from Examples",
    "abstract": "           Designing effective two-sided matching mechanisms is a major problem in mechanism design, and the goodness of matching cannot always be formulated. The existing work addresses this issue by searching over a parameterized family of mechanisms with certain properties by learning to fit a human-crafted dataset containing examples of preference profiles and matching results. However, this approach does not consider a strategy-proof mechanism, implicitly assumes the number of agents to be a constant, and does not consider the public contextual information of the agents. In this paper, we propose a new parametric family of strategy-proof matching mechanisms by extending the serial dictatorship (SD). We develop a novel attention-based neural network called NeuralSD, which can learn a strategy-proof mechanism from a human-crafted dataset containing public contextual information. NeuralSD is constructed by tensor operations that make SD differentiable and learns a parameterized mechanism by estimating an order of SD from the contextual information. We conducted experiments to learn a strategy-proof matching from matching examples with different numbers of agents. We demonstrated that our method shows the superiority of learning with context-awareness over a baseline in terms of regression performance and other metrics.         ",
    "url": "https://arxiv.org/abs/2410.19384",
    "authors": [
      "Ryota Maruo",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19394",
    "title": "Analysis of Financial Risk Behavior Prediction Using Deep Learning and Big Data Algorithms",
    "abstract": "           As the complexity and dynamism of financial markets continue to grow, traditional financial risk prediction methods increasingly struggle to handle large datasets and intricate behavior patterns. This paper explores the feasibility and effectiveness of using deep learning and big data algorithms for financial risk behavior prediction. First, the application and advantages of deep learning and big data algorithms in the financial field are analyzed. Then, a deep learning-based big data risk prediction framework is designed and experimentally validated on actual financial datasets. The experimental results show that this method significantly improves the accuracy of financial risk behavior prediction and provides valuable support for risk management in financial institutions. Challenges in the application of deep learning are also discussed, along with potential directions for future research.         ",
    "url": "https://arxiv.org/abs/2410.19394",
    "authors": [
      "Haowei Yang",
      "Zhan Cheng",
      "Zhaoyang Zhang",
      "Yuanshuai Luo",
      "Shuaishuai Huang",
      "Ao Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19410",
    "title": "Embedded Graph Reconstruction under Hausdorff Noise",
    "abstract": "           Filamentary structures (topologically embedded graphs with a metric structure) are ubiquitous in science and engineering. A challenging problem in topological data analysis (TDA) is to reconstruct the topology and geometry of such an underlying (usually unknown) metric graph from possibly noisy data sampled around it. Reeb graphs have recently been successfully employed in abstract metric graph reconstruction under Gromov$\\unicode{x2013}$Hausdorff noise: the sample is assumed to be metrically close to the ground truth. However, such a strong global density assumption is hardly achieved in applications, making the existing Reeb graph-based methods untractible. We relax the density assumption to give provable geometric reconstruction schemes, even when the sample is metrically close only locally. A very different yet more relevant paradigm focuses on the reconstruction of metric graphs$\\unicode{x2014}$embedded in the Euclidean space$\\unicode{x2014}$from Euclidean samples that are only Hausdorff-close. We further extend our methodologies to provide novel, provable guarantees for the successful geometric reconstruction of Euclidean graphs under the Hausdorff noise model. Our technique produces promising results in reconstructing earthquake plate tectonic boundaries from the global earthquake catalog.         ",
    "url": "https://arxiv.org/abs/2410.19410",
    "authors": [
      "Halley Fritze",
      "Sushovan Majhi",
      "Marissa Masden",
      "Atish Mitra",
      "Michael Stickney"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2410.19412",
    "title": "Robust Time Series Causal Discovery for Agent-Based Model Validation",
    "abstract": "           Agent-Based Model (ABM) validation is crucial as it helps ensuring the reliability of simulations, and causal discovery has become a powerful tool in this context. However, current causal discovery methods often face accuracy and robustness challenges when applied to complex and noisy time series data, which is typical in ABM scenarios. This study addresses these issues by proposing a Robust Cross-Validation (RCV) approach to enhance causal structure learning for ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two prominent causal discovery algorithms. These aim to reduce the impact of noise better and give more reliable causal relation results, even with high-dimensional, time-dependent data. The proposed approach is then integrated into an enhanced ABM validation framework, which is designed to handle diverse data and model structures. The approach is evaluated using synthetic datasets and a complex simulated fMRI dataset. The results demonstrate greater reliability in causal structure identification. The study examines how various characteristics of datasets affect the performance of established causal discovery methods. These characteristics include linearity, noise distribution, stationarity, and causal structure density. This analysis is then extended to the RCV method to see how it compares in these different situations. This examination helps confirm whether the results are consistent with existing literature and also reveals the strengths and weaknesses of the novel approaches. By tackling key methodological challenges, the study aims to enhance ABM validation with a more resilient valuation framework presented. These improvements increase the reliability of model-driven decision making processes in complex systems analysis.         ",
    "url": "https://arxiv.org/abs/2410.19412",
    "authors": [
      "Gene Yu",
      "Ce Guo",
      "Wayne Luk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Econometrics (econ.EM)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2410.19427",
    "title": "Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models",
    "abstract": "           Backdoor attacks covertly implant triggers into deep neural networks (DNNs) by poisoning a small portion of the training data with pre-designed backdoor triggers. This vulnerability is exacerbated in the era of large models, where extensive (pre-)training on web-crawled datasets is susceptible to compromise. In this paper, we introduce a novel two-step defense framework named Expose Before You Defend (EBYD). EBYD unifies existing backdoor defense methods into a comprehensive defense system with enhanced performance. Specifically, EBYD first exposes the backdoor functionality in the backdoored model through a model preprocessing step called backdoor exposure, and then applies detection and removal methods to the exposed model to identify and eliminate the backdoor features. In the first step of backdoor exposure, we propose a novel technique called Clean Unlearning (CUL), which proactively unlearns clean features from the backdoored model to reveal the hidden backdoor features. We also explore various model editing/modification techniques for backdoor exposure, including fine-tuning, model sparsification, and weight perturbation. Using EBYD, we conduct extensive experiments on 10 image attacks and 6 text attacks across 2 vision datasets (CIFAR-10 and an ImageNet subset) and 4 language datasets (SST-2, IMDB, Twitter, and AG's News). The results demonstrate the importance of backdoor exposure for backdoor defense, showing that the exposed models can significantly benefit a range of downstream defense tasks, including backdoor label detection, backdoor trigger recovery, backdoor model detection, and backdoor removal. We hope our work could inspire more research in developing advanced defense frameworks with exposed models. Our code is available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2410.19427",
    "authors": [
      "Yige Li",
      "Hanxun Huang",
      "Jiaming Zhang",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19437",
    "title": "Transductive Learning for Near-Duplicate Image Detection in Scanned Photo Collections",
    "abstract": "           This paper presents a comparative study of near-duplicate image detection techniques in a real-world use case scenario, where a document management company is commissioned to manually annotate a collection of scanned photographs. Detecting duplicate and near-duplicate photographs can reduce the time spent on manual annotation by archivists. This real use case differs from laboratory settings as the deployment dataset is available in advance, allowing the use of transductive learning. We propose a transductive learning approach that leverages state-of-the-art deep learning architectures such as convolutional neural networks (CNNs) and Vision Transformers (ViTs). Our approach involves pre-training a deep neural network on a large dataset and then fine-tuning the network on the unlabeled target collection with self-supervised learning. The results show that the proposed approach outperforms the baseline methods in the task of near-duplicate image detection in the UKBench and an in-house private dataset.         ",
    "url": "https://arxiv.org/abs/2410.19437",
    "authors": [
      "Francesc Net",
      "Marc Folia",
      "Pep Casals",
      "Lluis Gomez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19464",
    "title": "LOCAL: Learning with Orientation Matrix to Infer Causal Structure from Time Series Data",
    "abstract": "           Discovering the underlying Directed Acyclic Graph (DAG) from time series observational data is highly challenging due to the dynamic nature and complex nonlinear interactions between variables. Existing methods often struggle with inefficiency and the handling of high-dimensional data. To address these research gap, we propose LOCAL, a highly efficient, easy-to-implement, and constraint-free method for recovering dynamic causal structures. LOCAL is the first attempt to formulate a quasi-maximum likelihood-based score function for learning the dynamic DAG equivalent to the ground truth. On this basis, we propose two adaptive modules for enhancing the algebraic characterization of acyclicity with new capabilities: Asymptotic Causal Mask Learning (ACML) and Dynamic Graph Parameter Learning (DGPL). ACML generates causal masks using learnable priority vectors and the Gumbel-Sigmoid function, ensuring the creation of DAGs while optimizing computational efficiency. DGPL transforms causal learning into decomposed matrix products, capturing the dynamic causal structure of high-dimensional data and enhancing interpretability. Extensive experiments on synthetic and real-world datasets demonstrate that LOCAL significantly outperforms existing methods, and highlight LOCAL's potential as a robust and efficient method for dynamic causal discovery. Our code will be available soon.         ",
    "url": "https://arxiv.org/abs/2410.19464",
    "authors": [
      "Yue Cheng",
      "Jiajun Zhang",
      "Weiwei Xing",
      "Xiaoyu Guo",
      "Xiaohui Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.19473",
    "title": "A Robust and Efficient Visual-Inertial Initialization with Probabilistic Normal Epipolar Constraint",
    "abstract": "           Accurate and robust initialization is essential for Visual-Inertial Odometry (VIO), as poor initialization can severely degrade pose accuracy. During initialization, it is crucial to estimate parameters such as accelerometer bias, gyroscope bias, initial velocity, and gravity, etc. The IMU sensor requires precise estimation of gyroscope bias because gyroscope bias affects rotation, velocity and position. Most existing VIO initialization methods adopt Structure from Motion (SfM) to solve for gyroscope bias. However, SfM is not stable and efficient enough in fast motion or degenerate scenes. To overcome these limitations, we extended the rotation-translation-decoupling framework by adding new uncertainty parameters and optimization modules. First, we adopt a gyroscope bias optimizer that incorporates probabilistic normal epipolar constraints. Second, we fuse IMU and visual measurements to solve for velocity, gravity, and scale efficiently. Finally, we design an additional refinement module that effectively diminishes gravity and scale errors. Extensive initialization tests on the EuRoC dataset show that our method reduces the gyroscope bias and rotation estimation error by an average of 16% and 4% respectively. It also significantly reduces the gravity error, with an average reduction of 29%.         ",
    "url": "https://arxiv.org/abs/2410.19473",
    "authors": [
      "Changshi Mu",
      "Daquan Feng",
      "Qi Zheng",
      "Yuan Zhuang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2410.19494",
    "title": "Graph Linearization Methods for Reasoning on Graphs with Large Language Models",
    "abstract": "           Large language models have evolved to process multiple modalities beyond text, such as images and audio, which motivates us to explore how to effectively leverage them for graph machine learning tasks. The key question, therefore, is how to transform graphs into linear sequences of tokens, a process we term graph linearization, so that LLMs can handle graphs naturally. We consider that graphs should be linearized meaningfully to reflect certain properties of natural language text, such as local dependency and global alignment, in order to ease contemporary LLMs, trained on trillions of textual tokens, better understand graphs. To achieve this, we developed several graph linearization methods based on graph centrality, degeneracy, and node relabeling schemes. We then investigated their effect on LLM performance in graph reasoning tasks. Experimental results on synthetic graphs demonstrate the effectiveness of our methods compared to random linearization baselines. Our work introduces novel graph representations suitable for LLMs, contributing to the potential integration of graph machine learning with the trend of multi-modal processing using a unified transformer model.         ",
    "url": "https://arxiv.org/abs/2410.19494",
    "authors": [
      "Christos Xypolopoulos",
      "Guokan Shang",
      "Xiao Fei",
      "Giannis Nikolentzos",
      "Hadi Abdine",
      "Iakovos Evdaimon",
      "Michail Chatzianastasis",
      "Giorgos Stamou",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19495",
    "title": "Beyond One Solution: The Case for a Comprehensive Exploration of Solution Space in Community Detection",
    "abstract": "           This article explores the importance of examining the solution space in community detection, highlighting its role in achieving reliable results when dealing with real-world problems. A Bayesian framework is used to estimate the stability of the solution space and classify it into categories Single, Dominant, Multiple, Sparse or Empty. By applying this approach to real-world networks, the study highlights the importance of considering multiple solutions rather than relying on a single partition. This ensures more reliable results and efficient use of computational resources in community detection analysis.         ",
    "url": "https://arxiv.org/abs/2410.19495",
    "authors": [
      "Fabio Morea",
      "Domenico De Stefano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19496",
    "title": "A neural network approach for solving the Monge-Amp\\`ere equation with transport boundary condition",
    "abstract": "           This paper introduces a novel neural network-based approach to solving the Monge-Amp\u00e8re equation with the transport boundary condition, specifically targeted towards optical design applications. We leverage multilayer perceptron networks to learn approximate solutions by minimizing a loss function that encompasses the equation's residual, boundary conditions, and convexity constraints. Our main results demonstrate the efficacy of this method, optimized using L-BFGS, through a series of test cases encompassing symmetric and asymmetric circle-to-circle, square-to-circle, and circle-to-flower reflector mapping problems. Comparative analysis with a conventional least-squares finite-difference solver reveals the competitive, and often superior, performance of our neural network approach on the test cases examined here. A comprehensive hyperparameter study further illuminates the impact of factors such as sampling density, network architecture, and optimization algorithm. While promising, further investigation is needed to verify the method's robustness for more complicated problems and to ensure consistent convergence. Nonetheless, the simplicity and adaptability of this neural network-based approach position it as a compelling alternative to specialized partial differential equation solvers.         ",
    "url": "https://arxiv.org/abs/2410.19496",
    "authors": [
      "Roel Hacking",
      "Lisa Kusch",
      "Koondanibha Mitra",
      "Martijn Anthonissen",
      "Wilbert IJzerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19516",
    "title": "Near-Optimal Deterministic Network Decomposition and Ruling Set, and Improved MIS",
    "abstract": "           This paper improves and in two cases nearly settles, up to logarithmically lower-order factors, the deterministic complexity of some of the most central problems in distributed graph algorithms, which have been studied for over three decades: Near-Optimal Network Decomposition: We present a deterministic distributed algorithm that computes a network decomposition in approximately O(log^2 n) rounds, with O(log n) diameter and O(log n) colors. This round complexity is near-optimal in the following sense: even given an ideal network decomposition, using it (in the standard way) requires round complexity equal to the product of diameter and number of colors, which is known to be approximately Omega(log^2 n). This near-optimality is remarkable, considering the rarity of optimal deterministic distributed algorithms and that for network decomposition, the first polylogarithmic-round algorithm was achieved only recently, by Rozhon and Ghaffari [STOC 2020], after three decades. Near-Optimal Ruling Set: We present a deterministic distributed algorithm that computes an O(log log n) ruling set in approximately O(log n) rounds. This is an exponential improvement over the O(log n) ruling set of Awerbuch, Goldberg, Luby, and Plotkin [FOCS 1989], while almost matching their O(log n) round complexity. Our result's round complexity nearly matches the approximately Omega(log n) lower bound established by Balliu, Brandt, Kuhn, and Olivetti [STOC 2022], which applies to any poly(log log n) ruling set. Improved Maximal Independent Set (MIS): We present a deterministic distributed algorithm for computing an MIS in approximately O(log^(5/3) n) rounds. This improves upon the approximately O(log^2 n) complexity achieved by Ghaffari and Grunau [STOC 2023] and breaks the log-squared barrier necessary for any method based on network decomposition.         ",
    "url": "https://arxiv.org/abs/2410.19516",
    "authors": [
      "Mohsen Ghaffari",
      "Christoph Grunau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2410.19517",
    "title": "Detection of Human and Machine-Authored Fake News in Urdu",
    "abstract": "           The rise of social media has amplified the spread of fake news, now further complicated by large language models (LLMs) like ChatGPT, which ease the generation of highly convincing, error-free misinformation, making it increasingly challenging for the public to discern truth from falsehood. Traditional fake news detection methods relying on linguistic cues also becomes less effective. Moreover, current detectors primarily focus on binary classification and English texts, often overlooking the distinction between machine-generated true vs. fake news and the detection in low-resource languages. To this end, we updated detection schema to include machine-generated news with focus on the Urdu language. We further propose a hierarchical detection strategy to improve the accuracy and robustness. Experiments show its effectiveness across four datasets in various settings.         ",
    "url": "https://arxiv.org/abs/2410.19517",
    "authors": [
      "Muhammad Zain Ali",
      "Yuxia Wang",
      "Bernhard Pfahringer",
      "Tony Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19544",
    "title": "PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation",
    "abstract": "           Analyzing and forecasting trajectories of agents like pedestrians plays a pivotal role for embodied intelligent applications. The inherent indeterminacy of human behavior and complex social interaction among a rich variety of agents make this task more challenging than common time-series forecasting. In this letter, we aim to explore a distinct formulation for multi-agent trajectory prediction framework. Specifically, we proposed a patching-based temporal feature extraction module and a graph-based social feature extraction module, enabling effective feature extraction and cross-scenario generalization. Moreover, we reassess the role of social interaction and present a novel method based on explicit modality modulation to integrate temporal and social features, thereby constructing an efficient single-stage inference pipeline. Results on public benchmark datasets demonstrate the superior performance of our model compared with the state-of-the-art methods. The code is available at: this http URL.         ",
    "url": "https://arxiv.org/abs/2410.19544",
    "authors": [
      "Huajian Liu",
      "Wei Dong",
      "Kunpeng Fan",
      "Chao Wang",
      "Yongzhuo Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19550",
    "title": "DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks",
    "abstract": "           Software defect prediction (SDP) aims to identify high-risk defect modules in software development, optimizing resource allocation. While previous studies show that dependency network metrics improve defect prediction, most methods focus on code-based dependency graphs, overlooking developer factors. Current metrics, based on handcrafted features like ego and global network metrics, fail to fully capture defect-related information. To address this, we propose DeMuVGN, a defect prediction model that learns multi-view software dependency via graph neural networks. We introduce a Multi-view Software Dependency Graph (MSDG) that integrates data, call, and developer dependencies. DeMuVGN also leverages the Synthetic Minority Oversampling Technique (SMOTE) to address class imbalance and enhance defect module identification. In a case study of eight open-source projects across 20 versions, DeMuVGN demonstrates significant improvements: i) models based on multi-view graphs improve F1 scores by 11.1% to 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to 45.8% in within-project contexts and by 17.9% to 41.0% in cross-project contexts. Additionally, DeMuVGN excels in software evolution, showing more improvement in later-stage software versions. Its strong performance across different projects highlights its generalizability. We recommend future research focus on multi-view dependency graphs for defect prediction in both mature and newly developed projects.         ",
    "url": "https://arxiv.org/abs/2410.19550",
    "authors": [
      "Yu Qiao",
      "Lina Gong",
      "Yu Zhao",
      "Yongwei Wang",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19552",
    "title": "GeoLLaVA: Efficient Fine-Tuned Vision-Language Models for Temporal Change Detection in Remote Sensing",
    "abstract": "           Detecting temporal changes in geographical landscapes is critical for applications like environmental monitoring and urban planning. While remote sensing data is abundant, existing vision-language models (VLMs) often fail to capture temporal dynamics effectively. This paper addresses these limitations by introducing an annotated dataset of video frame pairs to track evolving geographical patterns over time. Using fine-tuning techniques like Low-Rank Adaptation (LoRA), quantized LoRA (QLoRA), and model pruning on models such as Video-LLaVA and LLaVA-NeXT-Video, we significantly enhance VLM performance in processing remote sensing temporal changes. Results show significant improvements, with the best performance achieving a BERT score of 0.864 and ROUGE-1 score of 0.576, demonstrating superior accuracy in describing land-use transformations.         ",
    "url": "https://arxiv.org/abs/2410.19552",
    "authors": [
      "Hosam Elgendy",
      "Ahmed Sharshar",
      "Ahmed Aboeitta",
      "Yasser Ashraf",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19556",
    "title": "Mapping leadership and communities in EU-funded research through network analysis",
    "abstract": "           Horizon 2020 and Horizon Europe the EU programs supporting research and innovation through collaboration between companies, academic institutions, and research organisations. This paper introduces a novel methodology using open data on Horizon programs to analyse collaborations, leadership roles, and their evolution, with a focus on the North Adriatic Hydrogen Valley project in the hydrogen energy sector. The methodology employs network analysis, transforming tabular data into weighted networks that represent collaborations between organisations. Centrality measures and community detection algorithms identify influential organisations and stable partnerships over time. To ensure robust and reliable results, the methodology addresses challenges such as input-ordering bias and result variability, while the exploration of the solution space enhances the accuracy of identified collaboration patterns. The case study reveals key leaders and stable communities within the hydrogen energy sector, providing valuable insights for policymakers and organisations fostering innovation through sustained collaborations. The proposed methodology effectively identifies influential organisations and tracks the stability of research collaborations. The insights gained are valuable for policymakers and organisations seeking to foster innovation through sustained partnerships. This approach can be extended to other sectors, offering a framework for understanding the impact of EU research funding on collaboration and leadership dynamics.         ",
    "url": "https://arxiv.org/abs/2410.19556",
    "authors": [
      "Fabio Morea",
      "Alberto Soraci",
      "Domenico De Stefano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19560",
    "title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning",
    "abstract": "           In recent advancements in unsupervised visual representation learning, the Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabeled imagery through an innovative masking strategy. Despite its success, two primary limitations have been identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPA in preventing entire collapse and the inadequacy of I-JEPA prediction in accurately learning the mean of patch representations. Addressing these challenges, this study introduces a novel framework, namely C-JEPA (Contrastive-JEPA), which integrates the Image-based Joint-Embedding Predictive Architecture with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This integration is designed to effectively learn the variance/covariance for preventing entire collapse and ensuring invariance in the mean of augmented views, thereby overcoming the identified limitations. Through empirical and theoretical evaluations, our work demonstrates that C-JEPA significantly enhances the stability and quality of visual representation learning. When pre-trained on the ImageNet-1K dataset, C-JEPA exhibits rapid and improved convergence in both linear probing and fine-tuning performance metrics.         ",
    "url": "https://arxiv.org/abs/2410.19560",
    "authors": [
      "Shentong Mo",
      "Shengbang Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2410.19564",
    "title": "Robotic Learning in your Backyard: A Neural Simulator from Open Source Components",
    "abstract": "           The emergence of 3D Gaussian Splatting for fast and high-quality novel view synthesize has opened up the possibility to construct photo-realistic simulations from video for robotic reinforcement learning. While the approach has been demonstrated in several research papers, the software tools used to build such a simulator remain unavailable or proprietary. We present SplatGym, an open source neural simulator for training data-driven robotic control policies. The simulator creates a photorealistic virtual environment from a single video. It supports ego camera view generation, collision detection, and virtual object in-painting. We demonstrate training several visual navigation policies via reinforcement learning. SplatGym represents a notable first step towards an open-source general-purpose neural environment for robotic learning. It broadens the range of applications that can effectively utilise reinforcement learning by providing convenient and unrestricted tooling, and by eliminating the need for the manual development of conventional 3D environments.         ",
    "url": "https://arxiv.org/abs/2410.19564",
    "authors": [
      "Liyou Zhou",
      "Oleg Sinavski",
      "Athanasios Polydoros"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2410.19589",
    "title": "Energy-Efficiency Architectural Enhancements for Sensing-Enabled Mobile Networks",
    "abstract": "           Sensing will be a key technology in 6G networks, enabling a plethora of new sensing-enabled use cases. Some of the use cases relate to deployments over a wide physical area that needs to be sensed by multiple sensing sources at different locations. The efficient management of the sensing resources is pivotal for sustainable sensing-enabled mobile network designs. In this paper, we provide an example of such use case, and show the energy consumption due to sensing has potential to scale to prohibitive levels. We then propose architectural enhancements to solve this problem, and discuss energy saving and energy efficient strategies in sensing, that can only be properly quantified and applied with the proposed architectural enhancements.         ",
    "url": "https://arxiv.org/abs/2410.19589",
    "authors": [
      "Filipe Conceicao",
      "Filipe B. Teixeira",
      "Luis M. Pessoa",
      "Sebastian Robitzsch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2410.19590",
    "title": "MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors",
    "abstract": "           Perspective projection has been extensively utilized in monocular 3D object detection methods. It introduces geometric priors from 2D bounding boxes and 3D object dimensions to reduce the uncertainty of depth estimation. However, due to depth errors originating from the object's visual surface, the height of the bounding box often fails to represent the actual projected central height, which undermines the effectiveness of geometric depth. Direct prediction for the projected height unavoidably results in a loss of 2D priors, while multi-depth prediction with complex branches does not fully leverage geometric depth. This paper presents a Transformer-based monocular 3D object detection method called MonoDGP, which adopts perspective-invariant geometry errors to modify the projection formula. We also try to systematically discuss and explain the mechanisms and efficacy behind geometry errors, which serve as a simple but effective alternative to multi-depth prediction. Additionally, MonoDGP decouples the depth-guided decoder and constructs a 2D decoder only dependent on visual features, providing 2D priors and initializing object queries without the disturbance of 3D detection. To further optimize and fine-tune input tokens of the transformer decoder, we also introduce a Region Segment Head (RSH) that generates enhanced features and segment embeddings. Our monocular method demonstrates state-of-the-art performance on the KITTI benchmark without extra data. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2410.19590",
    "authors": [
      "Fanqi Pu",
      "Yifan Wang",
      "Jiru Deng",
      "Wenming Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19606",
    "title": "Multi-modal Motion Prediction using Temporal Ensembling with Learning-based Aggregation",
    "abstract": "           Recent years have seen a shift towards learning-based methods for trajectory prediction, with challenges remaining in addressing uncertainty and capturing multi-modal distributions. This paper introduces Temporal Ensembling with Learning-based Aggregation, a meta-algorithm designed to mitigate the issue of missing behaviors in trajectory prediction, which leads to inconsistent predictions across consecutive frames. Unlike conventional model ensembling, temporal ensembling leverages predictions from nearby frames to enhance spatial coverage and prediction diversity. By confirming predictions from multiple frames, temporal ensembling compensates for occasional errors in individual frame predictions. Furthermore, trajectory-level aggregation, often utilized in model ensembling, is insufficient for temporal ensembling due to a lack of consideration of traffic context and its tendency to assign candidate trajectories with incorrect driving behaviors to final predictions. We further emphasize the necessity of learning-based aggregation by utilizing mode queries within a DETR-like architecture for our temporal ensembling, leveraging the characteristics of predictions from nearby frames. Our method, validated on the Argoverse 2 dataset, shows notable improvements: a 4% reduction in minADE, a 5% decrease in minFDE, and a 1.16% reduction in the miss rate compared to the strongest baseline, QCNet, highlighting its efficacy and potential in autonomous driving.         ",
    "url": "https://arxiv.org/abs/2410.19606",
    "authors": [
      "Kai-Yin Hong",
      "Chieh-Chih Wang",
      "Wen-Chieh Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2410.19607",
    "title": "Analyzing Neural Network Robustness Using Graph Curvature",
    "abstract": "           This paper presents a new look at the neural network (NN) robustness problem, from the point of view of graph theory analysis, specifically graph curvature. Graph curvature (e.g., Ricci curvature) has been used to analyze system dynamics and identify bottlenecks in many domains, including road traffic analysis and internet routing. We define the notion of neural Ricci curvature and use it to identify bottleneck NN edges that are heavily used to ``transport data\" to the NN outputs. We provide an evaluation on MNIST that illustrates that such edges indeed occur more frequently for inputs where NNs are less robust. These results will serve as the basis for an alternative method of robust training, by minimizing the number of bottleneck edges.         ",
    "url": "https://arxiv.org/abs/2410.19607",
    "authors": [
      "Shuhang Tan",
      "Jayson Sia",
      "Paul Bogdan",
      "Radoslav Ivanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19627",
    "title": "Knowledge Graph Enhanced Language Agents for Recommendation",
    "abstract": "           Language agents have recently been used to simulate human behavior and user-item interactions for recommendation systems. However, current language agent simulations do not understand the relationships between users and items, leading to inaccurate user profiles and ineffective recommendations. In this work, we explore the utility of Knowledge Graphs (KGs), which contain extensive and reliable relationships between users and items, for recommendation. Our key insight is that the paths in a KG can capture complex relationships between users and items, eliciting the underlying reasons for user preferences and enriching user profiles. Leveraging this insight, we propose Knowledge Graph Enhanced Language Agents(KGLA), a framework that unifies language agents and KG for recommendation systems. In the simulated recommendation scenario, we position the user and item within the KG and integrate KG paths as natural language descriptions into the simulation. This allows language agents to interact with each other and discover sufficient rationale behind their interactions, making the simulation more accurate and aligned with real-world cases, thus improving recommendation performance. Our experimental results show that KGLA significantly improves recommendation performance (with a 33%-95% boost in NDCG@1 among three widely used benchmarks) compared to the previous best baseline method.         ",
    "url": "https://arxiv.org/abs/2410.19627",
    "authors": [
      "Taicheng Guo",
      "Chaochun Liu",
      "Hai Wang",
      "Varun Mannam",
      "Fang Wang",
      "Xin Chen",
      "Xiangliang Zhang",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2410.19639",
    "title": "Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving",
    "abstract": "           Autonomous driving technology has seen significant advancements, but existing models often fail to fully capture the complexity of multi-agent environments, where interactions between dynamic agents are critical. To address this, we propose the Planning-Integrated Forecasting Model (PIFM), a novel framework inspired by neural mechanisms governing decision-making and multi-agent coordination in the brain. PIFM leverages rich contextual information, integrating road structures, traffic rules, and the behavior of surrounding vehicles to improve both the accuracy and interpretability of predictions. By adopting a diffusion-based architecture, akin to neural diffusion processes involved in predicting and planning, PIFM is able to forecast future trajectories of all agents within a scenario. This architecture enhances model transparency, as it parallels the brain's method of dynamically adjusting predictions based on external stimuli and other agents'behaviors. Extensive experiments validate PIFM's capacity to provide interpretable, neuroscience-driven solutions for safer and more efficient autonomous driving systems, with an extremely low number of parameters.         ",
    "url": "https://arxiv.org/abs/2410.19639",
    "authors": [
      "Liu Yunhao",
      "Ding Hong",
      "Zhang Ziming",
      "Wang Huixin",
      "Liu Jinzhao",
      "Xi Suyang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19651",
    "title": "Community detection on directed networks with missing edges",
    "abstract": "           Identifying significant community structures in networks with incomplete data is a challenging task, as the reliability of solutions diminishes with increasing levels of missing information. However, in many empirical contexts, some information about the uncertainty in the network measurements can be estimated. In this work, we extend the recently developed Flow Stability framework, originally designed for detecting communities in time-varying networks, to address the problem of community detection in weighted, directed networks with missing links. Our approach leverages known uncertainty levels in nodes' out-degrees to enhance the robustness of community detection. Through comparisons on synthetic networks and a real-world network of messaging channels on the Telegram platform, we demonstrate that our method delivers more reliable community structures, even when a significant portion of data is missing.         ",
    "url": "https://arxiv.org/abs/2410.19651",
    "authors": [
      "Nicola Pedreschi",
      "Renaud Lambiotte",
      "Alexandre Bovet"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2410.19653",
    "title": "Conformal Prediction for Multimodal Regression",
    "abstract": "           This paper introduces multimodal conformal regression. Traditionally confined to scenarios with solely numerical input features, conformal prediction is now extended to multimodal contexts through our methodology, which harnesses internal features from complex neural network architectures processing images and unstructured text. Our findings highlight the potential for internal neural network features, extracted from convergence points where multimodal information is combined, to be used by conformal prediction to construct prediction intervals (PIs). This capability paves new paths for deploying conformal prediction in domains abundant with multimodal data, enabling a broader range of problems to benefit from guaranteed distribution-free uncertainty quantification.         ",
    "url": "https://arxiv.org/abs/2410.19653",
    "authors": [
      "Alexis Bose",
      "Jonathan Ethier",
      "Paul Guinand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19673",
    "title": "Spatial Shortcuts in Graph Neural Controlled Differential Equations",
    "abstract": "           We incorporate prior graph topology information into a Neural Controlled Differential Equation (NCDE) to predict the future states of a dynamical system defined on a graph. The informed NCDE infers the future dynamics at the vertices of simulated advection data on graph edges with a known causal graph, observed only at vertices during training. We investigate different positions in the model architecture to inform the NCDE with graph information and identify an outer position between hidden state and control as theoretically and empirically favorable. Our such informed NCDE requires fewer parameters to reach a lower Mean Absolute Error (MAE) compared to previous methods that do not incorporate additional graph topology information.         ",
    "url": "https://arxiv.org/abs/2410.19673",
    "authors": [
      "Michael Detzel",
      "Gabriel Nobis",
      "Jackie Ma",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.19680",
    "title": "Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors",
    "abstract": "           It is important to estimate an accurate signed distance function (SDF) from a point cloud in many computer vision applications. The latest methods learn neural SDFs using either a data-driven based or an overfitting-based strategy. However, these two kinds of methods are with either poor generalization or slow convergence, which limits their capability under challenging scenarios like highly noisy point clouds. To resolve this issue, we propose a method to promote pros of both data-driven based and overfitting-based methods for better generalization, faster inference, and higher accuracy in learning neural SDFs. We introduce a novel statistical reasoning algorithm in local regions which is able to finetune data-driven based priors without signed distance supervision, clean point cloud, or point normals. This helps our method start with a good initialization, and converge to a minimum in a much faster way. Our numerical and visual comparisons with the state-of-the-art methods show our superiority over these methods in surface reconstruction and point cloud denoising on widely used shape and scene benchmarks. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2410.19680",
    "authors": [
      "Chao Chen",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19681",
    "title": "Optimizing Hearthstone Agents using an Evolutionary Algorithm",
    "abstract": "           Digital collectible card games are not only a growing part of the video game industry, but also an interesting research area for the field of computational intelligence. This game genre allows researchers to deal with hidden information, uncertainty and planning, among other aspects. This paper proposes the use of evolutionary algorithms (EAs) to develop agents who play a card game, Hearthstone, by optimizing a data-driven decision-making mechanism that takes into account all the elements currently in play. Agents feature self-learning by means of a competitive coevolutionary training approach, whereby no external sparring element defined by the user is required for the optimization process. One of the agents developed through the proposed approach was runner-up (best 6%) in an international Hearthstone Artificial Intelligence (AI) competition. Our proposal performed remarkably well, even when it faced state-of-the-art techniques that attempted to take into account future game states, such as Monte-Carlo Tree search. This outcome shows how evolutionary computation could represent a considerable advantage in developing AIs for collectible card games such as Hearthstone.         ",
    "url": "https://arxiv.org/abs/2410.19681",
    "authors": [
      "Pablo Garc\u00eda-S\u00e1nchez",
      "Alberto Tonda",
      "Antonio J. Fern\u00e1ndez-Leiva",
      "Carlos Cotta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2410.19685",
    "title": "The Sound of Silence in Social Networks",
    "abstract": "           We generalize the classic multi-agent DeGroot model for opinion dynamics to incorporate the Spiral of Silence theory from political science. This theory states that individuals may withhold their opinions when they perceive them to be in the minority. As in the DeGroot model, a community of agents is represented as a weighted directed graph whose edges indicate how much agents influence one another. However, agents whose current opinions are in the minority become silent (i.e., they do not express their opinion). Two models for opinion update are then introduced. In the memoryless opinion model ($\\mbox{SOM}^-$), agents update their opinion by taking the weighted average of their non-silent neighbors' opinions. In the memory based opinion model ($\\mbox{SOM}^+$), agents update their opinions by taking the weighted average of the opinions of all their neighbors, but for silent neighbors, their most recent opinion is considered. We show that for $\\mbox{SOM}^-$ convergence to consensus is guaranteed for clique graphs but, unlike for the classic DeGroot, not guaranteed for strongly-connected aperiodic graphs. In contrast, we show that for $\\mbox{SOM}^+$ convergence to consensus is not guaranteed even for clique graphs. We showcase our models through simulations offering experimental insights that align with key aspects of the Spiral of Silence theory. These findings reveal the impact of silence dynamics on opinion formation and highlight the limitations of consensus in more nuanced social models.         ",
    "url": "https://arxiv.org/abs/2410.19685",
    "authors": [
      "Jes\u00fas Aranda",
      "Juan Francisco D\u00edaz",
      "David Gaona",
      "Frank Valencia"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.19696",
    "title": "Age of Coded Updates In Gossip Networks Under Memory and Memoryless Schemes",
    "abstract": "           We consider an information update system on a gossip network, where a source node encodes information into $n$ total keys such that any subset of at least $k+1$ keys can fully reconstruct the original information. This encoding process follows the principles of a $k$-out-of-$n$ threshold system. The encoded updates are then disseminated across the network through peer-to-peer communication. We have two different types of nodes in a network: subscriber nodes, which receive a unique key from the source node for every status update instantaneously, and nonsubscriber nodes, which receive a unique key for an update only if the node is selected by the source, and this selection is renewed for each update. For the message structure between nodes, we consider two different schemes: a memory scheme (in which the nodes keep the source's current and previous encrypted messages) and a memoryless scheme (in which the nodes are allowed to only keep the source's current message). We measure the timeliness of information updates by using a recent performance metric, the version age of information. We present explicit formulas for the time average AoI in a scalable homogeneous network as functions of the network parameters under a memoryless scheme. Additionally, we provide strict lower and upper bounds for the time average AoI under a memory scheme.         ",
    "url": "https://arxiv.org/abs/2410.19696",
    "authors": [
      "Erkan Bayram",
      "Melih Bastopcu",
      "Mohamed-Ali Belabbas",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2410.19705",
    "title": "Robust Thompson Sampling Algorithms Against Reward Poisoning Attacks",
    "abstract": "           Thompson sampling is one of the most popular learning algorithms for online sequential decision-making problems and has rich real-world applications. However, current Thompson sampling algorithms are limited by the assumption that the rewards received are uncorrupted, which may not be true in real-world applications where adversarial reward poisoning exists. To make Thompson sampling more reliable, we want to make it robust against adversarial reward poisoning. The main challenge is that one can no longer compute the actual posteriors for the true reward, as the agent can only observe the rewards after corruption. In this work, we solve this problem by computing pseudo-posteriors that are less likely to be manipulated by the attack. We propose robust algorithms based on Thompson sampling for the popular stochastic and contextual linear bandit settings in both cases where the agent is aware or unaware of the budget of the attacker. We theoretically show that our algorithms guarantee near-optimal regret under any attack strategy.         ",
    "url": "https://arxiv.org/abs/2410.19705",
    "authors": [
      "Yinglun Xu",
      "Zhiwei Wang",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19708",
    "title": "Integrating LoRaWAN with Mobile Ad-hoc Networks for Enhanced Campus Communication",
    "abstract": "           The integration of Long Range Wide Area Network (LoRaWAN) with Mobile Ad-hoc Networks (MANETs) presents a promising solution for enhancing communication networks within campus environments. This paper explores the unique advantages of combining these two technologies, including scalability, energy efficiency, flexibility, and support for diverse applications. LoRaWAN low power consumption and extended range capabilities address the challenges of traditional communication methods, enabling reliable data transmission across various campus scenarios, such as emergency alerts, event coordination, and real-time monitoring. We also identify key challenges faced in this integrated architecture, including signal interference, data packet collisions, and energy management. By providing a comprehensive survey of existing techniques and solutions categorized by the network protocol stack layers, this study aims to inform future research and development efforts in creating robust, energy efficient communication systems tailored for modern educational institutions. Ultimately, the findings highlight the potential of LoRaWAN MANET architectures to transform campus communication into a more reliable, adaptable, and cost effective framework.         ",
    "url": "https://arxiv.org/abs/2410.19708",
    "authors": [
      "Ramakant Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2410.19715",
    "title": "Adversarial Environment Design via Regret-Guided Diffusion Models",
    "abstract": "           Training agents that are robust to environmental changes remains a significant challenge in deep reinforcement learning (RL). Unsupervised environment design (UED) has recently emerged to address this issue by generating a set of training environments tailored to the agent's capabilities. While prior works demonstrate that UED has the potential to learn a robust policy, their performance is constrained by the capabilities of the environment generation. To this end, we propose a novel UED algorithm, adversarial environment design via regret-guided diffusion models (ADD). The proposed method guides the diffusion-based environment generator with the regret of the agent to produce environments that the agent finds challenging but conducive to further improvement. By exploiting the representation power of diffusion models, ADD can directly generate adversarial environments while maintaining the diversity of training environments, enabling the agent to effectively learn a robust policy. Our experimental results demonstrate that the proposed method successfully generates an instructive curriculum of environments, outperforming UED baselines in zero-shot generalization across novel, out-of-distribution environments. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2410.19715",
    "authors": [
      "Hojun Chung",
      "Junseo Lee",
      "Minsoo Kim",
      "Dohyeong Kim",
      "Songhwai Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.19717",
    "title": "Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning",
    "abstract": "           Traditional intrusion detection systems (IDSs) often rely on either network traffic or process data, but this single-source approach may miss complex attack patterns that span multiple layers within industrial control systems (ICSs) or persistent threats that target different layers of operational technology systems. This study investigates whether combining both network and process data can improve attack detection in ICSs environments. Leveraging the SWaT dataset, we evaluate various machine learning models on individual and combined data sources. Our findings suggest that integrating network traffic with operational process data can enhance detection capabilities, evidenced by improved recall rates for cyber attack classification. Serving as a proof-of-concept within a limited testing environment, this research explores the feasibility of advancing intrusion detection through a multi-source data approach in ICSs. Although the results are promising, they are preliminary and highlight the need for further studies across diverse datasets and refined methodologies.         ",
    "url": "https://arxiv.org/abs/2410.19717",
    "authors": [
      "Vegard Berge",
      "Chunlei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.19722",
    "title": "Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection",
    "abstract": "           The early detection of potential failures in industrial machinery components is paramount for ensuring the reliability and safety of operations, thereby preserving Machine Condition Monitoring (MCM). This research addresses this imperative by introducing an innovative approach to Real-Time Acoustic Anomaly Detection. Our method combines semi-supervised temporal convolution with representation learning and a hybrid model strategy with Temporal Convolutional Networks (TCN) to handle various intricate anomaly patterns found in acoustic data effectively. The proposed model demonstrates superior performance compared to established research in the field, underscoring the effectiveness of this approach. Not only do we present quantitative evidence of its superiority, but we also employ visual representations, such as t-SNE plots, to further substantiate the model's efficacy.         ",
    "url": "https://arxiv.org/abs/2410.19722",
    "authors": [
      "Sahan Dissanayaka",
      "Manjusri Wickramasinghe",
      "Pasindu Marasinghe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2410.19723",
    "title": "Sparse Decomposition of Graph Neural Networks",
    "abstract": "           Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \\emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks.         ",
    "url": "https://arxiv.org/abs/2410.19723",
    "authors": [
      "Yaochen Hu",
      "Mai Zeng",
      "Ge Zhang",
      "Pavel Rumiantsev",
      "Liheng Ma",
      "Yingxue Zhang",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.18985",
    "title": "rECGnition_v1.0: Arrhythmia detection using cardiologist-inspired multi-modal architecture incorporating demographic attributes in ECG",
    "abstract": "           A substantial amount of variability in ECG manifested due to patient characteristics hinders the adoption of automated analysis algorithms in clinical practice. None of the ECG annotators developed till date consider the characteristics of the patients in a multi-modal architecture. We employed the XGBoost model to analyze the UCI Arrhythmia dataset, linking patient characteristics to ECG morphological changes. The model accurately classified patient gender using discriminative ECG features with 87.75% confidence. We propose a novel multi-modal methodology for ECG analysis and arrhythmia classification that can help defy the variability in ECG related to patient-specific conditions. This deep learning algorithm, named rECGnition_v1.0 (robust ECG abnormality detection Version 1), fuses Beat Morphology with Patient Characteristics to create a discriminative feature map that understands the internal correlation between both modalities. A Squeeze and Excitation based Patient characteristic Encoding Network (SEPcEnet) has been introduced, considering the patient's demographics. The trained model outperformed the various existing algorithms by achieving the overall F1-score of 0.986 for the ten arrhythmia class classification in the MITDB and achieved near perfect prediction scores of ~0.99 for LBBB, RBBB, Premature ventricular contraction beat, Atrial premature beat and Paced beat. Subsequently, the methodology was validated across INCARTDB, EDB and different class groups of MITDB using transfer learning. The generalizability test provided F1-scores of 0.980, 0.946, 0.977, and 0.980 for INCARTDB, EDB, MITDB AAMI, and MITDB Normal vs. Abnormal Classification, respectively. Therefore, with a more enhanced and comprehensive understanding of the patient being examined and their ECG for diverse CVD manifestations, the proposed rECGnition_v1.0 algorithm paves the way for its deployment in clinics.         ",
    "url": "https://arxiv.org/abs/2410.18985",
    "authors": [
      "Shreya Srivastava",
      "Durgesh Kumar",
      "Jatin Bedi",
      "Sandeep Seth",
      "Deepak Sharma"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19027",
    "title": "A Spectral-based Physics-informed Finite Operator Learning for Prediction of Mechanical Behavior of Microstructures",
    "abstract": "           A novel physics-informed operator learning technique based on spectral methods is introduced to model the complex behavior of heterogeneous materials. The Lippmann-Schwinger operator in Fourier space is employed to construct physical constraints with almost no additional overhead, eliminating the need for automatic differentiation. This methodology accelerates the training process by allowing gradient construction on a finite fixed discretization in Fourier space. Later, the spectral physics-informed finite operator learning (SPiFOL) framework is built based on this discretization and trained to map the arbitrary shape of microstructures to their mechanical responses (strain fields) without using any labeled data. The training is done by minimizing equilibrium in Fourier space concerning the macroscopic loading condition, which also guarantees the periodicity. The trained SPiFOL predicts full-field solutions for unseen cases accelerating the conventional fast Fourier transform (FFT) solvers by two orders of magnitude. The accuracy of the SPiFOL is investigated for a wide range of microstructures from dual-phase to multiphase materials and the homogenized stresses computed by SPiFOL show less than 1% error compared to results obtained by conventional FFT solvers. SPiFOL is further enhanced with a Fourier Neural Operator (FNO) to map microstructure to mechanical behavior using only physical equations in Fourier space. Compared to the standard data-driven FNO, SPiFOL shows higher accuracy in predicting stress fields and provides nearly resolution-independent results. Furthermore, the zero-shot-super-resolution feature in heterogeneous domains is investigated. Finally, the effectiveness of SPiFOL as a solver for individual microstructures is demonstrated, highlighting the reduction in solving time when utilizing GPUs.         ",
    "url": "https://arxiv.org/abs/2410.19027",
    "authors": [
      "Ali Harandi",
      "Hooman Danesh",
      "Kevin Linka",
      "Stefanie Reese",
      "Shahed Rezaei"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2410.19075",
    "title": "Parallelization of Network Dynamics Computations in Heterogeneous Distributed Environment",
    "abstract": "           This paper addresses the problem of parallelizing computations to study non-linear dynamics in large networks of non-locally coupled oscillators using heterogeneous computing resources. The proposed approach can be applied to a variety of non-linear dynamics models with runtime specification of parameters and network topologies. Parallelizing the solution of equations for different network elements is performed transparently and, in contrast to available tools, does not require parallel programming from end-users. The runtime scheduler takes into account the performance of computing and communication resources to reduce downtime and to achieve a quasi-optimal parallelizing speed-up. The proposed approach was implemented, and its efficiency is proven by numerous applications for simulating large dynamical networks with 10^3-10^8 elements described by Hodgkin-Huxley, FitzHugh-Nagumo, and Kuramoto models, for investigating pathological synchronization during Parkinson's disease, analyzing multi-stability, for studying chimera and solitary states in 3D networks, etc. All the above computations may be performed using symmetrical multiprocessors, graphic processing units, and a network of workstations within the same run and it was demonstrated that near-linear speed-up can be achieved for large networks. The proposed approach is promising for extension to new hardware like edge-computing devices.         ",
    "url": "https://arxiv.org/abs/2410.19075",
    "authors": [
      "Oleksandr Sudakov",
      "Volodymyr Maistrenko"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Pattern Formation and Solitons (nlin.PS)"
    ]
  },
  {
    "id": "arXiv:2410.19105",
    "title": "Conditional diffusions for neural posterior estimation",
    "abstract": "           Neural posterior estimation (NPE), a simulation-based computational approach for Bayesian inference, has shown great success in situations where posteriors are intractable or likelihood functions are treated as \"black boxes.\" Existing NPE methods typically rely on normalizing flows, which transform a base distributions into a complex posterior by composing many simple, invertible transformations. But flow-based models, while state of the art for NPE, are known to suffer from several limitations, including training instability and sharp trade-offs between representational power and computational cost. In this work, we demonstrate the effectiveness of conditional diffusions as an alternative to normalizing flows for NPE. Conditional diffusions address many of the challenges faced by flow-based methods. Our results show that, across a highly varied suite of benchmarking problems for NPE architectures, diffusions offer improved stability, superior accuracy, and faster training times, even with simpler, shallower models. These gains persist across a variety of different encoder or \"summary network\" architectures, as well as in situations where no summary network is required. The code will be publicly available at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2410.19105",
    "authors": [
      "Tianyu Chen",
      "Vansh Bansal",
      "James G. Scott"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2410.19131",
    "title": "Maximum a Posteriori Inference for Factor Graphs via Benders' Decomposition",
    "abstract": "           Many Bayesian statistical inference problems come down to computing a maximum a-posteriori (MAP) assignment of latent variables. Yet, standard methods for estimating the MAP assignment do not have a finite time guarantee that the algorithm has converged to a fixed point. Previous research has found that MAP inference can be represented in dual form as a linear programming problem with a non-polynomial number of constraints. A Lagrangian relaxation of the dual yields a statistical inference algorithm as a linear programming problem. However, the decision as to which constraints to remove in the relaxation is often heuristic. We present a method for maximum a-posteriori inference in general Bayesian factor models that sequentially adds constraints to the fully relaxed dual problem using Benders' decomposition. Our method enables the incorporation of expressive integer and logical constraints in clustering problems such as must-link, cannot-link, and a minimum number of whole samples allocated to each cluster. Using this approach, we derive MAP estimation algorithms for the Bayesian Gaussian mixture model and latent Dirichlet allocation. Empirical results show that our method produces a higher optimal posterior value compared to Gibbs sampling and variational Bayes methods for standard data sets and provides certificate of convergence.         ",
    "url": "https://arxiv.org/abs/2410.19131",
    "authors": [
      "Harsh Vardhan Dubey",
      "Ji Ah Lee",
      "Patrick Flaherty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19147",
    "title": "Functional Brain Network Identification in Opioid Use Disorder Using Machine Learning Analysis of Resting-State fMRI BOLD Signals",
    "abstract": "           Understanding the neurobiology of opioid use disorder (OUD) using resting-state functional magnetic resonance imaging (rs-fMRI) may help inform treatment strategies to improve patient outcomes. Recent literature suggests temporal characteristics of rs-fMRI blood oxygenation level-dependent (BOLD) signals may offer complementary information to functional connectivity analysis. However, existing studies of OUD analyze BOLD signals using measures computed across all time points. This study, for the first time in the literature, employs data-driven machine learning (ML) modeling of rs-fMRI BOLD features representing multiple time points to identify region(s) of interest that differentiate OUD subjects from healthy controls (HC). Following the triple network model, we obtain rs-fMRI BOLD features from the default mode network (DMN), salience network (SN), and executive control network (ECN) for 31 OUD and 45 HC subjects. Then, we use the Boruta ML algorithm to identify statistically significant BOLD features that differentiate OUD from HC, identifying the DMN as the most salient functional network for OUD. Furthermore, we conduct brain activity mapping, showing heightened neural activity within the DMN for OUD. We perform 5-fold cross-validation classification (OUD vs. HC) experiments to study the discriminative power of functional network features with and without fusing demographic features. The DMN shows the most discriminative power, achieving mean AUC and F1 scores of 80.91% and 73.97%, respectively, when fusing BOLD and demographic features. Follow-up Boruta analysis using BOLD features extracted from the medial prefrontal cortex, posterior cingulate cortex, and left and right temporoparietal junctions reveals significant features for all four functional hubs within the DMN.         ",
    "url": "https://arxiv.org/abs/2410.19147",
    "authors": [
      "Ahmed Temtam",
      "Megan A. Witherow",
      "Liangsuo Ma",
      "M. Shibly Sadique",
      "F. Gerard Moeller",
      "Khan M. Iftekharuddin"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19283",
    "title": "ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study",
    "abstract": "           During and after a course of therapy, imaging is routinely used to monitor the disease progression and assess the treatment responses. Despite of its significance, reliably capturing and predicting the spatial-temporal anatomic changes from a sequence of patient-specific image series presents a considerable challenge. Thus, the development of a computational framework becomes highly desirable for a multitude of practical applications. In this context, we propose a strategy of Spatial-Temporal Neural Representation learning with Prior embedding (ST-NeRP) for patient-specific imaging study. Our strategy involves leveraging an Implicit Neural Representation (INR) network to encode the image at the reference time point into a prior embedding. Subsequently, a spatial-temporally continuous deformation function is learned through another INR network. This network is trained using the whole patient-specific image sequence, enabling the prediction of deformation fields at various target time points. The efficacy of the ST-NeRP model is demonstrated through its application to diverse sequential image series, including 4D CT and longitudinal CT datasets within thoracic and abdominal imaging. The proposed ST-NeRP model exhibits substantial potential in enabling the monitoring of anatomical changes within a patient throughout the therapeutic journey.         ",
    "url": "https://arxiv.org/abs/2410.19283",
    "authors": [
      "Liang Qiu",
      "Liyue Shen",
      "Lianli Liu",
      "Junyan Liu",
      "Yizheng Chen",
      "Lei Xing"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19323",
    "title": "Double Difference Earthquake Location with Graph Neural Networks",
    "abstract": "           Double difference earthquake relocation is an essential component of many earthquake catalog development workflows. This technique produces high-resolution relative relocations between events by minimizing differential measurements of the arrival times of waves from nearby sources, which highlights the resolution of faults and improves interpretation of seismic activity. The inverse problem is typically solved iteratively using conjugate-gradient minimization, however the cost scales significantly with the total number of sources and stations considered. Here we propose a Graph Neural Network (GNN) based earthquake double-difference relocation framework, Graph Double Difference (GraphDD), that is trained to minimize the double-difference residuals of a catalog to locate earthquakes. Through batching and sampling the method can scale to arbitrarily large catalogs. Our architecture uses one graph to represent the stations, a second graph to represent the sources, and creates the Cartesian product graph between the two graphs to capture the relationships between the stations and sources (e.g., the residuals and travel time partial derivatives). This key feature allows a natural architecture that can be used to minimize the double-difference residuals. We implement our model on several distinct test cases including seismicity from northern California, Turkiye, and northern Chile, which have highly variable data quality, and station and source distributions. We obtain high resolution relocations in these tests, and our model shows adaptability to variable types of loss functions and location objectives, including learning station corrections and mapping into the reference frame of a different catalog. Our results suggest that a GNN approach to double-difference relocation is a promising direction for scaling to very large catalogs and gaining new insights into the relocation problem.         ",
    "url": "https://arxiv.org/abs/2410.19323",
    "authors": [
      "Ian W. McBrearty",
      "Gregory C. Beroza"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19332",
    "title": "Beyond Point Annotation: A Weakly Supervised Network Guided by Multi-Level Labels Generated from Four-Point Annotation for Thyroid Nodule Segmentation in Ultrasound Image",
    "abstract": "           Weakly-supervised methods typically guided the pixel-wise training by comparing the predictions to single-level labels containing diverse segmentation-related information at once, but struggled to represent delicate feature differences between nodule and background regions and confused incorrect information, resulting in underfitting or overfitting in the segmentation predictions. In this work, we propose a weakly-supervised network that generates multi-level labels from four-point annotation to refine diverse constraints for delicate nodule segmentation. The Distance-Similarity Fusion Prior referring to the points annotations filters out information irrelevant to nodules. The bounding box and pure foreground/background labels, generated from the point annotation, guarantee the rationality of the prediction in the arrangement of target localization and the spatial distribution of target/background regions, respectively. Our proposed network outperforms existing weakly-supervised methods on two public datasets with respect to the accuracy and robustness, improving the applicability of deep-learning based segmentation in the clinical practice of thyroid nodule diagnosis.         ",
    "url": "https://arxiv.org/abs/2410.19332",
    "authors": [
      "Jianning Chi",
      "Zelan Li",
      "Huixuan Wu",
      "Wenjun Zhang",
      "Ying Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19348",
    "title": "How high dimensional neural dynamics are confined in phase space",
    "abstract": "           High dimensional dynamics play a vital role in brain function, ecological systems, and neuro-inspired machine learning. Where and how these dynamics are confined in the phase space remains challenging to solve. Here, we provide an analytic argument that the confinement region is an M-shape when the neural dynamics show a diversity, with two sharp boundaries and a flat low-density region in between. Despite increasing synaptic strengths in a neural circuit, the shape remains qualitatively the same, while the left boundary is continuously pushed away. However, in deep chaotic regions, an arch-shaped confinement gradually emerges. Our theory is supported by numerical simulations on finite-sized networks. This analytic theory opens up a geometric route towards addressing fundamental questions about high dimensional non-equilibrium dynamics.         ",
    "url": "https://arxiv.org/abs/2410.19348",
    "authors": [
      "Shishe Wang",
      "Haiping Huang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2410.19469",
    "title": "Unified Causality Analysis Based on the Degrees of Freedom",
    "abstract": "           Temporally evolving systems are typically modeled by dynamic equations. A key challenge in accurate modeling is understanding the causal relationships between subsystems, as well as identifying the presence and influence of unobserved hidden drivers on the observed dynamics. This paper presents a unified method capable of identifying fundamental causal relationships between pairs of systems, whether deterministic or stochastic. Notably, the method also uncovers hidden common causes beyond the observed variables. By analyzing the degrees of freedom in the system, our approach provides a more comprehensive understanding of both causal influence and hidden confounders. This unified framework is validated through theoretical models and simulations, demonstrating its robustness and potential for broader application.         ",
    "url": "https://arxiv.org/abs/2410.19469",
    "authors": [
      "Andr\u00e1s Telcs",
      "Marcell T. Kurbucz",
      "Antal Jakov\u00e1c"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2410.19535",
    "title": "Detection of Emerging Infectious Diseases in Lung CT based on Spatial Anomaly Patterns",
    "abstract": "           Fast detection of emerging diseases is important for containing their spread and treating patients effectively. Local anomalies are relevant, but often novel diseases involve familiar disease patterns in new spatial distributions. Therefore, established local anomaly detection approaches may fail to identify them as new. Here, we present a novel approach to detect the emergence of new disease phenotypes exhibiting distinct patterns of the spatial distribution of lesions. We first identify anomalies in lung CT data, and then compare their distribution in a continually acquired new patient cohorts with historic patient population observed over a long prior period. We evaluate how accumulated evidence collected in the stream of patients is able to detect the onset of an emerging disease. In a gram-matrix based representation derived from the intermediate layers of a three-dimensional convolutional neural network, newly emerging clusters indicate emerging diseases.         ",
    "url": "https://arxiv.org/abs/2410.19535",
    "authors": [
      "Branko Mitic",
      "Philipp Seeb\u00f6ck",
      "Jennifer Straub",
      "Helmut Prosch",
      "Georg Langs"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.19568",
    "title": "Prediction of microstructural representativity from a single image",
    "abstract": "           In this study, we present a method for predicting the representativity of the phase fraction observed in a single image (2D or 3D) of a material. Traditional approaches often require large datasets and extensive statistical analysis to estimate the Integral Range, a key factor in determining the variance of microstructural properties. Our method leverages the Two-Point Correlation function to directly estimate the variance from a single image (2D or 3D), thereby enabling phase fraction prediction with associated confidence levels. We validate our approach using open-source datasets, demonstrating its efficacy across diverse microstructures. This technique significantly reduces the data requirements for representativity analysis, providing a practical tool for material scientists and engineers working with limited microstructural data. To make the method easily accessible, we have created a web-application, \\url{this http URL}, for quick, simple and informative use of the method.         ",
    "url": "https://arxiv.org/abs/2410.19568",
    "authors": [
      "Amir Dahari",
      "Ronan Docherty",
      "Steve Kench",
      "Samuel J. Cooper"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2410.19575",
    "title": "Considerations for Distribution Shift Robustness of Diagnostic Models in Healthcare",
    "abstract": "           We consider robustness to distribution shifts in the context of diagnostic models in healthcare, where the prediction target $Y$, e.g., the presence of a disease, is causally upstream of the observations $X$, e.g., a biomarker. Distribution shifts may occur, for instance, when the training data is collected in a domain with patients having particular demographic characteristics while the model is deployed on patients from a different demographic group. In the domain of applied ML for health, it is common to predict $Y$ from $X$ without considering further information about the patient. However, beyond the direct influence of the disease $Y$ on biomarker $X$, a predictive model may learn to exploit confounding dependencies (or shortcuts) between $X$ and $Y$ that are unstable under certain distribution shifts. In this work, we highlight a data generating mechanism common to healthcare settings and discuss how recent theoretical results from the causality literature can be applied to build robust predictive models. We theoretically show why ignoring covariates as well as common invariant learning approaches will in general not yield robust predictors in the studied setting, while including certain covariates into the prediction model will. In an extensive simulation study, we showcase the robustness (or lack thereof) of different predictors under various data generating processes. Lastly, we analyze the performance of the different approaches using the PTB-XL dataset, a public dataset of annotated ECG recordings.         ",
    "url": "https://arxiv.org/abs/2410.19575",
    "authors": [
      "Arno Blaas",
      "Adam Goli\u0144ski",
      "Andrew Miller",
      "Luca Zappella",
      "J\u00f6rn-Henrik Jacobsen",
      "Christina Heinze-Deml"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19704",
    "title": "Multi-view biomedical foundation models for molecule-target and property prediction",
    "abstract": "           Foundation models applied to bio-molecular space hold promise to accelerate drug discovery. Molecular representation is key to building such models. Previous works have typically focused on a single representation or view of the molecules. Here, we develop a multi-view foundation model approach, that integrates molecular views of graph, image and text. Single-view foundation models are each pre-trained on a dataset of up to 200M molecules and then aggregated into combined representations. Our multi-view model is validated on a diverse set of 18 tasks, encompassing ligand-protein binding, molecular solubility, metabolism and toxicity. We show that the multi-view models perform robustly and are able to balance the strengths and weaknesses of specific views. We then apply this model to screen compounds against a large (>100 targets) set of G Protein-Coupled receptors (GPCRs). From this library of targets, we identify 33 that are related to Alzheimer's disease. On this subset, we employ our model to identify strong binders, which are validated through structure-based modeling and identification of key binding motifs.         ",
    "url": "https://arxiv.org/abs/2410.19704",
    "authors": [
      "Parthasarathy Suryanarayanan",
      "Yunguang Qiu",
      "Shreyans Sethi",
      "Diwakar Mahajan",
      "Hongyang Li",
      "Yuxin Yang",
      "Elif Eyigoz",
      "Aldo Guzman Saenz",
      "Daniel E. Platt",
      "Timothy H. Rumbell",
      "Kenney Ng",
      "Sanjoy Dey",
      "Myson Burch",
      "Bum Chul Kwon",
      "Pablo Meyer",
      "Feixiong Cheng",
      "Jianying Hu",
      "Joseph A. Morrone"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19718",
    "title": "Evolving Neural Networks Reveal Emergent Collective Behavior from Minimal Agent Interactions",
    "abstract": "           Understanding the mechanisms behind emergent behaviors in multi-agent systems is critical for advancing fields such as swarm robotics and artificial intelligence. In this study, we investigate how neural networks evolve to control agents' behavior in a dynamic environment, focusing on the relationship between the network's complexity and collective behavior patterns. By performing quantitative and qualitative analyses, we demonstrate that the degree of network non-linearity correlates with the complexity of emergent behaviors. Simpler behaviors, such as lane formation and laminar flow, are characterized by more linear network operations, while complex behaviors like swarming and flocking show highly non-linear neural processing. Moreover, specific environmental parameters, such as moderate noise, broader field of view, and lower agent density, promote the evolution of non-linear networks that drive richer, more intricate collective behaviors. These results highlight the importance of tuning evolutionary conditions to induce desired behaviors in multi-agent systems, offering new pathways for optimizing coordination in autonomous swarms. Our findings contribute to a deeper understanding of how neural mechanisms influence collective dynamics, with implications for the design of intelligent, self-organizing systems.         ",
    "url": "https://arxiv.org/abs/2410.19718",
    "authors": [
      "Guilherme S. Y. Giardini",
      "John F. Hardy II",
      "Carlo R. da Cunha"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2205.06451",
    "title": "Towards Understanding the Link Between Modularity and Performance in Neural Networks for Reinforcement Learning",
    "abstract": "           Modularity has been widely studied as a mechanism to improve the capabilities of neural networks through various techniques such as hand-crafted modular architectures and automatic approaches. While these methods have sometimes shown improvements towards generalisation ability, robustness, and efficiency, the mechanisms that enable modularity to give performance advantages are unclear. In this paper, we investigate this issue and find that the amount of network modularity for optimal performance is likely entangled in complex relationships between many other features of the network and problem environment. Therefore, direct optimisation or arbitrary designation of a suitable amount of modularity in neural networks may not be beneficial. We used a classic neuroevolutionary algorithm which enables rich, automatic optimisation and exploration of neural network architectures and weights with varying levels of modularity. The structural modularity and performance of networks generated by the NeuroEvolution of Augmenting Topologies algorithm was assessed on three reinforcement learning tasks, with and without an additional modularity objective. The results of the quality-diversity optimisation algorithm, MAP-Elites, suggest intricate conditional relationships between modularity, performance, and other predefined network features.         ",
    "url": "https://arxiv.org/abs/2205.06451",
    "authors": [
      "Humphrey Munn",
      "Marcus Gallagher"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.04883",
    "title": "Neural-Rendezvous: Provably Robust Guidance and Control to Encounter Interstellar Objects",
    "abstract": "           Interstellar objects (ISOs) are likely representatives of primitive materials invaluable in understanding exoplanetary star systems. Due to their poorly constrained orbits with generally high inclinations and relative velocities, however, exploring ISOs with conventional human-in-the-loop approaches is significantly challenging. This paper presents Neural-Rendezvous -- a deep learning-based guidance and control framework for encountering fast-moving objects, including ISOs, robustly, accurately, and autonomously in real time. It uses pointwise minimum norm tracking control on top of a guidance policy modeled by a spectrally-normalized deep neural network, where its hyperparameters are tuned with a loss function directly penalizing the MPC state trajectory tracking error. We show that Neural-Rendezvous provides a high probability exponential bound on the expected spacecraft delivery error, the proof of which leverages stochastic incremental stability analysis. In particular, it is used to construct a non-negative function with a supermartingale property, explicitly accounting for the ISO state uncertainty and the local nature of nonlinear state estimation guarantees. In numerical simulations, Neural-Rendezvous is demonstrated to satisfy the expected error bound for 100 ISO candidates. This performance is also empirically validated using our spacecraft simulator and in high-conflict and distributed UAV swarm reconfiguration with up to 20 UAVs.         ",
    "url": "https://arxiv.org/abs/2208.04883",
    "authors": [
      "Hiroyasu Tsukamoto",
      "Soon-Jo Chung",
      "Yashwanth Kumar Nakka",
      "Benjamin Donitz",
      "Declan Mages",
      "Michel Ingham"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.04562",
    "title": "Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity",
    "abstract": "           Community detection is a classic network problem with extensive applications in various fields. Its most common method is using modularity maximization heuristics which rarely return an optimal partition or anything similar. Partitions with globally optimal modularity are difficult to compute, and therefore have been underexplored. Using structurally diverse networks, we compare 30 community detection methods including our proposed algorithm that offers optimality and approximation guarantees: the Bayan algorithm. Unlike existing methods, Bayan globally maximizes modularity or approximates it within a factor. Our results show the distinctive accuracy and stability of maximum-modularity partitions in retrieving planted partitions at rates higher than most alternatives for a wide range of parameter settings in two standard benchmarks. Compared to the partitions from 29 other algorithms, maximum-modularity partitions have the best medians for description length, coverage, performance, average conductance, and well clusteredness. These advantages come at the cost of additional computations which Bayan makes possible for small networks (networks that have up to 3000 edges in their largest connected component). Bayan is several times faster than using open-source and commercial solvers for modularity maximization, making it capable of finding optimal partitions for instances that cannot be optimized by any other existing method. Our results point to a few well performing algorithms, among which Bayan stands out as the most reliable method for small networks. A Python implementation of the Bayan algorithm (bayanpy) is publicly available through the package installer for Python.         ",
    "url": "https://arxiv.org/abs/2209.04562",
    "authors": [
      "Samin Aref",
      "Mahdi Mostajabdaveh",
      "Hriday Chheda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.06689",
    "title": "Self-planning Code Generation with Large Language Models",
    "abstract": "           Although large language models (LLMs) have demonstrated impressive ability in code generation, they are still struggling to address the complicated intent provided by humans. It is widely acknowledged that humans typically employ planning to decompose complex problems and schedule solution steps prior to implementation. To this end, we introduce planning into code generation to help the model understand complex intent and reduce the difficulty of problem-solving. This paper proposes a self-planning code generation approach with large language models, which consists of two phases, namely planning phase and implementation phase. Specifically, in the planning phase, LLM plans out concise solution steps from the intent combined with few-shot prompting. Subsequently, in the implementation phase, the model generates code step by step, guided by the preceding solution steps. We conduct extensive experiments on various code-generation benchmarks across multiple programming languages. Experimental results show that self-planning code generation achieves a relative improvement of up to 25.4% in Pass@1 compared to direct code generation, and up to 11.9% compared to Chain-of-Thought of code generation. Moreover, our self-planning approach also enhances the quality of the generated code with respect to correctness, readability, and robustness, as assessed by humans.         ",
    "url": "https://arxiv.org/abs/2303.06689",
    "authors": [
      "Xue Jiang",
      "Yihong Dong",
      "Lecheng Wang",
      "Zheng Fang",
      "Qiwei Shang",
      "Ge Li",
      "Zhi Jin",
      "Wenpin Jiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.18187",
    "title": "Contrastive-Signal-Dependent Plasticity: Self-Supervised Learning in Spiking Neural Circuits",
    "abstract": "           Brain-inspired machine intelligence research seeks to develop computational models that emulate the information processing and adaptability that distinguishes biological systems of neurons. This has led to the development of spiking neural networks, a class of models that promisingly addresses the biological implausibility and {the lack of energy efficiency} inherent to modern-day deep neural networks. In this work, we address the challenge of designing neurobiologically-motivated schemes for adjusting the synapses of spiking networks and propose contrastive-signal-dependent plasticity, a process which generalizes ideas behind self-supervised learning to facilitate local adaptation in architectures of event-based neuronal layers that operate in parallel. Our experimental simulations demonstrate a consistent advantage over other biologically-plausible approaches when training recurrent spiking networks, crucially side-stepping the need for extra structure such as feedback synapses.         ",
    "url": "https://arxiv.org/abs/2303.18187",
    "authors": [
      "Alexander Ororbia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14252",
    "title": "FLAC: Fairness-Aware Representation Learning by Suppressing Attribute-Class Associations",
    "abstract": "           Bias in computer vision systems can perpetuate or even amplify discrimination against certain populations. Considering that bias is often introduced by biased visual datasets, many recent research efforts focus on training fair models using such data. However, most of them heavily rely on the availability of protected attribute labels in the dataset, which limits their applicability, while label-unaware approaches, i.e., approaches operating without such labels, exhibit considerably lower performance. To overcome these limitations, this work introduces FLAC, a methodology that minimizes mutual information between the features extracted by the model and a protected attribute, without the use of attribute labels. To do that, FLAC proposes a sampling strategy that highlights underrepresented samples in the dataset, and casts the problem of learning fair representations as a probability matching problem that leverages representations extracted by a bias-capturing classifier. It is theoretically shown that FLAC can indeed lead to fair representations, that are independent of the protected attributes. FLAC surpasses the current state-of-the-art on Biased-MNIST, CelebA, and UTKFace, by 29.1%, 18.1%, and 21.9%, respectively. Additionally, FLAC exhibits 2.2% increased accuracy on ImageNet-A and up to 4.2% increased accuracy on Corrupted-Cifar10. Finally, in most experiments, FLAC even outperforms the bias label-aware state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2304.14252",
    "authors": [
      "Ioannis Sarridis",
      "Christos Koutlis",
      "Symeon Papadopoulos",
      "Christos Diou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18512",
    "title": "A Rainbow in Deep Network Black Boxes",
    "abstract": "           A central question in deep learning is to understand the functions learned by deep networks. What is their approximation class? Do the learned weights and representations depend on initialization? Previous empirical work has evidenced that kernels defined by network activations are similar across initializations. For shallow networks, this has been theoretically studied with random feature models, but an extension to deep networks has remained elusive. Here, we provide a deep extension of such random feature models, which we call the rainbow model. We prove that rainbow networks define deterministic (hierarchical) kernels in the infinite-width limit. The resulting functions thus belong to a data-dependent RKHS which does not depend on the weight randomness. We also verify numerically our modeling assumptions on deep CNNs trained on image classification tasks, and show that the trained networks approximately satisfy the rainbow hypothesis. In particular, rainbow networks sampled from the corresponding random feature model achieve similar performance as the trained networks. Our results highlight the central role played by the covariances of network weights at each layer, which are observed to be low-rank as a result of feature learning.         ",
    "url": "https://arxiv.org/abs/2305.18512",
    "authors": [
      "Florentin Guth",
      "Brice M\u00e9nard",
      "Gaspar Rochette",
      "St\u00e9phane Mallat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.07891",
    "title": "Online Matching in Geometric Random Graphs",
    "abstract": "           We investigate online maximum cardinality matching, a central problem in ad allocation. In this problem, users are revealed sequentially, and each new user can be paired with any previously unmatched campaign that it is compatible with. Despite the limited theoretical guarantees, the greedy algorithm, which matches incoming users with any available campaign, exhibits outstanding performance in practice. Some theoretical support for this practical success was established in specific classes of graphs, where the connections between different vertices lack strong correlations - an assumption not always valid. To bridge this gap, we focus on the following model: both users and campaigns are represented as points uniformly distributed in the interval $[0,1]$, and a user is eligible to be paired with a campaign if they are similar enough, i.e. the distance between their respective points is less than $c/N$, with $c>0$ a model parameter. As a benchmark, we determine the size of the optimal offline matching in these bipartite random geometric graphs. In the online setting and investigate the number of matches made by the online algorithm closest, which greedily pairs incoming points with their nearest available neighbors. We demonstrate that the algorithm's performance can be compared to its fluid limit, which is characterized as the solution to a specific partial differential equation (PDE). From this PDE solution, we can compute the competitive ratio of closest, and our computations reveal that it remains significantly better than its worst-case guarantee. This model turns out to be related to the online minimum cost matching problem, and we can extend the results to refine certain findings in that area of research. Specifically, we determine the exact asymptotic cost of closest in the $\\epsilon$-excess regime, providing a more accurate estimate than the previously known loose upper bound.         ",
    "url": "https://arxiv.org/abs/2306.07891",
    "authors": [
      "Flore Sentenac",
      "Nathan Noiry",
      "Matthieu Lerasle",
      "Laurent M\u00e9nard",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.11611",
    "title": "Hate speech detection in algerian dialect using deep learning",
    "abstract": "           With the proliferation of hate speech on social networks under different formats, such as abusive language, cyberbullying, and violence, etc., people have experienced a significant increase in violence, putting them in uncomfortable situations and threats. Plenty of efforts have been dedicated in the last few years to overcome this phenomenon to detect hate speech in different structured languages like English, French, Arabic, and others. However, a reduced number of works deal with Arabic dialects like Tunisian, Egyptian, and Gulf, mainly the Algerian ones. To fill in the gap, we propose in this work a complete approach for detecting hate speech on online Algerian messages. Many deep learning architectures have been evaluated on the corpus we created from some Algerian social networks (Facebook, YouTube, and Twitter). This corpus contains more than 13.5K documents in Algerian dialect written in Arabic, labeled as hateful or non-hateful. Promising results are obtained, which show the efficiency of our approach.         ",
    "url": "https://arxiv.org/abs/2309.11611",
    "authors": [
      "Dihia Lanasri",
      "Juan Olano",
      "Sifal Klioui",
      "Sin Liang Lee",
      "Lamia Sekkai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.02469",
    "title": "Large Language Models Can Be Contextual Privacy Protection Learners",
    "abstract": "           The proliferation of Large Language Models (LLMs) has driven considerable interest in fine-tuning them with domain-specific data to create specialized language models. Nevertheless, such domain-specific fine-tuning data often contains contextually sensitive personally identifiable information (PII). Direct fine-tuning of LLMs on this data without privacy protection poses a risk of data leakage of sensitive PII during inference time. To address this challenge, we introduce Contextual Privacy Protection Language Models (CPPLM), a novel paradigm for fine-tuning LLMs that effectively injects domain-specific knowledge while safeguarding inference-time data privacy. Our work offers a theoretical analysis for model design and benchmarks various techniques such as corpus curation, penalty-based unlikelihood in training loss, instruction-based tuning, etc. Extensive experiments across diverse datasets and scenarios demonstrate the effectiveness of our approaches. In particular, instruction tuning with both positive and negative examples stands out as a promising method, effectively protecting private data while enhancing the model's knowledge. Our work underscores the potential for Large Language Models as robust contextual privacy protection learners. The complete code and data for the work can be found at this https URL.         ",
    "url": "https://arxiv.org/abs/2310.02469",
    "authors": [
      "Yijia Xiao",
      "Yiqiao Jin",
      "Yushi Bai",
      "Yue Wu",
      "Xianjun Yang",
      "Xiao Luo",
      "Wenchao Yu",
      "Xujiang Zhao",
      "Yanchi Liu",
      "Quanquan Gu",
      "Haifeng Chen",
      "Wei Wang",
      "Wei Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.06812",
    "title": "MANSY: Generalizing Neural Adaptive Immersive Video Streaming With Ensemble and Representation Learning",
    "abstract": "           The popularity of immersive videos has prompted extensive research into neural adaptive tile-based streaming to optimize video transmission over networks with limited bandwidth. However, the diversity of users' viewing patterns and Quality of Experience (QoE) preferences has not been fully addressed yet by existing neural adaptive approaches for viewport prediction and bitrate selection. Their performance can significantly deteriorate when users' actual viewing patterns and QoE preferences differ considerably from those observed during the training phase, resulting in poor generalization. In this paper, we propose MANSY, a novel streaming system that embraces user diversity to improve generalization. Specifically, to accommodate users' diverse viewing patterns, we design a Transformer-based viewport prediction model with an efficient multi-viewport trajectory input output architecture based on implicit ensemble learning. Besides, we for the first time combine the advanced representation learning and deep reinforcement learning to train the bitrate selection model to maximize diverse QoE objectives, enabling the model to generalize across users with diverse preferences. Extensive experiments demonstrate that MANSY outperforms state-of-the-art approaches in viewport prediction accuracy and QoE improvement on both trained and unseen viewing patterns and QoE preferences, achieving better generalization.         ",
    "url": "https://arxiv.org/abs/2311.06812",
    "authors": [
      "Duo Wu",
      "Panlong Wu",
      "Miao Zhang",
      "Fangxin Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.01522",
    "title": "G2D: From Global to Dense Radiography Representation Learning via Vision-Language Pre-training",
    "abstract": "           Recently, medical vision-language pre-training (VLP) has reached substantial progress to learn global visual representation from medical images and their paired radiology reports. However, medical imaging tasks in real world usually require finer granularity in visual features. These tasks include visual localization tasks (e.g., semantic segmentation, object detection) and visual grounding task. Yet, current medical VLP methods face challenges in learning these fine-grained features, as they primarily focus on brute-force alignment between image patches and individual text tokens for local visual feature learning, which is suboptimal for downstream dense prediction tasks. In this work, we propose a new VLP framework, named \\textbf{G}lobal to \\textbf{D}ense level representation learning (G2D) that achieves significantly improved granularity and more accurate grounding for the learned features, compared to existing medical VLP approaches. In particular, G2D learns dense and semantically-grounded image representations via a pseudo segmentation task parallel with the global vision-language alignment. Notably, generating pseudo segmentation targets does not incur extra trainable parameters: they are obtained on the fly during VLP with a parameter-free processor. G2D achieves superior performance across 6 medical imaging tasks and 25 diseases, particularly in semantic segmentation, which necessitates fine-grained, semantically-grounded image features. In this task, G2D surpasses peer models even when fine-tuned with just 1\\% of the training data, compared to the 100\\% used by these models. The code can be found in this https URL.         ",
    "url": "https://arxiv.org/abs/2312.01522",
    "authors": [
      "Che Liu",
      "Cheng Ouyang",
      "Sibo Cheng",
      "Anand Shah",
      "Wenjia Bai",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06168",
    "title": "A Novel Planning Framework for Complex Flipping Manipulation of Multiple Mobile Manipulators",
    "abstract": "           During complex object manipulation, manipulator systems often face the configuration disconnectivity problem due to closed-chain constraints. Although regrasping can be adopted to get a piecewise connected manipulation, it is a challenging problem to determine whether there is a planning result without regrasping. To address this problem, a novel planning framework is proposed for multiple mobile manipulator systems. Coordinated platform motions and regrasping motions are proposed to enhance configuration connectivity. Given the object trajectory and the grasping pose set, the planning framework includes three steps. First, inverse kinematics for each mobile manipulator is verified along the given trajectory based on different grasping poses. Coverable trajectory segments are determined for each robot for a specific grasping pose. Second, the trajectory choice problem is formulated into a set cover problem, by which we can quickly determine whether the manipulation can be completed without regrasping or with the minimal regrasping number. Finally, the motions of each mobile manipulator are planned with the assigned trajectory segments using existing methods. Both simulations and experimental results show the performance of the planner in complex flipping manipulation. Additionally, the proposed planner can greatly extend the adaptability of multiple mobile manipulator systems in complex manipulation tasks.         ",
    "url": "https://arxiv.org/abs/2312.06168",
    "authors": [
      "Wenhang Liu",
      "Meng Ren",
      "Kun Song",
      "Michael Yu Wang",
      "Zhenhua Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.07468",
    "title": "CarSpeedNet: A Deep Neural Network-based Car Speed Estimation from Smartphone Accelerometer",
    "abstract": "           We introduce the CarSpeedNet, a deep learning model designed to estimate car speed using three-axis accelerometer data from smartphones. Using 13 hours of data collected from a smartphone in cars across various roads, CarSpeedNet accurately models the relationship between smartphone acceleration and car speed. Ground truth speed data was collected at 1 [Hz] from GPS receivers. The model provides high-frequency speed estimation by incorporating historical data and achieves a precision of less than 0.72 [m/s] during extended driving tests, relying solely on smartphone accelerometer data without any connection to the car.         ",
    "url": "https://arxiv.org/abs/2401.07468",
    "authors": [
      "Barak Or"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05827",
    "title": "On the Robustness of Editing Large Language Models",
    "abstract": "           Large language models (LLMs) have played a pivotal role in building communicative AI, yet they encounter the challenge of efficient updates. Model editing enables the manipulation of specific knowledge memories and the behavior of language generation without retraining. However, the robustness of model editing remains an open question. This work seeks to understand the strengths and limitations of editing methods, facilitating practical applications of communicative AI. We focus on three key research questions. RQ1: Can edited LLMs behave consistently resembling communicative AI in realistic situations? RQ2: To what extent does the rephrasing of prompts lead LLMs to deviate from the edited knowledge memory? RQ3: Which knowledge features are correlated with the performance and robustness of editing? Our empirical studies uncover a substantial disparity between existing editing methods and the practical application of LLMs. On rephrased prompts that are flexible but common in realistic applications, the performance of editing experiences a significant decline. Further analysis shows that more popular knowledge is memorized better, easier to recall, and more challenging to edit effectively. Code is publicly available at this https URL .         ",
    "url": "https://arxiv.org/abs/2402.05827",
    "authors": [
      "Xinbei Ma",
      "Tianjie Ju",
      "Jiyang Qiu",
      "Zhuosheng Zhang",
      "Hai Zhao",
      "Lifeng Liu",
      "Yulong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.16302",
    "title": "Graph Diffusion Policy Optimization",
    "abstract": "           Recent research has made significant progress in optimizing diffusion models for downstream objectives, which is an important pursuit in fields such as graph generation for drug design. However, directly applying these models to graph presents challenges, resulting in suboptimal performance. This paper introduces graph diffusion policy optimization (GDPO), a novel approach to optimize graph diffusion models for arbitrary (e.g., non-differentiable) objectives using reinforcement learning. GDPO is based on an eager policy gradient tailored for graph diffusion models, developed through meticulous analysis and promising improved performance. Experimental results show that GDPO achieves state-of-the-art performance in various graph generation tasks with complex and diverse objectives. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2402.16302",
    "authors": [
      "Yijing Liu",
      "Chao Du",
      "Tianyu Pang",
      "Chongxuan Li",
      "Min Lin",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2402.18153",
    "title": "Diffusion-Based Neural Network Weights Generation",
    "abstract": "           Transfer learning has gained significant attention in recent deep learning research due to its ability to accelerate convergence and enhance performance on new tasks. However, its success is often contingent on the similarity between source and target data, and training on numerous datasets can be costly, leading to blind selection of pretrained models with limited insight into their effectiveness. To address these challenges, we introduce D2NWG, a diffusion-based neural network weights generation technique that efficiently produces high-performing weights for transfer learning, conditioned on the target dataset. Our method extends generative hyper-representation learning to recast the latent diffusion paradigm for neural network weights generation, learning the weight distributions of models pretrained on various datasets. This allows for automatic generation of weights that generalize well across both seen and unseen tasks, outperforming state-of-the-art meta-learning methods and pretrained models. Moreover, our approach is scalable to large architectures such as large language models (LLMs), overcoming the limitations of current parameter generation techniques that rely on task-specific model collections or access to original training data. By modeling the parameter distribution of LLMs, D2NWG enables task-specific parameter generation without requiring additional fine-tuning or large collections of model variants. Extensive experiments show that our method consistently enhances the performance of diverse base models, regardless of their size or complexity, positioning it as a robust solution for scalable transfer learning.         ",
    "url": "https://arxiv.org/abs/2402.18153",
    "authors": [
      "Bedionita Soro",
      "Bruno Andreis",
      "Hayeon Lee",
      "Wonyong Jeong",
      "Song Chong",
      "Frank Hutter",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.00953",
    "title": "AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models",
    "abstract": "           Rare diseases affect millions worldwide but often face limited research focus due to their low prevalence. This results in prolonged diagnoses and a lack of approved therapies. Recent advancements in Large Language Models (LLMs) have shown promise in automating the extraction of medical information, offering potential to improve medical diagnosis and management. However, most LLMs lack professional medical knowledge, especially concerning rare diseases, and struggle to handle the latest rare disease information. They also cannot effectively manage rare disease data and are not directly suitable for diagnosis and management tasks. Our objective is to create an end-to-end system called AutoRD, which automates the extraction of information from medical texts about rare diseases, focusing on entities and their relations. AutoRD integrates up-to-date structured knowledge and demonstrates superior performance in rare disease extraction tasks. We conduct various experiments to evaluate AutoRD's performance, aiming to surpass common LLMs and traditional methods.         ",
    "url": "https://arxiv.org/abs/2403.00953",
    "authors": [
      "Lang Cao",
      "Jimeng Sun",
      "Adam Cross"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.14626",
    "title": "ODTFormer: Efficient Obstacle Detection and Tracking with Stereo Cameras Based on Transformer",
    "abstract": "           Obstacle detection and tracking represent a critical component in robot autonomous navigation. In this paper, we propose ODTFormer, a Transformer-based model to address both obstacle detection and tracking problems. For the detection task, our approach leverages deformable attention to construct a 3D cost volume, which is decoded progressively in the form of voxel occupancy grids. We further track the obstacles by matching the voxels between consecutive frames. The entire model can be optimized in an end-to-end manner. Through extensive experiments on DrivingStereo and KITTI benchmarks, our model achieves state-of-the-art performance in the obstacle detection task. We also report comparable accuracy to state-of-the-art obstacle tracking models while requiring only a fraction of their computation cost, typically ten-fold to twenty-fold less. The code and model weights will be publicly released.         ",
    "url": "https://arxiv.org/abs/2403.14626",
    "authors": [
      "Tianye Ding",
      "Hongyu Li",
      "Huaizu Jiang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15658",
    "title": "Data-Driven Predictive Control for Robust Exoskeleton Locomotion",
    "abstract": "           Exoskeleton locomotion must be robust while being adaptive to different users with and without payloads. To address these challenges, this work introduces a data-driven predictive control (DDPC) framework to synthesize walking gaits for lower-body exoskeletons, employing Hankel matrices and a state transition matrix for its data-driven model. The proposed approach leverages DDPC through a multi-layer architecture. At the top layer, DDPC serves as a planner employing Hankel matrices and a state transition matrix to generate a data-driven model that can learn and adapt to varying users and payloads. At the lower layer, our method incorporates inverse kinematics and passivity-based control to map the planned trajectory from DDPC into the full-order states of the lower-body exoskeleton. We validate the effectiveness of this approach through numerical simulations and hardware experiments conducted on the Atalante lower-body exoskeleton with different payloads. Moreover, we conducted a comparative analysis against the model predictive control (MPC) framework based on the reduced-order linear inverted pendulum (LIP) model. Through this comparison, the paper demonstrates that DDPC enables robust bipedal walking at various velocities while accounting for model uncertainties and unknown perturbations.         ",
    "url": "https://arxiv.org/abs/2403.15658",
    "authors": [
      "Kejun Li",
      "Jeeseop Kim",
      "Xiaobin Xiong",
      "Kaveh Akbari Hamed",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.05894",
    "title": "Learning Heuristics for Transit Network Design and Improvement with Deep Reinforcement Learning",
    "abstract": "           Transit agencies world-wide face tightening budgets. To maintain quality of service while cutting costs, efficient transit network design is essential. But planning a network of public transit routes is a challenging optimization problem. The most successful approaches to date use metaheuristic algorithms to search through the space of possible transit networks by applying low-level heuristics that randomly alter routes in a network. The design of these low-level heuristics has a major impact on the quality of the result. In this paper we use deep reinforcement learning with graph neural nets to learn low-level heuristics for an evolutionary algorithm, instead of designing them manually. These learned heuristics improve the algorithm's results on benchmark synthetic cities with 70 nodes or more, and obtain state-of-the-art results when optimizing operating costs. They also improve upon a simulation of the real transit network in the city of Laval, Canada, by as much as 54% and 18% on two key metrics, and offer cost savings of up to 12% over the city's existing transit network.         ",
    "url": "https://arxiv.org/abs/2404.05894",
    "authors": [
      "Andrew Holliday",
      "Ahmed El-Geneidy",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2404.06939",
    "title": "Late Breaking Results: Fast System Technology Co-Optimization Framework for Emerging Technology Based on Graph Neural Networks",
    "abstract": "           This paper proposes a fast system technology co-optimization (STCO) framework that optimizes power, performance, and area (PPA) for next-generation IC design, addressing the challenges and opportunities presented by novel materials and device architectures. We focus on accelerating the technology level of STCO using AI techniques, by employing graph neural network (GNN)-based approaches for both TCAD simulation and cell library characterization, which are interconnected through a unified compact model, collectively achieving over a 100X speedup over traditional methods. These advancements enable comprehensive STCO iterations with runtime speedups ranging from 1.9X to 14.1X and supports both emerging and traditional technologies.         ",
    "url": "https://arxiv.org/abs/2404.06939",
    "authors": [
      "Tianliang Ma",
      "Guangxi Fan",
      "Xuguang Sun",
      "Zhihui Deng",
      "Kainlu Low",
      "Leilai Shao"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.12115",
    "title": "Characterizing Manipulation Robustness through Energy Margin and Caging Analysis",
    "abstract": "           To develop robust manipulation policies, quantifying robustness is essential. Evaluating robustness in general manipulation, nonetheless, poses significant challenges due to complex hybrid dynamics, combinatorial explosion of possible contact interactions, global geometry, etc. This paper introduces an approach for evaluating manipulation robustness through energy margins and caging-based analysis. Our method assesses manipulation robustness by measuring the energy margin to failure and extends traditional caging concepts for dynamic manipulation. This global analysis is facilitated by a kinodynamic planning framework that naturally integrates global geometry, contact changes, and robot compliance. We validate the effectiveness of our approach in simulation and real-world experiments of multiple dynamic manipulation scenarios, highlighting its potential to predict manipulation success and robustness.         ",
    "url": "https://arxiv.org/abs/2404.12115",
    "authors": [
      "Yifei Dong",
      "Xianyi Cheng",
      "Florian T. Pokorny"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.18525",
    "title": "Enabling Efficient and Flexible Interpretability of Data-driven Anomaly Detection in Industrial Processes with AcME-AD",
    "abstract": "           While Machine Learning has become crucial for Industry 4.0, its opaque nature hinders trust and impedes the transformation of valuable insights into actionable decision, a challenge exacerbated in the evolving Industry 5.0 with its human-centric focus. This paper addresses this need by testing the applicability of AcME-AD in industrial settings. This recently developed framework facilitates fast and user-friendly explanations for anomaly detection. AcME-AD is model-agnostic, offering flexibility, and prioritizes real-time efficiency. Thus, it seems suitable for seamless integration with industrial Decision Support Systems. We present the first industrial application of AcME-AD, showcasing its effectiveness through experiments. These tests demonstrate AcME-AD's potential as a valuable tool for explainable AD and feature-based root cause analysis within industrial environments, paving the way for trustworthy and actionable insights in the age of Industry 5.0.         ",
    "url": "https://arxiv.org/abs/2404.18525",
    "authors": [
      "Valentina Zaccaria",
      "Chiara Masiero",
      "David Dandolo",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.18680",
    "title": "Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits",
    "abstract": "           There has been significant recent interest in graph-based nearest neighbor search methods, many of which are centered on the construction of navigable graphs over high-dimensional point sets. A graph is navigable if we can successfully move from any starting node to any target node using a greedy routing strategy where we always move to the neighbor that is closest to the destination according to a given distance function. The complete graph is navigable for any point set, but the important question for applications is if sparser graphs can be constructed. While this question is fairly well understood in low-dimensions, we establish some of the first upper and lower bounds for high-dimensional point sets. First, we give a simple and efficient way to construct a navigable graph with average degree $O(\\sqrt{n \\log n })$ for any set of $n$ points, in any dimension, for any distance function. We compliment this result with a nearly matching lower bound: even under the Euclidean metric in $O(\\log n)$ dimensions, a random point set has no navigable graph with average degree $O(n^{\\alpha})$ for any $\\alpha < 1/2$. Our lower bound relies on sharp anti-concentration bounds for binomial random variables, which we use to show that the near-neighborhoods of a set of random points do not overlap significantly, forcing any navigable graph to have many edges.         ",
    "url": "https://arxiv.org/abs/2405.18680",
    "authors": [
      "Haya Diwan",
      "Jinrui Gou",
      "Cameron Musco",
      "Christopher Musco",
      "Torsten Suel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.20725",
    "title": "GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search",
    "abstract": "           Gradient Inversion Attacks invert the transmitted gradients in Federated Learning (FL) systems to reconstruct the sensitive data of local clients and have raised considerable privacy concerns. A majority of gradient inversion methods rely heavily on explicit prior knowledge (e.g., a well pre-trained generative model), which is often unavailable in realistic scenarios. To alleviate this issue, researchers have proposed to leverage the implicit prior knowledge of an over-parameterized network. However, they only utilize a fixed neural architecture for all the attack settings. This would hinder the adaptive use of implicit architectural priors and consequently limit the generalizability. In this paper, we further exploit such implicit prior knowledge by proposing Gradient Inversion via Neural Architecture Search (GI-NAS), which adaptively searches the network and captures the implicit priors behind neural architectures. Extensive experiments verify that our proposed GI-NAS can achieve superior attack performance compared to state-of-the-art gradient inversion methods, even under more practical settings with high-resolution images, large-sized batches, and advanced defense strategies.         ",
    "url": "https://arxiv.org/abs/2405.20725",
    "authors": [
      "Wenbo Yu",
      "Hao Fang",
      "Bin Chen",
      "Xiaohang Sui",
      "Chuan Chen",
      "Hao Wu",
      "Shu-Tao Xia",
      "Ke Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.05087",
    "title": "Corpus Poisoning via Approximate Greedy Gradient Descent",
    "abstract": "           Dense retrievers are widely used in information retrieval and have also been successfully extended to other knowledge intensive areas such as language models, e.g., Retrieval-Augmented Generation (RAG) systems. Unfortunately, they have recently been shown to be vulnerable to corpus poisoning attacks in which a malicious user injects a small fraction of adversarial passages into the retrieval corpus to trick the system into returning these passages among the top-ranked results for a broad set of user queries. Further study is needed to understand the extent to which these attacks could limit the deployment of dense retrievers in real-world applications. In this work, we propose Approximate Greedy Gradient Descent (AGGD), a new attack on dense retrieval systems based on the widely used HotFlip method for efficiently generating adversarial passages. We demonstrate that AGGD can select a higher quality set of token-level perturbations than HotFlip by replacing its random token sampling with a more structured search. Experimentally, we show that our method achieves a high attack success rate on several datasets and using several retrievers, and can generalize to unseen queries and new domains. Notably, our method is extremely effective in attacking the ANCE retrieval model, achieving attack success rates that are 15.24\\% and 17.44\\% higher on the NQ and MS MARCO datasets, respectively, compared to HotFlip. Additionally, we demonstrate AGGD's potential to replace HotFlip in other adversarial attacks, such as knowledge poisoning of RAG systems.         ",
    "url": "https://arxiv.org/abs/2406.05087",
    "authors": [
      "Jinyan Su",
      "Preslav Nakov",
      "Claire Cardie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2406.11715",
    "title": "Measuring memorization in RLHF for code completion",
    "abstract": "           Reinforcement learning with human feedback (RLHF) has become the dominant method to align large models to user preferences. Unlike fine-tuning, for which there are many studies regarding training data memorization, it is not clear how memorization is affected by or introduced in the RLHF alignment process. Understanding this relationship is important as real user data may be collected and used to align large models; if user data is memorized during RLHF and later regurgitated, this could raise privacy concerns. In addition to RLHF, other methods such as Direct Preference Optimization (DPO) and $\\Psi$PO have gained popularity for learning directly from human preferences, removing the need for optimizing intermediary reward models with reinforcement learning. In this work, we analyze how training data memorization can surface and propagate through each phase of RLHF and direct preference learning. We focus our study on code completion models, as code completion is one of the most popular use cases for large language models. We find that RLHF significantly decreases the chance that data used for reward modeling and reinforcement learning is memorized in comparison to directly fine-tuning on this data, but that examples already memorized during the fine-tuning stage of RLHF, will, in the majority of cases, remain memorized after RLHF. In contrast, we find that aligning by learning directly from human preference data via a special case of $\\Psi$PO, Identity Preference Optimization (IPO), increases the likelihood that training data is regurgitated compared to RLHF. Our work suggests that RLHF, as opposed to direct preference learning, is a safer way to mitigate the risk of regurgitating sensitive preference data when aligning large language models. We find our conclusions are robust across multiple code completion datasets, tasks, and model scales.         ",
    "url": "https://arxiv.org/abs/2406.11715",
    "authors": [
      "Aneesh Pappu",
      "Billy Porter",
      "Ilia Shumailov",
      "Jamie Hayes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.16386",
    "title": "Automatically Generating UI Code from Screenshot: A Divide-and-Conquer-Based Approach",
    "abstract": "           Websites are critical in today's digital world, with over 1.11 billion currently active and approximately 252,000 new sites launched daily. Converting website layout design into functional UI code is a time-consuming yet indispensable step of website development. Manual methods of converting visual designs into functional code present significant challenges, especially for non-experts. To explore automatic design-to-code solutions, we first conduct a motivating study on GPT-4o and identify three types of issues in generating UI code: element omission, element distortion, and element misarrangement. We further reveal that a focus on smaller visual segments can help multimodal large language models (MLLMs) mitigate these failures in the generation process. In this paper, we propose DCGen, a divide-and-conquer-based approach to automate the translation of webpage design to UI code. DCGen starts by dividing screenshots into manageable segments, generating descriptions for each segment, and then reassembling them into complete UI code for the entire screenshot. We conduct extensive testing with a dataset comprised of real-world websites and various MLLMs and demonstrate that DCGen achieves up to a 14% improvement in visual similarity over competing methods. To the best of our knowledge, DCGen is the first segment-aware prompt-based approach for generating UI code directly from screenshots.         ",
    "url": "https://arxiv.org/abs/2406.16386",
    "authors": [
      "Yuxuan Wan",
      "Chaozheng Wang",
      "Yi Dong",
      "Wenxuan Wang",
      "Shuqing Li",
      "Yintong Huo",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.02062",
    "title": "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?",
    "abstract": "           This work investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks. For the future advance of NER in safety-critical fields like healthcare and finance, it is essential to achieve accurate predictions with calibrated confidence when applying Deep Neural Networks (DNNs), including Pre-trained Language Models (PLMs), as a real-world application. However, DNNs are prone to miscalibration, which limits their applicability. Moreover, existing methods for calibration and uncertainty estimation are computational expensive. Our investigation in NER found that data augmentation improves calibration and uncertainty in cross-genre and cross-lingual setting, especially in-domain setting. Furthermore, we showed that the calibration for NER tends to be more effective when the perplexity of the sentences generated by data augmentation is lower, and that increasing the size of the augmentation further improves calibration and uncertainty.         ",
    "url": "https://arxiv.org/abs/2407.02062",
    "authors": [
      "Wataru Hashimoto",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2407.03386",
    "title": "Visual Robustness Benchmark for Visual Question Answering (VQA)",
    "abstract": "           Can Visual Question Answering (VQA) systems perform just as well when deployed in the real world? Or are they susceptible to realistic corruption effects e.g. image blur, which can be detrimental in sensitive applications, such as medical VQA? While linguistic or textual robustness has been thoroughly explored in the VQA literature, there has yet to be any significant work on the visual robustness of VQA models. We propose the first large-scale benchmark comprising 213,000 augmented images, challenging the visual robustness of multiple VQA models and assessing the strength of realistic visual corruptions. Additionally, we have designed several robustness evaluation metrics that can be aggregated into a unified metric and tailored to fit a variety of use cases. Our experiments reveal several insights into the relationships between model size, performance, and robustness with the visual corruptions. Our benchmark highlights the need for a balanced approach in model development that considers model performance without compromising the robustness.         ",
    "url": "https://arxiv.org/abs/2407.03386",
    "authors": [
      "Md Farhan Ishmam",
      "Ishmam Tashdeed",
      "Talukder Asir Saadat",
      "Md Hamjajul Ashmafee",
      "Abu Raihan Mostofa Kamal",
      "Md. Azam Hossain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.05973",
    "title": "Active Label Refinement for Robust Training of Imbalanced Medical Image Classification Tasks in the Presence of High Label Noise",
    "abstract": "           The robustness of supervised deep learning-based medical image classification is significantly undermined by label noise. Although several methods have been proposed to enhance classification performance in the presence of noisy labels, they face some challenges: 1) a struggle with class-imbalanced datasets, leading to the frequent overlooking of minority classes as noisy samples; 2) a singular focus on maximizing performance using noisy datasets, without incorporating experts-in-the-loop for actively cleaning the noisy labels. To mitigate these challenges, we propose a two-phase approach that combines Learning with Noisy Labels (LNL) and active learning. This approach not only improves the robustness of medical image classification in the presence of noisy labels, but also iteratively improves the quality of the dataset by relabeling the important incorrect labels, under a limited annotation budget. Furthermore, we introduce a novel Variance of Gradients approach in LNL phase, which complements the loss-based sample selection by also sampling under-represented samples. Using two imbalanced noisy medical classification datasets, we demonstrate that that our proposed technique is superior to its predecessors at handling class imbalance by not misidentifying clean samples from minority classes as mostly noisy samples.         ",
    "url": "https://arxiv.org/abs/2407.05973",
    "authors": [
      "Bidur Khanal",
      "Tianhong Dai",
      "Binod Bhattarai",
      "Cristian Linte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.15421",
    "title": "Planning in a recurrent neural network that plays Sokoban",
    "abstract": "           How a neural network (NN) generalizes to novel situations depends on whether it has learned to select actions heuristically or via a planning process. \"An investigation of model-free planning\" (Guez et al. 2019) found that a recurrent NN (RNN) trained to play Sokoban appears to plan, with extra computation steps improving the RNN's success rate. We replicate and expand on their behavioral analysis, finding the RNN learns to give itself extra computation steps in complex situations by \"pacing\" in cycles. Moreover, we train linear probes that predict the future actions taken by the network and find that intervening on the hidden state using these probes controls the agent's subsequent actions. Leveraging these insights, we perform model surgery, enabling the convolutional NN to generalize beyond its 10x10 architectural limit to arbitrarily sized inputs. The resulting model solves challenging, highly off-distribution levels. We open-source our model and code, and believe the neural network's small size (1.29M parameters) makes it an excellent model organism to deepen our understanding of learned planning.         ",
    "url": "https://arxiv.org/abs/2407.15421",
    "authors": [
      "Mohammad Taufeeque",
      "Philip Quirke",
      "Maximilian Li",
      "Chris Cundy",
      "Aaron David Tucker",
      "Adam Gleave",
      "Adri\u00e0 Garriga-Alonso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.17822",
    "title": "Advanced deep-reinforcement-learning methods for flow control: group-invariant and positional-encoding networks improve learning speed and quality",
    "abstract": "           Flow control is key to maximize energy efficiency in a wide range of applications. However, traditional flow-control methods face significant challenges in addressing non-linear systems and high-dimensional data, limiting their application in realistic energy systems. This study advances deep-reinforcement-learning (DRL) methods for flow control, particularly focusing on integrating group-invariant networks and positional encoding into DRL architectures. Our methods leverage multi-agent reinforcement learning (MARL) to exploit policy invariance in space, in combination with group-invariant networks to ensure local symmetry invariance. Additionally, a positional encoding inspired by the transformer architecture is incorporated to provide location information to the agents, mitigating action constraints from strict invariance. The proposed methods are verified using a case study of Rayleigh-B\u00e9nard convection, where the goal is to minimize the Nusselt number Nu. The group-invariant neural networks (GI-NNs) show faster convergence compared to the base MARL, achieving better average policy performance. The GI-NNs not only cut DRL training time in half but also notably enhance learning reproducibility. Positional encoding further enhances these results, effectively reducing the minimum Nu and stabilizing convergence. Interestingly, group invariant networks specialize in improving learning speed and positional encoding specializes in improving learning quality. These results demonstrate that choosing a suitable feature-representation method according to the purpose as well as the characteristics of each control problem is essential. We believe that the results of this study will not only inspire novel DRL methods with invariant and unique representations, but also provide useful insights for industrial applications.         ",
    "url": "https://arxiv.org/abs/2407.17822",
    "authors": [
      "Joongoo Jeon",
      "Jean Rabault",
      "Joel Vasanth",
      "Francisco Alc\u00e1ntara-\u00c1vila",
      "Shilaj Baral",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2408.10368",
    "title": "Deep-MacroFin: Informed Equilibrium Neural Network for Continuous Time Economic Models",
    "abstract": "           In this paper, we present Deep-MacroFin, a comprehensive framework designed to solve partial differential equations, with a particular focus on models in continuous time economics. This framework leverages deep learning methodologies, including conventional Multi-Layer Perceptrons and the newly developed Kolmogorov-Arnold Networks. It is optimized using economic information encapsulated by Hamilton-Jacobi-Bellman equations and coupled algebraic equations. The application of neural networks holds the promise of accurately resolving high-dimensional problems with fewer computational demands and limitations compared to standard numerical methods. This versatile framework can be readily adapted for elementary differential equations, and systems of differential equations, even in cases where the solutions may exhibit discontinuities. Importantly, it offers a more straightforward and user-friendly implementation than existing libraries.         ",
    "url": "https://arxiv.org/abs/2408.10368",
    "authors": [
      "Yuntao Wu",
      "Jiayuan Guo",
      "Goutham Gopalakrishna",
      "Zisis Poulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2409.13770",
    "title": "A constrained optimization approach to improve robustness of neural networks",
    "abstract": "           In this paper, we present a novel nonlinear programming-based approach to fine-tune pre-trained neural networks to improve robustness against adversarial attacks while maintaining high accuracy on clean data. Our method introduces adversary-correction constraints to ensure correct classification of adversarial data and minimizes changes to the model parameters. We propose an efficient cutting-plane-based algorithm to iteratively solve the large-scale nonconvex optimization problem by approximating the feasible region through polyhedral cuts and balancing between robustness and accuracy. Computational experiments on standard datasets such as MNIST and CIFAR10 demonstrate that the proposed approach significantly improves robustness, even with a very small set of adversarial data, while maintaining minimal impact on accuracy.         ",
    "url": "https://arxiv.org/abs/2409.13770",
    "authors": [
      "Shudian Zhao",
      "Jan Kronqvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2410.00713",
    "title": "RAD: A Dataset and Benchmark for Real-Life Anomaly Detection with Robotic Observations",
    "abstract": "           Recent advancements in industrial anomaly detection have been hindered by the lack of realistic datasets that accurately represent real-world conditions. Existing algorithms are often developed and evaluated using idealized datasets, which deviate significantly from real-life scenarios characterized by environmental noise and data corruption such as fluctuating lighting conditions, variable object poses, and unstable camera positions. To address this gap, we introduce the Realistic Anomaly Detection (RAD) dataset, the first multi-view RGB-based anomaly detection dataset specifically collected using a real robot arm, providing unique and realistic data scenarios. RAD comprises 4765 images across 13 categories and 4 defect types, collected from more than 50 viewpoints, providing a comprehensive and realistic benchmark. This multi-viewpoint setup mirrors real-world conditions where anomalies may not be detectable from every perspective. Moreover, by sampling varying numbers of views, the algorithm's performance can be comprehensively evaluated across different viewpoints. This approach enhances the thoroughness of performance assessment and helps improve the algorithm's robustness. Besides, to support 3D multi-view reconstruction algorithms, we propose a data augmentation method to improve the accuracy of pose estimation and facilitate the reconstruction of 3D point clouds. We systematically evaluate state-of-the-art RGB-based and point cloud-based models using RAD, identifying limitations and future research directions. The code and dataset could found at this https URL ",
    "url": "https://arxiv.org/abs/2410.00713",
    "authors": [
      "Kaichen Zhou",
      "Yang Cao",
      "Taewhan Kim",
      "Hao Zhao",
      "Hao Dong",
      "Kai Ming Ting",
      "Ye Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.03306",
    "title": "Selective Test-Time Adaptation for Unsupervised Anomaly Detection using Neural Implicit Representations",
    "abstract": "           Deep learning models in medical imaging often encounter challenges when adapting to new clinical settings unseen during training. Test-time adaptation offers a promising approach to optimize models for these unseen domains, yet its application in anomaly detection (AD) remains largely unexplored. AD aims to efficiently identify deviations from normative distributions; however, full adaptation, including pathological shifts, may inadvertently learn the anomalies it intends to detect. We introduce a novel concept of selective test-time adaptation that utilizes the inherent characteristics of deep pre-trained features to adapt selectively in a zero-shot manner to any test image from an unseen domain. This approach employs a model-agnostic, lightweight multi-layer perceptron for neural implicit representations, enabling the adaptation of outputs from any reconstruction-based AD method without altering the source-trained model. Rigorous validation in brain AD demonstrated that our strategy substantially enhances detection accuracy for multiple conditions and different target distributions. Specifically, our method improves the detection rates by up to 78% for enlarged ventricles and 24% for edemas.         ",
    "url": "https://arxiv.org/abs/2410.03306",
    "authors": [
      "Sameer Ambekar",
      "Julia A. Schnabel",
      "Cosmin I. Bercea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.04663",
    "title": "Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates",
    "abstract": "           This paper explores optimal architectures for evaluating the outputs of large language models (LLMs) using LLMs themselves. We propose a novel framework that interprets LLMs as advocates within an ensemble of interacting agents, allowing them to defend their answers and reach conclusions through a judge and jury system. This approach offers a more dynamic and comprehensive evaluation process compared to traditional human-based assessments or automated metrics. We discuss the motivation behind this framework, its key components, and comparative advantages. We also present a probabilistic model to evaluate the error reduction achieved by iterative advocate systems. Finally, we outline experiments to validate the effectiveness of multi-advocate architectures and discuss future research directions.         ",
    "url": "https://arxiv.org/abs/2410.04663",
    "authors": [
      "Chaithanya Bandi",
      "Abir Harrasse"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2410.04992",
    "title": "MC-QDSNN: Quantized Deep evolutionary SNN with Multi-Dendritic Compartment Neurons for Stress Detection using Physiological Signals",
    "abstract": "           Long short-term memory (LSTM) has emerged as a definitive network for analyzing and inferring time series data. LSTM has the capability to extract spectral features and a mixture of temporal features. Due to this benefit, a similar feature extraction method is explored for the spiking counterparts targeting time-series data. Though LSTMs perform well in their spiking form, they tend to be compute and power intensive. Addressing this issue, this work proposes Multi-Compartment Leaky (MCLeaky) neuron as a viable alternative for efficient processing of time series data. The MCLeaky neuron, derived from the Leaky Integrate and Fire (LIF) neuron model, contains multiple memristive synapses interlinked to form a memory component, which emulates the human brain's Hippocampus region. The proposed MCLeaky neuron based Spiking Neural Network model and its quantized variant were benchmarked against state-of-the-art (SOTA) Spiking LSTMs to perform human stress detection, by comparing compute requirements, latency and real-world performances on unseen data with models derived through Neural Architecture Search (NAS). Results show that networks with MCLeaky activation neuron managed a superior accuracy of 98.8% to detect stress based on Electrodermal Activity (EDA) signals, better than any other investigated models, while using 20% less parameters on average. MCLeaky neuron was also tested for various signals including EDA Wrist and Chest, Temperature, ECG, and combinations of them. Quantized MCLeaky model was also derived and validated to forecast their performance on hardware architectures, which resulted in 91.84% accuracy. The neurons were evaluated for multiple modalities of data towards stress detection, which resulted in energy savings of 25.12x to 39.20x and EDP gains of 52.37x to 81.9x over ANNs, while offering a best accuracy of 98.8% when compared with the rest of the SOTA implementations.         ",
    "url": "https://arxiv.org/abs/2410.04992",
    "authors": [
      "Ajay B S",
      "Phani Pavan K",
      "Madhav Rao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.05058",
    "title": "Improving Object Detection via Local-global Contrastive Learning",
    "abstract": "           Visual domain gaps often impact object detection performance. Image-to-image translation can mitigate this effect, where contrastive approaches enable learning of the image-to-image mapping under unsupervised regimes. However, existing methods often fail to handle content-rich scenes with multiple object instances, which manifests in unsatisfactory detection performance. Sensitivity to such instance-level content is typically only gained through object annotations, which can be expensive to obtain. Towards addressing this issue, we present a novel image-to-image translation method that specifically targets cross-domain object detection. We formulate our approach as a contrastive learning framework with an inductive prior that optimises the appearance of object instances through spatial attention masks, implicitly delineating the scene into foreground regions associated with the target object instances and background non-object regions. Instead of relying on object annotations to explicitly account for object instances during translation, our approach learns to represent objects by contrasting local-global information. This affords investigation of an under-explored challenge: obtaining performant detection, under domain shifts, without relying on object annotations nor detector model fine-tuning. We experiment with multiple cross-domain object detection settings across three challenging benchmarks and report state-of-the-art performance. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2410.05058",
    "authors": [
      "Danai Triantafyllidou",
      "Sarah Parisot",
      "Ales Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.08511",
    "title": "Distributionally robust self-supervised learning for tabular data",
    "abstract": "           Machine learning (ML) models trained using Empirical Risk Minimization (ERM) often exhibit systematic errors on specific subpopulations of tabular data, known as error slices. Learning robust representation in presence of error slices is challenging, especially in self-supervised settings during the feature reconstruction phase, due to high cardinality features and the complexity of constructing error sets. Traditional robust representation learning methods are largely focused on improving worst group performance in supervised setting in computer vision, leaving a gap in approaches tailored for tabular data. We address this gap by developing a framework to learn robust representation in tabular data during self-supervised pre-training. Our approach utilizes an encoder-decoder model trained with Masked Language Modeling (MLM) loss to learn robust latent representations. This paper applies the Just Train Twice (JTT) and Deep Feature Reweighting (DFR) methods during the pre-training phase for tabular data. These methods fine-tune the ERM pre-trained model by up-weighting error-prone samples or creating balanced datasets for specific categorical features. This results in specialized models for each feature, which are then used in an ensemble approach to enhance downstream classification performance. This methodology improves robustness across slices, thus enhancing overall generalization performance. Extensive experiments across various datasets demonstrate the efficacy of our approach. The code is available: \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2410.08511",
    "authors": [
      "Shantanu Ghosh",
      "Tiankang Xie",
      "Mikhail Kuznetsov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.12455",
    "title": "Loss Landscape Characterization of Neural Networks without Over-Parametrization",
    "abstract": "           Optimization methods play a crucial role in modern machine learning, powering the remarkable empirical achievements of deep learning models. These successes are even more remarkable given the complex non-convex nature of the loss landscape of these models. Yet, ensuring the convergence of optimization methods requires specific structural conditions on the objective function that are rarely satisfied in practice. One prominent example is the widely recognized Polyak-Lojasiewicz (PL) inequality, which has gained considerable attention in recent years. However, validating such assumptions for deep neural networks entails substantial and often impractical levels of over-parametrization. In order to address this limitation, we propose a novel class of functions that can characterize the loss landscape of modern deep models without requiring extensive over-parametrization and can also include saddle points. Crucially, we prove that gradient-based optimizers possess theoretical guarantees of convergence under this assumption. Finally, we validate the soundness of our new function class through both theoretical analysis and empirical experimentation across a diverse range of deep learning models.         ",
    "url": "https://arxiv.org/abs/2410.12455",
    "authors": [
      "Rustem Islamov",
      "Niccol\u00f2 Ajroldi",
      "Antonio Orvieto",
      "Aurelien Lucchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.13281",
    "title": "BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla",
    "abstract": "           The proliferation of transliterated texts in digital spaces has emphasized the need for detecting and classifying hate speech in languages beyond English, particularly in low-resource languages. As online discourse can perpetuate discrimination based on target groups, e.g. gender, religion, and origin, multi-label classification of hateful content can help in comprehending hate motivation and enhance content moderation. While previous efforts have focused on monolingual or binary hate classification tasks, no work has yet addressed the challenge of multi-label hate speech classification in transliterated Bangla. We introduce BanTH, the first multi-label transliterated Bangla hate speech dataset comprising 37.3k samples. The samples are sourced from YouTube comments, where each instance is labeled with one or more target groups, reflecting the regional demographic. We establish novel transformer encoder-based baselines by further pre-training on transliterated Bangla corpus. We also propose a novel translation-based LLM prompting strategy for transliterated text. Experiments reveal that our further pre-trained encoders are achieving state-of-the-art performance on the BanTH dataset, while our translation-based prompting outperforms other strategies in the zero-shot setting. The introduction of BanTH not only fills a critical gap in hate speech research for Bangla but also sets the stage for future exploration into code-mixed and multi-label classification challenges in underrepresented languages.         ",
    "url": "https://arxiv.org/abs/2410.13281",
    "authors": [
      "Fabiha Haider",
      "Fariha Tanjim Shifat",
      "Md Farhan Ishmam",
      "Deeparghya Dutta Barua",
      "Md Sakib Ul Rahman Sourove",
      "Md Fahim",
      "Md Farhad Alam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.14721",
    "title": "The Representation of Meaningful Precision, and Accuracy",
    "abstract": "           The concepts of precision, and accuracy are domain and problem dependent. The simplified numeric hard and soft measures used in the fields of statistical learning, many types of machine learning, and binary or multiclass classification problems are known to be of limited use for understanding the meaningfulness of models or their relevance. Arguably, they are neither of patterns nor proofs. Further, there are no good measures or representations for analogous concepts in the cognition domain. In this research, the key issues are reflected upon, and a compositional knowledge representation approach in a minimalist general rough framework is proposed for the problem contexts. The latter is general enough to cover most application contexts, and may be applicable in the light of improved computational tools available.         ",
    "url": "https://arxiv.org/abs/2410.14721",
    "authors": [
      "A Mani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2410.15999",
    "title": "Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering",
    "abstract": "           Large language models (LLMs) can store a significant amount of factual knowledge in their parameters. However, their parametric knowledge may conflict with the information provided in the context -- this phenomenon, known as \\emph{context-memory knowledge conflicts}, can lead to undesirable model behaviour, such as reliance on outdated or incorrect information. Analysing the internal activations of LLMs, we find that they can internally register the signals of knowledge conflict at mid-layers. Such signals allow us to detect whether a knowledge conflict occurs and use \\emph{inference-time} intervention strategies to resolve it. In this work, we propose \\textsc{SpARE}, a \\emph{training-free} representation engineering method that uses pre-trained sparse auto-encoders (SAEs) to control the knowledge selection behaviour of LLMs. \\textsc{SpARE} identifies the functional features that control the knowledge selection behaviours and applies them to edit the internal activations of LLMs at inference time. Our experimental results show that \\textsc{SpARE} can effectively control the usage of either knowledge source to resolve knowledge conflict in open-domain question-answering tasks, surpassing existing representation engineering methods ($+10\\%$) as well as contrastive decoding methods ($+15\\%$).         ",
    "url": "https://arxiv.org/abs/2410.15999",
    "authors": [
      "Yu Zhao",
      "Alessio Devoto",
      "Giwon Hong",
      "Xiaotang Du",
      "Aryo Pradipta Gema",
      "Hongru Wang",
      "Xuanli He",
      "Kam-Fai Wong",
      "Pasquale Minervini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.16838",
    "title": "Neural Collaborative Filtering Classification Model to Obtain Prediction Reliabilities",
    "abstract": "           Neural collaborative filtering is the state of art field in the recommender systems area; it provides some models that obtain accurate predictions and recommendations. These models are regression-based, and they just return rating predictions. This paper proposes the use of a classification-based approach, returning both rating predictions and their reliabilities. The extra information (prediction reliabilities) can be used in a variety of relevant collaborative filtering areas such as detection of shilling attacks, recommendations explanation or navigational tools to show users and items dependences. Additionally, recommendation reliabilities can be gracefully provided to users: \"probably you will like this film\", \"almost certainly you will like this song\", etc. This paper provides the proposed neural architecture; it also tests that the quality of its recommendation results is as good as the state of art baselines. Remarkably, individual rating predictions are improved by using the proposed architecture compared to baselines. Experiments have been performed making use of four popular public datasets, showing generalizable quality results. Overall, the proposed architecture improves individual rating predictions quality, maintains recommendation results and opens the doors to a set of relevant collaborative filtering fields.         ",
    "url": "https://arxiv.org/abs/2410.16838",
    "authors": [
      "Jes\u00fas Bobadilla",
      "Abraham Guti\u00e9rrez",
      "Santiago Alonso",
      "\u00c1ngel Gonz\u00e1lez-Prieto"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2410.18658",
    "title": "NIDS Neural Networks Using Sliding Time Window Data Processing with Trainable Activations and its Generalization Capability",
    "abstract": "           This paper presents neural networks for network intrusion detection systems (NIDS), that operate on flow data preprocessed with a time window. It requires only eleven features which do not rely on deep packet inspection and can be found in most NIDS datasets and easily obtained from conventional flow collectors. The time window aggregates information with respect to hosts facilitating the identification of flow signatures that are missed by other aggregation methods. Several network architectures are studied and the use of Kolmogorov-Arnold Network (KAN)-inspired trainable activation functions that help to achieve higher accuracy with simpler network structure is proposed. The reported training accuracy exceeds 99% for the proposed method with as little as twenty neural network input features. This work also studies the generalization capability of NIDS, a crucial aspect that has not been adequately addressed in the previous studies. The generalization experiments are conducted using CICIDS2017 dataset and a custom dataset collected as part of this study. It is shown that the performance metrics decline significantly when changing datasets, and the reduction in performance metrics can be attributed to the difference in signatures of the same type flows in different datasets, which in turn can be attributed to the differences between the underlying networks. It is shown that the generalization accuracy of some neural networks can be very unstable and sensitive to random initialization parameters, and neural networks with fewer parameters and well-tuned activations are more stable and achieve higher accuracy.         ",
    "url": "https://arxiv.org/abs/2410.18658",
    "authors": [
      "Anton Raskovalov",
      "Nikita Gabdullin",
      "Ilya Androsov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05893",
    "title": "The Power of Two Matrices in Spectral Algorithms for Community Recovery",
    "abstract": "           Spectral algorithms are some of the main tools in optimization and inference problems on graphs. Typically, the graph is encoded as a matrix and eigenvectors and eigenvalues of the matrix are then used to solve the given graph problem. Spectral algorithms have been successfully used for graph partitioning, hidden clique recovery and graph coloring. In this paper, we study the power of spectral algorithms using two matrices in a graph partitioning problem. We use two different matrices resulting from two different encodings of the same graph and then combine the spectral information coming from these two matrices. We analyze a two-matrix spectral algorithm for the problem of identifying latent community structure in large random graphs. In particular, we consider the problem of recovering community assignments exactly in the censored stochastic block model, where each edge status is revealed independently with some probability. We show that spectral algorithms based on two matrices are optimal and succeed in recovering communities up to the information theoretic threshold. Further, we show that for most choices of the parameters, any spectral algorithm based on one matrix is suboptimal. The latter observation is in contrast to our prior works (2022a, 2022b) which showed that for the symmetric Stochastic Block Model and the Planted Dense Subgraph problem, a spectral algorithm based on one matrix achieves the information theoretic threshold. We additionally provide more general geometric conditions for the (sub)-optimality of spectral algorithms.         ",
    "url": "https://arxiv.org/abs/2210.05893",
    "authors": [
      "Souvik Dhara",
      "Julia Gaudio",
      "Elchanan Mossel",
      "Colin Sandon"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.19385",
    "title": "Gradient-free online learning of subgrid-scale dynamics with neural emulators",
    "abstract": "           In this paper, we propose a generic algorithm to train machine learning-based subgrid parametrizations online, i.e., with a posteriori loss functions, but for non-differentiable numerical solvers. The proposed approach leverages a neural emulator to approximate the reduced state-space solver, which is then used to allow gradient propagation through temporal integration steps. We apply this methodology on a single layer quasi-geostrophic system with topography, known to be highly unstable in around 500 temporal iterations with offline strategies. Using our algorithm, we are able to train a parametrization that recovers most of the benefits of online strategies without having to compute the gradient of the original solver. It is demonstrated that training the neural emulator and parametrization components separately with different loss quantities is necessary in order to minimize the propagation of approximation biases. Experiments on emulator architectures with different complexities also indicates that emulator performance is key in order to learn an accurate parametrization. This work is a step towards learning parametrization with online strategies for weather models.         ",
    "url": "https://arxiv.org/abs/2310.19385",
    "authors": [
      "Hugo Frezat",
      "Ronan Fablet",
      "Guillaume Balarac",
      "Julien Le Sommer"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2311.14759",
    "title": "Deep Learning and NLP in Cryptocurrency Forecasting: Integrating Financial, Blockchain, and Social Media Data",
    "abstract": "           We introduce novel approaches to cryptocurrency price forecasting, leveraging Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a focus on Bitcoin and Ethereum. By analysing news and social media content, primarily from Twitter and Reddit, we assess the impact of public sentiment on cryptocurrency markets. A distinctive feature of our methodology is the application of the BART MNLI zero-shot classification model to detect bullish and bearish trends, significantly advancing beyond traditional sentiment analysis. Additionally, we systematically compare a range of pre-trained and fine-tuned deep learning NLP models against conventional dictionary-based sentiment analysis methods. Another key contribution of our work is the adoption of local extrema alongside daily price movements as predictive targets, reducing trading frequency and portfolio volatility. Our findings demonstrate that integrating textual data into cryptocurrency price forecasting not only improves forecasting accuracy but also consistently enhances the profitability and Sharpe ratio across various validation scenarios, particularly when applying deep learning NLP techniques. The entire codebase of our experiments is made available via an online repository: this https URL ",
    "url": "https://arxiv.org/abs/2311.14759",
    "authors": [
      "Vincent Gurgul",
      "Stefan Lessmann",
      "Wolfgang Karl H\u00e4rdle"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.13884",
    "title": "Decision-Making Frameworks for Network Resilience -- Managing and Mitigating Systemic (Cyber) Risk",
    "abstract": "           We introduce a decision-making framework tailored for the management of systemic risk in networks. This framework is constructed upon three fundamental components: (1) a set of acceptable network configurations, (2) a set of interventions aimed at risk mitigation, and (3) a cost function quantifying the expenses associated with these interventions. While our discussion primarily revolves around the management of systemic cyber risks in digital networks, we concurrently draw parallels to risk management of other complex systems where analogous approaches may be adequate.         ",
    "url": "https://arxiv.org/abs/2312.13884",
    "authors": [
      "Gregor Svindland",
      "Alexander Vo\u00df"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.14007",
    "title": "Semantic Ensemble Loss and Latent Refinement for High-Fidelity Neural Image Compression",
    "abstract": "           Recent advancements in neural compression have surpassed traditional codecs in PSNR and MS-SSIM measurements. However, at low bit-rates, these methods can introduce visually displeasing artifacts, such as blurring, color shifting, and texture loss, thereby compromising perceptual quality of images. To address these issues, this study presents an enhanced neural compression method designed for optimal visual fidelity. We have trained our model with a sophisticated semantic ensemble loss, integrating Charbonnier loss, perceptual loss, style loss, and a non-binary adversarial loss, to enhance the perceptual quality of image reconstructions. Additionally, we have implemented a latent refinement process to generate content-aware latent codes. These codes adhere to bit-rate constraints, balance the trade-off between distortion and fidelity, and prioritize bit allocation to regions of greater importance. Our empirical findings demonstrate that this approach significantly improves the statistical fidelity of neural image compression. On CLIC2024 validation set, our approach achieves a 62% bitrate saving compared to MS-ILLM under FID metric.         ",
    "url": "https://arxiv.org/abs/2401.14007",
    "authors": [
      "Daxin Li",
      "Yuanchao Bai",
      "Kai Wang",
      "Junjun Jiang",
      "Xianming Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2410.18223",
    "title": "Locally seeded embeddings, and Ramsey numbers of bipartite graphs with sublinear bandwidth",
    "abstract": "           A seminal result of Lee asserts that the Ramsey number of any bipartite $d$-degenerate graph $H$ satisfies $\\log r(H) = \\log n + O(d)$. In particular, this bound applies to every bipartite graph of maximal degree $\\Delta$. It remains a compelling challenge to identify conditions that guarantee that an $n$-vertex graph $H$ has Ramsey number linear in $n$, independently of $\\Delta$. Our contribution is a characterization of bipartite graphs with linear-size Ramsey numbers in terms of graph bandwidth, a notion of local connectivity. We prove that for any $n$-vertex bipartite graph $H$ with maximal degree at most $\\Delta$ and bandwidth $b(H)$ at most $\\exp(-C\\Delta\\log\\Delta)\\,n$, we have $\\log r(H) = \\log n + O(1)$. This characterization is nearly optimal: for every $\\Delta$ there exists an $n$-vertex bipartite graph $H$ of degree at most $\\Delta$ and $b(H) \\leq \\exp(-c\\Delta)\\,n$, such that $\\log r(H) = \\log n + \\Omega(\\Delta)$. We also provide bounds interpolating between these two bandwidth regimes.         ",
    "url": "https://arxiv.org/abs/2410.18223",
    "authors": [
      "Dylan J. Altschuler",
      "Han Huang",
      "Konstantin Tikhomirov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  }
]