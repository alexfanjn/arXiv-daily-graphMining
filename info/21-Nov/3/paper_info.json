[
  {
    "id": "arXiv:2111.01166",
    "title": "Investigating the locality of neural network training dynamics",
    "abstract": "A fundamental quest in the theory of deep-learning is to understand the properties of the trajectories in the weight space that a learning algorithm takes. One such property that had very recently been isolated is that of \"local elasticity\" ($S_{\\rm rel}$), which quantifies the propagation of influence of a sampled data point on the prediction at another data point. In this work, we perform a comprehensive study of local elasticity by providing new theoretical insights and more careful empirical evidence of this property in a variety of settings. Firstly, specific to the classification setting, we suggest a new definition of the original idea of $S_{\\rm rel}$. Via experiments on state-of-the-art neural networks training on SVHN, CIFAR-10 and CIFAR-100 we demonstrate how our new $S_{\\rm rel}$ detects the property of the weight updates preferring to make changes in predictions within the same class of the sampled data. Next, we demonstrate via examples of neural nets doing regression that the original $S_{\\rm rel}$ reveals a $2-$phase behaviour: that their training proceeds via an initial elastic phase when $S_{\\rm rel}$ changes rapidly and an eventual inelastic phase when $S_{\\rm rel}$ remains large. Lastly, we give multiple examples of learning via gradient flows for which one can get a closed-form expression of the original $S_{\\rm rel}$ function. By studying the plots of these derived formulas we given a theoretical demonstration of some of the experimentally detected properties of $S_{\\rm rel}$ in the regression setting. ",
    "url": "https://arxiv.org/abs/2111.01166",
    "authors": [
      "Soham Dan",
      "Phanideep Gampa",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.01193",
    "title": "Transformers for prompt-level EMA non-response prediction",
    "abstract": "Ecological Momentary Assessments (EMAs) are an important psychological data source for measuring current cognitive states, affect, behavior, and environmental factors from participants in mobile health (mHealth) studies and treatment programs. Non-response, in which participants fail to respond to EMA prompts, is an endemic problem. The ability to accurately predict non-response could be utilized to improve EMA delivery and develop compliance interventions. Prior work has explored classical machine learning models for predicting non-response. However, as increasingly large EMA datasets become available, there is the potential to leverage deep learning models that have been effective in other fields. Recently, transformer models have shown state-of-the-art performance in NLP and other domains. This work is the first to explore the use of transformers for EMA data analysis. We address three key questions in applying transformers to EMA data: 1. Input representation, 2. encoding temporal information, 3. utility of pre-training on improving downstream prediction task performance. The transformer model achieves a non-response prediction AUC of 0.77 and is significantly better than classical ML and LSTM-based deep learning models. We will make our a predictive model trained on a corpus of 40K EMA samples freely-available to the research community, in order to facilitate the development of future transformer-based EMA analysis works. ",
    "url": "https://arxiv.org/abs/2111.01193",
    "authors": [
      "Supriya Nagesh",
      "Alexander Moreno",
      "Stephanie M. Carpenter",
      "Jamie Yap",
      "Soujanya Chatterjee",
      "Steven Lloyd Lizotte",
      "Neng Wan",
      "Santosh Kumar",
      "Cho Lam",
      "David W. Wetter",
      "Inbal Nahum-Shani",
      "James M. Rehg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01205",
    "title": "Evaluating robustness of You Only Hear Once(YOHO) Algorithm on noisy  audios in the VOICe Dataset",
    "abstract": "Sound event detection (SED) in machine listening entails identifying the different sounds in an audio file and identifying the start and end time of a particular sound event in the audio. SED finds use in various applications such as audio surveillance, speech recognition, and context-based indexing and retrieval of data in a multimedia database. However, in real-life scenarios, the audios from various sources are seldom devoid of any interfering noise or disturbance. In this paper, we test the performance of the You Only Hear Once (YOHO) algorithm on noisy audio data. Inspired by the You Only Look Once (YOLO) algorithm in computer vision, the YOHO algorithm can match the performance of the various state-of-the-art algorithms on datasets such as Music Speech Detection Dataset, TUT Sound Event, and Urban-SED datasets but at lower inference times. In this paper, we explore the performance of the YOHO algorithm on the VOICe dataset containing audio files with noise at different sound-to-noise ratios (SNR). YOHO could outperform or at least match the best performing SED algorithms reported in the VOICe dataset paper and make inferences in less time. ",
    "url": "https://arxiv.org/abs/2111.01205",
    "authors": [
      "Soham Tiwari",
      "Kshitiz Lakhotia",
      "Manjunath Mulimani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.01225",
    "title": "Identifying causal associations in tweets using deep learning: Use case  on diabetes-related tweets from 2017-2021",
    "abstract": "Objective: Leveraging machine learning methods, we aim to extract both explicit and implicit cause-effect associations in patient-reported, diabetes-related tweets and provide a tool to better understand opinion, feelings and observations shared within the diabetes online community from a causality perspective. Materials and Methods: More than 30 million diabetes-related tweets in English were collected between April 2017 and January 2021. Deep learning and natural language processing methods were applied to focus on tweets with personal and emotional content. A cause-effect-tweet dataset was manually labeled and used to train 1) a fine-tuned Bertweet model to detect causal sentences containing a causal association 2) a CRF model with BERT based features to extract possible cause-effect associations. Causes and effects were clustered in a semi-supervised approach and visualised in an interactive cause-effect-network. Results: Causal sentences were detected with a recall of 68% in an imbalanced dataset. A CRF model with BERT based features outperformed a fine-tuned BERT model for cause-effect detection with a macro recall of 68%. This led to 96,676 sentences with cause-effect associations. \"Diabetes\" was identified as the central cluster followed by \"Death\" and \"Insulin\". Insulin pricing related causes were frequently associated with \"Death\". Conclusions: A novel methodology was developed to detect causal sentences and identify both explicit and implicit, single and multi-word cause and corresponding effect as expressed in diabetes-related tweets leveraging BERT-based architectures and visualised as cause-effect-network. Extracting causal associations on real-life, patient reported outcomes in social media data provides a useful complementary source of information in diabetes research. ",
    "url": "https://arxiv.org/abs/2111.01225",
    "authors": [
      "Adrian Ahne",
      "Vivek Khetan",
      "Xavier Tannier",
      "Md Imbessat Hassan Rizvi",
      "Thomas Czernichow",
      "Francisco Orchard",
      "Charline Bour",
      "Andrew Fano",
      "Guy Fagherazzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01229",
    "title": "Impact of network topology on efficiency of proximity measures for  community detection",
    "abstract": "Many community detection algorithms require the introduction of a measure on the set of nodes. Previously, a lot of efforts have been made to find the top-performing measures. In most cases, experiments were conducted on several datasets or random graphs. However, graphs representing real systems can be completely different in topology: the difference can be in the size of the network, the structure of clusters, the distribution of degrees, the density of edges, and so on. Therefore, it is necessary to explicitly check whether the advantage of one measure over another is preserved for different network topologies. In this paper, we consider the efficiency of several proximity measures for clustering networks with different structures. The results show that the efficiency of measures really depends on the network topology in some cases. However, it is possible to find measures that behave well for most topologies. ",
    "url": "https://arxiv.org/abs/2111.01229",
    "authors": [
      "Rinat Aynulin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2111.01256",
    "title": "Reverse engineering recurrent neural networks with Jacobian switching  linear dynamical systems",
    "abstract": "Recurrent neural networks (RNNs) are powerful models for processing time-series data, but it remains challenging to understand how they function. Improving this understanding is of substantial interest to both the machine learning and neuroscience communities. The framework of reverse engineering a trained RNN by linearizing around its fixed points has provided insight, but the approach has significant challenges. These include difficulty choosing which fixed point to expand around when studying RNN dynamics and error accumulation when reconstructing the nonlinear dynamics with the linearized dynamics. We present a new model that overcomes these limitations by co-training an RNN with a novel switching linear dynamical system (SLDS) formulation. A first-order Taylor series expansion of the co-trained RNN and an auxiliary function trained to pick out the RNN's fixed points govern the SLDS dynamics. The results are a trained SLDS variant that closely approximates the RNN, an auxiliary function that can produce a fixed point for each point in state-space, and a trained nonlinear RNN whose dynamics have been regularized such that its first-order terms perform the computation, if possible. This model removes the post-training fixed point optimization and allows us to unambiguously study the learned dynamics of the SLDS at any point in state-space. It also generalizes SLDS models to continuous manifolds of switching points while sharing parameters across switches. We validate the utility of the model on two synthetic tasks relevant to previous work reverse engineering RNNs. We then show that our model can be used as a drop-in in more complex architectures, such as LFADS, and apply this LFADS hybrid to analyze single-trial spiking activity from the motor system of a non-human primate. ",
    "url": "https://arxiv.org/abs/2111.01256",
    "authors": [
      "Jimmy T.H. Smith",
      "Scott W. Linderman",
      "David Sussillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01276",
    "title": "Multi network InfoMax: A pre-training method involving graph  convolutional networks",
    "abstract": "Discovering distinct features and their relations from data can help us uncover valuable knowledge crucial for various tasks, e.g., classification. In neuroimaging, these features could help to understand, classify, and possibly prevent brain disorders. Model introspection of highly performant overparameterized deep learning (DL) models could help find these features and relations. However, to achieve high-performance level DL models require numerous labeled training samples ($n$) rarely available in many fields. This paper presents a pre-training method involving graph convolutional/neural networks (GCNs/GNNs), based on maximizing mutual information between two high-level embeddings of an input sample. Many of the recently proposed pre-training methods pre-train one of many possible networks of an architecture. Since almost every DL model is an ensemble of multiple networks, we take our high-level embeddings from two different networks of a model --a convolutional and a graph network--. The learned high-level graph latent representations help increase performance for downstream graph classification tasks and bypass the need for a high number of labeled data samples. We apply our method to a neuroimaging dataset for classifying subjects into healthy control (HC) and schizophrenia (SZ) groups. Our experiments show that the pre-trained model significantly outperforms the non-pre-trained model and requires $50\\%$ less data for similar performance. ",
    "url": "https://arxiv.org/abs/2111.01276",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.01297",
    "title": "Deep neural networks as nested dynamical systems",
    "abstract": "There is an analogy that is often made between deep neural networks and actual brains, suggested by the nomenclature itself: the \"neurons\" in deep neural networks should correspond to neurons (or nerve cells, to avoid confusion) in the brain. We claim, however, that this analogy doesn't even type check: it is structurally flawed. In agreement with the slightly glib summary of Hebbian learning as \"cells that fire together wire together\", this article makes the case that the analogy should be different. Since the \"neurons\" in deep neural networks are managing the changing weights, they are more akin to the synapses in the brain; instead, it is the wires in deep neural networks that are more like nerve cells, in that they are what cause the information to flow. An intuition that nerve cells seem like more than mere wires is exactly right, and is justified by a precise category-theoretic analogy which we will explore in this article. Throughout, we will continue to highlight the error in equating artificial neurons with nerve cells by leaving \"neuron\" in quotes or by calling them artificial neurons. We will first explain how to view deep neural networks as nested dynamical systems with a very restricted sort of interaction pattern, and then explain a more general sort of interaction for dynamical systems that is useful throughout engineering, but which fails to adapt to changing circumstances. As mentioned, an analogy is then forced upon us by the mathematical formalism in which they are both embedded. We call the resulting encompassing generalization deeply interacting learning systems: they have complex interaction as in control theory, but adaptation to circumstances as in deep neural networks. ",
    "url": "https://arxiv.org/abs/2111.01297",
    "authors": [
      "David I. Spivak",
      "Timothy Hosgood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Category Theory (math.CT)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2111.01334",
    "title": "Measuring and utilizing temporal network dissimilarity",
    "abstract": "Quantifying the structural and functional differences of temporal networks is a fundamental and challenging problem in the era of big data. This work proposes a temporal dissimilarity measure for temporal network comparison based on the fastest arrival distance distribution and spectral entropy based Jensen-Shannon divergence. Experimental results on both synthetic and empirical temporal networks show that the proposed measure could discriminate diverse temporal networks with different structures by capturing various topological and temporal properties. Moreover, the proposed measure can discern the functional distinctions and is found effective applications in temporal network classification and spreadability discrimination. ",
    "url": "https://arxiv.org/abs/2111.01334",
    "authors": [
      "Xiu-Xiu Zhan",
      "Chuang Liu",
      "Zhipeng Wang",
      "Huijuang Wang",
      "Petter Holme",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.01356",
    "title": "DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method",
    "abstract": "We introduce the so called DeepParticle method to learn and generate invariant measures of stochastic dynamical systems with physical parameters based on data computed from an interacting particle method (IPM). We utilize the expressiveness of deep neural networks (DNNs) to represent the transform of samples from a given input (source) distribution to an arbitrary target distribution, neither assuming distribution functions in closed form nor a finite state space for the samples. In training, we update the network weights to minimize a discrete Wasserstein distance between the input and target samples. To reduce computational cost, we propose an iterative divide-and-conquer (a mini-batch interior point) algorithm, to find the optimal transition matrix in the Wasserstein distance. We present numerical results to demonstrate the performance of our method for accelerating IPM computation of invariant measures of stochastic dynamical systems arising in computing reaction-diffusion front speeds through chaotic flows. The physical parameter is a large Pecl\\'et number reflecting the advection dominated regime of our interest. ",
    "url": "https://arxiv.org/abs/2111.01356",
    "authors": [
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2111.01378",
    "title": "Finding the KT partition of a weighted graph in near-linear time",
    "abstract": "In a breakthrough work, Kawarabayashi and Thorup (J.~ACM'19) gave a near-linear time deterministic algorithm for minimum cut in a simple graph $G = (V,E)$. A key component is finding the $(1+\\varepsilon)$-KT partition of $G$, the coarsest partition $\\{P_1, \\ldots, P_k\\}$ of $V$ such that for every non-trivial $(1+\\varepsilon)$-near minimum cut with sides $\\{S, \\bar{S}\\}$ it holds that $P_i$ is contained in either $S$ or $\\bar{S}$, for $i=1, \\ldots, k$. Here we give a near-linear time randomized algorithm to find the $(1+\\varepsilon)$-KT partition of a weighted graph. Our algorithm is quite different from that of Kawarabayashi and Thorup and builds on Karger's framework of tree-respecting cuts (J.~ACM'00). We describe applications of the algorithm. (i) The algorithm makes progress towards a more efficient algorithm for constructing the polygon representation of the set of near-minimum cuts in a graph. This is a generalization of the cactus representation initially described by Bencz\\'ur (FOCS'95). (ii) We improve the time complexity of a recent quantum algorithm for minimum cut in a simple graph in the adjacency list model from $\\widetilde O(n^{3/2})$ to $\\widetilde O(\\sqrt{mn})$. (iii) We describe a new type of randomized algorithm for minimum cut in simple graphs with complexity $O(m + n \\log^6 n)$. For slightly dense graphs this matches the complexity of the current best $O(m + n \\log^2 n)$ algorithm which uses a different approach based on random contractions. The key technical contribution of our work is the following. Given a weighted graph $G$ with $m$ edges and a spanning tree $T$, consider the graph $H$ whose nodes are the edges of $T$, and where there is an edge between two nodes of $H$ iff the corresponding 2-respecting cut of $T$ is a non-trivial near-minimum cut of $G$. We give a $O(m \\log^4 n)$ time deterministic algorithm to compute a spanning forest of $H$. ",
    "url": "https://arxiv.org/abs/2111.01378",
    "authors": [
      "Simon Apers",
      "Pawe\u0142 Gawrychowski",
      "Troy Lee"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2111.01440",
    "title": "HHP-Net: A light Heteroscedastic neural network for Head Pose estimation  with uncertainty",
    "abstract": "In this paper we introduce a novel method to estimate the head pose of people in single images starting from a small set of head keypoints. To this purpose, we propose a regression model that exploits keypoints computed automatically by 2D pose estimation algorithms and outputs the head pose represented by yaw, pitch, and roll. Our model is simple to implement and more efficient with respect to the state of the art -- faster in inference and smaller in terms of memory occupancy -- with comparable accuracy. Our method also provides a measure of the heteroscedastic uncertainties associated with the three angles, through an appropriately designed loss function; we show there is a correlation between error and uncertainty values, thus this extra source of information may be used in subsequent computational steps. As an example application, we address social interaction analysis in images: we propose an algorithm for a quantitative estimation of the level of interaction between people, starting from their head poses and reasoning on their mutual positions. The code is available at https://github.com/cantarinigiorgio/HHP-Net. ",
    "url": "https://arxiv.org/abs/2111.01440",
    "authors": [
      "Giorgio Cantarini",
      "Federico Figari Tomenotti",
      "Nicoletta Noceti",
      "Francesca Odone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.01526",
    "title": "A modified gravity model based on network efficiency for vital nodes  identification in complex networks",
    "abstract": "Vital nodes identification is an essential problem in network science. Various methods have been proposed to solve this problem. In particular, based on the gravity model, a series of improved gravity models are proposed to find vital nodes better in complex networks. However, they still have the room to be improved. In this paper, a novel and improved gravity model, which is named network efficiency gravity centrality model (NEG), integrates gravity model and network efficiency is proposed. Compared to other methods based on different gravity models, the proposed method considers the effect of the nodes on structure robustness of the network better. To solidate the superiority of the proposed method, experiments on varieties of real-world networks are carried out. ",
    "url": "https://arxiv.org/abs/2111.01526",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.01676",
    "title": "Towards text-based phishing detection",
    "abstract": "This paper reports on an experiment into text-based phishing detection using readily available resources and without the use of semantics. The developed algorithm is a modified version of previously published work that works with the same tools. The results obtained in recognizing phishing emails are considerably better than the previously reported work; but the rate of text falsely identified as phishing is slightly worse. It is expected that adding semantic component will reduce the false positive rate while preserving the detection accuracy. ",
    "url": "https://arxiv.org/abs/2111.01676",
    "authors": [
      "Gilchan Park",
      "Julia M. Taylor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.01681",
    "title": "Saliency detection with moving camera via background model completion",
    "abstract": "To detect saliency in video is a fundamental step in many computer vision systems. Saliency is the significant target(s) in the video. The object of interest is further analyzed for high-level applications. The segregation of saliency and the background can be made if they exhibit different visual cues. Therefore, saliency detection is often formulated as background subtraction. However, saliency detection is challenging. For instance, dynamic background can result in false positive errors. In another scenario, camouflage will lead to false negative errors. With moving camera, the captured scenes are even more complicated to handle. We propose a new framework, called saliency detection via background model completion (SD-BMC), that comprises of a background modeler and the deep learning background/foreground segmentation network. The background modeler generates an initial clean background image from a short image sequence. Based on the idea of video completion, a good background frame can be synthesized with the co-existence of changing background and moving objects. We adopt the background/foreground segmenter, although pre-trained with a specific video dataset, can also detect saliency in unseen videos. The background modeler can adjust the background image dynamically when the background/foreground segmenter output deteriorates during processing of a long video. To the best of our knowledge, our framework is the first one to adopt video completion for background modeling and saliency detection in videos captured by moving camera. The results, obtained from the PTZ videos, show that our proposed framework outperforms some deep learning-based background subtraction models by 11% or more. With more challenging videos, our framework also outperforms many high ranking background subtraction methods by more than 3%. ",
    "url": "https://arxiv.org/abs/2111.01681",
    "authors": [
      "Yupei Zhang",
      "Kwok-Leung Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.01715",
    "title": "Absolute distance prediction based on deep learning object detection and  monocular depth estimation models",
    "abstract": "Determining the distance between the objects in a scene and the camera sensor from 2D images is feasible by estimating depth images using stereo cameras or 3D cameras. The outcome of depth estimation is relative distances that can be used to calculate absolute distances to be applicable in reality. However, distance estimation is very challenging using 2D monocular cameras. This paper presents a deep learning framework that consists of two deep networks for depth estimation and object detection using a single image. Firstly, objects in the scene are detected and localized using the You Only Look Once (YOLOv5) network. In parallel, the estimated depth image is computed using a deep autoencoder network to detect the relative distances. The proposed object detection based YOLO was trained using a supervised learning technique, in turn, the network of depth estimation was self-supervised training. The presented distance estimation framework was evaluated on real images of outdoor scenes. The achieved results show that the proposed framework is promising and it yields an accuracy of 96% with RMSE of 0.203 of the correct absolute distance. ",
    "url": "https://arxiv.org/abs/2111.01715",
    "authors": [
      "Armin Masoumian",
      "David G. F. Marei",
      "Saddam Abdulwahab",
      "Julian Cristiano",
      "Domenec Puig",
      "Hatem A. Rashwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.01778",
    "title": "Location inference on social media data for agile monitoring of public  health crises: An application to opioid use and abuse during the Covid-19  pandemic",
    "abstract": "The Covid-19 pandemic has intersected with the opioid epidemic to create a unique public health crisis, with the health and economic consequences of the virus and associated lockdowns compounding pre-existing social and economic stressors associated with rising opioid and heroin use and abuse. In order to better understand these interlocking crises, we use social media data to extract qualitative and quantitative insights on the experiences of opioid users during the Covid-19 pandemic. In particular, we use an unsupervised learning approach to create a rich geolocated data source for public health surveillance and analysis. To do this we first infer the location of 26,000 Reddit users that participate in opiate-related sub-communities (subreddits) by combining named entity recognition, geocoding, density-based clustering, and heuristic methods. Our strategy achieves 63 percent accuracy at state-level location inference on a manually-annotated reference dataset. We then leverage the geospatial nature of our user cohort to answer policy-relevant questions about the impact of varying state-level policy approaches that balance economic versus health concerns during Covid-19. We find that state government strategies that prioritized economic reopening over curtailing the spread of the virus created a markedly different environment and outcomes for opioid users. Our results demonstrate that geospatial social media data can be used for agile monitoring of complex public health crises. ",
    "url": "https://arxiv.org/abs/2111.01778",
    "authors": [
      "Angela E. Kilby",
      "Charlie Denhart"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2111.01223",
    "title": "A framework for causal segmentation analysis with machine learning in  large-scale digital experiments",
    "abstract": "We present an end-to-end methodological framework for causal segment discovery that aims to uncover differential impacts of treatments across subgroups of users in large-scale digital experiments. Building on recent developments in causal inference and non/semi-parametric statistics, our approach unifies two objectives: (1) the discovery of user segments that stand to benefit from a candidate treatment based on subgroup-specific treatment effects, and (2) the evaluation of causal impacts of dynamically assigning units to a study's treatment arm based on their predicted segment-specific benefit or harm. Our proposal is model-agnostic, capable of incorporating state-of-the-art machine learning algorithms into the estimation procedure, and is applicable in randomized A/B tests and quasi-experiments. An open source R package implementation, sherlock, is introduced. ",
    "url": "https://arxiv.org/abs/2111.01223",
    "authors": [
      "Nima S. Hejazi",
      "Wenjing Zheng",
      "Sathya Anand"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.01275",
    "title": "Recurrent neural network models for working memory of continuous  variables: activity manifolds, connectivity patterns, and dynamic codes",
    "abstract": "Many daily activities and psychophysical experiments involve keeping multiple items in working memory. When items take continuous values (e.g., orientation, contrast, length, loudness) they must be stored in a continuous structure of appropriate dimensions. We investigate how this structure is represented in neural circuits by training recurrent networks to report two previously shown stimulus orientations. We find the activity manifold for the two orientations resembles a Clifford torus. Although a Clifford and standard torus (the surface of a donut) are topologically equivalent, they have important functional differences. A Clifford torus treats the two orientations equally and keeps them in orthogonal subspaces, as demanded by the task, whereas a standard torus does not. We find and characterize the connectivity patterns that support the Clifford torus. Moreover, in addition to attractors that store information via persistent activity, our networks also use a dynamic code where units change their tuning to prevent new sensory input from overwriting the previously stored one. We argue that such dynamic codes are generally required whenever multiple inputs enter a memory system via shared connections. Finally, we apply our framework to a human psychophysics experiment in which subjects reported two remembered orientations. By varying the training conditions of the RNNs, we test and support the hypothesis that human behavior is a product of both neural noise and reliance on the more stable and behaviorally relevant memory of the ordinal relationship between the two orientations. This suggests that suitable inductive biases in RNNs are important for uncovering how the human brain implements working memory. Together, these results offer an understanding of the neural computations underlying a class of visual decoding tasks, bridging the scales from human behavior to synaptic connectivity. ",
    "url": "https://arxiv.org/abs/2111.01275",
    "authors": [
      "Christopher J. Cueva",
      "Adel Ardalan",
      "Misha Tsodyks",
      "Ning Qian"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2111.01404",
    "title": "Cascadable all-optical NAND gates using diffractive networks",
    "abstract": "Owing to its potential advantages such as scalability, low latency and power efficiency, optical computing has seen rapid advances over the last decades. A core unit of a potential all-optical processor would be the NAND gate, which can be cascaded to perform an arbitrary logical operation. Here, we present the design and analysis of cascadable all-optical NAND gates using diffractive neural networks. We encoded the logical values at the input and output planes of a diffractive NAND gate using the relative optical power of two spatially-separated apertures. Based on this architecture, we numerically optimized the design of a diffractive neural network composed of 4 passive layers to all-optically perform NAND operation using the diffraction of light, and cascaded these diffractive NAND gates to perform complex logical functions by successively feeding the output of one diffractive NAND gate into another. We demonstrated the cascadability of our diffractive NAND gates by using identical diffractive designs to all-optically perform AND and OR operations, as well as a half-adder. Cascadable all-optical NAND gates composed of spatially-engineered passive diffractive layers can serve as a core component of various optical computing platforms. ",
    "url": "https://arxiv.org/abs/2111.01404",
    "authors": [
      "Yi Luo",
      "Deniz Mengu",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.01505",
    "title": "Out of distribution detection for skin and malaria images",
    "abstract": "Deep neural networks have shown promising results in disease detection and classification using medical image data. However, they still suffer from the challenges of handling real-world scenarios especially reliably detecting out-of-distribution (OoD) samples. We propose an approach to robustly classify OoD samples in skin and malaria images without the need to access labeled OoD samples during training. Specifically, we use metric learning along with logistic regression to force the deep networks to learn much rich class representative features. To guide the learning process against the OoD examples, we generate ID similar-looking examples by either removing class-specific salient regions in the image or permuting image parts and distancing them away from in-distribution samples. During inference time, the K-reciprocal nearest neighbor is employed to detect out-of-distribution samples. For skin cancer OoD detection, we employ two standard benchmark skin cancer ISIC datasets as ID, and six different datasets with varying difficulty levels were taken as out of distribution. For malaria OoD detection, we use the BBBC041 malaria dataset as ID and five different challenging datasets as out of distribution. We achieved state-of-the-art results, improving 5% and 4% in TNR@TPR95% over the previous state-of-the-art for skin cancer and malaria OoD detection respectively. ",
    "url": "https://arxiv.org/abs/2111.01505",
    "authors": [
      "Muhammad Zaida",
      "Shafaqat Ali",
      "Mohsen Ali",
      "Sarfaraz Hussein",
      "Asma Saadia",
      "Waqas Sultani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.01774",
    "title": "Emergence and structure of decentralised trade networks around dark web  marketplaces",
    "abstract": "Dark web marketplaces (DWMs) are online platforms that facilitate illicit trade among millions of users generating billions of dollars in annual revenue. Recently, two interview-based studies have suggested that DWMs may also promote the emergence of direct user-to-user (U2U) trading relationships. Here, we quantify the scale of, and thoroughly investigate, U2U trading around DWMs by analysing 31 million Bitcoin transactions among users of 40 DWMs between June 2011 and Jan 2021. We find that half of the DWM users trade through U2U pairs generating a total trading volume greater than DWMs themselves. We then show that hundreds of thousands of DWM users form stable trading pairs that are persistent over time. Users in stable pairs are typically the ones with the largest trading volume on DWMs. Then, we show that new U2U pairs often form while both users are active on the same DWM, suggesting the marketplace may serve as a catalyst for new direct trading relationships. Finally, we reveal that stable U2U pairs tend to survive DWM closures and that they were not affected by COVID-19, indicating that their trading activity is resilient to external shocks. Our work unveils sophisticated patterns of trade emerging in the dark web and highlights the importance of investigating user behaviour beyond the immediate buyer-seller network on a single marketplace. ",
    "url": "https://arxiv.org/abs/2111.01774",
    "authors": [
      "Matthieu Nadini",
      "Alberto Bracci",
      "Abeer ElBahrawy",
      "Philip Gradwell",
      "Alexander Teytelboym",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2006.09647",
    "title": "Regulating algorithmic filtering on social media",
    "abstract": " Comments: 23 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2006.09647",
    "authors": [
      "Sarah H. Cen",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2010.00300",
    "title": "OutbreakFlow: Model-based Bayesian inference of disease outbreak  dynamics with invertible neural networks and its application to the COVID-19  pandemics in Germany",
    "abstract": " Title: OutbreakFlow: Model-based Bayesian inference of disease outbreak  dynamics with invertible neural networks and its application to the COVID-19  pandemics in Germany ",
    "url": "https://arxiv.org/abs/2010.00300",
    "authors": [
      "Stefan T. Radev",
      "Frederik Graw",
      "Simiao Chen",
      "Nico T. Mutters",
      "Vanessa M. Eichel",
      "Till B\u00e4rnighausen",
      "Ullrich K\u00f6the"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2102.09759",
    "title": "Applications of deep learning in traffic congestion detection,  prediction and alleviation: A survey",
    "abstract": " Comments: 20 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2102.09759",
    "authors": [
      "Nishant Kumar",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.02040",
    "title": "Segmentation of EM showers for neutrino experiments with deep graph  neural networks",
    "abstract": " Comments: 29 pages, 27 figures ",
    "url": "https://arxiv.org/abs/2104.02040",
    "authors": [
      "Vladislav Belavin",
      "Ekaterina Trofimova",
      "Andrey Ustyuzhanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2106.09012",
    "title": "A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings",
    "abstract": " Title: A learning agent that acquires social norms from public sanctions in  decentralized multi-agent settings ",
    "url": "https://arxiv.org/abs/2106.09012",
    "authors": [
      "Eugene Vinitsky",
      "Raphael K\u00f6ster",
      "John P. Agapiou",
      "Edgar Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Alexander Sasha Vezhnevets",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2107.13875",
    "title": "Spatio-temporal graph neural networks for multi-site PV power  forecasting",
    "abstract": " Comments: 10 pages, 7 figures, accepted for publication in IEEE Transactions on Sustainable Energy ",
    "url": "https://arxiv.org/abs/2107.13875",
    "authors": [
      "Jelena Simeunovi\u0107",
      "Baptiste Schubnel",
      "Pierre-Jean Alet",
      "Rafael E. Carrillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.14124",
    "title": "A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems",
    "abstract": " Title: A novel decompostion-based multiobjective evolutionary algorithm with an  application to engineering optimal design problems ",
    "url": "https://arxiv.org/abs/2110.14124",
    "authors": [
      "Wang Chen",
      "Jian Chen",
      "Weitian Wu",
      "Xinmin Yang",
      "Hui Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  }
]