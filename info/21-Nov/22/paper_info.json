[
  {
    "id": "arXiv:2111.09955",
    "title": "SmartSlice: Dynamic, self-optimization of applications QoS requests to  5G networks",
    "abstract": "Applications can tailor a network slice by specifying a variety of QoS attributes related to application-specific performance, function or operation. However, some QoS attributes like guaranteed bandwidth required by the application do vary over time. For example, network bandwidth needs of video streams from surveillance cameras can vary a lot depending on the environmental conditions and the content in the video streams. In this paper, we propose a novel, dynamic QoS attribute prediction technique that assists any application to make optimal resource reservation requests at all times. Standard forecasting using traditional cost functions like MAE, MSE, RMSE, MDA, etc. don't work well because they do not take into account the direction (whether the forecasting of resources is more or less than needed), magnitude (by how much the forecast deviates, and in which direction), or frequency (how many times the forecast deviates from actual needs, and in which direction). The direction, magnitude and frequency have a direct impact on the application's accuracy of insights, and the operational costs. We propose a new, parameterized cost function that takes into account all three of them, and guides the design of a new prediction technique. To the best of our knowledge, this is the first work that considers time-varying application requirements and dynamically adjusts slice QoS requests to 5G networks in order to ensure a balance between application's accuracy and operational costs. In a real-world deployment of a surveillance video analytics application over 17 cameras, we show that our technique outperforms other traditional forecasting methods, and it saves 34% of network bandwidth (over a ~24 hour period) when compared to a static, one-time reservation. ",
    "url": "https://arxiv.org/abs/2111.09955",
    "authors": [
      "Kunal Rao",
      "Murugan Sankaradas",
      "Vivek Aswal",
      "Srimat Chakradhar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.10075",
    "title": "Enhanced countering adversarial attacks via input denoising and feature  restoring",
    "abstract": "Despite the fact that deep neural networks (DNNs) have achieved prominent performance in various applications, it is well known that DNNs are vulnerable to adversarial examples/samples (AEs) with imperceptible perturbations in clean/original samples. To overcome the weakness of the existing defense methods against adversarial attacks, which damages the information on the original samples, leading to the decrease of the target classifier accuracy, this paper presents an enhanced countering adversarial attack method IDFR (via Input Denoising and Feature Restoring). The proposed IDFR is made up of an enhanced input denoiser (ID) and a hidden lossy feature restorer (FR) based on the convex hull optimization. Extensive experiments conducted on benchmark datasets show that the proposed IDFR outperforms the various state-of-the-art defense methods, and is highly effective for protecting target models against various adversarial black-box or white-box attacks. \\footnote{Souce code is released at: \\href{https://github.com/ID-FR/IDFR}{https://github.com/ID-FR/IDFR}} ",
    "url": "https://arxiv.org/abs/2111.10075",
    "authors": [
      "Yanni Li",
      "Wenhui Zhang",
      "Jiawei Liu",
      "Xiaoli Kou",
      "Hui Li",
      "Jiangtao Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10167",
    "title": "UEFI virtual machine firmware hardening through snapshots and attack  surface reduction",
    "abstract": "The Unified Extensible Firmware Interface (UEFI) is a standardised interface between the firmware and the operating system used in all x86-based platforms over the past ten years. A side effect of the transition from conventional BIOS implementations to more complex and flexible implementations based on the UEFI was that it became easier for the malware to target BIOS in a widespread fashion, as these BIOS implementations are based on a common specification. This paper introduces Amaranth project - a solution to some of the contemporary security issues related to UEFI firmware. In this work we focused our attention on virtual machines as it allowed us to simplify the development of secure UEFI firmware. Security hardening of our firmware is achieved through several techniques, the most important of which are an operating system integrity checking mechanism (through snapshots) and overall firmware size reduction. ",
    "url": "https://arxiv.org/abs/2111.10167",
    "authors": [
      "Mikhail Krichanov",
      "Vitaly Cheptsov"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.10272",
    "title": "Resilience from Diversity: Population-based approach to harden models  against adversarial attacks",
    "abstract": "Traditional deep learning models exhibit intriguing vulnerabilities that allow an attacker to force them to fail at their task. Notorious attacks such as the Fast Gradient Sign Method (FGSM) and the more powerful Projected Gradient Descent (PGD) generate adversarial examples by adding a magnitude of perturbation $\\epsilon$ to the input's computed gradient, resulting in a deterioration of the effectiveness of the model's classification. This work introduces a model that is resilient to adversarial attacks. Our model leverages a well established principle from biological sciences: population diversity produces resilience against environmental changes. More precisely, our model consists of a population of $n$ diverse submodels, each one of them trained to individually obtain a high accuracy for the task at hand, while forced to maintain meaningful differences in their weight tensors. Each time our model receives a classification query, it selects a submodel from its population at random to answer the query. To introduce and maintain diversity in population of submodels, we introduce the concept of counter linking weights. A Counter-Linked Model (CLM) consists of submodels of the same architecture where a periodic random similarity examination is conducted during the simultaneous training to guarantee diversity while maintaining accuracy. In our testing, CLM robustness got enhanced by around 20% when tested on the MNIST dataset and at least 15% when tested on the CIFAR-10 dataset. When implemented with adversarially trained submodels, this methodology achieves state-of-the-art robustness. On the MNIST dataset with $\\epsilon=0.3$, it achieved 94.34% against FGSM and 91% against PGD. On the CIFAR-10 dataset with $\\epsilon=8/255$, it achieved 62.97% against FGSM and 59.16% against PGD. ",
    "url": "https://arxiv.org/abs/2111.10272",
    "authors": [
      "Jasser Jasser",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10293",
    "title": "A 3D 2D convolutional Neural Network Model for Hyperspectral Image  Classification",
    "abstract": "In the proposed SEHybridSN model, a dense block was used to reuse shallow feature and aimed at better exploiting hierarchical spatial spectral feature. Subsequent depth separable convolutional layers were used to discriminate the spatial information. Further refinement of spatial spectral features was realized by the channel attention method, which were performed behind every 3D convolutional layer and every 2D convolutional layer. Experiment results indicate that our proposed model learn more discriminative spatial spectral features using very few training data. SEHybridSN using only 0.05 and 0.01 labeled data for training, a very satisfactory performance is obtained. ",
    "url": "https://arxiv.org/abs/2111.10293",
    "authors": [
      "Jiaxin Cao",
      "Xiaoyan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.09902",
    "title": "A transformer-based model for default prediction in mid-cap corporate  markets",
    "abstract": "In this paper, we study mid-cap companies, i.e. publicly traded companies with less than US $10 billion in market capitalisation. Using a large dataset of US mid-cap companies observed over 30 years, we look to predict the default probability term structure over the medium term and understand which data sources (i.e. fundamental, market or pricing data) contribute most to the default risk. Whereas existing methods typically require that data from different time periods are first aggregated and turned into cross-sectional features, we frame the problem as a multi-label time-series classification problem. We adapt transformer models, a state-of-the-art deep learning model emanating from the natural language processing domain, to the credit risk modelling setting. We also interpret the predictions of these models using attention heat maps. To optimise the model further, we present a custom loss function for multi-label classification and a novel multi-channel architecture with differential training that gives the model the ability to use all input data efficiently. Our results show the proposed deep learning architecture's superior performance, resulting in a 13% improvement in AUC (Area Under the receiver operating characteristic Curve) over traditional models. We also demonstrate how to produce an importance ranking for the different data sources and the temporal relationships using a Shapley approach specific to these models. ",
    "url": "https://arxiv.org/abs/2111.09902",
    "authors": [
      "Kamesh Korangi",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10038",
    "title": "From word-representable graphs to altered Tverberg-type theorems",
    "abstract": "Tverberg's theorem says that a set with sufficiently many points in $\\mathbb{R}^d$ can always be partitioned into $m$ parts so that the $(m-1)$-simplex is the (nerve) intersection pattern of the convex hulls of the parts. In arXiv:1808.00551v1 [math.MG] the authors investigate how other simplicial complexes arise as nerve complexes once we have a set with sufficiently many points. In this paper we relate the theory of word-representable graphs as a way of codifying $1$-skeletons of simplicial complexes to generate nerves. In particular, we show that every $2$-word-representable triangle-free graph, every circle graph, every outerplanar graph, and every bipartite graph could be induced as a nerve complex once we have a set with sufficiently many points in $\\mathbb{R}^d$ for some $d$. ",
    "url": "https://arxiv.org/abs/2111.10038",
    "authors": [
      "Deborah Oliveros",
      "Antonio Torres"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2111.10043",
    "title": "A comparison of streaming models and data augmentation methods for  robust speech recognition",
    "abstract": "In this paper, we present a comparative study on the robustness of two different online streaming speech recognition models: Monotonic Chunkwise Attention (MoChA) and Recurrent Neural Network-Transducer (RNN-T). We explore three recently proposed data augmentation techniques, namely, multi-conditioned training using an acoustic simulator, Vocal Tract Length Perturbation (VTLP) for speaker variability, and SpecAugment. Experimental results show that unidirectional models are in general more sensitive to noisy examples in the training set. It is observed that the final performance of the model depends on the proportion of training examples processed by data augmentation techniques. MoChA models generally perform better than RNN-T models. However, we observe that training of MoChA models seems to be more sensitive to various factors such as the characteristics of training sets and the incorporation of additional augmentations techniques. On the other hand, RNN-T models perform better than MoChA models in terms of latency, inference time, and the stability of training. Additionally, RNN-T models are generally more robust against noise and reverberation. All these advantages make RNN-T models a better choice for streaming on-device speech recognition compared to MoChA models. ",
    "url": "https://arxiv.org/abs/2111.10043",
    "authors": [
      "Jiyeon Kim",
      "Mehul Kumar",
      "Dhananjaya Gowda",
      "Abhinav Garg",
      "Chanwoo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2111.10262",
    "title": "Residual fourier neural operator for thermochemical curing of composites",
    "abstract": "During the curing process of composites, the temperature history heavily determines the evolutions of the field of degree of cure as well as the residual stress, which will further influence the mechanical properties of composite, thus it is important to simulate the real temperature history to optimize the curing process of composites. Since thermochemical analysis using Finite Element (FE) simulations requires heavy computational loads and data-driven approaches suffer from the complexity of highdimensional mapping. This paper proposes a Residual Fourier Neural Operator (ResFNO) to establish the direct high-dimensional mapping from any given cure cycle to the corresponding temperature histories. By integrating domain knowledge into a time-resolution independent parameterized neural network, the mapping between cure cycles to temperature histories can be learned using limited number of labelled data. Besides, a novel Fourier residual mapping is designed based on mode decomposition to accelerate the training and boost the performance significantly. Several cases are carried out to evaluate the superior performance and generalizability of the proposed method comprehensively. ",
    "url": "https://arxiv.org/abs/2111.10262",
    "authors": [
      "Gengxiang Chen",
      "Yingguang Li",
      "Xu liu",
      "Qinglu Meng",
      "Jing Zhou",
      "Xiaozhong Hao"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1912.09323",
    "title": "NFAD: Fixing anomaly detection using normalizing flows",
    "abstract": " Title: NFAD: Fixing anomaly detection using normalizing flows ",
    "url": "https://arxiv.org/abs/1912.09323",
    "authors": [
      "Artem Ryzhikov",
      "Maxim Borisyak",
      "Andrey Ustyuzhanin",
      "Denis Derkach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2003.05425",
    "title": "Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric  graphs",
    "abstract": " Comments: Published at ICLR 2021 ",
    "url": "https://arxiv.org/abs/2003.05425",
    "authors": [
      "Pim de Haan",
      "Maurice Weiler",
      "Taco Cohen",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2005.10058",
    "title": "On embedding Lambek calculus into commutative categorial grammars",
    "abstract": " Comments: Some computational errors corrected. The final version of this draft was published in Jpurnal of Logic and Computation, Oxford University press ",
    "url": "https://arxiv.org/abs/2005.10058",
    "authors": [
      "Sergey Slavnov"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2007.00714",
    "title": "Quantifying intrinsic causal contributions via structure preserving  interventions",
    "abstract": " Title: Quantifying intrinsic causal contributions via structure preserving  interventions ",
    "url": "https://arxiv.org/abs/2007.00714",
    "authors": [
      "Dominik Janzing",
      "Patrick Bl\u00f6baum",
      "Lenon Minorics",
      "Philipp Faller",
      "Atalanti Mastakouri"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.06795",
    "title": "Similarity network fusion for scholarly journals",
    "abstract": " Comments: 21 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2011.06795",
    "authors": [
      "Federica Baccini",
      "Lucio Barabesi",
      "Alberto Baccini",
      "Mahdi Khelfaoui",
      "Yves Gingras"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2103.05222",
    "title": "Data augmentation by morphological mixup for solving Raven's Progressive  Matrices",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2103.05222",
    "authors": [
      "Wentao He",
      "Jianfeng Ren",
      "Ruibin Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.14886",
    "title": "Generalization over different cellular automata rules learned by a deep  feed-forward neural network",
    "abstract": " Comments: Accepted at 23rd International Conference on Artificial Intelligence (July 2021, Las Vegas, USA) To appear in: Springer Transactions on Computational Science & Computational Intelligence ",
    "url": "https://arxiv.org/abs/2103.14886",
    "authors": [
      "Marcel Aach",
      "Jens Henrik Goebbert",
      "Jenia Jitsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  }
]