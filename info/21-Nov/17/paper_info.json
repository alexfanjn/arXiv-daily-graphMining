[
  {
    "id": "arXiv:2111.08092",
    "title": "Improving the performance of reputation evaluating by combining the  structure of network and nonlinear recovery",
    "abstract": "Characterizing the reputation of an evaluator is particularly significant for consumer to obtain useful information from online rating systems. Furthermore, to overcome the difficulties with spam attacks on the rating system and to get the reliable on reputation of evaluators is an important topic in the research. We have noticed that most of the existing evaluator reputation evaluation methods only rely on the evaluator's rating information and abnormal behavior to establish a reputation system, which miss the systematic aspects of the rating systems including the structure of the evaluator-object bipartite network and the effects of nonlinear effects. This study we propose an improved reputation evaluation method by combining the structure of the evaluator-object bipartite network with rating information and introducing penalty and reward factors. This novel method has been empirically analyzed on a large-scale artificial data set and two real data sets. The results show that the proposed method is more accurate and robust in the presence of spam attacks. This fresh idea contributes a new way for building reputation evaluation models in sparse bipartite rating network. ",
    "url": "https://arxiv.org/abs/2111.08092",
    "authors": [
      "Meng Li",
      "Chengyuan Han",
      "Yuanxiang Jiang",
      "Zengru Di"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.08117",
    "title": "Neural networks with linear threshold activations: structure and  algorithms",
    "abstract": "In this article we present new results on neural networks with linear threshold activation functions. We precisely characterize the class of functions that are representable by such neural networks and show that 2 hidden layers are necessary and sufficient to represent any function representable in the class. This is a surprising result in the light of recent exact representability investigations for neural networks using other popular activation functions like rectified linear units (ReLU). We also give precise bounds on the sizes of the neural networks required to represent any function in the class. Finally, we design an algorithm to solve the empirical risk minimization (ERM) problem to global optimality for these neural networks with a fixed architecture. The algorithm's running time is polynomial in the size of the data sample, if the input dimension and the size of the network architecture are considered fixed constants. The algorithm is unique in the sense that it works for any architecture with any number of layers, whereas previous polynomial time globally optimal algorithms work only for very restricted classes of architectures. ",
    "url": "https://arxiv.org/abs/2111.08117",
    "authors": [
      "Sammy Khalife",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08146",
    "title": "A note on averaging prediction accuracy, Green's functions and other  kernels",
    "abstract": "In this note, we analyze a procedure used in predictive security applications that motivates the definition of the integral average transform. Our motivation comes from the need for a better mathematical understanding of the prediction accuracy index. This index is used to identify hot spots in predictive security and other applications. We present the mathematical context of the predictive accuracy index and then introduce the definition of integral average transform. We establish the relation of our definition with two variables kernels $K({\\bf y},{\\bf x})$. As an example of an application we show that integrating against the fundamental solution of the Laplace operator, that is, solving the Poisson equation, can be re-interpreted as an integral of averages of the forcing term over balls. ",
    "url": "https://arxiv.org/abs/2111.08146",
    "authors": [
      "J. Galvis",
      "Freddy Hern\u00e1ndez",
      "Francisco G\u00f3mez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Analysis of PDEs (math.AP)",
      "Classical Analysis and ODEs (math.CA)"
    ]
  },
  {
    "id": "arXiv:2111.08185",
    "title": "Graph neural network-based fault diagnosis: a review",
    "abstract": "Graph neural network (GNN)-based fault diagnosis (FD) has received increasing attention in recent years, due to the fact that data coming from several application domains can be advantageously represented as graphs. Indeed, this particular representation form has led to superior performance compared to traditional FD approaches. In this review, an easy introduction to GNN, potential applications to the field of fault diagnosis, and future perspectives are given. First, the paper reviews neural network-based FD methods by focusing on their data representations, namely, time-series, images, and graphs. Second, basic principles and principal architectures of GNN are introduced, with attention to graph convolutional networks, graph attention networks, graph sample and aggregate, graph auto-encoder, and spatial-temporal graph convolutional networks. Third, the most relevant fault diagnosis methods based on GNN are validated through the detailed experiments, and conclusions are made that the GNN-based methods can achieve good fault diagnosis performance. Finally, discussions and future challenges are provided. ",
    "url": "https://arxiv.org/abs/2111.08185",
    "authors": [
      "Zhiwen Chen",
      "Jiamin Xu",
      "Cesare Alippi",
      "Steven X. Ding",
      "Yuri Shardt",
      "Tao Peng",
      "Chunhua Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08191",
    "title": "CCA-MDD: A Coupled Cross-Attention based Framework for Streaming  Mispronunciation detection and diagnosis",
    "abstract": "End-to-end models are becoming popular approaches for mispronunciation detection and diagnosis (MDD). A streaming MDD framework which is demanded by many practical applications still remains a challenge. This paper proposes a streaming end-to-end MDD framework called CCA-MDD. CCA-MDD supports online processing and is able to run strictly in real-time. The encoder of CCA-MDD consists of a conv-Transformer network based streaming acoustic encoder and an improved cross-attention named coupled cross-attention (CCA). The coupled cross-attention integrates encoded acoustic features with pre-encoded linguistic features. An ensemble of decoders trained from multi-task learning is applied for final MDD decision. Experiments on publicly available corpora demonstrate that CCA-MDD achieves comparable performance to published offline end-to-end MDD models. ",
    "url": "https://arxiv.org/abs/2111.08191",
    "authors": [
      "Nianzu Zheng",
      "Liqun Deng",
      "Wenyong Huang",
      "Yu Ting Yeung",
      "Baohua Xu",
      "Yuanyuan Guo",
      "Yasheng Wang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.08264",
    "title": "Analysis of 5G academic Network based on graph representation learning  method",
    "abstract": "With the rapid development of 5th Generation Mobile Communication Technology (5G), the diverse forms of collaboration and extensive data in academic social networks constructed by 5G papers make the management and analysis of academic social networks increasingly challenging. Despite the particular success achieved by representation learning in analyzing academic and social networks, most present presentation learning models focus on maintaining the first-order and second-order similarity of nodes. They rarely possess similar structural characteristics of spatial independence in the network. This paper proposes a Low-order Network representation Learning Model (LNLM) based on Non-negative Matrix Factorization (NMF) to solve these problems. The model uses the random walk method to extract low-order features of nodes and map multiple components to a low-dimensional space, effectively maintaining the internal correlation between members. This paper verifies the performance of this model, conducts comparative experiments on four test datasets and four real network datasets through downstream tasks such as multi-label classification, clustering, and link prediction. Comparing eight mainstream network representation learning models shows that the proposed model can significantly improve the detection efficiency and learning methods and effectively extract local and low-order features of the network. ",
    "url": "https://arxiv.org/abs/2111.08264",
    "authors": [
      "Xiaoming Li",
      "Guangquan Xu",
      "Wei Yu",
      "Pengfei Jiao",
      "Xiangyu Song"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2111.08272",
    "title": "Task allocation for decentralized training in heterogeneous environment",
    "abstract": "The demand for large-scale deep learning is increasing, and distributed training is the current mainstream solution. Ring AllReduce is widely used as a data parallel decentralized algorithm. However, in a heterogeneous environment, each worker calculates the same amount of data, so that there is a lot of waiting time loss among different workers, which makes the algorithm unable to adapt well to heterogeneous clusters. Resources are not used as they should be. In this paper, we design an implementation of static allocation algorithm. The dataset is artificially allocated to each worker, and samples are drawn proportionally for training, thereby speeding up the training speed of the network in a heterogeneous environment. We verify the convergence and influence on training speed of the network model under this algorithm on one machine with multi-card and multi-machine with multi-card. On this basis of feasibility, we propose a self-adaptive allocation algorithm that allows each machine to find the data it needs to adapt to the current environment. The self-adaptive allocation algorithm can reduce the training time by nearly one-third to half compared to the same proportional allocation.In order to better show the applicability of the algorithm in heterogeneous clusters, We replace a poorly performing worker with a good performing worker or add a poorly performing worker to the heterogeneous cluster. Experimental results show that training time will decrease as the overall performance improves. Therefore, it means that resources are fully used. Further, this algorithm is not only suitable for straggler problems, but also for most heterogeneous situations. It can be used as a plug-in for AllReduce and its variant algorithms. ",
    "url": "https://arxiv.org/abs/2111.08272",
    "authors": [
      "Yongyue Chao",
      "Mingxue Liao",
      "Jiaxin Gao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2111.08275",
    "title": "Deep Distilling: automated code generation using explainable deep  learning",
    "abstract": "Human reasoning can distill principles from observed patterns and generalize them to explain and solve novel problems. The most powerful artificial intelligence systems lack explainability and symbolic reasoning ability, and have therefore not achieved supremacy in domains requiring human understanding, such as science or common sense reasoning. Here we introduce deep distilling, a machine learning method that learns patterns from data using explainable deep learning and then condenses it into concise, executable computer code. The code, which can contain loops, nested logical statements, and useful intermediate variables, is equivalent to the neural network but is generally orders of magnitude more compact and human-comprehensible. On a diverse set of problems involving arithmetic, computer vision, and optimization, we show that deep distilling generates concise code that generalizes out-of-distribution to solve problems orders-of-magnitude larger and more complex than the training data. For problems with a known ground-truth rule set, deep distilling discovers the rule set exactly with scalable guarantees. For problems that are ambiguous or computationally intractable, the distilled rules are similar to existing human-derived algorithms and perform at par or better. Our approach demonstrates that unassisted machine intelligence can build generalizable and intuitive rules explaining patterns in large datasets that would otherwise overwhelm human reasoning. ",
    "url": "https://arxiv.org/abs/2111.08275",
    "authors": [
      "Paul J. Blazek",
      "Kesavan Venkatesh",
      "Milo M. Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08324",
    "title": "Choose Settings Carefully: Comparing Action Unit detection at Different  Settings Using a Large-Scale Dataset",
    "abstract": "In this paper, we investigate the impact of some of the commonly used settings for (a) preprocessing face images, and (b) classification and training, on Action Unit (AU) detection performance and complexity. We use in our investigation a large-scale dataset, consisting of ~55K videos collected in the wild for participants watching commercial ads. The preprocessing settings include scaling the face to a fixed resolution, changing the color information (RGB to gray-scale), aligning the face, and cropping AU regions, while the classification and training settings include the kind of classifier (multi-label vs. binary) and the amount of data used for training models. To the best of our knowledge, no work had investigated the effect of those settings on AU detection. In our analysis we use CNNs as our baseline classification model. ",
    "url": "https://arxiv.org/abs/2111.08324",
    "authors": [
      "Mina Bishay",
      "Ahmed Ghoneim",
      "Mohamed Ashraf",
      "Mohammad Mavadati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.08334",
    "title": "Pansharpening by convolutional neural networks in the full resolution  framework",
    "abstract": "In recent years, there has been a growing interest on deep learning-based pansharpening. Research has mainly focused on architectures. However, lacking a ground truth, model training is also a major issue. A popular approach is to train networks in a reduced resolution domain, using the original data as ground truths. The trained networks are then used on full resolution data, relying on an implicit scale invariance hypothesis. Results are generally good at reduced resolution, but more questionable at full resolution. Here, we propose a full-resolution training framework for deep learning-based pansharpening. Training takes place in the high resolution domain, relying only on the original data, with no loss of information. To ensure spectral and spatial fidelity, suitable losses are defined, which force the pansharpened output to be consistent with the available panchromatic and multispectral input. Experiments carried out on WorldView-3, WorldView-2, and GeoEye-1 images show that methods trained with the proposed framework guarantee an excellent performance in terms of both full-resolution numerical indexes and visual quality. The framework is fully general, and can be used to train and fine-tune any deep learning-based pansharpening network. ",
    "url": "https://arxiv.org/abs/2111.08334",
    "authors": [
      "Matteo Ciotola",
      "Sergio Vitale",
      "Antonio Mazza",
      "Giovanni Poggi",
      "Giuseppe Scarpa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.08452",
    "title": "On minimizers and convolutional filters: a partial justification for the  unreasonable effectiveness of CNNs in categorical sequence analysis",
    "abstract": "Minimizers and convolutional neural networks (CNNs) are two quite distinct popular techniques that have both been employed to analyze biological sequences. At face value, the methods seem entirely dissimilar. Minimizers use min-wise hashing on a rolling window to extract a single important k-mer feature per window. CNNs start with a wide array of randomly initialized convolutional filters, paired with a pooling operation, and then multiple additional neural layers to learn both the filters themselves and how those filters can be used to classify the sequence. In this manuscript, I demonstrate through a careful mathematical analysis of hash function properties that there are deep theoretical connections between minimizers and convolutional filters -- in short, for sequences over a categorical alphabet, random Gaussian initialization of convolutional filters with max-pooling is equivalent to choosing minimizers from a random hash function biased towards more distinct k-mers. This provides a partial explanation for the unreasonable effectiveness of CNNs in categorical sequence analysis. ",
    "url": "https://arxiv.org/abs/2111.08452",
    "authors": [
      "Yun William Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2111.08468",
    "title": "Point detection through multi-instance deep heatmap regression for  sutures in endoscopy",
    "abstract": "Purpose: Mitral valve repair is a complex minimally invasive surgery of the heart valve. In this context, suture detection from endoscopic images is a highly relevant task that provides quantitative information to analyse suturing patterns, assess prosthetic configurations and produce augmented reality visualisations. Facial or anatomical landmark detection tasks typically contain a fixed number of landmarks, and use regression or fixed heatmap-based approaches to localize the landmarks. However in endoscopy, there are a varying number of sutures in every image, and the sutures may occur at any location in the annulus, as they are not semantically unique. Method: In this work, we formulate the suture detection task as a multi-instance deep heatmap regression problem, to identify entry and exit points of sutures. We extend our previous work, and introduce the novel use of a 2D Gaussian layer followed by a differentiable 2D spatial Soft-Argmax layer to function as a local non-maximum suppression. Results: We present extensive experiments with multiple heatmap distribution functions and two variants of the proposed model. In the intra-operative domain, Variant 1 showed a mean F1 of +0.0422 over the baseline. Similarly, in the simulator domain, Variant 1 showed a mean F1 of +0.0865 over the baseline. Conclusion: The proposed model shows an improvement over the baseline in the intra-operative and the simulator domains. The data is made publicly available within the scope of the MICCAI AdaptOR2021 Challenge https://adaptor2021.github.io/, and the code at https://github.com/Cardio-AI/suture-detection-pytorch/. DOI:10.1007/s11548-021-02523-w. The link to the open access article can be found here: https://link.springer.com/article/10.1007%2Fs11548-021-02523-w ",
    "url": "https://arxiv.org/abs/2111.08468",
    "authors": [
      "Lalith Sharan",
      "Gabriele Romano",
      "Julian Brand",
      "Halvar Kelm",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.08481",
    "title": "PySINDy: A comprehensive Python package for robust sparse system  identification",
    "abstract": "Automated data-driven modeling, the process of directly discovering the governing equations of a system from data, is increasingly being used across the scientific community. PySINDy is a Python package that provides tools for applying the sparse identification of nonlinear dynamics (SINDy) approach to data-driven model discovery. In this major update to PySINDy, we implement several advanced features that enable the discovery of more general differential equations from noisy and limited data. The library of candidate terms is extended for the identification of actuated systems, partial differential equations (PDEs), and implicit differential equations. Robust formulations, including the integral form of SINDy and ensembling techniques, are also implemented to improve performance for real-world data. Finally, we provide a range of new optimization algorithms, including several sparse regression techniques and algorithms to enforce and promote inequality constraints and stability. Together, these updates enable entirely new SINDy model discovery capabilities that have not been reported in the literature, such as constrained PDE identification and ensembling with different sparse regression optimizers. ",
    "url": "https://arxiv.org/abs/2111.08481",
    "authors": [
      "Alan A. Kaptanoglu",
      "Brian M. de Silva",
      "Urban Fasel",
      "Kadierdan Kaheman",
      "Jared L. Callaham",
      "Charles B. Delahunt",
      "Kathleen Champion",
      "Jean-Christophe Loiseau",
      "J. Nathan Kutz",
      "Steven L. Brunton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2111.08492",
    "title": "SequentialPointNet: A strong parallelized point cloud sequence network  for 3D action recognition",
    "abstract": "Point cloud sequences of 3D human actions exhibit unordered intra-frame spatial information and ordered interframe temporal information. In order to capture the spatiotemporal structures of the point cloud sequences, cross-frame spatio-temporal local neighborhoods around the centroids are usually constructed. However, the computationally expensive construction procedure of spatio-temporal local neighborhoods severely limits the parallelism of models. Moreover, it is unreasonable to treat spatial and temporal information equally in spatio-temporal local learning, because human actions are complicated along the spatial dimensions and simple along the temporal dimension. In this paper, to avoid spatio-temporal local encoding, we propose a strong parallelized point cloud sequence network referred to as SequentialPointNet for 3D action recognition. SequentialPointNet is composed of two serial modules, i.e., an intra-frame appearance encoding module and an inter-frame motion encoding module. For modeling the strong spatial structures of human actions, each point cloud frame is processed in parallel in the intra-frame appearance encoding module and the feature vector of each frame is output to form a feature vector sequence that characterizes static appearance changes along the temporal dimension. For modeling the weak temporal changes of human actions, in the inter-frame motion encoding module, the temporal position encoding and the hierarchical pyramid pooling strategy are implemented on the feature vector sequence. In addition, in order to better explore spatio-temporal content, multiple level features of human movements are aggregated before performing the end-to-end 3D action recognition. Extensive experiments conducted on three public datasets show that SequentialPointNet outperforms stateof-the-art approaches. ",
    "url": "https://arxiv.org/abs/2111.08492",
    "authors": [
      "Xing Li",
      "Qian Huang",
      "Zhijian Wang",
      "Zhenjie Hou",
      "Tianjin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.08529",
    "title": "Improving the robustness and accuracy of biomedical language models  through adversarial training",
    "abstract": "Deep transformer neural network models have improved the predictive accuracy of intelligent text processing systems in the biomedical domain. They have obtained state-of-the-art performance scores on a wide variety of biomedical and clinical Natural Language Processing (NLP) benchmarks. However, the robustness and reliability of these models has been less explored so far. Neural NLP models can be easily fooled by adversarial samples, i.e. minor changes to input that preserve the meaning and understandability of the text but force the NLP system to make erroneous decisions. This raises serious concerns about the security and trust-worthiness of biomedical NLP systems, especially when they are intended to be deployed in real-world use cases. We investigated the robustness of several transformer neural language models, i.e. BioBERT, SciBERT, BioMed-RoBERTa, and Bio-ClinicalBERT, on a wide range of biomedical and clinical text processing tasks. We implemented various adversarial attack methods to test the NLP systems in different attack scenarios. Experimental results showed that the biomedical NLP models are sensitive to adversarial samples; their performance dropped in average by 21 and 18.9 absolute percent on character-level and word-level adversarial noise, respectively. Conducting extensive adversarial training experiments, we fine-tuned the NLP models on a mixture of clean samples and adversarial inputs. Results showed that adversarial training is an effective defense mechanism against adversarial noise; the models robustness improved in average by 11.3 absolute percent. In addition, the models performance on clean data increased in average by 2.4 absolute present, demonstrating that adversarial training can boost generalization abilities of biomedical NLP systems. ",
    "url": "https://arxiv.org/abs/2111.08529",
    "authors": [
      "Milad Moradi",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.08585",
    "title": "CEHR-BERT: Incorporating temporal information from structured EHR data  to improve prediction tasks",
    "abstract": "Embedding algorithms are increasingly used to represent clinical concepts in healthcare for improving machine learning tasks such as clinical phenotyping and disease prediction. Recent studies have adapted state-of-the-art bidirectional encoder representations from transformers (BERT) architecture to structured electronic health records (EHR) data for the generation of contextualized concept embeddings, yet do not fully incorporate temporal data across multiple clinical domains. Therefore we developed a new BERT adaptation, CEHR-BERT, to incorporate temporal information using a hybrid approach by augmenting the input to BERT using artificial time tokens, incorporating time, age, and concept embeddings, and introducing a new second learning objective for visit type. CEHR-BERT was trained on a subset of Columbia University Irving Medical Center-York Presbyterian Hospital's clinical data, which includes 2.4M patients, spanning over three decades, and tested using 4-fold cross-validation on the following prediction tasks: hospitalization, death, new heart failure (HF) diagnosis, and HF readmission. Our experiments show that CEHR-BERT outperformed existing state-of-the-art clinical BERT adaptations and baseline models across all 4 prediction tasks in both ROC-AUC and PR-AUC. CEHR-BERT also demonstrated strong transfer learning capability, as our model trained on only 5% of data outperformed comparison models trained on the entire data set. Ablation studies to better understand the contribution of each time component showed incremental gains with every element, suggesting that CEHR-BERT's incorporation of artificial time tokens, time and age embeddings with concept embeddings, and the addition of the second learning objective represents a promising approach for future BERT-based clinical embeddings. ",
    "url": "https://arxiv.org/abs/2111.08585",
    "authors": [
      "Chao Pang",
      "Xinzhuo Jiang",
      "Krishna S Kalluri",
      "Matthew Spotnitz",
      "RuiJun Chen",
      "Adler Perotte",
      "Karthik Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08691",
    "title": "Uncertainty quantification and inverse modeling for subsurface flow in  3D heterogeneous formations using a theory-guided convolutional  encoder-decoder network",
    "abstract": "We build surrogate models for dynamic 3D subsurface single-phase flow problems with multiple vertical producing wells. The surrogate model provides efficient pressure estimation of the entire formation at any timestep given a stochastic permeability field, arbitrary well locations and penetration lengths, and a timestep matrix as inputs. The well production rate or bottom hole pressure can then be determined based on Peaceman's formula. The original surrogate modeling task is transformed into an image-to-image regression problem using a convolutional encoder-decoder neural network architecture. The residual of the governing flow equation in its discretized form is incorporated into the loss function to impose theoretical guidance on the model training process. As a result, the accuracy and generalization ability of the trained surrogate models are significantly improved compared to fully data-driven models. They are also shown to have flexible extrapolation ability to permeability fields with different statistics. The surrogate models are used to conduct uncertainty quantification considering a stochastic permeability field, as well as to infer unknown permeability information based on limited well production data and observation data of formation properties. Results are shown to be in good agreement with traditional numerical simulation tools, but computational efficiency is dramatically improved. ",
    "url": "https://arxiv.org/abs/2111.08691",
    "authors": [
      "Rui Xu",
      "Dongxiao Zhang",
      "Nanzhe Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2111.08014",
    "title": "Tensor network to learn the wavefunction of data",
    "abstract": "How many different ways are there to handwrite digit 3? To quantify this question imagine extending a dataset of handwritten digits MNIST by sampling additional images until they start repeating. We call the collection of all resulting images of digit 3 the \"full set.\" To study the properties of the full set we introduce a tensor network architecture which simultaneously accomplishes both classification (discrimination) and sampling tasks. Qualitatively, our trained network represents the indicator function of the full set. It therefore can be used to characterize the data itself. We illustrate that by studying the full sets associated with the digits of MNIST. Using quantum mechanical interpretation of our network we characterize the full set by calculating its entanglement entropy. We also study its geometric properties such as mean Hamming distance, effective dimension, and size. The latter answers the question above -- the total number of black and white threes written MNIST style is $2^{72}$. ",
    "url": "https://arxiv.org/abs/2111.08014",
    "authors": [
      "Anatoly Dymarsky",
      "Kirill Pavlenko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08228",
    "title": "SStaGCN: Simplified stacking based graph convolutional networks",
    "abstract": "Graph convolutional network (GCN) is a powerful model studied broadly in various graph structural data learning tasks. However, to mitigate the over-smoothing phenomenon, and deal with heterogeneous graph structural data, the design of GCN model remains a crucial issue to be investigated. In this paper, we propose a novel GCN called SStaGCN (Simplified stacking based GCN) by utilizing the ideas of stacking and aggregation, which is an adaptive general framework for tackling heterogeneous graph data. Specifically, we first use the base models of stacking to extract the node features of a graph. Subsequently, aggregation methods such as mean, attention and voting techniques are employed to further enhance the ability of node features extraction. Thereafter, the node features are considered as inputs and fed into vanilla GCN model. Furthermore, theoretical generalization bound analysis of the proposed model is explicitly given. Extensive experiments on $3$ public citation networks and another $3$ heterogeneous tabular data demonstrate the effectiveness and efficiency of the proposed approach over state-of-the-art GCNs. Notably, the proposed SStaGCN can efficiently mitigate the over-smoothing problem of GCN. ",
    "url": "https://arxiv.org/abs/2111.08228",
    "authors": [
      "Jia Cai",
      "Zhilong Xiong",
      "Shaogao Lv"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08387",
    "title": "S-DCCRN: Super Wide Band DCCRN with learnable complex feature for speech  enhancement",
    "abstract": "In speech enhancement, complex neural network has shown promising performance due to their effectiveness in processing complex-valued spectrum. Most of the recent speech enhancement approaches mainly focus on wide-band signal with a sampling rate of 16K Hz. However, research on super wide band (e.g., 32K Hz) or even full-band (48K) denoising is still lacked due to the difficulty of modeling more frequency bands and particularly high frequency components. In this paper, we extend our previous deep complex convolution recurrent neural network (DCCRN) substantially to a super wide band version -- S-DCCRN, to perform speech denoising on speech of 32K Hz sampling rate. We first employ a cascaded sub-band and full-band processing module, which consists of two small-footprint DCCRNs -- one operates on sub-band signal and one operates on full-band signal, aiming at benefiting from both local and global frequency information. Moreover, instead of simply adopting the STFT feature as input, we use a complex feature encoder trained in an end-to-end manner to refine the information of different frequency bands. We also use a complex feature decoder to revert the feature to time-frequency domain. Finally, a learnable spectrum compression method is adopted to adjust the energy of different frequency bands, which is beneficial for neural network learning. The proposed model, S-DCCRN, has surpassed PercepNet as well as several competitive models and achieves state-of-the-art performance in terms of speech quality and intelligibility. Ablation studies also demonstrate the effectiveness of different contributions. ",
    "url": "https://arxiv.org/abs/2111.08387",
    "authors": [
      "Shubo Lv",
      "Yihui Fu",
      "Mengtao Xing",
      "Jiayao Sun",
      "Lei Xie",
      "Jun Huang",
      "Yannan Wang",
      "Tao Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2111.08597",
    "title": "A layer-stress learning framework universally augments deep neural  network tasks",
    "abstract": "Deep neural networks (DNN) such as Multi-Layer Perception (MLP) and Convolutional Neural Networks (CNN) represent one of the most established deep learning algorithms. Given the tremendous effects of the number of hidden layers on network architecture and performance, it is very important to choose the number of hidden layers but still a serious challenge. More importantly, the current network architectures can only process the information from the last layer of the feature extractor, which greatly limited us to further improve its performance. Here we presented a layer-stress deep learning framework (x-NN) which implemented automatic and wise depth decision on shallow or deep feature map in a deep network through firstly designing enough number of layers and then trading off them by Multi-Head Attention Block. The x-NN can make use of features from various depth layers through attention allocation and then help to make final decision as well. As a result, x-NN showed outstanding prediction ability in the Alzheimer's Disease Classification Technique Challenge PRCV 2021, in which it won the top laurel and outperformed all other AI models. Moreover, the performance of x-NN was verified by one more AD neuroimaging dataset and other AI tasks. ",
    "url": "https://arxiv.org/abs/2111.08597",
    "authors": [
      "Shihao Shao",
      "Yong Liu",
      "Qinghua Cui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.08678",
    "title": "Unsupervised Speech Enhancement with speech recognition embedding and  disentanglement losses",
    "abstract": "Speech enhancement has recently achieved great success with various deep learning methods. However, most conventional speech enhancement systems are trained with supervised methods that impose two significant challenges. First, a majority of training datasets for speech enhancement systems are synthetic. When mixing clean speech and noisy corpora to create the synthetic datasets, domain mismatches occur between synthetic and real-world recordings of noisy speech or audio. Second, there is a trade-off between increasing speech enhancement performance and degrading speech recognition (ASR) performance. Thus, we propose an unsupervised loss function to tackle those two problems. Our function is developed by extending the MixIT loss function with speech recognition embedding and disentanglement loss. Our results show that the proposed function effectively improves the speech enhancement performance compared to a baseline trained in a supervised way on the noisy VoxCeleb dataset. While fully unsupervised training is unable to exceed the corresponding baseline, with joint super- and unsupervised training, the system is able to achieve similar speech quality and better ASR performance than the best supervised baseline. ",
    "url": "https://arxiv.org/abs/2111.08678",
    "authors": [
      "Viet Anh Trinh",
      "Sebastian Braun"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1709.05506",
    "title": "A statistical interpretation of spectral embedding: the generalised  random dot product graph",
    "abstract": " Comments: 34 pages; 12 figures ",
    "url": "https://arxiv.org/abs/1709.05506",
    "authors": [
      "Patrick Rubin-Delanchy",
      "Joshua Cape",
      "Minh Tang",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.12070",
    "title": "Criteria for integer and modulo 2 embeddability of graphs to surfaces",
    "abstract": " Title: Criteria for integer and modulo 2 embeddability of graphs to surfaces ",
    "url": "https://arxiv.org/abs/2012.12070",
    "authors": [
      "Arthur Bikeev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2103.14400",
    "title": "Data-driven sparse skin stimulation can convey social touch information  to humans",
    "abstract": " Comments: Awaiting publication for IEEE Transactions on Haptics ",
    "url": "https://arxiv.org/abs/2103.14400",
    "authors": [
      "M. Salvato",
      "Sophia R. Williams",
      "Cara M. Nunez",
      "Xin Zhu",
      "Ali Israr",
      "Frances Lau",
      "Keith Klumb",
      "Freddy Abnousi",
      "Allison M. Okamura",
      "Heather Culbertson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2106.12894",
    "title": "InFlow: Robust outlier detection utilizing Normalizing Flows",
    "abstract": " Title: InFlow: Robust outlier detection utilizing Normalizing Flows ",
    "url": "https://arxiv.org/abs/2106.12894",
    "authors": [
      "Nishant Kumar",
      "Pia Hanfeld",
      "Michael Hecht",
      "Michael Bussmann",
      "Stefan Gumhold",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2110.03666",
    "title": "Joint inference of multiple graphs with hidden variables from stationary  graph signals",
    "abstract": " Title: Joint inference of multiple graphs with hidden variables from stationary  graph signals ",
    "url": "https://arxiv.org/abs/2110.03666",
    "authors": [
      "Samuel Rey",
      "Andrei Buciulea",
      "Madeline Navarro",
      "Santiago Segarra",
      "Antonio G. Marques"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.05504",
    "title": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "abstract": " Title: Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs ",
    "url": "https://arxiv.org/abs/2111.05504",
    "authors": [
      "Dinh D\u0169ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  }
]