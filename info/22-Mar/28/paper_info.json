[
  {
    "id": "arXiv:2203.13262",
    "title": "Interpretability of Neural Network With Physiological Mechanisms",
    "abstract": "Deep learning continues to play as a powerful state-of-art technique that has achieved extraordinary accuracy levels in various domains of regression and classification tasks, including images, video, signal, and natural language data. The original goal of proposing the neural network model is to improve the understanding of complex human brains using a mathematical expression approach. However, recent deep learning techniques continue to lose the interpretations of its functional process by being treated mostly as a black-box approximator. To address this issue, such an AI model needs to be biological and physiological realistic to incorporate a better understanding of human-machine evolutionary intelligence. In this study, we compare neural networks and biological circuits to discover the similarities and differences from various perspective views. We further discuss the insights into how neural networks learn from data by investigating human biological behaviors and understandable justifications. ",
    "url": "https://arxiv.org/abs/2203.13262",
    "authors": [
      "Anna Zou",
      "Zhiyuan Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2203.13263",
    "title": "Precipitaion Nowcasting using Deep Neural Network",
    "abstract": "Precipitation nowcasting is of great importance for weather forecast users, for activities ranging from outdoor activities and sports competitions to airport traffic management. In contrast to long-term precipitation forecasts which are traditionally obtained from numerical models, precipitation nowcasting needs to be very fast. It is therefore more challenging to obtain because of this time constraint. Recently, many machine learning based methods had been proposed. We propose the use three popular deep learning models (U-net, ConvLSTM and SVG-LP) trained on two-dimensional precipitation maps for precipitation nowcasting. We proposed an algorithm for patch extraction to obtain high resolution precipitation maps. We proposed a loss function to solve the blurry image issue and to reduce the influence of zero value pixels in precipitation maps. ",
    "url": "https://arxiv.org/abs/2203.13263",
    "authors": [
      "Mohamed Chafik Bakkay",
      "Mathieu Serrurier",
      "Valentin Kivachuk Burda",
      "Florian Dupuy",
      "Naty Citlali Cabrera-Gutierrez",
      "Michael Zamo",
      "Maud-Alix Mader",
      "Olivier Mestre",
      "Guillaume Oller",
      "Jean-Christophe Jouhaud",
      "Laurent Terray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13273",
    "title": "On Exploiting Layerwise Gradient Statistics for Effective Training of  Deep Neural Networks",
    "abstract": "Adam and AdaBelief compute and make use of elementwise adaptive stepsizes in training deep neural networks (DNNs) by tracking the exponential moving average (EMA) of the squared-gradient g_t^2 and the squared prediction error (m_t-g_t)^2, respectively, where m_t is the first momentum at iteration t and can be viewed as a prediction of g_t. In this work, we attempt to find out if layerwise gradient statistics can be expoited in Adam and AdaBelief to allow for more effective training of DNNs. We address the above research question in two steps. Firstly, we slightly modify Adam and AdaBelief by introducing layerwise adaptive stepsizes in their update procedures via either pre or post processing. Empirical study indicates that the slight modification produces comparable performance for training VGG and ResNet models over CIFAR10, suggesting that layer-wise gradient statistics plays an important role towards the success of Adam and AdaBelief for at least certian DNN tasks. In the second step, instead of manual setup of layerwise stepsizes, we propose Aida, a new optimisation method, with the objective that the elementwise stepsizes within each layer have significantly small statistic variances. Motivated by the fact that (m_t-g_t)^2 in AdaBelief is conservative in comparison to g_t^2 in Adam in terms of layerwise statistic averages and variances, Aida is designed by tracking a more conservative function of m_t and g_t than (m_t-g_t)^2 in AdaBelief via layerwise orthogonal vector projections. Experimental results show that Aida produces either competitive or better performance with respect to a number of existing methods including Adam and AdaBelief for a set of challenging DNN tasks. ",
    "url": "https://arxiv.org/abs/2203.13273",
    "authors": [
      "Guoqiang Zhang",
      "Kenta Niwa",
      "W. Bastiaan Kleijn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13277",
    "title": "A Manifold View of Adversarial Risk",
    "abstract": "The adversarial risk of a machine learning model has been widely studied. Most previous works assume that the data lies in the whole ambient space. We propose to take a new angle and take the manifold assumption into consideration. Assuming data lies in a manifold, we investigate two new types of adversarial risk, the normal adversarial risk due to perturbation along normal direction, and the in-manifold adversarial risk due to perturbation within the manifold. We prove that the classic adversarial risk can be bounded from both sides using the normal and in-manifold adversarial risks. We also show with a surprisingly pessimistic case that the standard adversarial risk can be nonzero even when both normal and in-manifold risks are zero. We finalize the paper with empirical studies supporting our theoretical results. Our results suggest the possibility of improving the robustness of a classifier by only focusing on the normal adversarial risk. ",
    "url": "https://arxiv.org/abs/2203.13277",
    "authors": [
      "Wenjia Zhang",
      "Yikai Zhang",
      "Xiaolin Hu",
      "Mayank Goswami",
      "Chao Chen",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13301",
    "title": "Multi-modal Multi-label Facial Action Unit Detection with Transformer",
    "abstract": "Facial Action Coding System is an important approach of facial expression analysis.This paper describes our submission to the third Affective Behavior Analysis (ABAW) 2022 competition. We proposed a transfomer based model to detect facial action unit (FAU) in video. To be specific, we firstly trained a multi-modal model to extract both audio and visual feature. After that, we proposed a action units correlation module to learn relationships between each action unit labels and refine action unit detection result. Experimental results on validation dataset shows that our method achieves better performance than baseline model, which verifies that the effectiveness of proposed network. ",
    "url": "https://arxiv.org/abs/2203.13301",
    "authors": [
      "Lingfeng Wang",
      "Shisen Wang",
      "Jin Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13310",
    "title": "MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection has long been a challenging task in autonomous driving, which requires to decode 3D predictions solely from a single 2D image. Most existing methods follow conventional 2D object detectors to first localize objects by their centers, and then predict 3D attributes using center-neighboring local features. However, such center-based pipeline views 3D prediction as a subordinate task and lacks inter-object depth interactions with global spatial clues. In this paper, we introduce a simple framework for Monocular DEtection with depth-aware TRansformer, named MonoDETR. We enable the vanilla transformer to be depth-aware and enforce the whole detection process guided by depth. Specifically, we represent 3D object candidates as a set of queries and produce non-local depth embeddings of the input image by a lightweight depth predictor and an attention-based depth encoder. Then, we propose a depth-aware decoder to conduct both inter-query and query-scene depth feature communication. In this way, each object estimates its 3D attributes adaptively from the depth-informative regions on the image, not limited by center-around features. With minimal handcrafted designs, MonoDETR is an end-to-end framework without additional data, anchors or NMS and achieves competitive performance on KITTI benchmark among state-of-the-art center-based networks. Extensive ablation studies demonstrate the effectiveness of our approach and its potential to serve as a transformer baseline for future monocular research. Code is available at https://github.com/ZrrSkywalker/MonoDETR.git. ",
    "url": "https://arxiv.org/abs/2203.13310",
    "authors": [
      "Renrui Zhang",
      "Han Qiu",
      "Tai Wang",
      "Xuanzhuo Xu",
      "Ziyu Guo",
      "Yu Qiao",
      "Peng Gao",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.13317",
    "title": "Human Gait Recognition Using Bag of Words Feature Representation Method",
    "abstract": "In this paper, we propose a novel gait recognition method based on a bag-of-words feature representation method. The algorithm is trained, tested and evaluated on a unique human gait data consisting of 93 individuals who walked with comfortable pace between two end points during two different sessions. To evaluate the effectiveness of the proposed model, the results are compared with the outputs of the classification using extracted features. As it is presented, the proposed method results in significant improvement accuracy compared to using common statistical features, in all the used classifiers. ",
    "url": "https://arxiv.org/abs/2203.13317",
    "authors": [
      "Nasrin Bayat",
      "Elham Rastegari",
      "Qifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13318",
    "title": "NPBG++: Accelerating Neural Point-Based Graphics",
    "abstract": "We present a new system (NPBG++) for the novel view synthesis (NVS) task that achieves high rendering realism with low scene fitting time. Our method efficiently leverages the multiview observations and the point cloud of a static scene to predict a neural descriptor for each point, improving upon the pipeline of Neural Point-Based Graphics in several important ways. By predicting the descriptors with a single pass through the source images, we lift the requirement of per-scene optimization while also making the neural descriptors view-dependent and more suitable for scenes with strong non-Lambertian effects. In our comparisons, the proposed system outperforms previous NVS approaches in terms of fitting and rendering runtimes while producing images of similar quality. ",
    "url": "https://arxiv.org/abs/2203.13318",
    "authors": [
      "Ruslan Rakhimov",
      "Andrei-Timotei Ardelean",
      "Victor Lempitsky",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13369",
    "title": "Gender and Racial Stereotype Detection in Legal Opinion Word Embeddings",
    "abstract": "Studies have shown that some Natural Language Processing (NLP) systems encode and replicate harmful biases with potential adverse ethical effects in our society. In this article, we propose an approach for identifying gender and racial stereotypes in word embeddings trained on judicial opinions from U.S. case law. Embeddings containing stereotype information may cause harm when used by downstream systems for classification, information extraction, question answering, or other machine learning systems used to build legal research tools. We first explain how previously proposed methods for identifying these biases are not well suited for use with word embeddings trained on legal opinion text. We then propose a domain adapted method for identifying gender and racial biases in the legal domain. Our analyses using these methods suggest that racial and gender biases are encoded into word embeddings trained on legal opinions. These biases are not mitigated by exclusion of historical data, and appear across multiple large topical areas of the law. Implications for downstream systems that use legal opinion word embeddings and suggestions for potential mitigation strategies based on our observations are also discussed. ",
    "url": "https://arxiv.org/abs/2203.13369",
    "authors": [
      "Sean Matthews",
      "John Hudzina",
      "Dawn Sepehr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13381",
    "title": "Probing Representation Forgetting in Supervised and Unsupervised  Continual Learning",
    "abstract": "Continual Learning research typically focuses on tackling the phenomenon of catastrophic forgetting in neural networks. Catastrophic forgetting is associated with an abrupt loss of knowledge previously learned by a model when the task, or more broadly the data distribution, being trained on changes. In supervised learning problems this forgetting, resulting from a change in the model's representation, is typically measured or observed by evaluating the decrease in old task performance. However, a model's representation can change without losing knowledge about prior tasks. In this work we consider the concept of representation forgetting, observed by using the difference in performance of an optimal linear classifier before and after a new task is introduced. Using this tool we revisit a number of standard continual learning benchmarks and observe that, through this lens, model representations trained without any explicit control for forgetting often experience small representation forgetting and can sometimes be comparable to methods which explicitly control for forgetting, especially in longer task sequences. We also show that representation forgetting can lead to new insights on the effect of model capacity and loss function used in continual learning. Based on our results, we show that a simple yet competitive approach is to learn representations continually with standard supervised contrastive learning while constructing prototypes of class samples when queried on old samples. ",
    "url": "https://arxiv.org/abs/2203.13381",
    "authors": [
      "MohammadReza Davari",
      "Nader Asadi",
      "Sudhir Mudur",
      "Rahaf Aljundi",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13397",
    "title": "GPT-D: Inducing Dementia-related Linguistic Anomalies by Deliberate  Degradation of Artificial Neural Language Models",
    "abstract": "Deep learning (DL) techniques involving fine-tuning large numbers of model parameters have delivered impressive performance on the task of discriminating between language produced by cognitively healthy individuals, and those with Alzheimer's disease (AD). However, questions remain about their ability to generalize beyond the small reference sets that are publicly available for research. As an alternative to fitting model parameters directly, we propose a novel method by which a Transformer DL model (GPT-2) pre-trained on general English text is paired with an artificially degraded version of itself (GPT-D), to compute the ratio between these two models' \\textit{perplexities} on language from cognitively healthy and impaired individuals. This technique approaches state-of-the-art performance on text data from a widely used \"Cookie Theft\" picture description task, and unlike established alternatives also generalizes well to spontaneous conversations. Furthermore, GPT-D generates text with characteristics known to be associated with AD, demonstrating the induction of dementia-related linguistic anomalies. Our study is a step toward better understanding of the relationships between the inner workings of generative neural language models, the language that they produce, and the deleterious effects of dementia on human speech and language characteristics. ",
    "url": "https://arxiv.org/abs/2203.13397",
    "authors": [
      "Changye Li",
      "David Knopman",
      "Weizhe Xu",
      "Trevor Cohen",
      "Serguei Pakhomov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13410",
    "title": "Qualitative neural network approximation over R and C: Elementary proofs  for analytic and polynomial activation",
    "abstract": "In this article, we prove approximation theorems in classes of deep and shallow neural networks with analytic activation functions by elementary arguments. We prove for both real and complex networks with non-polynomial activation that the closure of the class of neural networks coincides with the closure of the space of polynomials. The closure can further be characterized by the Stone-Weierstrass theorem (in the real case) and Mergelyan's theorem (in the complex case). In the real case, we further prove approximation results for networks with higher-dimensional harmonic activation and orthogonally projected linear maps. We further show that fully connected and residual networks of large depth with polynomial activation functions can approximate any polynomial under certain width requirements. All proofs are entirely elementary. ",
    "url": "https://arxiv.org/abs/2203.13410",
    "authors": [
      "Josiah Park",
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.13412",
    "title": "Self-Supervised Predictive Learning: A Negative-Free Method for Sound  Source Localization in Visual Scenes",
    "abstract": "Sound source localization in visual scenes aims to localize objects emitting the sound in a given image. Recent works showing impressive localization performance typically rely on the contrastive learning framework. However, the random sampling of negatives, as commonly adopted in these methods, can result in misalignment between audio and visual features and thus inducing ambiguity in localization. In this paper, instead of following previous literature, we propose Self-Supervised Predictive Learning (SSPL), a negative-free method for sound localization via explicit positive mining. Specifically, we first devise a three-stream network to elegantly associate sound source with two augmented views of one corresponding video frame, leading to semantically coherent similarities between audio and visual features. Second, we introduce a novel predictive coding module for audio-visual feature alignment. Such a module assists SSPL to focus on target objects in a progressive manner and effectively lowers the positive-pair learning difficulty. Experiments show surprising results that SSPL outperforms the state-of-the-art approach on two standard sound localization benchmarks. In particular, SSPL achieves significant improvements of 8.6% cIoU and 3.4% AUC on SoundNet-Flickr compared to the previous best. Code is available at: https://github.com/zjsong/SSPL. ",
    "url": "https://arxiv.org/abs/2203.13412",
    "authors": [
      "Zengjie Song",
      "Yuxi Wang",
      "Junsong Fan",
      "Tieniu Tan",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13424",
    "title": "Dealing with Sparse Rewards Using Graph Neural Networks",
    "abstract": "Deep reinforcement learning in partially observable environments is a difficult task in itself, and can be further complicated by a sparse reward signal. Most tasks involving navigation in three-dimensional environments provide the agent with extremely limited information. Typically, the agent receives a visual observation input from the environment and is rewarded once at the end of the episode. A good reward function could substantially improve the convergence of reinforcement learning algorithms for such tasks. The classic approach to increase the density of the reward signal is to augment it with supplementary rewards. This technique is called the reward shaping. In this study, we propose two modifications of one of the recent reward shaping methods based on graph convolutional networks: the first involving advanced aggregation functions, and the second utilizing the attention mechanism. We empirically validate the effectiveness of our solutions for the task of navigation in a 3D environment with sparse rewards. For the solution featuring attention mechanism, we are also able to show that the learned attention is concentrated on edges corresponding to important transitions in 3D environment. ",
    "url": "https://arxiv.org/abs/2203.13424",
    "authors": [
      "Matvey Gerasyov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.13430",
    "title": "Plagiarism Detection in the Bengali Language: A Text Similarity-Based  Approach",
    "abstract": "Plagiarism means taking another person's work and not giving any credit to them for it. Plagiarism is one of the most serious problems in academia and among researchers. Even though there are multiple tools available to detect plagiarism in a document but most of them are domain-specific and designed to work in English texts, but plagiarism is not limited to a single language only. Bengali is the most widely spoken language of Bangladesh and the second most spoken language in India with 300 million native speakers and 37 million second-language speakers. Plagiarism detection requires a large corpus for comparison. Bengali Literature has a history of 1300 years. Hence most Bengali Literature books are not yet digitalized properly. As there was no such corpus present for our purpose so we have collected Bengali Literature books from the National Digital Library of India and with a comprehensive methodology extracted texts from it and constructed our corpus. Our experimental results find out average accuracy between 72.10 % - 79.89 % in text extraction using OCR. Levenshtein Distance algorithm is used for determining Plagiarism. We have built a web application for end-user and successfully tested it for Plagiarism detection in Bengali texts. In future, we aim to construct a corpus with more books for more accurate detection. ",
    "url": "https://arxiv.org/abs/2203.13430",
    "authors": [
      "Satyajit Ghosh",
      "Aniruddha Ghosh",
      "Bittaswer Ghosh",
      "Abhishek Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13432",
    "title": "Nash Neural Networks : Inferring Utilities from Optimal Behaviour",
    "abstract": "We propose Nash Neural Networks ($N^3$) as a new type of Physics Informed Neural Network that is able to infer the underlying utility from observations of how rational individuals behave in a differential game with a Nash equilibrium. We assume that the dynamics for both the population and the individual are known, but not the payoff function, which specifies the cost per unit time of being in any particular state. We construct our network in such a way that the Euler-Lagrange equations of the corresponding optimal control problem are satisfied and the optimal control is self-consistently determined. In this way, we are able to learn the unknown payoff function in an unsupervised manner. We have applied the $N^3$ to study the optimal behaviour during epidemics, in which individuals can choose to socially distance depending on the state of the pandemic and the cost of being infected. Training our network against synthetic data for a simple SIR model, we showed that it is possible to accurately reproduce the hidden payoff function, in such a way that the game dynamics are respected. Our approach will have far-reaching applications, as it allows one to infer utilities from behavioural data, and can thus be applied to study a wide array of problems in science, engineering, economics and government planning. ",
    "url": "https://arxiv.org/abs/2203.13432",
    "authors": [
      "John J. Molina",
      "Simon K. Schnyder",
      "Matthew S. Turner",
      "Ryoichi Yamamoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2203.13435",
    "title": "Independent set reconfiguration on directed graphs",
    "abstract": "\\textsc{Directed Token Sliding} asks, given a directed graph and two sets of pairwise nonadjacent vertices, whether one can reach from one set to the other by repeatedly applying a local operation that exchanges a vertex in the current set with one of its out-neighbors, while keeping the nonadjacency. It can be seen as a reconfiguration process where a token is placed on each vertex in the current set, and the local operation slides a token along an arc respecting its direction. Previously, such a problem was extensively studied on undirected graphs, where the edges have no directions and thus the local operation is symmetric. \\textsc{Directed Token Sliding} is a generalization of its undirected variant since an undirected edge can be simulated by two arcs of opposite directions. In this paper, we initiate the algorithmic study of \\textsc{Directed Token Sliding}. We first observe that the problem is PSPACE-complete even if we forbid parallel arcs in opposite directions and that the problem on directed acyclic graphs is NP-complete and W[1]-hard parameterized by the size of the sets in consideration. We then show our main result: a linear-time algorithm for the problem on directed graphs whose underlying undirected graphs are trees, which are called polytrees. Such a result is also known for the undirected variant of the problem on trees~[Demaine et al.~TCS 2015], but the techniques used here are quite different because of the asymmetric nature of the directed problem. We present a characterization of yes-instances based on the existence of a certain set of directed paths, and then derive simple equivalent conditions from it by some observations, which admits an efficient algorithm. For the polytree case, we also present a quadratic-time algorithm that outputs, if the input is a yes-instance, one of the shortest reconfiguration sequences. ",
    "url": "https://arxiv.org/abs/2203.13435",
    "authors": [
      "Takehiro Ito",
      "Yuni Iwamasa",
      "Yasuaki Kobayashi",
      "Yu Nakahata",
      "Yota Otachi",
      "Masahiro Takahashi",
      "Kunihiro Wasa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2203.13436",
    "title": "Frame-level Prediction of Facial Expressions, Valence, Arousal and  Action Units for Mobile Devices",
    "abstract": "In this paper, we consider the problem of real-time video-based facial emotion analytics, namely, facial expression recognition, prediction of valence and arousal and detection of action unit points. We propose the novel frame-level emotion recognition algorithm by extracting facial features with the single EfficientNet model pre-trained on AffectNet. As a result, our approach may be implemented even for video analytics on mobile devices. Experimental results for the large scale Aff-Wild2 database from the third Affective Behavior Analysis in-the-wild (ABAW) Competition demonstrate that our simple model is significantly better when compared to the VggFace baseline. In particular, our method is characterized by 0.15-0.2 higher performance measures for validation sets in uni-task Expression Classification, Valence-Arousal Estimation and Expression Classification. Due to simplicity, our approach may be considered as a new baseline for all four sub-challenges. ",
    "url": "https://arxiv.org/abs/2203.13436",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13443",
    "title": "MDAN: Multi-level Dependent Attention Network for Visual Emotion  Analysis",
    "abstract": "Visual Emotion Analysis (VEA) is attracting increasing attention. One of the biggest challenges of VEA is to bridge the affective gap between visual clues in a picture and the emotion expressed by the picture. As the granularity of emotions increases, the affective gap increases as well. Existing deep approaches try to bridge the gap by directly learning discrimination among emotions globally in one shot without considering the hierarchical relationship among emotions at different affective levels and the affective level of emotions to be classified. In this paper, we present the Multi-level Dependent Attention Network (MDAN) with two branches, to leverage the emotion hierarchy and the correlation between different affective levels and semantic levels. The bottom-up branch directly learns emotions at the highest affective level and strictly follows the emotion hierarchy while predicting emotions at lower affective levels. In contrast, the top-down branch attempt to disentangle the affective gap by one-to-one mapping between semantic levels and affective levels, namely, Affective Semantic Mapping. At each semantic level, a local classifier learns discrimination among emotions at the corresponding affective level. Finally, We integrate global learning and local learning into a unified deep framework and optimize the network simultaneously. Moreover, to properly extract and leverage channel dependencies and spatial attention while disentangling the affective gap, we carefully designed two attention modules: the Multi-head Cross Channel Attention module and the Level-dependent Class Activation Map module. Finally, the proposed deep framework obtains new state-of-the-art performance on six VEA benchmarks, where it outperforms existing state-of-the-art methods by a large margin, e.g., +3.85% on the WEBEmo dataset at 25 classes classification accuracy. ",
    "url": "https://arxiv.org/abs/2203.13443",
    "authors": [
      "Liwen Xu",
      "Zhengtao Wang",
      "Bin Wu",
      "Simon Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13449",
    "title": "A Comparative Evaluation of Machine Learning Algorithms for the  Prediction of R/C Buildings' Seismic Damage",
    "abstract": "Seismic assessment of buildings and determination of their structural damage is at the forefront of modern scientific research. Since now, several researchers have proposed a number of procedures, in an attempt to estimate the damage response of the buildings subjected to strong ground motions, without conducting time-consuming analyses. These procedures, e.g. construction of fragility curves, usually utilize methods based on the application of statistical theory. In the last decades, the increase of the computers' power has led to the development of modern soft computing methods based on the adoption of Machine Learning algorithms. The present paper attempts an extensive comparative evaluation of the capability of various Machine Learning methods to adequately predict the seismic response of R/C buildings. The training dataset is created by means of Nonlinear Time History Analyses of 90 3D R/C buildings with three different masonry infills' distributions, which are subjected to 65 earthquakes. The seismic damage is expressed in terms of the Maximum Interstory Drift Ratio. A large-scale comparison study is utilized by the most efficient Machine Learning algorithms. The experimentation shows that the LightGBM approach produces training stability, high overall performance and a remarkable coefficient of determination to estimate the ability to predict the buildings' damage response. Due to the extremely urgent issue, civil protection mechanisms need to incorporate in their technological systems scientific methodologies and appropriate technical or modeling tools such as the proposed one, which can offer valuable assistance in making optimal decisions. ",
    "url": "https://arxiv.org/abs/2203.13449",
    "authors": [
      "Konstantinos Demertzis",
      "Konstantinos Kostinakis",
      "Konstantinos Morfidis",
      "Lazaros Iliadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13453",
    "title": "CNN LEGO: Disassembling and Assembling Convolutional Neural Network",
    "abstract": "Convolutional Neural Network (CNN), which mimics human visual perception mechanism, has been successfully used in many computer vision areas. Some psychophysical studies show that the visual perception mechanism synchronously processes the form, color, movement, depth, etc., in the initial stage [7,20] and then integrates all information for final recognition [38]. What's more, the human visual system [20] contains different subdivisions or different tasks. Inspired by the above visual perception mechanism, we investigate a new task, termed as Model Disassembling and Assembling (MDA-Task), which can disassemble the deep models into independent parts and assemble those parts into a new deep model without performance cost like playing LEGO toys. To this end, we propose a feature route attribution technique (FRAT) for disassembling CNN classifiers in this paper. In FRAT, the positive derivatives of predicted class probability w.r.t. the feature maps are adopted to locate the critical features in each layer. Then, relevance analysis between the critical features and preceding/subsequent parameter layers is adopted to bridge the route between two adjacent parameter layers. In the assembling phase, class-wise components of each layer are assembled into a new deep model for a specific task. Extensive experiments demonstrate that the assembled CNN classifier can achieve close accuracy with the original classifier without any fine-tune, and excess original performance with one-epoch fine-tune. What's more, we also conduct massive experiments to verify the broad application of MDA-Task on model decision route visualization, model compression, knowledge distillation, transfer learning, incremental learning, and so on. ",
    "url": "https://arxiv.org/abs/2203.13453",
    "authors": [
      "Jiacong Hu",
      "Jing Gao",
      "Zunlei Feng",
      "Lechao Cheng",
      "Jie Lei",
      "Hujun Bao",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13455",
    "title": "A Unified Contrastive Energy-based Model for Understanding the  Generative Ability of Adversarial Training",
    "abstract": "Adversarial Training (AT) is known as an effective approach to enhance the robustness of deep neural networks. Recently researchers notice that robust models with AT have good generative ability and can synthesize realistic images, while the reason behind it is yet under-explored. In this paper, we demystify this phenomenon by developing a unified probabilistic framework, called Contrastive Energy-based Models (CEM). On the one hand, we provide the first probabilistic characterization of AT through a unified understanding of robustness and generative ability. On the other hand, our unified framework can be extended to the unsupervised scenario, which interprets unsupervised contrastive learning as an important sampling of CEM. Based on these, we propose a principled method to develop adversarial learning and sampling methods. Experiments show that the sampling methods derived from our framework improve the sample quality in both supervised and unsupervised learning. Notably, our unsupervised adversarial sampling method achieves an Inception score of 9.61 on CIFAR-10, which is superior to previous energy-based models and comparable to state-of-the-art generative models. ",
    "url": "https://arxiv.org/abs/2203.13455",
    "authors": [
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.13457",
    "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive  Learning via Augmentation Overlap",
    "abstract": "Recently, contrastive learning has risen to be a promising approach for large-scale self-supervised learning. However, theoretical understanding of how it works is still unclear. In this paper, we propose a new guarantee on the downstream performance without resorting to the conditional independence assumption that is widely adopted in previous work but hardly holds in practice. Our new theory hinges on the insight that the support of different intra-class samples will become more overlapped under aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learning cluster intra-class samples together. Based on this augmentation overlap perspective, theoretically, we obtain asymptotically closed bounds for downstream performance under weaker assumptions, and empirically, we propose an unsupervised model selection metric ARC that aligns well with downstream accuracy. Our theory suggests an alternative understanding of contrastive learning: the role of aligning positive samples is more like a surrogate task than an ultimate goal, and the overlapped augmented views (i.e., the chaos) create a ladder for contrastive learning to gradually learn class-separated representations. The code for computing ARC is available at https://github.com/zhangq327/ARC. ",
    "url": "https://arxiv.org/abs/2203.13457",
    "authors": [
      "Yifei Wang",
      "Qi Zhang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.13458",
    "title": "PANDORA: Polarization-Aided Neural Decomposition Of Radiance",
    "abstract": "Reconstructing an object's geometry and appearance from multiple images, also known as inverse rendering, is a fundamental problem in computer graphics and vision. Inverse rendering is inherently ill-posed because the captured image is an intricate function of unknown lighting conditions, material properties and scene geometry. Recent progress in representing scene properties as coordinate-based neural networks have facilitated neural inverse rendering resulting in impressive geometry reconstruction and novel-view synthesis. Our key insight is that polarization is a useful cue for neural inverse rendering as polarization strongly depends on surface normals and is distinct for diffuse and specular reflectance. With the advent of commodity, on-chip, polarization sensors, capturing polarization has become practical. Thus, we propose PANDORA, a polarimetric inverse rendering approach based on implicit neural representations. From multi-view polarization images of an object, PANDORA jointly extracts the object's 3D geometry, separates the outgoing radiance into diffuse and specular and estimates the illumination incident on the object. We show that PANDORA outperforms state-of-the-art radiance decomposition techniques. PANDORA outputs clean surface reconstructions free from texture artefacts, models strong specularities accurately and estimates illumination under practical unstructured scenarios. ",
    "url": "https://arxiv.org/abs/2203.13458",
    "authors": [
      "Akshat Dave",
      "Yongyi Zhao",
      "Ashok Veeraraghavan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.13464",
    "title": "From MIM-Based GAN to Anomaly Detection:Event Probability Influence on  Generative Adversarial Networks",
    "abstract": "In order to introduce deep learning technologies into anomaly detection, Generative Adversarial Networks (GANs) are considered as important roles in the algorithm design and realistic applications. In terms of GANs, event probability reflected in the objective function, has an impact on the event generation which plays a crucial part in GAN-based anomaly detection. The information metric, e.g. Kullback-Leibler divergence in the original GAN, makes the objective function have different sensitivity on different event probability, which provides an opportunity to refine GAN-based anomaly detection by influencing data generation. In this paper, we introduce the exponential information metric into the GAN, referred to as MIM-based GAN, whose superior characteristics on data generation are discussed in theory. Furthermore, we propose an anomaly detection method with MIM-based GAN, as well as explain its principle for the unsupervised learning case from the viewpoint of probability event generation. Since this method is promising to detect anomalies in Internet of Things (IoT), such as environmental, medical and biochemical outliers, we make use of several datasets from the online ODDS repository to evaluate its performance and compare it with other methods. ",
    "url": "https://arxiv.org/abs/2203.13464",
    "authors": [
      "Rui She",
      "Pingyi Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.13471",
    "title": "Non-Probability Sampling Network for Stochastic Human Trajectory  Prediction",
    "abstract": "Capturing multimodal natures is essential for stochastic pedestrian trajectory prediction, to infer a finite set of future trajectories. The inferred trajectories are based on observation paths and the latent vectors of potential decisions of pedestrians in the inference step. However, stochastic approaches provide varying results for the same data and parameter settings, due to the random sampling of the latent vector. In this paper, we analyze the problem by reconstructing and comparing probabilistic distributions from prediction samples and socially-acceptable paths, respectively. Through this analysis, we observe that the inferences of all stochastic models are biased toward the random sampling, and fail to generate a set of realistic paths from finite samples. The problem cannot be resolved unless an infinite number of samples is available, which is infeasible in practice. We introduce that the Quasi-Monte Carlo (QMC) method, ensuring uniform coverage on the sampling space, as an alternative to the conventional random sampling. With the same finite number of samples, the QMC improves all the multimodal prediction results. We take an additional step ahead by incorporating a learnable sampling network into the existing networks for trajectory prediction. For this purpose, we propose the Non-Probability Sampling Network (NPSN), a very small network (~5K parameters) that generates purposive sample sequences using the past paths of pedestrians and their social interactions. Extensive experiments confirm that NPSN can significantly improve both the prediction accuracy (up to 60%) and reliability of the public pedestrian trajectory prediction benchmark. Code is publicly available at https://github.com/inhwanbae/NPSN . ",
    "url": "https://arxiv.org/abs/2203.13471",
    "authors": [
      "Inhwan Bae",
      "Jin-Hwi Park",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.13479",
    "title": "Improving Adversarial Transferability with Spatial Momentum",
    "abstract": "Deep Neural Networks (DNN) are vulnerable to adversarial examples. Although many adversarial attack methods achieve satisfactory attack success rates under the white-box setting, they usually show poor transferability when attacking other DNN models. Momentum-based attack (MI-FGSM) is one effective method to improve transferability. It integrates the momentum term into the iterative process, which can stabilize the update directions by adding the gradients' temporal correlation for each pixel. We argue that only this temporal momentum is not enough, the gradients from the spatial domain within an image, i.e. gradients from the context pixels centered on the target pixel are also important to the stabilization. For that, in this paper, we propose a novel method named Spatial Momentum Iterative FGSM Attack (SMI-FGSM), which introduces the mechanism of momentum accumulation from temporal domain to spatial domain by considering the context gradient information from different regions within the image. SMI-FGSM is then integrated with MI-FGSM to simultaneously stabilize the gradients' update direction from both the temporal and spatial domain. The final method is called SM$^2$I-FGSM. Extensive experiments are conducted on the ImageNet dataset and results show that SM$^2$I-FGSM indeed further enhances the transferability. It achieves the best transferability success rate for multiple mainstream undefended and defended models, which outperforms the state-of-the-art methods by a large margin. ",
    "url": "https://arxiv.org/abs/2203.13479",
    "authors": [
      "Guoqiu Wang",
      "Xingxing Wei",
      "Huanqian Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13487",
    "title": "Compare learning: bi-attention network for few-shot learning",
    "abstract": "Learning with few labeled data is a key challenge for visual recognition, as deep neural networks tend to overfit using a few samples only. One of the Few-shot learning methods called metric learning addresses this challenge by first learning a deep distance metric to determine whether a pair of images belong to the same category, then applying the trained metric to instances from other test set with limited labels. This method makes the most of the few samples and limits the overfitting effectively. However, extant metric networks usually employ Linear classifiers or Convolutional neural networks (CNN) that are not precise enough to globally capture the subtle differences between vectors. In this paper, we propose a novel approach named Bi-attention network to compare the instances, which can measure the similarity between embeddings of instances precisely, globally and efficiently. We verify the effectiveness of our model on two benchmarks. Experiments show that our approach achieved improved accuracy and convergence speed over baseline models. ",
    "url": "https://arxiv.org/abs/2203.13487",
    "authors": [
      "Li Ke",
      "Meng Pan",
      "Weigao Wen",
      "Dong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13495",
    "title": "Machine-Learning Based Objective Function Selection for Community  Detection",
    "abstract": "NECTAR, a Node-centric ovErlapping Community deTection AlgoRithm, presented in 2016 by Cohen et. al, chooses dynamically between two objective functions which function to optimize, based on the network on which it is invoked. This approach, as shown by Cohen et al., outperforms six state-of-the-art algorithms for overlapping community detection. In this work, we present NECTAR-ML, an extension of the NECTAR algorithm that uses a machine-learning based model for automating the selection of the objective function, trained and evaluated on a dataset of 15,755 synthetic and 7 real-world networks. Our analysis shows that in approximately 90% of the cases our model was able to successfully select the correct objective function. We conducted a competitive analysis of NECTAR and NECTAR-ML. NECTAR-ML was shown to significantly outperform NECTAR's ability to select the best objective function. We also conducted a competitive analysis of NECTAR-ML and two additional state-of-the-art multi-objective community detection algorithms. NECTAR-ML outperformed both algorithms in terms of average detection quality. Multiobjective EAs (MOEAs) are considered to be the most popular approach to solve MOP and the fact that NECTAR-ML significantly outperforms them demonstrates the effectiveness of ML-based objective function selection. ",
    "url": "https://arxiv.org/abs/2203.13495",
    "authors": [
      "Asa Bornstein",
      "Amir Rubin",
      "Danny Hendler"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13497",
    "title": "WaveFuzz: A Clean-Label Poisoning Attack to Protect Your Voice",
    "abstract": "People are not always receptive to their voice data being collected and misused. Training the audio intelligence systems needs these data to build useful features, but the cost for getting permissions or purchasing data is very high, which inevitably encourages hackers to collect these voice data without people's awareness. To discourage the hackers from proactively collecting people's voice data, we are the first to propose a clean-label poisoning attack, called WaveFuzz, which can prevent intelligence audio models from building useful features from protected (poisoned) voice data but still preserve the semantic information to the humans. Specifically, WaveFuzz perturbs the voice data to cause Mel Frequency Cepstral Coefficients (MFCC) (typical representations of audio signals) to generate the poisoned frequency features. These poisoned features are then fed to audio prediction models, which degrades the performance of audio intelligence systems. Empirically, we show the efficacy of WaveFuzz by attacking two representative types of intelligent audio systems, i.e., speaker recognition system (SR) and speech command recognition system (SCR). For example, the accuracies of models are declined by $19.78\\%$ when only $10\\%$ of the poisoned voice data is to fine-tune models, and the accuracies of models declined by $6.07\\%$ when only $10\\%$ of the training voice data is poisoned. Consequently, WaveFuzz is an effective technique that enables people to fight back to protect their own voice data, which sheds new light on ameliorating privacy issues. ",
    "url": "https://arxiv.org/abs/2203.13497",
    "authors": [
      "Yunjie Ge",
      "Qian Wang",
      "Jingfeng Zhang",
      "Juntao Zhou",
      "Yunzhu Zhang",
      "Chao Shen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.13503",
    "title": "Supplemental Material: Lifelong Generative Modelling Using Dynamic  Expansion Graph Model",
    "abstract": "In this article, we provide the appendix for Lifelong Generative Modelling Using Dynamic Expansion Graph Model. This appendix includes additional visual results as well as the numerical results on the challenging datasets. In addition, we also provide detailed proofs for the proposed theoretical analysis framework. The source code can be found in https://github.com/dtuzi123/Expansion-Graph-Model. ",
    "url": "https://arxiv.org/abs/2203.13503",
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13510",
    "title": "On the Correlation between Angle and Distance Distributions in Finite  Wireless Networks",
    "abstract": "Directional beamforming will play a paramount role in 5G and beyond networks in order to combat the higher path losses incurred at millimeter wave bands. Appropriate modeling and analysis of the angles and distances between transmitters and receivers in these networks are thus essential to understand performance and limiting factors. Most existing literature considers either infinite and uniform networks, where nodes are drawn according to a Poisson point process, or finite networks with the reference receiver placed at the origin of a disk. Under either of these assumptions, the distance and azimuth angle between transmitter and receiver are independent, and the angle follows a uniform distribution between $0$ and $2\\pi$. Here, we consider a more realistic case of finite networks where the reference node is placed at any arbitrary location. We obtain the joint distribution between the distance and azimuth angle and demonstrate that these random variables do exhibit certain correlation, which depends on the shape of the region and the location of the reference node. To conduct the analysis, we present a general mathematical framework which is specialized to exemplify the case of a rectangular region. We then also derive the statistics for the 3D case where, considering antenna heights, the joint distribution of distance, azimuth and zenith angles is obtained. Finally, we describe some immediate applications of the present work, including the analysis of directional beamforming, the design of analog codebooks and wireless routing algorithms. ",
    "url": "https://arxiv.org/abs/2203.13510",
    "authors": [
      "Francisco J. Mart\u00edn-Vega",
      "Gerardo G\u00f3mez",
      "David Morales-Jim\u00e9nez",
      "F. Javier L\u00f3pez-Mart\u00ednez",
      "Mari Carmen Aguayo-Torres"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.13530",
    "title": "Multimodal Pre-training Based on Graph Attention Network for Document  Understanding",
    "abstract": "Document intelligence as a relatively new research topic supports many business applications. Its main task is to automatically read, understand, and analyze documents. However, due to the diversity of formats (invoices, reports, forms, etc.) and layouts in documents, it is difficult to make machines understand documents. In this paper, we present the GraphDoc, a multimodal graph attention-based model for various document understanding tasks. GraphDoc is pre-trained in a multimodal framework by utilizing text, layout, and image information simultaneously. In a document, a text block relies heavily on its surrounding contexts, so we inject the graph structure into the attention mechanism to form a graph attention layer so that each input node can only attend to its neighborhoods. The input nodes of each graph attention layer are composed of textual, visual, and positional features from semantically meaningful regions in a document image. We do the multimodal feature fusion of each node by the gate fusion layer. The contextualization between each node is modeled by the graph attention layer. GraphDoc learns a generic representation from only 320k unlabeled documents via the Masked Sentence Modeling task. Extensive experimental results on the publicly available datasets show that GraphDoc achieves state-of-the-art performance, which demonstrates the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2203.13530",
    "authors": [
      "Zhenrong Zhang",
      "Jiefeng Ma",
      "Jun Du",
      "Licheng Wang",
      "Jianshu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": "The LiFi paradigm is rapidly emerging as one of the technologies that will enable an impressive increase in the bandwidth made available to wireless devices in 6G networks. Due to their intrinsic physical characteristics, visible light and infrared communications present coverage features that are different from their radio wave counterparts. A popular paradigm which has recently emerged is that of hybrid networks, in which the two wireless connection are used together in an hybrid configuration. We consider a hybrid wireless local area network composed of both WiFi and LiFi Access Points (AP) and wireless devices, in which the union of the two technologies is performed at the data link layer, i.e., each device is identified in the network by a unique IP address, using a virtual network interface obtained by bonding the WiFi and LiFi physical interfaces, implemented through commercially available products. We measure the time it takes to switch across the two physical interfaces and its impact on the traffic flow, under specific triggering events for the switch, namely an interface malfunctioning, a loss of signal, and a manual switch. Our experimental results show that the different types of triggering events have an impact on the time it takes to reconfigure the currently active interface, with recovery times ranging from few tens milliseconds to few seconds. In terms of packet losses at the flow level, a switch can entail a maximum packet loss percentage in the order of 10% during 1 second. ",
    "url": "https://arxiv.org/abs/2203.13544",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.13550",
    "title": "Modeling Target-Side Morphology in Neural Machine Translation: A  Comparison of Strategies",
    "abstract": "Morphologically rich languages pose difficulties to machine translation. Machine translation engines that rely on statistical learning from parallel training data, such as state-of-the-art neural systems, face challenges especially with rich morphology on the output language side. Key challenges of rich target-side morphology in data-driven machine translation include: (1) A large amount of differently inflected word surface forms entails a larger vocabulary and thus data sparsity. (2) Some inflected forms of infrequent terms typically do not appear in the training corpus, which makes closed-vocabulary systems unable to generate these unobserved variants. (3) Linguistic agreement requires the system to correctly match the grammatical categories between inflected word forms in the output sentence, both in terms of target-side morpho-syntactic wellformedness and semantic adequacy with respect to the input. In this paper, we re-investigate two target-side linguistic processing techniques: a lemma-tag strategy and a linguistically informed word segmentation strategy. Our experiments are conducted on a English-German translation task under three training corpus conditions of different magnitudes. We find that a stronger Transformer baseline leaves less room for improvement than a shallow-RNN encoder-decoder model when translating in-domain. However, we find that linguistic modeling of target-side morphology does benefit the Transformer model when the same system is applied to out-of-domain input text. We also successfully apply our approach to English to Czech translation. ",
    "url": "https://arxiv.org/abs/2203.13550",
    "authors": [
      "Marion Weller-Di Marco",
      "Matthias Huck",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13551",
    "title": "Feature extraction using Spectral Clustering for Gene Function  Prediction",
    "abstract": "Gene annotation addresses the problem of predicting unknown associations between gene and functions (e.g., biological processes) of a specific organism. Despite recent advances, the cost and time demanded by annotation procedures that rely largely on in vivo biological experiments remain prohibitively high. This paper presents a novel in silico approach for to the annotation problem that combines cluster analysis and hierarchical multi-label classification (HMC). The approach uses spectral clustering to extract new features from the gene co-expression network (GCN) and enrich the prediction task. HMC is used to build multiple estimators that consider the hierarchical structure of gene functions. The proposed approach is applied to a case study on Zea mays, one of the most dominant and productive crops in the world. The results illustrate how in silico approaches are key to reduce the time and costs of gene annotation. More specifically, they highlight the importance of: (i) building new features that represent the structure of gene relationships in GCNs to annotate genes; and (ii) taking into account the structure of biological processes to obtain consistent predictions. ",
    "url": "https://arxiv.org/abs/2203.13551",
    "authors": [
      "Miguel Romero",
      "Oscar Ram\u00edrez",
      "Jorge Finke",
      "Camilo Rocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13558",
    "title": "Neural Networks with Divisive normalization for image segmentation with  application in cityscapes dataset",
    "abstract": "One of the key problems in computer vision is adaptation: models are too rigid to follow the variability of the inputs. The canonical computation that explains adaptation in sensory neuroscience is divisive normalization, and it has appealing effects on image manifolds. In this work we show that including divisive normalization in current deep networks makes them more invariant to non-informative changes in the images. In particular, we focus on U-Net architectures for image segmentation. Experiments show that the inclusion of divisive normalization in the U-Net architecture leads to better segmentation results with respect to conventional U-Net. The gain increases steadily when dealing with images acquired in bad weather conditions. In addition to the results on the Cityscapes and Foggy Cityscapes datasets, we explain these advantages through visualization of the responses: the equalization induced by the divisive normalization leads to more invariant features to local changes in contrast and illumination. ",
    "url": "https://arxiv.org/abs/2203.13558",
    "authors": [
      "Pablo Hern\u00e1ndez-C\u00e1mara",
      "Valero Laparra",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13563",
    "title": "An Intelligent End-to-End Neural Architecture Search Framework for  Electricity Forecasting Model Development",
    "abstract": "Recent years have witnessed an exponential growth in developing deep learning (DL) models for the time-series electricity forecasting in power systems. However, most of the proposed models are designed based on the designers' inherent knowledge and experience without elaborating on the suitability of the proposed neural architectures. Moreover, these models cannot be self-adjusted to the dynamically changing data patterns due to an inflexible design of their structures. Even though several latest studies have considered application of the neural architecture search (NAS) technique for obtaining a network with an optimized structure in the electricity forecasting sector, their training process is quite time-consuming, computationally expensive and not intelligent, indicating that the NAS application in electricity forecasting area is still at an infancy phase. In this research study, we propose an intelligent automated architecture search (IAAS) framework for the development of time-series electricity forecasting models. The proposed framework contains two primary components, i.e., network function-preserving transformation operation and reinforcement learning (RL)-based network transformation control. In the first component, we introduce a theoretical function-preserving transformation of recurrent neural networks (RNN) to the literature for capturing the hidden temporal patterns within the time-series data. In the second component, we develop three RL-based transformation actors and a net pool to intelligently and effectively search a high-quality neural architecture. After conducting comprehensive experiments on two publicly-available electricity load datasets and two wind power datasets, we demonstrate that the proposed IAAS framework significantly outperforms the ten existing models or methods in terms of forecasting accuracy and stability. ",
    "url": "https://arxiv.org/abs/2203.13563",
    "authors": [
      "Jin Yang",
      "Yingying Huang",
      "Guangxin Jiang",
      "Ying Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13570",
    "title": "Improving Question Answering over Knowledge Graphs Using Graph  Summarization",
    "abstract": "Question Answering (QA) systems over Knowledge Graphs (KGs) (KGQA) automatically answer natural language questions using triples contained in a KG. The key idea is to represent questions and entities of a KG as low-dimensional embeddings. Previous KGQAs have attempted to represent entities using Knowledge Graph Embedding (KGE) and Deep Learning (DL) methods. However, KGEs are too shallow to capture the expressive features and DL methods process each triple independently. Recently, Graph Convolutional Network (GCN) has shown to be excellent in providing entity embeddings. However, using GCNs to KGQAs is inefficient because GCNs treat all relations equally when aggregating neighbourhoods. Also, a problem could occur when using previous KGQAs: in most cases, questions often have an uncertain number of answers. To address the above issues, we propose a graph summarization technique using Recurrent Convolutional Neural Network (RCNN) and GCN. The combination of GCN and RCNN ensures that the embeddings are propagated together with the relations relevant to the question, and thus better answers. The proposed graph summarization technique can be used to tackle the issue that KGQAs cannot answer questions with an uncertain number of answers. In this paper, we demonstrated the proposed technique on the most common type of questions, which is single-relation questions. Experiments have demonstrated that the proposed graph summarization technique using RCNN and GCN can provide better results when compared to the GCN. The proposed graph summarization technique significantly improves the recall of actual answers when the questions have an uncertain number of answers. ",
    "url": "https://arxiv.org/abs/2203.13570",
    "authors": [
      "Sirui Li",
      "Kok Kai Wong",
      "Dengya Zhu",
      "Chun Che Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13571",
    "title": "Adaptive Neural Network-based OFDM Receivers",
    "abstract": "We propose and examine the idea of continuously adapting state-of-the-art neural network (NN)-based orthogonal frequency division multiplex (OFDM) receivers to current channel conditions. This online adaptation via retraining is mainly motivated by two reasons: First, receiver design typically focuses on the universal optimal performance for a wide range of possible channel realizations. However, in actual applications and within short time intervals, only a subset of these channel parameters is likely to occur, as macro parameters, e.g., the maximum channel delay, can assumed to be static. Second, in-the-field alterations like temporal interferences or other conditions out of the originally intended specifications can occur on a practical (real-world) transmission. While conventional (filter-based) systems would require reconfiguration or additional signal processing to cope with these unforeseen conditions, NN-based receivers can learn to mitigate previously unseen effects even after their deployment. For this, we showcase on-the-fly adaption to current channel conditions and temporal alterations solely based on recovered labels from an outer forward error correction (FEC) code without any additional piloting overhead. To underline the flexibility of the proposed adaptive training, we showcase substantial gains for scenarios with static channel macro parameters, for out-ofspecification usage and for interference compensation. ",
    "url": "https://arxiv.org/abs/2203.13571",
    "authors": [
      "Moritz Benedikt Fischer",
      "Sebastian D\u00f6rner",
      "Sebastian Cammerer",
      "Takayuki Shimizu",
      "Hongsheng Lu",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.13596",
    "title": "DeepALM: Holistic Optical Network Monitoring based on Machine Learning",
    "abstract": "We demonstrate a machine learning-based optical network monitoring system which can integrate fiber monitoring, predictive maintenance of optical hardware, and security information management in a single solution. ",
    "url": "https://arxiv.org/abs/2203.13596",
    "authors": [
      "Joo Yeon Cho",
      "Jose-Juan Pedreno-Manresa",
      "Sai Kireet Patri",
      "Khouloud Abdelli",
      "Carsten Tropschug",
      "Jim Zou",
      "Piotr Rydlichowski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.13607",
    "title": "Fast and computationally efficient generative adversarial network  algorithm for unmanned aerial vehicle-based network coverage optimization",
    "abstract": "The challenge of dynamic traffic demand in mobile networks is tackled by moving cells based on unmanned aerial vehicles. Considering the tremendous potential of unmanned aerial vehicles in the future, we propose a new heuristic algorithm for coverage optimization. The proposed algorithm is implemented based on a conditional generative adversarial neural network, with a unique multilayer sum-pooling loss function. To assess the performance of the proposed approach, we compare it with the optimal core-set algorithm and quasi-optimal spiral algorithm. Simulation results show that the proposed approach converges to the quasi-optimal solution with a negligible difference from the global optimum while maintaining a quadratic complexity regardless of the number of users. ",
    "url": "https://arxiv.org/abs/2203.13607",
    "authors": [
      "Marek Ru\u017ei\u010dka",
      "Marcel Volo\u0161in",
      "Juraj Gazda",
      "Taras Maksymyuk",
      "Longzhe Han",
      "Mischa Dohler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.13608",
    "title": "Rope3D: TheRoadside Perception Dataset for Autonomous Driving and  Monocular 3D Object Detection Task",
    "abstract": "Concurrent perception datasets for autonomous driving are mainly limited to frontal view with sensors mounted on the vehicle. None of them is designed for the overlooked roadside perception tasks. On the other hand, the data captured from roadside cameras have strengths over frontal-view data, which is believed to facilitate a safer and more intelligent autonomous driving system. To accelerate the progress of roadside perception, we present the first high-diversity challenging Roadside Perception 3D dataset- Rope3D from a novel view. The dataset consists of 50k images and over 1.5M 3D objects in various scenes, which are captured under different settings including various cameras with ambiguous mounting positions, camera specifications, viewpoints, and different environmental conditions. We conduct strict 2D-3D joint annotation and comprehensive data analysis, as well as set up a new 3D roadside perception benchmark with metrics and evaluation devkit. Furthermore, we tailor the existing frontal-view monocular 3D object detection approaches and propose to leverage the geometry constraint to solve the inherent ambiguities caused by various sensors, viewpoints. Our dataset is available on https://thudair.baai.ac.cn/rope. ",
    "url": "https://arxiv.org/abs/2203.13608",
    "authors": [
      "Xiaoqing Ye",
      "Mao Shu",
      "Hanyu Li",
      "Yifeng Shi",
      "Yingying Li",
      "Guangjie Wang",
      "Xiao Tan",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13616",
    "title": "Lightweight Graph Convolutional Networks with Topologically Consistent  Magnitude Pruning",
    "abstract": "Graph convolution networks (GCNs) are currently mainstream in learning with irregular data. These models rely on message passing and attention mechanisms that capture context and node-to-node relationships. With multi-head attention, GCNs become highly accurate but oversized, and their deployment on cheap devices requires their pruning. However, pruning at high regimes usually leads to topologically inconsistent networks with weak generalization. In this paper, we devise a novel method for lightweight GCN design. Our proposed approach parses and selects subnetworks with the highest magnitudes while guaranteeing their topological consistency. The latter is obtained by selecting only accessible and co-accessible connections which actually contribute in the evaluation of the selected subnetworks. Experiments conducted on the challenging FPHA dataset show the substantial gain of our topologically consistent pruning method especially at very high pruning regimes. ",
    "url": "https://arxiv.org/abs/2203.13616",
    "authors": [
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13623",
    "title": "The best defense is a good defense: adapting negotiation methods for  tackling pressure over software project estimates",
    "abstract": "Software estimation is critical for a software project's success and a challenging activity. We argue that estimation problems are not restricted to the generation of estimates but also their use for commitment establishment: project stakeholders pressure estimators to change their estimates or to accept unrealistic commitments to attain business goals. In this study, we employed a Design Science Research (DSR) methodology to design an artifact based on negotiation methods, to empower software estimators in defending their estimates and searching for alternatives to unrealistic commitments when facing pressure. The artifact is a concrete step towards disseminating the soft skill of negotiation among practitioners. We present the preliminary results from a focus group that showed that practitioners from the software industry could use the artifact in a concrete scenario when estimating and establishing commitments about a software project. Our future steps include improving the artifact with the suggestions from focus group participants and evaluating it empirically in real software projects in the industry. ",
    "url": "https://arxiv.org/abs/2203.13623",
    "authors": [
      "Patricia G. F. Matsubara",
      "Igor Steinmacher",
      "Bruno Gadelha",
      "Tayana Conte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.13628",
    "title": "DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio  Representation Learning",
    "abstract": "Inspired by the recent progress in self-supervised learning for computer vision, in this paper, through the DeLoRes learning framework, we introduce two new general-purpose audio representation learning approaches, the DeLoRes-S and DeLoRes-M. Our main objective is to make our network learn representations in a resource-constrained setting (both data and compute), that can generalize well across a diverse set of downstream tasks. Inspired from the Barlow Twins objective function, we propose to learn embeddings that are invariant to distortions of an input audio sample, while making sure that they contain non-redundant information about the sample. To achieve this, we measure the cross-correlation matrix between the outputs of two identical networks fed with distorted versions of an audio segment sampled from an audio file and make it as close to the identity matrix as possible. We call this the DeLoRes learning framework, which we employ in different fashions with the DeLoRes-S and DeLoRes-M. We use a combination of a small subset of the large-scale AudioSet dataset and FSD50K for self-supervised learning and are able to learn with less than half the parameters compared to state-of-the-art algorithms. For evaluation, we transfer these learned representations to 11 downstream classification tasks, including speech, music, and animal sounds, and achieve state-of-the-art results on 7 out of 11 tasks on linear evaluation with DeLoRes-M and show competitive results with DeLoRes-S, even when pre-trained using only a fraction of the total data when compared to prior art. Our transfer learning evaluation setup also shows extremely competitive results for both DeLoRes-S and DeLoRes-M, with DeLoRes-M achieving state-of-the-art in 4 tasks. ",
    "url": "https://arxiv.org/abs/2203.13628",
    "authors": [
      "Sreyan Ghosh",
      "Ashish Seth",
      "S Umesh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.13639",
    "title": "Give Me Your Attention: Dot-Product Attention Considered Harmful for  Adversarial Patch Robustness",
    "abstract": "Neural architectures based on attention such as vision transformers are revolutionizing image recognition. Their main benefit is that attention allows reasoning about all parts of a scene jointly. In this paper, we show how the global reasoning of (scaled) dot-product attention can be the source of a major vulnerability when confronted with adversarial patch attacks. We provide a theoretical understanding of this vulnerability and relate it to an adversary's ability to misdirect the attention of all queries to a single key token under the control of the adversarial patch. We propose novel adversarial objectives for crafting adversarial patches which target this vulnerability explicitly. We show the effectiveness of the proposed patch attacks on popular image classification (ViTs and DeiTs) and object detection models (DETR). We find that adversarial patches occupying 0.5% of the input can lead to robust accuracies as low as 0% for ViT on ImageNet, and reduce the mAP of DETR on MS COCO to less than 3%. ",
    "url": "https://arxiv.org/abs/2203.13639",
    "authors": [
      "Giulio Lovisotto",
      "Nicole Finnie",
      "Mauricio Munoz",
      "Chaithanya Kumar Mummadi",
      "Jan Hendrik Metzen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13641",
    "title": "StretchBEV: Stretching Future Instance Prediction Spatially and  Temporally",
    "abstract": "In self-driving, predicting future in terms of location and motion of all the agents around the vehicle is a crucial requirement for planning. Recently, a new joint formulation of perception and prediction has emerged by fusing rich sensory information perceived from multiple cameras into a compact bird's-eye view representation to perform prediction. However, the quality of future predictions degrades over time while extending to longer time horizons due to multiple plausible predictions. In this work, we address this inherent uncertainty in future predictions with a stochastic temporal model. Our model learns temporal dynamics in a latent space through stochastic residual updates at each time step. By sampling from a learned distribution at each time step, we obtain more diverse future predictions that are also more accurate compared to previous work, especially stretching both spatially further regions in the scene and temporally over longer time horizons. Despite separate processing of each time step, our model is still efficient through decoupling of the learning of dynamics and the generation of future predictions. ",
    "url": "https://arxiv.org/abs/2203.13641",
    "authors": [
      "Adil Kaan Akan",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13648",
    "title": "Understanding the Difficulty of Training Physics-Informed Neural  Networks on Dynamical Systems",
    "abstract": "Physics-informed neural networks (PINNs) seamlessly integrate data and physical constraints into the solving of problems governed by differential equations. In settings with little labeled training data, their optimization relies on the complexity of the embedded physics loss function. Two fundamental questions arise in any discussion of frequently reported convergence issues in PINNs: Why does the optimization often converge to solutions that lack physical behavior? And why do reduced domain methods improve convergence behavior in PINNs? We answer these questions by studying the physics loss function in the vicinity of fixed points of dynamical systems. Experiments on a simple dynamical system demonstrate that physics loss residuals are trivially minimized in the vicinity of fixed points. As a result we observe that solutions corresponding to nonphysical system dynamics can be dominant in the physics loss landscape and optimization. We find that reducing the computational domain lowers the optimization complexity and chance of getting trapped with nonphysical solutions. ",
    "url": "https://arxiv.org/abs/2203.13648",
    "authors": [
      "Franz M. Rohrhofer",
      "Stefan Posch",
      "Clemens G\u00f6\u00dfnitzer",
      "Bernhard C. Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13652",
    "title": "HYDRA: Competing convolutional kernels for fast and accurate time series  classification",
    "abstract": "We demonstrate a simple connection between dictionary methods for time series classification, which involve extracting and counting symbolic patterns in time series, and methods based on transforming input time series using convolutional kernels, namely ROCKET and its variants. We show that by adjusting a single hyperparameter it is possible to move by degrees between models resembling dictionary methods and models resembling ROCKET. We present HYDRA, a simple, fast, and accurate dictionary method for time series classification using competing convolutional kernels, combining key aspects of both ROCKET and conventional dictionary methods. HYDRA is faster and more accurate than the most accurate existing dictionary methods, and can be combined with ROCKET and its variants to further improve the accuracy of these methods. ",
    "url": "https://arxiv.org/abs/2203.13652",
    "authors": [
      "Angus Dempster",
      "Daniel F. Schmidt",
      "Geoffrey I. Webb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13655",
    "title": "Gransformer: Transformer-based Graph Generation",
    "abstract": "Transformers have become widely used in modern models for various tasks such as natural language processing and machine vision. This paper, proposes Gransformer, an algorithm for generating graphs that takes advantage of the transformer. We extend a simple autoregressive transformer encoder to exploit the structural information of the graph through efficient modifications. The attention mechanism is modified to consider the presence or absence of edges between each pair of nodes. We also introduce a graph-based familiarity measure that applies to both the attention and the positional coding. This autoregressive criterion, inspired by message passing algorithms, contains structural information about the graph. In the output layer, we also use a masked autoencoder for density estimation to efficiently model the generation of dependent edges. We also propose a technique to prevent the model from generating isolated nodes. We evaluate this method on two real-world datasets and compare it with some state-of-the-art autoregressive graph generation methods. Experimental results have shown that the proposed method performs comparative to these methods, including recurrent models and graph convolutional networks. ",
    "url": "https://arxiv.org/abs/2203.13655",
    "authors": [
      "Ahmad Khajenezhad",
      "Seyed Ali Osia",
      "Mahmood Karimian",
      "Hamid Beigy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13664",
    "title": "Adjacent Context Coordination Network for Salient Object Detection in  Optical Remote Sensing Images",
    "abstract": "Salient object detection (SOD) in optical remote sensing images (RSIs), or RSI-SOD, is an emerging topic in understanding optical RSIs. However, due to the difference between optical RSIs and natural scene images (NSIs), directly applying NSI-SOD methods to optical RSIs fails to achieve satisfactory results. In this paper, we propose a novel Adjacent Context Coordination Network (ACCoNet) to explore the coordination of adjacent features in an encoder-decoder architecture for RSI-SOD. Specifically, ACCoNet consists of three parts: an encoder, Adjacent Context Coordination Modules (ACCoMs), and a decoder. As the key component of ACCoNet, ACCoM activates the salient regions of output features of the encoder and transmits them to the decoder. ACCoM contains a local branch and two adjacent branches to coordinate the multi-level features simultaneously. The local branch highlights the salient regions in an adaptive way, while the adjacent branches introduce global information of adjacent levels to enhance salient regions. Additionally, to extend the capabilities of the classic decoder block (i.e., several cascaded convolutional layers), we extend it with two bifurcations and propose a Bifurcation-Aggregation Block to capture the contextual information in the decoder. Extensive experiments on two benchmark datasets demonstrate that the proposed ACCoNet outperforms 22 state-of-the-art methods under nine evaluation metrics, and runs up to 81 fps on a single NVIDIA Titan X GPU. The code and results of our method are available at https://github.com/MathLee/ACCoNet. ",
    "url": "https://arxiv.org/abs/2203.13664",
    "authors": [
      "Gongyang Li",
      "Zhi Liu",
      "Dan Zeng",
      "Weisi Lin",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13694",
    "title": "Implicit Neural Representations for Variable Length Human Motion  Generation",
    "abstract": "We propose an action-conditional human motion generation method using variational implicit neural representations (INR). The variational formalism enables action-conditional distributions of INRs, from which one can easily sample representations to generate novel human motion sequences. Our method offers variable-length sequence generation by construction because a part of INR is optimized for a whole sequence of arbitrary length with temporal embeddings. In contrast, previous works reported difficulties with modeling variable-length sequences. We confirm that our method with a Transformer decoder outperforms all relevant methods on HumanAct12, NTU-RGBD, and UESTC datasets in terms of realism and diversity of generated motions. Surprisingly, even our method with an MLP decoder consistently outperforms the state-of-the-art Transformer-based auto-encoder. In particular, we show that variable-length motions generated by our method are better than fixed-length motions generated by the state-of-the-art method in terms of realism and diversity. ",
    "url": "https://arxiv.org/abs/2203.13694",
    "authors": [
      "Pablo Cervantes",
      "Yusuke Sekikawa",
      "Ikuro Sato",
      "Koichi Shinoda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13696",
    "title": "Speech-enhanced and Noise-aware Networks for Robust Speech Recognition",
    "abstract": "Compensation for channel mismatch and noise interference is essential for robust automatic speech recognition. Enhanced speech has been introduced into the multi-condition training of acoustic models to improve their generalization ability. In this paper, a noise-aware training framework based on two cascaded neural structures is proposed to jointly optimize speech enhancement and speech recognition. The feature enhancement module is composed of a multi-task autoencoder, where noisy speech is decomposed into clean speech and noise. By concatenating its enhanced, noise-aware, and noisy features for each frame, the acoustic-modeling module maps each feature-augmented frame into a triphone state by optimizing the lattice-free maximum mutual information and cross entropy between the predicted and actual state sequences. On top of the factorized time delay neural network (TDNN-F) and its convolutional variant (CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error rate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared with the best existing systems that use bigram and trigram language models for decoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction of 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based system also outperforms the baseline CNN-TDNNF system on the AMI task. ",
    "url": "https://arxiv.org/abs/2203.13696",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Yuan Chen",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.13705",
    "title": "Anchoring Code Understandability Evaluations Through Task Descriptions",
    "abstract": "In code comprehension experiments, participants are usually told at the beginning what kind of code comprehension task to expect. Describing experiment scenarios and experimental tasks will influence participants in ways that are sometimes hard to predict and control. In particular, describing or even mentioning the difficulty of a code comprehension task might anchor participants and their perception of the task itself. In this study, we investigated in a randomized, controlled experiment with 256 participants (50 software professionals and 206 computer science students) whether a hint about the difficulty of the code to be understood in a task description anchors participants in their own code comprehensibility ratings. Subjective code evaluations are a commonly used measure for how well a developer in a code comprehension study understood code. Accordingly, it is important to understand how robust these measures are to cognitive biases such as the anchoring effect. Our results show that participants are significantly influenced by the initial scenario description in their assessment of code comprehensibility. An initial hint of hard to understand code leads participants to assess the code as harder to understand than participants who received no hint or a hint of easy to understand code. This affects students and professionals alike. We discuss examples of design decisions and contextual factors in the conduct of code comprehension experiments that can induce an anchoring effect, and recommend the use of more robust comprehension measures in code comprehension studies to enhance the validity of results. ",
    "url": "https://arxiv.org/abs/2203.13705",
    "authors": [
      "Marvin Wyrich",
      "Lasse Merz",
      "Daniel Graziotin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.13712",
    "title": "Effective and Efficient Core Decomposition in Signed Networks",
    "abstract": "With the proliferation of mobile technology and IT development, people can use social network services at any place and anytime. Among many social network mining problems, identifying cohesive subgraphs attract many attentions from different fields due to its numerous applications. Among many cohesive subgraph models, k-core is the most widely used model due to its simple and intuitive structure. In this paper, we formulate (p,n)-core in signed networks by extending k-core. (p,n)-core simultaneously guarantees the sufficient internal positive edges and deficient internal negative edges. We formally prove that finding an exact (p,n)-core is NP-hard. Hence, we propose three efficient and effective algorithms to find a solution. Using real-world and synthetic networks, we demonstrate the superiority of our proposed algorithms. ",
    "url": "https://arxiv.org/abs/2203.13712",
    "authors": [
      "Junghoon Kim",
      "Sungsu Lim",
      "Jungeun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.13714",
    "title": "Searching for Network Width with Bilaterally Coupled Network",
    "abstract": "Searching for a more compact network width recently serves as an effective way of channel pruning for the deployment of convolutional neural networks (CNNs) under hardware constraints. To fulfill the searching, a one-shot supernet is usually leveraged to efficiently evaluate the performance \\wrt~different network widths. However, current methods mainly follow a \\textit{unilaterally augmented} (UA) principle for the evaluation of each width, which induces the training unfairness of channels in supernet. In this paper, we introduce a new supernet called Bilaterally Coupled Network (BCNet) to address this issue. In BCNet, each channel is fairly trained and responsible for the same amount of network widths, thus each network width can be evaluated more accurately. Besides, we propose to reduce the redundant search space and present the BCNetV2 as the enhanced supernet to ensure rigorous training fairness over channels. Furthermore, we leverage a stochastic complementary strategy for training the BCNet, and propose a prior initial population sampling method to boost the performance of the evolutionary search. We also propose the first open-source width benchmark on macro structures named Channel-Bench-Macro for the better comparison of width search algorithms. Extensive experiments on benchmark CIFAR-10 and ImageNet datasets indicate that our method can achieve state-of-the-art or competing performance over other baseline methods. Moreover, our method turns out to further boost the performance of NAS models by refining their network widths. For example, with the same FLOPs budget, our obtained EfficientNet-B0 achieves 77.53\\% Top-1 accuracy on ImageNet dataset, surpassing the performance of original setting by 0.65\\%. ",
    "url": "https://arxiv.org/abs/2203.13714",
    "authors": [
      "Xiu Su",
      "Shan You",
      "Jiyang Xie",
      "Fei Wang",
      "Chen Qian",
      "Changshui Zhang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13716",
    "title": "Stabilizing Adversarially Learned One-Class Novelty Detection Using  Pseudo Anomalies",
    "abstract": "Recently, anomaly scores have been formulated using reconstruction loss of the adversarially learned generators and/or classification loss of discriminators. Unavailability of anomaly examples in the training data makes optimization of such networks challenging. Attributed to the adversarial training, performance of such models fluctuates drastically with each training step, making it difficult to halt the training at an optimal point. In the current study, we propose a robust anomaly detection framework that overcomes such instability by transforming the fundamental role of the discriminator from identifying real vs. fake data to distinguishing good vs. bad quality reconstructions. For this purpose, we propose a method that utilizes the current state as well as an old state of the same generator to create good and bad quality reconstruction examples. The discriminator is trained on these examples to detect the subtle distortions that are often present in the reconstructions of anomalous data. In addition, we propose an efficient generic criterion to stop the training of our model, ensuring elevated performance. Extensive experiments performed on six datasets across multiple domains including image and video based anomaly detection, medical diagnosis, and network security, have demonstrated excellent performance of our approach. ",
    "url": "https://arxiv.org/abs/2203.13716",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Jin Ha Lee",
      "Arif Mahmood",
      "Marcella Astrid",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13721",
    "title": "Salt Detection Using Segmentation of Seismic Image",
    "abstract": "In this project, a state-of-the-art deep convolution neural network (DCNN) is presented to segment seismic images for salt detection below the earth's surface. Detection of salt location is very important for starting mining. Hence, a seismic image is used to detect the exact salt location under the earth's surface. However, precisely detecting the exact location of salt deposits is difficult. Therefore, professional seismic imaging still requires expert human interpretation of salt bodies. This leads to very subjective, highly variable renderings. Hence, to create the most accurate seismic images and 3D renderings, we need a robust algorithm that automatically and accurately identifies if a surface target is a salt or not. Since the performance of DCNN is well-known and well-established for object recognition in images, DCNN is a very good choice for this particular problem and being successfully applied to a dataset of seismic images in which each pixel is labeled as salt or not. The result of this algorithm is promising. ",
    "url": "https://arxiv.org/abs/2203.13721",
    "authors": [
      "Mrinmoy Sarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.13746",
    "title": "Code Smells for Machine Learning Applications",
    "abstract": "The popularity of machine learning has wildly expanded in recent years. Machine learning techniques have been heatedly studied in academia and applied in the industry to create business value. However, there is a lack of guidelines for code quality in machine learning applications. In particular, code smells have rarely been studied in this domain. Although machine learning code is usually integrated as a small part of an overarching system, it usually plays an important role in its core functionality. Hence ensuring code quality is quintessential to avoid issues in the long run. This paper proposes and identifies a list of 22 machine learning-specific code smells collected from various sources, including papers, grey literature, GitHub commits, and Stack Overflow posts. We pinpoint each smell with a description of its context, potential issues in the long run, and proposed solutions. In addition, we link them to their respective pipeline stage and the evidence from both academic and grey literature. The code smell catalog helps data scientists and developers produce and maintain high-quality machine learning application code. ",
    "url": "https://arxiv.org/abs/2203.13746",
    "authors": [
      "Haiyin Zhang",
      "Lu\u00eds Cruz",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13777",
    "title": "Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion",
    "abstract": "Human behavior has the nature of indeterminacy, which requires the pedestrian trajectory prediction system to model the multi-modality of future motion states. Unlike existing stochastic trajectory prediction methods which usually use a latent variable to represent multi-modality, we explicitly simulate the process of human motion variation from indeterminate to determinate. In this paper, we present a new framework to formulate the trajectory prediction task as a reverse process of motion indeterminacy diffusion (MID), in which we progressively discard indeterminacy from all the walkable areas until reaching the desired trajectory. This process is learned with a parameterized Markov chain conditioned by the observed trajectories. We can adjust the length of the chain to control the degree of indeterminacy and balance the diversity and determinacy of the predictions. Specifically, we encode the history behavior information and the social interactions as a state embedding and devise a Transformer-based diffusion model to capture the temporal dependencies of trajectories. Extensive experiments on the human trajectory prediction benchmarks including the Stanford Drone and ETH/UCY datasets demonstrate the superiority of our method. Code is available at https://github.com/gutianpei/MID. ",
    "url": "https://arxiv.org/abs/2203.13777",
    "authors": [
      "Tianpei Gu",
      "Guangyi Chen",
      "Junlong Li",
      "Chunze Lin",
      "Yongming Rao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13778",
    "title": "L3Cube-MahaHate: A Tweet-based Marathi Hate Speech Detection Dataset and  BERT models",
    "abstract": "Social media platforms are used by a large number of people prominently to express their thoughts and opinions. However, these platforms have contributed to a substantial amount of hateful and abusive content as well. Therefore, it is important to curb the spread of hate speech on these platforms. In India, Marathi is one of the most popular languages used by a wide audience. In this work, we present L3Cube-MahaHate, the first major Hate Speech Dataset in Marathi. The dataset is curated from Twitter, annotated manually. Our dataset consists of over 25000 distinct tweets labeled into four major classes i.e hate, offensive, profane, and not. We present the approaches used for collecting and annotating the data and the challenges faced during the process. Finally, we present baseline classification results using deep learning models based on CNN, LSTM, and Transformers. We explore mono-lingual and multi-lingual variants of BERT like MahaBERT, IndicBERT, mBERT, and xlm-RoBERTa and show that mono-lingual models perform better than their multi-lingual counterparts. The MahaBERT model provides the best results on L3Cube-MahaHate Corpus. The data and models are available at https://github.com/l3cube-pune/MarathiNLP . ",
    "url": "https://arxiv.org/abs/2203.13778",
    "authors": [
      "Abhishek Velankar",
      "Hrushikesh Patil",
      "Amol Gore",
      "Shubham Salunke",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13783",
    "title": "Ensemble Spectral Prediction (ESP) Model for Metabolite Annotation",
    "abstract": "A key challenge in metabolomics is annotating measured spectra from a biological sample with chemical identities. Currently, only a small fraction of measurements can be assigned identities. Two complementary computational approaches have emerged to address the annotation problem: mapping candidate molecules to spectra, and mapping query spectra to molecular candidates. In essence, the candidate molecule with the spectrum that best explains the query spectrum is recommended as the target molecule. Despite candidate ranking being fundamental in both approaches, no prior works utilized rank learning tasks in determining the target molecule. We propose a novel machine learning model, Ensemble Spectral Prediction (ESP), for metabolite annotation. ESP takes advantage of prior neural network-based annotation models that utilize multilayer perceptron (MLP) networks and Graph Neural Networks (GNNs). Based on the ranking results of the MLP and GNN-based models, ESP learns a weighting for the outputs of MLP and GNN spectral predictors to generate a spectral prediction for a query molecule. Importantly, training data is stratified by molecular formula to provide candidate sets during model training. Further, baseline MLP and GNN models are enhanced by considering peak dependencies through multi-head attention mechanism and multi-tasking on spectral topic distributions. ESP improves average rank by 41% and 30% over the MLP and GNN baselines, respectively, demonstrating remarkable performance gain over state-of-the-art neural network approaches. We show that annotation performance, for ESP and other models, is a strong function of the number of molecules in the candidate set and their similarity to the target molecule. ",
    "url": "https://arxiv.org/abs/2203.13783",
    "authors": [
      "Xinmeng Li",
      "Hao Zhu",
      "Li-ping Liu",
      "Soha Hassoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2203.13817",
    "title": "AutoAvatar: Autoregressive Neural Fields for Dynamic Avatar Modeling",
    "abstract": "Neural fields such as implicit surfaces have recently enabled avatar modeling from raw scans without explicit temporal correspondences. In this work, we exploit autoregressive modeling to further extend this notion to capture dynamic effects, such as soft-tissue deformations. Although autoregressive models are naturally capable of handling dynamics, it is non-trivial to apply them to implicit representations, as explicit state decoding is infeasible due to prohibitive memory requirements. In this work, for the first time, we enable autoregressive modeling of implicit avatars. To reduce the memory bottleneck and efficiently model dynamic implicit surfaces, we introduce the notion of articulated observer points, which relate implicit states to the explicit surface of a parametric human body model. We demonstrate that encoding implicit surfaces as a set of height fields defined on articulated observer points leads to significantly better generalization compared to a latent representation. The experiments show that our approach outperforms the state of the art, achieving plausible dynamic deformations even for unseen motions. https://zqbai-jeremy.github.io/autoavatar ",
    "url": "https://arxiv.org/abs/2203.13817",
    "authors": [
      "Ziqian Bai",
      "Timur Bagautdinov",
      "Javier Romero",
      "Michael Zollh\u00f6fer",
      "Ping Tan",
      "Shunsuke Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.13256",
    "title": "Power Network Uniqueness and Synchronization Stability from a  Higher-order Structure Perspective",
    "abstract": "Triadic subgraph analysis reveals the structural features in power networks based on higher-order connectivity patterns. Power networks have a unique triad significance profile (TSP) of the five unidirectional triadic subgraphs in comparison with the scale-free, small-world and random networks. Notably, the triadic closure has the highest significance in power networks. Thus, the unique TSP can serve as a structural identifier to differentiate power networks from other complex networks. Power networks form a network superfamily. Furthermore, synthetic power networks based on the random growth model grow up to be networks belonging to the superfamily with a fewer number of transmission lines. The significance of triadic closures strongly correlates with the construction cost measured by network redundancy. The trade off between the synchronization stability and the construction cost leads to the power network superfamily. The power network characterized by the unique TSP is the consequence of the trade-off essentially. The uniqueness of the power network superfamily tells an important fact that power networks. ",
    "url": "https://arxiv.org/abs/2203.13256",
    "authors": [
      "Hao Liu",
      "Xin Chen",
      "Long Huo",
      "Chunming Niu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2203.13313",
    "title": "Deep learning for laboratory earthquake prediction and autoregressive  forecasting of fault zone stress",
    "abstract": "Earthquake forecasting and prediction have long and in some cases sordid histories but recent work has rekindled interest based on advances in early warning, hazard assessment for induced seismicity and successful prediction of laboratory earthquakes. In the lab, frictional stick-slip events provide an analog for earthquakes and the seismic cycle. Labquakes are ideal targets for machine learning (ML) because they can be produced in long sequences under controlled conditions. Recent works show that ML can predict several aspects of labquakes using fault zone acoustic emissions. Here, we generalize these results and explore deep learning (DL) methods for labquake prediction and autoregressive (AR) forecasting. DL improves existing ML methods of labquake prediction. AR methods allow forecasting at future horizons via iterative predictions. We demonstrate that DL models based on Long-Short Term Memory (LSTM) and Convolution Neural Networks predict labquakes under several conditions, and that fault zone stress can be predicted with fidelity, confirming that acoustic energy is a fingerprint of fault zone stress. We predict also time to start of failure (TTsF) and time to the end of Failure (TTeF) for labquakes. Interestingly, TTeF is successfully predicted in all seismic cycles, while the TTsF prediction varies with the amount of preseismic fault creep. We report AR methods to forecast the evolution of fault stress using three sequence modeling frameworks: LSTM, Temporal Convolution Network and Transformer Network. AR forecasting is distinct from existing predictive models, which predict only a target variable at a specific time. The results for forecasting beyond a single seismic cycle are limited but encouraging. Our ML/DL models outperform the state-of-the-art and our autoregressive model represents a novel framework that could enhance current methods of earthquake forecasting. ",
    "url": "https://arxiv.org/abs/2203.13313",
    "authors": [
      "Laura Laurenti",
      "Elisa Tinti",
      "Fabio Galasso",
      "Luca Franco",
      "Chris Marone"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13482",
    "title": "Polarization Multiplexed Diffractive Computing: All-Optical  Implementation of a Group of Linear Transformations Through a  Polarization-Encoded Diffractive Network",
    "abstract": "Research on optical computing has recently attracted significant attention due to the transformative advances in machine learning. Among different approaches, diffractive optical networks composed of spatially-engineered transmissive surfaces have been demonstrated for all-optical statistical inference and performing arbitrary linear transformations using passive, free-space optical layers. Here, we introduce a polarization multiplexed diffractive processor to all-optically perform multiple, arbitrarily-selected linear transformations through a single diffractive network trained using deep learning. In this framework, an array of pre-selected linear polarizers is positioned between trainable transmissive diffractive materials that are isotropic, and different target linear transformations (complex-valued) are uniquely assigned to different combinations of input/output polarization states. The transmission layers of this polarization multiplexed diffractive network are trained and optimized via deep learning and error-backpropagation by using thousands of examples of the input/output fields corresponding to each one of the complex-valued linear transformations assigned to different input/output polarization combinations. Our results and analysis reveal that a single diffractive network can successfully approximate and all-optically implement a group of arbitrarily-selected target transformations with a negligible error when the number of trainable diffractive features/neurons (N) approaches N_p x N_i x N_o, where N_i and N_o represent the number of pixels at the input and output fields-of-view, respectively, and N_p refers to the number of unique linear transformations assigned to different input/output polarization combinations. This polarization-multiplexed all-optical diffractive processor can find various applications in optical computing and polarization-based machine vision tasks. ",
    "url": "https://arxiv.org/abs/2203.13482",
    "authors": [
      "Jingxi Li",
      "Yi-Chun Hung",
      "Onur Kulce",
      "Deniz Mengu",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.13574",
    "title": "Embedding Recurrent Layers with Dual-Path Strategy in a Variant of  Convolutional Network for Speaker-Independent Speech Separation",
    "abstract": "Speaker-independent speech separation has achieved remarkable performance in recent years with the development of deep neural network (DNN). Various network architectures, from traditional convolutional neural network (CNN) and recurrent neural network (RNN) to advanced transformer, have been designed sophistically to improve separation performance. However, the state-of-the-art models usually suffer from several flaws related to the computation, such as large model size, huge memory consumption and computational complexity. To find the balance between the performance and computational efficiency and to further explore the modeling ability of traditional network structure, we combine RNN and a newly proposed variant of convolutional network to cope with speech separation problem. By embedding two RNNs into basic block of this variant with the help of dual-path strategy, the proposed network can effectively learn the local information and global dependency. Besides, a four-staged structure enables the separation procedure to be performed gradually at finer and finer scales as the feature dimension increases. The experimental results on various datasets have proven the effectiveness of the proposed method and shown that a trade-off between the separation performance and computational efficiency is well achieved. ",
    "url": "https://arxiv.org/abs/2203.13574",
    "authors": [
      "Xue Yang",
      "Changchun Bao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.13779",
    "title": "Origins of Low-dimensional Adversarial Perturbations",
    "abstract": "In this note, we initiate a rigorous study of the phenomenon of low-dimensional adversarial perturbations in classification. These are adversarial perturbations wherein, unlike the classical setting, the attacker's search is limited to a low-dimensional subspace of the feature space. The goal is to fool the classifier into flipping its decision on a nonzero fraction of inputs from a designated class, upon the addition of perturbations from a subspace chosen by the attacker and fixed once and for all. It is desirable that the dimension $k$ of the subspace be much smaller than the dimension $d$ of the feature space, while the norm of the perturbations should be negligible compared to the norm of a typical data point. In this work, we consider binary classification models under very general regularity conditions, which are verified by certain feedforward neural networks (e.g., with sufficiently smooth, or else ReLU activation function), and compute analytical lower-bounds for the fooling rate of any subspace. These bounds explicitly highlight the dependence that the fooling rate has on the margin of the model (i.e., the ratio of the output to its $L_2$-norm of its gradient at a test point), and on the alignment of the given subspace with the gradients of the model w.r.t. inputs. Our results provide a theoretical explanation for the recent success of heuristic methods for efficiently generating low-dimensional adversarial perturbations. Moreover, our theoretical results are confirmed by experiments. ",
    "url": "https://arxiv.org/abs/2203.13779",
    "authors": [
      "Elvis Dohmatob",
      "Chuan Guo",
      "Morgane Goibert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13787",
    "title": "A Hybrid Framework for Sequential Data Prediction with End-to-End  Optimization",
    "abstract": "We investigate nonlinear prediction in an online setting and introduce a hybrid model that effectively mitigates, via an end-to-end architecture, the need for hand-designed features and manual model selection issues of conventional nonlinear prediction/regression methods. In particular, we use recursive structures to extract features from sequential signals, while preserving the state information, i.e., the history, and boosted decision trees to produce the final output. The connection is in an end-to-end fashion and we jointly optimize the whole architecture using stochastic gradient descent, for which we also provide the backward pass update equations. In particular, we employ a recurrent neural network (LSTM) for adaptive feature extraction from sequential data and a gradient boosting machinery (soft GBDT) for effective supervised regression. Our framework is generic so that one can use other deep learning architectures for feature extraction (such as RNNs and GRUs) and machine learning algorithms for decision making as long as they are differentiable. We demonstrate the learning behavior of our algorithm on synthetic data and the significant performance improvements over the conventional methods over various real life datasets. Furthermore, we openly share the source code of the proposed method to facilitate further research. ",
    "url": "https://arxiv.org/abs/2203.13787",
    "authors": [
      "Mustafa E. Ayd\u0131n",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:1904.02342",
    "title": "Text Generation from Knowledge Graphs with Graph Transformers",
    "abstract": " Comments: Accepted as a long paper in NAACL 2019 ",
    "url": "https://arxiv.org/abs/1904.02342",
    "authors": [
      "Rik Koncel-Kedziorski",
      "Dhanush Bekal",
      "Yi Luan",
      "Mirella Lapata",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:1906.02831",
    "title": "Detection and Tracking of Multiple Mice Using Part Proposal Networks",
    "abstract": " Title: Detection and Tracking of Multiple Mice Using Part Proposal Networks ",
    "url": "https://arxiv.org/abs/1906.02831",
    "authors": [
      "Zheheng Jiang",
      "Zhihua Liu",
      "Long Chen",
      "Lei Tong",
      "Xiangrong Zhang",
      "Xiangyuan Lan",
      "Danny Crookes",
      "Ming-Hsuan Yang",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2010.11372",
    "title": "Symmetrical Z-Complementary Code Sets (SZCCSs) for Optimal Training in  Generalized Spatial Modulation",
    "abstract": " Comments: 13 pages, 7 figures, submitted to IEEE Transactions on Signal Processing ",
    "url": "https://arxiv.org/abs/2010.11372",
    "authors": [
      "Yajing Zhou",
      "Zhengchun Zhou",
      "Zilong Liu",
      "Yang Yang",
      "Ping Yang",
      "Pingzhi Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2010.12243",
    "title": "An analysis of the SIGMOD 2014 Programming Contest: Complex queries on  the LDBC social network graph",
    "abstract": " Title: An analysis of the SIGMOD 2014 Programming Contest: Complex queries on  the LDBC social network graph ",
    "url": "https://arxiv.org/abs/2010.12243",
    "authors": [
      "M\u00e1rton Elekes",
      "J\u00e1nos Benjamin Antal",
      "G\u00e1bor Sz\u00e1rnyas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2012.12368",
    "title": "Understanding and Increasing Efficiency of Frank-Wolfe Adversarial  Training",
    "abstract": " Comments: IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022. Preliminary version ICML 2021 Adversarial Machine Learning Workshop. Code: this https URL ",
    "url": "https://arxiv.org/abs/2012.12368",
    "authors": [
      "Theodoros Tsiligkaridis",
      "Jay Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.02725",
    "title": "CrossWalk: Fairness-enhanced Node Representation Learning",
    "abstract": " Comments: Association for the Advancement of Artificial Intelligence (AAAI) 2022 ",
    "url": "https://arxiv.org/abs/2105.02725",
    "authors": [
      "Ahmad Khajehnejad",
      "Moein Khajehnejad",
      "Mahmoudreza Babaei",
      "Krishna P. Gummadi",
      "Adrian Weller",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.03645",
    "title": "Photonic Differential Privacy with Direct Feedback Alignment",
    "abstract": " Title: Photonic Differential Privacy with Direct Feedback Alignment ",
    "url": "https://arxiv.org/abs/2106.03645",
    "authors": [
      "Ruben Ohana",
      "Hamlet J. Medina Ruiz",
      "Julien Launay",
      "Alessandro Cappelli",
      "Iacopo Poli",
      "Liva Ralaivola",
      "Alain Rakotomamonjy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.00605",
    "title": "Backstepping Mean-Field Density Control for Large-Scale Heterogeneous  Nonlinear Stochastic Systems",
    "abstract": " Title: Backstepping Mean-Field Density Control for Large-Scale Heterogeneous  Nonlinear Stochastic Systems ",
    "url": "https://arxiv.org/abs/2109.00605",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.05830",
    "title": "Adversarial Bone Length Attack on Action Recognition",
    "abstract": " Comments: 12 pages, 8 figures, accepted to AAAI2022 ",
    "url": "https://arxiv.org/abs/2109.05830",
    "authors": [
      "Nariki Tanaka",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.13675",
    "title": "FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for  Speech Synthesis",
    "abstract": " Title: FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for  Speech Synthesis ",
    "url": "https://arxiv.org/abs/2109.13675",
    "authors": [
      "Manh Luong",
      "Viet Anh Tran"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.07374",
    "title": "Physics informed neural networks for continuum micromechanics",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2110.07374",
    "authors": [
      "Alexander Henkes",
      "Henning Wessels",
      "Rolf Mahnken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14181",
    "title": "QU-net++: Image Quality Detection Framework for Segmentation of 3D  Medical Image Stacks",
    "abstract": " Comments: 4 pages, 7 figures, 1 Table ",
    "url": "https://arxiv.org/abs/2110.14181",
    "authors": [
      "Sohini Roychowdhury"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": " Comments: 49 pages, 19 figures ",
    "url": "https://arxiv.org/abs/2110.14953",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.00600",
    "title": "Minimum Description Length Recurrent Neural Networks",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2111.00600",
    "authors": [
      "Nur Lan",
      "Michal Geyer",
      "Emmanuel Chemla",
      "Roni Katzir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.08918",
    "title": "Local Texture Estimator for Implicit Representation Function",
    "abstract": " Comments: CVPR 2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2111.08918",
    "authors": [
      "Jaewon Lee",
      "Kyong Hwan Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.13585",
    "title": "Evaluating importance of nodes in complex networks with local volume  information dimension",
    "abstract": " Title: Evaluating importance of nodes in complex networks with local volume  information dimension ",
    "url": "https://arxiv.org/abs/2111.13585",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Fangzheng Duan",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.01917",
    "title": "A Structured Dictionary Perspective on Implicit Neural Representations",
    "abstract": " Comments: Accepted to IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022 (26 pages, 16 figures) ",
    "url": "https://arxiv.org/abs/2112.01917",
    "authors": [
      "Gizem Y\u00fcce",
      "Guillermo Ortiz-Jim\u00e9nez",
      "Beril Besbinar",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02500",
    "title": "Global-Local Context Network for Person Search",
    "abstract": " Title: Global-Local Context Network for Person Search ",
    "url": "https://arxiv.org/abs/2112.02500",
    "authors": [
      "Peng Zheng",
      "Jie Qin",
      "Yichao Yan",
      "Shengcai Liao",
      "Bingbing Ni",
      "Xiaogang Cheng",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04120",
    "title": "Feature Statistics Mixing Regularization for Generative Adversarial  Networks",
    "abstract": " Comments: Accepted to CVPR 2022. Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2112.04120",
    "authors": [
      "Junho Kim",
      "Yunjey Choi",
      "Youngjung Uh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12999",
    "title": "Total Energy Shaping with Neural Interconnection and Damping Assignment  -- Passivity Based Control",
    "abstract": " Comments: Accepted in 4th Annual Learning for Dynamics and Control (L4DC) Conference ",
    "url": "https://arxiv.org/abs/2112.12999",
    "authors": [
      "Santiago Sanchez-Escalonilla",
      "Rodolfo Reyes-Baez",
      "Bayu Jayawardhana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.05758",
    "title": "Robust Safe Control Synthesis with Disturbance Observer-Based Control  Barrier Functions",
    "abstract": " Comments: 6 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2201.05758",
    "authors": [
      "Ersin Da\u015f",
      "Richard M. Murray"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": " Comments: Accepted by WWW 2022 Poster ",
    "url": "https://arxiv.org/abs/2202.02113",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.08766",
    "title": "Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems?",
    "abstract": " Title: Can DtN and GenEO coarse spaces be sufficiently robust for heterogeneous  Helmholtz problems? ",
    "url": "https://arxiv.org/abs/2202.08766",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.01824",
    "title": "LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware  Transformer Network",
    "abstract": " Comments: To Appear in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.01824",
    "authors": [
      "Zhigang Jiang",
      "Zhongzheng Xiang",
      "Jinhua Xu",
      "Ming Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03820",
    "title": "A Variational Hierarchical Model for Neural Cross-Lingual Summarization",
    "abstract": " Comments: Accepted at ACL 2022 as a long paper of main conference. Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.03820",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Chulun Zhou",
      "Jinan Xu",
      "Yufeng Chen",
      "Jinsong Su",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.03978",
    "title": "Contrastive Conditional Neural Processes",
    "abstract": " Comments: accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.03978",
    "authors": [
      "Zesheng Ye",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.05154",
    "title": "Practical Evaluation of Adversarial Robustness via Adaptive Auto Attack",
    "abstract": " Comments: Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.05154",
    "authors": [
      "Ye Liu",
      "Yaya Cheng",
      "Lianli Gao",
      "Xianglong Liu",
      "Qilong Zhang",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05181",
    "title": "LineVD: Statement-level Vulnerability Detection using Graph Neural  Networks",
    "abstract": " Comments: Accepted in the 19th International Conference on Mining Software Repositories Technical Papers ",
    "url": "https://arxiv.org/abs/2203.05181",
    "authors": [
      "David Hin",
      "Andrey Kan",
      "Huaming Chen",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.08368",
    "title": "Mixed-Precision Neural Network Quantization via Learned Layer-wise  Importance",
    "abstract": " Title: Mixed-Precision Neural Network Quantization via Learned Layer-wise  Importance ",
    "url": "https://arxiv.org/abs/2203.08368",
    "authors": [
      "Chen Tang",
      "Kai Ouyang",
      "Zhi Wang",
      "Yifei Zhu",
      "Yaowei Wang",
      "Wen Ji",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09041",
    "title": "DATA: Domain-Aware and Task-Aware Self-supervised Learning",
    "abstract": " Comments: CVPR 2022,8 pages,3 figures ",
    "url": "https://arxiv.org/abs/2203.09041",
    "authors": [
      "Qing Chang",
      "Junran Peng",
      "Lingxie Xie",
      "Jiajun Sun",
      "Haoran Yin",
      "Qi Tian",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12208",
    "title": "Self-supervised Learning of Adversarial Example: Towards Good  Generalizations for Deepfake Detection",
    "abstract": " Comments: To appear in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.12208",
    "authors": [
      "Liang Chen",
      "Yong Zhang",
      "Yibing Song",
      "Lingqiao Liu",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12870",
    "title": "RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust  Correspondence Field Estimation and Pose Optimization",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.12870",
    "authors": [
      "Yan Xu",
      "Kwan-Yee Lin",
      "Guofeng Zhang",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.12932",
    "title": "Bioformers: Embedding Transformers for Ultra-Low Power sEMG-based  Gesture Recognition",
    "abstract": " Title: Bioformers: Embedding Transformers for Ultra-Low Power sEMG-based  Gesture Recognition ",
    "url": "https://arxiv.org/abs/2203.12932",
    "authors": [
      "Alessio Burrello",
      "Francesco Bianco Morghet",
      "Moritz Scherer",
      "Simone Benatti",
      "Luca Benini",
      "Enrico Macii",
      "Massimo Poncino",
      "Daniele Jahier Pagliari"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13052",
    "title": "Coarse-to-Fine Cascaded Networks with Smooth Predicting for Video Facial  Expression Recognition",
    "abstract": " Title: Coarse-to-Fine Cascaded Networks with Smooth Predicting for Video Facial  Expression Recognition ",
    "url": "https://arxiv.org/abs/2203.13052",
    "authors": [
      "Fanglei Xue",
      "Zichang Tan",
      "Yu Zhu",
      "Zhongsong Ma",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13181",
    "title": "The Cost-Accuracy Trade-Off In Operator Learning With Neural Networks",
    "abstract": " Comments: 25 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2203.13181",
    "authors": [
      "Maarten V. de Hoop",
      "Daniel Zhengyu Huang",
      "Elizabeth Qian",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  }
]