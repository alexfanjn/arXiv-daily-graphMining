[
  {
    "id": "arXiv:2203.01323",
    "title": "Benchmarking Robustness of Deep Learning Classifiers Using Two-Factor  Perturbation",
    "abstract": "Accuracies of deep learning (DL) classifiers are often unstable in that they may change significantly when retested on adversarial images, imperfect images, or perturbed images. This paper adds to the fundamental body of work on benchmarking the robustness of DL classifiers on defective images. To measure robust DL classifiers, previous research reported on single-factor corruption. We created comprehensive 69 benchmarking image sets, including a clean set, sets with single factor perturbations, and sets with two-factor perturbation conditions. The state-of-the-art two-factor perturbation includes (a) two digital perturbations (salt & pepper noise and Gaussian noise) applied in both sequences, and (b) one digital perturbation (salt & pepper noise) and a geometric perturbation (rotation) applied in both sequences. Previous research evaluating DL classifiers has often used top-1/top-5 accuracy. We innovate a new two-dimensional, statistical matrix to evaluating robustness of DL classifiers. Also, we introduce a new visualization tool, including minimum accuracy, maximum accuracy, mean accuracies, and coefficient of variation (CV), for benchmarking robustness of DL classifiers. Comparing with single factor corruption, we first report that using two-factor perturbed images improves both robustness and accuracy of DL classifiers. All source codes and related image sets are shared on the Website at this http URL to support future academic research and industry projects. ",
    "url": "https://arxiv.org/abs/2203.01323",
    "authors": [
      "Wei Dai",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.01360",
    "title": "Neural Galerkin Scheme with Active Learning for High-Dimensional  Evolution Equations",
    "abstract": "Machine learning methods have been shown to give accurate predictions in high dimensions provided that sufficient training data are available. Yet, many interesting questions in science and engineering involve situations where initially no data are available and the principal aim is to gather insights from a known model. Here we consider this problem in the context of systems whose evolution can be described by partial differential equations (PDEs). We use deep learning to solve these equations by generating data on-the-fly when and where they are needed, without prior information about the solution. The proposed Neural Galerkin schemes derive nonlinear dynamical equations for the network weights by minimization of the residual of the time derivative of the solution, and solve these equations using standard integrators for initial value problems. The sequential learning of the weights over time allows for adaptive collection of new input data for residual estimation. This step uses importance sampling informed by the current state of the solution, in contrast with other machine learning methods for PDEs that optimize the network parameters globally in time. This active form of data acquisition is essential to enable the approximation power of the neural networks and to break the curse of dimensionality faced by non-adaptative learning strategies. The applicability of the method is illustrated on several numerical examples involving high-dimensional PDEs, including advection equations with many variables, as well as Fokker-Planck equations for systems with several interacting particles. ",
    "url": "https://arxiv.org/abs/2203.01360",
    "authors": [
      "Joan Bruna",
      "Benjamin Peherstorfer",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01386",
    "title": "Exploring Hierarchical Graph Representation for Large-Scale Zero-Shot  Image Classification",
    "abstract": "The main question we address in this paper is how to scale up visual recognition of unseen classes, also known as zero-shot learning, to tens of thousands of categories as in the ImageNet-21K benchmark. At this scale, especially with many fine-grained categories included in ImageNet-21K, it is critical to learn quality visual semantic representations that are discriminative enough to recognize unseen classes and distinguish them from seen ones. We propose a Hierarchical Graphical knowledge Representation framework for the confidence-based classification method, dubbed as HGR-Net. Our experimental results demonstrate that HGR-Net can grasp class inheritance relations by utilizing hierarchical conceptual knowledge. Our method significantly outperformed all existing techniques, boosting the performance 7% compared to the runner-up approach on the ImageNet-21K benchmark. We show that HGR-Net is learning-efficient in few-shot scenarios. We also analyzed our method on smaller datasets like ImageNet-21K-P, 2-hops and 3-hops, demonstrating its generalization ability. Our benchmark and code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2203.01386",
    "authors": [
      "Kai Yi",
      "Xiaoqian Shen",
      "Yunhao Gou",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01388",
    "title": "Skew-Symmetric Adjacency Matrices for Clustering Directed Graphs",
    "abstract": "Cut-based directed graph (digraph) clustering often focuses on finding dense within-cluster or sparse between-cluster connections, similar to cut-based undirected graph clustering methods. In contrast, for flow-based clusterings the edges between clusters tend to be oriented in one direction and have been found in migration data, food webs, and trade data. In this paper we introduce a spectral algorithm for finding flow-based clusterings. The proposed algorithm is based on recent work which uses complex-valued Hermitian matrices to represent digraphs. By establishing an algebraic relationship between a complex-valued Hermitian representation and an associated real-valued, skew-symmetric matrix the proposed algorithm produces clusterings while remaining completely in the real field. Our algorithm uses less memory and asymptotically less computation while provably preserving solution quality. We also show the algorithm can be easily implemented using standard computational building blocks, possesses better numerical properties, and loans itself to a natural interpretation via an objective function relaxation argument. ",
    "url": "https://arxiv.org/abs/2203.01388",
    "authors": [
      "Koby Hayashi",
      "Sinan G. Aksoy",
      "Haesun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01391",
    "title": "iMVS: Improving MVS Networks by Learning Depth Discontinuities",
    "abstract": "Existing learning-based multi-view stereo (MVS) techniques are effective in terms of completeness in reconstruction. We further improve these techniques by learning depth continuities. Our idea is to jointly estimate the depth and boundary maps. To this end, we introduce learning-based MVS strategies to improve the quality of depth maps via mixture density and depth discontinuity learning. We validate our idea and demonstrate that our strategies can be easily integrated into existing learning-based MVS pipelines where the reconstruction depends on high-quality depth map estimation. We also introduce a bimodal depth representation and a novel spatial regularization approach to the MVS networks. Extensive experiments on various datasets show that our method sets a new state of the art in terms of completeness and overall reconstruction quality. Experiments also demonstrate that the presented model and strategies have good generalization capabilities. The source code will be available soon. ",
    "url": "https://arxiv.org/abs/2203.01391",
    "authors": [
      "Nail Ibrahimli",
      "Hugo Ledoux",
      "Julian Kooij",
      "Liangliang Nan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01394",
    "title": "Detecting Chronic Kidney Disease(CKD) at the Initial Stage: A Novel  Hybrid Feature-selection Method and Robust Data Preparation Pipeline for  Different ML Techniques",
    "abstract": "Chronic Kidney Disease (CKD) has infected almost 800 million people around the world. Around 1.7 million people die each year because of it. Detecting CKD in the initial stage is essential for saving millions of lives. Many researchers have applied distinct Machine Learning (ML) methods to detect CKD at an early stage, but detailed studies are still missing. We present a structured and thorough method for dealing with the complexities of medical data with optimal performance. Besides, this study will assist researchers in producing clear ideas on the medical data preparation pipeline. In this paper, we applied KNN Imputation to impute missing values, Local Outlier Factor to remove outliers, SMOTE to handle data imbalance, K-stratified K-fold Cross-validation to validate the ML models, and a novel hybrid feature selection method to remove redundant features. Applied algorithms in this study are Support Vector Machine, Gaussian Naive Bayes, Decision Tree, Random Forest, Logistic Regression, K-Nearest Neighbor, Gradient Boosting, Adaptive Boosting, and Extreme Gradient Boosting. Finally, the Random Forest can detect CKD with 100% accuracy without any data leakage. ",
    "url": "https://arxiv.org/abs/2203.01394",
    "authors": [
      "Md. Taufiqul Haque Khan Tusar",
      "Md. Touhidul Islam",
      "Foyjul Islam Raju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01404",
    "title": "Self-Supervised Online Learning for Safety-Critical Control using Stereo  Vision",
    "abstract": "With the increasing prevalence of complex vision-based sensing methods for use in obstacle identification and state estimation, characterizing environment-dependent measurement errors has become a difficult and essential part of modern robotics. This paper presents a self-supervised learning approach to safety-critical control. In particular, the uncertainty associated with stereo vision is estimated, and adapted online to new visual environments, wherein this estimate is leveraged in a safety-critical controller in a robust fashion. To this end, we propose an algorithm that exploits the structure of stereo-vision to learn an uncertainty estimate without the need for ground-truth data. We then robustify existing Control Barrier Function-based controllers to provide safety in the presence of this uncertainty estimate. We demonstrate the efficacy of our method on a quadrupedal robot in a variety of environments. When not using our method safety is violated. With offline training alone we observe the robot is safe, but overly-conservative. With our online method the quadruped remains safe and conservatism is reduced. ",
    "url": "https://arxiv.org/abs/2203.01404",
    "authors": [
      "Ryan K. Cosner",
      "Ivan D. Jimenez Rodriguez",
      "Tamas G. Molnar",
      "Wyatt Ubellacker",
      "Yisong Yue",
      "Aaron D. Ames",
      "Katherine L. Bouman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01414",
    "title": "ICARUS: A Lightweight Neural Plenoptic Rendering Architecture",
    "abstract": "The practical deployment of Neural Radiance Field (NeRF) in rendering applications faces several challenges, with the most critical one being low rendering speed on even high-end graphic processing units (GPUs). In this paper, we present ICARUS, a novel lightweight graphics architecture tailored for NeRF rendering. Unlike GPUs using general purpose computing and memory architectures for NeRF, ICARUS executes the complete NeRF pipeline using dedicated plenoptic cores (PLCore) consisting of a positional encoding unit (PEU), a multi-layer perceptron (MLP) engine, and a volume rendering unit (VRU). A PLCore takes in positions \\& directions and renders the corresponding pixel colors without any intermediate data going off-chip for temporary storage and exchange, which can be time and power consuming. To implement the most expensive component of NeRF, i.e., the MLP, we transform the fully connected operations to approximated reconfigurable multiple constant multiplications (MCMs), where common subexpressions are shared across different multiplications to improve the computation efficiency. We build a prototype ICARUS using Synopsys HAPS-80 S104, an FPGA-based prototyping system for large-scale integrated circuits and systems. We evaluate the area and power consumption of a PLCore using 40nm LP CMOS process. Working at 300 MHz, a single PLCore occupies 7.59 $mm^2$ and consumes 309.8 mW, translating to 0.174 uJ/sample. Evaluation results show that for NeRF rendering, the energy efficiency of ICARUS is 146 times higher than GPUs. By scaling to a multi-core system, the energy-efficient ICARUS can be deployed in practical edge applications for NeRF-based rendering tasks. ",
    "url": "https://arxiv.org/abs/2203.01414",
    "authors": [
      "Chaolin Rao",
      "Huangjie Yu",
      "Haochuan Wan",
      "Jindong Zhou",
      "Yueyang Zheng",
      "Yu Ma",
      "Anpei Chen",
      "Minye Wu",
      "Binzhe Yuan",
      "Pingqiang Zhou",
      "Xin Lou",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2203.01416",
    "title": "A Fully Memristive Spiking Neural Network with Unsupervised Learning",
    "abstract": "We present a fully memristive spiking neural network (MSNN) consisting of physically-realizable memristive neurons and memristive synapses to implement an unsupervised Spiking Time Dependent Plasticity (STDP) learning rule. The system is fully memristive in that both neuronal and synaptic dynamics can be realized by using memristors. The neuron is implemented using the SPICE-level memristive integrate-and-fire (MIF) model, which consists of a minimal number of circuit elements necessary to achieve distinct depolarization, hyperpolarization, and repolarization voltage waveforms. The proposed MSNN uniquely implements STDP learning by using cumulative weight changes in memristive synapses from the voltage waveform changes across the synapses, which arise from the presynaptic and postsynaptic spiking voltage signals during the training process. Two types of MSNN architectures are investigated: 1) a biologically plausible memory retrieval system, and 2) a multi-class classification system. Our circuit simulation results verify the MSNN's unsupervised learning efficacy by replicating biological memory retrieval mechanisms, and achieving 97.5% accuracy in a 4-pattern recognition problem in a large scale discriminative MSNN. ",
    "url": "https://arxiv.org/abs/2203.01416",
    "authors": [
      "Peng Zhou",
      "Dong-Uk Choi",
      "Jason K. Eshraghian",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2203.01426",
    "title": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "abstract": "We present a fully memristive spiking neural network (MSNN) consisting of novel memristive neurons trained using the backpropagation through time (BPTT) learning rule. Gradient descent is applied directly to the memristive integrated-and-fire (MIF) neuron designed using analog SPICE circuit models, which generates distinct depolarization, hyperpolarization, and repolarization voltage waveforms. Synaptic weights are trained by BPTT using the membrane potential of the MIF neuron model and can be processed on memristive crossbars. The natural spiking dynamics of the MIF neuron model and fully differentiable, eliminating the need for gradient approximations that are prevalent in the spiking neural network literature. Despite the added complexity of training directly on SPICE circuit models, we achieve 97.58% accuracy on the MNIST testing dataset and 75.26% on the Fashion-MNIST testing dataset, the highest accuracies among all fully MSNNs. ",
    "url": "https://arxiv.org/abs/2203.01426",
    "authors": [
      "Peng Zhou",
      "Jason K. Eshraghian",
      "Dong-Uk Choi",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2203.01429",
    "title": "SMTNet: Hierarchical cavitation intensity recognition based on sub-main  transfer network",
    "abstract": "With the rapid development of smart manufacturing, data-driven machinery health management has been of growing attention. In situations where some classes are more difficult to be distinguished compared to others and where classes might be organised in a hierarchy of categories, current DL methods can not work well. In this study, a novel hierarchical cavitation intensity recognition framework using Sub-Main Transfer Network, termed SMTNet, is proposed to classify acoustic signals of valve cavitation. SMTNet model outputs multiple predictions ordered from coarse to fine along a network corresponding to a hierarchy of target cavitation states. Firstly, a data augmentation method based on Sliding Window with Fast Fourier Transform (Swin-FFT) is developed to solve few-shot problem. Secondly, a 1-D double hierarchical residual block (1-D DHRB) is presented to capture sensitive features of the frequency domain valve acoustic signals. Thirdly, hierarchical multi-label tree is proposed to assist the embedding of the semantic structure of target cavitation states into SMTNet. Fourthly, experience filtering mechanism is proposed to fully learn a prior knowledge of cavitation detection model. Finally, SMTNet has been evaluated on two cavitation datasets without noise (Dataset 1 and Dataset 2), and one cavitation dataset with real noise (Dataset 3) provided by SAMSON AG (Frankfurt). The prediction accurcies of SMTNet for cavitation intensity recognition are as high as 95.32%, 97.16% and 100%, respectively. At the same time, the testing accuracies of SMTNet for cavitation detection are as high as 97.02%, 97.64% and 100%. In addition, SMTNet has also been tested for different frequencies of samples and has achieved excellent results of the highest frequency of samples of mobile phones. ",
    "url": "https://arxiv.org/abs/2203.01429",
    "authors": [
      "Yu Sha",
      "Johannes Faber",
      "Shuiping Gou",
      "Bo Liu",
      "Wei Li",
      "Stefan Schramm",
      "Horst Stoecker",
      "Thomas Steckenreiter",
      "Domagoj Vnucec",
      "Nadine Wetzstein",
      "Andreas Widl",
      "Kai Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01439",
    "title": "Enhancing Adversarial Robustness for Deep Metric Learning",
    "abstract": "Owing to security implications of adversarial vulnerability, adversarial robustness of deep metric learning models has to be improved. In order to avoid model collapse due to excessively hard examples, the existing defenses dismiss the min-max adversarial training, but instead learn from a weak adversary inefficiently. Conversely, we propose Hardness Manipulation to efficiently perturb the training triplet till a specified level of hardness for adversarial training, according to a harder benign triplet or a pseudo-hardness function. It is flexible since regular training and min-max adversarial training are its boundary cases. Besides, Gradual Adversary, a family of pseudo-hardness functions is proposed to gradually increase the specified hardness level during training for a better balance between performance and robustness. Additionally, an Intra-Class Structure loss term among benign and adversarial examples further improves model robustness and efficiency. Comprehensive experimental results suggest that the proposed method, although simple in its form, overwhelmingly outperforms the state-of-the-art defenses in terms of robustness, training efficiency, as well as performance on benign examples. ",
    "url": "https://arxiv.org/abs/2203.01439",
    "authors": [
      "Mo Zhou",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01440",
    "title": "Near-Optimal Correlation Clustering with Privacy",
    "abstract": "Correlation clustering is a central problem in unsupervised learning, with applications spanning community detection, duplicate detection, automated labelling and many more. In the correlation clustering problem one receives as input a set of nodes and for each node a list of co-clustering preferences, and the goal is to output a clustering that minimizes the disagreement with the specified nodes' preferences. In this paper, we introduce a simple and computationally efficient algorithm for the correlation clustering problem with provable privacy guarantees. Our approximation guarantees are stronger than those shown in prior work and are optimal up to logarithmic factors. ",
    "url": "https://arxiv.org/abs/2203.01440",
    "authors": [
      "Vincent Cohen-Addad",
      "Chenglin Fan",
      "Silvio Lattanzi",
      "Slobodan Mitrovi\u0107",
      "Ashkan Norouzi-Fard",
      "Nikos Parotsidis",
      "Jakub Tarnawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.01441",
    "title": "3D Common Corruptions and Data Augmentation",
    "abstract": "We introduce a set of image transformations that can be used as `corruptions' to evaluate the robustness of models as well as `data augmentation' mechanisms for training neural networks. The primary distinction of the proposed transformations is that, unlike existing approaches such as Common Corruptions, the geometry of the scene is incorporated in the transformations -- thus leading to corruptions that are more likely to occur in the real world. We show these transformations are `efficient' (can be computed on-the-fly), `extendable' (can be applied on most datasets of real images), expose vulnerability of existing models, and can effectively make models more robust when employed as `3D data augmentation' mechanisms. Our evaluations performed on several tasks and datasets suggest incorporating 3D information into robustness benchmarking and training opens up a promising direction for robustness research. ",
    "url": "https://arxiv.org/abs/2203.01441",
    "authors": [
      "O\u011fuzhan Fatih Kar",
      "Teresa Yeo",
      "Andrei Atanov",
      "Amir Zamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01442",
    "title": "Deformable Radar Polygon: A Lightweight and Predictable Occupancy  Representation for Short-range Collision Avoidance",
    "abstract": "Inferring the drivable area in a scene is a key capability for ensuring vehicle avoids obstacles and enabling safe autonomous driving. However, traditional occupancy grid map suffers from high memory consumption when forming a fine-resolution grid for a large map. In this paper, we propose a lightweight, accurate, and predictable occupancy representation for automotive radars working for short-range applications that take interest in instantaneous free space surrounding the sensor. This new occupancy format is a polygon composed of a bunch of vertexes selected from radar measurements, which covers free space inside and gives a Doppler moving velocity for each vertex. It not only takes a very small memory for storage and update at every timeslot, but also has the predictable shape-change property based on vertex Doppler velocity. We name this kind of occupancy representation `deformable radar polygon'. Two formation algorithms for radar polygon are introduced for both single timeslot and continuous ISM update. To fit this new polygon representation, a matrix-form collision detection method have been modeled as well. The radar polygon algorithms and collision detection model have been validated via extensive experiments with real collected data and simulations, showing that the deformable radar polygon is very competitive in terms of its completeness, smoothness, accuracy, lightweight as well as shape-predictable property. Our codes will be made publicly available for ease of future works. ",
    "url": "https://arxiv.org/abs/2203.01442",
    "authors": [
      "Gao Xiangyu",
      "Ding Sihao",
      "Vanas Karl",
      "Dasari Harshavardhan Reddy",
      "Soderlund Henrik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.01445",
    "title": "LILE: Look In-Depth before Looking Elsewhere -- A Dual Attention Network  using Transformers for Cross-Modal Information Retrieval in Histopathology  Archives",
    "abstract": "The volume of available data has grown dramatically in recent years in many applications. Furthermore, the age of networks that used multiple modalities separately has practically ended. Therefore, enabling bidirectional cross-modality data retrieval capable of processing has become a requirement for many domains and disciplines of research. This is especially true in the medical field, as data comes in a multitude of types, including various types of images and reports as well as molecular data. Most contemporary works apply cross attention to highlight the essential elements of an image or text in relation to the other modalities and try to match them together. However, regardless of their importance in their own modality, these approaches usually consider features of each modality equally. In this study, self-attention as an additional loss term will be proposed to enrich the internal representation provided into the cross attention module. This work suggests a novel architecture with a new loss term to help represent images and texts in the joint latent space. Experiment results on two benchmark datasets, i.e. MS-COCO and ARCH, show the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2203.01445",
    "authors": [
      "Danial Maleki",
      "H.R Tizhoosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01446",
    "title": "RoLoMa: Robust Loco-Manipulation for Quadruped Robots with Arms",
    "abstract": "Deployment of robotic systems in the real world requires a certain level of robustness in order to deal with uncertainty factors, such as mismatches in the dynamics model, noise in sensor readings, and communication delays. Some approaches tackle these issues reactively at the control stage. However, regardless of the controller, online motion execution can only be as robust as the system capabilities allow at any given state. This is why it is important to have good motion plans to begin with, where robustness is considered proactively. To this end, we propose a metric (derived from first principles) for representing robustness against external disturbances. We then use this metric within our trajectory optimization framework for solving complex loco-manipulation tasks. Through our experiments, we show that trajectories generated using our approach can resist a greater range of forces originating from any possible direction. By using our method, we can compute trajectories that solve tasks as effectively as before, with the added benefit of being able to counteract stronger disturbances in worst-case scenarios. ",
    "url": "https://arxiv.org/abs/2203.01446",
    "authors": [
      "Henrique Ferrolho",
      "Vladimir Ivan",
      "Wolfgang Merkt",
      "Ioannis Havoutis",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01451",
    "title": "Label Leakage and Protection from Forward Embedding in Vertical  Federated Learning",
    "abstract": "Vertical federated learning (vFL) has gained much attention and been deployed to solve machine learning problems with data privacy concerns in recent years. However, some recent work demonstrated that vFL is vulnerable to privacy leakage even though only the forward intermediate embedding (rather than raw features) and backpropagated gradients (rather than raw labels) are communicated between the involved participants. As the raw labels often contain highly sensitive information, some recent work has been proposed to prevent the label leakage from the backpropagated gradients effectively in vFL. However, these work only identified and defended the threat of label leakage from the backpropagated gradients. None of these work has paid attention to the problem of label leakage from the intermediate embedding. In this paper, we propose a practical label inference method which can steal private labels effectively from the shared intermediate embedding even though some existing protection methods such as label differential privacy and gradients perturbation are applied. The effectiveness of the label attack is inseparable from the correlation between the intermediate embedding and corresponding private labels. To mitigate the issue of label leakage from the forward embedding, we add an additional optimization goal at the label party to limit the label stealing ability of the adversary by minimizing the distance correlation between the intermediate embedding and corresponding private labels. We conducted massive experiments to demonstrate the effectiveness of our proposed protection methods. ",
    "url": "https://arxiv.org/abs/2203.01451",
    "authors": [
      "Jiankai Sun",
      "Xin Yang",
      "Yuanshun Yao",
      "Chong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.01474",
    "title": "Spatial-Temporal Gating-Adjacency GCN for Human Motion Prediction",
    "abstract": "Predicting future motion based on historical motion sequence is a fundamental problem in computer vision, and it has wide applications in autonomous driving and robotics. Some recent works have shown that Graph Convolutional Networks(GCN) are instrumental in modeling the relationship between different joints. However, considering the variants and diverse action types in human motion data, the cross-dependency of the spatial-temporal relationships will be difficult to depict due to the decoupled modeling strategy, which may also exacerbate the problem of insufficient generalization. Therefore, we propose the Spatial-Temporal Gating-Adjacency GCN(GAGCN) to learn the complex spatial-temporal dependencies over diverse action types. Specifically, we adopt gating networks to enhance the generalization of GCN via the trainable adaptive adjacency matrix obtained by blending the candidate spatial-temporal adjacency matrices. Moreover, GAGCN addresses the cross-dependency of space and time by balancing the weights of spatial-temporal modeling and fusing the decoupled spatial-temporal features. Extensive experiments on Human 3.6M, AMASS, and 3DPW demonstrate that GAGCN achieves state-of-the-art performance in both short-term and long-term predictions. Our code will be released in the future. ",
    "url": "https://arxiv.org/abs/2203.01474",
    "authors": [
      "Chongyang Zhong",
      "Lei Hu",
      "Zihao Zhang",
      "Yongjing Ye",
      "Shihong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01479",
    "title": "Weightless Neural Networks for Efficient Edge Inference",
    "abstract": "Weightless Neural Networks (WNNs) are a class of machine learning model which use table lookups to perform inference. This is in contrast with Deep Neural Networks (DNNs), which use multiply-accumulate operations. State-of-the-art WNN architectures have a fraction of the implementation cost of DNNs, but still lag behind them on accuracy for common image recognition tasks. Additionally, many existing WNN architectures suffer from high memory requirements. In this paper, we propose a novel WNN architecture, BTHOWeN, with key algorithmic and architectural improvements over prior work, namely counting Bloom filters, hardware-friendly hashing, and Gaussian-based nonlinear thermometer encodings to improve model accuracy and reduce area and energy consumption. BTHOWeN targets the large and growing edge computing sector by providing superior latency and energy efficiency to comparable quantized DNNs. Compared to state-of-the-art WNNs across nine classification datasets, BTHOWeN on average reduces error by more than than 40% and model size by more than 50%. We then demonstrate the viability of the BTHOWeN architecture by presenting an FPGA-based accelerator, and compare its latency and resource usage against similarly accurate quantized DNN accelerators, including Multi-Layer Perceptron (MLP) and convolutional models. The proposed BTHOWeN models consume almost 80% less energy than the MLP models, with nearly 85% reduction in latency. In our quest for efficient ML on the edge, WNNs are clearly deserving of additional attention. ",
    "url": "https://arxiv.org/abs/2203.01479",
    "authors": [
      "Zachary Susskind",
      "Aman Arora",
      "Igor Dantas Dos Santos Miranda",
      "Luis Armando Quintanilla Villon",
      "Rafael Fontella Katopodis",
      "Leandro Santiago de Araujo",
      "Diego Leonel Cadette Dutra",
      "Priscila Machado Vieira Lima",
      "Felipe Maia Galvao Franca",
      "Mauricio Breternitz Jr.",
      "Lizy K. John"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01480",
    "title": "Modularity of the ABCD Random Graph Model with Community Structure",
    "abstract": "The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs with similar properties as the well-known LFR one, and its main parameter $\\xi$ can be tuned to mimic its counterpart in the LFR model, the mixing parameter $\\mu$. In this paper, we investigate various theoretical asymptotic properties of the ABCD model. In particular, we analyze the modularity function, arguably, the most important graph property of networks in the context of community detection. Indeed, the modularity function is often used to measure the presence of community structure in networks. It is also used as a quality function in many community detection algorithms, including the widely used Louvain algorithm. ",
    "url": "https://arxiv.org/abs/2203.01480",
    "authors": [
      "Bogumil Kaminski",
      "Bartosz Pankratz",
      "Pawel Pralat",
      "Francois Theberge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2203.01502",
    "title": "NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth  Estimation",
    "abstract": "Estimating the accurate depth from a single image is challenging since it is inherently ambiguous and ill-posed. While recent works design increasingly complicated and powerful networks to directly regress the depth map, we take the path of CRFs optimization. Due to the expensive computation, CRFs are usually performed between neighborhoods rather than the whole graph. To leverage the potential of fully-connected CRFs, we split the input into windows and perform the FC-CRFs optimization within each window, which reduces the computation complexity and makes FC-CRFs feasible. To better capture the relationships between nodes in the graph, we exploit the multi-head attention mechanism to compute a multi-head potential function, which is fed to the networks to output an optimized depth map. Then we build a bottom-up-top-down structure, where this neural window FC-CRFs module serves as the decoder, and a vision transformer serves as the encoder. The experiments demonstrate that our method significantly improves the performance across all metrics on both the KITTI and NYUv2 datasets, compared to previous methods. Furthermore, the proposed method can be directly applied to panorama images and outperforms all previous panorama methods on the MatterPort3D dataset. The source code of our method will be made public. ",
    "url": "https://arxiv.org/abs/2203.01502",
    "authors": [
      "Weihao Yuan",
      "Xiaodong Gu",
      "Zuozhuo Dai",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01514",
    "title": "Physics-informed neural network solution of thermo-hydro-mechanical  (THM) processes in porous media",
    "abstract": "Physics-Informed Neural Networks (PINNs) have received increased interest for forward, inverse, and surrogate modeling of problems described by partial differential equations (PDE). However, their application to multiphysics problem, governed by several coupled PDEs, present unique challenges that have hindered the robustness and widespread applicability of this approach. Here we investigate the application of PINNs to the forward solution of problems involving thermo-hydro-mechanical (THM) processes in porous media, which exhibit disparate spatial and temporal scales in thermal conductivity, hydraulic permeability, and elasticity. In addition, PINNs are faced with the challenges of the multi-objective and non-convex nature of the optimization problem. To address these fundamental issues, we: (1)~rewrite the THM governing equations in dimensionless form that is best suited for deep-learning algorithms; (2)~propose a sequential training strategy that circumvents the need for a simultaneous solution of the multiphysics problem and facilitates the task of optimizers in the solution search; and (3)~leverage adaptive weight strategies to overcome the stiffness in the gradient flow of the multi-objective optimization problem. Finally, we apply this framework to the solution of several synthetic problems in 1D and~2D. ",
    "url": "https://arxiv.org/abs/2203.01514",
    "authors": [
      "Danial Amini",
      "Ehsan Haghighat",
      "Ruben Juanes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2203.01515",
    "title": "Code Synonyms Do Matter: Multiple Synonyms Matching Network for  Automatic ICD Coding",
    "abstract": "Automatic ICD coding is defined as assigning disease codes to electronic medical records (EMRs). Existing methods usually apply label attention with code representations to match related text snippets. Unlike these works that model the label with the code hierarchy or description, we argue that the code synonyms can provide more comprehensive knowledge based on the observation that the code expressions in EMRs vary from their descriptions in ICD. By aligning codes to concepts in UMLS, we collect synonyms of every code. Then, we propose a multiple synonyms matching network to leverage synonyms for better code representation learning, and finally help the code classification. Experiments on the MIMIC-III dataset show that our proposed method outperforms previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.01515",
    "authors": [
      "Zheng Yuan",
      "Chuanqi Tan",
      "Songfang Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.01516",
    "title": "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking",
    "abstract": "Visual tracking is adopted to extensive unmanned aerial vehicle (UAV)-related applications, which leads to a highly demanding requirement on the robustness of UAV trackers. However, adding imperceptible perturbations can easily fool the tracker and cause tracking failures. This risk is often overlooked and rarely researched at present. Therefore, to help increase awareness of the potential risk and the robustness of UAV tracking, this work proposes a novel adaptive adversarial attack approach, i.e., Ad$^2$Attack, against UAV object tracking. Specifically, adversarial examples are generated online during the resampling of the search patch image, which leads trackers to lose the target in the following frames. Ad$^2$Attack is composed of a direct downsampling module and a super-resolution upsampling module with adaptive stages. A novel optimization function is proposed for balancing the imperceptibility and efficiency of the attack. Comprehensive experiments on several well-known benchmarks and real-world conditions show the effectiveness of our attack method, which dramatically reduces the performance of the most advanced Siamese trackers. ",
    "url": "https://arxiv.org/abs/2203.01516",
    "authors": [
      "Changhong Fu",
      "Sihang Li",
      "Xinnan Yuan",
      "Junjie Ye",
      "Ziang Cao",
      "Fangqiang Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01517",
    "title": "Correct-N-Contrast: A Contrastive Approach for Improving Robustness to  Spurious Correlations",
    "abstract": "Spurious correlations pose a major challenge for robust machine learning. Models trained with empirical risk minimization (ERM) may learn to rely on correlations between class labels and spurious attributes, leading to poor performance on data groups without these correlations. This is particularly challenging to address when spurious attribute labels are unavailable. To improve worst-group performance on spuriously correlated data without training attribute labels, we propose Correct-N-Contrast (CNC), a contrastive approach to directly learn representations robust to spurious correlations. As ERM models can be good spurious attribute predictors, CNC works by (1) using a trained ERM model's outputs to identify samples with the same class but dissimilar spurious features, and (2) training a robust model with contrastive learning to learn similar representations for same-class samples. To support CNC, we introduce new connections between worst-group error and a representation alignment loss that CNC aims to minimize. We empirically observe that worst-group error closely tracks with alignment loss, and prove that the alignment loss over a class helps upper-bound the class's worst-group vs. average error gap. On popular benchmarks, CNC reduces alignment loss drastically, and achieves state-of-the-art worst-group accuracy by 3.6% average absolute lift. CNC is also competitive with oracle methods that require group labels. ",
    "url": "https://arxiv.org/abs/2203.01517",
    "authors": [
      "Michael Zhang",
      "Nimit S. Sohoni",
      "Hongyang R. Zhang",
      "Chelsea Finn",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01520",
    "title": "An Open Challenge for Inductive Link Prediction on Knowledge Graphs",
    "abstract": "An emerging trend in representation learning over knowledge graphs (KGs) moves beyond transductive link prediction tasks over a fixed set of known entities in favor of inductive tasks that imply training on one graph and performing inference over a new graph with unseen entities. In inductive setups, node features are often not available and training shallow entity embedding matrices is meaningless as they cannot be used at inference time with unseen entities. Despite the growing interest, there are not enough benchmarks for evaluating inductive representation learning methods. In this work, we introduce ILPC 2022, a novel open challenge on KG inductive link prediction. To this end, we constructed two new datasets based on Wikidata with various sizes of training and inference graphs that are much larger than existing inductive benchmarks. We also provide two strong baselines leveraging recently proposed inductive methods. We hope this challenge helps to streamline community efforts in the inductive graph representation learning area. ILPC 2022 follows best practices on evaluation fairness and reproducibility, and is available at https://github.com/pykeen/ilpc2022. ",
    "url": "https://arxiv.org/abs/2203.01520",
    "authors": [
      "Mikhail Galkin",
      "Max Berrendorf",
      "Charles Tapley Hoyt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01522",
    "title": "BatchFormer: Learning to Explore Sample Relationships for Robust  Representation Learning",
    "abstract": "Despite the success of deep neural networks, there are still many challenges in deep representation learning due to the data scarcity issues such as data imbalance, unseen distribution, and domain shift. To address the above-mentioned issues, a variety of methods have been devised to explore the sample relationships in a vanilla way (i.e., from the perspectives of either the input or the loss function), failing to explore the internal structure of deep neural networks for learning with sample relationships. Inspired by this, we propose to enable deep neural networks themselves with the ability to learn the sample relationships from each mini-batch. Specifically, we introduce a batch transformer module or BatchFormer, which is then applied into the batch dimension of each mini-batch to implicitly explore sample relationships during training. By doing this, the proposed method enables the collaboration of different samples, e.g., the head-class samples can also contribute to the learning of the tail classes for long-tailed recognition. Furthermore, to mitigate the gap between training and testing, we share the classifier between with or without the BatchFormer during training, which can thus be removed during testing. We perform extensive experiments on over ten datasets and the proposed method achieves significant improvements on different data scarcity applications without any bells and whistles, including the tasks of long-tailed recognition, compositional zero-shot learning, domain generalization, and contrastive learning. Code will be made publicly available at \\url{https://github.com/zhihou7/BatchFormer} ",
    "url": "https://arxiv.org/abs/2203.01522",
    "authors": [
      "Zhi Hou",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01524",
    "title": "Semi-supervised Learning using Robust Loss",
    "abstract": "The amount of manually labeled data is limited in medical applications, so semi-supervised learning and automatic labeling strategies can be an asset for training deep neural networks. However, the quality of the automatically generated labels can be uneven and inferior to manual labels. In this paper, we suggest a semi-supervised training strategy for leveraging both manually labeled data and extra unlabeled data. In contrast to the existing approaches, we apply robust loss for the automated labeled data to automatically compensate for the uneven data quality using a teacher-student framework. First, we generate pseudo-labels for unlabeled data using a teacher model pre-trained on labeled data. These pseudo-labels are noisy, and using them along with labeled data for training a deep neural network can severely degrade learned feature representations and the generalization of the network. Here we mitigate the effect of these pseudo-labels by using robust loss functions. Specifically, we use three robust loss functions, namely beta cross-entropy, symmetric cross-entropy, and generalized cross-entropy. We show that our proposed strategy improves the model performance by compensating for the uneven quality of labels in image classification as well as segmentation applications. ",
    "url": "https://arxiv.org/abs/2203.01524",
    "authors": [
      "Wenhui Cui",
      "Haleh Akrami",
      "Anand A. Joshi",
      "Richard M. Leahy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01528",
    "title": "Towards Smart Networking with SDN Enabled IPv6 Network",
    "abstract": "This paper presents the features and benefits of legacy IPv4 network migration towards major two latest networking paradigms viz. Internet protocol version 6 (IPv6) and the software-defined networking (SDN). These latest networking paradigms are the enabler of future generation networking so that the standards and requirements of fifth generation (5G) wireless networking can be achieved. Features and migration approaches of IPv6 and SDN will be separately discussed, then a joint migration approach of SDN and IPv6 network termed as SoDIP6 network migration will be presented, and the integration of SoDIP6 network as a backbone of 5G network will be introduced. ",
    "url": "https://arxiv.org/abs/2203.01528",
    "authors": [
      "Babu R. Dawadi",
      "Danda B. Rawat",
      "Shashidhar R. Joshi",
      "Pietro Manzoni"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.01538",
    "title": "Self-supervised Transparent Liquid Segmentation for Robotic Pouring",
    "abstract": "Liquid state estimation is important for robotics tasks such as pouring; however, estimating the state of transparent liquids is a challenging problem. We propose a novel segmentation pipeline that can segment transparent liquids such as water from a static, RGB image without requiring any manual annotations or heating of the liquid for training. Instead, we use a generative model that is capable of translating images of colored liquids into synthetically generated transparent liquid images, trained only on an unpaired dataset of colored and transparent liquid images. Segmentation labels of colored liquids are obtained automatically using background subtraction. Our experiments show that we are able to accurately predict a segmentation mask for transparent liquids without requiring any manual annotations. We demonstrate the utility of transparent liquid segmentation in a robotic pouring task that controls pouring by perceiving the liquid height in a transparent cup. Accompanying video and supplementary materials can be found ",
    "url": "https://arxiv.org/abs/2203.01538",
    "authors": [
      "Gautham Narayan Narasimhan",
      "Kai Zhang",
      "Ben Eisner",
      "Xingyu Lin",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01542",
    "title": "SegTAD: Precise Temporal Action Detection via Semantic Segmentation",
    "abstract": "Temporal action detection (TAD) is an important yet challenging task in video analysis. Most existing works draw inspiration from image object detection and tend to reformulate it as a proposal generation - classification problem. However, there are two caveats with this paradigm. First, proposals are not equipped with annotated labels, which have to be empirically compiled, thus the information in the annotations is not necessarily precisely employed in the model training process. Second, there are large variations in the temporal scale of actions, and neglecting this fact may lead to deficient representation in the video features. To address these issues and precisely model temporal action detection, we formulate the task of temporal action detection in a novel perspective of semantic segmentation. Owing to the 1-dimensional property of TAD, we are able to convert the coarse-grained detection annotations to fine-grained semantic segmentation annotations for free. We take advantage of them to provide precise supervision so as to mitigate the impact induced by the imprecise proposal labels. We propose an end-to-end framework SegTAD composed of a 1D semantic segmentation network (1D-SSN) and a proposal detection network (PDN). ",
    "url": "https://arxiv.org/abs/2203.01542",
    "authors": [
      "Chen Zhao",
      "Merey Ramazanova",
      "Mengmeng Xu",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01544",
    "title": "Rethinking the role of normalization and residual blocks for spiking  neural networks",
    "abstract": "Biologically inspired spiking neural networks (SNNs) are widely used to realize ultralow-power energy consumption. However, deep SNNs are not easy to train due to the excessive firing of spiking neurons in the hidden layers. To tackle this problem, we propose a novel but simple normalization technique called postsynaptic potential normalization. This normalization removes the subtraction term from the standard normalization and uses the second raw moment instead of the variance as the division term. The spike firing can be controlled, enabling the training to proceed appropriating, by conducting this simple normalization to the postsynaptic potential. The experimental results show that SNNs with our normalization outperformed other models using other normalizations. Furthermore, through the pre-activation residual blocks, the proposed model can train with more than 100 layers without other special techniques dedicated to SNNs. ",
    "url": "https://arxiv.org/abs/2203.01544",
    "authors": [
      "Shin-ichi Ikegawa",
      "Ryuji Saiin",
      "Yoshihide Sawada",
      "Naotake Natori"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01547",
    "title": "The RATTLE Motion Planning Algorithm for Robust Online Parametric Model  Improvement with On-Orbit Validation",
    "abstract": "Certain forms of uncertainty that robotic systems encounter can be explicitly learned within the context of a known model, like parametric model uncertainties such as mass and moments of inertia. Quantifying such parametric uncertainty is important for more accurate prediction of the system behavior, leading to safe and precise task execution. In tandem, providing a form of robustness guarantee against prevailing uncertainty levels like environmental disturbances and current model knowledge is also desirable. To that end, the authors' previously proposed RATTLE algorithm, a framework for online information-aware motion planning, is outlined and extended to enhance its applicability to real robotic systems. RATTLE provides a clear tradeoff between information-seeking motion and traditional goal-achieving motion and features online-updateable models. Additionally, online-updateable low level control robustness guarantees and a new method for automatic adjustment of information content down to a specified estimation precision is proposed. Results of extensive experimentation in microgravity using the Astrobee robots aboard the International Space Station and practical implementation details are presented, demonstrating RATTLE's capabilities for real-time, robust, online-updateable, and model information-seeking motion planning capabilities under parametric uncertainty. ",
    "url": "https://arxiv.org/abs/2203.01547",
    "authors": [
      "Keenan Albee",
      "Monica Ekal",
      "Brian Coltin",
      "Rodrigo Ventura",
      "Richard Linares",
      "David W. Miller"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01557",
    "title": "Self-Supervised Ego-Motion Estimation Based on Multi-Layer Fusion of RGB  and Inferred Depth",
    "abstract": "In existing self-supervised depth and ego-motion estimation methods, ego-motion estimation is usually limited to only leveraging RGB information. Recently, several methods have been proposed to further improve the accuracy of self-supervised ego-motion estimation by fusing information from other modalities, e.g., depth, acceleration, and angular velocity. However, they rarely focus on how different fusion strategies affect performance. In this paper, we investigate the effect of different fusion strategies for ego-motion estimation and propose a new framework for self-supervised learning of depth and ego-motion estimation, which performs ego-motion estimation by leveraging RGB and inferred depth information in a Multi-Layer Fusion manner. As a result, we have achieved state-of-the-art performance among learning-based methods on the KITTI odometry benchmark. Detailed studies on the design choices of leveraging inferred depth information and fusion strategies have also been carried out, which clearly demonstrate the advantages of our proposed framework. ",
    "url": "https://arxiv.org/abs/2203.01557",
    "authors": [
      "Zijie Jiang",
      "Hajime Taira",
      "Naoyuki Miyashita",
      "Masatoshi Okutomi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01559",
    "title": "Neural Architecture Search using Progressive Evolution",
    "abstract": "Vanilla neural architecture search using evolutionary algorithms (EA) involves evaluating each architecture by training it from scratch, which is extremely time-consuming. This can be reduced by using a supernet to estimate the fitness of every architecture in the search space due to its weight sharing nature. However, the estimated fitness is very noisy due to the co-adaptation of the operations in the supernet. In this work, we propose a method called pEvoNAS wherein the whole neural architecture search space is progressively reduced to smaller search space regions with good architectures. This is achieved by using a trained supernet for architecture evaluation during the architecture search using genetic algorithm to find search space regions with good architectures. Upon reaching the final reduced search space, the supernet is then used to search for the best architecture in that search space using evolution. The search is also enhanced by using weight inheritance wherein the supernet for the smaller search space inherits its weights from previous trained supernet for the bigger search space. Exerimentally, pEvoNAS gives better results on CIFAR-10 and CIFAR-100 while using significantly less computational resources as compared to previous EA-based methods. The code for our paper can be found in https://github.com/nightstorm0909/pEvoNAS ",
    "url": "https://arxiv.org/abs/2203.01559",
    "authors": [
      "Nilotpal Sinha",
      "Kuan-Wen Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.01562",
    "title": "ViTransPAD: Video Transformer using convolution and self-attention for  Face Presentation Attack Detection",
    "abstract": "Face Presentation Attack Detection (PAD) is an important measure to prevent spoof attacks for face biometric systems. Many works based on Convolution Neural Networks (CNNs) for face PAD formulate the problem as an image-level binary classification task without considering the context. Alternatively, Vision Transformers (ViT) using self-attention to attend the context of an image become the mainstreams in face PAD. Inspired by ViT, we propose a Video-based Transformer for face PAD (ViTransPAD) with short/long-range spatio-temporal attention which can not only focus on local details with short attention within a frame but also capture long-range dependencies over frames. Instead of using coarse image patches with single-scale as in ViT, we propose the Multi-scale Multi-Head Self-Attention (MsMHSA) architecture to accommodate multi-scale patch partitions of Q, K, V feature maps to the heads of transformer in a coarse-to-fine manner, which enables to learn a fine-grained representation to perform pixel-level discrimination for face PAD. Due to lack inductive biases of convolutions in pure transformers, we also introduce convolutions to the proposed ViTransPAD to integrate the desirable properties of CNNs by using convolution patch embedding and convolution projection. The extensive experiments show the effectiveness of our proposed ViTransPAD with a preferable accuracy-computation balance, which can serve as a new backbone for face PAD. ",
    "url": "https://arxiv.org/abs/2203.01562",
    "authors": [
      "Zuheng Ming",
      "Zitong Yu",
      "Musab Al-Ghadi",
      "Muriel Visani",
      "Muhammad MuzzamilLuqman",
      "Jean-Christophe Burie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01564",
    "title": "Graph Representation Learning Beyond Node and Homophily",
    "abstract": "Unsupervised graph representation learning aims to distill various graph information into a downstream task-agnostic dense vector embedding. However, existing graph representation learning approaches are designed mainly under the node homophily assumption: connected nodes tend to have similar labels and optimize performance on node-centric downstream tasks. Their design is apparently against the task-agnostic principle and generally suffers poor performance in tasks, e.g., edge classification, that demands feature signals beyond the node-view and homophily assumption. To condense different feature signals into the embeddings, this paper proposes PairE, a novel unsupervised graph embedding method using two paired nodes as the basic unit of embedding to retain the high-frequency signals between nodes to support node-related and edge-related tasks. Accordingly, a multi-self-supervised autoencoder is designed to fulfill two pretext tasks: one retains the high-frequency signal better, and another enhances the representation of commonality. Our extensive experiments on a diversity of benchmark datasets clearly show that PairE outperforms the unsupervised state-of-the-art baselines, with up to 101.1\\% relative improvement on the edge classification tasks that rely on both the high and low-frequency signals in the pair and up to 82.5\\% relative performance gain on the node classification tasks. ",
    "url": "https://arxiv.org/abs/2203.01564",
    "authors": [
      "You Li",
      "Bei Lin",
      "Binli Luo",
      "Ning Gui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.01572",
    "title": "Data Augmentation as Feature Manipulation: a story of desert cows and  grass cows",
    "abstract": "Data augmentation is a cornerstone of the machine learning pipeline, yet its theoretical underpinnings remain unclear. Is it merely a way to artificially augment the data set size? Or is it about encouraging the model to satisfy certain invariance? In this work we consider another angle, and we study the effect of data augmentation on the dynamic of the learning process. We find that data augmentation can alter the relative importance of various features, effectively making certain informative but hard to learn features more likely to be captured in the learning process. Importantly, we show that this effect is more pronounced for non-linear models, such as neural networks. Our main contribution is a detailed analysis of data augmentation on the learning dynamic for a two layer convolutional neural network in the recently proposed multi-view model by Allen-Zhu and Li [2020]. We complement this analysis with further experimental evidence that data augmentation can be viewed as a form of feature manipulation. ",
    "url": "https://arxiv.org/abs/2203.01572",
    "authors": [
      "Ruoqi Shen",
      "S\u00e9bastien Bubeck",
      "Suriya Gunasekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01579",
    "title": "A Formalisation of Algorithms for Sorting Network",
    "abstract": "This notes explains how standard algorithms that construct sorting networks have been formalised and proved correct in the Coq proof assistant using the SSReflect extension. ",
    "url": "https://arxiv.org/abs/2203.01579",
    "authors": [
      "Laurent Th\u00e9ry"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.01581",
    "title": "A shallow physics-informed neural network for solving partial  differential equations on surfaces",
    "abstract": "In this paper, we introduce a mesh-free physics-informed neural network for solving partial differential equations on surfaces. Based on the idea of embedding techniques, we write the underlying surface differential equations using conventional Cartesian differential operators. With the aid of level set function, the surface geometrical quantities, such as the normal and mean curvature of the surface, can be computed directly and used in our surface differential expressions. So instead of imposing the normal extension constraints used in literature, we take the whole Cartesian differential expressions into account in our loss function. Meanwhile, we adopt a completely shallow (one hidden layer) network so the present model is easy to implement and train. We perform a series of numerical experiments on both stationary and time-dependent partial differential equations on complicated surface geometries. The result shows that, with just a few hundred trainable parameters, our network model is able to achieve high predictive accuracy. ",
    "url": "https://arxiv.org/abs/2203.01581",
    "authors": [
      "Wei-Fan Hu",
      "Yi-Jun Shih",
      "Te-Sheng Lin",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01583",
    "title": "Towards Universal Backward-Compatible Representation Learning",
    "abstract": "Conventional model upgrades for visual search systems require offline refresh of gallery features by feeding gallery images into new models (dubbed as \"backfill\"), which is time-consuming and expensive, especially in large-scale applications. The task of backward-compatible representation learning is therefore introduced to support backfill-free model upgrades, where the new query features are interoperable with the old gallery features. Despite the success, previous works only investigated a close-set training scenario (i.e., the new training set shares the same classes as the old one), and are limited by more realistic and challenging open-set scenarios. To this end, we first introduce a new problem of universal backward-compatible representation learning, covering all possible data split in model upgrades. We further propose a simple yet effective method, dubbed as Universal Backward-Compatible Training (UniBCT) with a novel structural prototype refinement algorithm, to learn compatible representations in all kinds of model upgrading benchmarks in a unified manner. Comprehensive experiments on the large-scale face recognition datasets MS1Mv3 and IJB-C fully demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2203.01583",
    "authors": [
      "Binjie Zhang",
      "Yixiao Ge",
      "Yantao Shen",
      "Shupeng Su",
      "Chun Yuan",
      "Xuyuan Xu",
      "Yexin Wang",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01584",
    "title": "Fairness-aware Adversarial Perturbation Towards Bias Mitigation for  Deployed Deep Models",
    "abstract": "Prioritizing fairness is of central importance in artificial intelligence (AI) systems, especially for those societal applications, e.g., hiring systems should recommend applicants equally from different demographic groups, and risk assessment systems must eliminate racism in criminal justice. Existing efforts towards the ethical development of AI systems have leveraged data science to mitigate biases in the training set or introduced fairness principles into the training process. For a deployed AI system, however, it may not allow for retraining or tuning in practice. By contrast, we propose a more flexible approach, i.e., fairness-aware adversarial perturbation (FAAP), which learns to perturb input data to blind deployed models on fairness-related features, e.g., gender and ethnicity. The key advantage is that FAAP does not modify deployed models in terms of parameters and structures. To achieve this, we design a discriminator to distinguish fairness-related attributes based on latent representations from deployed models. Meanwhile, a perturbation generator is trained against the discriminator, such that no fairness-related features could be extracted from perturbed inputs. Exhaustive experimental evaluation demonstrates the effectiveness and superior performance of the proposed FAAP. In addition, FAAP is validated on real-world commercial deployments (inaccessible to model parameters), which shows the transferability of FAAP, foreseeing the potential of black-box adaptation. ",
    "url": "https://arxiv.org/abs/2203.01584",
    "authors": [
      "Zhibo Wang",
      "Xiaowei Dong",
      "Henry Xue",
      "Zhifei Zhang",
      "Weifeng Chiu",
      "Tao Wei",
      "Kui Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01590",
    "title": "5G Network Slice Isolation",
    "abstract": "This article reveals an adequate comprehension of basic defense, security challenges, 2 and attack vectors in deploying multi-network slicing. Network slicing is a revolutionary concept 3 of providing mobile network on-demand and expanding mobile networking business and services 4 to a new era. The new business paradigm and service opportunities are encouraging vertical 5 industries to join and develop their own mobile network capabilities for enhanced performances 6 that are coherent with their applications. However, a number of security concerns are also raised 7 in this new era. In this article, we focus on the deployment of multi-network slicing with multi8 tenancy. We identify the security concerns, and discuss about the defense approaches such as 9 network slice isolation and insulation in a multi-layer network slicing security model. Also, we 10 identify the importance to appropriately select the network slice isolation points, and propose 11 a generic framework to optimize the isolation policy regarding the implementation cost while 12 guaranteeing the security and performance requirements. ",
    "url": "https://arxiv.org/abs/2203.01590",
    "authors": [
      "Stan Wong",
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.01594",
    "title": "A Deep Neural Framework for Image Caption Generation Using GRU-Based  Attention Mechanism",
    "abstract": "Image captioning is a fast-growing research field of computer vision and natural language processing that involves creating text explanations for images. This study aims to develop a system that uses a pre-trained convolutional neural network (CNN) to extract features from an image, integrates the features with an attention mechanism, and creates captions using a recurrent neural network (RNN). To encode an image into a feature vector as graphical attributes, we employed multiple pre-trained convolutional neural networks. Following that, a language model known as GRU is chosen as the decoder to construct the descriptive sentence. In order to increase performance, we merge the Bahdanau attention model with GRU to allow learning to be focused on a specific portion of the image. On the MSCOCO dataset, the experimental results achieve competitive performance against state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2203.01594",
    "authors": [
      "Rashid Khan",
      "M Shujah Islam",
      "Khadija Kanwal",
      "Mansoor Iqbal",
      "Md. Imran Hossain",
      "Zhongfu Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01597",
    "title": "Neural Graph Matching for Pre-training Graph Neural Networks",
    "abstract": "Recently, graph neural networks (GNNs) have been shown powerful capacity at modeling structural data. However, when adapted to downstream tasks, it usually requires abundant task-specific labeled data, which can be extremely scarce in practice. A promising solution to data scarcity is to pre-train a transferable and expressive GNN model on large amounts of unlabeled graphs or coarse-grained labeled graphs. Then the pre-trained GNN is fine-tuned on downstream datasets with task-specific fine-grained labels. In this paper, we present a novel Graph Matching based GNN Pre-Training framework, called GMPT. Focusing on a pair of graphs, we propose to learn structural correspondences between them via neural graph matching, consisting of both intra-graph message passing and inter-graph message passing. In this way, we can learn adaptive representations for a given graph when paired with different graphs, and both node- and graph-level characteristics are naturally considered in a single pre-training task. The proposed method can be applied to fully self-supervised pre-training and coarse-grained supervised pre-training. We further propose an approximate contrastive training strategy to significantly reduce time/memory consumption. Extensive experiments on multi-domain, out-of-distribution benchmarks have demonstrated the effectiveness of our approach. The code is available at: https://github.com/RUCAIBox/GMPT. ",
    "url": "https://arxiv.org/abs/2203.01597",
    "authors": [
      "Yupeng Hou",
      "Binbin Hu",
      "Wayne Xin Zhao",
      "Zhiqiang Zhang",
      "Jun Zhou",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01601",
    "title": "Syntax-Aware Network for Handwritten Mathematical Expression Recognition",
    "abstract": "Handwritten mathematical expression recognition (HMER) is a challenging task that has many potential applications. Recent methods for HMER have achieved outstanding performance with an encoder-decoder architecture. However, these methods adhere to the paradigm that the prediction is made \"from one character to another\", which inevitably yields prediction errors due to the complicated structures of mathematical expressions or crabbed handwritings. In this paper, we propose a simple and efficient method for HMER, which is the first to incorporate syntax information into an encoder-decoder network. Specifically, we present a set of grammar rules for converting the LaTeX markup sequence of each expression into a parsing tree; then, we model the markup sequence prediction as a tree traverse process with a deep neural network. In this way, the proposed method can effectively describe the syntax context of expressions, avoiding the structure prediction errors of HMER. Experiments on two benchmark datasets demonstrate that our method achieves significantly better recognition performance than prior arts. To further validate the effectiveness of our method, we create a large-scale dataset consisting of 100k handwritten mathematical expression images acquired from ten thousand writers. The source code, new dataset, and pre-trained models of this work will be publicly available. ",
    "url": "https://arxiv.org/abs/2203.01601",
    "authors": [
      "Ye Yuan",
      "Xiao Liu",
      "Wondimu Dikubab",
      "Hui Liu",
      "Zhilong Ji",
      "Zhongqin Wu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01604",
    "title": "Curvature Graph Generative Adversarial Networks",
    "abstract": "Generative adversarial network (GAN) is widely used for generalized and robust learning on graph data. However, for non-Euclidean graph data, the existing GAN-based graph representation methods generate negative samples by random walk or traverse in discrete space, leading to the information loss of topological properties (e.g. hierarchy and circularity). Moreover, due to the topological heterogeneity (i.e., different densities across the graph structure) of graph data, they suffer from serious topological distortion problems. In this paper, we proposed a novel Curvature Graph Generative Adversarial Networks method, named \\textbf{\\modelname}, which is the first GAN-based graph representation method in the Riemannian geometric manifold. To better preserve the topological properties, we approximate the discrete structure as a continuous Riemannian geometric manifold and generate negative samples efficiently from the wrapped normal distribution. To deal with the topological heterogeneity, we leverage the Ricci curvature for local structures with different topological properties, obtaining to low-distortion representations. Extensive experiments show that CurvGAN consistently and significantly outperforms the state-of-the-art methods across multiple tasks and shows superior robustness and generalization. ",
    "url": "https://arxiv.org/abs/2203.01604",
    "authors": [
      "Jianxin Li",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Cheng Ji",
      "Jiajun Tan",
      "Jia Wu",
      "Hao Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.01606",
    "title": "Ensemble Methods for Robust Support Vector Machines using Integer  Programming",
    "abstract": "In this work we study binary classification problems where we assume that our training data is subject to uncertainty, i.e. the precise data points are not known. To tackle this issue in the field of robust machine learning the aim is to develop models which are robust against small perturbations in the training data. We study robust support vector machines (SVM) and extend the classical approach by an ensemble method which iteratively solves a non-robust SVM on different perturbations of the dataset, where the perturbations are derived by an adversarial problem. Afterwards for classification of an unknown data point we perform a majority vote of all calculated SVM solutions. We study three different variants for the adversarial problem, the exact problem, a relaxed variant and an efficient heuristic variant. While the exact and the relaxed variant can be modeled using integer programming formulations, the heuristic one can be implemented by an easy and efficient algorithm. All derived methods are tested on random and realistic datasets and the results indicate that the derived ensemble methods have a much more stable behaviour when changing the protection level compared to the classical robust SVM model. ",
    "url": "https://arxiv.org/abs/2203.01606",
    "authors": [
      "Jannis Kurtz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.01620",
    "title": "Linear cuts in Boolean networks",
    "abstract": "Boolean networks are popular tools for the exploration of qualitative dynamical properties of biological systems. Several dynamical interpretations have been proposed based on the same logical structure that captures the interactions between Boolean components. They reproduce, in different degrees, the behaviours emerging in more quantitative models. In particular, regulatory conflicts can prevent the standard asynchronous dynamics from reproducing some trajectories that might be expected upon inspection of more detailed models. We introduce and study the class of networks with linear cuts, where linear components -- intermediates with a single regulator and a single target -- eliminate the aforementioned regulatory conflicts. The interaction graph of a Boolean network admits a linear cut when a linear component occurs in each cycle and in each path from components with multiple targets to components with multiple regulators. Under this structural condition the attractors are in one-to-one correspondence with the minimal trap spaces, and the reachability of attractors can also be easily characterized. Linear cuts provide the base for a new interpretation of the Boolean semantics that captures all behaviours of multi-valued refinements with regulatory thresholds that are uniquely defined for each interaction, and contribute a new approach for the investigation of behaviour of logical models. ",
    "url": "https://arxiv.org/abs/2203.01620",
    "authors": [
      "Aur\u00e9lien Naldi",
      "Adrien Richard",
      "Elisa Tonello"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2203.01631",
    "title": "Fully-Connected Network on Noncompact Symmetric Space and Ridgelet  Transform based on Helgason-Fourier Analysis",
    "abstract": "Neural network on Riemannian symmetric space such as hyperbolic space and the manifold of symmetric positive definite (SPD) matrices is an emerging subject of research in geometric deep learning. Based on the well-established framework of the Helgason-Fourier transform on the noncompact symmetric space, we present a fully-connected network and its associated ridgelet transform on the noncompact symmetric space, covering the hyperbolic neural network (HNN) and the SPDNet as special cases. The ridgelet transform is an analysis operator of a depth-2 continuous network spanned by neurons, namely, it maps an arbitrary given function to the weights of a network. Thanks to the coordinate-free reformulation, the role of nonlinear activation functions is revealed to be a wavelet function, and the reconstruction formula directly yields the universality of the proposed networks. ",
    "url": "https://arxiv.org/abs/2203.01631",
    "authors": [
      "Sho Sonoda",
      "Isao Ishikawa",
      "Masahiro Ikeda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01641",
    "title": "On generating parametrised structural data using conditional generative  adversarial networks",
    "abstract": "A powerful approach, and one of the most common ones in structural health monitoring (SHM), is to use data-driven models to make predictions and inferences about structures and their condition. Such methods almost exclusively rely on the quality of the data. Within the SHM discipline, data do not always suffice to build models with satisfactory accuracy for given tasks. Even worse, data may be completely missing from one's dataset, regarding the behaviour of a structure under different environmental conditions. In the current work, with a view to confronting such issues, the generation of artificial data using a variation of the generative adversarial network (GAN) algorithm, is used. The aforementioned variation is that of the conditional GAN or cGAN. The algorithm is not only used to generate artificial data, but also to learn transformations of manifolds according to some known parameters. Assuming that the structure's response is represented by points in a manifold, part of the space will be formed due to variations in external conditions affecting the structure. This idea proves efficient in SHM, as it is exploited to generate structural data for specific values of environmental coefficients. The scheme is applied here on a simulated structure which operates under different temperature and humidity conditions. The cGAN is trained on data for some discrete values of the temperature within some range, and is able to generate data for every temperature in this range with satisfactory accuracy. The novelty, compared to classic regression in similar problems, is that the cGAN allows unknown environmental parameters to affect the structure and can generate whole manifolds of data for every value of the known parameters, while the unknown ones vary within the generated manifolds. ",
    "url": "https://arxiv.org/abs/2203.01641",
    "authors": [
      "G. Tsialiamanis",
      "D.J. Wagg",
      "N. Dervilis",
      "K. Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01646",
    "title": "On an application of graph neural networks in population based SHM",
    "abstract": "Attempts have been made recently in the field of population-based structural health monitoring (PBSHM), to transfer knowledge between SHM models of different structures. The attempts have been focussed on homogeneous and heterogeneous populations. A more general approach to transferring knowledge between structures, is by considering all plausible structures as points on a multidimensional base manifold and building a fibre bundle. The idea is quite powerful, since, a mapping between points in the base manifold and their fibres, the potential states of any arbitrary structure, can be learnt. A smaller scale problem, but still useful, is that of learning a specific point of every fibre, i.e. that corresponding to the undamaged state of structures within a population. Under the framework of PBSHM, a data-driven approach to the aforementioned problem is developed. Structures are converted into graphs and inference is attempted within a population, using a graph neural network (GNN) algorithm. The algorithm solves a major problem existing in such applications. Structures comprise different sizes and are defined as abstract objects, thus attempting to perform inference within a heterogeneous population is not trivial. The proposed approach is tested in a simulated population of trusses. The goal of the application is to predict the first natural frequency of trusses of different sizes, across different environmental temperatures and having different bar member types. After training the GNN using part of the total population, it was tested on trusses that were not included in the training dataset. Results show that the accuracy of the regression is satisfactory even in structures with higher number of nodes and members than those used to train it. ",
    "url": "https://arxiv.org/abs/2203.01646",
    "authors": [
      "G. Tsialiamanis",
      "C. Mylonas",
      "E. Chatzi",
      "D.J. Wagg",
      "N. Dervilis",
      "K. Worden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.01677",
    "title": "Detection of Word Adversarial Examples in Text Classification: Benchmark  and Baseline via Robust Density Estimation",
    "abstract": "Word-level adversarial attacks have shown success in NLP models, drastically decreasing the performance of transformer-based models in recent years. As a countermeasure, adversarial defense has been explored, but relatively few efforts have been made to detect adversarial examples. However, detecting adversarial examples may be crucial for automated tasks (e.g. review sentiment analysis) that wish to amass information about a certain population and additionally be a step towards a robust defense system. To this end, we release a dataset for four popular attack methods on four datasets and four models to encourage further research in this field. Along with it, we propose a competitive baseline based on density estimation that has the highest AUC on 29 out of 30 dataset-attack-model combinations. Source code is available in https://github.com/anoymous92874838/text-adv-detection. ",
    "url": "https://arxiv.org/abs/2203.01677",
    "authors": [
      "KiYoon Yoo",
      "Jangho Kim",
      "Jiho Jang",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01684",
    "title": "Anomaly Detection in Big Data",
    "abstract": "Anomaly is defined as a state of the system that do not conform to the normal behavior. For example, the emission of neutrons in a nuclear reactor channel above the specified threshold is an anomaly. Big data refers to the data set that is \\emph{high volume, streaming, heterogeneous, distributed} and often \\emph{sparse}. Big data is not uncommon these days. For example, as per Internet live stats, the number of tweets posted per day has gone above 500 millions. Due to data explosion in data laden domains, traditional anomaly detection techniques developed for small data sets scale poorly on large-scale data sets. Therefore, we take an alternative approach to tackle anomaly detection in big data. Essentially, there are two ways to scale anomaly detection in big data. The first is based on the \\emph{online} learning and the second is based on the \\emph{distributed} learning. Our aim in the thesis is to tackle big data problems while detecting anomaly efficiently. To that end, we first take \\emph{streaming} issue of the big data and propose Passive-Aggressive GMEAN (PAGMEAN) algorithms. Although, online learning algorithm can scale well over large number of data points and dimensions, they can not process data when it is distributed at multiple locations; which is quite common these days. Therefore, we propose anomaly detection algorithm which is inherently distributed using ADMM. Finally, we present a case study on anomaly detection in nuclear power plant data. ",
    "url": "https://arxiv.org/abs/2203.01684",
    "authors": [
      "Chandresh Kumar Maurya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01687",
    "title": "Relative distance matters for one-shot landmark detection",
    "abstract": "Contrastive learning based methods such as cascade comparing to detect (CC2D) have shown great potential for one-shot medical landmark detection. However, the important cue of relative distance between landmarks is ignored in CC2D. In this paper, we upgrade CC2D to version II by incorporating a simple-yet-effective relative distance bias in the training stage, which is theoretically proved to encourage the encoder to project the relatively distant landmarks to the embeddings with low similarities. As consequence, CC2Dv2 is less possible to detect a wrong point far from the correct landmark. Furthermore, we present an open-source, landmark-labeled dataset for the measurement of biomechanical parameters of the lower extremity to alleviate the burden of orthopedic surgeons. The effectiveness of CC2Dv2 is evaluated on the public dataset from the ISBI 2015 Grand-Challenge of cephalometric radiographs and our new dataset, which greatly outperforms the state-of-the-art one-shot landmark detection approaches. ",
    "url": "https://arxiv.org/abs/2203.01687",
    "authors": [
      "Qingsong Yao",
      "Jianji Wang",
      "Yihua Sun",
      "Quan Quan",
      "Heqin Zhu",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01696",
    "title": "Fail-Safe Generative Adversarial Imitation Learning",
    "abstract": "For flexible yet safe imitation learning (IL), we propose a modular approach that uses a generative imitator policy with a safety layer, has an overall explicit density/gradient, can therefore be end-to-end trained using generative adversarial IL (GAIL), and comes with theoretical worst-case safety/robustness guarantees. The safety layer's exact density comes from using a countable non-injective gluing of piecewise differentiable injections and the change-of-variables formula. The safe set (into which the safety layer maps) is inferred by sampling actions and their potential future fail-safe fallback continuations, together with Lipschitz continuity and convexity arguments. We also provide theoretical bounds showing the advantage of using the safety layer already during training (imitation error linear in the horizon) compared to only using it at test time (quadratic error). In an experiment on challenging real-world driver interaction data, we empirically demonstrate tractability, safety and imitation performance of our approach. ",
    "url": "https://arxiv.org/abs/2203.01696",
    "authors": [
      "Philipp Geiger",
      "Christoph-Nikolas Straehle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01716",
    "title": "Detecting High-Quality GAN-Generated Face Images using Neural Networks",
    "abstract": "In the past decades, the excessive use of the last-generation GAN (Generative Adversarial Networks) models in computer vision has enabled the creation of artificial face images that are visually indistinguishable from genuine ones. These images are particularly used in adversarial settings to create fake social media accounts and other fake online profiles. Such malicious activities can negatively impact the trustworthiness of users identities. On the other hand, the recent development of GAN models may create high-quality face images without evidence of spatial artifacts. Therefore, reassembling uniform color channel correlations is a challenging research problem. To face these challenges, we need to develop efficient tools able to differentiate between fake and authentic face images. In this chapter, we propose a new strategy to differentiate GAN-generated images from authentic images by leveraging spectral band discrepancies, focusing on artificial face image synthesis. In particular, we enable the digital preservation of face images using the Cross-band co-occurrence matrix and spatial co-occurrence matrix. Then, we implement these techniques and feed them to a Convolutional Neural Networks (CNN) architecture to identify the real from artificial faces. Additionally, we show that the performance boost is particularly significant and achieves more than 92% in different post-processing environments. Finally, we provide several research observations demonstrating that this strategy improves a comparable detection method based only on intra-band spatial co-occurrences. ",
    "url": "https://arxiv.org/abs/2203.01716",
    "authors": [
      "Ehsan Nowroozi",
      "Mauro Conti",
      "Yassine Mekdad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01728",
    "title": "Distributed Matrix-Vector Multiplication with Sparsity and Privacy  Guarantees",
    "abstract": "We consider the problem of designing a coding scheme that allows both sparsity and privacy for distributed matrix-vector multiplication. Perfect information-theoretic privacy requires encoding the input sparse matrices into matrices distributed uniformly at random from the considered alphabet; thus destroying the sparsity. Computing matrix-vector multiplication for sparse matrices is known to be fast. Distributing the computation over the non-sparse encoded matrices maintains privacy, but introduces artificial computing delays. In this work, we relax the privacy constraint and show that a certain level of sparsity can be maintained in the encoded matrices. We consider the chief/worker setting while assuming the presence of two clusters of workers: one is completely untrusted in which all workers collude to eavesdrop on the input matrix and in which perfect privacy must be satisfied; in the partly trusted cluster, only up to $z$ workers may collude and to which revealing small amount of information about the input matrix is allowed. We design a scheme that trades sparsity for privacy while achieving the desired constraints. We use cyclic task assignments of the encoded matrices to tolerate partial and full stragglers. ",
    "url": "https://arxiv.org/abs/2203.01728",
    "authors": [
      "Marvin Xhemrishi",
      "Rawad Bitar",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.01746",
    "title": "SaPHyRa: A Learning Theory Approach to Ranking Nodes in Large Networks",
    "abstract": "Ranking nodes based on their centrality stands a fundamental, yet, challenging problem in large-scale networks. Approximate methods can quickly estimate nodes' centrality and identify the most central nodes, but the ranking for the majority of remaining nodes may be meaningless. For example, ranking for less-known websites in search queries is known to be noisy and unstable. To this end, we investigate a new node ranking problem with two important distinctions: a) ranking quality, rather than the centrality estimation quality, as the primary objective; and b) ranking only nodes of interest, e.g., websites that matched search criteria. We propose Sample space Partitioning Hypothesis Ranking, or SaPHyRa, that transforms node ranking into a hypothesis ranking in machine learning. This transformation maps nodes' centrality to the expected risks of hypotheses, opening doors for theoretical machine learning (ML) tools. The key of SaPHyRa is to partition the sample space into exact and approximate subspaces. The exact subspace contains samples related to the nodes of interest, increasing both estimation and ranking qualities. The approximate space can be efficiently sampled with ML-based techniques to provide theoretical guarantees on the estimation error. Lastly, we present SaPHyRa_bc, an illustration of SaPHyRa on ranking nodes' betweenness centrality (BC). By combining a novel bi-component sampling, a 2-hop sample partitioning, and improved bounds on the Vapnik-Chervonenkis dimension, SaPHyRa_bc can effectively rank any node subset in BC. Its performance is up to 200x faster than state-of-the-art methods in approximating BC, while its rank correlation to the ground truth is improved by multifold. ",
    "url": "https://arxiv.org/abs/2203.01746",
    "authors": [
      "Phuc Thai",
      "My T. Thai",
      "Tam Vu",
      "Thang N. Dinh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.01754",
    "title": "PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D  Video Sequence",
    "abstract": "We present a novel method to learn Personalized Implicit Neural Avatars (PINA) from a short RGB-D sequence. This allows non-expert users to create a detailed and personalized virtual copy of themselves, which can be animated with realistic clothing deformations. PINA does not require complete scans, nor does it require a prior learned from large datasets of clothed humans. Learning a complete avatar in this setting is challenging, since only few depth observations are available, which are noisy and incomplete (i.e.only partial visibility of the body per frame). We propose a method to learn the shape and non-rigid deformations via a pose-conditioned implicit surface and a deformation field, defined in canonical space. This allows us to fuse all partial observations into a single consistent canonical representation. Fusion is formulated as a global optimization problem over the pose, shape and skinning parameters. The method can learn neural avatars from real noisy RGB-D sequences for a diverse set of people and clothing styles and these avatars can be animated given unseen motion sequences. ",
    "url": "https://arxiv.org/abs/2203.01754",
    "authors": [
      "Zijian Dong",
      "Chen Guo",
      "Jie Song",
      "Xu Chen",
      "Andreas Geiger",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01762",
    "title": "NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural  Radiance Fields",
    "abstract": "Deep learning has shown great potential for modeling the physical dynamics of complex particle systems such as fluids (in Lagrangian descriptions). Existing approaches, however, require the supervision of consecutive particle properties, including positions and velocities. In this paper, we consider a partially observable scenario known as fluid dynamics grounding, that is, inferring the state transitions and interactions within the fluid particle systems from sequential visual observations of the fluid surface. We propose a differentiable two-stage network named NeuroFluid. Our approach consists of (i) a particle-driven neural renderer, which involves fluid physical properties into the volume rendering function, and (ii) a particle transition model optimized to reduce the differences between the rendered and the observed images. NeuroFluid provides the first solution to unsupervised learning of particle-based fluid dynamics by training these two models jointly. It is shown to reasonably estimate the underlying physics of fluids with different initial shapes, viscosity, and densities. It is a potential alternative approach to understanding complex fluid mechanics, such as turbulence, that are difficult to model using traditional methods of mathematical physics. ",
    "url": "https://arxiv.org/abs/2203.01762",
    "authors": [
      "Shanyan Guan",
      "Huayu Deng",
      "Yunbo Wang",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2203.01786",
    "title": "Generative Modeling for Low Dimensional Speech Attributes with Neural  Spline Flows",
    "abstract": "Despite recent advances in generative modeling for text-to-speech synthesis, these models do not yet have the same fine-grained adjustability of pitch-conditioned deterministic models such as FastPitch and FastSpeech2. Pitch information is not only low-dimensional, but also discontinuous, making it particularly difficult to model in a generative setting. Our work explores several techniques for handling the aforementioned issues in the context of Normalizing Flow models. We also find this problem to be very well suited for Neural Spline flows, which is a highly expressive alternative to the more common affine-coupling mechanism in Normalizing Flows. ",
    "url": "https://arxiv.org/abs/2203.01786",
    "authors": [
      "Kevin J. Shih",
      "Rafael Valle",
      "Rohan Badlani",
      "J\u00f5ao Felipe Santos",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01800",
    "title": "Adaptive Local-Global Relational Network for Facial Action Units  Recognition and Facial Paralysis Estimation",
    "abstract": "Facial action units (AUs) refer to a unique set of facial muscle movements at certain facial locations defined by the Facial Action Coding System (FACS), which can be used for describing nearly any anatomically possible facial expression. Many existing facial action units (AUs) recognition approaches often enhance the AU representation by combining local features from multiple independent branches, each corresponding to a different AU, which usually neglect potential mutual assistance and exclusion relationship between AU branches or simply employ a pre-defined and fixed knowledge-graph as a prior. In addition, extracting features from pre-defined AU regions of regular shapes limits the representation ability. In this paper, we propose a novel Adaptive Local-Global Relational Network (ALGRNet) for facial AU recognition and apply it to facial paralysis estimation. ALGRNet mainly consists of three novel structures, i.e., an adaptive region learning module which learns the adaptive muscle regions based on the detected landmarks, a skip-BiLSTM module which models the latent mutual assistance and exclusion relationship among local AU features, and a feature fusion\\&refining module which explores the complementarity between local AUs and the whole face for the local AU refinement. In order to evaluate our proposed method, we migrated ALGRNet to a facial paralysis dataset which is collected and annotated by medical professionals. Experiments on the BP4D and DISFA AU datasets show that the proposed approach outperforms the state-of-the-art methods by a large margin. Additionally, we also demonstrated the effectiveness of the proposed ALGRNet in applications to facial paralysis estimation. ",
    "url": "https://arxiv.org/abs/2203.01800",
    "authors": [
      "Xuri Ge",
      "Joemon M. Jose",
      "Pengcheng Wang",
      "Arunachalam Iyer",
      "Xiao Liu",
      "Hu Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01820",
    "title": "An Effective Graph Learning based Approach for Temporal Link Prediction:  The First Place of WSDM Cup 2022",
    "abstract": "Temporal link prediction, as one of the most crucial work in temporal graphs, has attracted lots of attention from the research area. The WSDM Cup 2022 seeks for solutions that predict the existence probabilities of edges within time spans over temporal graph. This paper introduces the solution of AntGraph, which wins the 1st place in the competition. We first analysis the theoretical upper-bound of the performance by removing temporal information, which implies that only structure and attribute information on the graph could achieve great performance. Based on this hypothesis, then we introduce several well-designed features. Finally, experiments conducted on the competition datasets show the superiority of our proposal, which achieved AUC score of 0.666 on dataset A and 0.902 on dataset B, the ablation studies also prove the efficiency of each feature. Code is publicly available at https://github.com/im0qianqian/WSDM2022TGP-AntGraph. ",
    "url": "https://arxiv.org/abs/2203.01820",
    "authors": [
      "Qian Zhao",
      "Shuo Yang",
      "Binbin Hu",
      "Zhiqiang Zhang",
      "Yakun Wang",
      "Yusong Chen",
      "Jun Zhou",
      "Chuan Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01821",
    "title": "Socially Aware Robot Crowd Navigation with Interaction Graphs and Human  Trajectory Prediction",
    "abstract": "We study the problem of safe and socially aware robot navigation in dense and interactive human crowds. Previous works use simplified methods to model the personal spaces of pedestrians and ignore the social compliance of the robot behaviors. In this paper, we provide a more accurate representation of personal zones of walking pedestrians with their future trajectories. The predicted personal zones are incorporated into a reinforcement learning framework to prevent the robot from intruding into the personal zones. To learn socially aware navigation policies, we propose a novel recurrent graph neural network with attention mechanisms to capture the interactions among agents through space and time. We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i. ",
    "url": "https://arxiv.org/abs/2203.01821",
    "authors": [
      "Shuijing Liu",
      "Peixin Chang",
      "Zhe Huang",
      "Neeloy Chakraborty",
      "Weihang Liang",
      "Junyi Geng",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01823",
    "title": "Mobile device users' susceptibility to phishing attacks",
    "abstract": "The mobile device is one of the fasted growing technologies that is widely used in a diversifying sector. Mobile devices are used for everyday life, such as personal information exchange - chatting, email, shopping, and mobile banking, contributing to information security threats. Users' behavior can influence information security threats. More research is needed to understand users' threat avoidance behavior and motivation. Using Technology threat avoidance theory (TTAT), this study assessed factors that influenced mobile device users' threat avoidance motivations and behaviors as it relates to phishing attacks. From the data collected from 137 mobile device users using a questionnaire, the findings indicate that (1) mobile device users' perceived susceptibility and severity of phishing attacks have a significant correlation with a users' perception of the threat; (2) mobile device users' motivation to avoid a threat is correlated to a users' behavior in avoiding threat; and (3) a mobile device user's susceptibility to phishing attacks can be reduced by their perception of the threat. These findings reveal that a user's perception of threat increases if they perceive that the consequence of such threat to their mobile devices will be severe, thereby increasing a user's motivation and behavior to avoid phishing attack threats. This study is beneficial to mobile device users in personal and organizational settings. ",
    "url": "https://arxiv.org/abs/2203.01823",
    "authors": [
      "F. Ley Sylvester"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.01824",
    "title": "LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware  Transformer Network",
    "abstract": "3D room layout estimation by a single panorama using deep neural networks has made great progress. However, previous approaches can not obtain efficient geometry awareness of room layout with the only latitude of boundaries or horizon-depth. We present that using horizon-depth along with room height can obtain omnidirectional-geometry awareness of room layout in both horizontal and vertical directions. In addition, we propose a planar-geometry aware loss function with normals and gradients of normals to supervise the planeness of walls and turning of corners. We propose an efficient network, LGT-Net, for room layout estimation, which contains a novel Transformer architecture called SWG Transformer to model geometry relations. SWG Transformer consists of (Shifted) Window Blocks and Global Blocks to combine the local and global geometry relations. Moreover, we design a novel relative position embedding of Transformer to enhance the spatial identification ability for the panorama. Experiments show that the proposed LGT-Net achieves better performance than current state-of-the-arts (SOTA) on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2203.01824",
    "authors": [
      "Zhigang Jiang",
      "Zhongzheng Xiang",
      "Jinhua Xu",
      "Ming Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01827",
    "title": "Democratic Governance and International Research Collaboration: A  Longitudinal Analysis of the Global Science Network",
    "abstract": "The connection between democracy and science has traditionally been examined through philosophical conjecture and single country case studies. As such, there remains limited global scale empirical research on the topic. However, there is a large body of evidence suggesting that research collaboration is associated with scientific productivity and performance. Further, international relations theory suggests democratic nations are more likely to cooperate across a range of modalities. This study explores country level factors that affect dynamics of the global scientific research collaboration network, focusing on structural effects of democratic governance on the formation, persistence, and strength of international research collaboration ties. This study combines longitudinal data between 2008 and 2017 from the Varieties of Democracy Project, World Bank Indicators, Scopus, and Web of Science bibliometric data. Methods of analysis include a combination of temporal and weighted exponential random graph models to test hypotheses regarding the connection between democratic governance and global collaboration patterns. The results suggest positive significant effects of both democratic governance on international research collaboration and assortative mixing between countries with similar levels of democratic governance. Finally, the results also show support for drivers of collaboration including exogenous economic, population, and geo-political factors, as well as endogenous network effects including preferential attachment and transitivity. ",
    "url": "https://arxiv.org/abs/2203.01827",
    "authors": [
      "Travis A. Whetsell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2203.01842",
    "title": "Nonlinear Reduced Order Modelling of Soil Structure Interaction Effects  via LSTM and Autoencoder Neural Networks",
    "abstract": "In the field of structural health monitoring (SHM), inverse problems which require repeated analyses are common. With the increase in the use of nonlinear models, the development of nonlinear reduced order modelling techniques is of paramount interest. Of considerable research interest, is the use of flexible and scalable machine learning methods which can learn to approximate the behaviour of nonlinear dynamic systems using input and output data. One such nonlinear system of interest, in the context of wind turbine structures, is the soil structure interaction (SSI) problem. Soil demonstrates strongly nonlinear behaviour with regards to its restoring force and has been shown to considerably influence the dynamic response of wind turbine structures. In this work, we demonstrate the application of a recently developed nonlinear reduced order modelling method, which leverages Autoencoder and LSTM neural networks, to a nonlinear soil structure interaction problem of a wind turbine monopile subject to realistic loading at the seabed level. The accuracy and efficiency of the methodology is compared to full order simulations carried out using Abaqus. The ROM was shown to have good fidelity and a considerable reduction in computational time for the system considered. ",
    "url": "https://arxiv.org/abs/2203.01842",
    "authors": [
      "Thomas Simpson",
      "Nikolaos Dervilis",
      "Philippe Couturier",
      "Nico Maljaars",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2203.01845",
    "title": "MooAFEM: An object oriented Matlab code for higher-order (nonlinear)  adaptive FEM",
    "abstract": "We present an easily accessible, object oriented code (written exclusively in Matlab) for finite element simulations in 2D. The object oriented programming paradigm allows for fast implementation of higher-order FEM on triangular meshes for problems with very general coefficients. In particular, our code can handle problems typically arising from iterative linearization methods used to solve nonlinear PDEs. We explain the basic principles of our code and give numerical experiments that underline its flexibility as well as its efficiency. ",
    "url": "https://arxiv.org/abs/2203.01845",
    "authors": [
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2203.01848",
    "title": "Local Constraint-Based Causal Discovery under Selection Bias",
    "abstract": "We consider the problem of discovering causal relations from independence constraints selection bias in addition to confounding is present. While the seminal FCI algorithm is sound and complete in this setup, no criterion for the causal interpretation of its output under selection bias is presently known. We focus instead on local patterns of independence relations, where we find no sound method for only three variable that can include background knowledge. Y-Structure patterns are shown to be sound in predicting causal relations from data under selection bias, where cycles may be present. We introduce a finite-sample scoring rule for Y-Structures that is shown to successfully predict causal relations in simulation experiments that include selection mechanisms. On real-world microarray data, we show that a Y-Structure variant performs well across different datasets, potentially circumventing spurious correlations due to selection bias. ",
    "url": "https://arxiv.org/abs/2203.01848",
    "authors": [
      "Philip Versteeg",
      "Cheng Zhang",
      "Joris M. Mooij"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01852",
    "title": "Identification in Tree-shaped Linear Structural Causal Models",
    "abstract": "Linear structural equation models represent direct causal effects as directed edges and confounding factors as bidirected edges. An open problem is to identify the causal parameters from correlations between the nodes. We investigate models, whose directed component forms a tree, and show that there, besides classical instrumental variables, missing cycles of bidirected edges can be used to identify the model. They can yield systems of quadratic equations that we explicitly solve to obtain one or two solutions for the causal parameters of adjacent directed edges. We show how multiple missing cycles can be combined to obtain a unique solution. This results in an algorithm that can identify instances that previously required approaches based on Gr\\\"obner bases, which have doubly-exponential time complexity in the number of structural parameters. ",
    "url": "https://arxiv.org/abs/2203.01852",
    "authors": [
      "Benito van der Zander",
      "Marcel Wien\u00f6bst",
      "Markus Bl\u00e4ser",
      "Maciej Li\u015bkiewicz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01854",
    "title": "A study on the distribution of social biases in self-supervised learning  visual models",
    "abstract": "Deep neural networks are efficient at learning the data distribution if it is sufficiently sampled. However, they can be strongly biased by non-relevant factors implicitly incorporated in the training data. These include operational biases, such as ineffective or uneven data sampling, but also ethical concerns, as the social biases are implicitly present\\textemdash even inadvertently, in the training data or explicitly defined in unfair training schedules. In tasks having impact on human processes, the learning of social biases may produce discriminatory, unethical and untrustworthy consequences. It is often assumed that social biases stem from supervised learning on labelled data, and thus, Self-Supervised Learning (SSL) wrongly appears as an efficient and bias-free solution, as it does not require labelled data. However, it was recently proven that a popular SSL method also incorporates biases. In this paper, we study the biases of a varied set of SSL visual models, trained using ImageNet data, using a method and dataset designed by psychological experts to measure social biases. We show that there is a correlation between the type of the SSL model and the number of biases that it incorporates. Furthermore, the results also suggest that this number does not strictly depend on the model's accuracy and changes throughout the network. Finally, we conclude that a careful SSL model selection process can reduce the number of social biases in the deployed model, whilst keeping high performance. ",
    "url": "https://arxiv.org/abs/2203.01854",
    "authors": [
      "Kirill Sirotkin",
      "Pablo Carballeira",
      "Marcos Escudero-Vi\u00f1olo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01859",
    "title": "Robust PAC$^m$: Training Ensemble Models Under Model Misspecification  and Outliers",
    "abstract": "Standard Bayesian learning is known to have suboptimal generalization capabilities under model misspecification and in the presence of outliers. PAC-Bayes theory demonstrates that the free energy criterion minimized by Bayesian learning is a bound on the generalization error for Gibbs predictors (i.e., for single models drawn at random from the posterior) under the assumption of sampling distributions uncontaminated by outliers. This viewpoint provides a justification for the limitations of Bayesian learning when the model is misspecified, requiring ensembling, and when data is affected by outliers. In recent work, PAC-Bayes bounds - referred to as PAC$^m$ - were derived to introduce free energy metrics that account for the performance of ensemble predictors, obtaining enhanced performance under misspecification. This work presents a novel robust free energy criterion that combines the generalized logarithm score function with PAC$^m$ ensemble bounds. The proposed free energy training criterion produces predictive distributions that are able to concurrently counteract the detrimental effects of model misspecification and outliers. ",
    "url": "https://arxiv.org/abs/2203.01859",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Marios Kountouris",
      "David Gesbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.01864",
    "title": "Robustness and Adaptation to Hidden Factors of Variation",
    "abstract": "We tackle here a specific, still not widely addressed aspect, of AI robustness, which consists of seeking invariance / insensitivity of model performance to hidden factors of variations in the data. Towards this end, we employ a two step strategy that a) does unsupervised discovery, via generative models, of sensitive factors that cause models to under-perform, and b) intervenes models to make their performance invariant to these sensitive factors' influence. We consider 3 separate interventions for robustness, including: data augmentation, semantic consistency, and adversarial alignment. We evaluate our method using metrics that measure trade offs between invariance (insensitivity) and overall performance (utility) and show the benefits of our method for 3 settings (unsupervised, semi-supervised and generalization). ",
    "url": "https://arxiv.org/abs/2203.01864",
    "authors": [
      "William Paul",
      "Philippe Burlina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01874",
    "title": "Thermodynamics-informed graph neural networks",
    "abstract": "In this paper we present a deep learning method to predict the time evolution of dissipative dynamical systems. We propose using both geometric and thermodynamic inductive biases to improve accuracy and generalization of the resulting integration scheme. The first is achieved with Graph Neural Networks, which induces a non-Euclidean geometrical prior and permutation invariant node and edge update functions. The second bias is forced by learning the GENERIC structure of the problem, an extension of the Hamiltonian formalism, to model more general non-conservative dynamics. Several examples are provided in both Eulerian and Lagrangian description in the context of fluid and solid mechanics respectively. ",
    "url": "https://arxiv.org/abs/2203.01874",
    "authors": [
      "Quercus Hern\u00e1ndez",
      "Alberto Bad\u00edas",
      "Francisco Chinesta",
      "El\u00edas Cueto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2203.01880",
    "title": "LatentFormer: Multi-Agent Transformer-Based Interaction Modeling and  Trajectory Prediction",
    "abstract": "Multi-agent trajectory prediction is a fundamental problem in autonomous driving. The key challenges in prediction are accurately anticipating the behavior of surrounding agents and understanding the scene context. To address these problems, we propose LatentFormer, a transformer-based model for predicting future vehicle trajectories. The proposed method leverages a novel technique for modeling interactions among dynamic objects in the scene. Contrary to many existing approaches which model cross-agent interactions during the observation time, our method additionally exploits the future states of the agents. This is accomplished using a hierarchical attention mechanism where the evolving states of the agents autoregressively control the contributions of past trajectories and scene encodings in the final prediction. Furthermore, we propose a multi-resolution map encoding scheme that relies on a vision transformer module to effectively capture both local and global scene context to guide the generation of more admissible future trajectories. We evaluate the proposed method on the nuScenes benchmark dataset and show that our approach achieves state-of-the-art performance and improves upon trajectory metrics by up to 40%. We further investigate the contributions of various components of the proposed technique via extensive ablation studies. ",
    "url": "https://arxiv.org/abs/2203.01880",
    "authors": [
      "Elmira Amirloo",
      "Amir Rasouli",
      "Peter Lakner",
      "Mohsen Rohani",
      "Jun Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01881",
    "title": "Understanding Failure Modes of Self-Supervised Learning",
    "abstract": "Self-supervised learning methods have shown impressive results in downstream classification tasks. However, there is limited work in understanding their failure models and interpreting the learned representations of these models. In this paper, we tackle these issues and study the representation space of self-supervised models by understanding the underlying reasons for misclassifications in a downstream task. Over several state-of-the-art self-supervised models including SimCLR, SwaV, MoCo V2 and BYOL, we observe that representations of correctly classified samples have few discriminative features with highly deviated values compared to other features. This is in a clear contrast with representations of misclassified samples. We also observe that noisy features in the representation space often correspond to spurious attributes in images making the models less interpretable. Building on these observations, we propose a sample-wise Self-Supervised Representation Quality Score (or, Q-Score) that, without access to any label information, is able to predict if a given sample is likely to be misclassified in the downstream task, achieving an AUPRC of up to 0.90. Q-Score can also be used as a regularization to remedy low-quality representations leading to 3.26% relative improvement in accuracy of SimCLR on ImageNet-100. Moreover, we show that Q-Score regularization increases representation sparsity, thus reducing noise and improving interpretability through gradient heatmaps. ",
    "url": "https://arxiv.org/abs/2203.01881",
    "authors": [
      "Neha Mukund Kalibhat",
      "Kanika Narang",
      "Liang Tan",
      "Hamed Firooz",
      "Maziar Sanjabi",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01884",
    "title": "Graph Neural Networks for Multimodal Single-Cell Data Integration",
    "abstract": "Recent advances in multimodal single-cell technologies have enabled simultaneous acquisitions of multiple omics data from the same cell, providing deeper insights into cellular states and dynamics. However, it is challenging to learn the joint representations from the multimodal data, model the relationship between modalities, and, more importantly, incorporate the vast amount of single-modality datasets into the downstream analyses. To address these challenges and correspondingly facilitate multimodal single-cell data analyses, three key tasks have been introduced: $\\textit{modality prediction}$, $\\textit{modality matching}$ and $\\textit{joint embedding}$. In this work, we present a general Graph Neural Network framework $\\textit{scMoGNN}$ to tackle these three tasks and show that $\\textit{scMoGNN}$ demonstrates superior results in all three tasks compared with the state-of-the-art and conventional approaches. Our method is an official winner in the overall ranking of $\\textit{modality prediction}$ from $\\href{https://openproblems.bio/neurips_2021/}{\\textit{NeurIPS 2021 Competition}}$. ",
    "url": "https://arxiv.org/abs/2203.01884",
    "authors": [
      "Hongzhi Wen",
      "Jiayuan Ding",
      "Wei Jin",
      "Yuying Xie",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01893",
    "title": "Generating Synthetic but Realistic Human Trafficking Networks for  Modeling Disruptions through Transdisciplinary and Community-Based Action  Research",
    "abstract": "One of the major challenges associated with applying operations research (OR) models to disrupting human trafficking networks is a limited amount of reliable data sources readily available for public use, since operations are intentionally hidden to prevent detection, and data from known operations are often incomplete. To help address this data gap, we propose a network generator for domestic sex trafficking networks by integrating OR concepts and qualitative research. Multiple sources have been triangulated to ensure that networks produced by the generator are realistic, including law enforcement case file analysis, interviews with domain experts, and a survivor-centered advisory group with first-hand knowledge of sex trafficking. The output models the relationships between traffickers, so-called \"bottoms\", and victims. This generator allows operations researchers to access realistic sex trafficking network structures in a responsible manner that does not disclose identifiable details of the people involved. We demonstrate the use of output networks in exploring policy recommendations from max flow network interdiction with restructuring. To do so, we propose a novel conceptualization of flow as the ability of a trafficker to control their victims. Our results show the importance of understanding how sex traffickers react to disruptions, especially in terms of recruiting new victims. ",
    "url": "https://arxiv.org/abs/2203.01893",
    "authors": [
      "Daniel Kosmas",
      "Christina Melander",
      "Emily Singerhouse",
      "Thomas C. Sharkey",
      "Kayse Lee Maass",
      "Kelle Barrick",
      "Lauren Martin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.01895",
    "title": "Improving Health Mentioning Classification of Tweets using Contrastive  Adversarial Training",
    "abstract": "Health mentioning classification (HMC) classifies an input text as health mention or not. Figurative and non-health mention of disease words makes the classification task challenging. Learning the context of the input text is the key to this problem. The idea is to learn word representation by its surrounding words and utilize emojis in the text to help improve the classification results. In this paper, we improve the word representation of the input text using adversarial training that acts as a regularizer during fine-tuning of the model. We generate adversarial examples by perturbing the embeddings of the model and then train the model on a pair of clean and adversarial examples. Additionally, we utilize contrastive loss that pushes a pair of clean and perturbed examples close to each other and other examples away in the representation space. We train and evaluate the method on an extended version of the publicly available PHM2017 dataset. Experiments show an improvement of 1.0% over BERT-Large baseline and 0.6% over RoBERTa-Large baseline, whereas 5.8% over the state-of-the-art in terms of F1 score. Furthermore, we provide a brief analysis of the results by utilizing the power of explainable AI. ",
    "url": "https://arxiv.org/abs/2203.01895",
    "authors": [
      "Pervaiz Iqbal Khan",
      "Shoaib Ahmed Siddiqui",
      "Imran Razzak",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01903",
    "title": "Pay Attention to Relations: Multi-embeddings for Attributed Multiplex  Networks",
    "abstract": "Graph Convolutional Neural Networks (GCNs) have become effective machine learning algorithms for many downstream network mining tasks such as node classification, link prediction, and community detection. However, most GCN methods have been developed for homogenous networks and are limited to a single embedding for each node. Complex systems, often represented by heterogeneous, multiplex networks present a more difficult challenge for GCN models and require that such techniques capture the diverse contexts and assorted interactions that occur between nodes. In this work, we propose RAHMeN, a novel unified relation-aware embedding framework for attributed heterogeneous multiplex networks. Our model incorporates node attributes, motif-based features, relation-based GCN approaches, and relational self-attention to learn embeddings of nodes with respect to the various relations in a heterogeneous, multiplex network. In contrast to prior work, RAHMeN is a more expressive embedding framework that embraces the multi-faceted nature of nodes in such networks, producing a set of multi-embeddings that capture the varied and diverse contexts of nodes. We evaluate our model on four real-world datasets from Amazon, Twitter, YouTube, and Tissue PPIs in both transductive and inductive settings. Our results show that RAHMeN consistently outperforms comparable state-of-the-art network embedding models, and an analysis of RAHMeN's relational self-attention demonstrates that our model discovers interpretable connections between relations present in heterogeneous, multiplex networks. ",
    "url": "https://arxiv.org/abs/2203.01903",
    "authors": [
      "Joshua Melton",
      "Michael Ridenhour",
      "Siddharth Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01913",
    "title": "NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance  Fields",
    "abstract": "Thin, reflective objects such as forks and whisks are common in our daily lives, but they are particularly challenging for robot perception because it is hard to reconstruct them using commodity RGB-D cameras or multi-view stereo techniques. While traditional pipelines struggle with objects like these, Neural Radiance Fields (NeRFs) have recently been shown to be remarkably effective for performing view synthesis on objects with thin structures or reflective materials. In this paper we explore the use of NeRF as a new source of supervision for robust robot vision systems. In particular, we demonstrate that a NeRF representation of a scene can be used to train dense object descriptors. We use an optimized NeRF to extract dense correspondences between multiple views of an object, and then use these correspondences as training data for learning a view-invariant representation of the object. NeRF's usage of a density field allows us to reformulate the correspondence problem with a novel distribution-of-depths formulation, as opposed to the conventional approach of using a depth map. Dense correspondence models supervised with our method significantly outperform off-the-shelf learned descriptors by 106% (PCK@3px metric, more than doubling performance) and outperform our baseline supervised with multi-view stereo by 29%. Furthermore, we demonstrate the learned dense descriptors enable robots to perform accurate 6-degree of freedom (6-DoF) pick and place of thin and reflective objects. ",
    "url": "https://arxiv.org/abs/2203.01913",
    "authors": [
      "Lin Yen-Chen",
      "Pete Florence",
      "Jonathan T. Barron",
      "Tsung-Yi Lin",
      "Alberto Rodriguez",
      "Phillip Isola"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01922",
    "title": "Vision-Language Intelligence: Tasks, Representation Learning, and Large  Models",
    "abstract": "This paper presents a comprehensive survey of vision-language (VL) intelligence from the perspective of time. This survey is inspired by the remarkable progress in both computer vision and natural language processing, and recent trends shifting from single modality processing to multiple modality comprehension. We summarize the development in this field into three time periods, namely task-specific methods, vision-language pre-training (VLP) methods, and larger models empowered by large-scale weakly-labeled data. We first take some common VL tasks as examples to introduce the development of task-specific methods. Then we focus on VLP methods and comprehensively review key components of the model structures and training methods. After that, we show how recent work utilizes large-scale raw image-text data to learn language-aligned visual representations that generalize better on zero or few shot learning tasks. Finally, we discuss some potential future trends towards modality cooperation, unified representation, and knowledge incorporation. We believe that this review will be of help for researchers and practitioners of AI and ML, especially those interested in computer vision and natural language processing. ",
    "url": "https://arxiv.org/abs/2203.01922",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Yi-Fan Zhang",
      "Shilong Liu",
      "Jian Guo",
      "Lionel M. Ni",
      "PengChuan Zhang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.01925",
    "title": "Label-Only Model Inversion Attacks via Boundary Repulsion",
    "abstract": "Recent studies show that the state-of-the-art deep neural networks are vulnerable to model inversion attacks, in which access to a model is abused to reconstruct private training data of any given target class. Existing attacks rely on having access to either the complete target model (whitebox) or the model's soft-labels (blackbox). However, no prior work has been done in the harder but more practical scenario, in which the attacker only has access to the model's predicted label, without a confidence measure. In this paper, we introduce an algorithm, Boundary-Repelling Model Inversion (BREP-MI), to invert private training data using only the target model's predicted labels. The key idea of our algorithm is to evaluate the model's predicted labels over a sphere and then estimate the direction to reach the target class's centroid. Using the example of face recognition, we show that the images reconstructed by BREP-MI successfully reproduce the semantics of the private training data for various datasets and target model architectures. We compare BREP-MI with the state-of-the-art whitebox and blackbox model inversion attacks and the results show that despite assuming less knowledge about the target model, BREP-MI outperforms the blackbox attack and achieves comparable results to the whitebox attack. ",
    "url": "https://arxiv.org/abs/2203.01925",
    "authors": [
      "Mostafa Kahla",
      "Si Chen",
      "Hoang Anh Just",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.03379",
    "title": "Application of Ghost-DeblurGAN to Fiducial Marker Detection",
    "abstract": "Feature extraction or localization based on the fiducial marker could fail due to motion blur in real-world robotic applications. To solve this problem, a lightweight generative adversarial network, named Ghost-DeblurGAN, for real-time motion deblurring is developed in this paper. Furthermore, on account that there is no existing deblurring benchmark for such task, a new large-scale dataset, YorkTag, is proposed that provides pairs of sharp/blurred images containing fiducial markers. With the proposed model trained and tested on YorkTag, it is demonstrated that when applied along with fiducial marker systems to motion-blurred images, Ghost-DeblurGAN improves the marker detection significantly. The datasets and codes used in this paper are available at: https://github.com/York-SDCNLab/Ghost-DeblurGAN. ",
    "url": "https://arxiv.org/abs/2109.03379",
    "authors": [
      "Yibo Liu",
      "Amaldev Haridevan",
      "Hunter Schofield",
      "Jinjun Shan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.09661",
    "title": "Detection of Stealthy Adversaries for Networked Unmanned Aerial Vehicles",
    "abstract": "A network of unmanned aerial vehicles (UAVs) provides distributed coverage, reconfigurability, and maneuverability in performing complex cooperative tasks. However, it relies on wireless communications that can be susceptible to cyber adversaries and intrusions, disrupting the entire network's operation. This paper develops model-based centralized and decentralized observer techniques for detecting a class of stealthy intrusions, namely zero-dynamics and covert attacks, on networked UAVs in formation control settings. The centralized observer that runs in a control center leverages switching in the UAVs' communication topology for attack detection, and the decentralized observers, implemented onboard each UAV in the network, use the model of networked UAVs and locally available measurements. Experimental results are provided to show the effectiveness of the proposed detection schemes in different case studies. ",
    "url": "https://arxiv.org/abs/2202.09661",
    "authors": [
      "Mohammad Bahrami",
      "Hamidreza Jafarnejadsani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.01325",
    "title": "Self-Supervised Learning for Real-World Super-Resolution from Dual  Zoomed Observations",
    "abstract": "In this paper, we consider two challenging issues in reference-based super-resolution (RefSR), (i) how to choose a proper reference image, and (ii) how to learn real-world RefSR in a self-supervised manner. Particularly, we present a novel self-supervised learning approach for real-world image SR from observations at dual camera zooms (SelfDZSR). For the first issue, the more zoomed (telephoto) image can be naturally leveraged as the reference to guide the SR of the lesser zoomed (short-focus) image. For the second issue, SelfDZSR learns a deep network to obtain the SR result of short-focal image and with the same resolution as the telephoto image. For this purpose, we take the telephoto image instead of an additional high-resolution image as the supervision information and select a patch from it as the reference to super-resolve the corresponding short-focus image patch. To mitigate the effect of various misalignment between the short-focus low-resolution (LR) image and telephoto ground-truth (GT) image, we design a degradation model and map the GT to a pseudo-LR image aligned with GT. Then the pseudo-LR and LR image can be fed into the proposed adaptive spatial transformer networks (AdaSTN) to deform the LR features. During testing, SelfDZSR can be directly deployed to super-solve the whole short-focus image with the reference of telephoto image. Experiments show that our method achieves better quantitative and qualitative performance against state-of-the-arts. The code and pre-trained models will be publicly available. ",
    "url": "https://arxiv.org/abs/2203.01325",
    "authors": [
      "Zhilu Zhang",
      "Ruohao Wang",
      "Hongzhi Zhang",
      "Yunjin Chen",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01326",
    "title": "Precise Stock Price Prediction for Optimized Portfolio Design Using an  LSTM Model",
    "abstract": "Accurate prediction of future prices of stocks is a difficult task to perform. Even more challenging is to design an optimized portfolio of stocks with the identification of proper weights of allocation to achieve the optimized values of return and risk. We present optimized portfolios based on the seven sectors of the Indian economy. The past prices of the stocks are extracted from the web from January 1, 2016, to December 31, 2020. Optimum portfolios are designed on the selected seven sectors. An LSTM regression model is also designed for predicting future stock prices. Five months after the construction of the portfolios, i.e., on June 1, 2021, the actual and predicted returns and risks of each portfolio are computed. The predicted and the actual returns indicate the very high accuracy of the LSTM model. ",
    "url": "https://arxiv.org/abs/2203.01326",
    "authors": [
      "Jaydip Sen",
      "Sidra Mehtab",
      "Abhishek Dutta",
      "Saikat Mondal"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01573",
    "title": "The Vicomtech Audio Deepfake Detection System based on Wav2Vec2 for the  2022 ADD Challenge",
    "abstract": "This paper describes our submitted systems to the 2022 ADD challenge withing the tracks 1 and 2. Our approach is based on the combination of a pre-trained wav2vec2 feature extractor and a downstream classifier to detect spoofed audio. This method exploits the contextualized speech representations at the different transformer layers to fully capture discriminative information. Furthermore, the classification model is adapted to the application scenario using different data augmentation techniques. We evaluate our system for audio synthesis detection in both the ASVspoof 2021 and the 2022 ADD challenges, showing its robustness and good performance in realistic challenging environments such as telephonic and audio codec systems, noisy audio, and partial deepfakes. ",
    "url": "https://arxiv.org/abs/2203.01573",
    "authors": [
      "Juan M. Mart\u00edn-Do\u00f1as",
      "Aitor \u00c1lvarez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.01721",
    "title": "Asymptotic Optimality of Speed-Aware JSQ for Heterogeneous Systems",
    "abstract": "The Join-the-Shortest-Queue (JSQ) load-balancing scheme is known to minimise the average delay of jobs in homogeneous systems consisting of identical servers. However, it performs poorly in heterogeneous systems where servers have different processing rates. Finding a delay optimal scheme remains an open problem for heterogeneous systems. In this paper, we consider a speed-aware version of the JSQ scheme for heterogeneous systems and show that it achieves delay optimality in the fluid limit. One of the major technical challenges in establishing this optimality result for heterogeneous systems is to show that the sequence of steady-state distributions indexed by the system size is tight in an appropriately defined space. We prove this through the use of exponential Lyapunov functions. Another difficulty is the characterisation of the fluid-limit which involves the stationary probabilities of a certain multi-dimensional Markov chain. By characterising these stationary probabilities and using the motonicity of the system, we show that the fluid limit is unique and has a globally attractive fixed point. ",
    "url": "https://arxiv.org/abs/2203.01721",
    "authors": [
      "Sanidhay Bhambay",
      "Arpan Mukhopadhyay"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2203.01764",
    "title": "Random Quantum Neural Networks (RQNN) for Noisy Image Recognition",
    "abstract": "Classical Random Neural Networks (RNNs) have demonstrated effective applications in decision making, signal processing, and image recognition tasks. However, their implementation has been limited to deterministic digital systems that output probability distributions in lieu of stochastic behaviors of random spiking signals. We introduce the novel class of supervised Random Quantum Neural Networks (RQNNs) with a robust training strategy to better exploit the random nature of the spiking RNN. The proposed RQNN employs hybrid classical-quantum algorithms with superposition state and amplitude encoding features, inspired by quantum information theory and the brain's spatial-temporal stochastic spiking property of neuron information encoding. We have extensively validated our proposed RQNN model, relying on hybrid classical-quantum algorithms via the PennyLane Quantum simulator with a limited number of \\emph{qubits}. Experiments on the MNIST, FashionMNIST, and KMNIST datasets demonstrate that the proposed RQNN model achieves an average classification accuracy of $94.9\\%$. Additionally, the experimental findings illustrate the proposed RQNN's effectiveness and resilience in noisy settings, with enhanced image classification accuracy when compared to the classical counterparts (RNNs), classical Spiking Neural Networks (SNNs), and the classical convolutional neural network (AlexNet). Furthermore, the RQNN can deal with noise, which is useful for various applications, including computer vision in NISQ devices. The PyTorch code (https://github.com/darthsimpus/RQN) is made available on GitHub to reproduce the results reported in this manuscript. ",
    "url": "https://arxiv.org/abs/2203.01764",
    "authors": [
      "Debanjan Konar",
      "Erol Gelenbe",
      "Soham Bhandary",
      "Aditya Das Sarma",
      "Attila Cangi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.01818",
    "title": "ADPCM with nonlinear prediction",
    "abstract": "Many speech coders are based on linear prediction coding (LPC), nevertheless with LPC is not possible to model the nonlinearities present in the speech signal. Because of this there is a growing interest for nonlinear techniques. In this paper we discuss ADPCM schemes with a nonlinear predictor based on neural nets, which yields an increase of 1-2.5dB in the SEGSNR over classical methods. This paper will discuss the block-adaptive and sample-adaptive predictions. ",
    "url": "https://arxiv.org/abs/2203.01818",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Oscar Oliva-Suarez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01826",
    "title": "Improving Non-native Word-level Pronunciation Scoring with Phone-level  Mixup Data Augmentation and Multi-source Information",
    "abstract": "Deep learning-based pronunciation scoring models highly rely on the availability of the annotated non-native data, which is costly and has scalability issues. To deal with the data scarcity problem, data augmentation is commonly used for model pretraining. In this paper, we propose a phone-level mixup, a simple yet effective data augmentation method, to improve the performance of word-level pronunciation scoring. Specifically, given a phoneme sequence from lexicon, the artificial augmented word sample can be generated by randomly sampling from the corresponding phone-level features in training data, while the word score is the average of their GOP scores. Benefit from the arbitrary phone-level combination, the mixup is able to generate any word with various pronunciation scores. Moreover, we utilize multi-source information (e.g., MFCC and deep features) to further improve the scoring system performance. The experiments conducted on the Speechocean762 show that the proposed system outperforms the baseline by adding the mixup data for pretraining, with Pearson correlation coefficients (PCC) increasing from 0.567 to 0.61. The results also indicate that proposed method achieves similar performance by using 1/10 unlabeled data of baseline. In addition, the experimental results also demonstrate the efficiency of our proposed multi-source approach. ",
    "url": "https://arxiv.org/abs/2203.01826",
    "authors": [
      "Kaiqi Fu",
      "Shaojun Gao",
      "Kai Wang",
      "Wei Li",
      "Xiaohai Tian",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01829",
    "title": "A Brief Overview of Unsupervised Neural Speech Representation Learning",
    "abstract": "Unsupervised representation learning for speech processing has matured greatly in the last few years. Work in computer vision and natural language processing has paved the way, but speech data offers unique challenges. As a result, methods from other domains rarely translate directly. We review the development of unsupervised representation learning for speech over the last decade. We identify two primary model categories: self-supervised methods and probabilistic latent variable models. We describe the models and develop a comprehensive taxonomy. Finally, we discuss and compare models from the two categories. ",
    "url": "https://arxiv.org/abs/2203.01829",
    "authors": [
      "Lasse Borgholt",
      "Jakob Drachmann Havtorn",
      "Joakim Edin",
      "Lars Maal\u00f8e",
      "Christian Igel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.01830",
    "title": "Understanding microbiome dynamics via interpretable graph representation  learning",
    "abstract": "Large-scale perturbations in the microbiome constitution are strongly correlated, whether as a driver or a consequence, with the health and functioning of human physiology. However, understanding the difference in the microbiome profiles of healthy and ill individuals can be complicated due to the large number of complex interactions among microbes. We propose to model these interactions as a time-evolving graph whose nodes are microbes and edges are interactions among them. Motivated by the need to analyse such complex interactions, we develop a method that learns a low-dimensional representation of the time-evolving graph and maintains the dynamics occurring in the high-dimensional space. Through our experiments, we show that we can extract graph features such as clusters of nodes or edges that have the highest impact on the model to learn the low-dimensional representation. This information can be crucial to identify microbes and interactions among them that are strongly correlated with clinical diseases. We conduct our experiments on both synthetic and real-world microbiome datasets. ",
    "url": "https://arxiv.org/abs/2203.01830",
    "authors": [
      "Kateryna Melnyk",
      "Kuba Weimann",
      "Tim O.F. Conrad"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.01862",
    "title": "The world seems different in a social context: a neural network analysis  of human experimental data",
    "abstract": "Human perception and behavior are affected by the situational context, in particular during social interactions. A recent study demonstrated that humans perceive visual stimuli differently depending on whether they do the task by themselves or together with a robot. Specifically, it was found that the central tendency effect is stronger in social than in non-social task settings. The particular nature of such behavioral changes induced by social interaction, and their underlying cognitive processes in the human brain are, however, still not well understood. In this paper, we address this question by training an artificial neural network inspired by the predictive coding theory on the above behavioral data set. Using this computational model, we investigate whether the change in behavior that was caused by the situational context in the human experiment could be explained by continuous modifications of a parameter expressing how strongly sensory and prior information affect perception. We demonstrate that it is possible to replicate human behavioral data in both individual and social task settings by modifying the precision of prior and sensory signals, indicating that social and non-social task settings might in fact exist on a continuum. At the same time an analysis of the neural activation traces of the trained networks provides evidence that information is coded in fundamentally different ways in the network in the individual and in the social conditions. Our results emphasize the importance of computational replications of behavioral data for generating hypotheses on the underlying cognitive mechanisms of shared perception and may provide inspiration for follow-up studies in the field of neuroscience. ",
    "url": "https://arxiv.org/abs/2203.01862",
    "authors": [
      "Maria Tsfasman",
      "Anja Philippsen",
      "Carlo Mazzola",
      "Serge Thill",
      "Alessandra Sciutti",
      "Yukie Nagai"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01870",
    "title": "KamNet: An Integrated Spatiotemporal Deep Neural Network for Rare Event  Search in KamLAND-Zen",
    "abstract": "Rare event searches allow us to search for new physics at energy scales inaccessible with other means by leveraging specialized large-mass detectors. Machine learning provides a new tool to maximize the information provided by these detectors. The information is sparse, which forces these algorithms to start from the lowest level data and exploit all symmetries in the detector to produce results. In this work we present KamNet which harnesses breakthroughs in geometric deep learning and spatiotemporal data analysis to maximize the physics reach of KamLAND-Zen, a kiloton scale spherical liquid scintillator detector searching for neutrinoless double beta decay ($0\\nu\\beta\\beta$). Using a simplified background model for KamLAND we show that KamNet outperforms a conventional CNN on benchmarking MC simulations with an increasing level of robustness. Using simulated data, we then demonstrate KamNet's ability to increase KamLAND-Zen's sensitivity to $0\\nu\\beta\\beta$ and $0\\nu\\beta\\beta$ to excited states. A key component of this work is the addition of an attention mechanism to elucidate the underlying physics KamNet is using for the background rejection. ",
    "url": "https://arxiv.org/abs/2203.01870",
    "authors": [
      "Aobo Li",
      "Zhenghao Fu",
      "Lindley A. Winslow",
      "Christopher P. Grant",
      "Hasung Song",
      "Hideyoshi Ozaki",
      "Itaru Shimizu",
      "Atsuto Takeuchi"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01883",
    "title": "ROCT-Net: A new ensemble deep convolutional model with improved spatial  resolution learning for detecting common diseases from retinal OCT images",
    "abstract": "Optical coherence tomography (OCT) imaging is a well-known technology for visualizing retinal layers and helps ophthalmologists to detect possible diseases. Accurate and early diagnosis of common retinal diseases can prevent the patients from suffering critical damages to their vision. Computer-aided diagnosis (CAD) systems can significantly assist ophthalmologists in improving their examinations. This paper presents a new enhanced deep ensemble convolutional neural network for detecting retinal diseases from OCT images. Our model generates rich and multi-resolution features by employing the learning architectures of two robust convolutional models. Spatial resolution is a critical factor in medical images, especially the OCT images that contain tiny essential points. To empower our model, we apply a new post-architecture model to our ensemble model for enhancing spatial resolution learning without increasing computational costs. The introduced post-architecture model can be deployed to any feature extraction model to improve the utilization of the feature map's spatial values. We have collected two open-source datasets for our experiments to make our models capable of detecting six crucial retinal diseases: Age-related Macular Degeneration (AMD), Central Serous Retinopathy (CSR), Diabetic Retinopathy (DR), Choroidal Neovascularization (CNV), Diabetic Macular Edema (DME), and Drusen alongside the normal cases. Our experiments on two datasets and comparing our model with some other well-known deep convolutional neural networks have proven that our architecture can increase the classification accuracy up to 5%. We hope that our proposed methods create the next step of CAD systems development and help future researches. The code of this paper is shared at https://github.com/mr7495/OCT-classification. ",
    "url": "https://arxiv.org/abs/2203.01883",
    "authors": [
      "Mohammad Rahimzadeh",
      "Mahmoud Reza Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01907",
    "title": "Computer Vision Aided Blockage Prediction in Real-World Millimeter Wave  Deployments",
    "abstract": "This paper provides the first real-world evaluation of using visual (RGB camera) data and machine learning for proactively predicting millimeter wave (mmWave) dynamic link blockages before they happen. Proactively predicting line-of-sight (LOS) link blockages enables mmWave/sub-THz networks to make proactive network management decisions, such as proactive beam switching and hand-off) before a link failure happens. This can significantly enhance the network reliability and latency while efficiently utilizing the wireless resources. To evaluate this gain in reality, this paper (i) develops a computer vision based solution that processes the visual data captured by a camera installed at the infrastructure node and (ii) studies the feasibility of the proposed solution based on the large-scale real-world dataset, DeepSense 6G, that comprises multi-modal sensing and communication data. Based on the adopted real-world dataset, the developed solution achieves $\\approx 90\\%$ accuracy in predicting blockages happening within the future $0.1$s and $\\approx 80\\%$ for blockages happening within $1$s, which highlights a promising solution for mmWave/sub-THz communication networks. ",
    "url": "https://arxiv.org/abs/2203.01907",
    "authors": [
      "Gouranga Charan",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01910",
    "title": "Efficient Data Structures for Exploiting Sparsity and Structure in  Representation of Polynomial Optimization Problems: Implementation in  SOSTOOLS",
    "abstract": "We present a new data structure for representation of polynomial variables in the parsing of sum-of-squares (SOS) programs. In SOS programs, the variables $s(x;P)$ are polynomial in the independent variables $x$, but linear in the decision variables $P$. Current SOS parsers, however, fail to exploit the semi-linear structure of the polynomial variables, treating the decision variables as independent variables in their representation. This results in unnecessary overhead in storage and manipulation of the polynomial variables, prohibiting the parser from addressing larger-scale optimization problems. To eliminate this computational overhead, we introduce a new representation of polynomial variables, the \"dpvar\" structure, that is affine in the decision variables. We show that the complexity of operations on variables in the dpvar representation scales favorably with the number of decision variables. We further show that the required memory for storing polynomial variables is relatively small using the dpvar structure, particularly when exploiting the MATLAB sparse storage structure. Finally, we incorporate the dpvar data structure into SOSTOOLS 4.00, and test the performance of the parser for several polynomial optimization problems. ",
    "url": "https://arxiv.org/abs/2203.01910",
    "authors": [
      "Declan Jagt",
      "Sachin Shivakumar",
      "Peter Seiler",
      "Matthew Peet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2203.01912",
    "title": "Bayesian Spillover Graphs for Dynamic Networks",
    "abstract": "We present Bayesian Spillover Graphs (BSG), a novel method for learning temporal relationships, identifying critical nodes, and quantifying uncertainty for multi-horizon spillover effects in a dynamic system. BSG leverages both an interpretable framework via forecast error variance decompositions (FEVD) and comprehensive uncertainty quantification via Bayesian time series models to contextualize temporal relationships in terms of systemic risk and prediction variability. Forecast horizon hyperparameter $h$ allows for learning both short-term and equilibrium state network behaviors. Experiments for identifying source and sink nodes under various graph and error specifications show significant performance gains against state-of-the-art Bayesian Networks and deep-learning baselines. Applications to real-world systems also showcase BSG as an exploratory analysis tool for uncovering indirect spillovers and quantifying risk. ",
    "url": "https://arxiv.org/abs/2203.01912",
    "authors": [
      "Grace Deng",
      "David S. Matteson"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1812.10097",
    "title": "Trip Prediction by Leveraging Trip Histories from Neighboring Users",
    "abstract": " Title: Trip Prediction by Leveraging Trip Histories from Neighboring Users ",
    "url": "https://arxiv.org/abs/1812.10097",
    "authors": [
      "Yuxin Chen",
      "Morteza Haghir Chehreghani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1910.05513",
    "title": "On Robustness of Neural Ordinary Differential Equations",
    "abstract": " Title: On Robustness of Neural Ordinary Differential Equations ",
    "url": "https://arxiv.org/abs/1910.05513",
    "authors": [
      "Hanshu Yan",
      "Jiawei Du",
      "Vincent Y. F. Tan",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1912.01452",
    "title": "Assessing the Robustness of Visual Question Answering Models",
    "abstract": " Comments: 24 pages, 13 figures, International Journal of Computer Vision (IJCV) [under review]. arXiv admin note: substantial text overlap with arXiv:1711.06232, arXiv:1709.04625 ",
    "url": "https://arxiv.org/abs/1912.01452",
    "authors": [
      "Jia-Hong Huang",
      "Modar Alfadly",
      "Bernard Ghanem",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2002.07606",
    "title": "Scheduling periodic messages on a shared link",
    "abstract": " Comments: 30 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2002.07606",
    "authors": [
      "Ma\u00ebl Guiraud",
      "Yann Strozecki"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2006.09911",
    "title": "Image Response Regression via Deep Neural Networks",
    "abstract": " Title: Image Response Regression via Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2006.09911",
    "authors": [
      "Daiwei Zhang",
      "Lexin Li",
      "Chandra Sripada",
      "Jian Kang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2009.14681",
    "title": "Encoding cloth manipulations using a graph of states and transitions",
    "abstract": " Comments: 6 pages, 7 figures, submitted ",
    "url": "https://arxiv.org/abs/2009.14681",
    "authors": [
      "J\u00falia Borr\u00e0s",
      "Guillem Aleny\u00e0",
      "Carme Torras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.01282",
    "title": "Progressive Localization Networks for Language-based Moment Localization",
    "abstract": " Comments: submited to TOMM ",
    "url": "https://arxiv.org/abs/2102.01282",
    "authors": [
      "Qi Zheng",
      "Jianfeng Dong",
      "Xiaoye Qu",
      "Xun Yang",
      "Yabing Wang",
      "Pan Zhou",
      "Baolong Liu",
      "Xun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.00959",
    "title": "CogDL: A Toolkit for Deep Learning on Graphs",
    "abstract": " Title: CogDL: A Toolkit for Deep Learning on Graphs ",
    "url": "https://arxiv.org/abs/2103.00959",
    "authors": [
      "Yukuo Cen",
      "Zhenyu Hou",
      "Yan Wang",
      "Qibin Chen",
      "Yizhen Luo",
      "Zhongming Yu",
      "Hengrui Zhang",
      "Xingcheng Yao",
      "Aohan Zeng",
      "Shiguang Guo",
      "Yuxiao Dong",
      "Yang Yang",
      "Peng Zhang",
      "Guohao Dai",
      "Yu Wang",
      "Chang Zhou",
      "Hongxia Yang",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.04053",
    "title": "NVUM: Non-Volatile Unbiased Memory for Robust Medical Image  Classification",
    "abstract": " Title: NVUM: Non-Volatile Unbiased Memory for Robust Medical Image  Classification ",
    "url": "https://arxiv.org/abs/2103.04053",
    "authors": [
      "Fengbei Liu",
      "Yuanhong Chen",
      "Yu Tian",
      "Yuyuan Liu",
      "Chong Wang",
      "Vasileios Belagiannis",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.09351",
    "title": "Optimizing Edge Sets in Networks to Produce Ground Truth Communities  Based on Modularity",
    "abstract": " Title: Optimizing Edge Sets in Networks to Produce Ground Truth Communities  Based on Modularity ",
    "url": "https://arxiv.org/abs/2103.09351",
    "authors": [
      "Daniel Kosmas",
      "John E. Mitchell",
      "Thomas C. Sharkey",
      "Boleslaw K. Szymanski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2104.09425",
    "title": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve  Adversarial Robustness?",
    "abstract": " Comments: ICLR 2022 version (30 pages, 13 figures, 12 tables) ",
    "url": "https://arxiv.org/abs/2104.09425",
    "authors": [
      "Vikash Sehwag",
      "Saeed Mahloujifar",
      "Tinashe Handina",
      "Sihui Dai",
      "Chong Xiang",
      "Mung Chiang",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.14132",
    "title": "Generalization Guarantees for Neural Architecture Search with  Train-Validation Split",
    "abstract": " Comments: ICML 2021 ",
    "url": "https://arxiv.org/abs/2104.14132",
    "authors": [
      "Samet Oymak",
      "Mingchen Li",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.08023",
    "title": "Removing Data Heterogeneity Influence Enhances Network Topology  Dependence of Decentralized SGD",
    "abstract": " Title: Removing Data Heterogeneity Influence Enhances Network Topology  Dependence of Decentralized SGD ",
    "url": "https://arxiv.org/abs/2105.08023",
    "authors": [
      "Kun Yuan",
      "Sulaiman A. Alghunaim",
      "Xinmeng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.04169",
    "title": "On Improving Adversarial Transferability of Vision Transformers",
    "abstract": " Comments: ICLR'22 (Spotlight), the first two authors contributed equally. Code: this https URL ",
    "url": "https://arxiv.org/abs/2106.04169",
    "authors": [
      "Muzammal Naseer",
      "Kanchana Ranasinghe",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.08609",
    "title": "Reinforcement learning for pursuit and evasion of microswimmers at low  Reynolds number",
    "abstract": " Comments: 20 pages, 5 figures (Supplementary Material in ancillary directory) ",
    "url": "https://arxiv.org/abs/2106.08609",
    "authors": [
      "Francesco Borra",
      "Luca Biferale",
      "Massimo Cencini",
      "Antonio Celani"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2106.13898",
    "title": "Closed-form Continuous-time Neural Models",
    "abstract": " Comments: 40 pages ",
    "url": "https://arxiv.org/abs/2106.13898",
    "authors": [
      "Ramin Hasani",
      "Mathias Lechner",
      "Alexander Amini",
      "Lucas Liebenwein",
      "Aaron Ray",
      "Max Tschaikowski",
      "Gerald Teschl",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2109.08830",
    "title": "Multilingual Molecular Representation Learning via Contrastive  Pre-training",
    "abstract": " Comments: Accepted to ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2109.08830",
    "authors": [
      "Zhihui Guo",
      "Pramod Sharma",
      "Andy Martinez",
      "Liang Du",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2109.10072",
    "title": "Scenario generation for market risk models using generative neural  networks",
    "abstract": " Title: Scenario generation for market risk models using generative neural  networks ",
    "url": "https://arxiv.org/abs/2109.10072",
    "authors": [
      "Solveig Flaig",
      "Gero Junike"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2109.11488",
    "title": "Characterization of Real-time Haptic Feedback from Multimodal Neural  Network-based Force Estimates during Teleoperation",
    "abstract": " Comments: 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2109.11488",
    "authors": [
      "Zonghe Chua",
      "Allison M. Okamura"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.03037",
    "title": "Reactive Locomotion Decision-Making and Robust Motion Planning for  Real-Time Perturbation Recovery",
    "abstract": " Title: Reactive Locomotion Decision-Making and Robust Motion Planning for  Real-Time Perturbation Recovery ",
    "url": "https://arxiv.org/abs/2110.03037",
    "authors": [
      "Zhaoyuan Gu",
      "Nathan Boyd",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.05876",
    "title": "Label-Aware Ranked Loss for robust People Counting using Automotive  in-cabin Radar",
    "abstract": " Comments: accepted at ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.05876",
    "authors": [
      "Lorenzo Servadei",
      "Huawei Sun",
      "Julius Ott",
      "Michael Stephan",
      "Souvik Hazra",
      "Thomas Stadelmayer",
      "Daniela Sanchez Lopera",
      "Robert Wille",
      "Avik Santra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07470",
    "title": "Universally Rank Consistent Ordinal Regression in Neural Networks",
    "abstract": " Title: Universally Rank Consistent Ordinal Regression in Neural Networks ",
    "url": "https://arxiv.org/abs/2110.07470",
    "authors": [
      "Garrett Jenkinson",
      "Gavin R. Oliver",
      "Kia Khezeli",
      "John Kalantari",
      "Eric W. Klee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.13694",
    "title": "A Horizon Detection Algorithm for Maritime Surveillance",
    "abstract": " Title: A Horizon Detection Algorithm for Maritime Surveillance ",
    "url": "https://arxiv.org/abs/2110.13694",
    "authors": [
      "Yassir Zardoua",
      "Astito Abdelali",
      "Boulaala Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.15163",
    "title": "Authentication Attacks on Projection-based Cancelable Biometric Schemes",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1910.01389 by other authors ",
    "url": "https://arxiv.org/abs/2110.15163",
    "authors": [
      "Axel Durbet",
      "Pascal Lafourcade",
      "Denis Migdal",
      "Kevin Thiry-Atighehchi",
      "Paul-Marie Grollemund"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.01166",
    "title": "Investigating the locality of neural network training dynamics",
    "abstract": " Comments: 12 pages (double column) + 6 pages (single column) ",
    "url": "https://arxiv.org/abs/2111.01166",
    "authors": [
      "Soham Dan",
      "Phanideep Gampa",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.09099",
    "title": "Self-Supervised Predictive Convolutional Attentive Block for Anomaly  Detection",
    "abstract": " Comments: Accepted at CVPR 2022. Paper + supplementary (14 pages, 9 figures) ",
    "url": "https://arxiv.org/abs/2111.09099",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Neelu Madan",
      "Radu Tudor Ionescu",
      "Kamal Nasrollahi",
      "Fahad Shahbaz Khan",
      "Thomas B. Moeslund",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10969",
    "title": "Medical Aegis: Robust adversarial protectors for medical images",
    "abstract": " Title: Medical Aegis: Robust adversarial protectors for medical images ",
    "url": "https://arxiv.org/abs/2111.10969",
    "authors": [
      "Qingsong Yao",
      "Zecheng He",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13216",
    "title": "Cross-Domain Object Detection via Adaptive Self-Training",
    "abstract": " Comments: 10 pages including references ",
    "url": "https://arxiv.org/abs/2111.13216",
    "authors": [
      "Yu-Jhe Li",
      "Xiaoliang Dai",
      "Chih-Yao Ma",
      "Yen-Cheng Liu",
      "Kan Chen",
      "Bichen Wu",
      "Zijian He",
      "Kris Kitani",
      "Peter Vajda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.15430",
    "title": "The Devil is in the Margin: Margin-based Label Smoothing for Network  Calibration",
    "abstract": " Comments: To Appear at CVPR 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2111.15430",
    "authors": [
      "Bingyuan Liu",
      "Ismail Ben Ayed",
      "Adrian Galdran",
      "Jose Dolz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04108",
    "title": "Fully Attentional Network for Semantic Segmentation",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2112.04108",
    "authors": [
      "Qi Song",
      "Jie Li",
      "Chenghong Li",
      "Hao Guo",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04222",
    "title": "Classification-Then-Grounding: Reformulating Video Scene Graphs as  Temporal Bipartite Graphs",
    "abstract": " Comments: 12 pages, 8 figures. Accepted by CVPR 2022. We also won the 1st place of Video Relation Understanding (VRU) Grand Challenge in ACM Multimedia 2021, with a simplified version of our model.(The code for object tracklets generation is available at this https URL). We will also release the code for this CVPR paper before March 28, 2022 ",
    "url": "https://arxiv.org/abs/2112.04222",
    "authors": [
      "Kaifeng Gao",
      "Long Chen",
      "Yulei Niu",
      "Jian Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2112.08196",
    "title": "Generative Adversarial Networks for Data Generation in Structural Health  Monitoring",
    "abstract": " Title: Generative Adversarial Networks for Data Generation in Structural Health  Monitoring ",
    "url": "https://arxiv.org/abs/2112.08196",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2201.01486",
    "title": "Sign Language Recognition System using TensorFlow Object Detection API",
    "abstract": " Comments: 14 pages, 5 figures, ANTIC 2021 ",
    "url": "https://arxiv.org/abs/2201.01486",
    "authors": [
      "Sharvani Srivastava",
      "Amisha Gangwar",
      "Richa Mishra",
      "Sudhakar Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2201.02863",
    "title": "PocketNN: Integer-only Training and Inference of Neural Networks via  Direct Feedback Alignment and Pocket Activations in Pure C++",
    "abstract": " Comments: Accepted in tinyML Research Symposium '22, March 2022, San Jose, CA (TinyML 2022). 7 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2201.02863",
    "authors": [
      "Jaewoo Song",
      "Fangzhen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.09051",
    "title": "On the Robustness of Counterfactual Explanations to Adverse  Perturbations",
    "abstract": " Comments: - added a few more relevant references - added link to cogs repo in the appendix ",
    "url": "https://arxiv.org/abs/2201.09051",
    "authors": [
      "Marco Virgolin",
      "Saverio Fracaros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09168",
    "title": "Reading-strategy Inspired Visual Representation Learning for  Text-to-Video Retrieval",
    "abstract": " Comments: Accepted by IEEE Transactions on Circuits and Systems for Video Technology. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2201.09168",
    "authors": [
      "Jianfeng Dong",
      "Yabing Wang",
      "Xianke Chen",
      "Xiaoye Qu",
      "Xirong Li",
      "Yuan He",
      "Xun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2202.01417",
    "title": "Generalized Omega Turn Gait Enables Agile Limbless Robot Turning in  Complex Environments",
    "abstract": " Comments: Accepted to ICRA 2022 ",
    "url": "https://arxiv.org/abs/2202.01417",
    "authors": [
      "Tianyu Wang",
      "Baxi Chong",
      "Yuelin Deng",
      "Ruijie Fu",
      "Howie Choset",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01891",
    "title": "Weighted Random Cut Forest Algorithm for Anomaly Detection",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/2202.01891",
    "authors": [
      "Sijin Yeom",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06491",
    "title": "Adversarial Graph Contrastive Learning with Information Regularization",
    "abstract": " Comments: WWW 2022 ",
    "url": "https://arxiv.org/abs/2202.06491",
    "authors": [
      "Shengyu Feng",
      "Baoyu Jing",
      "Yada Zhu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06509",
    "title": "A Novel Transfer Learning Framework with Prototypical Representation  based Pairwise Learning for Cross-Subject Cross-Session EEG-Based Emotion  Recognition",
    "abstract": " Title: A Novel Transfer Learning Framework with Prototypical Representation  based Pairwise Learning for Cross-Subject Cross-Session EEG-Based Emotion  Recognition ",
    "url": "https://arxiv.org/abs/2202.06509",
    "authors": [
      "Rushuang Zhou",
      "Zhiguo Zhang",
      "Xin Yang",
      "Hong Fu",
      "Li Zhang",
      "Linling Li",
      "Gan Huang",
      "Yining Dong",
      "Fali Li",
      "Zhen Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2202.07831",
    "title": "CycleGAN for Undamaged-to-Damaged Domain Translation for Structural  Health Monitoring and Damage Detection",
    "abstract": " Title: CycleGAN for Undamaged-to-Damaged Domain Translation for Structural  Health Monitoring and Damage Detection ",
    "url": "https://arxiv.org/abs/2202.07831",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.09741",
    "title": "Visual Attention Network",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.09741",
    "authors": [
      "Meng-Hao Guo",
      "Cheng-Ze Lu",
      "Zheng-Ning Liu",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.12138",
    "title": "How reparametrization trick broke differentially-private text  representation learning",
    "abstract": " Comments: Pre-print version; Accepted at ACL 2022; (v2: fixing title typo) ",
    "url": "https://arxiv.org/abs/2202.12138",
    "authors": [
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00048",
    "title": "Multi-modal Alignment using Representation Codebook",
    "abstract": " Title: Multi-modal Alignment using Representation Codebook ",
    "url": "https://arxiv.org/abs/2203.00048",
    "authors": [
      "Jiali Duan",
      "Liqun Chen",
      "Son Tran",
      "Jinyu Yang",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00199",
    "title": "Equivariant and Stable Positional Encoding for More Powerful Graph  Neural Networks",
    "abstract": " Comments: ICLR 2022; code available at this https URL ",
    "url": "https://arxiv.org/abs/2203.00199",
    "authors": [
      "Haorui Wang",
      "Haoteng Yin",
      "Muhan Zhang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.00438",
    "title": "An Analytical Approach to Compute the Exact Preimage of Feed-Forward  Neural Networks",
    "abstract": " Title: An Analytical Approach to Compute the Exact Preimage of Feed-Forward  Neural Networks ",
    "url": "https://arxiv.org/abs/2203.00438",
    "authors": [
      "Th\u00e9o Nancy",
      "Vassili Maillet",
      "Johann Barbier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00551",
    "title": "Bayesian Optimisation for Robust Model Predictive Control under Model  Parameter Uncertainty",
    "abstract": " Comments: Paper accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA ",
    "url": "https://arxiv.org/abs/2203.00551",
    "authors": [
      "Rel Guzman",
      "Rafael Oliveira",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.01216",
    "title": "A Simple and Universal Rotation Equivariant Point-cloud Network",
    "abstract": " Title: A Simple and Universal Rotation Equivariant Point-cloud Network ",
    "url": "https://arxiv.org/abs/2203.01216",
    "authors": [
      "Ben Finkelshtein",
      "Chaim Baskin",
      "Haggai Maron",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01236",
    "title": "Convolutional neural networks as an alternative to Bayesian retrievals",
    "abstract": " Comments: Accepted for publication in A&A ",
    "url": "https://arxiv.org/abs/2203.01236",
    "authors": [
      "Francisco Ardevol Martinez",
      "Michiel Min",
      "Inga Kamp",
      "Paul I. Palmer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01298",
    "title": "Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP",
    "abstract": " Title: Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP ",
    "url": "https://arxiv.org/abs/2203.01298",
    "authors": [
      "Ishaan Mehta",
      "Sajad Saeedi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]