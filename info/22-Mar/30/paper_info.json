[
  {
    "id": "arXiv:2203.14961",
    "title": "A Deep Learning Approach for Thermal Plume Prediction of Groundwater  Heat Pumps",
    "abstract": "Climate control of buildings makes up a significant portion of global energy consumption, with groundwater heat pumps providing a suitable alternative. To prevent possibly negative interactions between heat pumps throughout a city, city planners have to optimize their layouts in the future. We develop a novel data-driven approach for building small-scale surrogates for modelling the thermal plumes generated by groundwater heat pumps in the surrounding subsurface water. Building on a data set generated from 2D numerical simulations, we train a convolutional neural network for predicting steady-state subsurface temperature fields from a given subsurface velocity field. We show that compared to existing models ours can capture more complex dynamics while still being quick to compute. The resulting surrogate is thus well-suited for interactive design tools by city planners. ",
    "url": "https://arxiv.org/abs/2203.14961",
    "authors": [
      "Raphael Leiteritz",
      "Kyle Davis",
      "Miriam Schulte",
      "Dirk Pfl\u00fcger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2203.14965",
    "title": "A Systematic Survey of Attack Detection and Prevention in Connected and  Autonomous Vehicles",
    "abstract": "The number of Connected and Autonomous Vehicles (CAVs) is increasing rapidly in various smart transportation services and applications due to many benefits to society, people, and the environment. Several research surveys were conducted in the domain of CAVs. Such surveys primarily focus on various security threats and vulnerabilities in the domain of CAVs to classify different types of attacks, impacts of attacks, attacks features, cyber-risk, defense methodologies against attacks, and safety standards in CAVs. However, the importance of attacks detection and prevention approaches for CAVs has not been discussed extensively in the state-of-the-art surveys, and there is a clear gap in the existing literature on such methodologies to detect new and conventional threats and protect the CAV system from unexpected hazards on the road. There are some surveys with a limited discussion on Attacks Detection and Prevention Systems (ADPS), but such surveys provide only partial coverage of different types of ADPS for CAVs. Furthermore, there is a scope for discussing security, privacy, and efficiency challenges in ADPS that can give an overview of important security and performance attributes. This survey paper presents the significance of CAVs, potential challenges in CAVs, and an explanation of important security and privacy properties, attack scenarios, possible attacks in CAV, and performance evaluation parameters for ADPS. This survey paper extensively provides a discussion on the overview of different ADPS categories and state-of-the-art research works based on each ADPS category that gives the latest findings in this research domain. This survey also discusses crucial and open security research problems that are required to be focused on a secure deployment of CAVs in the market. ",
    "url": "https://arxiv.org/abs/2203.14965",
    "authors": [
      "Trupil Limbasiya",
      "Ko Zheng Teng",
      "Sudipta Chattopadhyay",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.14966",
    "title": "Error Correction Code Transformer",
    "abstract": "Error correction code is a major part of the communication physical layer, ensuring the reliable transfer of data over noisy channels. Recently, neural decoders were shown to outperform classical decoding techniques. However, the existing neural approaches present strong overfitting due to the exponential training complexity, or a restrictive inductive bias due to reliance on Belief Propagation. Recently, Transformers have become methods of choice in many applications thanks to their ability to represent complex interactions between elements. In this work, we propose to extend for the first time the Transformer architecture to the soft decoding of linear codes at arbitrary block lengths. We encode each channel's output dimension to high dimension for better representation of the bits information to be processed separately. The element-wise processing allows the analysis of the channel output reliability, while the algebraic code and the interaction between the bits are inserted into the model via an adapted masked self-attention module. The proposed approach demonstrates the extreme power and flexibility of Transformers and outperforms existing state-of-the-art neural decoders by large margins at a fraction of their time complexity. ",
    "url": "https://arxiv.org/abs/2203.14966",
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.14987",
    "title": "Multilingual Knowledge Graph Completion with Self-Supervised Adaptive  Graph Alignment",
    "abstract": "Predicting missing facts in a knowledge graph (KG) is crucial as modern KGs are far from complete. Due to labor-intensive human labeling, this phenomenon deteriorates when handling knowledge represented in various languages. In this paper, we explore multilingual KG completion, which leverages limited seed alignment as a bridge, to embrace the collective knowledge from multiple languages. However, language alignment used in prior works is still not fully exploited: (1) alignment pairs are treated equally to maximally push parallel entities to be close, which ignores KG capacity inconsistency; (2) seed alignment is scarce and new alignment identification is usually in a noisily unsupervised manner. To tackle these issues, we propose a novel self-supervised adaptive graph alignment (SS-AGA) method. Specifically, SS-AGA fuses all KGs as a whole graph by regarding alignment as a new edge type. As such, information propagation and noise influence across KGs can be adaptively controlled via relation-aware attention weights. Meanwhile, SS-AGA features a new pair generator that dynamically captures potential alignment pairs in a self-supervised paradigm. Extensive experiments on both the public multilingual DBPedia KG and newly-created industrial multilingual E-commerce KG empirically demonstrate the effectiveness of SS-AG ",
    "url": "https://arxiv.org/abs/2203.14987",
    "authors": [
      "Zijie Huang",
      "Zheng Li",
      "Haoming Jiang",
      "Tianyu Cao",
      "Hanqing Lu",
      "Bing Yin",
      "Karthik Subbian",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.15004",
    "title": "Offline-Online Learning of Deformation Model for Cable Manipulation with  Graph Neural Networks",
    "abstract": "Manipulating deformable linear objects by robots has a wide range of applications, e.g., manufacturing and medical surgery. To complete such tasks, an accurate dynamics model for predicting the deformation is critical for robust control. In this work, we deal with this challenge by proposing a hybrid offline-online method to learn the dynamics of cables in a robust and data-efficient manner. In the offline phase, we adopt Graph Neural Network (GNN) to learn the deformation dynamics purely from the simulation data. Then a linear residual model is learned in real-time to bridge the sim-to-real gap. The learned model is then utilized as the dynamics constraint of a trust region based Model Predictive Controller (MPC) to calculate the optimal robot movements. The online learning and MPC run in a closed-loop manner to robustly accomplish the task. Finally, comparative results with existing methods are provided to quantitatively show the effectiveness and robustness. ",
    "url": "https://arxiv.org/abs/2203.15004",
    "authors": [
      "Changhao Wang",
      "Yuyou Zhang",
      "Xiang Zhang",
      "Zheng Wu",
      "Xinghao Zhu",
      "Shiyu Jin",
      "Te Tang",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15021",
    "title": "Few-Shot Object Detection with Fully Cross-Transformer",
    "abstract": "Few-shot object detection (FSOD), with the aim to detect novel objects using very few training examples, has recently attracted great research interest in the community. Metric-learning based methods have been demonstrated to be effective for this task using a two-branch based siamese network, and calculate the similarity between image regions and few-shot examples for detection. However, in previous works, the interaction between the two branches is only restricted in the detection head, while leaving the remaining hundreds of layers for separate feature extraction. Inspired by the recent work on vision transformers and vision-language transformers, we propose a novel Fully Cross-Transformer based model (FCT) for FSOD by incorporating cross-transformer into both the feature backbone and detection head. The asymmetric-batched cross-attention is proposed to aggregate the key information from the two branches with different batch sizes. Our model can improve the few-shot similarity learning between the two branches by introducing the multi-level interactions. Comprehensive experiments on both PASCAL VOC and MSCOCO FSOD benchmarks demonstrate the effectiveness of our model. ",
    "url": "https://arxiv.org/abs/2203.15021",
    "authors": [
      "Guangxing Han",
      "Jiawei Ma",
      "Shiyuan Huang",
      "Long Chen",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.15030",
    "title": "Solving Disjunctive Temporal Networks with Uncertainty under Restricted  Time-Based Controllability using Tree Search and Graph Neural Networks",
    "abstract": "Planning under uncertainty is an area of interest in artificial intelligence. We present a novel approach based on tree search and graph machine learning for the scheduling problem known as Disjunctive Temporal Networks with Uncertainty (DTNU). Dynamic Controllability (DC) of DTNUs seeks a reactive scheduling strategy to satisfy temporal constraints in response to uncontrollable action durations. We introduce new semantics for reactive scheduling: Time-based Dynamic Controllability (TDC) and a restricted subset of TDC, R-TDC. We design a tree search algorithm to determine whether or not a DTNU is R-TDC. Moreover, we leverage a graph neural network as a heuristic for tree search guidance. Finally, we conduct experiments on a known benchmark on which we show R-TDC to retain significant completeness with regard to DC, while being faster to prove. This results in the tree search processing fifty percent more DTNU problems in R-TDC than the state-of-the-art DC solver does in DC with the same time budget. We also observe that graph neural network search guidance leads to substantial performance gains on benchmarks of more complex DTNUs, with up to eleven times more problems solved than the baseline tree search. ",
    "url": "https://arxiv.org/abs/2203.15030",
    "authors": [
      "Kevin Osanlou",
      "Jeremy Frank",
      "Andrei Bursuc",
      "Tristan Cazenave",
      "Eric Jacopin",
      "Christophe Guettier",
      "J. Benton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15041",
    "title": "Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of  Demonstrations for Social Navigation",
    "abstract": "Social navigation is the capability of an autonomous agent, such as a robot, to navigate in a 'socially compliant' manner in the presence of other intelligent agents such as humans. With the emergence of autonomously navigating mobile robots in human populated environments (e.g., domestic service robots in homes and restaurants and food delivery robots on public sidewalks), incorporating socially compliant navigation behaviors on these robots becomes critical to ensuring safe and comfortable human robot coexistence. To address this challenge, imitation learning is a promising framework, since it is easier for humans to demonstrate the task of social navigation rather than to formulate reward functions that accurately capture the complex multi objective setting of social navigation. The use of imitation learning and inverse reinforcement learning to social navigation for mobile robots, however, is currently hindered by a lack of large scale datasets that capture socially compliant robot navigation demonstrations in the wild. To fill this gap, we introduce Socially CompliAnt Navigation Dataset (SCAND) a large scale, first person view dataset of socially compliant navigation demonstrations. Our dataset contains 8.7 hours, 138 trajectories, 25 miles of socially compliant, human teleoperated driving demonstrations that comprises multi modal data streams including 3D lidar, joystick commands, odometry, visual and inertial information, collected on two morphologically different mobile robots a Boston Dynamics Spot and a Clearpath Jackal by four different human demonstrators in both indoor and outdoor environments. We additionally perform preliminary analysis and validation through real world robot experiments and show that navigation policies learned by imitation learning on SCAND generate socially compliant behaviors ",
    "url": "https://arxiv.org/abs/2203.15041",
    "authors": [
      "Haresh Karnan",
      "Anirudh Nair",
      "Xuesu Xiao",
      "Garrett Warnell",
      "Soeren Pirk",
      "Alexander Toshev",
      "Justin Hart",
      "Joydeep Biswas",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15065",
    "title": "DeepShadow: Neural Shape from Shadow",
    "abstract": "This paper presents DeepShadow, a one-shot method for recovering the depth map and surface normals from photometric stereo shadow maps. Previous works that try to recover the surface normals from photometric stereo images treat cast shadows as a disturbance. We show that the self and cast shadows not only do not disturb 3D reconstruction, but can be used alone, as a strong learning signal, to recover the depth map and surface normals. We demonstrate that 3D reconstruction from shadows can even outperform shape-from-shading in certain cases. To the best of our knowledge, our method is the first to reconstruct 3D shape-from-shadows using neural networks. The method does not require any pre-training or expensive labeled data, and is optimized during inference time. ",
    "url": "https://arxiv.org/abs/2203.15065",
    "authors": [
      "Asaf Karnieli",
      "Ohad Fried",
      "Yacov Hel-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15078",
    "title": "CD-Net: Histopathology Representation Learning using Pyramidal  Context-Detail Network",
    "abstract": "Extracting rich phenotype information, such as cell density and arrangement, from whole slide histology images (WSIs), requires analysis of large field of view, i.e more contexual information. This can be achieved through analyzing the digital slides at lower resolution. A potential drawback is missing out on details present at a higher resolution. To jointly leverage complementary information from multiple resolutions, we present a novel transformer based Pyramidal Context-Detail Network (CD-Net). CD-Net exploits the WSI pyramidal structure through co-training of proposed Context and Detail Modules, which operate on inputs from multiple resolutions. The residual connections between the modules enable the joint training paradigm while learning self-supervised representation for WSIs. The efficacy of CD-Net is demonstrated in classifying Lung Adenocarcinoma from Squamous cell carcinoma. ",
    "url": "https://arxiv.org/abs/2203.15078",
    "authors": [
      "Saarthak Kapse",
      "Srijan Das",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15095",
    "title": "Robust Speaker Recognition with Transformers Using wav2vec 2.0",
    "abstract": "Recent advances in unsupervised speech representation learning discover new approaches and provide new state-of-the-art for diverse types of speech processing tasks. This paper presents an investigation of using wav2vec 2.0 deep speech representations for the speaker recognition task. The proposed fine-tuning procedure of wav2vec 2.0 with simple TDNN and statistic pooling back-end using additive angular margin loss allows to obtain deep speaker embedding extractor that is well-generalized across different domains. It is concluded that Contrastive Predictive Coding pretraining scheme efficiently utilizes the power of unlabeled data, and thus opens the door to powerful transformer-based speaker recognition systems. The experimental results obtained in this study demonstrate that fine-tuning can be done on relatively small sets and a clean version of data. Using data augmentation during fine-tuning provides additional performance gains in speaker verification. In this study speaker recognition systems were analyzed on a wide range of well-known verification protocols: VoxCeleb1 cleaned test set, NIST SRE 18 development set, NIST SRE 2016 and NIST SRE 2019 evaluation set, VOiCES evaluation set, NIST 2021 SRE, and CTS challenges sets. ",
    "url": "https://arxiv.org/abs/2203.15095",
    "authors": [
      "Sergey Novoselov",
      "Galina Lavrentyeva",
      "Anastasia Avdeeva",
      "Vladimir Volokhov",
      "Aleksei Gusev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15103",
    "title": "Adversarial Motion Priors Make Good Substitutes for Complex Reward  Functions",
    "abstract": "Training a high-dimensional simulated agent with an under-specified reward function often leads the agent to learn physically infeasible strategies that are ineffective when deployed in the real world. To mitigate these unnatural behaviors, reinforcement learning practitioners often utilize complex reward functions that encourage physically plausible behaviors. However, a tedious labor-intensive tuning process is often required to create hand-designed rewards which might not easily generalize across platforms and tasks. We propose substituting complex reward functions with \"style rewards\" learned from a dataset of motion capture demonstrations. A learned style reward can be combined with an arbitrary task reward to train policies that perform tasks using naturalistic strategies. These natural strategies can also facilitate transfer to the real world. We build upon Adversarial Motion Priors -- an approach from the computer graphics domain that encodes a style reward from a dataset of reference motions -- to demonstrate that an adversarial approach to training policies can produce behaviors that transfer to a real quadrupedal robot without requiring complex reward functions. We also demonstrate that an effective style reward can be learned from a few seconds of motion capture data gathered from a German Shepherd and leads to energy-efficient locomotion strategies with natural gait transitions. ",
    "url": "https://arxiv.org/abs/2203.15103",
    "authors": [
      "Alejandro Escontrela",
      "Xue Bin Peng",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Atil Iscen",
      "Ken Goldberg",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15106",
    "title": "Investigation of Different Calibration Methods for Deep Speaker  Embedding based Verification Systems",
    "abstract": "Deep speaker embedding extractors have already become new state-of-the-art systems in the speaker verification field. However, the problem of verification score calibration for such systems often remains out of focus. An irrelevant score calibration leads to serious issues, especially in the case of unknown acoustic conditions, even if we use a strong speaker verification system in terms of threshold-free metrics. This paper presents an investigation over several methods of score calibration: a classical approach based on the logistic regression model; the recently presented magnitude estimation network MagnetO that uses activations from the pooling layer of the trained deep speaker extractor and generalization of such approach based on separate scale and offset prediction neural networks. An additional focus of this research is to estimate the impact of score normalization on the calibration performance of the system. The obtained results demonstrate that there are no serious problems if in-domain development data are used for calibration tuning. Otherwise, a trade-off between good calibration performance and threshold-free system quality arises. In most cases using adaptive s-norm helps to stabilize score distributions and to improve system performance. Meanwhile, some experiments demonstrate that novel approaches have their limits in score stabilization on several datasets. ",
    "url": "https://arxiv.org/abs/2203.15106",
    "authors": [
      "Galina Lavrentyeva",
      "Sergey Novoselov",
      "Andrey Shulipa",
      "Marina Volkova",
      "Aleksandr Kozlov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15112",
    "title": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction",
    "abstract": "Motion forecasting in highly interactive scenarios is a challenging problem in autonomous driving. In such scenarios, we need to accurately predict the joint behavior of interacting agents to ensure the safe and efficient navigation of autonomous vehicles. Recently, goal-conditioned methods have gained increasing attention due to their advantage in performance and their ability to capture the multimodality in trajectory distribution. In this work, we study the joint trajectory prediction problem with the goal-conditioned framework. In particular, we introduce a conditional-variational-autoencoder-based (CVAE) model to explicitly encode different interaction modes into the latent space. However, we discover that the vanilla model suffers from posterior collapse and cannot induce an informative latent space as desired. To address these issues, we propose a novel approach to avoid KL vanishing and induce an interpretable interactive latent space with pseudo labels. The pseudo labels allow us to incorporate arbitrary domain knowledge on interaction. We motivate the proposed method using an illustrative toy example. In addition, we validate our framework on the Waymo Open Motion Dataset with both quantitative and qualitative evaluations. ",
    "url": "https://arxiv.org/abs/2203.15112",
    "authors": [
      "Lingfeng Sun",
      "Chen Tang",
      "Yaru Niu",
      "Enna Sachdeva",
      "Chiho Cho",
      "Teruhisa Misu",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15118",
    "title": "LiDAR Snowfall Simulation for Robust 3D Object Detection",
    "abstract": "3D object detection is a central task for applications such as autonomous driving, in which the system needs to localize and classify surrounding traffic agents, even in the presence of adverse weather. In this paper, we address the problem of LiDAR-based 3D object detection under snowfall. Due to the difficulty of collecting and annotating training data in this setting, we propose a physically based method to simulate the effect of snowfall on real clear-weather LiDAR point clouds. Our method samples snow particles in 2D space for each LiDAR line and uses the induced geometry to modify the measurement for each LiDAR beam accordingly. Moreover, as snowfall often causes wetness on the ground, we also simulate ground wetness on LiDAR point clouds. We use our simulation to generate partially synthetic snowy LiDAR data and leverage these data for training 3D object detection models that are robust to snowfall. We conduct an extensive evaluation using several state-of-the-art 3D object detection methods and show that our simulation consistently yields significant performance gains on the real snowy STF dataset compared to clear-weather baselines and competing simulation approaches, while not sacrificing performance in clear weather. Our code is available at www.github.com/SysCV/LiDAR_snow_sim. ",
    "url": "https://arxiv.org/abs/2203.15118",
    "authors": [
      "Martin Hahner",
      "Christos Sakaridis",
      "Mario Bijelic",
      "Felix Heide",
      "Fisher Yu",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15126",
    "title": "Network Performance Estimator with Applications to Route Selection for  IoT Multimedia Applications",
    "abstract": "Estimating the performance of multimedia traffic is important in numerous contexts, including routing and forwarding, QoS provisioning, and adaptive video streaming. This paper proposes a network performance estimator which aims at providing, in quasi real-time, network performance estimates for IoT multimedia traffic in IEEE 802.11 multihop wireless networks. To our knowledge, the proposed multimedia-aware performance estimator, or MAPE, is the first deterministic simulation-based estimator that provides real-time per-flow throughput, packet loss and delay estimates while considering inter-flow interference and multi-rate flows, typical of multimedia traffic. Our experimental results indicate that MAPE is able to provide network performance estimates that can be used by IoT multimedia services, notably to inform real-time route selection in IoT video transmission, at a fraction of the execution time when compared to stochastic network simulators. When compared to existing deterministic simulators, MAPE yields higher accuracy at comparable execution times due to its ability to consider multi-rate flows. ",
    "url": "https://arxiv.org/abs/2203.15126",
    "authors": [
      "Fabiano Bhering",
      "Diego Passos",
      "C\u00e9lio Albuquerque",
      "Katia Obraczka"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.15135",
    "title": "Filler Word Detection and Classification: A Dataset and Benchmark",
    "abstract": "Filler words such as `uh' or `um' are sounds or words people use to signal they are pausing to think. Finding and removing filler words from recordings is a common and tedious task in media editing. Automatically detecting and classifying filler words could greatly aid in this task, but few studies have been published on this problem. A key reason is the absence of a dataset with annotated filler words for training and evaluation. In this work, we present a novel speech dataset, PodcastFillers, with 35K annotated filler words and 50K annotations of other sounds that commonly occur in podcasts such as breaths, laughter, and word repetitions. We propose a pipeline that leverages VAD and ASR to detect filler candidates and a classifier to distinguish between filler word types. We evaluate our proposed pipeline on PodcastFillers, compare to several baselines, and present a detailed ablation study. In particular, we evaluate the importance of using ASR and how it compares to a transcription-free approach resembling keyword spotting. We show that our pipeline obtains state-of-the-art results, and that leveraging ASR strongly outperforms a keyword spotting approach. We make PodcastFillers publicly available, and hope our work serves as a benchmark for future research. ",
    "url": "https://arxiv.org/abs/2203.15135",
    "authors": [
      "Ge Zhu",
      "Juan-Pablo Caceres",
      "Justin Salamon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15143",
    "title": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
    "abstract": "Scene text detection and document layout analysis have long been treated as two separate tasks in different image domains. In this paper, we bring them together and introduce the task of unified scene text detection and layout analysis. The first hierarchical scene text dataset is introduced to enable this novel research task. We also propose a novel method that is able to simultaneously detect scene text and form text clusters in a unified way. Comprehensive experiments show that our unified model achieves better performance than multiple well-designed baseline methods. Additionally, this model achieves state-of-the-art results on multiple scene text detection datasets without the need of complex post-processing. Dataset and code: https://github.com/google-research-datasets/hiertext. ",
    "url": "https://arxiv.org/abs/2203.15143",
    "authors": [
      "Shangbang Long",
      "Siyang Qin",
      "Dmitry Panteleev",
      "Alessandro Bissacco",
      "Yasuhisa Fujii",
      "Michalis Raptis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15151",
    "title": "A machine learning-based severity prediction tool for diabetic  sensorimotor polyneuropathy using Michigan neuropathy screening  instrumentations",
    "abstract": "Background: Diabetic Sensorimotor polyneuropathy (DSPN) is a major long-term complication in diabetic patients associated with painful neuropathy, foot ulceration and amputation. The Michigan neuropathy screening instrument (MNSI) is one of the most common screening techniques for DSPN, however, it does not provide any direct severity grading system. Method: For designing and modelling the DSPN severity grading systems for MNSI, 19 years of data from Epidemiology of Diabetes Interventions and Complications (EDIC) clinical trials were used. MNSI variables and patient outcomes were investigated using machine learning tools to identify the features having higher association in DSPN identification. A multivariable logistic regression-based nomogram was generated and validated for DSPN severity grading. Results: The top-7 ranked features from MNSI: 10-gm filament, Vibration perception (R), Vibration perception (L), previous diabetic neuropathy, the appearance of deformities, appearance of callus and appearance of fissure were identified as key features for identifying DSPN using the extra tree model. The area under the curve (AUC) of the nomogram for the internal and external datasets were 0.9421 and 0.946, respectively. From the developed nomogram, the probability of having DSPN was predicted and a DSPN severity scoring system for MNSI was developed from the probability score. The model performance was validated on an independent dataset. Patients were stratified into four severity levels: absent, mild, moderate, and severe using a cut-off value of 10.5, 12.7 and 15 for a DSPN probability less than 50%, 75% to 90%, and above 90%, respectively. Conclusions: This study provides a simple, easy-to-use and reliable algorithm for defining the prognosis and management of patients with DSPN. ",
    "url": "https://arxiv.org/abs/2203.15151",
    "authors": [
      "Fahmida Haque",
      "Mamun B. I. Reaz",
      "Muhammad E. H. Chowdhury",
      "Rayaz Malik",
      "Mohammed Alhatou",
      "Syoji Kobashi",
      "Iffat Ara",
      "Sawal H. M. Ali",
      "Ahmad A. A Bakar",
      "Geetika Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.15162",
    "title": "A Distribution Evolutionary Algorithm for Graph Coloring",
    "abstract": "Graph Coloring Problem (GCP) is a classic combinatorial optimization problem that has a wide application in theoretical research and engineering. To address complicated GCPs efficiently, a distribution evolutionary algorithm based on population of probability models (DEA-PPM) is proposed. Based on a novel representation of probability model, DEA-PPM employs a Gaussian orthogonal search strategy to explore the probability space, by which global exploration can be realized using a small population. With assistance of local exploitation on a small solution population, DEA-PPM strikes a good balance between exploration and exploitation. Numerical results demonstrate that DEA-PPM performs well on selected complicated GCPs, which contributes to its competitiveness to the state-of-the-art metaheuristics. ",
    "url": "https://arxiv.org/abs/2203.15162",
    "authors": [
      "Yongjian Xu",
      "Huabin Cheng",
      "Yu Chen",
      "Chengwang Xie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.15171",
    "title": "Self-Supervised Light Field Depth Estimation Using Epipolar Plane Images",
    "abstract": "Exploiting light field data makes it possible to obtain dense and accurate depth map. However, synthetic scenes with limited disparity range cannot contain the diversity of real scenes. By training in synthetic data, current learning-based methods do not perform well in real scenes. In this paper, we propose a self-supervised learning framework for light field depth estimation. Different from the existing end-to-end training methods using disparity label per pixel, our approach implements network training by estimating EPI disparity shift after refocusing, which extends the disparity range of epipolar lines. To reduce the sensitivity of EPI to noise, we propose a new input mode called EPI-Stack, which stacks EPIs in the view dimension. This method is less sensitive to noise scenes than traditional input mode and improves the efficiency of estimation. Compared with other state-of-the-art methods, the proposed method can also obtain higher quality results in real-world scenarios, especially in the complex occlusion and depth discontinuity. ",
    "url": "https://arxiv.org/abs/2203.15171",
    "authors": [
      "Kunyuan Li",
      "Jun Zhang",
      "Jun Gao",
      "Meibin Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15172",
    "title": "Assessing Evolutionary Terrain Generation Methods for Curriculum  Reinforcement Learning",
    "abstract": "Curriculum learning allows complex tasks to be mastered via incremental progression over `stepping stone' goals towards a final desired behaviour. Typical implementations learn locomotion policies for challenging environments through gradual complexification of a terrain mesh generated through a parameterised noise function. To date, researchers have predominantly generated terrains from a limited range of noise functions, and the effect of the generator on the learning process is underrepresented in the literature. We compare popular noise-based terrain generators to two indirect encodings, CPPN and GAN. To allow direct comparison between both direct and indirect representations, we assess the impact of a range of representation-agnostic MAP-Elites feature descriptors that compute metrics directly from the generated terrain meshes. Next, performance and coverage are assessed when training a humanoid robot in a physics simulator using the PPO algorithm. Results describe key differences between the generators that inform their use in curriculum learning, and present a range of useful feature descriptors for uptake by the community. ",
    "url": "https://arxiv.org/abs/2203.15172",
    "authors": [
      "David Howard",
      "Josh Kannemeyer",
      "Davide Dolcetti",
      "Humphrey Munn",
      "Nicole Robinson"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15176",
    "title": "Improving Generalization of Deep Neural Network Acoustic Models with  Length Perturbation and N-best Based Label Smoothing",
    "abstract": "We introduce two techniques, length perturbation and n-best based label smoothing, to improve generalization of deep neural network (DNN) acoustic models for automatic speech recognition (ASR). Length perturbation is a data augmentation algorithm that randomly drops and inserts frames of an utterance to alter the length of the speech feature sequence. N-best based label smoothing randomly injects noise to ground truth labels during training in order to avoid overfitting, where the noisy labels are generated from n-best hypotheses. We evaluate these two techniques extensively on the 300-hour Switchboard (SWB300) dataset and an in-house 500-hour Japanese (JPN500) dataset using recurrent neural network transducer (RNNT) acoustic models for ASR. We show that both techniques improve the generalization of RNNT models individually and they can also be complementary. In particular, they yield good improvements over a strong SWB300 baseline and give state-of-art performance on SWB300 using RNNT models. ",
    "url": "https://arxiv.org/abs/2203.15176",
    "authors": [
      "Xiaodong Cui",
      "George Saon",
      "Tohru Nagano",
      "Masayuki Suzuki",
      "Takashi Fukuda",
      "Brian Kingsbury",
      "Gakuto Kurata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Learning Based Semi-Supervised  Learning Network for Surgical Tools Segmentation",
    "abstract": "Segmentation of images is a popular topic in medical AI. This is mainly due to the difficulty to obtain a significant number of pixel-level annotated data to train a neural network. To address this issue, we proposed a semi-supervised segmentation network based on contrastive learning. In contrast to the previous state-of-the-art, we introduce a contrastive learning form of dual-view training by employing classifiers and projectors to build all-negative, and positive and negative feature pairs respectively to formulate the learning problem as solving min-max similarity problem. The all-negative pairs are used to supervise the networks learning from different views and make sure to capture general features, and the consistency of unlabeled predictions is measured by pixel-wise contrastive loss between positive and negative pairs. To quantitative and qualitative evaluate our proposed method, we test it on two public endoscopy surgical tool segmentation datasets and one cochlear implant surgery dataset which we manually annotate the cochlear implant in surgical videos. The segmentation performance (dice coefficients) indicates that our proposed method outperforms state-of-the-art semi-supervised and fully supervised segmentation algorithms consistently. The code is publicly available at: https://github.com/AngeLouCN/Min_Max_Similarity ",
    "url": "https://arxiv.org/abs/2203.15177",
    "authors": [
      "Ange Lou",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15182",
    "title": "Long-term Visual Map Sparsification with Heterogeneous GNN",
    "abstract": "We address the problem of map sparsification for long-term visual localization. For map sparsification, a commonly employed assumption is that the pre-build map and the later captured localization query are consistent. However, this assumption can be easily violated in the dynamic world. Additionally, the map size grows as new data accumulate through time, causing large data overhead in the long term. In this paper, we aim to overcome the environmental changes and reduce the map size at the same time by selecting points that are valuable to future localization. Inspired by the recent progress in Graph Neural Network(GNN), we propose the first work that models SfM maps as heterogeneous graphs and predicts 3D point importance scores with a GNN, which enables us to directly exploit the rich information in the SfM map graph. Two novel supervisions are proposed: 1) a data-fitting term for selecting valuable points to future localization based on training queries; 2) a K-Cover term for selecting sparse points with full map coverage. The experiments show that our method selected map points on stable and widely visible structures and outperformed baselines in localization performance. ",
    "url": "https://arxiv.org/abs/2203.15182",
    "authors": [
      "Ming-Fang Chang",
      "Yipu Zhao",
      "Rajvi Shah",
      "Jakob J. Engel",
      "Michael Kaess",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15195",
    "title": "AnoDFDNet: A Deep Feature Difference Network for Anomaly Detection",
    "abstract": "This paper proposed a novel anomaly detection (AD) approach of High-speed Train images based on convolutional neural networks and the Vision Transformer. Different from previous AD works, in which anomalies are identified with a single image using classification, segmentation, or object detection methods, the proposed method detects abnormal difference between two images taken at different times of the same region. In other words, we cast anomaly detection problem with a single image into a difference detection problem with two images. The core idea of the proposed method is that the 'anomaly' usually represents an abnormal state instead of a specific object, and this state should be identified by a pair of images. In addition, we introduced a deep feature difference AD network (AnoDFDNet) which sufficiently explored the potential of the Vision Transformer and convolutional neural networks. To verify the effectiveness of the proposed AnoDFDNet, we collected three datasets, a difference dataset (Diff Dataset), a foreign body dataset (FB Dataset), and an oil leakage dataset (OL Dataset). Experimental results on above datasets demonstrate the superiority of proposed method. Source code are available at https://github.com/wangle53/AnoDFDNet. ",
    "url": "https://arxiv.org/abs/2203.15195",
    "authors": [
      "Zhixue Wang",
      "Yu Zhang",
      "Lin Luo",
      "Nan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15205",
    "title": "SPAct: Self-supervised Privacy Preservation for Action Recognition",
    "abstract": "Visual private information leakage is an emerging key issue for the fast growing applications of video understanding like activity recognition. Existing approaches for mitigating privacy leakage in action recognition require privacy labels along with the action labels from the video dataset. However, annotating frames of video dataset for privacy labels is not feasible. Recent developments of self-supervised learning (SSL) have unleashed the untapped potential of the unlabeled data. For the first time, we present a novel training framework which removes privacy information from input video in a self-supervised manner without requiring privacy labels. Our training framework consists of three main components: anonymization function, self-supervised privacy removal branch, and action recognition branch. We train our framework using a minimax optimization strategy to minimize the action recognition cost function and maximize the privacy cost function through a contrastive self-supervised loss. Employing existing protocols of known-action and privacy attributes, our framework achieves a competitive action-privacy trade-off to the existing state-of-the-art supervised methods. In addition, we introduce a new protocol to evaluate the generalization of learned the anonymization function to novel-action and privacy attributes and show that our self-supervised framework outperforms existing supervised methods. Code available at: https://github.com/DAVEISHAN/SPAct ",
    "url": "https://arxiv.org/abs/2203.15205",
    "authors": [
      "Ishan Rajendrakumar Dave",
      "Chen Chen",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15209",
    "title": "OrphicX: A Causality-Inspired Latent Variable Model for Interpreting  Graph Neural Networks",
    "abstract": "This paper proposes a new eXplanation framework, called OrphicX, for generating causal explanations for any graph neural networks (GNNs) based on learned latent causal factors. Specifically, we construct a distinct generative model and design an objective function that encourages the generative model to produce causal, compact, and faithful explanations. This is achieved by isolating the causal factors in the latent space of graphs by maximizing the information flow measurements. We theoretically analyze the cause-effect relationships in the proposed causal graph, identify node attributes as confounders between graphs and GNN predictions, and circumvent such confounder effect by leveraging the backdoor adjustment formula. Our framework is compatible with any GNNs, and it does not require access to the process by which the target GNN produces its predictions. In addition, it does not rely on the linear-independence assumption of the explained features, nor require prior knowledge on the graph learning tasks. We show a proof-of-concept of OrphicX on canonical classification problems on graph data. In particular, we analyze the explanatory subgraphs obtained from explanations for molecular graphs (i.e., Mutag) and quantitatively evaluate the explanation performance with frequently occurring subgraph patterns. Empirically, we show that OrphicX can effectively identify the causal semantics for generating causal explanations, significantly outperforming its alternatives. ",
    "url": "https://arxiv.org/abs/2203.15209",
    "authors": [
      "Wanyu Lin",
      "Hao Lan",
      "Hao Wang",
      "Baochun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15212",
    "title": "Are Edge Weights in Summary Graphs Useful? -- A Comparative Study",
    "abstract": "Which one is better between two representative graph summarization models with and without edge weights? From web graphs to online social networks, large graphs are everywhere. Graph summarization, which is an effective graph compression technique, aims to find a compact summary graph that accurately represents a given large graph. Two versions of the problem, where one allows edge weights in summary graphs and the other does not, have been studied in parallel without direct comparison between their underlying representation models. In this work, we conduct a systematic comparison by extending three search algorithms to both models and evaluating their outputs on eight datasets in five aspects: (a) reconstruction error, (b) error in node importance, (c) error in node proximity, (d) the size of reconstructed graphs, and (e) compression ratios. Surprisingly, using unweighted summary graphs leads to outputs significantly better in all the aspects than using weighted ones, and this finding is supported theoretically. Notably, we show that a state-of-the-art algorithm can be improved substantially (specifically, 8.2X, 7.8X, and 5.9X in terms of (a), (b), and (c), respectively, when (e) is fixed) based on the observation. ",
    "url": "https://arxiv.org/abs/2203.15212",
    "authors": [
      "Shinhwan Kang",
      "Kyuhan Lee",
      "Kijung Shin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.15215",
    "title": "Spatial-Aware Local Community Detection Guided by Dominance Relation",
    "abstract": "The problem of finding the spatial-aware community for a given node has been defined and investigated in geo-social networks. However, existing studies suffer from two limitations: a) the criteria of defining communities are determined by parameters, which are difficult to set; b) algorithms may require global information and are not suitable for situations where the network is incomplete. Therefore, we propose spatial-aware local community detection (SLCD), which finds the spatial-aware local community with only local information and defines the community based on the difference in the sparseness of edges inside and outside the community. Specifically, to address the SLCD problem, we design a novel spatial aware local community detection algorithm based on dominance relation, but this algorithm incurs high cost. To further improve the efficiency, we propose an approximate algorithm. Experimental results demonstrate that the proposed approximate algorithm outperforms the comparison algorithms. ",
    "url": "https://arxiv.org/abs/2203.15215",
    "authors": [
      "Li Ni",
      "Hefei Xu",
      "Yiwen Zhang",
      "Wenjian Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.15221",
    "title": "Few Could Be Better Than All: Feature Sampling and Grouping for Scene  Text Detection",
    "abstract": "Recently, transformer-based methods have achieved promising progresses in object detection, as they can eliminate the post-processes like NMS and enrich the deep representations. However, these methods cannot well cope with scene text due to its extreme variance of scales and aspect ratios. In this paper, we present a simple yet effective transformer-based architecture for scene text detection. Different from previous approaches that learn robust deep representations of scene text in a holistic manner, our method performs scene text detection based on a few representative features, which avoids the disturbance by background and reduces the computational cost. Specifically, we first select a few representative features at all scales that are highly relevant to foreground text. Then, we adopt a transformer for modeling the relationship of the sampled features, which effectively divides them into reasonable groups. As each feature group corresponds to a text instance, its bounding box can be easily obtained without any post-processing operation. Using the basic feature pyramid network for feature extraction, our method consistently achieves state-of-the-art results on several popular datasets for scene text detection. ",
    "url": "https://arxiv.org/abs/2203.15221",
    "authors": [
      "Jingqun Tang",
      "Wenqing Zhang",
      "Hongye Liu",
      "MingKun Yang",
      "Bo Jiang",
      "Guanglong Hu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15228",
    "title": "SHOP: A Deep Learning Based Pipeline for near Real-Time Detection of  Small Handheld Objects Present in Blurry Video",
    "abstract": "While prior works have investigated and developed computational models capable of object detection, models still struggle to reliably interpret images with motion blur and small objects. Moreover, none of these models are specifically designed for handheld object detection. In this work, we present SHOP (Small Handheld Object Pipeline), a pipeline that reliably and efficiently interprets blurry images containing handheld objects. The specific models used in each stage of the pipeline are flexible and can be changed based on performance requirements. First, images are deblurred and then run through a pose detection system where areas-of-interest are proposed around the hands of any people present. Next, object detection is performed on the images by a single-stage object detector. Finally, the proposed areas-of-interest are used to filter out low confidence detections. Testing on a handheld subset of Microsoft Common Objects in Context (MS COCO) demonstrates that this 3 stage process results in a 70 percent decrease in false positives while only reducing true positives by 17 percent in its strongest configuration. We also present a subset of MS COCO consisting solely of handheld objects that can be used to continue the development of handheld object detection methods. https://github.com/spider-sense/SHOP ",
    "url": "https://arxiv.org/abs/2203.15228",
    "authors": [
      "Abhinav Ganguly",
      "Amar C Gandhi",
      "Sylvia E",
      "Jeffrey D Chang",
      "Ian M Hudson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15229",
    "title": "Edge Detection and Deep Learning Based SETI Signal Classification Method",
    "abstract": "Scientists at the Berkeley SETI Research Center are Searching for Extraterrestrial Intelligence (SETI) by a new signal detection method that converts radio signals into spectrograms through Fourier transforms and classifies signals represented by two-dimensional time-frequency spectrums, which successfully converts a signal classification problem into an image classification task. In view of the negative impact of background noises on the accuracy of spectrograms classification, a new method is introduced in this paper. After Gaussian convolution smoothing the signals, edge detection functions are applied to detect the edge of the signals and enhance the outline of the signals, then the processed spectrograms are used to train the deep neural network to compare the classification accuracy of various image classification networks. The results show that the proposed method can effectively improve the classification accuracy of SETI spectrums. ",
    "url": "https://arxiv.org/abs/2203.15229",
    "authors": [
      "Zhewei Chen",
      "Sami Ahmed Haider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.15230",
    "title": "Zero-Query Transfer Attacks on Context-Aware Object Detectors",
    "abstract": "Adversarial attacks perturb images such that a deep neural network produces incorrect classification results. A promising approach to defend against adversarial attacks on natural multi-object scenes is to impose a context-consistency check, wherein, if the detected objects are not consistent with an appropriately defined context, then an attack is suspected. Stronger attacks are needed to fool such context-aware detectors. We present the first approach for generating context-consistent adversarial attacks that can evade the context-consistency check of black-box object detectors operating on complex, natural scenes. Unlike many black-box attacks that perform repeated attempts and open themselves to detection, we assume a \"zero-query\" setting, where the attacker has no knowledge of the classification decisions of the victim system. First, we derive multiple attack plans that assign incorrect labels to victim objects in a context-consistent manner. Then we design and use a novel data structure that we call the perturbation success probability matrix, which enables us to filter the attack plans and choose the one most likely to succeed. This final attack plan is implemented using a perturbation-bounded adversarial attack algorithm. We compare our zero-query attack against a few-query scheme that repeatedly checks if the victim system is fooled. We also compare against state-of-the-art context-agnostic attacks. Against a context-aware defense, the fooling rate of our zero-query approach is significantly higher than context-agnostic approaches and higher than that achievable with up to three rounds of the few-query scheme. ",
    "url": "https://arxiv.org/abs/2203.15230",
    "authors": [
      "Zikui Cai",
      "Shantanu Rane",
      "Alejandro E. Brito",
      "Chengyu Song",
      "Srikanth V. Krishnamurthy",
      "Amit K. Roy-Chowdhury",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15245",
    "title": "Robust Structured Declarative Classifiers for 3D Point Clouds: Defending  Adversarial Attacks with Implicit Gradients",
    "abstract": "Deep neural networks for 3D point cloud classification, such as PointNet, have been demonstrated to be vulnerable to adversarial attacks. Current adversarial defenders often learn to denoise the (attacked) point clouds by reconstruction, and then feed them to the classifiers as input. In contrast to the literature, we propose a family of robust structured declarative classifiers for point cloud classification, where the internal constrained optimization mechanism can effectively defend adversarial attacks through implicit gradients. Such classifiers can be formulated using a bilevel optimization framework. We further propose an effective and efficient instantiation of our approach, namely, Lattice Point Classifier (LPC), based on structured sparse coding in the permutohedral lattice and 2D convolutional neural networks (CNNs) that is end-to-end trainable. We demonstrate state-of-the-art robust point cloud classification performance on ModelNet40 and ScanNet under seven different attackers. For instance, we achieve 89.51% and 83.16% test accuracy on each dataset under the recent JGBA attacker that outperforms DUP-Net and IF-Defense with PointNet by ~70%. Demo code is available at https://zhang-vislab.github.io. ",
    "url": "https://arxiv.org/abs/2203.15245",
    "authors": [
      "Kaidong Li",
      "Ziming Zhang",
      "Cuncong Zhong",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15246",
    "title": "A quantum-inspired tensor network method for constrained combinatorial  optimization problems",
    "abstract": "Combinatorial optimization is of general interest for both theoretical study and real-world applications. Fast-developing quantum algorithms provide a different perspective on solving combinatorial optimization problems. In this paper, we propose a quantum inspired algorithm for general locally constrained combinatorial optimization problems by encoding the constraints directly into a tensor network state. The optimal solution can be efficiently solved by borrowing the imaginary time evolution from a quantum many-body system. We demonstrate our algorithm with the open-pit mining problem numerically. Our computational results show the effectiveness of this construction and potential applications in further studies for general combinatorial optimization problems. ",
    "url": "https://arxiv.org/abs/2203.15246",
    "authors": [
      "Tianyi Hao",
      "Xuxin Huang",
      "Chunjing Jia",
      "Cheng Peng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2203.15252",
    "title": "Identification and classification of exfoliated graphene flakes from  microscopy images using a hierarchical deep convolutional neural network",
    "abstract": "Identification of the mechanically exfoliated graphene flakes and classification of the thickness is important in the nanomanufacturing of next-generation materials and devices that overcome the bottleneck of Moore's Law. Currently, identification and classification of exfoliated graphene flakes are conducted by human via inspecting the optical microscope images. The existing state-of-the-art automatic identification by machine learning is not able to accommodate images with different backgrounds while different backgrounds are unavoidable in experiments. This paper presents a deep learning method to automatically identify and classify the thickness of exfoliated graphene flakes on Si/SiO2 substrates from optical microscope images with various settings and background colors. The presented method uses a hierarchical deep convolutional neural network that is capable of learning new images while preserving the knowledge from previous images. The deep learning model was trained and used to classify exfoliated graphene flakes into monolayer (1L), bi-layer (2L), tri-layer (3L), four-to-six-layer (4-6L), seven-to-ten-layer (7-10L), and bulk categories. Compared with existing machine learning methods, the presented method possesses high accuracy and efficiency as well as robustness to the backgrounds and resolutions of images. The results indicated that our deep learning model has accuracy as high as 99% in identifying and classifying exfoliated graphene flakes. This research will shed light on scaled-up manufacturing and characterization of graphene for advanced materials and devices. ",
    "url": "https://arxiv.org/abs/2203.15252",
    "authors": [
      "Soroush Mahjoubi",
      "Fan Ye",
      "Yi Bao",
      "Weina Meng",
      "Xian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15253",
    "title": "NeuraGen-A Low-Resource Neural Network based approach for Gender  Classification",
    "abstract": "Human voice is the source of several important information. This is in the form of features. These Features help in interpreting various features associated with the speaker and speech. The speaker dependent work researchersare targeted towards speaker identification, Speaker verification, speaker biometric, forensics using feature, and cross-modal matching via speech and face images. In such context research, it is a very difficult task to come across clean, and well annotated publicly available speech corpus as data set. Acquiring volunteers to generate such dataset is also very expensive, not to mention the enormous amount of effort and time researchers spend to gather such data. The present paper work, a Neural Network proposal as NeuraGen focused which is a low-resource ANN architecture. The proposed tool used to classify gender of the speaker from the speech recordings. We have used speech recordings collected from the ELSDSR and limited TIMIT datasets, from which we extracted 8 speech features, which were pre-processed and then fed into NeuraGen to identify the gender. NeuraGen has successfully achieved accuracy of 90.7407% and F1 score of 91.227% in train and 20-fold cross validation dataset. ",
    "url": "https://arxiv.org/abs/2203.15253",
    "authors": [
      "Shankhanil Ghosh",
      "Chhanda Saha",
      "Naagamani Molakathaala"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15266",
    "title": "Interactive Multi-Class Tiny-Object Detection",
    "abstract": "Annotating tens or hundreds of tiny objects in a given image is laborious yet crucial for a multitude of Computer Vision tasks. Such imagery typically contains objects from various categories, yet the multi-class interactive annotation setting for the detection task has thus far been unexplored. To address these needs, we propose a novel interactive annotation method for multiple instances of tiny objects from multiple classes, based on a few point-based user inputs. Our approach, C3Det, relates the full image context with annotator inputs in a local and global manner via late-fusion and feature-correlation, respectively. We perform experiments on the Tiny-DOTA and LCell datasets using both two-stage and one-stage object detection architectures to verify the efficacy of our approach. Our approach outperforms existing approaches in interactive annotation, achieving higher mAP with fewer clicks. Furthermore, we validate the annotation efficiency of our approach in a user study where it is shown to be 2.85x faster and yield only 0.36x task load (NASA-TLX, lower is better) compared to manual annotation. The code is available at https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection. ",
    "url": "https://arxiv.org/abs/2203.15266",
    "authors": [
      "Chunggi Lee",
      "Seonwook Park",
      "Heon Song",
      "Jeongun Ryu",
      "Sanghoon Kim",
      "Haejoon Kim",
      "S\u00e9rgio Pereira",
      "Donggeun Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15274",
    "title": "Finding Structure and Causality in Linear Programs",
    "abstract": "Linear Programs (LP) are celebrated widely, particularly so in machine learning where they have allowed for effectively solving probabilistic inference tasks or imposing structure on end-to-end learning systems. Their potential might seem depleted but we propose a foundational, causal perspective that reveals intriguing intra- and inter-structure relations for LP components. We conduct a systematic, empirical investigation on general-, shortest path- and energy system LPs. ",
    "url": "https://arxiv.org/abs/2203.15274",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Florian Peter Busch",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15276",
    "title": "Applying Syntax$\\unicode{x2013}$Prosody Mapping Hypothesis and Prosodic  Well-Formedness Constraints to Neural Sequence-to-Sequence Speech Synthesis",
    "abstract": "End-to-end text-to-speech synthesis (TTS), which generates speech sounds directly from strings of texts or phonemes, has improved the quality of speech synthesis over the conventional TTS. However, most previous studies have been evaluated based on subjective naturalness and have not objectively examined whether they can reproduce pitch patterns of phonological phenomena such as downstep, rhythmic boost, and initial lowering that reflect syntactic structures in Japanese. These phenomena can be linguistically explained by phonological constraints and the syntax$\\unicode{x2013}$prosody mapping hypothesis (SPMH), which assumes projections from syntactic structures to phonological hierarchy. Although some experiments in psycholinguistics have verified the validity of the SPMH, it is crucial to investigate whether it can be implemented in TTS. To synthesize linguistic phenomena involving syntactic or phonological constraints, we propose a model using phonological symbols based on the SPMH and prosodic well-formedness constraints. Experimental results showed that the proposed method synthesized similar pitch patterns to those reported in linguistics experiments for the phenomena of initial lowering and rhythmic boost. The proposed model efficiently synthesizes phonological phenomena in the test data that were not explicitly included in the training data. ",
    "url": "https://arxiv.org/abs/2203.15276",
    "authors": [
      "Kei Furukawa",
      "Takeshi Kishiyama",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15285",
    "title": "Semantic Line Detection Using Mirror Attention and Comparative Ranking  and Matching",
    "abstract": "A novel algorithm to detect semantic lines is proposed in this paper. We develop three networks: detection network with mirror attention (D-Net) and comparative ranking and matching networks (R-Net and M-Net). D-Net extracts semantic lines by exploiting rich contextual information. To this end, we design the mirror attention module. Then, through pairwise comparisons of extracted semantic lines, we iteratively select the most semantic line and remove redundant ones overlapping with the selected one. For the pairwise comparisons, we develop R-Net and M-Net in the Siamese architecture. Experiments demonstrate that the proposed algorithm outperforms the conventional semantic line detector significantly. Moreover, we apply the proposed algorithm to detect two important kinds of semantic lines successfully: dominant parallel lines and reflection symmetry axes. Our codes are available at https://github.com/dongkwonjin/Semantic-Line-DRM. ",
    "url": "https://arxiv.org/abs/2203.15285",
    "authors": [
      "Dongkwon Jin",
      "Jun-Tae Lee",
      "Chang-Su Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15287",
    "title": "Accelerating Code Search with Deep Hashing and Code Classification",
    "abstract": "Code search is to search reusable code snippets from source code corpus based on natural languages queries. Deep learning-based methods of code search have shown promising results. However, previous methods focus on retrieval accuracy but lacked attention to the efficiency of the retrieval process. We propose a novel method CoSHC to accelerate code search with deep hashing and code classification, aiming to perform an efficient code search without sacrificing too much accuracy. To evaluate the effectiveness of CoSHC, we apply our method to five code search models. Extensive experimental results indicate that compared with previous code search baselines, CoSHC can save more than 90% of retrieval time meanwhile preserving at least 99% of retrieval accuracy. ",
    "url": "https://arxiv.org/abs/2203.15287",
    "authors": [
      "Wenchao Gu",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15293",
    "title": "Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose  Estimation",
    "abstract": "The advances in monocular 3D human pose estimation are dominated by supervised techniques that require large-scale 2D/3D pose annotations. Such methods often behave erratically in the absence of any provision to discard unfamiliar out-of-distribution data. To this end, we cast the 3D human pose learning as an unsupervised domain adaptation problem. We introduce MRP-Net that constitutes a common deep network backbone with two output heads subscribing to two diverse configurations; a) model-free joint localization and b) model-based parametric regression. Such a design allows us to derive suitable measures to quantify prediction uncertainty at both pose and joint level granularity. While supervising only on labeled synthetic samples, the adaptation process aims to minimize the uncertainty for the unlabeled target images while maximizing the same for an extreme out-of-distribution dataset (backgrounds). Alongside synthetic-to-real 3D pose adaptation, the joint-uncertainties allow expanding the adaptation to work on in-the-wild images even in the presence of occlusion and truncation scenarios. We present a comprehensive evaluation of the proposed approach and demonstrate state-of-the-art performance on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2203.15293",
    "authors": [
      "Jogendra Nath Kundu",
      "Siddharth Seth",
      "Pradyumna YM",
      "Varun Jampani",
      "Anirban Chakraborty",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15297",
    "title": "Kernel Modulation: A Parameter-Efficient Method for Training  Convolutional Neural Networks",
    "abstract": "Deep Neural Networks, particularly Convolutional Neural Networks (ConvNets), have achieved incredible success in many vision tasks, but they usually require millions of parameters for good accuracy performance. With increasing applications that use ConvNets, updating hundreds of networks for multiple tasks on an embedded device can be costly in terms of memory, bandwidth, and energy. Approaches to reduce this cost include model compression and parameter-efficient models that adapt a subset of network layers for each new task. This work proposes a novel parameter-efficient kernel modulation (KM) method that adapts all parameters of a base network instead of a subset of layers. KM uses lightweight task-specialized kernel modulators that require only an additional 1.4% of the base network parameters. With multiple tasks, only the task-specialized KM weights are communicated and stored on the end-user device. We applied this method in training ConvNets for Transfer Learning and Meta-Learning scenarios. Our results show that KM delivers up to 9% higher accuracy than other parameter-efficient methods on the Transfer Learning benchmark. ",
    "url": "https://arxiv.org/abs/2203.15297",
    "authors": [
      "Yuhuang Hu",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15298",
    "title": "A Wavelet, AR and SVM based hybrid method for short-term wind speed  prediction",
    "abstract": "Wind speed modelling and prediction has been gaining importance because of its significant roles in various stages of wind energy management. In this paper, we propose a hybrid model, based on wavelet transform to improve the accuracy of the short-term forecast. The wind speed time series are split into various frequency components using wavelet decomposition technique, and each frequency components are modelled separately. Since the components associated with the high- frequency range shows stochastic nature, we modelled them with autoregressive (AR) method and rest of low-frequency components modelled with support vector machine (SVM). The results of the hybrid method show a promising improvement in accuracy of wind speed prediction compared to that of stand-alone AR or SVM model. ",
    "url": "https://arxiv.org/abs/2203.15298",
    "authors": [
      "G.V. Drisya",
      "K. Satheesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15319",
    "title": "Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT  Models for Code Generation",
    "abstract": "Neural Machine Translation (NMT) has reached a level of maturity to be recognized as the premier method for the translation between different languages and aroused interest in different research areas, including software engineering. A key step to validate the robustness of the NMT models consists in evaluating the performance of the models on adversarial inputs, i.e., inputs obtained from the original ones by adding small amounts of perturbation. However, when dealing with the specific task of the code generation (i.e., the generation of code starting from a description in natural language), it has not yet been defined an approach to validate the robustness of the NMT models. In this work, we address the problem by identifying a set of perturbations and metrics tailored for the robustness assessment of such models. We present a preliminary experimental evaluation, showing what type of perturbations affect the model the most and deriving useful insights for future directions. ",
    "url": "https://arxiv.org/abs/2203.15319",
    "authors": [
      "Pietro Liguori",
      "Cristina Improta",
      "Simona De Vivo",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.15323",
    "title": "Improving Persian Relation Extraction Models by Data Augmentation",
    "abstract": "Relation extraction that is the task of predicting semantic relation type between entities in a sentence or document is an important task in natural language processing. Although there are many researches and datasets for English, Persian suffers from sufficient researches and comprehensive datasets. The only available Persian dataset for this task is PERLEX, which is a Persian expert-translated version of the SemEval-2010-Task-8 dataset. In this paper, we present our augmented dataset and the results and findings of our system, participated in the Persian relation Extraction shared task of NSURL 2021 workshop. We use PERLEX as the base dataset and enhance it by applying some text preprocessing steps and by increasing its size via data augmentation techniques to improve the generalization and robustness of applied models. We then employ two different models including ParsBERT and multilingual BERT for relation extraction on the augmented PERLEX dataset. Our best model obtained 64.67% of Macro-F1 on the test phase of the contest and it achieved 83.68% of Macro-F1 on the test set of PERLEX. ",
    "url": "https://arxiv.org/abs/2203.15323",
    "authors": [
      "Moein Salimi Sartakhti",
      "Romina Etezadi",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.15324",
    "title": "syslrn: Learning What to Monitor for Efficient Anomaly Detection",
    "abstract": "While monitoring system behavior to detect anomalies and failures is important, existing methods based on log-analysis can only be as good as the information contained in the logs, and other approaches that look at the OS-level software state introduce high overheads. We tackle the problem with syslrn, a system that first builds an understanding of a target system offline, and then tailors the online monitoring instrumentation based on the learned identifiers of normal behavior. While our syslrn prototype is still preliminary and lacks many features, we show in a case study for the monitoring of OpenStack failures that it can outperform state-of-the-art log-analysis systems with little overhead. ",
    "url": "https://arxiv.org/abs/2203.15324",
    "authors": [
      "Davide Sanvito",
      "Giuseppe Siracusano",
      "Sharan Santhanam",
      "Roberto Gonzalez",
      "Roberto Bifulco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2203.15325",
    "title": "Robust Single Image Dehazing Based on Consistent and Contrast-Assisted  Reconstruction",
    "abstract": "Single image dehazing as a fundamental low-level vision task, is essential for the development of robust intelligent surveillance system. In this paper, we make an early effort to consider dehazing robustness under variational haze density, which is a realistic while under-studied problem in the research filed of singe image dehazing. To properly address this problem, we propose a novel density-variational learning framework to improve the robustness of the image dehzing model assisted by a variety of negative hazy images, to better deal with various complex hazy scenarios. Specifically, the dehazing network is optimized under the consistency-regularized framework with the proposed Contrast-Assisted Reconstruction Loss (CARL). The CARL can fully exploit the negative information to facilitate the traditional positive-orient dehazing objective function, by squeezing the dehazed image to its clean target from different directions. Meanwhile, the consistency regularization keeps consistent outputs given multi-level hazy images, thus improving the model robustness. Extensive experimental results on two synthetic and three real-world datasets demonstrate that our method significantly surpasses the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2203.15325",
    "authors": [
      "De Cheng",
      "Yan Li",
      "Dingwen Zhang",
      "Nannan Wang",
      "Xinbo Gao",
      "Jiande Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15331",
    "title": "CNN Filter DB: An Empirical Investigation of Trained Convolutional  Filters",
    "abstract": "Currently, many theoretical as well as practically relevant questions towards the transferability and robustness of Convolutional Neural Networks (CNNs) remain unsolved. While ongoing research efforts are engaging these problems from various angles, in most computer vision related cases these approaches can be generalized to investigations of the effects of distribution shifts in image data. In this context, we propose to study the shifts in the learned weights of trained CNN models. Here we focus on the properties of the distributions of dominantly used 3x3 convolution filter kernels. We collected and publicly provide a dataset with over 1.4 billion filters from hundreds of trained CNNs, using a wide range of datasets, architectures, and vision tasks. In a first use case of the proposed dataset, we can show highly relevant properties of many publicly available pre-trained models for practical applications: I) We analyze distribution shifts (or the lack thereof) between trained filters along different axes of meta-parameters, like visual category of the dataset, task, architecture, or layer depth. Based on these results, we conclude that model pre-training can succeed on arbitrary datasets if they meet size and variance conditions. II) We show that many pre-trained models contain degenerated filters which make them less robust and less suitable for fine-tuning on target applications. Data & Project website: https://github.com/paulgavrikov/cnn-filter-db ",
    "url": "https://arxiv.org/abs/2203.15331",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15333",
    "title": "On Affine Policies for Wasserstein Distributionally Robust Unit  Commitment",
    "abstract": "This paper proposes a unit commitment (UC) model based on data-driven Wasserstein distributionally robust optimization (WDRO) for power systems under uncertainty of renewable generation as well as its tractable exact reformulation. The proposed model is formulated as a WDRO problem relying on an affine policy, which nests an infinite-dimensional worst-case expectation problem and satisfies the non-anticipativity constraint. To reduce conservativeness, we develop a novel technique that defines a subset of the uncertainty set with a probabilistic guarantee. Subsequently, the proposed model is recast as a semi-infinite programming problem that can be efficiently solved using existing algorithms. Notably, the scale of this reformulation is invariant with the sample size. As a result, a number of samples are easily incorporated without using sophisticated decomposition algorithms. Numerical simulations on 6- and 24-bus test systems demonstrate the economic and computational efficiency of the proposed model. ",
    "url": "https://arxiv.org/abs/2203.15333",
    "authors": [
      "Youngchae Cho",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15335",
    "title": "Iranian Modal Music (Dastgah) detection using deep neural networks",
    "abstract": "In this work, several deep neural networks are implemented to recognize Iranian modal music in seven high correlated categories. The best model, which achieved 92 percent overall accuracy, uses an architecture inspired by autoencoder, including BiLSTM and BiGRU layers. This model is trained using the Nava dataset, with 1786 records and up to 55 hours of music played solo by Kamanche, Tar, Setar, Reed, and Santoor (Dulcimer). Features that have been studied through this research contain MFCC, Chroma CENS, and Mel spectrogram. The results indicate that MFCC carries more valuable information for detecting Iranian modal music (Dastgah) than other sound representations. Moreover, the architecture, which is inspired by autoencoder, is robust in distinguishing high correlated data like Dastgahs. It also shows that because of the precise order in Iranian Dastgah Music, Bidirectional Recurrent networks are more efficient than any other networks that have been implemented in this study. ",
    "url": "https://arxiv.org/abs/2203.15335",
    "authors": [
      "Danial Ebrat",
      "Farzad Didehvar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15336",
    "title": "End-to-End Compressed Video Representation Learning for Generic Event  Boundary Detection",
    "abstract": "Generic event boundary detection aims to localize the generic, taxonomy-free event boundaries that segment videos into chunks. Existing methods typically require video frames to be decoded before feeding into the network, which demands considerable computational power and storage space. To that end, we propose a new end-to-end compressed video representation learning for event boundary detection that leverages the rich information in the compressed domain, i.e., RGB, motion vectors, residuals, and the internal group of pictures (GOP) structure, without fully decoding the video. Specifically, we first use the ConvNets to extract features of the I-frames in the GOPs. After that, a light-weight spatial-channel compressed encoder is designed to compute the feature representations of the P-frames based on the motion vectors, residuals and representations of their dependent I-frames. A temporal contrastive module is proposed to determine the event boundaries of video sequences. To remedy the ambiguities of annotations and speed up the training process, we use the Gaussian kernel to preprocess the ground-truth event boundaries. Extensive experiments conducted on the Kinetics-GEBD dataset demonstrate that the proposed method achieves comparable results to the state-of-the-art methods with $4.5\\times$ faster running speed. ",
    "url": "https://arxiv.org/abs/2203.15336",
    "authors": [
      "Congcong Li",
      "Xinyao Wang",
      "Longyin Wen",
      "Dexiang Hong",
      "Tiejian Luo",
      "Libo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15337",
    "title": "Infrared and Visible Image Fusion via Interactive Compensatory Attention  Adversarial Learning",
    "abstract": "The existing generative adversarial fusion methods generally concatenate source images and extract local features through convolution operation, without considering their global characteristics, which tends to produce an unbalanced result and is biased towards the infrared image or visible image. Toward this end, we propose a novel end-to-end mode based on generative adversarial training to achieve better fusion balance, termed as \\textit{interactive compensatory attention fusion network} (ICAFusion). In particular, in the generator, we construct a multi-level encoder-decoder network with a triple path, and adopt infrared and visible paths to provide additional intensity and gradient information. Moreover, we develop interactive and compensatory attention modules to communicate their pathwise information, and model their long-range dependencies to generate attention maps, which can more focus on infrared target perception and visible detail characterization, and further increase the representation power for feature extraction and feature reconstruction. In addition, dual discriminators are designed to identify the similar distribution between fused result and source images, and the generator is optimized to produce a more balanced result. Extensive experiments illustrate that our ICAFusion obtains superior fusion performance and better generalization ability, which precedes other advanced methods in the subjective visual description and objective metric evaluation. Our codes will be public at \\url{https://github.com/Zhishe-Wang/ICAFusion} ",
    "url": "https://arxiv.org/abs/2203.15337",
    "authors": [
      "Zhishe Wang",
      "Wenyu Shao",
      "Yanlin Chen",
      "Jiawei Xu",
      "Xiaoqin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15345",
    "title": "Task-specific Inconsistency Alignment for Domain Adaptive Object  Detection",
    "abstract": "Detectors trained with massive labeled data often exhibit dramatic performance degradation in some particular scenarios with data distribution gap. To alleviate this problem of domain shift, conventional wisdom typically concentrates solely on reducing the discrepancy between the source and target domains via attached domain classifiers, yet ignoring the difficulty of such transferable features in coping with both classification and localization subtasks in object detection. To address this issue, in this paper, we propose Task-specific Inconsistency Alignment (TIA), by developing a new alignment mechanism in separate task spaces, improving the performance of the detector on both subtasks. Specifically, we add a set of auxiliary predictors for both classification and localization branches, and exploit their behavioral inconsistencies as finer-grained domain-specific measures. Then, we devise task-specific losses to align such cross-domain disagreement of both subtasks. By optimizing them individually, we are able to well approximate the category- and boundary-wise discrepancies in each task space, and therefore narrow them in a decoupled manner. TIA demonstrates superior results on various scenarios to the previous state-of-the-art methods. It is also observed that both the classification and localization capabilities of the detector are sufficiently strengthened, further demonstrating the effectiveness of our TIA method. Code and trained models are publicly available at https://github.com/MCG-NJU/TIA. ",
    "url": "https://arxiv.org/abs/2203.15345",
    "authors": [
      "Liang Zhao",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15353",
    "title": "SIOD: Single Instance Annotated Per Category Per Image for Object  Detection",
    "abstract": "Object detection under imperfect data receives great attention recently. Weakly supervised object detection (WSOD) suffers from severe localization issues due to the lack of instance-level annotation, while semi-supervised object detection (SSOD) remains challenging led by the inter-image discrepancy between labeled and unlabeled data. In this study, we propose the Single Instance annotated Object Detection (SIOD), requiring only one instance annotation for each existing category in an image. Degraded from inter-task (WSOD) or inter-image (SSOD) discrepancies to the intra-image discrepancy, SIOD provides more reliable and rich prior knowledge for mining the rest of unlabeled instances and trades off the annotation cost and performance. Under the SIOD setting, we propose a simple yet effective framework, termed Dual-Mining (DMiner), which consists of a Similarity-based Pseudo Label Generating module (SPLG) and a Pixel-level Group Contrastive Learning module (PGCL). SPLG firstly mines latent instances from feature representation space to alleviate the annotation missing problem. To avoid being misled by inaccurate pseudo labels, we propose PGCL to boost the tolerance to false pseudo labels. Extensive experiments on MS COCO verify the feasibility of the SIOD setting and the superiority of the proposed method, which obtains consistent and significant improvements compared to baseline methods and achieves comparable results with fully supervised object detection (FSOD) methods with only 40% instances annotated. ",
    "url": "https://arxiv.org/abs/2203.15353",
    "authors": [
      "Hanjun Li",
      "Xingjia Pan",
      "Ke Yan",
      "Fan Tang",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15361",
    "title": "Self-Supervised Image Representation Learning with Geometric Set  Consistency",
    "abstract": "We propose a method for self-supervised image representation learning under the guidance of 3D geometric consistency. Our intuition is that 3D geometric consistency priors such as smooth regions and surface discontinuities may imply consistent semantics or object boundaries, and can act as strong cues to guide the learning of 2D image representations without semantic labels. Specifically, we introduce 3D geometric consistency into a contrastive learning framework to enforce the feature consistency within image views. We propose to use geometric consistency sets as constraints and adapt the InfoNCE loss accordingly. We show that our learned image representations are general. By fine-tuning our pre-trained representations for various 2D image-based downstream tasks, including semantic segmentation, object detection, and instance segmentation on real-world indoor scene datasets, we achieve superior performance compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.15361",
    "authors": [
      "Nenglun Chen",
      "Lei Chu",
      "Hao Pan",
      "Yan Lu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15362",
    "title": "Domain Invariant Siamese Attention Mask for Small Object Change  Detection via Everyday Indoor Robot Navigation",
    "abstract": "The problem of image change detection via everyday indoor robot navigation is explored from a novel perspective of the self-attention technique. Detecting semantically non-distinctive and visually small changes remains a key challenge in the robotics community. Intuitively, these small non-distinctive changes may be better handled by the recent paradigm of the attention mechanism, which is the basic idea of this work. However, existing self-attention models require significant retraining cost per domain, so it is not directly applicable to robotics applications. We propose a new self-attention technique with an ability of unsupervised on-the-fly domain adaptation, which introduces an attention mask into the intermediate layer of an image change detection model, without modifying the input and output layers of the model. Experiments, in which an indoor robot aims to detect visually small changes in everyday navigation, demonstrate that our attention technique significantly boosts the state-of-the-art image change detection model. ",
    "url": "https://arxiv.org/abs/2203.15362",
    "authors": [
      "Koji Takeda",
      "Kanji Tanaka",
      "Yoshimasa Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15369",
    "title": "Geographic Diversity in Public Code Contributions",
    "abstract": "We conduct an exploratory, large-scale, longitudinal study of 50 years of commits to publicly available version control system repositories, in order to characterize the geographic diversity of contributors to public code and its evolution over time. We analyze in total 2.2 billion commits collected by Software Heritage from 160 million projects and authored by 43 million authors during the 1971-2021 time period. We geolocate developers to 12 world regions derived from the United Nation geoscheme, using as signals email top-level domains, author names compared with names distributions around the world, and UTC offsets mined from commit metadata.We find evidence of the early dominance of North America in open source software, later joined by Europe. After that period, the geographic diversity in public code has been constantly increasing. We also identify relevant historical shifts related to the UNIX wars, the increase of coding literacy in Central and South Asia, and broader phenomena like colonialism and people movement across countries (immigration/emigration). ",
    "url": "https://arxiv.org/abs/2203.15369",
    "authors": [
      "Davide Rossi",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.15381",
    "title": "Alignment-Uniformity aware Representation Learning for Zero-shot Video  Classification",
    "abstract": "Most methods tackle zero-shot video classification by aligning visual-semantic representations within seen classes, which limits generalization to unseen classes. To enhance model generalizability, this paper presents an end-to-end framework that preserves alignment and uniformity properties for representations on both seen and unseen classes. Specifically, we formulate a supervised contrastive loss to simultaneously align visual-semantic features (i.e., alignment) and encourage the learned features to distribute uniformly (i.e., uniformity). Unlike existing methods that only consider the alignment, we propose uniformity to preserve maximal-info of existing features, which improves the probability that unobserved features fall around observed data. Further, we synthesize features of unseen classes by proposing a class generator that interpolates and extrapolates the features of seen classes. Besides, we introduce two metrics, closeness and dispersion, to quantify the two properties and serve as new measurements of model generalizability. Experiments show that our method significantly outperforms SoTA by relative improvements of 28.1% on UCF101 and 27.0% on HMDB51. Code is available. ",
    "url": "https://arxiv.org/abs/2203.15381",
    "authors": [
      "Shi Pu",
      "Kaili Zhao",
      "Mao Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15386",
    "title": "Pareto Set Learning for Neural Multi-objective Combinatorial  Optimization",
    "abstract": "Multiobjective combinatorial optimization (MOCO) problems can be found in many real-world applications. However, exactly solving these problems would be very challenging, particularly when they are NP-hard. Many handcrafted heuristic methods have been proposed to tackle different MOCO problems over the past decades. In this work, we generalize the idea of neural combinatorial optimization, and develop a learning-based approach to approximate the whole Pareto set for a given MOCO problem without further search procedure. We propose a single preference-conditioned model to directly generate approximate Pareto solutions for any trade-off preference, and design an efficient multiobjective reinforcement learning algorithm to train this model. Our proposed method can be treated as a learning-based extension for the widely-used decomposition-based multiobjective evolutionary algorithm (MOEA/D). It uses a single model to accommodate all the possible preferences, whereas other methods use a finite number of solution to approximate the Pareto set. Experimental results show that our proposed method significantly outperforms some other methods on the multiobjective traveling salesman problem, multiobjective vehicle routing problem and multiobjective knapsack problem in terms of solution quality, speed, and model efficiency. ",
    "url": "https://arxiv.org/abs/2203.15386",
    "authors": [
      "Xi Lin",
      "Zhiyuan Yang",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.15401",
    "title": "Neural Face Video Compression using Multiple Views",
    "abstract": "Recent advances in deep generative models led to the development of neural face video compression codecs that use an order of magnitude less bandwidth than engineered codecs. These neural codecs reconstruct the current frame by warping a source frame and using a generative model to compensate for imperfections in the warped source frame. Thereby, the warp is encoded and transmitted using a small number of keypoints rather than a dense flow field, which leads to massive savings compared to traditional codecs. However, by relying on a single source frame only, these methods lead to inaccurate reconstructions (e.g. one side of the head becomes unoccluded when turning the head and has to be synthesized). Here, we aim to tackle this issue by relying on multiple source frames (views of the face) and present encouraging results. ",
    "url": "https://arxiv.org/abs/2203.15401",
    "authors": [
      "Anna Volokitin",
      "Stefan Brugger",
      "Ali Benlalah",
      "Sebastian Martin",
      "Brian Amberg",
      "Michael Tschannen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15406",
    "title": "TransductGAN: a Transductive Adversarial Model for Novelty Detection",
    "abstract": "Novelty detection, a widely studied problem in machine learning, is the problem of detecting a novel class of data that has not been previously observed. A common setting for novelty detection is inductive whereby only examples of the negative class are available during training time. Transductive novelty detection on the other hand has only witnessed a recent surge in interest, it not only makes use of the negative class during training but also incorporates the (unlabeled) test set to detect novel examples. Several studies have emerged under the transductive setting umbrella that have demonstrated its advantage over its inductive counterpart. Depending on the assumptions about the data, these methods go by different names (e.g. transductive novelty detection, semi-supervised novelty detection, positive-unlabeled learning, out-of-distribution detection). With the use of generative adversarial networks (GAN), a segment of those studies have adopted a transductive setup in order to learn how to generate examples of the novel class. In this study, we propose TransductGAN, a transductive generative adversarial network that attempts to learn how to generate image examples from both the novel and negative classes by using a mixture of two Gaussians in the latent space. It achieves that by incorporating an adversarial autoencoder with a GAN network, the ability to generate examples of novel data points offers not only a visual representation of novelties, but also overcomes the hurdle faced by many inductive methods of how to tune the model hyperparameters at the decision rule level. Our model has shown superior performance over state-of-the-art inductive and transductive methods. Our study is fully reproducible with the code available publicly. ",
    "url": "https://arxiv.org/abs/2203.15406",
    "authors": [
      "Najiba Toron",
      "Janaina Mourao-Miranda",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15408",
    "title": "AutoCoMet: Smart Neural Architecture Search via Co-Regulated Shaping  Reinforcement",
    "abstract": "Designing suitable deep model architectures, for AI-driven on-device apps and features, at par with rapidly evolving mobile hardware and increasingly complex target scenarios is a difficult task. Though Neural Architecture Search (NAS/AutoML) has made this easier by shifting paradigm from extensive manual effort to automated architecture learning from data, yet it has major limitations, leading to critical bottlenecks in the context of mobile devices, including model-hardware fidelity, prohibitive search times and deviation from primary target objective(s). Thus, we propose AutoCoMet that can learn the most suitable DNN architecture optimized for varied types of device hardware and task contexts, ~ 3x faster. Our novel co-regulated shaping reinforcement controller together with the high fidelity hardware meta-behavior predictor produces a smart, fast NAS framework that adapts to context via a generalized formalism for any kind of multi-criteria optimization. ",
    "url": "https://arxiv.org/abs/2203.15408",
    "authors": [
      "Mayukh Das",
      "Brijraj Singh",
      "Harsh Kanti Chheda",
      "Pawan Sharma",
      "Pradeep NS"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15425",
    "title": "Process Mining Analysis of Puzzle-Based Cybersecurity Training",
    "abstract": "The hands-on cybersecurity training quality is crucial to mitigate cyber threats and attacks effectively. However, practical cybersecurity training is strongly process-oriented, making the post-training analysis very difficult. This paper presents process-mining methods applied to the learning analytics workflow. We introduce a unified approach to reconstruct behavioral graphs from sparse event logs of cyber ranges. Furthermore, we discuss significant data features that affect their practical usability for educational process mining. Based on that, methods of dealing with the complexity of process graphs are presented, taking advantage of the puzzle-based gamification of in-class training sessions. ",
    "url": "https://arxiv.org/abs/2203.15425",
    "authors": [
      "Martin Macak",
      "Radek Oslejsek",
      "Barbora Buhnova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.15429",
    "title": "Heterogeneous Differential Privacy via Graphs",
    "abstract": "We generalize a previous framework for designing utility-optimal differentially private (DP) mechanisms via graphs, where datasets are vertices in the graph and edges represent dataset neighborhood. The boundary set contains datasets where an individual's response changes the binary-valued query compared to its neighbors. Previous work was limited to the homogeneous case where the privacy parameter $\\varepsilon$ across all datasets was the same and the mechanism at boundary datasets was identical. In our work, the mechanism can take different distributions at the boundary and the privacy parameter $\\varepsilon$ is a function of neighboring datasets, which recovers an earlier definition of personalized DP as special case. The problem is how to extend the mechanism, which is only defined at the boundary set, to other datasets in the graph in a computationally efficient and utility optimal manner. Using the concept of strongest induced DP condition we solve this problem efficiently in polynomial time (in the size of the graph). ",
    "url": "https://arxiv.org/abs/2203.15429",
    "authors": [
      "Sahel Torkamani",
      "Javad B. Ebrahimi",
      "Parastoo Sadeghi",
      "Rafael G. L. D'Oliveira",
      "Muriel Medard"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.15431",
    "title": "Investigating Self-supervised Pretraining Frameworks for Pathological  Speech Recognition",
    "abstract": "We investigate the performance of self-supervised pretraining frameworks on pathological speech datasets used for automatic speech recognition (ASR). Modern end-to-end models require thousands of hours of data to train well, but only a small number of pathological speech datasets are publicly available. A proven solution to this problem is by first pretraining the model on a huge number of healthy speech datasets and then fine-tuning it on the pathological speech datasets. One new pretraining framework called self-supervised learning (SSL) trains a network using only speech data, providing more flexibility in training data requirements and allowing more speech data to be used in pretraining. We investigate SSL frameworks such as the wav2vec 2.0 and WavLM models using different setups and compare their performance with different supervised pretraining setups, using two types of pathological speech, namely, Japanese electrolaryngeal and English dysarthric. Although the SSL setup is promising against Transformer-based supervised setups, other supervised setups such as the Conformer still outperform SSL pretraining. Our results show that the best supervised setup outperforms the best SSL setup by 13.9% character error rate in electrolaryngeal speech and 16.8% word error rate in dysarthric speech. ",
    "url": "https://arxiv.org/abs/2203.15431",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15435",
    "title": "Impact of Network Densification on the Performance of a Non-Public URLLC  Factory Network",
    "abstract": "Densification of the network deployment, for example by adding new sectors or sites within an existing mobile communication network, has traditionally been an efficient way to improve the system coverage and capacity. That will be the case even for the ultra-reliable low-latency communication (URLLC) services, but the overall situation and the feasibility of the different deployment options will depend on the characteristics of the URLLC service in question. URLLC services with relaxed latency requirements, allowing multiple transmission attempts, can tolerate a decent level of inter-cell interference while still being able to guarantee the desired quality-of-service for all users, which makes it possible to improve the URLLC service capacity by adding new gNodeBs with omnidirectional or directional antennas. However, when the URLLC services require extremely low latency that do not allow for retransmissions, the system performance becomes quite sensitive to the inter-cell interference, which means that in practice the gNodeBs should be equipped with beamformed antennas to reach high levels of URLLC service capacity. Finally, an active distributed antenna system could be an efficient way to secure good coverage throughout the desired service area. ",
    "url": "https://arxiv.org/abs/2203.15435",
    "authors": [
      "Kimmo Hiltunen",
      "Yanpeng Yang",
      "Fedor Chernogorov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.15437",
    "title": "Contextual Information Based Anomaly Detection for a Multi-Scene UAV  Aerial Videos",
    "abstract": "UAV based surveillance is gaining much interest worldwide due to its extensive applications in monitoring wildlife, urban planning, disaster management, campus security, etc. These videos are analyzed for strange/odd/anomalous patterns which are essential aspects of surveillance. But manual analysis of these videos is tedious and laborious. Hence, the development of computer-aided systems for the analysis of UAV based surveillance videos is crucial. Despite this interest, in literature, several computer aided systems are developed focusing only on CCTV based surveillance videos. These methods are designed for single scene scenarios and lack contextual knowledge which is required for multi-scene scenarios. Furthermore, the lack of standard UAV based anomaly detection datasets limits the development of these systems. In this regard, the present work aims at the development of a Computer Aided Decision support system to analyse UAV based surveillance videos. A new UAV based multi-scene anomaly detection dataset is developed with frame-level annotations for the development of computer aided systems. It holistically uses contextual, temporal and appearance features for accurate detection of anomalies. Furthermore, a new inference strategy is proposed that utilizes few anomalous samples along with normal samples to identify better decision boundaries. The proposed method is extensively evaluated on the UAV based anomaly detection dataset and performed competitively with respect to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.15437",
    "authors": [
      "Girisha S",
      "Ujjwal Verma",
      "Manohara Pai M M",
      "Radhika M Pai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15442",
    "title": "Shifting More Attention to Visual Backbone: Query-modulated Refinement  Networks for End-to-End Visual Grounding",
    "abstract": "Visual grounding focuses on establishing fine-grained alignment between vision and natural language, which has essential applications in multimodal reasoning systems. Existing methods use pre-trained query-agnostic visual backbones to extract visual feature maps independently without considering the query information. We argue that the visual features extracted from the visual backbones and the features really needed for multimodal reasoning are inconsistent. One reason is that there are differences between pre-training tasks and visual grounding. Moreover, since the backbones are query-agnostic, it is difficult to completely avoid the inconsistency issue by training the visual backbone end-to-end in the visual grounding framework. In this paper, we propose a Query-modulated Refinement Network (QRNet) to address the inconsistent issue by adjusting intermediate features in the visual backbone with a novel Query-aware Dynamic Attention (QD-ATT) mechanism and query-aware multiscale fusion. The QD-ATT can dynamically compute query-dependent visual attention at the spatial and channel levels of the feature maps produced by the visual backbone. We apply the QRNet to an end-to-end visual grounding framework. Extensive experiments show that the proposed method outperforms state-of-the-art methods on five widely used datasets. ",
    "url": "https://arxiv.org/abs/2203.15442",
    "authors": [
      "Jiabo Ye",
      "Junfeng Tian",
      "Ming Yan",
      "Xiaoshan Yang",
      "Xuwu Wang",
      "Ji Zhang",
      "Liang He",
      "Xin Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.15468",
    "title": "Machine Composition of Korean Music via Topological Data Analysis and  Artificial Neural Network",
    "abstract": "Common AI music composition algorithms based on artificial neural networks are to train a machine by feeding a large number of music pieces and create artificial neural networks that can produce music similar to the input music data. This approach is a blackbox optimization, that is, the underlying composition algorithm is, in general, not known to users. In this paper, we present a way of machine composition that trains a machine the composition principle embedded in the given music data instead of directly feeding music pieces. We propose this approach by using the concept of {\\color{black}{Overlap}} matrix proposed in \\cite{TPJ}. In \\cite{TPJ}, a type of Korean music, so-called the {\\it Dodeuri} music such as Suyeonjangjigok has been analyzed using topological data analysis (TDA), particularly using persistent homology. As the raw music data is not suitable for TDA analysis, the music data is first reconstructed as a graph. The node of the graph is defined as a two-dimensional vector composed of the pitch and duration of each music note. The edge between two nodes is created when those nodes appear consecutively in the music flow. Distance is defined based on the frequency of such appearances. Through TDA on the constructed graph, a unique set of cycles is found for the given music. In \\cite{TPJ}, the new concept of the {\\it {\\color{black}{Overlap}} matrix} has been proposed, which visualizes how those cycles are interconnected over the music flow, in a matrix form. In this paper, we explain how we use the {\\color{black}{Overlap}} matrix for machine composition. The {\\color{black}{Overlap}} matrix makes it possible to compose a new music piece algorithmically and also provide a seed music towards the desired artificial neural network. In this paper, we use the {\\it Dodeuri} music and explain detailed steps. ",
    "url": "https://arxiv.org/abs/2203.15468",
    "authors": [
      "Mai Lan Tran",
      "Dongjin Lee",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15480",
    "title": "SAR-ShipNet: SAR-Ship Detection Neural Network via Bidirectional  Coordinate Attention and Multi-resolution Feature Fusion",
    "abstract": "This paper studies a practically meaningful ship detection problem from synthetic aperture radar (SAR) images by the neural network. We broadly extract different types of SAR image features and raise the intriguing question that whether these extracted features are beneficial to (1) suppress data variations (e.g., complex land-sea backgrounds, scattered noise) of real-world SAR images, and (2) enhance the features of ships that are small objects and have different aspect (length-width) ratios, therefore resulting in the improvement of ship detection. To answer this question, we propose a SAR-ship detection neural network (call SAR-ShipNet for short), by newly developing Bidirectional Coordinate Attention (BCA) and Multi-resolution Feature Fusion (MRF) based on CenterNet. Moreover, considering the varying length-width ratio of arbitrary ships, we adopt elliptical Gaussian probability distribution in CenterNet to improve the performance of base detector models. Experimental results on the public SAR-Ship dataset show that our SAR-ShipNet achieves competitive advantages in both speed and accuracy. ",
    "url": "https://arxiv.org/abs/2203.15480",
    "authors": [
      "Yuwen Deng",
      "Donghai Guan",
      "Yanyu Chen",
      "Weiwei Yuan",
      "Jiemin Ji",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15498",
    "title": "Powerful Physical Adversarial Examples Against Practical Face  Recognition Systems",
    "abstract": "It is well-known that the most existing machine learning (ML)-based safety-critical applications are vulnerable to carefully crafted input instances called adversarial examples (AXs). An adversary can conveniently attack these target systems from digital as well as physical worlds. This paper aims to the generation of robust physical AXs against face recognition systems. We present a novel smoothness loss function and a patch-noise combo attack for realizing powerful physical AXs. The smoothness loss interjects the concept of delayed constraints during the attack generation process, thereby causing better handling of optimization complexity and smoother AXs for the physical domain. The patch-noise combo attack combines patch noise and imperceptibly small noises from different distributions to generate powerful registration-based physical AXs. An extensive experimental analysis found that our smoothness loss results in robust and more transferable digital and physical AXs than the conventional techniques. Notably, our smoothness loss results in a 1.17 and 1.97 times better mean attack success rate (ASR) in physical white-box and black-box attacks, respectively. Our patch-noise combo attack furthers the performance gains and results in 2.39 and 4.74 times higher mean ASR than conventional technique in physical world white-box and black-box attacks, respectively. ",
    "url": "https://arxiv.org/abs/2203.15498",
    "authors": [
      "Inderjeet Singh",
      "Toshinori Araki",
      "Kazuya Kakizaki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15501",
    "title": "Deep Learning for Encrypted Traffic Classification and Unknown Data  Detection",
    "abstract": "Despite the widespread use of encryption techniques to provide confidentiality over Internet communications, mobile device users are still susceptible to privacy and security risks. In this paper, a new Deep Neural Network (DNN) based user activity detection framework is proposed to identify fine grained user activities performed on mobile applications (known as in-app activities) from a sniffed encrypted Internet traffic stream. One of the challenges is that there are countless applications, and it is practically impossible to collect and train a DNN model using all possible data from them. Therefore, in this work we exploit the probability distribution of DNN output layer to filter the data from applications that are not considered during the model training (i.e., unknown data). The proposed framework uses a time window based approach to divide the traffic flow of an activity into segments, so that in-app activities can be identified just by observing only a fraction of the activity related traffic. Our tests have shown that the DNN based framework has demonstrated an accuracy of 90% or above in identifying previously trained in-app activities and an average accuracy of 79% in identifying previously untrained in-app activity traffic as unknown data when this framework is employed. ",
    "url": "https://arxiv.org/abs/2203.15501",
    "authors": [
      "Madushi H. Pathmaperuma",
      "Yogachandran Rahulamathavan",
      "Safak Dogan",
      "Ahmet M. Kondoz",
      "Rongxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.15502",
    "title": "Analysis of OODA Loop based on Adversarial for Complex Game Environments",
    "abstract": "To address the problem of imperfect confrontation strategy caused by the lack of information of game environment in the simulation of non-complete information dynamic countermeasure modeling for intelligent game, the hierarchical analysis game strategy of confrontation model based on OODA ring (Observation, Orientation, Decision, Action) theory is proposed. At the same time, taking into account the trend of unmanned future warfare, NetLogo software simulation is used to construct a dynamic derivation of the confrontation between two tanks. In the validation process, the OODA loop theory is used to describe the operation process of the complex system between red and blue sides, and the four-step cycle of observation, judgment, decision and execution is carried out according to the number of armor of both sides, and then the OODA loop system adjusts the judgment and decision time coefficients for the next confrontation cycle according to the results of the first cycle. Compared with traditional simulation methods that consider objective factors such as loss rate and support rate, the OODA-loop-based hierarchical game analysis can analyze the confrontation situation more comprehensively. ",
    "url": "https://arxiv.org/abs/2203.15502",
    "authors": [
      "Xiangri Lu",
      "Hongbin Ma",
      "Zhanqing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15506",
    "title": "Trojan Horse Training for Breaking Defenses against Backdoor Attacks in  Deep Learning",
    "abstract": "Machine learning (ML) models that use deep neural networks are vulnerable to backdoor attacks. Such attacks involve the insertion of a (hidden) trigger by an adversary. As a consequence, any input that contains the trigger will cause the neural network to misclassify the input to a (single) target class, while classifying other inputs without a trigger correctly. ML models that contain a backdoor are called Trojan models. Backdoors can have severe consequences in safety-critical cyber and cyber physical systems when only the outputs of the model are available. Defense mechanisms have been developed and illustrated to be able to distinguish between outputs from a Trojan model and a non-Trojan model in the case of a single-target backdoor attack with accuracy > 96 percent. Understanding the limitations of a defense mechanism requires the construction of examples where the mechanism fails. Current single-target backdoor attacks require one trigger per target class. We introduce a new, more general attack that will enable a single trigger to result in misclassification to more than one target class. Such a misclassification will depend on the true (actual) class that the input belongs to. We term this category of attacks multi-target backdoor attacks. We demonstrate that a Trojan model with either a single-target or multi-target trigger can be trained so that the accuracy of a defense mechanism that seeks to distinguish between outputs coming from a Trojan and a non-Trojan model will be reduced. Our approach uses the non-Trojan model as a teacher for the Trojan model and solves a min-max optimization problem between the Trojan model and defense mechanism. Empirical evaluations demonstrate that our training procedure reduces the accuracy of a state-of-the-art defense mechanism from >96 to 0 percent. ",
    "url": "https://arxiv.org/abs/2203.15506",
    "authors": [
      "Arezoo Rajabi",
      "Bhaskar Ramasubramanian",
      "Radha Poovendran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15508",
    "title": "Improving Contrastive Learning with Model Augmentation",
    "abstract": "The sequential recommendation aims at predicting the next items in user behaviors, which can be solved by characterizing item relationships in sequences. Due to the data sparsity and noise issues in sequences, a new self-supervised learning (SSL) paradigm is proposed to improve the performance, which employs contrastive learning between positive and negative views of sequences. However, existing methods all construct views by adopting augmentation from data perspectives, while we argue that 1) optimal data augmentation methods are hard to devise, 2) data augmentation methods destroy sequential correlations, and 3) data augmentation fails to incorporate comprehensive self-supervised signals. Therefore, we investigate the possibility of model augmentation to construct view pairs. We propose three levels of model augmentation methods: neuron masking, layer dropping, and encoder complementing. This work opens up a novel direction in constructing views for contrastive SSL. Experiments verify the efficacy of model augmentation for the SSL in the sequential recommendation. Code is available\\footnote{\\url{https://github.com/salesforce/SRMA}}. ",
    "url": "https://arxiv.org/abs/2203.15508",
    "authors": [
      "Zhiwei Liu",
      "Yongjun Chen",
      "Jia Li",
      "Man Luo",
      "Philip S. Yu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.15509",
    "title": "Firefighter Problem with Minimum Budget: Hardness and Approximation  Algorithm for Unit Disk Graphs",
    "abstract": "Unit disk graphs are the set of graphs which represent the intersection of disk graphs and interval graphs. These graphs are of great importance due to their structural similarity with wireless communication networks. Firefighter problem on unit disk graph is interesting as it models the virus spreading in an wireless network and asks for a solution to stop it. In this paper, we consider the MIN-BUDGET firefighter problem where the goal is to determine the minimum number of firefighters required and the nodes to place them at each time instant to save a given set of vertices of a given graph and a fire breakout node. We show that, the MIN-BUDGET firefighter problem in a unit disk graph is NP-Hard. We also present a constant factor approximation algorithm. ",
    "url": "https://arxiv.org/abs/2203.15509",
    "authors": [
      "Diptendu Chatterjee",
      "Rishiraj Bhattacharyya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.15511",
    "title": "Explaining random forest prediction through diverse rulesets",
    "abstract": "Tree-ensemble algorithms, such as random forest, are effective machine learning methods popular for their flexibility, high performance, and robustness to overfitting. However, since multiple learners are combined,they are not as interpretable as a single decision tree. In this work we propose a methodology, called Local Tree eXtractor (LTreeX) which is able to explain the forest prediction for a given test instance with a few diverse rules. Starting from the decision trees generated by a random forest, our method 1) pre-selects a subset of them, 2) creates a vector representation, and 3) eventually clusters such a representation. Each cluster prototype results in a rule that explains the test instance prediction. We test the effectiveness of LTreeX on 71 real-world datasets and we demonstrate the validity of our approach for binary classification, regression, multi-label classification and time-to-event tasks. In all set-ups, we show that our extracted surrogate model manages to approximate the performance of the corresponding ensemble model, while selecting only few trees from the whole forest.We also show that our proposed approach substantially outperforms other explainable methods in terms of predictive performance. ",
    "url": "https://arxiv.org/abs/2203.15511",
    "authors": [
      "Klest Dedja",
      "Felipe Kenji Nakano",
      "Konstantinos Pliakos",
      "Celine Vens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15519",
    "title": "Learning neural audio features without supervision",
    "abstract": "Deep audio classification, traditionally cast as training a deep neural network on top of mel-filterbanks in a supervised fashion, has recently benefited from two independent lines of work. The first one explores \"learnable frontends\", i.e., neural modules that produce a learnable time-frequency representation, to overcome limitations of fixed features. The second one uses self-supervised learning to leverage unprecedented scales of pre-training data. In this work, we study the feasibility of combining both approaches, i.e., pre-training learnable frontend jointly with the main architecture for downstream classification. First, we show that pretraining two previously proposed frontends (SincNet and LEAF) on Audioset drastically improves linear-probe performance over fixed mel-filterbanks, suggesting that learnable time-frequency representations can benefit self-supervised pre-training even more than supervised training. Surprisingly, randomly initialized learnable filterbanks outperform mel-scaled initialization in the self-supervised setting, a counter-intuitive result that questions the appropriateness of strong priors when designing learnable filters. Through exploratory analysis of the learned frontend components, we uncover crucial differences in properties of these frontends when used in a supervised and self-supervised setting, especially the affinity of self-supervised filters to diverge significantly from the mel-scale to model a broader range of frequencies. ",
    "url": "https://arxiv.org/abs/2203.15519",
    "authors": [
      "Sarthak Yadav",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15522",
    "title": "Collision-Free Navigation using Evolutionary Symmetrical Neural Networks",
    "abstract": "Collision avoidance systems play a vital role in reducing the number of vehicle accidents and saving human lives. This paper extends the previous work using evolutionary neural networks for reactive collision avoidance. We are proposing a new method we have called symmetric neural networks. The method improves the model's performance by enforcing constraints between the network weights which reduces the model optimization search space and hence, learns more accurate control of the vehicle steering for improved maneuvering. The training and validation processes are carried out using a simulation environment - the codebase is publicly available. Extensive experiments are conducted to analyze the proposed method and evaluate its performance. The method is tested in several simulated driving scenarios. In addition, we have analyzed the effect of the rangefinder sensor resolution and noise on the overall goal of reactive collision avoidance. Finally, we have tested the generalization of the proposed method. The results are encouraging; the proposed method has improved the model's learning curve for training scenarios and generalization to the new test scenarios. Using constrained weights has significantly improved the number of generations required for the Genetic Algorithm optimization. ",
    "url": "https://arxiv.org/abs/2203.15522",
    "authors": [
      "Hesham M. Eraqi",
      "Mena Nagiub",
      "Peter Sidra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15526",
    "title": "Interactive Audio-text Representation for Automated Audio Captioning  with Contrastive Learning",
    "abstract": "Automated Audio captioning (AAC) is a cross-modal task that generates natural language to describe the content of input audio. Most prior works usually extract single-modality acoustic features and are therefore sub-optimal for the cross-modal decoding task. In this work, we propose a novel AAC system called CLIP-AAC to learn interactive cross-modality representation with both acoustic and textual information. Specifically, the proposed CLIP-AAC introduces an audio-head and a text-head in the pre-trained encoder to extract audio-text information. Furthermore, we also apply contrastive learning to narrow the domain difference by learning the correspondence between the audio signal and its paired captions. Experimental results show that the proposed CLIP-AAC approach surpasses the best baseline by a significant margin on the Clotho dataset in terms of NLP evaluation metrics. The ablation study indicates that both the pre-trained model and contrastive learning contribute to the performance gain of the AAC model. ",
    "url": "https://arxiv.org/abs/2203.15526",
    "authors": [
      "Chen Chen",
      "Nana Hou",
      "Yuchen Hu",
      "Heqing Zou",
      "Xiaofeng Qi",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15535",
    "title": "Game-theoretical trajectory planning enhances social acceptability for  humans",
    "abstract": "Since humans and robots are increasingly sharing portions of their operational spaces, experimental evidence is needed to ascertain the safety and social acceptability of robots in human-populated environments. Although several studies have aimed at devising strategies for robot trajectory planning to perform \\emph{safe} motion in populated environments, a few efforts have \\emph{measured} to what extent a robot trajectory is \\emph{accepted} by humans. Here, we present a navigation system for autonomous robotics that ensures safety and social acceptability of robotic trajectories. We overcome the typical reactive nature of state-of-the-art trajectory planners by leveraging non-cooperative game theory to design a planner that encapsulates human-like features of preservation of a vital space, recognition of groups, sequential and strategized decision making, and smooth obstacle avoidance. Social acceptability is measured through a variation of the Turing test administered in the form of a survey questionnaire to a pool of 691 participants. Comparison terms for our tests are a state-of-the-art navigation algorithm (Enhanced Vector Field Histogram, VFH) and purely human trajectories. While all participants easily recognized the non-human nature of VFH-generated trajectories, the distinction between game-theoretical trajectories and human ones were hardly revealed. These results mark a strong milestone toward the full integration of robots in social environments. ",
    "url": "https://arxiv.org/abs/2203.15535",
    "authors": [
      "Giada Galati",
      "Stefano Primatesta",
      "Sergio Grammatico",
      "Simone Macr\u00ec",
      "Alessandro Rizzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.15542",
    "title": "Modeling Users' Contextualized Page-wise Feedback for Click-Through Rate  Prediction in E-commerce Search",
    "abstract": "Modeling user's historical feedback is essential for Click-Through Rate Prediction in personalized search and recommendation. Existing methods usually only model users' positive feedback information such as click sequences which neglects the context information of the feedback. In this paper, we propose a new perspective for context-aware users' behavior modeling by including the whole page-wisely exposed products and the corresponding feedback as contextualized page-wise feedback sequence. The intra-page context information and inter-page interest evolution can be captured to learn more specific user preference. We design a novel neural ranking model RACP(i.e., Recurrent Attention over Contextualized Page sequence), which utilizes page-context aware attention to model the intra-page context. A recurrent attention process is used to model the cross-page interest convergence evolution as denoising the interest in the previous pages. Experiments on public and real-world industrial datasets verify our model's effectiveness. ",
    "url": "https://arxiv.org/abs/2203.15542",
    "authors": [
      "Zhifang Fan",
      "Dan Ou",
      "Yulong Gu",
      "Bairan Fu",
      "Xiang Li",
      "Wentian Bao",
      "Xin-Yu Dai",
      "Xiaoyi Zeng",
      "Tao Zhuang",
      "Qingwen Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15544",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "abstract": "Recent advances in neural algorithmic reasoning with graph neural networks (GNNs) are propped up by the notion of algorithmic alignment. Broadly, a neural network will be better at learning to execute a reasoning task (in terms of sample complexity) if its individual components align well with the target algorithm. Specifically, GNNs are claimed to align with dynamic programming (DP), a general problem-solving strategy which expresses many polynomial-time algorithms. However, has this alignment truly been demonstrated and theoretically quantified? Here we show, using methods from category theory and abstract algebra, that there exists an intricate connection between GNNs and DP, going well beyond the initial observations over individual algorithms such as Bellman-Ford. Exposing this connection, we easily verify several prior findings in the literature, and hope it will serve as a foundation for building stronger algorithmically aligned GNNs. ",
    "url": "https://arxiv.org/abs/2203.15544",
    "authors": [
      "Andrew Dudzik",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15547",
    "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism",
    "abstract": "Convolutional Neural Networks need the construction of informative features, which are determined by channel-wise and spatial-wise information at the network's layers. In this research, we focus on bringing in a novel solution that uses sophisticated optimization for enhancing both the spatial and channel components inside each layer's receptive field. Capsule Networks were used to understand the spatial association between features in the feature map. Standalone capsule networks have shown good results on comparatively simple datasets than on complex datasets as a result of the inordinate amount of feature information. Thus, to tackle this issue, we have proposed ME-CapsNet by introducing deeper convolutional layers to extract important features before passing through modules of capsule layers strategically to improve the performance of the network significantly. The deeper convolutional layer includes blocks of Squeeze-Excitation networks which uses a soft-pooling approach for progressively reducing the spatial size thereby dynamically recalibrating the channels by reconstructing their interdependencies without much loss of important feature information. Extensive experimentation was done using commonly used datasets demonstrating the efficiency of the proposed ME-CapsNet, which clearly outperforms various research works by achieving higher accuracy with minimal model complexity in complex datasets. ",
    "url": "https://arxiv.org/abs/2203.15547",
    "authors": [
      "Jerrin Bright",
      "Suryaprakash Rajkumar",
      "Arockia Selvakumar Arockia Doss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15565",
    "title": "Killing Two Birds with One Stone:Efficient and Robust Training of Face  Recognition CNNs by Partial FC",
    "abstract": "Learning discriminative deep feature embeddings by using million-scale in-the-wild datasets and margin-based softmax loss is the current state-of-the-art approach for face recognition. However, the memory and computing cost of the Fully Connected (FC) layer linearly scales up to the number of identities in the training set. Besides, the large-scale training data inevitably suffers from inter-class conflict and long-tailed distribution. In this paper, we propose a sparsely updating variant of the FC layer, named Partial FC (PFC). In each iteration, positive class centers and a random subset of negative class centers are selected to compute the margin-based softmax loss. All class centers are still maintained throughout the whole training process, but only a subset is selected and updated in each iteration. Therefore, the computing requirement, the probability of inter-class conflict, and the frequency of passive update on tail class centers, are dramatically reduced. Extensive experiments across different training data and backbones (e.g. CNN and ViT) confirm the effectiveness, robustness and efficiency of the proposed PFC. The source code is available at \\https://github.com/deepinsight/insightface/tree/master/recognition. ",
    "url": "https://arxiv.org/abs/2203.15565",
    "authors": [
      "Xiang An",
      "Jiankang Deng",
      "Jia Guo",
      "Ziyong Feng",
      "Xuhan Zhu",
      "Jing Yang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15576",
    "title": "Subspace-based Representation and Learning for Phonotactic Spoken  Language Recognition",
    "abstract": "Phonotactic constraints can be employed to distinguish languages by representing a speech utterance as a multinomial distribution or phone events. In the present study, we propose a new learning mechanism based on subspace-based representation, which can extract concealed phonotactic structures from utterances, for language verification and dialect/accent identification. The framework mainly involves two successive parts. The first part involves subspace construction. Specifically, it decodes each utterance into a sequence of vectors filled with phone-posteriors and transforms the vector sequence into a linear orthogonal subspace based on low-rank matrix factorization or dynamic linear modeling. The second part involves subspace learning based on kernel machines, such as support vector machines and the newly developed subspace-based neural networks (SNNs). The input layer of SNNs is specifically designed for the sample represented by subspaces. The topology ensures that the same output can be derived from identical subspaces by modifying the conventional feed-forward pass to fit the mathematical definition of subspace similarity. Evaluated on the \"General LR\" test of NIST LRE 2007, the proposed method achieved up to 52%, 46%, 56%, and 27% relative reductions in equal error rates over the sequence-based PPR-LM, PPR-VSM, and PPR-IVEC methods and the lattice-based PPR-LM method, respectively. Furthermore, on the dialect/accent identification task of NIST LRE 2009, the SNN-based system performed better than the aforementioned four baseline methods. ",
    "url": "https://arxiv.org/abs/2203.15576",
    "authors": [
      "Hung-Shin Lee",
      "Yu Tsao",
      "Shyh-Kang Jeng",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15577",
    "title": "Understanding Code Snippets in Code Reviews: A Preliminary Study of the  OpenStack Community",
    "abstract": "Code review is a mature practice for software quality assurance in software development with which reviewers check the code that has been committed by developers, and verify the quality of code. During the code review discussions, reviewers and developers might use code snippets to provide necessary information (e.g., suggestions or explanations). However, little is known about the intentions and impacts of code snippets in code reviews. To this end, we conducted a preliminary study to investigate the nature of code snippets and their purposes in code reviews. We manually collected and checked 10,790 review comments from the Nova and Neutron projects of the OpenStack community, and finally obtained 626 review comments that contain code snippets for further analysis. The results show that: (1) code snippets are not prevalently used in code reviews, and most of the code snippets are provided by reviewers. (2) We identified two high-level purposes of code snippets provided by reviewers (i.e., Suggestion and Citation) with six detailed purposes, among which, Improving Code Implementation is the most common purpose. (3) For the code snippets in code reviews with the aim of suggestion, around 68.1% was accepted by developers. The results highlight promising research directions on using code snippets in code reviews. ",
    "url": "https://arxiv.org/abs/2203.15577",
    "authors": [
      "Liming Fu",
      "Peng Liang",
      "Beiqi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.15578",
    "title": "Disentangling speech from surroundings in a neural audio codec",
    "abstract": "We present a method to separate speech signals from noisy environments in the compressed domain of a neural audio codec. We introduce a new training procedure that allows our model to produce structured encodings of audio waveforms given by embedding vectors, where one part of the embedding vector represents the speech signal, and the rest represents the environment. We achieve this by partitioning the embeddings of different input waveforms and training the model to faithfully reconstruct audio from mixed partitions, thereby ensuring each partition encodes a separate audio attribute. As use cases, we demonstrate the separation of speech from background noise or from reverberation characteristics. Our method also allows for targeted adjustments of the audio output characteristics. ",
    "url": "https://arxiv.org/abs/2203.15578",
    "authors": [
      "Ahmed Omran",
      "Neil Zeghidour",
      "Zal\u00e1n Borsos",
      "F\u00e9lix de Chaumont Quitry",
      "Malcolm Slaney",
      "Marco Tagliasacchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15587",
    "title": "RGB-D Neural Radiance Fields: Local Sampling for Faster Training",
    "abstract": "Learning a 3D representation of a scene has been a challenging problem for decades in computer vision. Recent advances in implicit neural representation from images using neural radiance fields(NeRF) have shown promising results. Some of the limitations of previous NeRF based methods include longer training time, and inaccurate underlying geometry. The proposed method takes advantage of RGB-D data to reduce training time by leveraging depth sensing to improve local sampling. This paper proposes a depth-guided local sampling strategy and a smaller neural network architecture to achieve faster training time without compromising quality. ",
    "url": "https://arxiv.org/abs/2203.15587",
    "authors": [
      "Arnab Dey",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15597",
    "title": "Sparse Pose Graph Optimization in Cycle Space",
    "abstract": "The state-of-the-art modern pose-graph optimization (PGO) systems are vertex based. In this context the number of variables might be high, albeit the number of cycles in the graph (loop closures) is relatively low. For sparse problems particularly, the cycle space has a significantly smaller dimension than the number of vertices. By exploiting this observation, in this paper we propose an alternative solution to PGO, that directly exploits the cycle space. We characterize the topology of the graph as a cycle matrix, and re-parameterize the problem using relative poses, which are further constrained by a cycle basis of the graph. We show that by using a minimum cycle basis, the cycle-based approach has superior convergence properties against its vertex-based counterpart, in terms of convergence speed and convergence to the global minimum. For sparse graphs, our cycle-based approach is also more time efficient than the vertex-based. As an additional contribution of this work we present an effective algorithm to compute the minimum cycle basis. Albeit known in computer science, we believe that this algorithm is not familiar to the robotics community. All the claims are validated by experiments on both standard benchmarks and simulated datasets. To foster the reproduction of the results, we provide a complete open-source C++ implementation (Code: \\url{https://bitbucket.org/FangBai/cycleBasedPGO) of our approach. ",
    "url": "https://arxiv.org/abs/2203.15597",
    "authors": [
      "Fang Bai",
      "Teresa Vidal-Calleja",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.15601",
    "title": "Photographic Visualization of Weather Forecasts with Generative  Adversarial Networks",
    "abstract": "Outdoor webcam images are an information-dense yet accessible visualization of past and present weather conditions, and are consulted by meteorologists and the general public alike. Weather forecasts, however, are still communicated as text, pictograms or charts. We therefore introduce a novel method that uses photographic images to also visualize future weather conditions. This is challenging, because photographic visualizations of weather forecasts should look real, be free of obvious artifacts, and should match the predicted weather conditions. The transition from observation to forecast should be seamless, and there should be visual continuity between images for consecutive lead times. We use conditional Generative Adversarial Networks to synthesize such visualizations. The generator network, conditioned on the analysis and the forecasting state of the numerical weather prediction (NWP) model, transforms the present camera image into the future. The discriminator network judges whether a given image is the real image of the future, or whether it has been synthesized. Training the two networks against each other results in a visualization method that scores well on all four evaluation criteria. We present results for three camera sites across Switzerland that differ in climatology and terrain. We show that users find it challenging to distinguish real from generated images, performing not much better than if they guessed randomly. The generated images match the atmospheric, ground and illumination conditions of the COSMO-1 NWP model forecast in at least 89 % of the examined cases. Nowcasting sequences of generated images achieve a seamless transition from observation to forecast and attain visual continuity. ",
    "url": "https://arxiv.org/abs/2203.15601",
    "authors": [
      "Christian Sigg",
      "Flavia Cavallaro",
      "Tobias G\u00fcnther",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15638",
    "title": "NL-FCOS: Improving FCOS through Non-Local Modules for Object Detection",
    "abstract": "During the last years, we have seen significant advances in the object detection task, mainly due to the outperforming results of convolutional neural networks. In this vein, anchor-based models have achieved the best results. However, these models require prior information about the aspect and scales of target objects, needing more hyperparameters to fit. In addition, using anchors to fit bounding boxes seems far from how our visual system does the same visual task. Instead, our visual system uses the interactions of different scene parts to semantically identify objects, called perceptual grouping. An object detection methodology closer to the natural model is anchor-free detection, where models like FCOS or Centernet have shown competitive results, but these have not yet exploited the concept of perceptual grouping. Therefore, to increase the effectiveness of anchor-free models keeping the inference time low, we propose to add non-local attention (NL modules) modules to boost the feature map of the underlying backbone. NL modules implement the perceptual grouping mechanism, allowing receptive fields to cooperate in visual representation learning. We show that non-local modules combined with an FCOS head (NL-FCOS) are practical and efficient. Thus, we establish state-of-the-art performance in clothing detection and handwritten amount recognition problems. ",
    "url": "https://arxiv.org/abs/2203.15638",
    "authors": [
      "Lukas Pavez",
      "Jose M. Saavedra Rondo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15640",
    "title": "Synthesis and Execution of Communicative Robotic Movements with  Generative Adversarial Networks",
    "abstract": "Object manipulation is a natural activity we perform every day. How humans handle objects can communicate not only the willfulness of the acting, or key aspects of the context where we operate, but also the properties of the objects involved, without any need for explicit verbal description. Since human intelligence comprises the ability to read the context, allowing robots to perform actions that intuitively convey this kind of information would greatly facilitate collaboration. In this work, we focus on how to transfer on two different robotic platforms the same kinematics modulation that humans adopt when manipulating delicate objects, aiming to endow robots with the capability to show carefulness in their movements. We choose to modulate the velocity profile adopted by the robots' end-effector, inspired by what humans do when transporting objects with different characteristics. We exploit a novel Generative Adversarial Network architecture, trained with human kinematics examples, to generalize over them and generate new and meaningful velocity profiles, either associated with careful or not careful attitudes. This approach would allow next generation robots to select the most appropriate style of movement, depending on the perceived context, and autonomously generate their motor action execution. ",
    "url": "https://arxiv.org/abs/2203.15640",
    "authors": [
      "Linda Lastrico",
      "Luca Garello",
      "Alessandra Sciutti",
      "Nicoletta Noceti",
      "Fulvio Mastrogiovanni",
      "Francesco Rea"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15651",
    "title": "Gaze-based Object Detection in the Wild",
    "abstract": "In human-robot collaboration, one challenging task is to teach a robot new yet unknown objects. Thereby, gaze can contain valuable information. We investigate if it is possible to detect objects (object or no object) from gaze data and determine their bounding box parameters. For this purpose, we explore different sizes of temporal windows, which serve as a basis for the computation of heatmaps, i.e., the spatial distribution of the gaze data. Additionally, we analyze different grid sizes of these heatmaps, and various machine learning techniques are applied. To generate the data, we conducted a small study with five subjects who could move freely and thus, turn towards arbitrary objects. This way, we chose a scenario for our data collection that is as realistic as possible. Since the subjects move while facing objects, the heatmaps also contain gaze data trajectories, complicating the detection and parameter regression. ",
    "url": "https://arxiv.org/abs/2203.15651",
    "authors": [
      "Daniel Weber",
      "Wolfgang Fuhl",
      "Andreas Zell",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15655",
    "title": "Parameterized Consistency Learning-based Deep Polynomial Chaos Neural  Network Method for Reliability Analysis in Aerospace Engineering",
    "abstract": "Polynomial chaos expansion (PCE) is a powerful surrogate model-based reliability analysis method in aerospace engineering. Generally, a PCE model with a higher expansion order is usually required to obtain an accurate surrogate model for some non-linear complex stochastic systems. However, the high-order PCE increases the labeled training data cost for solving the expansion coefficients. To alleviate this problem, this paper proposes a parameterized consistency learning-based deep polynomial chaos neural network (Deep PCNN) method, including the low-order adaptive PCE model (the auxiliary model) and the high-order polynomial chaos neural network (the main model). The expansion coefficients of the high-order main model are parameterized into the learnable weights of the polynomial chaos neural network. The auxiliary model uses a proposed unsupervised consistency loss function to assist in training the main model. The Deep PCNN method can significantly reduce the training data cost in constructing a high-order PCE model without losing surrogate model accuracy by using a small amount of labeled data and many unlabeled data. A numerical example validates the effectiveness of the Deep PCNN method, and the Deep PCNN method is applied to analyze the reliability of two aerospace engineering systems. ",
    "url": "https://arxiv.org/abs/2203.15655",
    "authors": [
      "Xiaohu Zheng",
      "Wen Yao",
      "Yunyang Zhang",
      "Xiaoya Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15661",
    "title": "Temporal Robustness of Temporal Logic Specifications: Analysis and  Control Design",
    "abstract": "We study the temporal robustness of temporal logic specifications and show how to design temporally robust control laws for time-critical control systems. This topic is of particular interest in connected systems and interleaving processes such as multi-robot and human-robot systems where uncertainty in the behavior of individual agents and humans can induce timing uncertainty. Despite the importance of time-critical systems, temporal robustness of temporal logic specifications has not been studied, especially from a control design point of view. We define synchronous and asynchronous temporal robustness and show that these notions quantify the robustness with respect to synchronous and asynchronous time shifts in the predicates of the temporal logic specification. It is further shown that the synchronous temporal robustness upper bounds the asynchronous temporal robustness. We then study the control design problem in which we aim to design a control law that maximizes the temporal robustness of a dynamical system. Our solution consists of a Mixed-Integer Linear Programming (MILP) encoding that can be used to obtain a sequence of optimal control inputs. While asynchronous temporal robustness is arguably more nuanced than synchronous temporal robustness, we show that control design using synchronous temporal robustness is computationally more efficient. This trade-off can be exploited by the designer depending on the particular application at hand. We conclude the paper with a variety of case studies. ",
    "url": "https://arxiv.org/abs/2203.15661",
    "authors": [
      "Al\u00ebna Rodionova",
      "Lars Lindemann",
      "Manfred Morari",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2203.15664",
    "title": "Nearly Minimax Algorithms for Linear Bandits with Shared Representation",
    "abstract": "We give novel algorithms for multi-task and lifelong linear bandits with shared representation. Specifically, we consider the setting where we play $M$ linear bandits with dimension $d$, each for $T$ rounds, and these $M$ bandit tasks share a common $k(\\ll d)$ dimensional linear representation. For both the multi-task setting where we play the tasks concurrently, and the lifelong setting where we play tasks sequentially, we come up with novel algorithms that achieve $\\widetilde{O}\\left(d\\sqrt{kMT} + kM\\sqrt{T}\\right)$ regret bounds, which matches the known minimax regret lower bound up to logarithmic factors and closes the gap in existing results [Yang et al., 2021]. Our main technique include a more efficient estimator for the low-rank linear feature extractor and an accompanied novel analysis for this estimator. ",
    "url": "https://arxiv.org/abs/2203.15664",
    "authors": [
      "Jiaqi Yang",
      "Qi Lei",
      "Jason D. Lee",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.15674",
    "title": "Exploring Frequency Adversarial Attacks for Face Forgery Detection",
    "abstract": "Various facial manipulation techniques have drawn serious public concerns in morality, security, and privacy. Although existing face forgery classifiers achieve promising performance on detecting fake images, these methods are vulnerable to adversarial examples with injected imperceptible perturbations on the pixels. Meanwhile, many face forgery detectors always utilize the frequency diversity between real and fake faces as a crucial clue. In this paper, instead of injecting adversarial perturbations into the spatial domain, we propose a frequency adversarial attack method against face forgery detectors. Concretely, we apply discrete cosine transform (DCT) on the input images and introduce a fusion module to capture the salient region of adversary in the frequency domain. Compared with existing adversarial attacks (e.g. FGSM, PGD) in the spatial domain, our method is more imperceptible to human observers and does not degrade the visual quality of the original images. Moreover, inspired by the idea of meta-learning, we also propose a hybrid adversarial attack that performs attacks in both the spatial and frequency domains. Extensive experiments indicate that the proposed method fools not only the spatial-based detectors but also the state-of-the-art frequency-based detectors effectively. In addition, the proposed frequency attack enhances the transferability across face forgery detectors as black-box attacks. ",
    "url": "https://arxiv.org/abs/2203.15674",
    "authors": [
      "Shuai Jia",
      "Chao Ma",
      "Taiping Yao",
      "Bangjie Yin",
      "Shouhong Ding",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15683",
    "title": "DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level  and Utterance-Level Acoustic Representation Learning",
    "abstract": "Most text-to-speech (TTS) methods use high-quality speech corpora recorded in a well-designed environment, incurring a high cost for data collection. To solve this problem, existing noise-robust TTS methods are intended to use noisy speech corpora as training data. However, they only address either time-invariant or time-variant noises. We propose a degradation-robust TTS method, which can be trained on speech corpora that contain both additive noises and environmental distortions. It jointly represents the time-variant additive noises with a frame-level encoder and the time-invariant environmental distortions with an utterance-level encoder. We also propose a regularization method to attain clean environmental embedding that is disentangled from the utterance-dependent information such as linguistic contents and speaker characteristics. Evaluation results show that our method achieved significantly higher-quality synthetic speech than previous methods in the condition including both additive noise and reverberation. ",
    "url": "https://arxiv.org/abs/2203.15683",
    "authors": [
      "Takaaki Saeki",
      "Kentaro Tachibana",
      "Ryuichi Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15687",
    "title": "Texture based Prototypical Network for Few-Shot Semantic Segmentation of  Forest Cover: Generalizing for Different Geographical Regions",
    "abstract": "Forest plays a vital role in reducing greenhouse gas emissions and mitigating climate change besides maintaining the world's biodiversity. The existing satellite-based forest monitoring system utilizes supervised learning approaches that are limited to a particular region and depend on manually annotated data to identify forest. This work envisages forest identification as a few-shot semantic segmentation task to achieve generalization across different geographical regions. The proposed few-shot segmentation approach incorporates a texture attention module in the prototypical network to highlight the texture features of the forest. Indeed, the forest exhibits a characteristic texture different from other classes, such as road, water, etc. In this work, the proposed approach is trained for identifying tropical forests of South Asia and adapted to determine the temperate forest of Central Europe with the help of a few (one image for 1-shot) manually annotated support images of the temperate forest. An IoU of 0.62 for forest class (1-way 1-shot) was obtained using the proposed method, which is significantly higher (0.46 for PANet) than the existing few-shot semantic segmentation approach. This result demonstrates that the proposed approach can generalize across geographical regions for forest identification, creating an opportunity to develop a global forest cover identification tool. ",
    "url": "https://arxiv.org/abs/2203.15687",
    "authors": [
      "Gokul P",
      "Ujjwal Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15691",
    "title": "Improved Counting and Localization from Density Maps for Object  Detection in 2D and 3D Microscopy Imaging",
    "abstract": "Object counting and localization are key steps for quantitative analysis in large-scale microscopy applications. This procedure becomes challenging when target objects are overlapping, are densely clustered, and/or present fuzzy boundaries. Previous methods producing density maps based on deep learning have reached a high level of accuracy for object counting by assuming that object counting is equivalent to the integration of the density map. However, this model fails when objects show significant overlap regarding accurate localization. We propose an alternative method to count and localize objects from the density map to overcome this limitation. Our procedure includes the following three key aspects: 1) Proposing a new counting method based on the statistical properties of the density map, 2) optimizing the counting results for those objects which are well-detected based on the proposed counting method, and 3) improving localization of poorly detected objects using the proposed counting method as prior information. Validation includes processing of microscopy data with known ground truth and comparison with other models that use conventional processing of the density map. Our results show improved performance in counting and localization of objects in 2D and 3D microscopy data. Furthermore, the proposed method is generic, considering various applications that rely on the density map approach. Our code will be released post-review. ",
    "url": "https://arxiv.org/abs/2203.15691",
    "authors": [
      "Shijie Li",
      "Thomas Ach",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15696",
    "title": "Auditing Privacy Defenses in Federated Learning via Generative Gradient  Leakage",
    "abstract": "Federated Learning (FL) framework brings privacy benefits to distributed learning systems by allowing multiple clients to participate in a learning task under the coordination of a central server without exchanging their private data. However, recent studies have revealed that private information can still be leaked through shared gradient information. To further protect user's privacy, several defense mechanisms have been proposed to prevent privacy leakage via gradient information degradation methods, such as using additive noise or gradient compression before sharing it with the server. In this work, we validate that the private training data can still be leaked under certain defense settings with a new type of leakage, i.e., Generative Gradient Leakage (GGL). Unlike existing methods that only rely on gradient information to reconstruct data, our method leverages the latent space of generative adversarial networks (GAN) learned from public image datasets as a prior to compensate for the informational loss during gradient degradation. To address the nonlinearity caused by the gradient operator and the GAN model, we explore various gradient-free optimization methods (e.g., evolution strategies and Bayesian optimization) and empirically show their superiority in reconstructing high-quality images from gradients compared to gradient-based optimizers. We hope the proposed method can serve as a tool for empirically measuring the amount of privacy leakage to facilitate the design of more robust defense mechanisms. ",
    "url": "https://arxiv.org/abs/2203.15696",
    "authors": [
      "Zhuohang Li",
      "Jiaxin Zhang",
      "Luyang Liu",
      "Jian Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15706",
    "title": "Stabilized Neural Ordinary Differential Equations for Long-Time  Forecasting of Dynamical Systems",
    "abstract": "In data-driven modeling of spatiotemporal phenomena careful consideration often needs to be made in capturing the dynamics of the high wavenumbers. This problem becomes especially challenging when the system of interest exhibits shocks or chaotic dynamics. We present a data-driven modeling method that accurately captures shocks and chaotic dynamics by proposing a novel architecture, stabilized neural ordinary differential equation (ODE). In our proposed architecture, we learn the right-hand-side (RHS) of an ODE by adding the outputs of two NN together where one learns a linear term and the other a nonlinear term. Specifically, we implement this by training a sparse linear convolutional NN to learn the linear term and a dense fully-connected nonlinear NN to learn the nonlinear term. This is in contrast with the standard neural ODE which involves training only a single NN for learning the RHS. We apply this setup to the viscous Burgers equation, which exhibits shocked behavior, and show better short-time tracking and prediction of the energy spectrum at high wavenumbers than a standard neural ODE. We also find that the stabilized neural ODE models are much more robust to noisy initial conditions than the standard neural ODE approach. We also apply this method to chaotic trajectories of the Kuramoto-Sivashinsky equation. In this case, stabilized neural ODEs keep long-time trajectories on the attractor, and are highly robust to noisy initial conditions, while standard neural ODEs fail at achieving either of these results. We conclude by demonstrating how stabilizing neural ODEs provide a natural extension for use in reduced-order modeling by projecting the dynamics onto the eigenvectors of the learned linear term. ",
    "url": "https://arxiv.org/abs/2203.15706",
    "authors": [
      "Alec J. Linot",
      "Josh W. Burby",
      "Qi Tang",
      "Prasanna Balaprakash",
      "Michael D. Graham",
      "Romit Maulik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15721",
    "title": "On Decoding Strategies for Neural Text Generators",
    "abstract": "When generating text from probabilistic models, the chosen decoding strategy has a profound effect on the resulting text. Yet the properties elicited by various decoding strategies do not always transfer across natural language generation tasks. For example, while mode-seeking methods like beam search perform remarkably well for machine translation, they have been observed to lead to incoherent and repetitive text in story generation. Despite such observations, the effectiveness of decoding strategies is often assessed with respect to only a single task. This work -- in contrast -- provides a comprehensive analysis of the interaction between language generation tasks and decoding strategies. Specifically, we measure changes in attributes of generated text as a function of both decoding strategy and task using human and automatic evaluation. Our results reveal both previously-observed and surprising findings. For example, the nature of the diversity-quality trade-off in language generation is very task-specific; the length bias often attributed to beam search is not constant across tasks. ",
    "url": "https://arxiv.org/abs/2203.15721",
    "authors": [
      "Gian Wiher",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15722",
    "title": "Transformer Network-based Reinforcement Learning Method for Power  Distribution Network (PDN) Optimization of High Bandwidth Memory (HBM)",
    "abstract": "In this article, for the first time, we propose a transformer network-based reinforcement learning (RL) method for power distribution network (PDN) optimization of high bandwidth memory (HBM). The proposed method can provide an optimal decoupling capacitor (decap) design to maximize the reduction of PDN self- and transfer impedance seen at multiple ports. An attention-based transformer network is implemented to directly parameterize decap optimization policy. The optimality performance is significantly improved since the attention mechanism has powerful expression to explore massive combinatorial space for decap assignments. Moreover, it can capture sequential relationships between the decap assignments. The computing time for optimization is dramatically reduced due to the reusable network on positions of probing ports and decap assignment candidates. This is because the transformer network has a context embedding process to capture meta-features including probing ports positions. In addition, the network is trained with randomly generated data sets. Therefore, without additional training, the trained network can solve new decap optimization problems. The computing time for training and data cost are critically decreased due to the scalability of the network. Thanks to its shared weight property, the network can adapt to a larger scale of problems without additional training. For verification, we compare the results with conventional genetic algorithm (GA), random search (RS), and all the previous RL-based methods. As a result, the proposed method outperforms in all the following aspects: optimality performance, computing time, and data efficiency. ",
    "url": "https://arxiv.org/abs/2203.15722",
    "authors": [
      "Hyunwook Park",
      "Minsu Kim",
      "Seongguk Kim",
      "Keunwoo Kim",
      "Haeyeon Kim",
      "Taein Shin",
      "Keeyoung Son",
      "Boogyo Sim",
      "Subin Kim",
      "Seungtaek Jeong",
      "Chulsoon Hwang",
      "Joungho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15724",
    "title": "On $d$-stable locally checkable problems on bounded mim-width graphs",
    "abstract": "In this paper we continue the study of locally checkable problems under the framework introduced by Bonomo-Braberman and Gonzalez in 2020, by focusing on graphs of bounded mim-width. We study which restrictions on a locally checkable problem are necessary in order to be able to solve it efficiently on graphs of bounded mim-width. To this end, we introduce the concept of $d$-stability of a check function. The related locally checkable problems contain large classes of problems, among which we can mention, for example, LCVP problems. We provide an algorithm which solves all $d$-stable locally checkable problems on graphs of bounded mim-width in polynomial time and explain how we can include additional global properties (size of the color classes and connectivity). We explore the relation between $d$-stable locally checkable problems with the recently introduced DN-logic (Bergougnoux, Dreier and Jaffke, 2022). We conclude by listing concrete examples of problems whose complexity on graphs of bounded mim-width was open so far. ",
    "url": "https://arxiv.org/abs/2203.15724",
    "authors": [
      "Carolina Luc\u00eda Gonzalez",
      "Felix Mann"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2203.15733",
    "title": "Energy Balancing Algorithm for Wireless Sensor Network",
    "abstract": "A Wireless Sensor Network (WSN) is made up of a large number of nodes that are spread randomly or on a regular basis to detect the surrounding environment and transfer data to a base station (BS) over the Internet to the user. It is widely used in a variety of civil and military concerns. Because the sensor has limited battery capacity, energy efficiency is a critical issue with WSNs. As a result, developing a routing protocol that decreases energy consumption in sensor nodes to extend the lifetime of the WSN using an intelligence algorithm has become difficult. LEACH is the first hierarchical routing protocol that divides the WSN into clusters to reduce energy usage. However, it has reached its limit in selecting a suitable cluster head and the sensor nodes to be joined, as well as their quantity. Thus, this research proposes an algorithm called Wireless Energy Balancing algorithm (WEB) that works on energy balancing distribution by identifying a suitable cluster head with minimum distance and high energy. Then it uses the knapsack-problem as a novel algorithm to design the cluster members. The simulation results demonstrate that the WEB algorithm outperforms LEACH by 31% in terms of energy conservation and WSN lifetime extension. ",
    "url": "https://arxiv.org/abs/2203.15733",
    "authors": [
      "Ghassan Samara",
      "Mohammad A. Hassan",
      "Munir Al-Okour"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.15738",
    "title": "Encryption and encoding of facial images into quick response and high  capacity color 2d code for biometric passport security system",
    "abstract": "In this thesis, a multimodal biometric, secure encrypted data and encrypted biometric encoded into the QR code-based biometric-passport authentication method is proposed for national security applications. Firstly, using the Extended Profile - Local Binary Patterns (EP-LBP), a Canny edge detector, and the Scale Invariant Feature Transform (SIFT) algorithm with Image File Information (IMFINFO) process, the facial mark size recognition is initially achieved. Secondly, by using the Active Shape Model (ASM) into Active Appearance Model (AAM) to follow the hand and infusion the hand geometry characteristics for verification and identification, hand geometry recognition is achieved. Thirdly, the encrypted biometric passport information that is publicly accessible is encoded into the QR code and inserted into the electronic passport to improve protection. Further, Personal information and biometric data are encrypted by applying the Advanced Encryption Standard (AES) and the Secure Hash Algorithm (SHA) 256 algorithm. It will enhance the biometric passport security system. ",
    "url": "https://arxiv.org/abs/2203.15738",
    "authors": [
      "Ziaul Haque Choudhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15745",
    "title": "Super-resolving multiple scatterers detection in SAR Tomography assisted  by correlation information",
    "abstract": "This paper proposes a method for detecting multiple scatterers (targets) in the elevation direction for synthetic aperture radar (SAR) tomography. The proposed method can resolve closely spaced targets through a twostep procedure. In the first step, coarse detection is performed with a successive cancellation scheme in which possible locations of targets are marked. Then, in the second step, by searching in the reduced search space which is finely 10 gridded, the accurate location of the targets is found. For estimating the actual number of targets, a model order selection scheme is used in two cases of known and unknown noise variance. Also, by analytical investigation of the probability of detection for the proposed method, the effect of the influential parameters on the detection ability is explicitly demonstrated. Compared to the super-resolution methods based on compressed sensing (CS), the proposed method has a lower computational cost and higher estimation accuracy, especially at low signal-to-noise ratio regime. 15 Simulation results show the superiority of the proposed method in terms of both 3D scatterer reconstruction and detection ability ",
    "url": "https://arxiv.org/abs/2203.15745",
    "authors": [
      "Ahmad Naghavia",
      "Mohammad Sadegh Fazel",
      "Mojtaba Beheshti",
      "Ehsan Yazdian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.15752",
    "title": "Information Consumption and Boundary Spanning in Decentralized Online  Social Networks: the case of Mastodon Users",
    "abstract": "Decentralized Online Social Networks (DOSNs) represent a growing trend in the social media landscape, as opposed to the well-known centralized peers, which are often in the spotlight due to privacy concerns and a vision typically focused on monetization through user relationships. By exploiting open-source software, DOSNs allow users to create their own servers, or instances, thus favoring the proliferation of platforms that are independent yet interconnected with each other in a transparent way. Nonetheless, the resulting cooperation model, commonly known as the Fediverse, still represents a world to be fully discovered, since existing studies have mainly focused on a limited number of structural aspects of interest in DOSNs. In this work, we aim to fill a lack of study on user relations and roles in DOSNs, by taking two main actions: understanding the impact of decentralization on how users relate to each other within their membership instance and/or across different instances, and unveiling user roles that can explain two interrelated axes of social behavioral phenomena, namely information consumption and boundary spanning. To this purpose, we build our analysis on user networks from Mastodon, since it represents the most widely used DOSN platform. We believe that the findings drawn from our study on Mastodon users' roles and information flow can pave a way for further development of fascinating research on DOSNs. ",
    "url": "https://arxiv.org/abs/2203.15752",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2203.15770",
    "title": "Target Geometry Estimation Using Deep Neural Networks in Sonar Sensing",
    "abstract": "Accurate imaging of target shape is a crucial aspect of wideband FM biosonar in echolocating bats, for which we have developed new algorithms that provide a solution for the shape of complicated targets in the computational domain. We use recurrent neural networks and convolutional neural networks to determine the number of glints (i.e., major reflecting surfaces) making up the target's structure and the distances between the glints (target shape in sonar). Echoes are dechirped relative to broadcasts, and the dechirped spectrograms are scanned in short time segments to find local spectral ripple patterns arising from different interglint delay separations. By proceeding in successive time-window slices, we mimic time-frequency neural processing in the bat's auditory system as a novel means of real-time target discrimination for sonar sensing in robotics. ",
    "url": "https://arxiv.org/abs/2203.15770",
    "authors": [
      "Chen Ming",
      "James A. Simmons"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15789",
    "title": "Revisiting Neighborhood-based Link Prediction for Collaborative  Filtering",
    "abstract": "Collaborative filtering (CF) is one of the most successful and fundamental techniques in recommendation systems. In recent years, Graph Neural Network (GNN)-based CF models, such as NGCF [31], LightGCN [10] and GTN [9] have achieved tremendous success and significantly advanced the state-of-the-art. While there is a rich literature of such works using advanced models for learning user and item representations separately, item recommendation is essentially a link prediction problem between users and items. Furthermore, while there have been early works employing link prediction for collaborative filtering [5, 6], this trend has largely given way to works focused on aggregating information from user and item nodes, rather than modeling links directly. In this paper, we propose a new linkage (connectivity) score for bipartite graphs, generalizing multiple standard link prediction methods. We combine this new score with an iterative degree update process in the user-item interaction bipartite graph to exploit local graph structures without any node modeling. The result is a simple, non-deep learning model with only six learnable parameters. Despite its simplicity, we demonstrate our approach significantly outperforms existing state-of-the-art GNN-based CF approaches on four widely used benchmarks. In particular, on Amazon-Book, we demonstrate an over 60% improvement for both Recall and NDCG. We hope our work would invite the community to revisit the link prediction aspect of collaborative filtering, where significant performance gains could be achieved through aligning link prediction with item recommendations. ",
    "url": "https://arxiv.org/abs/2203.15789",
    "authors": [
      "Hao-Ming Fu",
      "Patrick Poirson",
      "Kwot Sin Lee",
      "Chen Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15793",
    "title": "Instance Relation Graph Guided Source-Free Domain Adaptive Object  Detection",
    "abstract": "Unsupervised Domain Adaptation (UDA) is an effective approach to tackle the issue of domain shift. Specifically, UDA methods try to align the source and target representations to improve the generalization on the target domain. Further, UDA methods work under the assumption that the source data is accessible during the adaptation process. However, in real-world scenarios, the labelled source data is often restricted due to privacy regulations, data transmission constraints, or proprietary data concerns. The Source-Free Domain Adaptation (SFDA) setting aims to alleviate these concerns by adapting a source-trained model for the target domain without requiring access to the source data. In this paper, we explore the SFDA setting for the task of adaptive object detection. To this end, we propose a novel training strategy for adapting a source-trained object detector to the target domain without source data. More precisely, we design a novel contrastive loss to enhance the target representations by exploiting the objects relations for a given target domain input. These object instance relations are modelled using an Instance Relation Graph (IRG) network, which are then used to guide the contrastive representation learning. In addition, we utilize a student-teacher based knowledge distillation strategy to avoid overfitting to the noisy pseudo-labels generated by the source-trained model. Extensive experiments on multiple object detection benchmark datasets show that the proposed approach is able to efficiently adapt source-trained object detectors to the target domain, outperforming previous state-of-the-art domain adaptive detection methods. Code is available at https://github.com/Vibashan/irg-sfda. ",
    "url": "https://arxiv.org/abs/2203.15793",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15798",
    "title": "DRaCoN -- Differentiable Rasterization Conditioned Neural Radiance  Fields for Articulated Avatars",
    "abstract": "Acquisition and creation of digital human avatars is an important problem with applications to virtual telepresence, gaming, and human modeling. Most contemporary approaches for avatar generation can be viewed either as 3D-based methods, which use multi-view data to learn a 3D representation with appearance (such as a mesh, implicit surface, or volume), or 2D-based methods which learn photo-realistic renderings of avatars but lack accurate 3D representations. In this work, we present, DRaCoN, a framework for learning full-body volumetric avatars which exploits the advantages of both the 2D and 3D neural rendering techniques. It consists of a Differentiable Rasterization module, DiffRas, that synthesizes a low-resolution version of the target image along with additional latent features guided by a parametric body model. The output of DiffRas is then used as conditioning to our conditional neural 3D representation module (c-NeRF) which generates the final high-res image along with body geometry using volumetric rendering. While DiffRas helps in obtaining photo-realistic image quality, c-NeRF, which employs signed distance fields (SDF) for 3D representations, helps to obtain fine 3D geometric details. Experiments on the challenging ZJU-MoCap and Human3.6M datasets indicate that DRaCoN outperforms state-of-the-art methods both in terms of error metrics and visual quality. ",
    "url": "https://arxiv.org/abs/2203.15798",
    "authors": [
      "Amit Raj",
      "Umar Iqbal",
      "Koki Nagano",
      "Sameh Khamis",
      "Pavlo Molchanov",
      "James Hays",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.13714",
    "title": "MSR-NV: Neural Vocoder Using Multiple Sampling Rates",
    "abstract": "The development of neural vocoders (NVs) has resulted in the high-quality and fast generation of waveforms. However, conventional NVs target a single sampling rate and require re-training when applied to different sampling rates. A suitable sampling rate varies from application to application due to the trade-off between speech quality and generation speed. In this study, we propose a method to handle multiple sampling rates in a single NV, called the MSR-NV. By generating waveforms step-by-step starting from a low sampling rate, MSR-NV can efficiently learn the characteristics of each frequency band and synthesize high-quality speech at multiple sampling rates. It can be regarded as an extension of the previously proposed NVs, and in this study, we extend the structure of Parallel WaveGAN (PWG). Experimental evaluation results demonstrate that the proposed method achieves remarkably higher subjective quality than the original PWG trained separately at 16, 24, and 48 kHz, without increasing the inference time. We also show that MSR-NV can leverage speech with lower sampling rates to further improve the quality of the synthetic speech. ",
    "url": "https://arxiv.org/abs/2109.13714",
    "authors": [
      "Kentaro Mitsui",
      "Kei Sawada"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.13847",
    "title": "Cluster Algebras: Network Science and Machine Learning",
    "abstract": "Cluster algebras have recently become an important player in mathematics and physics. In this work, we investigate them through the lens of modern data science, specifically with techniques from network science and machine-learning. Network analysis methods are applied to the exchange graphs for cluster algebras of varying mutation types. The analysis indicates that when the graphs are represented without identifying by permutation equivalence between clusters an elegant symmetry emerges in the quiver exchange graph embedding. The ratio between number of seeds and number of quivers associated to this symmetry is computed for finite Dynkin type algebras up to rank 5, and conjectured for higher ranks. Simple machine learning techniques successfully learn to differentiate cluster algebras from their seeds. The learning performance exceeds 0.9 accuracies between algebras of the same mutation type and between types, as well as relative to artificially generated data. ",
    "url": "https://arxiv.org/abs/2203.13847",
    "authors": [
      "Pierre-Philippe Dechant",
      "Yang-Hui He",
      "Elli Heyes",
      "Edward Hirst"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2203.14173",
    "title": "Maximal origami flip graphs of flat-foldable vertices: properties and  algorithms",
    "abstract": "Flat origami studies straight line, planar graphs $C=(V,E)$ drawn on a region $R\\subset\\mathbb{R}^2$ that can act as crease patterns to map, or fold, $R$ into $\\mathbb{R}^2$ in a way that is continuous and a piecewise isometry exactly on the faces of $C$. Associated with such crease pattern graphs are valid mountain-valley (MV) assignments $\\mu:E\\to\\{-1,1\\}$, indicating which creases can be mountains (convex) or valleys (concave) to allow $R$ to physically fold flat without self-intersecting. In this paper, we initiate the first study of how valid MV assignments of single-vertex crease patterns are related to one another via face-flips, a concept that emerged from applications of origami in engineering and physics, where flipping a face $F$ means switching the MV parity of all creases of $C$ that border $F$. Specifically, we study the origami flip graph ${\\rm{OFG}}(C)$, whose vertices are all valid MV assignments of $C$ and edges connect assignments that differ by only one face flip. We prove that, for the single-vertex crease pattern $A_{2n}$ whose $2n$ sector angles around the vertex are all equal, ${\\rm{OFG}}(A_{2n})$ contains as subgraphs all other origami flip graphs of degree-$2n$ flat origami vertex crease patterns. We also prove that ${\\rm{OFG}}(A_{2n})$ is connected and has diameter $n$ by providing two $O(n^2)$ algorithms to traverse between vertices in the graph, and we enumerate the vertices, edges, and degree sequence of ${\\rm{OFG}}(A_{2n})$. We conclude with open questions on the surprising complexity found in origami flip graphs of this type. ",
    "url": "https://arxiv.org/abs/2203.14173",
    "authors": [
      "Thomas C. Hull",
      "Manuel Morales",
      "Sarah Nash",
      "Natalya Ter-Saakov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2203.15009",
    "title": "DAMNETS: A Deep Autoregressive Model for Generating Markovian Network  Time Series",
    "abstract": "In this work, we introduce DAMNETS, a deep generative model for Markovian network time series. Time series of networks are found in many fields such as trade or payment networks in economics, contact networks in epidemiology or social media posts over time. Generative models of such data are useful for Monte-Carlo estimation and data set expansion, which is of interest for both data privacy and model fitting. Using recent ideas from the Graph Neural Network (GNN) literature, we introduce a novel GNN encoder-decoder structure in which an encoder GNN learns a latent representation of the input graph, and a decoder GNN uses this representation to simulate the network dynamics. We show using synthetic data sets that DAMNETS can replicate features of network topology across time observed in the real world, such as changing community structure and preferential attachment. DAMNETS outperforms competing methods on all of our measures of sample quality over several real and synthetic data sets. ",
    "url": "https://arxiv.org/abs/2203.15009",
    "authors": [
      "Jase Clarkson",
      "Mihai Cucuringu",
      "Andrew Elliott",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.15081",
    "title": "Word Discovery in Visually Grounded, Self-Supervised Speech Models",
    "abstract": "We present a method for visually-grounded spoken term discovery. After training either a HuBERT or wav2vec2.0 model to associate spoken captions with natural images, we show that powerful word segmentation and clustering capability emerges within the model's self-attention heads. Our experiments reveal that this ability is not present to nearly the same extent in the base HuBERT and wav2vec2.0 models, suggesting that the visual grounding task is a crucial component of the word discovery capability we observe. We also evaluate our method on the Buckeye word segmentation and ZeroSpeech spoken term discovery tasks, where we outperform all currently published methods on several metrics. ",
    "url": "https://arxiv.org/abs/2203.15081",
    "authors": [
      "Puyuan Peng",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15183",
    "title": "Visualizations of Complex Sequences of Family-Infant Vocalizations Using  Bag-of-Audio-Words Approach Based on Wav2vec 2.0 Features",
    "abstract": "In the U.S., approximately 15-17% of children 2-8 years of age are estimated to have at least one diagnosed mental, behavioral or developmental disorder. However, such disorders often go undiagnosed, and the ability to evaluate and treat disorders in the first years of life is limited. To analyze infant developmental changes, previous studies have shown advanced ML models excel at classifying infant and/or parent vocalizations collected using cell phone, video, or audio-only recording device like LENA. In this study, we pilot test the audio component of a new infant wearable multi-modal device that we have developed called LittleBeats (LB). LB audio pipeline is advanced in that it provides reliable labels for both speaker diarization and vocalization classification tasks, compared with other platforms that only record audio and/or provide speaker diarization labels. We leverage wav2vec 2.0 to obtain superior and more nuanced results with the LB family audio stream. We use a bag-of-audio-words method with wav2vec 2.0 features to create high-level visualizations to understand family-infant vocalization interactions. We demonstrate that our high-quality visualizations capture major types of family vocalization interactions, in categories indicative of mental, behavioral, and developmental health, for both labeled and unlabeled LB audio. ",
    "url": "https://arxiv.org/abs/2203.15183",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15275",
    "title": "A Multi-size Kernel based Adaptive Convolutional Neural Network for  Bearing Fault Diagnosis",
    "abstract": "Bearing fault identification and analysis is an important research area in the field of machinery fault diagnosis. Aiming at the common faults of rolling bearings, we propose a data-driven diagnostic algorithm based on the characteristics of bearing vibrations called multi-size kernel based adaptive convolutional neural network (MSKACNN). Using raw bearing vibration signals as the inputs, MSKACNN provides vibration feature learning and signal classification capabilities to identify and analyze bearing faults. Ball mixing is a ball bearing production quality problem that is difficult to identify using traditional frequency domain analysis methods since it requires high frequency resolutions of the measurement signals and results in a long analyzing time. The proposed MSKACNN is shown to improve the efficiency and accuracy of ball mixing diagnosis. To further demonstrate the effectiveness of MSKACNN in bearing fault identification, a bearing vibration data acquisition system was developed, and vibration signal acquisition was performed on rolling bearings under five different fault conditions including ball mixing. The resulting datasets were used to analyze the performance of our proposed model. To validate the adaptive ability of MSKACNN, fault test data from the Case Western Reserve University Bearing Data Center were also used. Test results show that MSKACNN can identify the different bearing conditions with high accuracy with high generalization ability. We presented an implementation of the MSKACNN as a lightweight module for a real-time bearing fault diagnosis system that is suitable for production. ",
    "url": "https://arxiv.org/abs/2203.15275",
    "authors": [
      "Guangwei Yu",
      "Gang Li",
      "Xingtong Si",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15277",
    "title": "Decomposed Temporal Dynamic CNN: Efficient Time-Adaptive Network for  Text-Independent Speaker Verification Explained with Speaker Activation Map",
    "abstract": "Temporal dynamic models for text-independent speaker verification extract consistent speaker information regardless of phonemes by using temporal dynamic CNN (TDY-CNN) in which kernels adapt to each time bin. However, TDY-CNN shows limitations that the model is too large and does not guarantee the diversity of adaptive kernels. To address these limitations, we propose decomposed temporal dynamic CNN (DTDY-CNN) that makes adaptive kernel by combining static kernel and dynamic residual based on matrix decomposition. The baseline model using DTDY-CNN maintained speaker verification performance while reducing the number of model parameters by 35% compared to the model using TDY-CNN. In addition, detailed behaviors of temporal dynamic models on extraction of speaker information was explained using speaker activation maps (SAM) modified from gradient-weighted class activation mapping (Grad-CAM). In DTDY-CNN, the static kernel activates voiced features of utterances, and the dynamic residual activates unvoiced high-frequency features of phonemes. DTDY-CNN effectively extracts speaker information from not only formant frequencies and harmonics but also detailed unvoiced phonemes' information, thus explaining its outstanding performance on text-independent speaker verification. ",
    "url": "https://arxiv.org/abs/2203.15277",
    "authors": [
      "Seong-Hu Kim",
      "Hyeonuk Nam",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15283",
    "title": "Mel Frequency Spectral Domain Defenses against Adversarial Attacks on  Speech Recognition Systems",
    "abstract": "A variety of recent works have looked into defenses for deep neural networks against adversarial attacks particularly within the image processing domain. Speech processing applications such as automatic speech recognition (ASR) are increasingly relying on deep learning models, and so are also prone to adversarial attacks. However, many of the defenses explored for ASR simply adapt the image-domain defenses, which may not provide optimal robustness. This paper explores speech specific defenses using the mel spectral domain, and introduces a novel defense method called 'mel domain noise flooding' (MDNF). MDNF applies additive noise to the mel spectrogram of a speech utterance prior to re-synthesising the audio signal. We test the defenses against strong white-box adversarial attacks such as projected gradient descent (PGD) and Carlini-Wagner (CW) attacks, and show better robustness compared to a randomized smoothing baseline across strong threat models. ",
    "url": "https://arxiv.org/abs/2203.15283",
    "authors": [
      "Nicholas Mehlman",
      "Anirudh Sreeram",
      "Raghuveer Peri",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15368",
    "title": "Multiclass classification using quantum convolutional neural networks  with hybrid quantum-classical learning",
    "abstract": "Multiclass classification is of great interest for various machine learning applications, for example, it is a common task in computer vision, where one needs to categorize an image into three or more classes. Here we propose a quantum machine learning approach based on quantum convolutional neural networks for solving this problem. The corresponding learning procedure is implemented via TensorFlowQuantum as a hybrid quantum-classical (variational) model, where quantum output results are fed to softmax cost function with subsequent minimization of it via optimization of parameters of quantum circuit. Our conceptional improvements include a new model for quantum perceptron and optimized structure of the quantum circuit. We use the proposed approach to demonstrate the 4-class classification for the case of the MNIST dataset using eight qubits for data encoding and four acnilla qubits. Our results demonstrate comparable accuracy of our solution with classical convolutional neural networks with comparable numbers of trainable parameters. We expect that our finding provide a new step towards the use of quantum machine learning for solving practically relevant problems in the NISQ era and beyond. ",
    "url": "https://arxiv.org/abs/2203.15368",
    "authors": [
      "Denis Bokhan",
      "Alena S. Mastiukova",
      "Aleksey S. Boev",
      "Dmitrii N. Trubnikov",
      "Aleksey K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15383",
    "title": "Category Guided Attention Network for Brain Tumor Segmentation in MRI",
    "abstract": "Objective: Magnetic resonance imaging (MRI) has been widely used for the analysis and diagnosis of brain diseases. Accurate and automatic brain tumor segmentation is of paramount importance for radiation treatment. However, low tissue contrast in tumor regions makes it a challenging task.Approach: We propose a novel segmentation network named Category Guided Attention U-Net (CGA U-Net). In this model, we design a Supervised Attention Module (SAM) based on the attention mechanism, which can capture more accurate and stable long-range dependency in feature maps without introducing much computational cost. Moreover, we propose an intra-class update approach to reconstruct feature maps by aggregating pixels of the same category. Main results: Experimental results on the BraTS 2019 datasets show that the proposed method outperformers the state-of-the-art algorithms in both segmentation performance and computational complexity. Significance: The CGA U-Net can effectively capture the global semantic information in the MRI image by using the SAM module, while significantly reducing the computational cost. Code is available at https://github.com/delugewalker/CGA-U-Net. ",
    "url": "https://arxiv.org/abs/2203.15383",
    "authors": [
      "Jiangyun Li",
      "Hong Yu",
      "Chen Chen",
      "Meng Ding",
      "Sen Zha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15405",
    "title": "Automatic Detection of Speech Sound Disorder in Child Speech Using  Posterior-based Speaker Representations",
    "abstract": "This paper presents a macroscopic approach to automatic detection of speech sound disorder (SSD) in child speech. Typically, SSD is manifested by persistent articulation and phonological errors on specific phonemes in the language. The disorder can be detected by focally analyzing the phonemes or the words elicited by the child subject. In the present study, instead of attempting to detect individual phone- and word-level errors, we propose to extract a subject-level representation from a long utterance that is constructed by concatenating multiple test words. The speaker verification approach, and posterior features generated by deep neural network models, are applied to derive various types of holistic representations. A linear classifier is trained to differentiate disordered speech in normal one. On the task of detecting SSD in Cantonese-speaking children, experimental results show that the proposed approach achieves improved detection performance over previous method that requires fusing phone-level detection results. Using articulatory posterior features to derive i-vectors from multiple-word utterances achieves an unweighted average recall of 78.2% and a macro F1 score of 78.0%. ",
    "url": "https://arxiv.org/abs/2203.15405",
    "authors": [
      "Si-Ioi Ng",
      "Cymie Wing-Yee Ng",
      "Jiarui Wang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15446",
    "title": "A framework for minimal hereditary classes of graphs of unbounded  clique-width",
    "abstract": "We create a framework for hereditary graph classes $\\mathcal{G}^\\delta$ built on a two-dimensional grid of vertices and edge sets defined by a triple $\\delta=\\{\\alpha,\\beta,\\gamma\\}$ of objects that define edges between consecutive columns, edges between non-consecutive columns (called bonds), and edges within columns. This framework captures all previously proven minimal hereditary classes of graph of unbounded clique-width, and many new ones, although we do not claim this includes all such classes. We show that a graph class $\\mathcal{G}^\\delta$ has unbounded clique-width if and only if a certain parameter $\\mathcal{N}^\\delta$ is unbounded. We further show that $\\mathcal{G}^\\delta$ is minimal of unbounded clique-width (and, indeed, minimal of unbounded linear clique-width) if another parameter $\\mathcal{M}^\\beta$ is bounded, and also $\\delta$ has defined recurrence characteristics. Both the parameters $\\mathcal{N}^\\delta$ and $\\mathcal{M}^\\beta$ are properties of a triple $\\delta=(\\alpha,\\beta,\\gamma)$, and measure the number of distinct neighbourhoods in certain auxiliary graphs. Throughout our work, we introduce new methods to the study of clique-width, including the use of Ramsey theory in arguments related to unboundedness, and explicit (linear) clique-width expressions for subclasses of minimal classes of unbounded clique-width. ",
    "url": "https://arxiv.org/abs/2203.15446",
    "authors": [
      "Robert Brignall",
      "Daniel Cocks"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.15470",
    "title": "Graph similarity learning for change-point detection in dynamic networks",
    "abstract": "Dynamic networks are ubiquitous for modelling sequential graph-structured data, e.g., brain connectome, population flows and messages exchanges. In this work, we consider dynamic networks that are temporal sequences of graph snapshots, and aim at detecting abrupt changes in their structure. This task is often termed network change-point detection and has numerous applications, such as fraud detection or physical motion monitoring. Leveraging a graph neural network model, we design a method to perform online network change-point detection that can adapt to the specific network domain and localise changes with no delay. The main novelty of our method is to use a siamese graph neural network architecture for learning a data-driven graph similarity function, which allows to effectively compare the current graph and its recent history. Importantly, our method does not require prior knowledge on the network generative distribution and is agnostic to the type of change-points; moreover, it can be applied to a large variety of networks, that include for instance edge weights and node attributes. We show on synthetic and real data that our method enjoys a number of benefits: it is able to learn an adequate graph similarity function for performing online network change-point detection in diverse types of change-point settings, and requires a shorter data history to detect changes than most existing state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2203.15470",
    "authors": [
      "Deborah Sulem",
      "Henry Kenlay",
      "Mihai Cucuringu",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.15490",
    "title": "Neural representation of a time optimal, constant acceleration  rendezvous",
    "abstract": "We train neural models to represent both the optimal policy (i.e. the optimal thrust direction) and the value function (i.e. the time of flight) for a time optimal, constant acceleration low-thrust rendezvous. In both cases we develop and make use of the data augmentation technique we call backward generation of optimal examples. We are thus able to produce and work with large dataset and to fully exploit the benefit of employing a deep learning framework. We achieve, in all cases, accuracies resulting in successful rendezvous (simulated following the learned policy) and time of flight predictions (using the learned value function). We find that residuals as small as a few m/s, thus well within the possibility of a spacecraft navigation $\\Delta V$ budget, are achievable for the velocity at rendezvous. We also find that, on average, the absolute error to predict the optimal time of flight to rendezvous from any orbit in the asteroid belt to an Earth-like orbit is small (less than 4\\%) and thus also of interest for practical uses, for example, during preliminary mission design phases. ",
    "url": "https://arxiv.org/abs/2203.15490",
    "authors": [
      "Dario Izzo",
      "Sebastien Origer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15598",
    "title": "Angular Super-Resolution in Diffusion MRI with a 3D Recurrent  Convolutional Autoencoder",
    "abstract": "High resolution diffusion MRI (dMRI) data is often constrained by limited scanning time in clinical settings, thus restricting the use of downstream analysis techniques that would otherwise be available. In this work we develop a 3D recurrent convolutional neural network (RCNN) capable of super-resolving dMRI volumes in the angular (q-space) domain. Our approach formulates the task of angular super-resolution as a patch-wise regression using a 3D autoencoder conditioned on target b-vectors. Within the network we use a convolutional long short term memory (ConvLSTM) cell to model the relationship between q-space samples. We compare model performance against a baseline spherical harmonic interpolation and a 1D variant of the model architecture. We show that the 3D model has the lowest error rates across different subsampling schemes and b-values. The relative performance of the 3D RCNN is greatest in the very low angular resolution domain. Code for this project is available at https://github.com/m-lyon/dMRI-RCNN. ",
    "url": "https://arxiv.org/abs/2203.15598",
    "authors": [
      "Matthew Lyon",
      "Paul Armitage",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15610",
    "title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning  with Once-for-All Hidden-Unit BERT",
    "abstract": "Self-supervised speech representation learning has shown promising results in various speech processing tasks. However, the pre-trained models, e.g., HuBERT, are storage-intensive Transformers, limiting their scope of applications under low-resource settings. To this end, we propose LightHuBERT, a once-for-all Transformer compression framework, to find the desired architectures automatically by pruning structured parameters. More precisely, we create a Transformer-based supernet that is nested with thousands of weight-sharing subnets and design a two-stage distillation strategy to leverage the contextualized latent representations from HuBERT. Experiments on automatic speech recognition (ASR) and the SUPERB benchmark show the proposed LightHuBERT enables over $10^9$ architectures concerning the embedding dimension, attention dimension, head number, feed-forward network ratio, and network depth. LightHuBERT outperforms the original HuBERT on ASR and five SUPERB tasks with the HuBERT size, achieves comparable performance to the teacher model in most tasks with a reduction of 29% parameters, and obtains a $3.5\\times$ compression ratio in three SUPERB tasks, e.g., automatic speaker verification, keyword spotting, and intent classification, with a slight accuracy loss. The code and pre-trained models are available at https://github.com/mechanicalsea/lighthubert. ",
    "url": "https://arxiv.org/abs/2203.15610",
    "authors": [
      "Rui Wang",
      "Qibing Bai",
      "Junyi Ao",
      "Long Zhou",
      "Zhixiang Xiong",
      "Zhihua Wei",
      "Yu Zhang",
      "Tom Ko",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.15635",
    "title": "BASiNETEntropy: an alignment-free method for classification of  biological sequences through complex networks and entropy maximization",
    "abstract": "The discovery of nucleic acids and the structure of DNA have brought considerable advances in the understanding of life. The development of next-generation sequencing technologies has led to a large-scale generation of data, for which computational methods have become essential for analysis and knowledge discovery. In particular, RNAs have received much attention because of the diversity of their functionalities in the organism and the discoveries of different classes with different functions in many biological processes. Therefore, the correct identification of RNA sequences is increasingly important to provide relevant information to understand the functioning of organisms. This work addresses this context by presenting a new method for the classification of biological sequences through complex networks and entropy maximization. The maximum entropy principle is proposed to identify the most informative edges about the RNA class, generating a filtered complex network. The proposed method was evaluated in the classification of different RNA classes from 13 species. The proposed method was compared to PLEK, CPC2 and BASiNET methods, outperforming all compared methods. BASiNETEntropy classified all RNA sequences with high accuracy and low standard deviation in results, showing assertiveness and robustness. The proposed method is implemented in an open source in R language and is freely available at https://cran.r-project.org/web/packages/BASiNETEntropy. ",
    "url": "https://arxiv.org/abs/2203.15635",
    "authors": [
      "Murilo Montanini Breve",
      "Matheus Henrique Pimenta-Zanon",
      "Fabr\u00edcio Martins Lopes"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2203.15672",
    "title": "SurvCaus : Representation Balancing for Survival Causal Inference",
    "abstract": "Individual Treatment Effects (ITE) estimation methods have risen in popularity in the last years. Most of the time, individual effects are better presented as Conditional Average Treatment Effects (CATE). Recently, representation balancing techniques have gained considerable momentum in causal inference from observational data, still limited to continuous (and binary) outcomes. However, in numerous pathologies, the outcome of interest is a (possibly censored) survival time. Our paper proposes theoretical guarantees for a representation balancing framework applied to counterfactual inference in a survival setting using a neural network capable of predicting the factual and counterfactual survival functions (and then the CATE), in the presence of censorship, at the individual level. We also present extensive experiments on synthetic and semisynthetic datasets that show that the proposed extensions outperform baseline methods. ",
    "url": "https://arxiv.org/abs/2203.15672",
    "authors": [
      "Ayoub Abraich",
      "Agathe Guilloux",
      "Blaise Hanczar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.15736",
    "title": "Exact Community Recovery in Correlated Stochastic Block Models",
    "abstract": "We consider the problem of learning latent community structure from multiple correlated networks. We study edge-correlated stochastic block models with two balanced communities, focusing on the regime where the average degree is logarithmic in the number of vertices. Our main result derives the precise information-theoretic threshold for exact community recovery using multiple correlated graphs. This threshold captures the interplay between the community recovery and graph matching tasks. In particular, we uncover and characterize a region of the parameter space where exact community recovery is possible using multiple correlated graphs, even though (1) this is information-theoretically impossible using a single graph and (2) exact graph matching is also information-theoretically impossible. In this regime, we develop a novel algorithm that carefully synthesizes algorithms from the community recovery and graph matching literatures. ",
    "url": "https://arxiv.org/abs/2203.15736",
    "authors": [
      "Julia Gaudio",
      "Miklos Z. Racz",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2203.15756",
    "title": "Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data",
    "abstract": "Learning invariant causal structure often relies on conditional independence testing and assumption of independent and identically distributed data. Recent work has explored inferring invariant causal structure using data coming from different environments. These approaches are based on independent causal mechanism (ICM) principle which postulates that the cause mechanism is independent of the effect given cause mechanism. Despite its wide application in machine learning and causal inference, there lacks a statistical formalization of what independent mechanism means. Here we present Causal de Finetti which offers a first statistical formalization of ICM principle. ",
    "url": "https://arxiv.org/abs/2203.15756",
    "authors": [
      "Siyuan Guo",
      "Viktor T\u00f3th",
      "Bernhard Sch\u00f6lkopf",
      "Ferenc Husz\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1701.07447",
    "title": "An Explicit, Coupled-Layer Construction of a High-Rate Regenerating Code  with Low Sub-Packetization Level, Small Field Size and $d< (n-1)$",
    "abstract": " Comments: In the revised version, a correction is made in the rate calculation. As the rate stands corrected, the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335 ",
    "url": "https://arxiv.org/abs/1701.07447",
    "authors": [
      "Birenjith Sasidharan",
      "Myna Vajha",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:1812.10761",
    "title": "Improving Generalization of Deep Neural Networks by Leveraging Margin  Distribution",
    "abstract": " Comments: 25 pages, 7 figures, 1 table. Accepted by Neural Networks ",
    "url": "https://arxiv.org/abs/1812.10761",
    "authors": [
      "Shen-Huan Lyu",
      "Lu Wang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1901.07868",
    "title": "Constant Time Graph Neural Networks",
    "abstract": " Comments: TKDD 2022 ",
    "url": "https://arxiv.org/abs/1901.07868",
    "authors": [
      "Ryoma Sato",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2002.10438",
    "title": "xAI-GAN: Enhancing Generative Adversarial Networks via Explainable AI  Systems",
    "abstract": " Comments: 7 pages (+ 2 page for reference) ",
    "url": "https://arxiv.org/abs/2002.10438",
    "authors": [
      "Vineel Nagisetty",
      "Laura Graves",
      "Joseph Scott",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.09371",
    "title": "Towards Improving Selective Prediction Ability of NLP Systems",
    "abstract": " Comments: ACL 2022 RepL4NLP Workshop ",
    "url": "https://arxiv.org/abs/2008.09371",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.09891",
    "title": "Robust Optimization as Data Augmentation for Large-scale Graphs",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2010.09891",
    "authors": [
      "Kezhi Kong",
      "Guohao Li",
      "Mucong Ding",
      "Zuxuan Wu",
      "Chen Zhu",
      "Bernard Ghanem",
      "Gavin Taylor",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.01028",
    "title": "CRaDLe: Deep Code Retrieval Based on Semantic Dependency Learning",
    "abstract": " Title: CRaDLe: Deep Code Retrieval Based on Semantic Dependency Learning ",
    "url": "https://arxiv.org/abs/2012.01028",
    "authors": [
      "Wenchao Gu",
      "Zongjie Li",
      "Cuiyun Gao",
      "Chaozheng Wang",
      "Hongyu Zhang",
      "Zenglin Xu",
      "Michael R.Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2101.05792",
    "title": "Group Testing with a Graph Infection Spread Model",
    "abstract": " Title: Group Testing with a Graph Infection Spread Model ",
    "url": "https://arxiv.org/abs/2101.05792",
    "authors": [
      "Batuhan Arasli",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2102.00499",
    "title": "On the Indecisiveness of Kelly-Strategyproof Social Choice Functions",
    "abstract": " Comments: Appears in: Proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021 ",
    "url": "https://arxiv.org/abs/2102.00499",
    "authors": [
      "Felix Brandt",
      "Martin Bullinger",
      "Patrick Lederer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2103.01209",
    "title": "Generative Adversarial Transformers",
    "abstract": " Comments: Published as a conference paper at ICML 2021 ",
    "url": "https://arxiv.org/abs/2103.01209",
    "authors": [
      "Drew A. Hudson",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.11139",
    "title": "MogFace: Towards a Deeper Appreciation on Face Detection",
    "abstract": " Title: MogFace: Towards a Deeper Appreciation on Face Detection ",
    "url": "https://arxiv.org/abs/2103.11139",
    "authors": [
      "Yang Liu",
      "Fei Wang",
      "Jiankang Deng",
      "Zhipeng Zhou",
      "Baigui Sun",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.15383",
    "title": "Selective Output Smoothing Regularization: Regularize Neural Networks by  Softening Output Distributions",
    "abstract": " Title: Selective Output Smoothing Regularization: Regularize Neural Networks by  Softening Output Distributions ",
    "url": "https://arxiv.org/abs/2103.15383",
    "authors": [
      "Xuan Cheng",
      "Tianshu Xie",
      "Xiaomin Wang",
      "Qifeng Weng",
      "Minghui Liu",
      "Jiali Deng",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.00419",
    "title": "Graph Vulnerability and Robustness: A Survey",
    "abstract": " Comments: Accepted into Transactions on Knowledge and Data Engineering (TKDE) 2022 ",
    "url": "https://arxiv.org/abs/2105.00419",
    "authors": [
      "Scott Freitas",
      "Diyi Yang",
      "Srijan Kumar",
      "Hanghang Tong",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2105.11527",
    "title": "Unsupervised Visual Representation Learning by Online Constrained  K-Means",
    "abstract": " Comments: accepted by CVPR'22 ",
    "url": "https://arxiv.org/abs/2105.11527",
    "authors": [
      "Qi Qian",
      "Yuanhong Xu",
      "Juhua Hu",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.13353",
    "title": "Unsupervised Action Segmentation by Joint Representation Learning and  Online Clustering",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2105.13353",
    "authors": [
      "Sateesh Kumar",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.04550",
    "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection",
    "abstract": " Comments: CVPR 2022 Camera Ready ",
    "url": "https://arxiv.org/abs/2106.04550",
    "authors": [
      "Amir Bar",
      "Xin Wang",
      "Vadim Kantorov",
      "Colorado J Reed",
      "Roei Herzig",
      "Gal Chechik",
      "Anna Rohrbach",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.00309",
    "title": "Spotting adversarial samples for speaker verification by neural vocoders",
    "abstract": " Comments: Accepted by ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2107.00309",
    "authors": [
      "Haibin Wu",
      "Po-chun Hsu",
      "Ji Gao",
      "Shanshan Zhang",
      "Shen Huang",
      "Jian Kang",
      "Zhiyong Wu",
      "Helen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2108.01036",
    "title": "Optimal Solving of Constrained Path-Planning Problems with Graph  Convolutional Networks and Optimized Tree Search",
    "abstract": " Comments: Complete version with full references ",
    "url": "https://arxiv.org/abs/2108.01036",
    "authors": [
      "Kevin Osanlou",
      "Andrei Bursuc",
      "Christophe Guettier",
      "Tristan Cazenave",
      "Eric Jacopin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.10360",
    "title": "Interpreting Face Inference Models using Hierarchical Network Dissection",
    "abstract": " Title: Interpreting Face Inference Models using Hierarchical Network Dissection ",
    "url": "https://arxiv.org/abs/2108.10360",
    "authors": [
      "Divyang Teotia",
      "Agata Lapedriza",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.10742",
    "title": "Early Lane Change Prediction for Automated Driving Systems Using  Multi-Task Attention-based Convolutional Neural Networks",
    "abstract": " Comments: 13 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2109.10742",
    "authors": [
      "Sajjad Mozaffari",
      "Eduardo Arnold",
      "Mehrdad Dianati",
      "Saber Fallah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03012",
    "title": "Emphasis control for parallel neural TTS",
    "abstract": " Comments: 5 pages, 5 figures, submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2110.03012",
    "authors": [
      "Shreyas Seshadri",
      "Tuomo Raitio",
      "Dan Castellani",
      "Jiangchuan Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.03299",
    "title": "End-To-End Label Uncertainty Modeling for Speech-based Arousal  Recognition Using Bayesian Neural Networks",
    "abstract": " Comments: This paper is submitted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2110.03299",
    "authors": [
      "Navin Raj Prabhu",
      "Guillaume Carbajal",
      "Nale Lehmann-Willenbrock",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.05064",
    "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave  Functions",
    "abstract": " Comments: Published as a conference paper at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.05064",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2110.06651",
    "title": "MDERank: A Masked Document Embedding Rank Approach for Unsupervised  Keyphrase Extraction",
    "abstract": " Comments: 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2110.06651",
    "authors": [
      "Linhan Zhang",
      "Qian Chen",
      "Wen Wang",
      "Chong Deng",
      "Shiliang Zhang",
      "Bing Li",
      "Wei Wang",
      "Xin Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.06691",
    "title": "Diverse Audio Captioning via Adversarial Training",
    "abstract": " Comments: 5 pages, 1 figure, accepted by ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.06691",
    "authors": [
      "Xinhao Mei",
      "Xubo Liu",
      "Jianyuan Sun",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.08851",
    "title": "Unsupervised Representation Learning for Binary Networks by Joint  Classifier Learning",
    "abstract": " Comments: to appear in CVPR2022 ",
    "url": "https://arxiv.org/abs/2110.08851",
    "authors": [
      "Dahyun Kim",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.10720",
    "title": "Privacy in Open Search: A Review of Challenges and Solutions",
    "abstract": " Comments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium ",
    "url": "https://arxiv.org/abs/2110.10720",
    "authors": [
      "Samuel Sousa",
      "Christian Guetl",
      "Roman Kern"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2110.12509",
    "title": "Per-Pixel Lung Thickness and Lung Capacity Estimation on Chest X-Rays  using Convolutional Neural Networks",
    "abstract": " Comments: v4: fixed simulation bug, improved text, various other improvements ",
    "url": "https://arxiv.org/abs/2110.12509",
    "authors": [
      "Manuel Schultheiss",
      "Philipp Schmette",
      "Thorsten Sellerer",
      "Rafael Schick",
      "Kirsten Taphorn",
      "Korbinian Mechlem",
      "Lorenz Birnbacher",
      "Bernhard Renger",
      "Marcus R. Makowski",
      "Franz Pfeiffer",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.12663",
    "title": "Industrial Scene Text Detection with Refined Feature-attentive Network",
    "abstract": " Title: Industrial Scene Text Detection with Refined Feature-attentive Network ",
    "url": "https://arxiv.org/abs/2110.12663",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Changsheng Lu",
      "Jingzheng Tu",
      "Qi Feng",
      "Kaijie Wu",
      "Xinping Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.04330",
    "title": "Characterizing the adversarial vulnerability of speech self-supervised  learning",
    "abstract": " Comments: Accepted by ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2111.04330",
    "authors": [
      "Haibin Wu",
      "Bo Zheng",
      "Xu Li",
      "Xixin Wu",
      "Hung-yi Lee",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.13152",
    "title": "Scene Representation Transformer: Geometry-Free Novel View Synthesis  Through Set-Latent Scene Representations",
    "abstract": " Comments: Accepted to CVPR 2022, Project website: this https URL ",
    "url": "https://arxiv.org/abs/2111.13152",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Henning Meyer",
      "Etienne Pot",
      "Urs Bergmann",
      "Klaus Greff",
      "Noha Radwan",
      "Suhani Vora",
      "Mario Lucic",
      "Daniel Duckworth",
      "Alexey Dosovitskiy",
      "Jakob Uszkoreit",
      "Thomas Funkhouser",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.13844",
    "title": "Adaptive Image Transformations for Transfer-based Adversarial Attack",
    "abstract": " Comments: 33 pages, 7 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2111.13844",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14820",
    "title": "Towards Robust and Adaptive Motion Forecasting: A Causal Representation  Perspective",
    "abstract": " Comments: CVPR 2022. Code is available at this https URL v3: update details ",
    "url": "https://arxiv.org/abs/2111.14820",
    "authors": [
      "Yuejiang Liu",
      "Riccardo Cadei",
      "Jonas Schweizer",
      "Sherwin Bahmani",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.14887",
    "title": "DAFormer: Improving Network Architectures and Training Strategies for  Domain-Adaptive Semantic Segmentation",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2111.14887",
    "authors": [
      "Lukas Hoyer",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03109",
    "title": "General Facial Representation Learning in a Visual-Linguistic Manner",
    "abstract": " Comments: CVPR22 oral; 16 pages, 6 figures, 14 tables ",
    "url": "https://arxiv.org/abs/2112.03109",
    "authors": [
      "Yinglin Zheng",
      "Hao Yang",
      "Ting Zhang",
      "Jianmin Bao",
      "Dongdong Chen",
      "Yangyu Huang",
      "Lu Yuan",
      "Dong Chen",
      "Ming Zeng",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.03902",
    "title": "MS-TCT: Multi-Scale Temporal ConvTransformer for Action Detection",
    "abstract": " Comments: Accepted in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2112.03902",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Kumara Kahatapitiya",
      "Michael S. Ryoo",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03909",
    "title": "Vehicle trajectory prediction works, but not everywhere",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2112.03909",
    "authors": [
      "Mohammadhossein Bahari",
      "Saeed Saadatnejad",
      "Ahmad Rahimi",
      "Mohammad Shaverdikondori",
      "Amir-Hossein Shahidzadeh",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04809",
    "title": "Next Steps: Learning a Disentangled Gait Representation for Versatile  Quadruped Locomotion",
    "abstract": " Comments: 7 pages, 4 figures, accepted at IEEE International Conference on Robotics and Automation (ICRA), 2022 ",
    "url": "https://arxiv.org/abs/2112.04809",
    "authors": [
      "Alexander L. Mitchell",
      "Wolfgang Merkt",
      "Mathieu Geisert",
      "Siddhant Gangapurwala",
      "Martin Engelcke",
      "Oiwi Parker Jones",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05749",
    "title": "Label, Verify, Correct: A Simple Few Shot Object Detection Method",
    "abstract": " Comments: CVPR 2022, project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.05749",
    "authors": [
      "Prannay Kaul",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06183",
    "title": "Few-shot Keypoint Detection with Uncertainty Learning for Unseen Species",
    "abstract": " Comments: 8 pages for main paper, 6 pages for supplementary materials ",
    "url": "https://arxiv.org/abs/2112.06183",
    "authors": [
      "Changsheng Lu",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.06721",
    "title": "PM-MMUT: Boosted Phone-mask Data Augmentation using Multi-Modeling Unit  Training for Phonetic-Reduction-Robust E2E Speech Recognition",
    "abstract": " Comments: Submitted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2112.06721",
    "authors": [
      "Guodong Ma",
      "Pengfei Hu",
      "Nurmemet Yolwas",
      "Shen Huang",
      "Hao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.09687",
    "title": "Light Field Neural Rendering",
    "abstract": " Comments: Project page with code and videos at this https URL ",
    "url": "https://arxiv.org/abs/2112.09687",
    "authors": [
      "Mohammed Suhail",
      "Carlos Esteves",
      "Leonid Sigal",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12785",
    "title": "NinjaDesc: Content-Concealing Visual Descriptors via Adversarial  Learning",
    "abstract": " Comments: Accepted at CVPR 2022. Supplementary material included after references. 15 pages, 14 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2112.12785",
    "authors": [
      "Tony Ng",
      "Hyo Jin Kim",
      "Vincent Lee",
      "Daniel DeTone",
      "Tsun-Yi Yang",
      "Tianwei Shen",
      "Eddy Ilg",
      "Vassileios Balntas",
      "Krystian Mikolajczyk",
      "Chris Sweeney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03943",
    "title": "Neural Architecture Search For LF-MMI Trained Time Delay Neural Networks",
    "abstract": " Comments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP). arXiv admin note: text overlap with arXiv:2007.08818 ",
    "url": "https://arxiv.org/abs/2201.03943",
    "authors": [
      "Shoukang Hu",
      "Xurong Xie",
      "Mingyu Cui",
      "Jiajun Deng",
      "Shansong Liu",
      "Jianwei Yu",
      "Mengzhe Geng",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2201.05905",
    "title": "SS-3DCapsNet: Self-supervised 3D Capsule Networks for Medical  Segmentation on Less Labeled Data",
    "abstract": " Comments: Accepted to ISBI 2022 ",
    "url": "https://arxiv.org/abs/2201.05905",
    "authors": [
      "Minh Tran",
      "Loi Ly",
      "Binh-Son Hua",
      "Ngan Le"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.06147",
    "title": "Data augmentation through multivariate scenario forecasting in Data  Centers using Generative Adversarial Networks",
    "abstract": " Title: Data augmentation through multivariate scenario forecasting in Data  Centers using Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2201.06147",
    "authors": [
      "Jaime P\u00e9rez",
      "Patricia Arroba",
      "Jos\u00e9 M. Moya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.09032",
    "title": "NAS-VAD: Neural Architecture Search for Voice Activity Detection",
    "abstract": " Comments: Submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2201.09032",
    "authors": [
      "Daniel Rho",
      "Jinhyeok Park",
      "Jong Hwan Ko"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2201.09366",
    "title": "Optimal transport for causal discovery",
    "abstract": " Title: Optimal transport for causal discovery ",
    "url": "https://arxiv.org/abs/2201.09366",
    "authors": [
      "Ruibo Tu",
      "Kun Zhang",
      "Hedvig Kjellstr\u00f6m",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2201.10326",
    "title": "ShapeFormer: Transformer-based Shape Completion via Sparse  Representation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2201.10326",
    "authors": [
      "Xingguang Yan",
      "Liqiang Lin",
      "Niloy J. Mitra",
      "Dani Lischinski",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.00660",
    "title": "Interactron: Embodied Adaptive Object Detection",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2202.00660",
    "authors": [
      "Klemen Kotar",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01850",
    "title": "A Robust Phased Elimination Algorithm for Corruption-Tolerant Gaussian  Process Bandits",
    "abstract": " Comments: Added references ",
    "url": "https://arxiv.org/abs/2202.01850",
    "authors": [
      "Ilija Bogunovic",
      "Zihan Li",
      "Andreas Krause",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08703",
    "title": "Robust Frequency Constrained UC Using Data Driven Logistic Regression  for Island Power Systems",
    "abstract": " Title: Robust Frequency Constrained UC Using Data Driven Logistic Regression  for Island Power Systems ",
    "url": "https://arxiv.org/abs/2202.08703",
    "authors": [
      "Mohammad Rajabdorri",
      "Enrique Lobato",
      "Lukas Sigrist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.12513",
    "title": "TeachAugment: Data Augmentation Optimization Using Teacher Knowledge",
    "abstract": " Comments: To appear in CVPR2022 (Oral presentation) Code: this https URL ",
    "url": "https://arxiv.org/abs/2202.12513",
    "authors": [
      "Teppei Suzuki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01522",
    "title": "BatchFormer: Learning to Explore Sample Relationships for Robust  Representation Learning",
    "abstract": " Comments: Camera Ready, CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.01522",
    "authors": [
      "Zhi Hou",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": " Title: DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection ",
    "url": "https://arxiv.org/abs/2203.03605",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04234",
    "title": "Adaptative Perturbation Patterns: Realistic Adversarial Learning for  Robust Intrusion Detection",
    "abstract": " Comments: 18 pages, 6 tables, 10 figures, Future Internet journal ",
    "url": "https://arxiv.org/abs/2203.04234",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Nuno Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08207",
    "title": "SocialVAE: Human Trajectory Prediction using Timewise Latents",
    "abstract": " Title: SocialVAE: Human Trajectory Prediction using Timewise Latents ",
    "url": "https://arxiv.org/abs/2203.08207",
    "authors": [
      "Pei Xu",
      "Jean-Bernard Hayet",
      "Ioannis Karamouzas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08667",
    "title": "Graph Flow: Cross-layer Graph Flow Distillation for Dual Efficient  Medical Image Segmentation",
    "abstract": " Title: Graph Flow: Cross-layer Graph Flow Distillation for Dual Efficient  Medical Image Segmentation ",
    "url": "https://arxiv.org/abs/2203.08667",
    "authors": [
      "Wenxuan Zou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09116",
    "title": "MotionAug: Augmentation with Physical Correction for Human Motion  Prediction",
    "abstract": " Comments: Accepted at CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.09116",
    "authors": [
      "Takahiro Maeda",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10627",
    "title": "Enriching Unsupervised User Embedding via Medical Concepts",
    "abstract": " Comments: accepted at ACM CHIL 2022. a revision for section reformat ",
    "url": "https://arxiv.org/abs/2203.10627",
    "authors": [
      "Xiaolei Huang",
      "Franck Dernoncourt",
      "Mark Dredze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10637",
    "title": "Vocal effort modeling in neural TTS for improving the intelligibility of  synthetic speech in noise",
    "abstract": " Comments: 5 pages, 5 figures. Submitted to Interspeech 2022, revision includes more data in results and improved text ",
    "url": "https://arxiv.org/abs/2203.10637",
    "authors": [
      "Tuomo Raitio",
      "Petko Petkov",
      "Jiangchuan Li",
      "Muhammed Shifas",
      "Andrea Davis",
      "Yannis Stylianou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.11481",
    "title": "Mixed Differential Privacy in Computer Vision",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.11481",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Yu-Xiang Wang",
      "Aaron Roth",
      "Michael Kearns",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.11804",
    "title": "Information-Theoretic Approaches to Differential Privacy",
    "abstract": " Title: Information-Theoretic Approaches to Differential Privacy ",
    "url": "https://arxiv.org/abs/2203.11804",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.12338",
    "title": "Real-time Object Detection for Streaming Perception",
    "abstract": " Comments: CVPR 2022 Accepted Paper (Oral) ",
    "url": "https://arxiv.org/abs/2203.12338",
    "authors": [
      "Jinrong Yang",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12369",
    "title": "MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data",
    "abstract": " Comments: 5 pages, 4 figures, Submitted to EUSIPCO 2022 ",
    "url": "https://arxiv.org/abs/2203.12369",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.12961",
    "title": "Multilevel Bayesian Deep Neural Networks",
    "abstract": " Title: Multilevel Bayesian Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2203.12961",
    "authors": [
      "Neil K. Chada",
      "Ajay Jasra",
      "Kody J. H. Law",
      "Sumeetpal S. Singh"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.12980",
    "title": "MERLIN -- Malware Evasion with Reinforcement LearnINg",
    "abstract": " Title: MERLIN -- Malware Evasion with Reinforcement LearnINg ",
    "url": "https://arxiv.org/abs/2203.12980",
    "authors": [
      "Tony Quertier",
      "Benjamin Marais",
      "St\u00e9phane Morucci",
      "Bertrand Fournel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13005",
    "title": "GX-Plug: a Middleware for Plugging Accelerators to Distributed Graph  Processing",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2203.13005",
    "authors": [
      "Kai Zou",
      "Xike Xie",
      "Qi Li",
      "Deyu Kong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.13009",
    "title": "CVF-SID: Cyclic multi-Variate Function for Self-Supervised Image  Denoising by Disentangling Noise from Image",
    "abstract": " Comments: Published at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.13009",
    "authors": [
      "Reyhaneh Neshatavar",
      "Mohsen Yavartanoo",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.13510",
    "title": "Joint Distribution of Distance and Angles in Finite Wireless Networks",
    "abstract": " Comments: 14 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2203.13510",
    "authors": [
      "Francisco J. Mart\u00edn-Vega",
      "Gerardo G\u00f3mez",
      "David Morales-Jim\u00e9nez",
      "F. Javier L\u00f3pez-Mart\u00ednez",
      "Mari Carmen Aguayo-Torres"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.14093",
    "title": "MQDD: Pre-training of Multimodal Question Duplicity Detection for  Software Engineering Domain",
    "abstract": " Title: MQDD: Pre-training of Multimodal Question Duplicity Detection for  Software Engineering Domain ",
    "url": "https://arxiv.org/abs/2203.14093",
    "authors": [
      "Jan Pa\u0161ek",
      "Jakub Sido",
      "Miloslav Konop\u00edk",
      "Ond\u0159ej Pra\u017e\u00e1k"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.14333",
    "title": "Locality-Aware Inter-and Intra-Video Reconstruction for Self-Supervised  Correspondence Learning",
    "abstract": " Comments: CVPR 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.14333",
    "authors": [
      "Liulei Li",
      "Tianfei Zhou",
      "Wenguan Wang",
      "Lu Yang",
      "Jianwu Li",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14341",
    "title": "MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation",
    "abstract": " Title: MFSNet: A Multi Focus Segmentation Network for Skin Lesion Segmentation ",
    "url": "https://arxiv.org/abs/2203.14341",
    "authors": [
      "Hritam Basak",
      "Rohit Kundu",
      "Ram Sarkar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.14807",
    "title": "Who is next: rising star prediction via diffusion of user interest in  social networks",
    "abstract": " Comments: Accepted to TKDE 2022 ",
    "url": "https://arxiv.org/abs/2203.14807",
    "authors": [
      "Xuan Yang",
      "Yang Yang",
      "Jintao Su",
      "Yifei Sun",
      "Shen Fan",
      "Zhongyao Wang",
      "Jun Zhang",
      "Jingmin Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  }
]