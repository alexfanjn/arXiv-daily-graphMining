[
  {
    "id": "arXiv:2203.05602",
    "title": "Gesture based Arabic Sign Language Recognition for Impaired People based  on Convolution Neural Network",
    "abstract": "The Arabic Sign Language has endorsed outstanding research achievements for identifying gestures and hand signs using the deep learning methodology. The term \"forms of communication\" refers to the actions used by hearing-impaired people to communicate. These actions are difficult for ordinary people to comprehend. The recognition of Arabic Sign Language (ArSL) has become a difficult study subject due to variations in Arabic Sign Language (ArSL) from one territory to another and then within states. The Convolution Neural Network has been encapsulated in the proposed system which is based on the machine learning technique. For the recognition of the Arabic Sign Language, the wearable sensor is utilized. This approach has been used a different system that could suit all Arabic gestures. This could be used by the impaired people of the local Arabic community. The research method has been used with reasonable and moderate accuracy. A deep Convolutional network is initially developed for feature extraction from the data gathered by the sensing devices. These sensors can reliably recognize the Arabic sign language's 30 hand sign letters. The hand movements in the dataset were captured using DG5-V hand gloves with wearable sensors. For categorization purposes, the CNN technique is used. The suggested system takes Arabic sign language hand gestures as input and outputs vocalized speech as output. The results were recognized by 90% of the people. ",
    "url": "https://arxiv.org/abs/2203.05602",
    "authors": [
      "Rady El Rwelli",
      "Osama R. Shahin",
      "Ahmed I. Taloba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05625",
    "title": "PETR: Position Embedding Transformation for Multi-View 3D Object  Detection",
    "abstract": "In this paper, we develop position embedding transformation (PETR) for multi-view 3D object detection. PETR encodes the position information of 3D coordinates into image features, producing the 3D position-aware features. Object query can perceive the 3D position-aware features and perform end-to-end object detection. PETR achieves state-of-the-art performance (50.4% NDS and 44.1% mAP) on standard nuScenes dataset and ranks 1st place on the benchmark. It can serve as a simple yet strong baseline for future research. ",
    "url": "https://arxiv.org/abs/2203.05625",
    "authors": [
      "Yingfei Liu",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05653",
    "title": "Attack Analysis of Face Recognition Authentication Systems Using Fast  Gradient Sign Method",
    "abstract": "Biometric authentication methods, representing the \"something you are\" scheme, are considered the most secure approach for gaining access to protected resources. Recent attacks using Machine Learning techniques demand a serious systematic reevaluation of biometric authentication. This paper analyzes and presents the Fast Gradient Sign Method (FGSM) attack using face recognition for biometric authentication. Machine Learning techniques have been used to train and test the model, which can classify and identify different people's faces and which will be used as a target for carrying out the attack. Furthermore, the case study will analyze the implementation of the FGSM and the level of performance reduction that the model will have by applying this method in attacking. The test results were performed with the change of parameters both in terms of training and attacking the model, thus showing the efficiency of applying the FGSM. ",
    "url": "https://arxiv.org/abs/2203.05653",
    "authors": [
      "Arbena Musa",
      "Kamer Vishi",
      "Blerim Rexha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05662",
    "title": "Point Density-Aware Voxels for LiDAR 3D Object Detection",
    "abstract": "LiDAR has become one of the primary 3D object detection sensors in autonomous driving. However, LiDAR's diverging point pattern with increasing distance results in a non-uniform sampled point cloud ill-suited to discretized volumetric feature extraction. Current methods either rely on voxelized point clouds or use inefficient farthest point sampling to mitigate detrimental effects caused by density variation but largely ignore point density as a feature and its predictable relationship with distance from the LiDAR sensor. Our proposed solution, Point Density-Aware Voxel network (PDV), is an end-to-end two stage LiDAR 3D object detection architecture that is designed to account for these point density variations. PDV efficiently localizes voxel features from the 3D sparse convolution backbone through voxel point centroids. The spatially localized voxel features are then aggregated through a density-aware RoI grid pooling module using kernel density estimation (KDE) and self-attention with point density positional encoding. Finally, we exploit LiDAR's point density to distance relationship to refine our final bounding box confidences. PDV outperforms all state-of-the-art methods on the Waymo Open Dataset and achieves competitive results on the KITTI dataset. We provide a code release for PDV which is available at https://github.com/TRAILab/PDV. ",
    "url": "https://arxiv.org/abs/2203.05662",
    "authors": [
      "Jordan S. K. Hu",
      "Tianshu Kuai",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05664",
    "title": "Facilitating Federated Genomic Data Analysis by Identifying Record  Correlations while Ensuring Privacy",
    "abstract": "With the reduction of sequencing costs and the pervasiveness of computing devices, genomic data collection is continually growing. However, data collection is highly fragmented and the data is still siloed across different repositories. Analyzing all of this data would be transformative for genomics research. However, the data is sensitive, and therefore cannot be easily centralized. Furthermore, there may be correlations in the data, which if not detected, can impact the analysis. In this paper, we take the first step towards identifying correlated records across multiple data repositories in a privacy-preserving manner. The proposed framework, based on random shuffling, synthetic record generation, and local differential privacy, allows a trade-off of accuracy and computational efficiency. An extensive evaluation on real genomic data from the OpenSNP dataset shows that the proposed solution is efficient and effective. ",
    "url": "https://arxiv.org/abs/2203.05664",
    "authors": [
      "Leonard Dervishi",
      "Xinyue Wang",
      "Wentao Li",
      "Anisa Halimi",
      "Jaideep Vaidya",
      "Xiaoqian Jiang",
      "Erman Ayday"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.05684",
    "title": "PC-SwinMorph: Patch Representation for Unsupervised Medical Image  Registration and Segmentation",
    "abstract": "Medical image registration and segmentation are critical tasks for several clinical procedures. Manual realisation of those tasks is time-consuming and the quality is highly dependent on the level of expertise of the physician. To mitigate that laborious task, automatic tools have been developed where the majority of solutions are supervised techniques. However, in medical domain, the strong assumption of having a well-representative ground truth is far from being realistic. To overcome this challenge, unsupervised techniques have been investigated. However, they are still limited in performance and they fail to produce plausible results. In this work, we propose a novel unified unsupervised framework for image registration and segmentation that we called PC-SwinMorph. The core of our framework is two patch-based strategies, where we demonstrate that patch representation is key for performance gain. We first introduce a patch-based contrastive strategy that enforces locality conditions and richer feature representation. Secondly, we utilise a 3D window/shifted-window multi-head self-attention module as a patch stitching strategy to eliminate artifacts from the patch splitting. We demonstrate, through a set of numerical and visual results, that our technique outperforms current state-of-the-art unsupervised techniques. ",
    "url": "https://arxiv.org/abs/2203.05684",
    "authors": [
      "Lihao Liu",
      "Zhening Huang",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica I. Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05685",
    "title": "Data-driven geometric scale detection via Delaunay interpolation",
    "abstract": "Accurate approximation of a real-valued function depends on two aspects of the available data: the density of inputs within the domain of interest and the variation of the outputs over that domain. There are few methods for assessing whether the density of inputs is \\textit{sufficient} to identify the relevant variations in outputs -- i.e., the \"geometric scale\" of the function -- despite the fact that sampling density is closely tied to the success or failure of an approximation method. In this paper, we introduce a general purpose, computational approach to detecting the geometric scale of real-valued functions over a fixed domain using a deterministic interpolation technique from computational geometry. Our algorithm is based on the observation that a sequence of piecewise linear interpolants will converge to a continuous function at a quadratic rate (in $L^2$ norm) if and only if the data are sampled densely enough to distinguish the feature from noise. We present numerical experiments demonstrating how our method can identify feature scale, estimate uncertainty in feature scale, and assess the sampling density for fixed (i.e. static) datasets of input-output pairs. In addition, we include analytical results in support of our numerical findings and will release lightweight code that can be adapted for use in a variety of data science settings. ",
    "url": "https://arxiv.org/abs/2203.05685",
    "authors": [
      "Andrew Gillette",
      "Eugene Kur"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.05692",
    "title": "Lifelong Adaptive Machine Learning for Sensor-based Human Activity  Recognition Using Prototypical Networks",
    "abstract": "Continual learning, also known as lifelong learning, is an emerging research topic that has been attracting increasing interest in the field of machine learning. With human activity recognition (HAR) playing a key role in enabling numerous real-world applications, an essential step towards the long-term deployment of such recognition systems is to extend the activity model to dynamically adapt to changes in people's everyday behavior. Current research in continual learning applied to HAR domain is still under-explored with researchers exploring existing methods developed for computer vision in HAR. Moreover, analysis has so far focused on task-incremental or class-incremental learning paradigms where task boundaries are known. This impedes the applicability of such methods for real-world systems since data is presented in a randomly streaming fashion. To push this field forward, we build on recent advances in the area of continual machine learning and design a lifelong adaptive learning framework using Prototypical Networks, LAPNet-HAR, that processes sensor-based data streams in a task-free data-incremental fashion and mitigates catastrophic forgetting using experience replay and continual prototype adaptation. Online learning is further facilitated using contrastive loss to enforce inter-class separation. LAPNet-HAR is evaluated on 5 publicly available activity datasets in terms of the framework's ability to acquire new information while preserving previous knowledge. Our extensive empirical results demonstrate the effectiveness of LAPNet-HAR in task-free continual learning and uncover useful insights for future challenges. ",
    "url": "https://arxiv.org/abs/2203.05692",
    "authors": [
      "Rebecca Adaimi",
      "Edison Thomaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.05698",
    "title": "Learning-based Localizability Estimation for Robust LiDAR Localization",
    "abstract": "LiDAR-based localization and mapping is one of the core components in many modern robotic systems due to the direct integration of range and geometry, allowing for precise motion estimation and generation of high quality maps in real-time. Yet, as a consequence of insufficient environmental constraints present in the scene, this dependence on geometry can result in localization failure, happening in self-symmetric surroundings such as tunnels. This work addresses precisely this issue by proposing a neural network-based estimation approach for detecting (non-)localizability during robot operation. Special attention is given to the localizability of scan-to-scan registration, as it is a crucial component in many LiDAR odometry estimation pipelines. In contrast to previous, mostly traditional detection approaches, the proposed method enables early detection of failure by estimating the localizability on raw sensor measurements without evaluating the underlying registration optimization. Moreover, previous approaches remain limited in their ability to generalize across environments and sensor types, as heuristic-tuning of degeneracy detection thresholds is required. The proposed approach avoids this problem by learning from a corpus of different environments, allowing the network to function over various scenarios. Furthermore, the network is trained exclusively on simulated data, avoiding arduous data collection in challenging and degenerate, often hard-to-access, environments. The presented method is tested during field experiments conducted across challenging environments and on two different sensor types without any modifications. The observed detection performance is on par with state-of-the-art methods after environment-specific threshold tuning. ",
    "url": "https://arxiv.org/abs/2203.05698",
    "authors": [
      "Julian Nubert",
      "Etienne Walther",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05725",
    "title": "Dual-Domain Reconstruction Networks with V-Net and K-Net for fast MRI",
    "abstract": "Purpose: To introduce a dual-domain reconstruction network with V-Net and K-Net for accurate MR image reconstruction from undersampled k-space data. Methods: Most state-of-the-art reconstruction methods apply U-Net or cascaded U-Nets in image domain and/or k-space domain. Nevertheless, these methods have following problems: (1) Directly applying U-Net in k-space domain is not optimal for extracting features in k-space domain; (2) Classical image-domain oriented U-Net is heavy-weight and hence is inefficient to be cascaded many times for yielding good reconstruction accuracy; (3) Classical image-domain oriented U-Net does not fully make use information of encoder network for extracting features in decoder network; and (4) Existing methods are ineffective in simultaneously extracting and fusing features in image domain and its dual k-space domain. To tackle these problems, we propose in this paper (1) an image-domain encoder-decoder sub-network called V-Net which is more light-weight for cascading and effective in fully utilizing features in the encoder for decoding, (2) a k-space domain sub-network called K-Net which is more suitable for extracting hierarchical features in k-space domain, and (3) a dual-domain reconstruction network where V-Nets and K-Nets are parallelly and effectively combined and cascaded. Results: Extensive experimental results on the challenging fastMRI dataset demonstrate that the proposed KV-Net can reconstruct high-quality images and outperform current state-of-the-art approaches with fewer parameters. Conclusions: To reconstruct images effectively and efficiently from incomplete k-space data, we have presented a parallel dual-domain KV-Net to combine K-Nets and V-Nets. The KV-Net is more lightweight than state-of-the-art methods but achieves better reconstruction performance. ",
    "url": "https://arxiv.org/abs/2203.05725",
    "authors": [
      "Xiaohan Liu",
      "Yanwei Pang",
      "Ruiqi Jin",
      "Yu Liu",
      "Zhenchang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05733",
    "title": "A Survey of Surface Defect Detection of Industrial Products Based on A  Small Number of Labeled Data",
    "abstract": "The surface defect detection method based on visual perception has been widely used in industrial quality inspection. Because defect data are not easy to obtain and the annotation of a large number of defect data will waste a lot of manpower and material resources. Therefore, this paper reviews the methods of surface defect detection of industrial products based on a small number of labeled data, and this method is divided into traditional image processing-based industrial product surface defect detection methods and deep learning-based industrial product surface defect detection methods suitable for a small number of labeled data. The traditional image processing-based industrial product surface defect detection methods are divided into statistical methods, spectral methods and model methods. Deep learning-based industrial product surface defect detection methods suitable for a small number of labeled data are divided into based on data augmentation, based on transfer learning, model-based fine-tuning, semi-supervised, weak supervised and unsupervised. ",
    "url": "https://arxiv.org/abs/2203.05733",
    "authors": [
      "Qifan Jin",
      "Li Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05778",
    "title": "Redistribution in Public Project Problems via Neural Networks",
    "abstract": "Many important problems in multiagent systems involve resource allocations. Self-interested agents may lie about their valuations if doing so increases their own utilities. Therefore, it is necessary to design mechanisms (collective decision-making rules) with desired properties and objectives. The VCG redistribution mechanisms are efficient (the agents who value the resources the most will be allocated), strategy-proof (the agents have no incentives to lie about their valuations), and weakly budget-balanced (no deficits). We focus on the VCG redistribution mechanisms for the classic public project problem, where a group of agents needs to decide whether or not to build a non-excludable public project. We design mechanisms via neural networks with two welfare-maximizing objectives: optimal in the worst case and optimal in expectation. Previous studies showed two worst-case optimal mechanisms for 3 agents, but worst-case optimal mechanisms have not been identified for more than 3 agents. For maximizing expected welfare, there are no existing results. We use neural networks to design VCG redistribution mechanisms. Neural networks have been used to design the redistribution mechanisms for multi-unit auctions with unit demand. We show that for the public project problem, the previously proposed neural networks, which led to optimal/near-optimal mechanisms for multi-unit auctions with unit demand, perform abysmally for the public project problem. We significantly improve the existing networks on multiple fronts: We conduct a GAN network to generate worst-case type profiles and feed prior distribution into loss function to provide quality gradients for the optimal-in-expectation objective...... ",
    "url": "https://arxiv.org/abs/2203.05778",
    "authors": [
      "Guanhua Wang",
      "Wuli Zuo",
      "Mingyu Guo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.05787",
    "title": "Democracy Does Matter: Comprehensive Feature Mining for Co-Salient  Object Detection",
    "abstract": "Co-salient object detection, with the target of detecting co-existed salient objects among a group of images, is gaining popularity. Recent works use the attention mechanism or extra information to aggregate common co-salient features, leading to incomplete even incorrect responses for target objects. In this paper, we aim to mine comprehensive co-salient features with democracy and reduce background interference without introducing any extra information. To achieve this, we design a democratic prototype generation module to generate democratic response maps, covering sufficient co-salient regions and thereby involving more shared attributes of co-salient objects. Then a comprehensive prototype based on the response maps can be generated as a guide for final prediction. To suppress the noisy background information in the prototype, we propose a self-contrastive learning module, where both positive and negative pairs are formed without relying on additional classification information. Besides, we also design a democratic feature enhancement module to further strengthen the co-salient features by readjusting attention values. Extensive experiments show that our model obtains better performance than previous state-of-the-art methods, especially on challenging real-world cases (e.g., for CoCA, we obtain a gain of 2.0% for MAE, 5.4% for maximum F-measure, 2.3% for maximum E-measure, and 3.7% for S-measure) under the same settings. Code will be released soon. ",
    "url": "https://arxiv.org/abs/2203.05787",
    "authors": [
      "Siyue Yu",
      "Jimin Xiao",
      "Bingfeng Zhang",
      "Eng Gee Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05793",
    "title": "PathSAGE: Spatial Graph Attention Neural Networks With Random Path  Sampling",
    "abstract": "Graph Convolutional Networks (GCNs) achieve great success in non-Euclidean structure data processing recently. In existing studies, deeper layers are used in CCNs to extract deeper features of Euclidean structure data. However, for non-Euclidean structure data, too deep GCNs will confront with problems like \"neighbor explosion\" and \"over-smoothing\", it also cannot be applied to large datasets. To address these problems, we propose a model called PathSAGE, which can learn high-order topological information and improve the model's performance by expanding the receptive field. The model randomly samples paths starting from the central node and aggregates them by Transformer encoder. PathSAGE has only one layer of structure to aggregate nodes which avoid those problems above. The results of evaluation shows that our model achieves comparable performance with the state-of-the-art models in inductive learning tasks. ",
    "url": "https://arxiv.org/abs/2203.05793",
    "authors": [
      "Junhua Ma",
      "Jiajun Li",
      "Xueming Li",
      "Xu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05794",
    "title": "BERTopic: Neural topic modeling with a class-based TF-IDF procedure",
    "abstract": "Topic models can be useful tools to discover latent topics in collections of documents. Recent studies have shown the feasibility of approach topic modeling as a clustering task. We present BERTopic, a topic model that extends this process by extracting coherent topic representation through the development of a class-based variation of TF-IDF. More specifically, BERTopic generates document embedding with pre-trained transformer-based language models, clusters these embeddings, and finally, generates topic representations with the class-based TF-IDF procedure. BERTopic generates coherent topics and remains competitive across a variety of benchmarks involving classical models and those that follow the more recent clustering approach of topic modeling. ",
    "url": "https://arxiv.org/abs/2203.05794",
    "authors": [
      "Maarten Grootendorst"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.05807",
    "title": "Improve Convolutional Neural Network Pruning by Maximizing Filter  Variety",
    "abstract": "Neural network pruning is a widely used strategy for reducing model storage and computing requirements. It allows to lower the complexity of the network by introducing sparsity in the weights. Because taking advantage of sparse matrices is still challenging, pruning is often performed in a structured way, i.e. removing entire convolution filters in the case of ConvNets, according to a chosen pruning criteria. Common pruning criteria, such as l1-norm or movement, usually do not consider the individual utility of filters, which may lead to: (1) the removal of filters exhibiting rare, thus important and discriminative behaviour, and (2) the retaining of filters with redundant information. In this paper, we present a technique solving those two issues, and which can be appended to any pruning criteria. This technique ensures that the criteria of selection focuses on redundant filters, while retaining the rare ones, thus maximizing the variety of remaining filters. The experimental results, carried out on different datasets (CIFAR-10, CIFAR-100 and CALTECH-101) and using different architectures (VGG-16 and ResNet-18) demonstrate that it is possible to achieve similar sparsity levels while maintaining a higher performance when appending our filter selection technique to pruning criteria. Moreover, we assess the quality of the found sparse sub-networks by applying the Lottery Ticket Hypothesis and find that the addition of our method allows to discover better performing tickets in most cases ",
    "url": "https://arxiv.org/abs/2203.05807",
    "authors": [
      "Nathan Hubens",
      "Matei Mancas",
      "Bernard Gosselin",
      "Marius Preda",
      "Titus Zaharia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05823",
    "title": "Towards Open Intent Detection",
    "abstract": "The open intent detection problem is presented in this paper, which aims to identify known intents and detect open intent in natural language understanding. Current methods have two core challenges. On the one hand, the existing methods have limitations in learning robust representations to detect the open intent without any prior knowledge. On the other hand, there lacks an effective approach to learning the specific and compact decision boundary to distinguish the known intents and the open intent. This paper introduces an original pipeline framework, DA-ADB, to address these issues, which successively learns discriminative intent features with distance-aware strategy and appropriate decision boundaries adaptive to the feature space for open intent detection. The proposed method first leverages distance information to enhance the distinguishing capability of the intent representations. Then, it obtains discriminative decision boundaries adaptive to the known intent feature space by balancing both the empirical and open space risks. Extensive experiments show the effectiveness of distance-aware and boundary learning strategies. Compared with the state-of-the-art methods, our method achieves substantial improvements on three benchmark intent datasets. It also yields robust performance with different proportions of labeled data and known categories. ",
    "url": "https://arxiv.org/abs/2203.05823",
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Shaojie Zhao",
      "Qianrui Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.05824",
    "title": "Towards Analyzing the Bias of News Recommender Systems Using Sentiment  and Stance Detection",
    "abstract": "News recommender systems are used by online news providers to alleviate information overload and to provide personalized content to users. However, algorithmic news curation has been hypothesized to create filter bubbles and to intensify users' selective exposure, potentially increasing their vulnerability to polarized opinions and fake news. In this paper, we show how information on news items' stance and sentiment can be utilized to analyze and quantify the extent to which recommender systems suffer from biases. To that end, we have annotated a German news corpus on the topic of migration using stance detection and sentiment analysis. In an experimental evaluation with four different recommender systems, our results show a slight tendency of all four models for recommending articles with negative sentiments and stances against the topic of refugees and migration. Moreover, we observed a positive correlation between the sentiment and stance bias of the text-based recommenders and the preexisting user bias, which indicates that these systems amplify users' opinions and decrease the diversity of recommended news. The knowledge-aware model appears to be the least prone to such biases, at the cost of predictive accuracy. ",
    "url": "https://arxiv.org/abs/2203.05824",
    "authors": [
      "Mehwish Alam",
      "Andreea Iana",
      "Alexander Grote",
      "Katharina Ludwig",
      "Philipp M\u00fcller",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.05835",
    "title": "MLRM: A Multiple Linear Regression based Model for Average Temperature  Prediction of A Day",
    "abstract": "Weather is a phenomenon that affects everything and everyone around us on a daily basis. Weather prediction has been an important point of study for decades as researchers have tried to predict the weather and climatic changes using traditional meteorological techniques. With the advent of modern technologies and computing power, we can do so with the help of machine learning techniques. We aim to predict the weather of an area using past meteorological data and features using the Multiple Linear Regression Model. The performance of the model is evaluated and a conclusion is drawn. The model is successfully able to predict the average temperature of a day with an error of 2.8 degrees Celsius. ",
    "url": "https://arxiv.org/abs/2203.05835",
    "authors": [
      "Ishu Gupta",
      "Harsh Mittal",
      "Deepak Rikhari",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05836",
    "title": "Efficient and Robust Semantic Mapping for Indoor Environments",
    "abstract": "A key proficiency an autonomous mobile robot must have to perform high-level tasks is a strong understanding of its environment. This involves information about what types of objects are present, where they are, what their spatial extend is, and how they can be reached, i.e., information about free space is also crucial. Semantic maps are a powerful instrument providing such information. However, applying semantic segmentation and building 3D maps with high spatial resolution is challenging given limited resources on mobile robots. In this paper, we incorporate semantic information into efficient occupancy normal distribution transform (NDT) maps to enable real-time semantic mapping on mobile robots. On the publicly available dataset Hypersim, we show that, due to their sub-voxel accuracy, semantic NDT maps are superior to other approaches. We compare them to the recent state-of-the-art approach based on voxels and semantic Bayesian spatial kernel inference~(S-BKI) and to an optimized version of it derived in this paper. The proposed semantic NDT maps can represent semantics to the same level of detail, while mapping is 2.7 to 17.5 times faster. For the same grid resolution, they perform significantly better, while mapping is up to more than 5 times faster. Finally, we prove the real-world applicability of semantic NDT maps with qualitative results in a domestic application. ",
    "url": "https://arxiv.org/abs/2203.05836",
    "authors": [
      "Daniel Seichter",
      "Patrick Langer",
      "Tim Wengefeld",
      "Benjamin Lewandowski",
      "Dominik Hoechemer",
      "Horst-Michael Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.05840",
    "title": "Automatic Identification and Classification of Bragging in Social Media",
    "abstract": "Bragging is a speech act employed with the goal of constructing a favorable self-image through positive statements about oneself. It is widespread in daily communication and especially popular in social media, where users aim to build a positive image of their persona directly or indirectly. In this paper, we present the first large scale study of bragging in computational linguistics, building on previous research in linguistics and pragmatics. To facilitate this, we introduce a new publicly available data set of tweets annotated for bragging and their types. We empirically evaluate different transformer-based models injected with linguistic information in (a) binary bragging classification, i.e., if tweets contain bragging statements or not; and (b) multi-class bragging type prediction including not bragging. Our results show that our models can predict bragging with macro F1 up to 72.42 and 35.95 in the binary and multi-class classification tasks respectively. Finally, we present an extensive linguistic and error analysis of bragging prediction to guide future research on this topic. ",
    "url": "https://arxiv.org/abs/2203.05840",
    "authors": [
      "Mali Jin",
      "Daniel Preo\u0163iuc-Pietro",
      "A. Seza Do\u011fru\u00f6z",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.05842",
    "title": "Multiple Inputs Neural Networks for Medicare fraud Detection",
    "abstract": "Medicare fraud results in considerable losses for governments and insurance companies and results in higher premiums from clients. Medicare fraud costs around 13 billion euros in Europe and between 21 billion and 71 billion US dollars per year in the United States. This study aims to use artificial neural network based classifiers to predict medicare fraud. The main difficulty using machine learning techniques in fraud detection or more generally anomaly detection is that the data sets are highly imbalanced. To detect medicare frauds, we propose a multiple inputs deep neural network based classifier with a Long-short Term Memory (LSTM) autoencoder component. This architecture makes it possible to take into account many sources of data without mixing them and makes the classification task easier for the final model. The latent features extracted from the LSTM autoencoder have a strong discriminating power and separate the providers into homogeneous clusters. We use the data sets from the Centers for Medicaid and Medicare Services (CMS) of the US federal government. The CMS provides publicly available data that brings together all of the cost price requests sent by American hospitals to medicare companies. Our results show that although baseline artificial neural network give good performances, they are outperformed by our multiple inputs neural networks. We have shown that using a LSTM autoencoder to embed the provider behavior gives better results and makes the classifiers more robust to class imbalance. ",
    "url": "https://arxiv.org/abs/2203.05842",
    "authors": [
      "Mansour Zoubeirou A Mayaki",
      "Michel Riveill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05858",
    "title": "Deep Learning-Based Blind Multiple User Detection for Grant-free SCMA  and MUSA Systems",
    "abstract": "Grant-free random access and uplink non-orthogonal multiple access (NOMA) are techniques to increase the overload factor and reduce transmission latency with signaling overhead in massive machine-type communications (mMTC). Sparse code multiple access (SCMA) and Multi-user shared access (MUSA) are introduced as advanced code domain NOMA schemes. In grant-free NOMA, machine-type devices (MTD) transmit information to the base station (BS) without a grant, creating a challenging task for the BS to identify the active MTD among all potential active devices. In this paper, a novel deep neural network (DNN)-based multi-user detection (MUD) scheme for the grant-free SCMA and MUSA system in an mMTC uplink framework is proposed to jointly identify the received signal's sparsity and the active MTDs in the absence of channel state information. The proposed scheme learns the correlation between the received signal and the multi-dimensional codebook for SCMA and spreading sequences for MUSA schemes and is able to identify the active MTDs from the received signal without any prior knowledge of the device sparsity level. The application of the proposed MUD scheme is further investigated in an indoor factory setting using four different mmWave channels. Numerical results show that when the number of active MTDs in the system is large, DNN-MUD has a significantly higher probability of detection compared to existing approaches over the signal-to-noise ratio range of interest. ",
    "url": "https://arxiv.org/abs/2203.05858",
    "authors": [
      "Thushan Sivalingam",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Nandana Rajatheva",
      "Matti Latva Aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.05880",
    "title": "Multi-modal Graph Learning for Disease Prediction",
    "abstract": "Benefiting from the powerful expressive capability of graphs, graph-based approaches have been popularly applied to handle multi-modal medical data and achieved impressive performance in various biomedical applications. For disease prediction tasks, most existing graph-based methods tend to define the graph manually based on specified modality (e.g., demographic information), and then integrated other modalities to obtain the patient representation by Graph Representation Learning (GRL). However, constructing an appropriate graph in advance is not a simple matter for these methods. Meanwhile, the complex correlation between modalities is ignored. These factors inevitably yield the inadequacy of providing sufficient information about the patient's condition for a reliable diagnosis. To this end, we propose an end-to-end Multi-modal Graph Learning framework (MMGL) for disease prediction with multi-modality. To effectively exploit the rich information across multi-modality associated with the disease, modality-aware representation learning is proposed to aggregate the features of each modality by leveraging the correlation and complementarity between the modalities. Furthermore, instead of defining the graph manually, the latent graph structure is captured through an effective way of adaptive graph learning. It could be jointly optimized with the prediction model, thus revealing the intrinsic connections among samples. Our model is also applicable to the scenario of inductive learning for those unseen data. An extensive group of experiments on two disease prediction tasks demonstrates that the proposed MMGL achieves more favorable performance. The code of MMGL is available at \\url{https://github.com/SsGood/MMGL}. ",
    "url": "https://arxiv.org/abs/2203.05880",
    "authors": [
      "Shuai Zheng",
      "Zhenfeng Zhu",
      "Zhizhe Liu",
      "Zhenyu Guo",
      "Yang Liu",
      "Yuchen Yang",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05903",
    "title": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models",
    "abstract": "Neural networks (NNs) are emerging as powerful tools to represent the dynamics of control systems with complicated physics or black-box components. Due to complexity of NNs, however, existing methods are unable to synthesize complex behaviors with guarantees for NN dynamic models (NNDMs). This work introduces a control synthesis framework for stochastic NNDMs with performance guarantees. The focus is on specifications expressed in linear temporal logic interpreted over finite traces (LTLf), and the approach is based on finite abstraction. Specifically, we leverage recent techniques for convex relaxation of NNs to formally abstract a NNDM into an interval Markov decision process (IMDP). Then, a strategy that maximizes the probability of satisfying a given LTLf specification is synthesized over the IMDP and mapped back to the underlying NNDM. We show that the process of abstracting NNDMs to IMDPs reduces to a set of convex optimization problems, hence guaranteeing efficiency. We also present an adaptive refinement procedure that makes the framework scalable. On several case studies, we illustrate the efficacy of the framework in providing non-trivial guarantees of correctness for NNDMs with architectures of up to 5 hidden layers and hundreds of neurons per layer. ",
    "url": "https://arxiv.org/abs/2203.05903",
    "authors": [
      "Steven Adams",
      "Morteza Lahijanian",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.05918",
    "title": "Integrating Dependency Tree Into Self-attention for Sentence  Representation",
    "abstract": "Recent progress on parse tree encoder for sentence representation learning is notable. However, these works mainly encode tree structures recursively, which is not conducive to parallelization. On the other hand, these works rarely take into account the labels of arcs in dependency trees. To address both issues, we propose Dependency-Transformer, which applies a relation-attention mechanism that works in concert with the self-attention mechanism. This mechanism aims to encode the dependency and the spatial positional relations between nodes in the dependency tree of sentences. By a score-based method, we successfully inject the syntax information without affecting Transformer's parallelizability. Our model outperforms or is comparable to the state-of-the-art methods on four tasks for sentence representation and has obvious advantages in computational efficiency. ",
    "url": "https://arxiv.org/abs/2203.05918",
    "authors": [
      "Junhua Ma",
      "Jiajun Li",
      "Yuxuan Liu",
      "Shangbo Zhou",
      "Xue Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05919",
    "title": "Graph Summarization with Graph Neural Networks",
    "abstract": "The goal of graph summarization is to represent large graphs in a structured and compact way. A graph summary based on equivalence classes preserves pre-defined features of a graph's vertex within a $k$-hop neighborhood such as the vertex labels and edge labels. Based on these neighborhood characteristics, the vertex is assigned to an equivalence class. The calculation of the assigned equivalence class must be a permutation invariant operation on the pre-defined features. This is achieved by sorting on the feature values, e. g., the edge labels, which is computationally expensive, and subsequently hashing the result. Graph Neural Networks (GNN) fulfill the permutation invariance requirement. We formulate the problem of graph summarization as a subgraph classification task on the root vertex of the $k$-hop neighborhood. We adapt different GNN architectures, both based on the popular message-passing protocol and alternative approaches, to perform the structural graph summarization task. We compare different GNNs with a standard multi-layer perceptron (MLP) and Bloom filter as non-neural method. For our experiments, we consider four popular graph summary models on a large web graph. This resembles challenging multi-class vertex classification tasks with the numbers of classes ranging from $576$ to multiple hundreds of thousands. Our results show that the performance of GNNs are close to each other. In three out of four experiments, the non-message-passing GraphMLP model outperforms the other GNNs. The performance of the standard MLP is extraordinary good, especially in the presence of many classes. Finally, the Bloom filter outperforms all neural architectures by a large margin, except for the dataset with the fewest number of $576$ classes. ",
    "url": "https://arxiv.org/abs/2203.05919",
    "authors": [
      "Maximilian Blasi",
      "Manuel Freudenreich",
      "Johannes Horvath",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05928",
    "title": "TFCNet: Temporal Fully Connected Networks for Static Unbiased Temporal  Reasoning",
    "abstract": "Temporal Reasoning is one important functionality for vision intelligence. In computer vision research community, temporal reasoning is usually studied in the form of video classification, for which many state-of-the-art Neural Network structures and dataset benchmarks are proposed in recent years, especially 3D CNNs and Kinetics. However, some recent works found that current video classification benchmarks contain strong biases towards static features, thus cannot accurately reflect the temporal modeling ability. New video classification benchmarks aiming to eliminate static biases are proposed, with experiments on these new benchmarks showing that the current clip-based 3D CNNs are outperformed by RNN structures and recent video transformers. In this paper, we find that 3D CNNs and their efficient depthwise variants, when video-level sampling strategy is used, are actually able to beat RNNs and recent vision transformers by significant margins on static-unbiased temporal reasoning benchmarks. Further, we propose Temporal Fully Connected Block (TFC Block), an efficient and effective component, which approximates fully connected layers along temporal dimension to obtain video-level receptive field, enhancing the spatiotemporal reasoning ability. With TFC blocks inserted into Video-level 3D CNNs (V3D), our proposed TFCNets establish new state-of-the-art results on synthetic temporal reasoning benchmark, CATER, and real world static-unbiased dataset, Diving48, surpassing all previous methods. ",
    "url": "https://arxiv.org/abs/2203.05928",
    "authors": [
      "Shiwen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05933",
    "title": "A fast, high-order scheme for evaluating volume potentials on complex 2D  geometries via area-to-line integral conversion and domain mappings",
    "abstract": "This article presents a new high-order accurate algorithm for finding a particular solution to a linear, constant-coefficient partial differential equation (PDE) by means of a convolution of the volumetric source function with the Green's function in complex geometries. Utilizing volumetric domain decomposition, the integral is computed over a union of regular boxes (lending the scheme compatibility with adaptive box codes) and triangular regions (which may be potentially curved near boundaries). Singular and near-singular quadrature is handled by converting integrals on volumetric regions to line integrals bounding a reference volume cell using cell mappings and elements of the Poincar\\'e lemma, followed by leveraging existing one-dimensional near-singular and singular quadratures appropriate to the singular nature of the kernel. The scheme achieves compatibility with fast multipole methods (FMMs) and thereby optimal asymptotic complexity by coupling global rules for target-independent quadrature of smooth functions to local target-dependent singular quadrature corrections, and it relies on orthogonal polynomial systems on each cell for well-conditioned, high-order and efficient (with respect to number of required volume function evaluations) approximation of arbitrary volumetric sources. Our domain discretization scheme is naturally compatible with standard meshing software such as Gmsh, which are employed to discretize a narrow region surrounding the domain boundaries. We present 8th-order accurate results, demonstrate the success of the method with examples showing up to 12-digit accuracy on complex geometries, and, for static geometries, our numerical examples show well over $99\\%$ of evaluation time of the particular solution is spent in the FMM step. ",
    "url": "https://arxiv.org/abs/2203.05933",
    "authors": [
      "Thomas G. Anderson",
      "Hai Zhu",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.05944",
    "title": "Saliency-Driven Versatile Video Coding for Neural Object Detection",
    "abstract": "Saliency-driven image and video coding for humans has gained importance in the recent past. In this paper, we propose such a saliency-driven coding framework for the video coding for machines task using the latest video coding standard Versatile Video Coding (VVC). To determine the salient regions before encoding, we employ the real-time-capable object detection network You Only Look Once~(YOLO) in combination with a novel decision criterion. To measure the coding quality for a machine, the state-of-the-art object segmentation network Mask R-CNN was applied to the decoded frame. From extensive simulations we find that, compared to the reference VVC with a constant quality, up to 29 % of bitrate can be saved with the same detection accuracy at the decoder side by applying the proposed saliency-driven framework. Besides, we compare YOLO against other, more traditional saliency detection methods. ",
    "url": "https://arxiv.org/abs/2203.05944",
    "authors": [
      "Kristian Fischer",
      "Felix Fleckenstein",
      "Christian Herglotz",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.05948",
    "title": "Block-Sparse Adversarial Attack to Fool Transformer-Based Text  Classifiers",
    "abstract": "Recently, it has been shown that, in spite of the significant performance of deep neural networks in different fields, those are vulnerable to adversarial examples. In this paper, we propose a gradient-based adversarial attack against transformer-based text classifiers. The adversarial perturbation in our method is imposed to be block-sparse so that the resultant adversarial example differs from the original sentence in only a few words. Due to the discrete nature of textual data, we perform gradient projection to find the minimizer of our proposed optimization problem. Experimental results demonstrate that, while our adversarial attack maintains the semantics of the sentence, it can reduce the accuracy of GPT-2 to less than 5% on different datasets (AG News, MNLI, and Yelp Reviews). Furthermore, the block-sparsity constraint of the proposed optimization problem results in small perturbations in the adversarial example. ",
    "url": "https://arxiv.org/abs/2203.05948",
    "authors": [
      "Sahar Sadrizadeh",
      "Ljiljana Dolamic",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05949",
    "title": "Peng Cheng Object Detection Benchmark for Smart City",
    "abstract": "Object detection is an algorithm that recognizes and locates the objects in the image and has a wide range of applications in the visual understanding of complex urban scenes. Existing object detection benchmarks mainly focus on a single specific scenario and their annotation attributes are not rich enough, these make the object detection model is not generalized for the smart city scenes. Considering the diversity and complexity of scenes in intelligent city governance, we build a large-scale object detection benchmark for the smart city. Our benchmark contains about 500K images and includes three scenarios: intelligent transportation, intelligent security, and drones. For the complexity of the real scene in the smart city, the diversity of weather, occlusion, and other complex environment diversity attributes of the images in the three scenes are annotated. The characteristics of the benchmark are analyzed and extensive experiments of the current state-of-the-art target detection algorithm are conducted based on our benchmark to show their performance. ",
    "url": "https://arxiv.org/abs/2203.05949",
    "authors": [
      "Yaowei Wang",
      "Zhouxin Yang",
      "Rui Liu",
      "Deng Li",
      "Yuandu Lai",
      "Leyuan Fang",
      "Yahong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05966",
    "title": "Online User Profiling to Detect Social Bots on Twitter",
    "abstract": "Social media platforms can expose influential trends in many aspects of everyday life. However, the movements they represent can be contaminated by disinformation. Social bots are one of the significant sources of disinformation in social media. Social bots can pose serious cyber threats to society and public opinion. This research aims to develop machine learning models to detect bots based on the extracted user's profile from a Tweet's text. Online users' profile shows the user's personal information, such as age, gender, education, and personality. In this work, the user's profile is constructed based on the user's online posts. This work's main contribution is three-fold: First, we aim to improve bot detection through machine learning models based on the user's personal information generated by the user's online comments. When comparing two online posts, the similarity of personal information makes it difficult to differentiate a bot from a human user. However, this research turns personal information similarity among two online posts into an advantage for the new bot detection model. The new proposed model for bot detection creates user profiles based on personal information such as age, personality, gender, education from users' online posts and introduces a machine learning model to detect social bots with high prediction accuracy based on personal information. Second, create a new public data set that shows the user's profile for more than 6900 Twitter accounts in the Cresci 2017 data set. ",
    "url": "https://arxiv.org/abs/2203.05966",
    "authors": [
      "Maryam Heidari",
      "James H Jr Jones",
      "Ozlem Uzuner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.05974",
    "title": "On The Scale Dependence and Spacetime Dimension of the Internet with  Causal Sets",
    "abstract": "A statistical measure of dimension is used to compute the effective average space dimension for the Internet and other graphs, based on typed edges (links) from an ensemble of starting points. The method is applied to CAIDA's ITDK data for the Internet. The effective dimension at different scales is calibrated to the conventional Euclidean dimension using low dimensional hypercubes. Internet spacetime has a 'foamy' multi-scale containment hierarchy, with interleaving semantic types. There is an emergent scale for approximate long range order in the device node spectrum, but this is not evident at the AS level, where there is finite distance containment. Statistical dimension is thus a locally varying measure, which is scale-dependent, giving an visual analogy for the hidden scale-dependent dimensions of Kaluza-Klein theories. The characteristic exterior dimensions of the Internet lie between 1.66 +- 0.00 and 6.12 +- 0.00, and maximal interior dimensions rise to 7.7. ",
    "url": "https://arxiv.org/abs/2203.05974",
    "authors": [
      "Mark Burgess"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2203.05983",
    "title": "PseudoProp: Robust Pseudo-Label Generation for Semi-Supervised Object  Detection in Autonomous Driving Systems",
    "abstract": "Semi-supervised object detection methods are widely used in autonomous driving systems, where only a fraction of objects are labeled. To propagate information from the labeled objects to the unlabeled ones, pseudo-labels for unlabeled objects must be generated. Although pseudo-labels have proven to improve the performance of semi-supervised object detection significantly, the applications of image-based methods to video frames result in numerous miss or false detections using such generated pseudo-labels. In this paper, we propose a new approach, PseudoProp, to generate robust pseudo-labels by leveraging motion continuity in video frames. Specifically, PseudoProp uses a novel bidirectional pseudo-label propagation approach to compensate for misdetection. A feature-based fusion technique is also used to suppress inference noise. Extensive experiments on the large-scale Cityscapes dataset demonstrate that our method outperforms the state-of-the-art semi-supervised object detection methods by 7.4% on mAP75. ",
    "url": "https://arxiv.org/abs/2203.05983",
    "authors": [
      "Shu Hu",
      "Chun-Hao Liu",
      "Jayanta Dutta",
      "Ming-Ching Chang",
      "Siwei Lyu",
      "Naveen Ramakrishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05985",
    "title": "Graph Neural Networks for Relational Inductive Bias in Vision-based Deep  Reinforcement Learning of Robot Control",
    "abstract": "State-of-the-art reinforcement learning algorithms predominantly learn a policy from either a numerical state vector or images. Both approaches generally do not take structural knowledge of the task into account, which is especially prevalent in robotic applications and can benefit learning if exploited. This work introduces a neural network architecture that combines relational inductive bias and visual feedback to learn an efficient position control policy for robotic manipulation. We derive a graph representation that models the physical structure of the manipulator and combines the robot's internal state with a low-dimensional description of the visual scene generated by an image encoding network. On this basis, a graph neural network trained with reinforcement learning predicts joint velocities to control the robot. We further introduce an asymmetric approach of training the image encoder separately from the policy using supervised learning. Experimental results demonstrate that, for a 2-DoF planar robot in a geometrically simplistic 2D environment, a learned representation of the visual scene can replace access to the explicit coordinates of the reaching target without compromising on the quality and sample efficiency of the policy. We further show the ability of the model to improve sample efficiency for a 6-DoF robot arm in a visually realistic 3D environment. ",
    "url": "https://arxiv.org/abs/2203.05985",
    "authors": [
      "Marco Oliva",
      "Soubarna Banik",
      "Josip Josifovski",
      "Alois Knoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.05997",
    "title": "Towards Self-Supervised Learning of Global and Object-Centric  Representations",
    "abstract": "Self-supervision allows learning meaningful representations of natural images which usually contain one central object. How well does it transfer to multi-entity scenes? We discuss key aspects of learning structured object-centric representations with self-supervision and validate our insights through several experiments on the CLEVR dataset. Regarding the architecture, we confirm the importance of competition for attention-based object discovery, where each image patch is exclusively attended by one object. For training, we show that contrastive losses equipped with matching can be applied directly in a latent space, avoiding pixel-based reconstruction. However, such an optimization objective is sensitive to false negatives (recurring objects) and false positives (matching errors). Thus, careful consideration is required around data augmentation and negative sample selection. ",
    "url": "https://arxiv.org/abs/2203.05997",
    "authors": [
      "Federico Baldassarre",
      "Hossein Azizpour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06012",
    "title": "Snap-Stabilizing Tasks in Anonymous Networks",
    "abstract": "We consider snap-stabilizing algorithms in anonymous networks. Self-stabilizing algorithms are well known fault tolerant algorithms : a self-stabilizing algorithm will eventually recover from arbitrary transient faults. On the other hand, an algorithm is snap-stabilizing if it can withstand arbitrary initial values and immediately satisfy its safety requirement. It is a subset of self-stabilizing algorithms. Distributed tasks that are solvable with self-stabilizing algorithms in anonymous networks have already been characterized by Boldi and Vigna in [BV02b]. In this paper, we show how the more demanding snap-stabilizing algorithms can be handled with standard tools for (not stabilizing) algorithms in anonymous networks. We give a characterization of which tasks are solvable by snap-stabilizing algorithms in anonymous networks. We also present a snap-stabilizing version of Mazurkiewicz' enumeration algorithm. This work exposes, from a task-equivalence point of view, the complete correspondence in anonymous networks between self or snap-stabilizing tasks and distributed tasks with various termination detection requirements. ",
    "url": "https://arxiv.org/abs/2203.06012",
    "authors": [
      "Emmanuel Godard"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.06015",
    "title": "Comparing Global Tourism Flows Measured by Official Census and Social  Sensing",
    "abstract": "A better understanding of the behavior of tourists is strategic for improving services in the competitive and important economic segment of global tourism. Critical studies in the literature often explore the issue using traditional data, such as questionnaires or interviews. Traditional approaches provide precious information; however, they impose challenges to obtaining large-scale data, making it hard to study worldwide patterns. Location-based social networks (LBSNs) can potentially mitigate such issues due to the relatively low cost of acquiring large amounts of behavioral data. Nevertheless, before using such data for studying tourists' behavior, it is necessary to verify whether the information adequately reveals the behavior measured with traditional data -- considered the ground truth. Thus, the present work investigates in which countries the global tourism network measured with an LBSN agreeably reflects the behavior estimated by the World Tourism Organization using traditional methods. Although we could find exceptions, the results suggest that, for most countries, LBSN data can satisfactorily represent the behavior studied. We have an indication that, in countries with high correlations between results obtained from both datasets, LBSN data can be used in research regarding the mobility of the tourists in the studied context. ",
    "url": "https://arxiv.org/abs/2203.06015",
    "authors": [
      "Lucas Skora",
      "Helen Senefonte",
      "Myriam Delgado",
      "Ricardo L\u00fcders",
      "Thiago Silva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.06020",
    "title": "Enhancing Adversarial Training with Second-Order Statistics of Weights",
    "abstract": "Adversarial training has been shown to be one of the most effective approaches to improve the robustness of deep neural networks. It is formalized as a min-max optimization over model weights and adversarial perturbations, where the weights can be optimized through gradient descent methods like SGD. In this paper, we show that treating model weights as random variables allows for enhancing adversarial training through \\textbf{S}econd-Order \\textbf{S}tatistics \\textbf{O}ptimization (S$^2$O) with respect to the weights. By relaxing a common (but unrealistic) assumption of previous PAC-Bayesian frameworks that all weights are statistically independent, we derive an improved PAC-Bayesian adversarial generalization bound, which suggests that optimizing second-order statistics of weights can effectively tighten the bound. In addition to this theoretical insight, we conduct an extensive set of experiments, which show that S$^2$O not only improves the robustness and generalization of the trained neural networks when used in isolation, but also integrates easily in state-of-the-art adversarial training techniques like TRADES, AWP, MART, and AVMixup, leading to a measurable improvement of these techniques. The code is available at \\url{https://github.com/Alexkael/S2O}. ",
    "url": "https://arxiv.org/abs/2203.06020",
    "authors": [
      "Gaojie Jin",
      "Xinping Yi",
      "Wei Huang",
      "Sven Schewe",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06031",
    "title": "Exploiting Low-Rank Tensor-Train Deep Neural Networks Based on  Riemannian Gradient Descent With Illustrations of Speech Processing",
    "abstract": "This work focuses on designing low complexity hybrid tensor networks by considering trade-offs between the model complexity and practical performance. Firstly, we exploit a low-rank tensor-train deep neural network (TT-DNN) to build an end-to-end deep learning pipeline, namely LR-TT-DNN. Secondly, a hybrid model combining LR-TT-DNN with a convolutional neural network (CNN), which is denoted as CNN+(LR-TT-DNN), is set up to boost the performance. Instead of randomly assigning large TT-ranks for TT-DNN, we leverage Riemannian gradient descent to determine a TT-DNN associated with small TT-ranks. Furthermore, CNN+(LR-TT-DNN) consists of convolutional layers at the bottom for feature extraction and several TT layers at the top to solve regression and classification problems. We separately assess the LR-TT-DNN and CNN+(LR-TT-DNN) models on speech enhancement and spoken command recognition tasks. Our empirical evidence demonstrates that the LR-TT-DNN and CNN+(LR-TT-DNN) models with fewer model parameters can outperform the TT-DNN and CNN+(TT-DNN) counterparts. ",
    "url": "https://arxiv.org/abs/2203.06031",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Javier Tejedor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.06041",
    "title": "Embedding Earth: Self-supervised contrastive pre-training for dense land  cover classification",
    "abstract": "In training machine learning models for land cover semantic segmentation there is a stark contrast between the availability of satellite imagery to be used as inputs and ground truth data to enable supervised learning. While thousands of new satellite images become freely available on a daily basis, getting ground truth data is still very challenging, time consuming and costly. In this paper we present Embedding Earth a self-supervised contrastive pre-training method for leveraging the large availability of satellite imagery to improve performance on downstream dense land cover classification tasks. Performing an extensive experimental evaluation spanning four countries and two continents we use models pre-trained with our proposed method as initialization points for supervised land cover semantic segmentation and observe significant improvements up to 25% absolute mIoU. In every case tested we outperform random initialization, especially so when ground truth data are scarse. Through a series of ablation studies we explore the qualities of the proposed approach and find that learnt features can generalize between disparate regions opening up the possibility of using the proposed pre-training scheme as a replacement to random initialization for Earth observation tasks. Code will be uploaded soon at https://github.com/michaeltrs/DeepSatModels. ",
    "url": "https://arxiv.org/abs/2203.06041",
    "authors": [
      "Michail Tarasiou",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06055",
    "title": "Physics-aware Complex-valued Adversarial Machine Learning in  Reconfigurable Diffractive All-optical Neural Network",
    "abstract": "Diffractive optical neural networks have shown promising advantages over electronic circuits for accelerating modern machine learning (ML) algorithms. However, it is challenging to achieve fully programmable all-optical implementation and rapid hardware deployment. Furthermore, understanding the threat of adversarial ML in such system becomes crucial for real-world applications, which remains unexplored. Here, we demonstrate a large-scale, cost-effective, complex-valued, and reconfigurable diffractive all-optical neural networks system in the visible range based on cascaded transmissive twisted nematic liquid crystal spatial light modulators. With the assist of categorical reparameterization, we create a physics-aware training framework for the fast and accurate deployment of computer-trained models onto optical hardware. Furthermore, we theoretically analyze and experimentally demonstrate physics-aware adversarial attacks onto the system, which are generated from a complex-valued gradient-based algorithm. The detailed adversarial robustness comparison with conventional multiple layer perceptrons and convolutional neural networks features a distinct statistical adversarial property in diffractive optical neural networks. Our full stack of software and hardware provides new opportunities of employing diffractive optics in a variety of ML tasks and enabling the research on optical adversarial ML. ",
    "url": "https://arxiv.org/abs/2203.06055",
    "authors": [
      "Ruiyang Chen",
      "Yingjie Li",
      "Minhan Lou",
      "Jichao Fan",
      "Yingheng Tang",
      "Berardi Sensale-Rodriguez",
      "Cunxi Yu",
      "Weilu Gao"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.06059",
    "title": "Deep Convolutional Neural Network for Roadway Incident Surveillance  Using Audio Data",
    "abstract": "Crash events identification and prediction plays a vital role in understanding safety conditions for transportation systems. While existing systems use traffic parameters correlated with crash data to classify and train these models, we propose the use of a novel sensory unit that can also accurately identify crash events: microphone. Audio events can be collected and analyzed to classify events such as crash. In this paper, we have demonstrated the use of a deep Convolutional Neural Network (CNN) for road event classification. Important audio parameters such as Mel Frequency Cepstral Coefficients (MFCC), log Mel-filterbank energy spectrum and Fourier Spectrum were used as feature set. Additionally, the dataset was augmented with more sample data by the use of audio augmentation techniques such as time and pitch shifting. Together with the feature extraction this data augmentation can achieve reasonable accuracy. Four events such as crash, tire skid, horn and siren sounds can be accurately identified giving indication of a road hazard that can be useful for traffic operators or paramedics. The proposed methodology can reach accuracy up to 94%. Such audio systems can be implemented as a part of an Internet of Things (IoT) platform that can complement video-based sensors without complete coverage. ",
    "url": "https://arxiv.org/abs/2203.06059",
    "authors": [
      "Zubayer Islam",
      "Mohamed Abdel-Aty"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.06074",
    "title": "TAPE: Task-Agnostic Prior Embedding for Image Restoration",
    "abstract": "Learning an generalized prior for natural image restoration is an important yet challenging task. Early methods mostly involved handcrafted priors including normalized sparsity, L0 gradients, dark channel priors, etc. Recently, deep neural networks have been used to learn various image priors but do not guarantee to generalize. In this paper, we propose a novel approach that embeds a task-agnostic prior into a transformer. Our approach, named Task-Agnostic Prior Embedding (TAPE), consists of three stages, namely, task-agnostic pre-training, task-agnostic fine-tuning, and task-specific fine-tuning, where the first one embeds prior knowledge about natural images into the transformer and the latter two extracts the knowledge to assist downstream image restoration. Experiments on various types of degradation validate the effectiveness of TAPE. The image restoration performance in terms of PSNR is improved by as much as 1.45 dB and even outperforms task-specific algorithms. More importantly, TAPE shows the ability of disentangling generalized image priors from degraded images, which enjoys favorable transfer ability to unknown downstream tasks. ",
    "url": "https://arxiv.org/abs/2203.06074",
    "authors": [
      "Lin Liu",
      "Lingxi Xie",
      "Xiaopeng Zhang",
      "Shanxin Yuan",
      "Xiangyu Chen",
      "Wengang Zhou",
      "Houqiang Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06125",
    "title": "Protein Representation Learning by Geometric Structure Pretraining",
    "abstract": "Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled data in downstream tasks. Despite the effectiveness of sequence-based approaches, the power of pretraining on smaller numbers of known protein structures has not been explored for protein property prediction, though protein structures are known to be determinants of protein function. We first present a simple yet effective encoder to learn protein geometry features. We pretrain the protein graph encoder by leveraging multiview contrastive learning and different self-prediction tasks. Experimental results on both function prediction and fold classification tasks show that our proposed pretraining methods outperform or are on par with the state-of-the-art sequence-based methods using much less data. All codes and models will be published upon acceptance. ",
    "url": "https://arxiv.org/abs/2203.06125",
    "authors": [
      "Zuobai Zhang",
      "Minghao Xu",
      "Arian Jamasb",
      "Vijil Chenthamarakshan",
      "Aurelie Lozano",
      "Payel Das",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06143",
    "title": "Twisted Ways to Find Plane Structures in Simple Drawings of Complete  Graphs",
    "abstract": "Simple drawings are drawings of graphs in which the edges are Jordan arcs and each pair of edges share at most one point (a proper crossing or a common endpoint). We introduce a special kind of simple drawings that we call generalized twisted drawings. A simple drawing is generalized twisted if there is a point $O$ such that every ray emanating from $O$ crosses every edge of the drawing at most once and there is a ray emanating from $O$ which crosses every edge exactly once. Via this new class of simple drawings, we show that every simple drawing of the complete graph with $n$ vertices contains $\\Omega(n^{\\frac{1}{2}})$ pairwise disjoint edges and a plane path of length $\\Omega(\\frac{\\log n }{\\log \\log n})$. Both results improve over previously known best lower bounds. On the way we show several structural results about and properties of generalized twisted drawings. We further present different characterizations of generalized twisted drawings, which might be of independent interest. ",
    "url": "https://arxiv.org/abs/2203.06143",
    "authors": [
      "Oswin Aichholzer",
      "Alfredo Garc\u00eda",
      "Javier Tejel",
      "Birgit Vogtenhuber",
      "Alexandra Weinberger"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2203.06145",
    "title": "Neuromorphic Data Augmentation for Training Spiking Neural Networks",
    "abstract": "Developing neuromorphic intelligence on event-based datasets with spiking neural networks (SNNs) has recently attracted much research attention. However, the limited size of event-based datasets makes SNNs prone to overfitting and unstable convergence. This issue remains unexplored by previous academic works. In an effort to minimize this generalization gap, we propose neuromorphic data augmentation (NDA), a family of geometric augmentations specifically designed for event-based datasets with the goal of significantly stabilizing the SNN training and reducing the generalization gap between training and test performance. The proposed method is simple and compatible with existing SNN training pipelines. Using the proposed augmentation, for the first time, we demonstrate the feasibility of unsupervised contrastive learning for SNNs. We conduct comprehensive experiments on prevailing neuromorphic vision benchmarks and show that NDA yields substantial improvements over previous state-of-the-art results. For example, NDA-based SNN achieves accuracy gain on CIFAR10-DVS and N-Caltech 101 by 10.1% and 13.7%, respectively. ",
    "url": "https://arxiv.org/abs/2203.06145",
    "authors": [
      "Yuhang Li",
      "Youngeun Kim",
      "Hyoungseob Park",
      "Tamar Geller",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06176",
    "title": "More Than a Toy: Random Matrix Models Predict How Real-World Neural  Representations Generalize",
    "abstract": "Of theories for why large-scale machine learning models generalize despite being vastly overparameterized, which of their assumptions are needed to capture the qualitative phenomena of generalization in the real world? On one hand, we find that most theoretical analyses fall short of capturing these qualitative phenomena even for kernel regression, when applied to kernels derived from large-scale neural networks (e.g., ResNet-50) and real data (e.g., CIFAR-100). On the other hand, we find that the classical GCV estimator (Craven and Wahba, 1978) accurately predicts generalization risk even in such overparameterized settings. To bolster this empirical finding, we prove that the GCV estimator converges to the generalization risk whenever a local random matrix law holds. Finally, we apply this random matrix theory lens to explain why pretrained representations generalize better as well as what factors govern scaling laws for kernel regression. Our findings suggest that random matrix theory, rather than just being a toy model, may be central to understanding the properties of neural representations in practice. ",
    "url": "https://arxiv.org/abs/2203.06176",
    "authors": [
      "Alexander Wei",
      "Wei Hu",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.13289",
    "title": "The loss landscape of deep linear neural networks: a second-order  analysis",
    "abstract": "We study the optimization landscape of deep linear neural networks with the square loss. It is known that, under weak assumptions, there are no spurious local minima and no local maxima. However, the existence and diversity of non-strict saddle points, which can play a role in first-order algorithms' dynamics, have only been lightly studied. We go a step further with a full analysis of the optimization landscape at order 2. We characterize, among all critical points, which are global minimizers, strict saddle points, and non-strict saddle points. We enumerate all the associated critical values. The characterization is simple, involves conditions on the ranks of partial matrix products, and sheds some light on global convergence or implicit regularization that have been proved or observed when optimizing linear neural networks. In passing, we provide an explicit parameterization of the set of all global minimizers and exhibit large sets of strict and non-strict saddle points. ",
    "url": "https://arxiv.org/abs/2107.13289",
    "authors": [
      "El Mehdi Achour",
      "Fran\u00e7ois Malgouyres",
      "S\u00e9bastien Gerchinovitz"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05571",
    "title": "Deep Convolutional Neural Networks for Molecular Subtyping of Gliomas  Using Magnetic Resonance Imaging",
    "abstract": "Knowledge of molecular subtypes of gliomas can provide valuable information for tailored therapies. This study aimed to investigate the use of deep convolutional neural networks (DCNNs) for noninvasive glioma subtyping with radiological imaging data according to the new taxonomy announced by the World Health Organization in 2016. Methods: A DCNN model was developed for the prediction of the five glioma subtypes based on a hierarchical classification paradigm. This model used three parallel, weight-sharing, deep residual learning networks to process 2.5-dimensional input of trimodal MRI data, including T1-weighted, T1-weighted with contrast enhancement, and T2-weighted images. A data set comprising 1,016 real patients was collected for evaluation of the developed DCNN model. The predictive performance was evaluated via the area under the curve (AUC) from the receiver operating characteristic analysis. For comparison, the performance of a radiomics-based approach was also evaluated. Results: The AUCs of the DCNN model for the four classification tasks in the hierarchical classification paradigm were 0.89, 0.89, 0.85, and 0.66, respectively, as compared to 0.85, 0.75, 0.67, and 0.59 of the radiomics approach. Conclusion: The results showed that the developed DCNN model can predict glioma subtypes with promising performance, given sufficient, non-ill-balanced training data. ",
    "url": "https://arxiv.org/abs/2203.05571",
    "authors": [
      "Dong Wei",
      "Yiming Li",
      "Yinyan Wang",
      "Tianyi Qian",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05757",
    "title": "A comparative study of non-deep learning, deep learning, and ensemble  learning methods for sunspot number prediction",
    "abstract": "Solar activity has significant impacts on human activities and health. One most commonly used measure of solar activity is the sunspot number. This paper compares three important non-deep learning models, four popular deep learning models, and their five ensemble models in forecasting sunspot numbers. Our proposed ensemble model XGBoost-DL, which uses XGBoost as a two-level nonlinear ensemble method to combine the deep learning models, achieves the best forecasting performance among all considered models and the NASA's forecast. Our XGBoost-DL forecasts a peak sunspot number of 133.47 in May 2025 for Solar Cycle 25 and 164.62 in November 2035 for Solar Cycle 26, similar to but later than the NASA's at 137.7 in October 2024 and 161.2 in December 2034. ",
    "url": "https://arxiv.org/abs/2203.05757",
    "authors": [
      "Yuchen Dang",
      "Ziqi Chen",
      "Heng Li",
      "Hai Shu"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05844",
    "title": "Resource Allocation in Quantum Networks for Distributed Quantum  Computing",
    "abstract": "The evolution of quantum computing technologies has been advancing at a steady pace in the recent years, and the current trend suggests that it will become available at scale for commercial purposes in the near future. The acceleration can be boosted by pooling compute infrastructures to either parallelize algorithm execution or solve bigger instances that are not feasible on a single quantum computer, which requires an underlying Quantum Internet: the interconnection of quantum computers by quantum links and repeaters to exchange entangled quantum bits. However, Quantum Internet research so far has been focused on provisioning point-to-point flows only, which is suitable for (e.g.) quantum sensing and metrology, but not for distributed quantum computing. In this paper, after a primer on quantum computing and networking, we investigate the requirements and objectives of smart computing on distributed nodes from the perspective of quantum network provisioning. We then design a resource allocation strategy that is evaluated through a comprehensive simulation campaign, whose results highlight the key features and performance issues, and lead the way to further investigation in this direction. ",
    "url": "https://arxiv.org/abs/2203.05844",
    "authors": [
      "Claudio Cicconetti",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.05947",
    "title": "Hybrid Artifact Detection System for Minute Resolution Blood Pressure  Signals from ICU",
    "abstract": "Physiological monitoring in intensive care units generates data that can be used to aid clinical decision making facilitating early interventions. However, the low data quality of physiological signals due to the recording conditions in clinical settings limits the automated extraction of relevant information and leads to significant numbers of false alarms. This paper investigates the utilization of a hybrid artifact detection system that combines a Variational Autoencoder with a statistical detection component for the labeling of artifactual samples to automate the costly process of cleaning physiological recordings. The system is applied to mean blood pressure signals from an intensive care unit dataset recorded within the scope of the KidsBrainIT project. Its performance is benchmarked to manual annotations made by trained researchers. Our preliminary results indicate that the system is capable of consistently achieving sensitivity and specificity levels that surpass 90%. Thus, it provides an initial foundation that can be expanded upon to partially automate data cleaning in offline applications and reduce false alarms in online applications. ",
    "url": "https://arxiv.org/abs/2203.05947",
    "authors": [
      "Hollan Haule",
      "Evangelos Kafantaris",
      "Tsz-Yan Milly Lo",
      "Chen Qin",
      "Javier Escudero"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05968",
    "title": "Multi-Channel Convolutional Analysis Operator Learning for Dual-Energy  CT Reconstruction",
    "abstract": "Objective. Dual-energy computed tomography (DECT) has the potential to improve contrast, reduce artifacts and the ability to perform material decomposition in advanced imaging applications. The increased number or measurements results with a higher radiation dose and it is therefore essential to reduce either number of projections per energy or the source X-ray intensity, but this makes tomographic reconstruction more ill-posed. Approach. We developed the multi-channel convolutional analysis operator learning (MCAOL) method to exploit common spatial features within attenuation images at different energies and we propose an optimization method which jointly reconstructs the attenuation images at low and high energies with a mixed norm regularization on the sparse features obtained by pre-trained convolutional filters through the convolutional analysis operator learning (CAOL) algorithm. Main results. Extensive experiments with simulated and real computed tomography (CT) data were performed to validate the effectiveness of the proposed methods and we reported increased reconstruction accuracy compared to CAOL and iterative methods with single and joint total-variation (TV) regularization. Significance. Qualitative and quantitative results on sparse-views and low-dose DECT demonstrate that the proposed MCAOL method outperforms both CAOL applied on each energy independently and several existing state-of-the-art model-based iterative reconstruction (MBIR) techniques, thus paving the way for dose reduction. ",
    "url": "https://arxiv.org/abs/2203.05968",
    "authors": [
      "Alessandro Perelli",
      "Suxer Alfonso Garcia",
      "Alexandre Bousse",
      "Jean-Pierre Tasu",
      "Nikolaos Efthimiadis",
      "Dimitris Visvikis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2203.06006",
    "title": "Edge and Pair Queries -- Random Graphs and Complexity",
    "abstract": "We investigate two types of query games played on a graph, pair queries and edge queries. We concentrate on investigating the two associated graph parameters for binomial random graphs, and showing that determining any of the two parameters is NP-hard for bounded degree graphs. ",
    "url": "https://arxiv.org/abs/2203.06006",
    "authors": [
      "Dariusz Dereniowski",
      "Przemys\u0142aw Gordinowicz",
      "Pawe\u0142 Pra\u0142at"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.06007",
    "title": "Online Graph Learning from Social Interactions",
    "abstract": "Social learning algorithms provide models for the formation of opinions over social networks resulting from local reasoning and peer-to-peer exchanges. Interactions occur over an underlying graph topology, which describes the flow of information and relative influence between pairs of agents. For a given graph topology, these algorithms allow for the prediction of formed opinions. In this work, we study the inverse problem. Given a social learning model and observations of the evolution of beliefs over time, we aim at identifying the underlying graph topology. The learned graph allows for the inference of pairwise influence between agents, the overall influence agents have over the behavior of the network, as well as the flow of information through the social network. The proposed algorithm is online in nature and can adapt dynamically to changes in the graph topology or the true hypothesis. ",
    "url": "https://arxiv.org/abs/2203.06007",
    "authors": [
      "Valentina Shumovskaia",
      "Konstantinos Ntemos",
      "Stefan Vlaski",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.06060",
    "title": "ROOD-MRI: Benchmarking the robustness of deep learning segmentation  models to out-of-distribution and corrupted data in MRI",
    "abstract": "Deep artificial neural networks (DNNs) have moved to the forefront of medical image analysis due to their success in classification, segmentation, and detection challenges. A principal challenge in large-scale deployment of DNNs in neuroimage analysis is the potential for shifts in signal-to-noise ratio, contrast, resolution, and presence of artifacts from site to site due to variances in scanners and acquisition protocols. DNNs are famously susceptible to these distribution shifts in computer vision. Currently, there are no benchmarking platforms or frameworks to assess the robustness of new and existing models to specific distribution shifts in MRI, and accessible multi-site benchmarking datasets are still scarce or task-specific. To address these limitations, we propose ROOD-MRI: a platform for benchmarking the Robustness of DNNs to Out-Of-Distribution (OOD) data, corruptions, and artifacts in MRI. The platform provides modules for generating benchmarking datasets using transforms that model distribution shifts in MRI, implementations of newly derived benchmarking metrics for image segmentation, and examples for using the methodology with new models and tasks. We apply our methodology to hippocampus, ventricle, and white matter hyperintensity segmentation in several large studies, providing the hippocampus dataset as a publicly available benchmark. By evaluating modern DNNs on these datasets, we demonstrate that they are highly susceptible to distribution shifts and corruptions in MRI. We show that while data augmentation strategies can substantially improve robustness to OOD data for anatomical segmentation tasks, modern DNNs using augmentation still lack robustness in more challenging lesion-based segmentation tasks. We finally benchmark U-Nets and transformer-based models, finding consistent differences in robustness to particular classes of transforms across architectures. ",
    "url": "https://arxiv.org/abs/2203.06060",
    "authors": [
      "Lyndon Boone",
      "Mahdi Biparva",
      "Parisa Mojiri Forooshani",
      "Joel Ramirez",
      "Mario Masellis",
      "Robert Bartha",
      "Sean Symons",
      "Stephen Strother",
      "Sandra E. Black",
      "Chris Heyn",
      "Anne L. Martel",
      "Richard H. Swartz",
      "Maged Goubran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06113",
    "title": "Detection of multiple retinal diseases in ultra-widefield fundus images  using deep learning: data-driven identification of relevant regions",
    "abstract": "Ultra-widefield (UWF) imaging is a promising modality that captures a larger retinal field of view compared to traditional fundus photography. Previous studies showed that deep learning (DL) models are effective for detecting retinal disease in UWF images, but primarily considered individual diseases under less-than-realistic conditions (excluding images with other diseases, artefacts, comorbidities, or borderline cases; and balancing healthy and diseased images) and did not systematically investigate which regions of the UWF images are relevant for disease detection. We first improve on the state of the field by proposing a DL model that can recognise multiple retinal diseases under more realistic conditions. We then use global explainability methods to identify which regions of the UWF images the model generally attends to. Our model performs very well, separating between healthy and diseased retinas with an area under the curve (AUC) of 0.9206 on an internal test set, and an AUC of 0.9841 on a challenging, external test set. When diagnosing specific diseases, the model attends to regions where we would expect those diseases to occur. We further identify the posterior pole as the most important region in a purely data-driven fashion. Surprisingly, 10% of the image around the posterior pole is sufficient for achieving comparable performance to having the full images available. ",
    "url": "https://arxiv.org/abs/2203.06113",
    "authors": [
      "Justin Engelmann",
      "Alice D. McTrusty",
      "Ian J. C. MacCormick",
      "Emma Pead",
      "Amos Storkey",
      "Miguel O. Bernabeu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:1806.09768",
    "title": "Optimal Streaming Erasure Codes over the Three-Node Relay Network",
    "abstract": " Comments: Another researcher pointed out that the upper bound on rate in (21) is incorrect. We found that this is the case and we confirmed that there exists a transmission scheme on a 3-node relay network which achieves a rate strictly higher than our upper bound ",
    "url": "https://arxiv.org/abs/1806.09768",
    "authors": [
      "Silas L. Fong",
      "Ashish Khisti",
      "Baochun Li",
      "Wai-Tian Tan",
      "Xiaoqing Zhu",
      "John Apostolopoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2001.03754",
    "title": "Sparse Black-box Video Attack with Reinforcement Learning",
    "abstract": " Comments: Accepted at IJCV 2022 ",
    "url": "https://arxiv.org/abs/2001.03754",
    "authors": [
      "Xingxing Wei",
      "Huanqian Yan",
      "Bo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2004.09304",
    "title": "From graph cuts to isoperimetric inequalities: Convergence rates of  Cheeger cuts on data clouds",
    "abstract": " Title: From graph cuts to isoperimetric inequalities: Convergence rates of  Cheeger cuts on data clouds ",
    "url": "https://arxiv.org/abs/2004.09304",
    "authors": [
      "Nicolas Garcia Trillos",
      "Ryan Murray",
      "Matthew Thorpe"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.03222",
    "title": "Adaptive Multi-Feature Budgeted Profit Maximization in Social Networks",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2006.03222",
    "authors": [
      "Tiantian Chen",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2009.08811",
    "title": "Disordered complex networks: energy optimal lattices and persistent  homology",
    "abstract": " Title: Disordered complex networks: energy optimal lattices and persistent  homology ",
    "url": "https://arxiv.org/abs/2009.08811",
    "authors": [
      "Subhro Ghosh",
      "Naoto Miyoshi",
      "Tomoyuki Shirai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2011.10797",
    "title": "Adversarial Classification: Necessary conditions and geometric flows",
    "abstract": " Title: Adversarial Classification: Necessary conditions and geometric flows ",
    "url": "https://arxiv.org/abs/2011.10797",
    "authors": [
      "Nicolas Garcia Trillos",
      "Ryan Murray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.05825",
    "title": "Semi-supervised novelty detection using ensembles with regularized  disagreement",
    "abstract": " Title: Semi-supervised novelty detection using ensembles with regularized  disagreement ",
    "url": "https://arxiv.org/abs/2012.05825",
    "authors": [
      "Alexandru \u0162ifrea",
      "Eric Stavarache",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.09302",
    "title": "TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural  Backdoors",
    "abstract": " Comments: Accepted as a full paper at EuroS&P 2022 ",
    "url": "https://arxiv.org/abs/2012.09302",
    "authors": [
      "Ren Pang",
      "Zheng Zhang",
      "Xiangshan Gao",
      "Zhaohan Xi",
      "Shouling Ji",
      "Peng Cheng",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.04736",
    "title": "Content-Aware Detection of Temporal Metadata Manipulation",
    "abstract": " Title: Content-Aware Detection of Temporal Metadata Manipulation ",
    "url": "https://arxiv.org/abs/2103.04736",
    "authors": [
      "Rafael Padilha",
      "Tawfiq Salem",
      "Scott Workman",
      "Fernanda A. Andal\u00f3",
      "Anderson Rocha",
      "Nathan Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.01989",
    "title": "Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker  Recognition",
    "abstract": " Comments: Interspeech 2021 ",
    "url": "https://arxiv.org/abs/2104.01989",
    "authors": [
      "Jason Pelecanos",
      "Quan Wang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.08840",
    "title": "Training Heterogeneous Features in Sequence to Sequence Tasks: Latent  Enhanced Multi-filter Seq2Seq Model",
    "abstract": " Comments: Accepted to Intelligent Systems Conference 2022 ",
    "url": "https://arxiv.org/abs/2105.08840",
    "authors": [
      "Yunhao Yang",
      "Zhaokun Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.13240",
    "title": "Local Latent Representation based on Geometric Convolution for Particle  Data Feature Exploration",
    "abstract": " Title: Local Latent Representation based on Geometric Convolution for Particle  Data Feature Exploration ",
    "url": "https://arxiv.org/abs/2105.13240",
    "authors": [
      "Haoyu Li",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.09117",
    "title": "DeepSplit: Scalable Verification of Deep Neural Networks via Operator  Splitting",
    "abstract": " Title: DeepSplit: Scalable Verification of Deep Neural Networks via Operator  Splitting ",
    "url": "https://arxiv.org/abs/2106.09117",
    "authors": [
      "Shaoru Chen",
      "Eric Wong",
      "J. Zico Kolter",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.03605",
    "title": "PNC Enabled IIoT: A General Framework for Channel-Coded Asymmetric  Physical-Layer Network Coding",
    "abstract": " Comments: Under major revision ",
    "url": "https://arxiv.org/abs/2107.03605",
    "authors": [
      "Zhaorui Wang",
      "Ling Liu",
      "Shengli Zhang",
      "Pengpeng Dong",
      "Qing Yang",
      "Taotao Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2107.06696",
    "title": "Social nucleation: Group formation as a phase transition",
    "abstract": " Title: Social nucleation: Group formation as a phase transition ",
    "url": "https://arxiv.org/abs/2107.06696",
    "authors": [
      "Frank Schweitzer",
      "Georges Andres"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2107.10043",
    "title": "KalmanNet: Neural Network Aided Kalman Filtering for Partially Known  Dynamics",
    "abstract": " Comments: Accepted for publication in IEEE Transactions on Signal Processing - TSP ",
    "url": "https://arxiv.org/abs/2107.10043",
    "authors": [
      "Guy Revach",
      "Nir Shlezinger",
      "Xiaoyong Ni",
      "Adria Lopez Escoriza",
      "Ruud J. G. van Sloun",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.13279",
    "title": "Pseudo-LiDAR Based Road Detection",
    "abstract": " Comments: 13 pages, 11 figures. This paper has been accepted by TCSVT. IEEE Trans. Circuit Syst.Video Technol. 2022 ",
    "url": "https://arxiv.org/abs/2107.13279",
    "authors": [
      "Libo Sun",
      "Haokui Zhang",
      "Wei Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.02165",
    "title": "FBDNN: Filter Banks and Deep Neural Networks for Portable and Fast  Brain-Computer Interfaces",
    "abstract": " Comments: We included tests in additional datasets to further support our proposal ",
    "url": "https://arxiv.org/abs/2109.02165",
    "authors": [
      "Pedro R. A. S. Bassi",
      "Romis Attux"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.06148",
    "title": "DAFNe: A One-Stage Anchor-Free Approach for Oriented Object Detection",
    "abstract": " Comments: Main paper: 14 pages, References: 4 pages, Appendix: 8 pages; Main paper: 6 figures, Appendix: 6 figures ",
    "url": "https://arxiv.org/abs/2109.06148",
    "authors": [
      "Steven Lang",
      "Fabrizio Ventola",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.12855",
    "title": "Routing brain traffic through the von Neumann bottleneck: Efficient  cache usage in spiking neural network simulation code on general purpose  computers",
    "abstract": " Title: Routing brain traffic through the von Neumann bottleneck: Efficient  cache usage in spiking neural network simulation code on general purpose  computers ",
    "url": "https://arxiv.org/abs/2109.12855",
    "authors": [
      "Jari Pronold",
      "Jakob Jordan",
      "Brian J. N. Wylie",
      "Itaru Kitayama",
      "Markus Diesmann",
      "Susanne Kunkel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2110.00843",
    "title": "SHARP: Shielding-Aware Robust Planning for Safe and Efficient  Human-Robot Interaction",
    "abstract": " Title: SHARP: Shielding-Aware Robust Planning for Safe and Efficient  Human-Robot Interaction ",
    "url": "https://arxiv.org/abs/2110.00843",
    "authors": [
      "Haimin Hu",
      "Kensuke Nakamura",
      "Jaime F. Fisac"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2110.01775",
    "title": "Deep Instance Segmentation with Automotive Radar Detection Points",
    "abstract": " Title: Deep Instance Segmentation with Automotive Radar Detection Points ",
    "url": "https://arxiv.org/abs/2110.01775",
    "authors": [
      "Jianan Liu",
      "Weiyi Xiong",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Wanli Ouyang",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.08934",
    "title": "On the Effect of Selfie Beautification Filters on Face Detection and  Recognition",
    "abstract": " Comments: Under consideration at Pattern Recognition Letters ",
    "url": "https://arxiv.org/abs/2110.08934",
    "authors": [
      "Pontus Hedman",
      "Vasilios Skepetzis",
      "Kevin Hernandez-Diaz",
      "Josef Bigun",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.09581",
    "title": "Improving GNSS Positioning using Neural Network-based Corrections",
    "abstract": " Comments: 15 pages, 8 figures, submitted to Navigation ",
    "url": "https://arxiv.org/abs/2110.09581",
    "authors": [
      "Ashwin V. Kanhere",
      "Shubh Gupta",
      "Akshay Shetty",
      "Grace Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2111.00064",
    "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood  Prediction",
    "abstract": " Comments: Published in ICLR 2022 ",
    "url": "https://arxiv.org/abs/2111.00064",
    "authors": [
      "Eli Chien",
      "Wei-Cheng Chang",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu",
      "Jiong Zhang",
      "Olgica Milenkovic",
      "Inderjit S Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03199",
    "title": "Concurrent multiscale analysis without meshing: Microscale  representation with CutFEM and micro/macro model blending",
    "abstract": " Title: Concurrent multiscale analysis without meshing: Microscale  representation with CutFEM and micro/macro model blending ",
    "url": "https://arxiv.org/abs/2111.03199",
    "authors": [
      "Ehsan Mikaeili",
      "Susanne Claus",
      "Pierre Kerfriden"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2111.04332",
    "title": "Succinct Data Structure for Path Graphs",
    "abstract": " Comments: 19 pages, 1 figure, 5 sections ",
    "url": "https://arxiv.org/abs/2111.04332",
    "authors": [
      "Girish Balakrishnan",
      "Sankardeep Chakraborty",
      "N S Narayanaswamy",
      "Kunihiko Sadakane"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.13868",
    "title": "Spine-like Joint Link Mechanism to Design Wearable Assistive Devices  with Comfort and Support",
    "abstract": " Comments: The experiment parts in Sec IV.A and IV.B need to be improved. The author would like to restructure the manuscript and perform major revision ",
    "url": "https://arxiv.org/abs/2111.13868",
    "authors": [
      "Jungyeong Kim",
      "Jungsan Cho",
      "Jinhyeon Kim",
      "Jin Tak Kim",
      "Sangchul Han",
      "Sangshin Park",
      "Han Ul Yoon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.00544",
    "title": "Molecular Contrastive Learning with Chemical Element Knowledge Graph",
    "abstract": " Comments: Accepted in AAAI 2022 Main track ",
    "url": "https://arxiv.org/abs/2112.00544",
    "authors": [
      "Yin Fang",
      "Qiang Zhang",
      "Haihong Yang",
      "Xiang Zhuang",
      "Shumin Deng",
      "Wen Zhang",
      "Ming Qin",
      "Zhuo Chen",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2112.00970",
    "title": "Narrative Cartography with Knowledge Graphs",
    "abstract": " Comments: 33 pages, 5 figures, Accepted to Journal of Geovisualization and Spatial Analysis ",
    "url": "https://arxiv.org/abs/2112.00970",
    "authors": [
      "Gengchen Mai",
      "Weiming Huang",
      "Ling Cai",
      "Rui Zhu",
      "Ni Lao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2112.08184",
    "title": "Interactive Visualization and Representation Analysis Applied to Glacier  Segmentation",
    "abstract": " Comments: 10 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2112.08184",
    "authors": [
      "Minxing Zheng",
      "Xinran Miao",
      "Kris Sankaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.10184",
    "title": "A Deep Learning Based Workflow for Detection of Lung Nodules With Chest  Radiograph",
    "abstract": " Title: A Deep Learning Based Workflow for Detection of Lung Nodules With Chest  Radiograph ",
    "url": "https://arxiv.org/abs/2112.10184",
    "authors": [
      "Yang Tai",
      "Yu-Wen Fang",
      "Fang-Yi Su",
      "Jung-Hsien Chiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01501",
    "title": "Rethinking Depth Estimation for Multi-View Stereo: A Unified  Representation",
    "abstract": " Comments: CVPR 2022 Accepted ",
    "url": "https://arxiv.org/abs/2201.01501",
    "authors": [
      "Rui Peng",
      "Rongjie Wang",
      "Zhenyu Wang",
      "Yawen Lai",
      "Ronggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.05057",
    "title": "On Adversarial Robustness of Trajectory Prediction for Autonomous  Vehicles",
    "abstract": " Comments: 13 pages, 13 figures, accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2201.05057",
    "authors": [
      "Qingzhao Zhang",
      "Shengtuo Hu",
      "Jiachen Sun",
      "Qi Alfred Chen",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.11628",
    "title": "Early Detection of Network Attacks Using Deep Learning",
    "abstract": " Comments: Submitted to ITEQS 2022 Workshop ",
    "url": "https://arxiv.org/abs/2201.11628",
    "authors": [
      "Tanwir Ahmad",
      "Dragos Truscan",
      "Juri Vain",
      "Ivan Porres"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2202.04595",
    "title": "Exploring Structural Sparsity in Neural Image Compression",
    "abstract": " Comments: 6 pages, 5 figures, submitted to ICIP 2022 ",
    "url": "https://arxiv.org/abs/2202.04595",
    "authors": [
      "Shanzhi Yin",
      "Chao Li",
      "Wen Tan",
      "Youneng Bao",
      "Yongsheng Liang",
      "Wei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09400",
    "title": "Equivariant Transporter Network",
    "abstract": " Title: Equivariant Transporter Network ",
    "url": "https://arxiv.org/abs/2202.09400",
    "authors": [
      "Haojie Huang",
      "Dian Wang",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.03093",
    "title": "Derivative-Free Placement Optimization for Multi-UAV Wireless Networks  with Channel Knowledge Map",
    "abstract": " Title: Derivative-Free Placement Optimization for Multi-UAV Wireless Networks  with Channel Knowledge Map ",
    "url": "https://arxiv.org/abs/2203.03093",
    "authors": [
      "Haoyun Li",
      "Peiming Li",
      "Jie Xu",
      "Junting Chen",
      "Yong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.04708",
    "title": "A Unified Transformer Framework for Group-based Segmentation:  Co-Segmentation, Co-Saliency Detection and Video Salient Object Detection",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.04708",
    "authors": [
      "Yukun Su",
      "Jingliang Deng",
      "Ruizhou Sun",
      "Guosheng Lin",
      "Qingyao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05248",
    "title": "Look Backward and Forward: Self-Knowledge Distillation with  Bidirectional Decoder for Neural Machine Translation",
    "abstract": " Title: Look Backward and Forward: Self-Knowledge Distillation with  Bidirectional Decoder for Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2203.05248",
    "authors": [
      "Xuanwei Zhang",
      "Libin Shen",
      "Disheng Pan",
      "Liang Wang",
      "Yanjun Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.05337",
    "title": "Parsimonious Physics-Informed Random Projection Neural Networks for  Initial-Value Problems of ODEs and index-1 DAEs",
    "abstract": " Title: Parsimonious Physics-Informed Random Projection Neural Networks for  Initial-Value Problems of ODEs and index-1 DAEs ",
    "url": "https://arxiv.org/abs/2203.05337",
    "authors": [
      "Gianluca Fabiani",
      "Evangelos Galaris",
      "Lucia Russo",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2203.05534",
    "title": "AGCN: Augmented Graph Convolutional Network for Lifelong Multi-label  Image Recognition",
    "abstract": " Comments: Accpted in ICME 2022 ",
    "url": "https://arxiv.org/abs/2203.05534",
    "authors": [
      "Kaile Du",
      "Fan Lyu",
      "Fuyuan Hu",
      "Linyan Li",
      "Wei Feng",
      "Fenglei Xu",
      "Qiming Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]