[
  {
    "id": "arXiv:2203.10093",
    "title": "Deep Reinforcement Learning Guided Graph Neural Networks for Brain  Network Analysis",
    "abstract": "Modern neuroimaging techniques, such as diffusion tensor imaging (DTI) and functional magnetic resonance imaging (fMRI), enable us to model the human brain as a brain network or connectome. Capturing brain networks' structural information and hierarchical patterns is essential for understanding brain functions and disease states. Recently, the promising network representation learning capability of graph neural networks (GNNs) has prompted many GNN-based methods for brain network analysis to be proposed. Specifically, these methods apply feature aggregation and global pooling to convert brain network instances into meaningful low-dimensional representations used for downstream brain network analysis tasks. However, existing GNN-based methods often neglect that brain networks of different subjects may require various aggregation iterations and use GNN with a fixed number of layers to learn all brain networks. Therefore, how to fully release the potential of GNNs to promote brain network analysis is still non-trivial. To solve this problem, we propose a novel brain network representation framework, namely BN-GNN, which searches for the optimal GNN architecture for each brain network. Concretely, BN-GNN employs deep reinforcement learning (DRL) to train a meta-policy to automatically determine the optimal number of feature aggregations (reflected in the number of GNN layers) required for a given brain network. Extensive experiments on eight real-world brain network datasets demonstrate that our proposed BN-GNN improves the performance of traditional GNNs on different brain network analysis tasks. ",
    "url": "https://arxiv.org/abs/2203.10093",
    "authors": [
      "Xusheng Zhao",
      "Jia Wu",
      "Hao Peng",
      "Amin Beheshti",
      "Jessica Monaghan",
      "David McAlpine",
      "Heivet Hernandez-Perez",
      "Mark Dras",
      "Qiong Dai",
      "Yangyang Li",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2203.10145",
    "title": "Improving Heuristic-based Process Discovery Methods by Detecting Optimal  Dependency Graphs",
    "abstract": "Heuristic-based methods are among the most popular methods in the process discovery area. This category of methods is composed of two main steps: 1) discovering a dependency graph 2) determining the split/join patterns of the dependency graph. The current dependency graph discovery techniques of heuristic-based methods select the initial set of graph arcs according to dependency measures and then modify the set regarding some criteria. This can lead to selecting the non-optimal set of arcs. Also, the modifications can result in modeling rare behaviors and, consequently, low precision and non-simple process models. Thus, constructing dependency graphs through selecting the optimal set of arcs has a high potential for improving graphs quality. Hence, this paper proposes a new integer linear programming model that determines the optimal set of graph arcs regarding dependency measures. Simultaneously, the proposed method can eliminate some other issues that the existing methods cannot handle completely; i.e., even in the presence of loops, it guarantees that all tasks are on a path from the initial to the final tasks. This approach also allows utilizing domain knowledge by introducing appropriate constraints, which can be a practical advantage in real-world problems. To assess the results, we modified two existing methods of evaluating process models to make them capable of measuring the quality of dependency graphs. According to assessments, the outputs of the proposed method are superior to the outputs of the most prominent dependency graph discovery methods in terms of fitness, precision, and especially simplicity. ",
    "url": "https://arxiv.org/abs/2203.10145",
    "authors": [
      "Maryam Tavakoli-Zaniani",
      "Mohammad Reza Gholamian",
      "S. Alireza Hashemi Golpayegani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10155",
    "title": "Subreddit Links Drive Community Creation and User Engagement on Reddit",
    "abstract": "On Reddit, individual subreddits are used to organize content and connect users. One mode of interaction is the subreddit link, which occurs when a user makes a direct reference to a subreddit in another community. Based on the ubiquity of these references, we have undertaken a study on subreddit links on Reddit, with the goal of understanding their impact on both the referenced subreddit, and on the subreddit landscape as a whole. By way of an extensive observational study along with several natural experiments using the entire history of Reddit, we were able to determine that (1) subreddit links are a significant driver of new suberddit creation; (2) subreddit links (2a) substantially drive activity in the referenced subreddit, and (2b) are frequently created in response to high levels of activity in the referenced subreddit; and (3) the graph of subreddit links has become less dense and more treelike over time. We conclude with a discussion of how these results confirm, add to, and in some cases conflict with existing theories on information-seeking behavior and self-organizing behavior in online social systems. ",
    "url": "https://arxiv.org/abs/2203.10155",
    "authors": [
      "Rachel Krohn",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.10157",
    "title": "ViewFormer: NeRF-free Neural Rendering from Few Images Using  Transformers",
    "abstract": "Novel view synthesis is a long-standing problem. In this work, we consider a variant of the problem where we are given only a few context views sparsely covering a scene or an object. The goal is to predict novel viewpoints in the scene, which requires learning priors. The current state of the art is based on Neural Radiance Fields (NeRFs), and while achieving impressive results, the methods suffer from long training times as they require evaluating thousands of 3D point samples via a deep neural network for each image. We propose a 2D-only method that maps multiple context views and a query pose to a new image in a single pass of a neural network. Our model uses a two-stage architecture consisting of a codebook and a transformer model. The codebook is used to embed individual images into a smaller latent space, and the transformer solves the view synthesis task in this more compact space. To train our model efficiently, we introduce a novel branching attention mechanism that allows us to use the same model not only for neural rendering but also for camera pose estimation. Experimental results on real-world scenes show that our approach is competitive compared to NeRF-based methods while not reasoning in 3D, and it is faster to train. ",
    "url": "https://arxiv.org/abs/2203.10157",
    "authors": [
      "Jon\u00e1\u0161 Kulh\u00e1nek",
      "Erik Derner",
      "Torsten Sattler",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10158",
    "title": "Botnets Breaking Transformers: Localization of Power Botnet Attacks  Against the Distribution Grid",
    "abstract": "Traditional botnet attacks leverage large and distributed numbers of compromised internet-connected devices to target and overwhelm other devices with internet packets. With increasing consumer adoption of high-wattage internet-facing \"smart devices\", a new \"power botnet\" attack emerges, where such devices are used to target and overwhelm power grid devices with unusual load demand. We introduce a variant of this attack, the power-botnet weardown-attack, which does not intend to cause blackouts or short-term acute instability, but instead forces expensive mechanical components to activate more frequently, necessitating costly replacements / repairs. Specifically, we target the on-load tap-changer (OLTC) transformer, which uses a mechanical switch that responds to change in load demand. In our analysis and simulations, these attacks can halve the lifespan of an OLTC, or in the most extreme cases, reduce it to $2.5\\%$ of its original lifespan. Notably, these power botnets are composed of devices not connected to the internal SCADA systems used to control power grids. This represents a new internet-based cyberattack that targets the power grid from the outside. To help the power system to mitigate these types of botnet attacks, we develop attack-localization strategies. We formulate the problem as a supervised machine learning task to locate the source of power botnet attacks. Within a simulated environment, we generate the training and testing dataset to evaluate several machine learning algorithm based localization methods, including SVM, neural network and decision tree. We show that decision-tree based classification successfully identifies power botnet attacks and locates compromised devices with at least $94\\%$ improvement of accuracy over a baseline \"most-frequent\" classifier. ",
    "url": "https://arxiv.org/abs/2203.10158",
    "authors": [
      "Lynn Pepin",
      "Lizhi Wang",
      "Jiangwei Wang",
      "Songyang Han",
      "Pranav Pishawikar",
      "Amir Herzberg",
      "Peng Zhang",
      "Fei Miao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10166",
    "title": "Concept-based Adversarial Attacks: Tricking Humans and Classifiers Alike",
    "abstract": "We propose to generate adversarial samples by modifying activations of upper layers encoding semantically meaningful concepts. The original sample is shifted towards a target sample, yielding an adversarial sample, by using the modified activations to reconstruct the original sample. A human might (and possibly should) notice differences between the original and the adversarial sample. Depending on the attacker-provided constraints, an adversarial sample can exhibit subtle differences or appear like a \"forged\" sample from another class. Our approach and goal are in stark contrast to common attacks involving perturbations of single pixels that are not recognizable by humans. Our approach is relevant in, e.g., multi-stage processing of inputs, where both humans and machines are involved in decision-making because invisible perturbations will not fool a human. Our evaluation focuses on deep neural networks. We also show the transferability of our adversarial examples among networks. ",
    "url": "https://arxiv.org/abs/2203.10166",
    "authors": [
      "Johannes Schneider",
      "Giovanni Apruzzese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10183",
    "title": "Adversarial Attacks on Deep Learning-based Video Compression and  Classification Systems",
    "abstract": "Video compression plays a crucial role in enabling video streaming and classification systems and maximizing the end-user quality of experience (QoE) at a given bandwidth budget. In this paper, we conduct the first systematic study for adversarial attacks on deep learning based video compression and downstream classification systems. We propose an adaptive adversarial attack that can manipulate the Rate-Distortion (R-D) relationship of a video compression model to achieve two adversarial goals: (1) increasing the network bandwidth or (2) degrading the video quality for end-users. We further devise novel objectives for targeted and untargeted attacks to a downstream video classification service. Finally, we design an input-invariant perturbation that universally disrupts video compression and classification systems in real time. Unlike previously proposed attacks on video classification, our adversarial perturbations are the first to withstand compression. We empirically show the resilience of our attacks against various defenses, i.e., adversarial training, video denoising, and JPEG compression. Our extensive experimental results on various video datasets demonstrate the effectiveness of our attacks. Our video quality and bandwidth attacks deteriorate peak signal-to-noise ratio by up to 5.4dB and the bit-rate by up to 2.4 times on the standard video compression datasets while achieving over 90% attack success rate on a downstream classifier. ",
    "url": "https://arxiv.org/abs/2203.10183",
    "authors": [
      "Jung-Woo Chang",
      "Mojan Javaheripi",
      "Seira Hidano",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10188",
    "title": "Trackers Bounce Back: Measuring Evasion of Partitioned Storage in the  Wild",
    "abstract": "This work presents a systematic study of navigational tracking, the latest development in the cat-and-mouse game between browsers and online trackers. Navigational tracking allows trackers to 'aggregate users' activities and behaviors across sites by modifying their navigation requests. This technique is particularly important because it circumvents the increasing efforts by browsers to partition or block third-party storage, which was previously necessary for most cross-website tracking. While previous work has studied specific navigational tracking techniques (i.e. \"bounce tracking\"), our work is the first effort to systematically study and measure the entire category of navigational tracking techniques. We describe and measure the frequency of two different navigational tracking techniques on the Web, and find that navigational tracking is present on slightly more than ten percent of all navigations that we made. Our contributions include identifying 214 domains belonging to at least 104 organizations tracking users across sites through link decoration techniques using direct or indirect navigation flows. We identify a further 23 domains belonging to at least 16 organizations tracking users through bounce tracking (i.e. bouncing users through unrelated third parties to generate user profiles). We also improve on prior techniques for differenting user identifiers from non-sensitive information, which is necessary to detect one class of navigational tracking. We discuss how our findings can used to protect users from navigational tracking, and commit to releasing both our complete dataset and our measurement pipeline ",
    "url": "https://arxiv.org/abs/2203.10188",
    "authors": [
      "Audrey Randall",
      "Peter Snyder",
      "Alisha Ukani",
      "Alex Snoeren",
      "Geoff Voelker",
      "Stefan Savage",
      "Aaron Schulman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10194",
    "title": "Analysis and Adaptation of YOLOv4 for Object Detection in Aerial Images",
    "abstract": "The recent and rapid growth in Unmanned Aerial Vehicles (UAVs) deployment for various computer vision tasks has paved the path for numerous opportunities to make them more effective and valuable. Object detection in aerial images is challenging due to variations in appearance, pose, and scale. Autonomous aerial flight systems with their inherited limited memory and computational power demand accurate and computationally efficient detection algorithms for real-time applications. Our work shows the adaptation of the popular YOLOv4 framework for predicting the objects and their locations in aerial images with high accuracy and inference speed. We utilized transfer learning for faster convergence of the model on the VisDrone DET aerial object detection dataset. The trained model resulted in a mean average precision (mAP) of 45.64% with an inference speed reaching 8.7 FPS on the Tesla K80 GPU and was highly accurate in detecting truncated and occluded objects. We experimentally evaluated the impact of varying network resolution sizes and training epochs on the performance. A comparative study with several contemporary aerial object detectors proved that YOLOv4 performed better, implying a more suitable detection algorithm to incorporate on aerial platforms. ",
    "url": "https://arxiv.org/abs/2203.10194",
    "authors": [
      "Aryaman Singh Samyal",
      "Akshatha K R",
      "Soham Hans",
      "Karunakar A K",
      "Satish Shenoy B"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.10197",
    "title": "Cost Function Learning in Memorized Social Networks with Cognitive  Behavioral Asymmetry",
    "abstract": "This paper investigates the cost function learning in social information networks, wherein the influence of humans' memory on information consumption is explicitly taken into account. We first propose a model for social information-diffusion dynamics with a focus on systematic modeling of asymmetric cognitive bias, represented by confirmation bias and novelty bias. Building on the proposed social model, we then propose the M$^{3}$IRL: a model and maximum-entropy based inverse reinforcement learning framework for learning the cost functions of target individuals in the memorized social networks. Compared with the existing Bayesian IRL, maximum entropy IRL, relative entropy IRL and maximum causal entropy IRL, the characteristics of M$^{3}$IRL are significantly different here: no dependency on the Markov Decision Process principle, the need of only a single finite-time trajectory sample, and bounded decision variables. Finally, the effectiveness of the proposed social information-diffusion model and the M$^{3}$IRL algorithm are validated by the online social media data. ",
    "url": "https://arxiv.org/abs/2203.10197",
    "authors": [
      "Yanbing Mao",
      "Jining Li",
      "Naira Hovakimyan",
      "Tarek Abdelzaher",
      "Christian Lebiere"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.10209",
    "title": "SwinTextSpotter: Scene Text Spotting via Better Synergy between Text  Detection and Text Recognition",
    "abstract": "End-to-end scene text spotting has attracted great attention in recent years due to the success of excavating the intrinsic synergy of the scene text detection and recognition. However, recent state-of-the-art methods usually incorporate detection and recognition simply by sharing the backbone, which does not directly take advantage of the feature interaction between the two tasks. In this paper, we propose a new end-to-end scene text spotting framework termed SwinTextSpotter. Using a transformer encoder with dynamic head as the detector, we unify the two tasks with a novel Recognition Conversion mechanism to explicitly guide text localization through recognition loss. The straightforward design results in a concise framework that requires neither additional rectification module nor character-level annotation for the arbitrarily-shaped text. Qualitative and quantitative experiments on multi-oriented datasets RoIC13 and ICDAR 2015, arbitrarily-shaped datasets Total-Text and CTW1500, and multi-lingual datasets ReCTS (Chinese) and VinText (Vietnamese) demonstrate SwinTextSpotter significantly outperforms existing methods. Code is available at https://github.com/mxin262/SwinTextSpotter. ",
    "url": "https://arxiv.org/abs/2203.10209",
    "authors": [
      "Mingxin Huang",
      "Yuliang Liu",
      "Zhenghao Peng",
      "Chongyu Liu",
      "Dahua Lin",
      "Shenggao Zhu",
      "Nicholas Yuan",
      "Kai Ding",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10228",
    "title": "A Track-Wise Ensemble Event Independent Network for Polyphonic Sound  Event Localization and Detection",
    "abstract": "Polyphonic sound event localization and detection (SELD) aims at detecting types of sound events with corresponding temporal activities and spatial locations. In this paper, a track-wise ensemble event independent network with a novel data augmentation method is proposed. The proposed model is based on our previous proposed Event-Independent Network V2 and is extended by conformer blocks and dense blocks. The track-wise ensemble model with track-wise output format is proposed to solve an ensemble model problem for track-wise output format that track permutation may occur among different models. The data augmentation approach contains several data augmentation chains, which are composed of random combinations of several data augmentation operations. The method also utilizes log-mel spectrograms, intensity vectors, and Spatial Cues-Augmented Log-Spectrogram (SALSA) for different models. We evaluate our proposed method in the Task of the L3DAS22 challenge and obtain the top ranking solution with a location-dependent F-score to be 0.699. Source code is released. ",
    "url": "https://arxiv.org/abs/2203.10228",
    "authors": [
      "Jinbo Hu",
      "Yin Cao",
      "Ming Wu",
      "Qiuqiang Kong",
      "Feiran Yang",
      "Mark D. Plumbley",
      "Jun Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.10233",
    "title": "DirecFormer: A Directed Attention in Transformer Approach to Robust  Action Recognition",
    "abstract": "Human action recognition has recently become one of the popular research topics in the computer vision community. Various 3D-CNN based methods have been presented to tackle both the spatial and temporal dimensions in the task of video action recognition with competitive results. However, these methods have suffered some fundamental limitations such as lack of robustness and generalization, e.g., how does the temporal ordering of video frames affect the recognition results? This work presents a novel end-to-end Transformer-based Directed Attention (DirecFormer) framework for robust action recognition. The method takes a simple but novel perspective of Transformer-based approach to understand the right order of sequence actions. Therefore, the contributions of this work are three-fold. Firstly, we introduce the problem of ordered temporal learning issues to the action recognition problem. Secondly, a new Directed Attention mechanism is introduced to understand and provide attentions to human actions in the right order. Thirdly, we introduce the conditional dependency in action sequence modeling that includes orders and classes. The proposed approach consistently achieves the state-of-the-art (SOTA) results compared with the recent action recognition methods, on three standard large-scale benchmarks, i.e. Jester, Kinetics-400 and Something-Something-V2. ",
    "url": "https://arxiv.org/abs/2203.10233",
    "authors": [
      "Thanh-Dat Truong",
      "Quoc-Huy Bui",
      "Chi Nhan Duong",
      "Han-Seok Seo",
      "Son Lam Phung",
      "Xin Li",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10238",
    "title": "On the entropy projection and the robustness of high order entropy  stable discontinuous Galerkin schemes for under-resolved flows",
    "abstract": "High order entropy stable schemes provide improved robustness for computational simulations of fluid flows. However, additional stabilization and positivity preserving limiting can still be required for variable-density flows with under-resolved features. We demonstrate numerically that entropy stable DG methods which incorporate an \"entropy projection\" are less likely to require additional limiting to retain positivity for certain types of flows. We conclude by investigating potential explanations for this observed improvement in robustness. ",
    "url": "https://arxiv.org/abs/2203.10238",
    "authors": [
      "Jesse Chan",
      "Hendrik Ranocha",
      "Andres Rueda-Ramirez",
      "Gregor Gassner",
      "Tim Warburton"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.10258",
    "title": "Doubly Robust Collaborative Targeted Learning for Recommendation on Data  Missing Not at Random",
    "abstract": "In recommender systems, the feedback data received is always missing not at random (MNAR), which poses challenges for accurate rating prediction. To address this issue, many recent studies have been conducted on the doubly robust (DR) method and its variants to reduce bias. However, theoretical analysis shows that the DR method has a relatively large variance, while that of the error imputation-based (EIB) method is smaller. In this paper, we propose {\\bf DR-TMLE} that effectively captures the merits of both EIB and DR, by leveraging the targeted maximum likelihood estimation (TMLE) technique. DR-TMLE first obtains an initial EIB estimator and then updates the error imputation model along with the bias-reduced direction. Furthermore, we propose a novel RCT-free collaborative targeted learning algorithm for DR-TMLE, called {\\bf DR-TMLE-TL}, which updates the propensity model adaptively to reduce the bias of imputed errors. Both theoretical analysis and experiments demonstrate the advantages of the proposed methods compared with existing debiasing methods. ",
    "url": "https://arxiv.org/abs/2203.10258",
    "authors": [
      "Peng Wu",
      "Haoxuan Li",
      "Yan Lyu",
      "Xiao-Hua Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.10261",
    "title": "FaiRR: Faithful and Robust Deductive Reasoning over Natural Language",
    "abstract": "Transformers have been shown to be able to perform deductive reasoning on a logical rulebase containing rules and statements written in natural language. Recent works show that such models can also produce the reasoning steps (i.e., the proof graph) that emulate the model's logical reasoning process. Currently, these black-box models generate both the proof graph and intermediate inferences within the same model and thus may be unfaithful. In this work, we frame the deductive logical reasoning task by defining three modular components: rule selection, fact selection, and knowledge composition. The rule and fact selection steps select the candidate rule and facts to be used and then the knowledge composition combines them to generate new inferences. This ensures model faithfulness by assured causal relation from the proof step to the inference reasoning. To test our framework, we propose FaiRR (Faithful and Robust Reasoner) where the above three components are independently modeled by transformers. We observe that FaiRR is robust to novel language perturbations, and is faster at inference than previous works on existing reasoning datasets. Additionally, in contrast to black-box generative models, the errors made by FaiRR are more interpretable due to the modular approach. ",
    "url": "https://arxiv.org/abs/2203.10261",
    "authors": [
      "Soumya Sanyal",
      "Harman Singh",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10276",
    "title": "Epidemic Propagation under Evolutionary Behavioral Dynamics: Stability  and Bifurcation Analysis",
    "abstract": "We consider the class of SIS epidemic models in which a large population of individuals chooses whether to adopt protection or to remain unprotected as the epidemic evolves. For a susceptible individual, adopting protection reduces the probability of becoming infected but it comes with a cost that is weighed with the instantaneous risk of becoming infected. An infected individual adopting protection transmits a new infection with a smaller probability compared to an unprotected infected individual. We focus on the replicator evolutionary dynamics to model the evolution of protection decisions by susceptible and infected subpopulations. We completely characterize the existence and local stability of the equilibria of the resulting coupled epidemic and replicator dynamics. We further show how the stability of different equilibrium points gets exchanged as certain parameters change. Finally, we investigate the system behavior under timescale separation between the epidemic and the evolutionary dynamics. ",
    "url": "https://arxiv.org/abs/2203.10276",
    "authors": [
      "Abhisek Satapathi",
      "Narendra Kumar Dhar",
      "Ashish R. Hota",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.10278",
    "title": "Learning Self-Supervised Low-Rank Network for Single-Stage Weakly and  Semi-Supervised Semantic Segmentation",
    "abstract": "Semantic segmentation with limited annotations, such as weakly supervised semantic segmentation (WSSS) and semi-supervised semantic segmentation (SSSS), is a challenging task that has attracted much attention recently. Most leading WSSS methods employ a sophisticated multi-stage training strategy to estimate pseudo-labels as precise as possible, but they suffer from high model complexity. In contrast, there exists another research line that trains a single network with image-level labels in one training cycle. However, such a single-stage strategy often performs poorly because of the compounding effect caused by inaccurate pseudo-label estimation. To address this issue, this paper presents a Self-supervised Low-Rank Network (SLRNet) for single-stage WSSS and SSSS. The SLRNet uses cross-view self-supervision, that is, it simultaneously predicts several complementary attentive LR representations from different views of an image to learn precise pseudo-labels. Specifically, we reformulate the LR representation learning as a collective matrix factorization problem and optimize it jointly with the network learning in an end-to-end manner. The resulting LR representation deprecates noisy information while capturing stable semantics across different views, making it robust to the input variations, thereby reducing overfitting to self-supervision errors. The SLRNet can provide a unified single-stage framework for various label-efficient semantic segmentation settings: 1) WSSS with image-level labeled data, 2) SSSS with a few pixel-level labeled data, and 3) SSSS with a few pixel-level labeled data and many image-level labeled data. Extensive experiments on the Pascal VOC 2012, COCO, and L2ID datasets demonstrate that our SLRNet outperforms both state-of-the-art WSSS and SSSS methods with a variety of different settings, proving its good generalizability and efficacy. ",
    "url": "https://arxiv.org/abs/2203.10278",
    "authors": [
      "Junwen Pan",
      "Pengfei Zhu",
      "Kaihua Zhang",
      "Bing Cao",
      "Yu Wang",
      "Dingwen Zhang",
      "Junwei Han",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10280",
    "title": "Meta-Weight Graph Neural Network: Push the Limits Beyond Global  Homophily",
    "abstract": "Graph Neural Networks (GNNs) show strong expressive power on graph data mining, by aggregating information from neighbors and using the integrated representation in the downstream tasks. The same aggregation methods and parameters for each node in a graph are used to enable the GNNs to utilize the homophily relational data. However, not all graphs are homophilic, even in the same graph, the distributions may vary significantly. Using the same convolution over all nodes may lead to the ignorance of various graph patterns. Furthermore, many existing GNNs integrate node features and structure identically, which ignores the distributions of nodes and further limits the expressive power of GNNs. To solve these problems, we propose Meta Weight Graph Neural Network (MWGNN) to adaptively construct graph convolution layers for different nodes. First, we model the Node Local Distribution (NLD) from node feature, topological structure and positional identity aspects with the Meta-Weight. Then, based on the Meta-Weight, we generate the adaptive graph convolutions to perform a node-specific weighted aggregation and boost the node representations. Finally, we design extensive experiments on real-world and synthetic benchmarks to evaluate the effectiveness of MWGNN. These experiments show the excellent expressive power of MWGNN in dealing with graph data with various distributions. ",
    "url": "https://arxiv.org/abs/2203.10280",
    "authors": [
      "Xiaojun Ma",
      "Qin Chen",
      "Yuanyi Ren",
      "Guojie Song",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.10290",
    "title": "Adversarial Defense via Image Denoising with Chaotic Encryption",
    "abstract": "In the literature on adversarial examples, white box and black box attacks have received the most attention. The adversary is assumed to have either full (white) or no (black) access to the defender's model. In this work, we focus on the equally practical gray box setting, assuming an attacker has partial information. We propose a novel defense that assumes everything but a private key will be made available to the attacker. Our framework uses an image denoising procedure coupled with encryption via a discretized Baker map. Extensive testing against adversarial images (e.g. FGSM, PGD) crafted using various gradients shows that our defense achieves significantly better results on CIFAR-10 and CIFAR-100 than the state-of-the-art gray box defenses in both natural and adversarial accuracy. ",
    "url": "https://arxiv.org/abs/2203.10290",
    "authors": [
      "Shi Hu",
      "Eric Nalisnick",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10299",
    "title": "Neural Machine Translation with Phrase-Level Universal Visual  Representations",
    "abstract": "Multimodal machine translation (MMT) aims to improve neural machine translation (NMT) with additional visual information, but most existing MMT methods require paired input of source sentence and image, which makes them suffer from shortage of sentence-image pairs. In this paper, we propose a phrase-level retrieval-based method for MMT to get visual information for the source input from existing sentence-image data sets so that MMT can break the limitation of paired sentence-image input. Our method performs retrieval at the phrase level and hence learns visual information from pairs of source phrase and grounded region, which can mitigate data sparsity. Furthermore, our method employs the conditional variational auto-encoder to learn visual representations which can filter redundant visual information and only retain visual information related to the phrase. Experiments show that the proposed method significantly outperforms strong baselines on multiple MMT datasets, especially when the textual context is limited. ",
    "url": "https://arxiv.org/abs/2203.10299",
    "authors": [
      "Qingkai Fang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10301",
    "title": "Exploring the impact of spatiotemporal granularity on the demand  prediction of dynamic ride-hailing",
    "abstract": "Dynamic demand prediction is a key issue in ride-hailing dispatching. Many methods have been developed to improve the demand prediction accuracy of an increase in demand-responsive, ride-hailing transport services. However, the uncertainties in predicting ride-hailing demands due to multiscale spatiotemporal granularity, as well as the resulting statistical errors, are seldom explored. This paper attempts to fill this gap and to examine the spatiotemporal granularity effects on ride-hailing demand prediction accuracy by using empirical data for Chengdu, China. A convolutional, long short-term memory model combined with a hexagonal convolution operation (H-ConvLSTM) is proposed to explore the complex spatial and temporal relations. Experimental analysis results show that the proposed approach outperforms conventional methods in terms of prediction accuracy. A comparison of 36 spatiotemporal granularities with both departure demands and arrival demands shows that the combination of a hexagonal spatial partition with an 800 m side length and a 30 min time interval achieves the best comprehensive prediction accuracy. However, the departure demands and arrival demands reveal different variation trends in the prediction errors for various spatiotemporal granularities. ",
    "url": "https://arxiv.org/abs/2203.10301",
    "authors": [
      "Kai Liu",
      "Zhiju Chen",
      "Toshiyuki Yamamoto",
      "Liheng Tuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10304",
    "title": "PACE: A Parallelizable Computation Encoder for Directed Acyclic Graphs",
    "abstract": "Optimization of directed acyclic graph (DAG) structures has many applications, such as neural architecture search (NAS) and probabilistic graphical model learning. Encoding DAGs into real vectors is a dominant component in most neural-network-based DAG optimization frameworks. Currently, most DAG encoders use an asynchronous message passing scheme which sequentially processes nodes according to the dependency between nodes in a DAG. That is, a node must not be processed until all its predecessors are processed. As a result, they are inherently not parallelizable. In this work, we propose a Parallelizable Attention-based Computation structure Encoder (PACE) that processes nodes simultaneously and encodes DAGs in parallel. We demonstrate the superiority of PACE through encoder-dependent optimization subroutines that search the optimal DAG structure based on the learned DAG embeddings. Experiments show that PACE not only improves the effectiveness over previous sequential DAG encoders with a significantly boosted training and inference speed, but also generates smooth latent (DAG encoding) spaces that are beneficial to downstream optimization subroutines. Our source code is available at \\url{https://github.com/zehaodong/PACE} ",
    "url": "https://arxiv.org/abs/2203.10304",
    "authors": [
      "Zehao Dong",
      "Muhan Zhang",
      "Fuhai Li",
      "Yixin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10314",
    "title": "Voxel Set Transformer: A Set-to-Set Approach to 3D Object Detection from  Point Clouds",
    "abstract": "Transformer has demonstrated promising performance in many 2D vision tasks. However, it is cumbersome to compute the self-attention on large-scale point cloud data because point cloud is a long sequence and unevenly distributed in 3D space. To solve this issue, existing methods usually compute self-attention locally by grouping the points into clusters of the same size, or perform convolutional self-attention on a discretized representation. However, the former results in stochastic point dropout, while the latter typically has narrow attention fields. In this paper, we propose a novel voxel-based architecture, namely Voxel Set Transformer (VoxSeT), to detect 3D objects from point clouds by means of set-to-set translation. VoxSeT is built upon a voxel-based set attention (VSA) module, which reduces the self-attention in each voxel by two cross-attentions and models features in a hidden space induced by a group of latent codes. With the VSA module, VoxSeT can manage voxelized point clusters with arbitrary size in a wide range, and process them in parallel with linear complexity. The proposed VoxSeT integrates the high performance of transformer with the efficiency of voxel-based model, which can be used as a good alternative to the convolutional and point-based backbones. VoxSeT reports competitive results on the KITTI and Waymo detection benchmarks. The source codes can be found at \\url{https://github.com/skyhehe123/VoxSeT}. ",
    "url": "https://arxiv.org/abs/2203.10314",
    "authors": [
      "Chenhang He",
      "Ruihuang Li",
      "Shuai Li",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10316",
    "title": "Learning to Reason Deductively: Math Word Problem Solving as Complex  Relation Extraction",
    "abstract": "Solving math word problems requires deductive reasoning over the quantities in the text. Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context. While empirically effective, such approaches typically do not provide explanations for the generated expressions. In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation. Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines. We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning. ",
    "url": "https://arxiv.org/abs/2203.10316",
    "authors": [
      "Zhanming Jie",
      "Jierui Li",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10321",
    "title": "Sequence-to-Sequence Knowledge Graph Completion and Question Answering",
    "abstract": "Knowledge graph embedding (KGE) models represent each entity and relation of a knowledge graph (KG) with low-dimensional embedding vectors. These methods have recently been applied to KG link prediction and question answering over incomplete KGs (KGQA). KGEs typically create an embedding for each entity in the graph, which results in large model sizes on real-world graphs with millions of entities. For downstream tasks these atomic entity representations often need to be integrated into a multi stage pipeline, limiting their utility. We show that an off-the-shelf encoder-decoder Transformer model can serve as a scalable and versatile KGE model obtaining state-of-the-art results for KG link prediction and incomplete KG question answering. We achieve this by posing KG link prediction as a sequence-to-sequence task and exchange the triple scoring approach taken by prior KGE methods with autoregressive decoding. Such a simple but powerful method reduces the model size up to 98% compared to conventional KGE models while keeping inference time tractable. After finetuning this model on the task of KGQA over incomplete KGs, our approach outperforms baselines on multiple large-scale datasets without extensive hyperparameter tuning. ",
    "url": "https://arxiv.org/abs/2203.10321",
    "authors": [
      "Apoorv Saxena",
      "Adrian Kochsiek",
      "Rainer Gemulla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10339",
    "title": "Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation",
    "abstract": "6D object pose estimation is a fundamental yet challenging problem in computer vision. Convolutional Neural Networks (CNNs) have recently proven to be capable of predicting reliable 6D pose estimates even under monocular settings. Nonetheless, CNNs are identified as being extremely data-driven, and acquiring adequate annotations is oftentimes very time-consuming and labor intensive. To overcome this limitation, we propose a novel monocular 6D pose estimation approach by means of self-supervised learning, removing the need for real annotations. After training our proposed network fully supervised with synthetic RGB data, we leverage current trends in noisy student training and differentiable rendering to further self-supervise the model on these unsupervised real RGB(-D) samples, seeking for a visually and geometrically optimal alignment. Moreover, employing both visible and amodal mask information, our self-supervision becomes very robust towards challenging scenarios such as occlusion. Extensive evaluations demonstrate that our proposed self-supervision outperforms all other methods relying on synthetic data or employing elaborate techniques from the domain adaptation realm. Noteworthy, our self-supervised approach consistently improves over its synthetically trained baseline and often almost closes the gap towards its fully supervised counterpart. The code and models are publicly available at https://github.com/THU-DA-6D-Pose-Group/self6dpp.git. ",
    "url": "https://arxiv.org/abs/2203.10339",
    "authors": [
      "Gu Wang",
      "Fabian Manhardt",
      "Xingyu Liu",
      "Xiangyang Ji",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.10343",
    "title": "Automatic Detection of Entity-Manipulated Text using Factual Knowledge",
    "abstract": "In this work, we focus on the problem of distinguishing a human written news article from a news article that is created by manipulating entities in a human written news article (e.g., replacing entities with factually incorrect entities). Such manipulated articles can mislead the reader by posing as a human written news article. We propose a neural network based detector that detects manipulated news articles by reasoning about the facts mentioned in the article. Our proposed detector exploits factual knowledge via graph convolutional neural network along with the textual information in the news article. We also create challenging datasets for this task by considering various strategies to generate the new replacement entity (e.g., entity generation from GPT-2). In all the settings, our proposed model either matches or outperforms the state-of-the-art detector in terms of accuracy. Our code and data are available at https://github.com/UBC-NLP/manipulated_entity_detection. ",
    "url": "https://arxiv.org/abs/2203.10343",
    "authors": [
      "Ganesh Jawahar",
      "Muhammad Abdul-Mageed",
      "Laks V. S. Lakshmanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10344",
    "title": "No Shifted Augmentations (NSA): compact distributions for robust  self-supervised Anomaly Detection",
    "abstract": "Unsupervised Anomaly detection (AD) requires building a notion of normalcy, distinguishing in-distribution (ID) and out-of-distribution (OOD) data, using only available ID samples. Recently, large gains were made on this task for the domain of natural images using self-supervised contrastive feature learning as a first step followed by kNN or traditional one-class classifiers for feature scoring. Learned representations that are non-uniformly distributed on the unit hypersphere have been shown to be beneficial for this task. We go a step further and investigate how the \\emph {geometrical compactness} of the ID feature distribution makes isolating and detecting outliers easier, especially in the realistic situation when ID training data is polluted (i.e. ID data contains some OOD data that is used for learning the feature extractor parameters). We propose novel architectural modifications to the self-supervised feature learning step, that enable such compact distributions for ID data to be learned. We show that the proposed modifications can be effectively applied to most existing self-supervised objectives, with large gains in performance. Furthermore, this improved OOD performance is obtained without resorting to tricks such as using strongly augmented ID images (e.g. by 90 degree rotations) as proxies for the unseen OOD data, as these impose overly prescriptive assumptions about ID data and its invariances. We perform extensive studies on benchmark datasets for one-class OOD detection and show state-of-the-art performance in the presence of pollution in the ID data, and comparable performance otherwise. We also propose and extensively evaluate a novel feature scoring technique based on the angular Mahalanobis distance, and propose a simple and novel technique for feature ensembling during evaluation that enables a big boost in performance at nearly zero run-time cost. ",
    "url": "https://arxiv.org/abs/2203.10344",
    "authors": [
      "Mohamed Yousef",
      "Marcel Ackermann",
      "Unmesh Kurup",
      "Tom Bishop"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10346",
    "title": "Perturbations in the Wild: Leveraging Human-Written Text Perturbations  for Realistic Adversarial Attack and Defense",
    "abstract": "We proposes a novel algorithm, ANTHRO, that inductively extracts over 600K human-written text perturbations in the wild and leverages them for realistic adversarial attack. Unlike existing character-based attacks which often deductively hypothesize a set of manipulation strategies, our work is grounded on actual observations from real-world texts. We find that adversarial texts generated by ANTHRO achieve the best trade-off between (1) attack success rate, (2) semantic preservation of the original text, and (3) stealthiness--i.e. indistinguishable from human writings hence harder to be flagged as suspicious. Specifically, our attacks accomplished around 83% and 91% attack success rates on BERT and RoBERTa, respectively. Moreover, it outperformed the TextBugger baseline with an increase of 50% and 40% in terms of semantic preservation and stealthiness when evaluated by both layperson and professional human workers. ANTHRO can further enhance a BERT classifier's performance in understanding different variations of human-written toxic texts via adversarial training when compared to the Perspective API. ",
    "url": "https://arxiv.org/abs/2203.10346",
    "authors": [
      "Thai Le",
      "Jooyoung Lee",
      "Kevin Yen",
      "Yifan Hu",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10350",
    "title": "CLRNet: Cross Layer Refinement Network for Lane Detection",
    "abstract": "Lane is critical in the vision navigation system of the intelligent vehicle. Naturally, lane is a traffic sign with high-level semantics, whereas it owns the specific local pattern which needs detailed low-level features to localize accurately. Using different feature levels is of great importance for accurate lane detection, but it is still under-explored. In this work, we present Cross Layer Refinement Network (CLRNet) aiming at fully utilizing both high-level and low-level features in lane detection. In particular, it first detects lanes with high-level semantic features then performs refinement based on low-level features. In this way, we can exploit more contextual information to detect lanes while leveraging local detailed lane features to improve localization accuracy. We present ROIGather to gather global context, which further enhances the feature representation of lanes. In addition to our novel network design, we introduce Line IoU loss which regresses the lane line as a whole unit to improve the localization accuracy. Experiments demonstrate that the proposed method greatly outperforms the state-of-the-art lane detection approaches. ",
    "url": "https://arxiv.org/abs/2203.10350",
    "authors": [
      "Tu Zheng",
      "Yifei Huang",
      "Yang Liu",
      "Wenjian Tang",
      "Zheng Yang",
      "Deng Cai",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10369",
    "title": "The Online Behaviour of the Algerian Abusers in Social Media Networks",
    "abstract": "Connecting to social media networks becomes a daily task for the majority of people around the world, and the amount of shared information is growing exponentially. Thus, controlling the way in which people communicate is necessary, in order to protect them from disorientation, conflicts, aggressions, etc. In this paper, we conduct a statistical study on the cyber-bullying and the abusive content in social media (i.e. Facebook), where we try to spot the online behaviour of the abusers in the Algerian community. More specifically, we have involved 200 Facebook users from different regions among 600 to carry out this study. The aim of this investigation is to aid automatic systems of abuse detection to take decision by incorporating the online activity. Abuse detection systems require a large amount of data to perform better on such kind of texts (i.e. unstructured and informal texts), and this is due to the lack of standard orthography, where there are various Algerian dialects and languages spoken. ",
    "url": "https://arxiv.org/abs/2203.10369",
    "authors": [
      "Kheireddine Abainia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10378",
    "title": "On Robust Prefix-Tuning for Text Classification",
    "abstract": "Recently, prefix-tuning has gained increasing attention as a parameter-efficient finetuning method for large-scale pretrained language models. The method keeps the pretrained models fixed and only updates the prefix token parameters for each downstream task. Despite being lightweight and modular, prefix-tuning still lacks robustness to textual adversarial attacks. However, most currently developed defense techniques necessitate auxiliary model update and storage, which inevitably hamper the modularity and low storage of prefix-tuning. In this work, we propose a robust prefix-tuning framework that preserves the efficiency and modularity of prefix-tuning. The core idea of our framework is leveraging the layerwise activations of the language model by correctly-classified training data as the standard for additional prefix finetuning. During the test phase, an extra batch-level prefix is tuned for each batch and added to the original prefix for robustness enhancement. Extensive experiments on three text classification benchmarks show that our framework substantially improves robustness over several strong baselines against five textual attacks of different types while maintaining comparable accuracy on clean texts. We also interpret our robust prefix-tuning framework from the optimal control perspective and pose several directions for future research. ",
    "url": "https://arxiv.org/abs/2203.10378",
    "authors": [
      "Zonghan Yang",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.10384",
    "title": "Data Smells: Categories, Causes and Consequences, and Detection of  Suspicious Data in AI-based Systems",
    "abstract": "High data quality is fundamental for today's AI-based systems. However, although data quality has been an object of research for decades, there is a clear lack of research on potential data quality issues (e.g., ambiguous, extraneous values). These kinds of issues are latent in nature and thus often not obvious. Nevertheless, they can be associated with an increased risk of future problems in AI-based systems (e.g., technical debt, data-induced faults). As a counterpart to code smells in software engineering, we refer to such issues as Data Smells. This article conceptualizes data smells and elaborates on their causes, consequences, detection, and use in the context of AI-based systems. In addition, a catalogue of 36 data smells divided into three categories (i.e., Believability Smells, Understandability Smells, Consistency Smells) is presented. Moreover, the article outlines tool support for detecting data smells and presents the result of an initial smell detection on more than 240 real-world datasets. ",
    "url": "https://arxiv.org/abs/2203.10384",
    "authors": [
      "Harald Foidl",
      "Michael Felderer",
      "Rudolf Ramler"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10395",
    "title": "Towards Robust Semantic Segmentation of Accident Scenes via Multi-Source  Mixed Sampling and Meta-Learning",
    "abstract": "Autonomous vehicles utilize urban scene segmentation to understand the real world like a human and react accordingly. Semantic segmentation of normal scenes has experienced a remarkable rise in accuracy on conventional benchmarks. However, a significant portion of real-life accidents features abnormal scenes, such as those with object deformations, overturns, and unexpected traffic behaviors. Since even small mis-segmentation of driving scenes can lead to serious threats to human lives, the robustness of such models in accident scenarios is an extremely important factor in ensuring safety of intelligent transportation systems. In this paper, we propose a Multi-source Meta-learning Unsupervised Domain Adaptation (MMUDA) framework, to improve the generalization of segmentation transformers to extreme accident scenes. In MMUDA, we make use of Multi-Domain Mixed Sampling to augment the images of multiple-source domains (normal scenes) with the target data appearances (abnormal scenes). To train our model, we intertwine and study a meta-learning strategy in the multi-source setting for robustifying the segmentation results. We further enhance the segmentation backbone (SegFormer) with a HybridASPP decoder design, featuring large window attention spatial pyramid pooling and strip pooling, to efficiently aggregate long-range contextual dependencies. Our approach achieves a mIoU score of 46.97% on the DADA-seg benchmark, surpassing the previous state-of-the-art model by more than 7.50%. Code will be made publicly available at https://github.com/xinyu-laura/MMUDA. ",
    "url": "https://arxiv.org/abs/2203.10395",
    "authors": [
      "Xinyu Luo",
      "Jiaming Zhang",
      "Kailun Yang",
      "Alina Roitberg",
      "Kunyu Peng",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.10398",
    "title": "Ethical Considerations When Constructing Participatory Design Protocols  for Social Robots",
    "abstract": "Participatory design has emerged as a popular approach to foreground ethical considerations in social robots by incorporating anticipated users and stakeholders as designers. Here we draw attention to the ethics of participatory design as a method, distinct from the ethical considerations of the social robot being co-designed. More specifically, we consider the ethical concerns posed by the act of stakeholder participation - the morals and values that should be explicitly considered when we, as researchers or practitioners, devise protocols for participatory design of social robots (\"how\" stakeholders participate). We use the case of robot-assisted sexual violence mitigation to exemplify ethical considerations of participatory design protocols such as risk of harm, exploitation, and reduction of stakeholder agency. To incorporate these and other ethical considerations in the creation of social robot participatory design protocols, we advocate letting stakeholders design their own form of participation by including them in the creation of participatory design sessions, structures, and processes. ",
    "url": "https://arxiv.org/abs/2203.10398",
    "authors": [
      "Douglas Zytko",
      "Wing-Yue Geoffrey Louie"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.10403",
    "title": "An Exploratory Study into Vulnerability Chaining Blindness Terminology  and Viability",
    "abstract": "To tie together the concepts of linkage blindness and the inability to link vulnerabilities together in a Vulnerability Management Program (VMP), the researcher postulated new terminology. The terminology of vulnerability chaining blindness is proposed to understand the underlying issues behind vulnerability management and vulnerabilities that can be used in combination. The general problem is that IT and cybersecurity professionals have a difficult time identifying chained vulnerabilities due to the complexity of vulnerability prioritization and remediation (Abomhara & K{\\o}ien, 2015; Felmetsger et al., 2010). The specific problem is the inability to link and view multiple vulnerabilities in combination based on limited expertise and awareness of vulnerability chaining (Tang et al., 2017). The population of this study was limited to one focus group, within the IT and Security fields, within the United States. The sample size consisted of one focus group comprised of 8-10 IT and cybersecurity professionals. The research questions focused on if participants were aware of linkage blindness or vulnerability chaining, as well as if vulnerability chaining blindness would be applicable to describe the phenomenon. Several themes emerged through top-level, eclectic, and second-level coding data analysis. These themes included complexity in cybersecurity programs, new concepts in vulnerability management, as well as fear of the unknown and where security meets technology. Keywords: linkage blindness, vulnerability chaining, vulnerability chaining blindness, vulnerability management ",
    "url": "https://arxiv.org/abs/2203.10403",
    "authors": [
      "Nikki Robinson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10408",
    "title": "Anomaly Detection in Emails using Machine Learning and Header  Information",
    "abstract": "Anomalies in emails such as phishing and spam present major security risks such as the loss of privacy, money, and brand reputation to both individuals and organizations. Previous studies on email anomaly detection relied on a single type of anomaly and the analysis of the email body and subject content. A drawback of this approach is that it takes into account the written language of the email content. To overcome this deficit, this study conducted feature extraction and selection on email header datasets and leveraged both multi and one-class anomaly detection approaches. Experimental analysis results obtained demonstrate that email header information only is enough to reliably detect spam and phishing emails. Supervised learning algorithms such as Random Forest, SVM, MLP, KNN, and their stacked ensembles were found to be very successful, achieving high accuracy scores of 97% for phishing and 99% for spam emails. One-class classification with One-Class SVM achieved accuracy scores of 87% and 89% with spam and phishing emails, respectively. Real-world email filtering applications will benefit from the use of only the header information in terms of resources utilization and efficiency. ",
    "url": "https://arxiv.org/abs/2203.10408",
    "authors": [
      "Craig Beaman",
      "Haruna Isah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.10422",
    "title": "Subspace Modeling for Fast Out-Of-Distribution and Anomaly Detection",
    "abstract": "This paper presents a fast, principled approach for detecting anomalous and out-of-distribution (OOD) samples in deep neural networks (DNN). We propose the application of linear statistical dimensionality reduction techniques on the semantic features produced by a DNN, in order to capture the low-dimensional subspace truly spanned by said features. We show that the \"feature reconstruction error\" (FRE), which is the $\\ell_2$-norm of the difference between the original feature in the high-dimensional space and the pre-image of its low-dimensional reduced embedding, is highly effective for OOD and anomaly detection. To generalize to intermediate features produced at any given layer, we extend the methodology by applying nonlinear kernel-based methods. Experiments using standard image datasets and DNN architectures demonstrate that our method meets or exceeds best-in-class quality performance, but at a fraction of the computational and memory cost required by the state of the art. It can be trained and run very efficiently, even on a traditional CPU. ",
    "url": "https://arxiv.org/abs/2203.10422",
    "authors": [
      "Ibrahima J. Ndiour",
      "Nilesh A. Ahuja",
      "Omesh Tickoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10425",
    "title": "A Study on Robustness to Perturbations for Representations of  Environmental Sound",
    "abstract": "Many audio applications, such as environmental sound analysis, are increasingly using general-purpose audio representations for transfer learning. The robustness of such representations has been determined by evaluating them across a variety of domains and applications. However, it is unclear how the application-specific evaluation can be utilized to predict the impact of variability in real-world deployments caused by myriad microphones' range and acoustic conditions, commonly known as \\textit{channel effects}. In this paper, we integrate the results of various distance metrics with downstream performance to make a more informed prediction of how robust the representations or embeddings are to the audio channel effects. To accomplish this, we use two embeddings, YAMNet and OpenL$^3$, and three distance metrics to quantify the change in the embeddings when injecting perturbations to the audio signal that imitate channel effects. In monophonic (UrbanSound8K) and polyphonic (SONYC UST) data, we show a combination of two distances, Fr\\'echet Audio Distance (FAD) and Cophenetic Correlation Distance (CPCD), correlates well with the effects of perturbations. We further discuss the limitations of each distance measure. ",
    "url": "https://arxiv.org/abs/2203.10425",
    "authors": [
      "Sangeeta Srivastava",
      "Ho-Hsiang Wu",
      "Joao Rulff",
      "Magdalena Fuentes",
      "Mark Cartwright",
      "Claudio Silva",
      "Anish Arora",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.10428",
    "title": "PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks  with Pipelined Feature Communication",
    "abstract": "Graph Convolutional Networks (GCNs) is the state-of-the-art method for learning graph-structured data, and training large-scale GCNs requires distributed training across multiple accelerators such that each accelerator is able to hold a partitioned subgraph. However, distributed GCN training incurs prohibitive overhead of communicating node features and feature gradients among partitions for every GCN layer during each training iteration, limiting the achievable training efficiency and model scalability. To this end, we propose PipeGCN, a simple yet effective scheme that hides the communication overhead by pipelining inter-partition communication with intra-partition computation. It is non-trivial to pipeline for efficient GCN training, as communicated node features/gradients will become stale and thus can harm the convergence, negating the pipeline benefit. Notably, little is known regarding the convergence rate of GCN training with both stale features and stale feature gradients. This work not only provides a theoretical convergence analysis but also finds the convergence rate of PipeGCN to be close to that of the vanilla distributed GCN training without any staleness. Furthermore, we develop a smoothing method to further improve PipeGCN's convergence. Extensive experiments show that PipeGCN can largely boost the training throughput (1.7x~28.5x) while achieving the same accuracy as its vanilla counterpart and existing full-graph training methods. The code is available at https://github.com/RICE-EIC/PipeGCN. ",
    "url": "https://arxiv.org/abs/2203.10428",
    "authors": [
      "Cheng Wan",
      "Youjie Li",
      "Cameron R. Wolfe",
      "Anastasios Kyrillidis",
      "Nam Sung Kim",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10433",
    "title": "End-to-End Human-Gaze-Target Detection with Transformers",
    "abstract": "In this paper, we propose an effective and efficient method for Human-Gaze-Target (HGT) detection, i.e., gaze following. Current approaches decouple the HGT detection task into separate branches of salient object detection and human gaze prediction, employing a two-stage framework where human head locations must first be detected and then be fed into the next gaze target prediction sub-network. In contrast, we redefine the HGT detection task as detecting human head locations and their gaze targets, simultaneously. By this way, our method, named Human-Gaze-Target detection TRansformer or HGTTR, streamlines the HGT detection pipeline by eliminating all other additional components. HGTTR reasons about the relations of salient objects and human gaze from the global image context. Moreover, unlike existing two-stage methods that require human head locations as input and can predict only one human's gaze target at a time, HGTTR can directly predict the locations of all people and their gaze targets at one time in an end-to-end manner. The effectiveness and robustness of our proposed method are verified with extensive experiments on the two standard benchmark datasets, GazeFollowing and VideoAttentionTarget. Without bells and whistles, HGTTR outperforms existing state-of-the-art methods by large margins (6.4 mAP gain on GazeFollowing and 10.3 mAP gain on VideoAttentionTarget) with a much simpler architecture. ",
    "url": "https://arxiv.org/abs/2203.10433",
    "authors": [
      "Danyang Tu",
      "Xiongkuo Min",
      "Huiyu Duan",
      "Guodong Guo",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10453",
    "title": "Fine-Tuning Graph Neural Networks via Graph Topology induced Optimal  Transport",
    "abstract": "Recently, the pretrain-finetuning paradigm has attracted tons of attention in graph learning community due to its power of alleviating the lack of labels problem in many real-world applications. Current studies use existing techniques, such as weight constraint, representation constraint, which are derived from images or text data, to transfer the invariant knowledge from the pre-train stage to fine-tuning stage. However, these methods failed to preserve invariances from graph structure and Graph Neural Network (GNN) style models. In this paper, we present a novel optimal transport-based fine-tuning framework called GTOT-Tuning, namely, Graph Topology induced Optimal Transport fine-Tuning, for GNN style backbones. GTOT-Tuning is required to utilize the property of graph data to enhance the preservation of representation produced by fine-tuned networks. Toward this goal, we formulate graph local knowledge transfer as an Optimal Transport (OT) problem with a structural prior and construct the GTOT regularizer to constrain the fine-tuned model behaviors. By using the adjacency relationship amongst nodes, the GTOT regularizer achieves node-level optimal transport procedures and reduces redundant transport procedures, resulting in efficient knowledge transfer from the pre-trained models. We evaluate GTOT-Tuning on eight downstream tasks with various GNN backbones and demonstrate that it achieves state-of-the-art fine-tuning performance for GNNs. ",
    "url": "https://arxiv.org/abs/2203.10453",
    "authors": [
      "Jiying Zhang",
      "Xi Xiao",
      "Long-Kai Huang",
      "Yu Rong",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10454",
    "title": "Partitioning Image Representation in Contrastive Learning",
    "abstract": "In contrastive learning in the image domain, the anchor and positive samples are forced to have as close representations as possible. However, forcing the two samples to have the same representation could be misleading because the data augmentation techniques make the two samples different. In this paper, we introduce a new representation, partitioned representation, which can learn both common and unique features of the anchor and positive samples in contrastive learning. The partitioned representation consists of two parts: the content part and the style part. The content part represents common features of the class, and the style part represents the own features of each sample, which can lead to the representation of the data augmentation method. We can achieve the partitioned representation simply by decomposing a loss function of contrastive learning into two terms on the two separate representations, respectively. To evaluate our representation with two parts, we take two framework models: Variational AutoEncoder (VAE) and BootstrapYour Own Latent(BYOL) to show the separability of content and style, and to confirm the generalization ability in classification, respectively. Based on the experiments, we show that our approach can separate two types of information in the VAE framework and outperforms the conventional BYOL in linear separability and a few-shot learning task as downstream tasks. ",
    "url": "https://arxiv.org/abs/2203.10454",
    "authors": [
      "Hyunsub Lee",
      "Heeyoul Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10455",
    "title": "Adversarial Mutual Leakage Network for Cell Image Segmentation",
    "abstract": "We propose three segmentation methods using GAN and information leakage between generator and discriminator. First, we propose an Adversarial Training Attention Module (ATA-Module) that uses an attention mechanism from the discriminator to the generator to enhance and leak important information in the discriminator. ATA-Module transmits important information to the generator from the discriminator. Second, we propose a Top-Down Pixel-wise Difficulty Attention Module (Top-Down PDA-Module) that leaks an attention map based on pixel-wise difficulty in the generator to the discriminator. The generator trains to focus on pixel-wise difficulty, and the discriminator uses the difficulty information leaked from the generator for classification. Finally, we propose an Adversarial Mutual Leakage Network (AML-Net) that mutually leaks the information each other between the generator and the discriminator. By using the information of the other network, it is able to train more efficiently than ordinary segmentation models. Three proposed methods have been evaluated on two datasets for cell image segmentation. The experimental results show that the segmentation accuracy of AML-Net was much improved in comparison with conventional methods. ",
    "url": "https://arxiv.org/abs/2203.10455",
    "authors": [
      "Hiroki Tsuda",
      "Kazuhiro Hotta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10456",
    "title": "simCrossTrans: A Simple Cross-Modality Transfer Learning for Object  Detection with ConvNets or Vision Transformers",
    "abstract": "Transfer learning is widely used in computer vision (CV), natural language processing (NLP) and achieves great success. Most transfer learning systems are based on the same modality (e.g. RGB image in CV and text in NLP). However, the cross-modality transfer learning (CMTL) systems are scarce. In this work, we study CMTL from 2D to 3D sensor to explore the upper bound performance of 3D sensor only systems, which play critical roles in robotic navigation and perform well in low light scenarios. While most CMTL pipelines from 2D to 3D vision are complicated and based on Convolutional Neural Networks (ConvNets), ours is easy to implement, expand and based on both ConvNets and Vision transformers(ViTs): 1) By converting point clouds to pseudo-images, we can use an almost identical network from pre-trained models based on 2D images. This makes our system easy to implement and expand. 2) Recently ViTs have been showing good performance and robustness to occlusions, one of the key reasons for poor performance of 3D vision systems. We explored both ViT and ConvNet with similar model sizes to investigate the performance difference. We name our approach simCrossTrans: simple cross-modality transfer learning with ConvNets or ViTs. Experiments on SUN RGB-D dataset show: with simCrossTrans we achieve $13.2\\%$ and $16.1\\%$ absolute performance gain based on ConvNets and ViTs separately. We also observed the ViTs based performs $9.7\\%$ better than the ConvNets one, showing the power of simCrossTrans with ViT. simCrossTrans with ViTs surpasses the previous state-of-the-art (SOTA) by a large margin of $+15.4\\%$ mAP50. Compared with the previous 2D detection SOTA based RGB images, our depth image only system only has a $1\\%$ gap. The code, training/inference logs and models are publicly available at https://github.com/liketheflower/simCrossTrans ",
    "url": "https://arxiv.org/abs/2203.10456",
    "authors": [
      "Xiaoke Shen",
      "Ioannis Stamos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10463",
    "title": "{Unidirectional Thin Adapter for Efficient Adaptation of Deep Neural  Networks",
    "abstract": "In this paper, we propose a new adapter network for adapting a pre-trained deep neural network to a target domain with minimal computation. The proposed model, unidirectional thin adapter (UDTA), helps the classifier adapt to new data by providing auxiliary features that complement the backbone network. UDTA takes outputs from multiple layers of the backbone as input features but does not transmit any feature to the backbone. As a result, UDTA can learn without computing the gradient of the backbone, which saves computation for training significantly. In addition, since UDTA learns the target task without modifying the backbone, a single backbone can adapt to multiple tasks by learning only UDTAs separately. In experiments on five fine-grained classification datasets consisting of a small number of samples, UDTA significantly reduced computation and training time required for backpropagation while showing comparable or even improved accuracy compared with conventional adapter models. ",
    "url": "https://arxiv.org/abs/2203.10463",
    "authors": [
      "Han Gyel Sun",
      "Hyunjae Ahn",
      "HyunGyu Lee",
      "Injung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10465",
    "title": "Inspection-L: Practical GNN-Based Money Laundering Detection System for  Bitcoin",
    "abstract": "Criminals have become increasingly experienced in using cryptocurrencies, such as Bitcoin, for money laundering. The use of cryptocurrencies can hide criminal identities and transfer hundreds of millions of dollars of dirty funds through their criminal digital wallets. However, this is considered a paradox because cryptocurrencies are gold mines for open-source intelligence, allowing law enforcement agencies to have more power in conducting forensic analyses. This paper proposed Inspection-L, a graph neural network (GNN) framework based on self-supervised Deep Graph Infomax (DGI), with Random Forest (RF), to detect illicit transactions for Anti-Money laundering (AML). To the best of our knowledge, our proposal is the first of applying self-supervised GNNs to the problem of AML in Bitcoin. The proposed method has been evaluated on the Elliptic dataset and shows that our approach outperforms the state-of-the-art in terms of key classification metrics, which demonstrates the potential of self-supervised GNN in cryptocurrency illicit transaction detection. ",
    "url": "https://arxiv.org/abs/2203.10465",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2203.10492",
    "title": "SimAN: Exploring Self-Supervised Representation Learning of Scene Text  via Similarity-Aware Normalization",
    "abstract": "Recently self-supervised representation learning has drawn considerable attention from the scene text recognition community. Different from previous studies using contrastive learning, we tackle the issue from an alternative perspective, i.e., by formulating the representation learning scheme in a generative manner. Typically, the neighboring image patches among one text line tend to have similar styles, including the strokes, textures, colors, etc. Motivated by this common sense, we augment one image patch and use its neighboring patch as guidance to recover itself. Specifically, we propose a Similarity-Aware Normalization (SimAN) module to identify the different patterns and align the corresponding styles from the guiding patch. In this way, the network gains representation capability for distinguishing complex patterns such as messy strokes and cluttered backgrounds. Experiments show that the proposed SimAN significantly improves the representation quality and achieves promising performance. Moreover, we surprisingly find that our self-supervised generative network has impressive potential for data synthesis, text image editing, and font interpolation, which suggests that the proposed SimAN has a wide range of practical applications. ",
    "url": "https://arxiv.org/abs/2203.10492",
    "authors": [
      "Canjie Luo",
      "Lianwen Jin",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10496",
    "title": "Single-image Human-body Reshaping with Deep Neural Networks",
    "abstract": "In this paper, we present NeuralReshaper, a novel method for semantic reshaping of human bodies in single images using deep generative networks. To achieve globally coherent reshaping effects, our approach follows a fit-then-reshape pipeline, which first fits a parametric 3D human model to a source human image and then reshapes the fitted 3D model with respect to user-specified semantic attributes. Previous methods rely on image warping to transfer 3D reshaping effects to the entire image domain and thus often cause distortions in both foreground and background. Instead, to achieve more realistic reshaping results, we resort to generative adversarial nets conditioned on the source image and a 2D warping field induced by the reshaped 3D model. Specifically, we separately encode the foreground and background information in the source image using a two-headed U-net-like generator and guide the information flow from the foreground branch to the background branch via feature space warping. Furthermore, to deal with the lack-of-data problem that no paired data exist (i.e., the same human bodies in varying shapes), we introduce a novel weakly-supervised strategy to train our network. Besides, unlike previous methods that often require manual efforts to correct undesirable artifacts caused by incorrect body-to-image fitting, our method is fully automatic. Extensive experiments on both indoor and outdoor datasets demonstrate the superiority of our method over previous approaches. ",
    "url": "https://arxiv.org/abs/2203.10496",
    "authors": [
      "Beijia Chen",
      "Hongbo Fu",
      "Xiang Chen",
      "Kun Zhou",
      "Youyi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.10502",
    "title": "Adversarial Parameter Attack on Deep Neural Networks",
    "abstract": "In this paper, a new parameter perturbation attack on DNNs, called adversarial parameter attack, is proposed, in which small perturbations to the parameters of the DNN are made such that the accuracy of the attacked DNN does not decrease much, but its robustness becomes much lower. The adversarial parameter attack is stronger than previous parameter perturbation attacks in that the attack is more difficult to be recognized by users and the attacked DNN gives a wrong label for any modified sample input with high probability. The existence of adversarial parameters is proved. For a DNN $F_{\\Theta}$ with the parameter set $\\Theta$ satisfying certain conditions, it is shown that if the depth of the DNN is sufficiently large, then there exists an adversarial parameter set $\\Theta_a$ for $\\Theta$ such that the accuracy of $F_{\\Theta_a}$ is equal to that of $F_{\\Theta}$, but the robustness measure of $F_{\\Theta_a}$ is smaller than any given bound. An effective training algorithm is given to compute adversarial parameters and numerical experiments are used to demonstrate that the algorithms are effective to produce high quality adversarial parameters. ",
    "url": "https://arxiv.org/abs/2203.10502",
    "authors": [
      "Lijia Yu",
      "Yihan Wang",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10507",
    "title": "Soft-CP: A Credible and Effective Data Augmentation for Semantic  Segmentation of Medical Lesions",
    "abstract": "The medical datasets are usually faced with the problem of scarcity and data imbalance. Moreover, annotating large datasets for semantic segmentation of medical lesions is domain-knowledge and time-consuming. In this paper, we propose a new object-blend method(short in soft-CP) that combines the Copy-Paste augmentation method for semantic segmentation of medical lesions offline, ensuring the correct edge information around the lession to solve the issue above-mentioned. We proved the method's validity with several datasets in different imaging modalities. In our experiments on the KiTS19[2] dataset, Soft-CP outperforms existing medical lesions synthesis approaches. The Soft-CP augementation provides gains of +26.5% DSC in the low data regime(10% of data) and +10.2% DSC in the high data regime(all of data), In offline training data, the ratio of real images to synthetic images is 3:1. ",
    "url": "https://arxiv.org/abs/2203.10507",
    "authors": [
      "Pingping Dai",
      "Licong Dong",
      "Ruihan Zhang",
      "Haiming Zhu",
      "Jie Wu",
      "Kehong Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10528",
    "title": "Stochastic Video Prediction with Structure and Motion",
    "abstract": "While stochastic video prediction models enable future prediction under uncertainty, they mostly fail to model the complex dynamics of real-world scenes. For example, they cannot provide reliable predictions for scenes with a moving camera and independently moving foreground objects in driving scenarios. The existing methods fail to fully capture the dynamics of the structured world by only focusing on changes in pixels. In this paper, we assume that there is an underlying process creating observations in a video and propose to factorize it into static and dynamic components. We model the static part based on the scene structure and the ego-motion of the vehicle, and the dynamic part based on the remaining motion of the dynamic objects. By learning separate distributions of changes in foreground and background, we can decompose the scene into static and dynamic parts and separately model the change in each. Our experiments demonstrate that disentangling structure and motion helps stochastic video prediction, leading to better future predictions in complex driving scenarios on two real-world driving datasets, KITTI and Cityscapes. ",
    "url": "https://arxiv.org/abs/2203.10528",
    "authors": [
      "Adil Kaan Akan",
      "Sadra Safadoust",
      "Erkut Erdem",
      "Aykut Erdem",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10533",
    "title": "Strategic Analysis to defend against Griefing Attack in Lightning  Network",
    "abstract": "Payments routed in Lightning Network are susceptible to a \\emph{griefing attack}. In this attack, the channels get blocked, and the affected parties cannot process any payment request. Our work is the first to analyze griefing attacks in Hashed Timelock Contract or \\emph{HTLC}, from a game-theoretic point of view. Using the same model, we analyze another payment protocol Hashed Timelock Contract with Griefing-Penalty or \\emph{HTLC-GP}, which was proposed to counter griefing attacks. We find that \\emph{HTLC-GP} is \\emph{weakly effective} in disincentivizing the attacker. To further increase the cost of attack, we introduce the concept of \\emph{guaranteed minimum compensation} and integrate it into \\emph{HTLC-GP}. This modified payment protocol is termed $\\textrm{HTLC-GP}^{\\zeta}$ and unlike \\emph{HTLC-GP}, the protocol considers the participants to act rationally. By experimenting on several instances of Lightning Network, we show that the capacity locked drops to $40\\%$ in the case of \\emph{HTLC-GP} when the rate of griefing-penalty is set to $4.5\\times 10^{-5}$, and $28\\%$ in the case of $\\textrm{HTLC-GP}^{\\zeta}$ when guaranteed minimum compensation is $2.5\\%$ of the transaction amount. These results justify our claim that $\\textrm{HTLC-GP}^{\\zeta}$ is better than \\emph{HTLC-GP} to counter griefing attacks. ",
    "url": "https://arxiv.org/abs/2203.10533",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Abhinandan Sinha",
      "Sushmita Ruj",
      "Bimal Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.10537",
    "title": "Iwin: Human-Object Interaction Detection via Transformer with Irregular  Windows",
    "abstract": "This paper presents a new vision Transformer, named Iwin Transformer, which is specifically designed for human-object interaction (HOI) detection, a detailed scene understanding task involving a sequential process of human/object detection and interaction recognition. Iwin Transformer is a hierarchical Transformer which progressively performs token representation learning and token agglomeration within irregular windows. The irregular windows, achieved by augmenting regular grid locations with learned offsets, 1) eliminate redundancy in token representation learning, which leads to efficient human/object detection, and 2) enable the agglomerated tokens to align with humans/objects with different shapes, which facilitates the acquisition of highly-abstracted visual semantics for interaction recognition. The effectiveness and efficiency of Iwin Transformer are verified on the two standard HOI detection benchmark datasets, HICO-DET and V-COCO. Results show our method outperforms existing Transformers-based methods by large margins (3.7 mAP gain on HICO-DET and 2.0 mAP gain on V-COCO) with fewer training epochs ($0.5 \\times$). ",
    "url": "https://arxiv.org/abs/2203.10537",
    "authors": [
      "Danyang Tu",
      "Xiongkuo Min",
      "Huiyu Duan",
      "Guodong Guo",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10545",
    "title": "Parallel Instance Query Network for Named Entity Recognition",
    "abstract": "Named entity recognition (NER) is a fundamental task in natural language processing. Recent works treat named entity recognition as a reading comprehension task, constructing type-specific queries manually to extract entities. This paradigm suffers from three issues. First, type-specific queries can only extract one type of entities per inference, which is inefficient. Second, the extraction for different types of entities is isolated, ignoring the dependencies between them. Third, query construction relies on external knowledge and is difficult to apply to realistic scenarios with hundreds of entity types. To deal with them, we propose Parallel Instance Query Network (PIQN), which sets up global and learnable instance queries to extract entities from a sentence in a parallel manner. Each instance query predicts one entity, and by feeding all instance queries simultaneously, we can query all entities in parallel. Instead of being constructed from external knowledge, instance queries can learn their different query semantics during training. For training the model, we treat label assignment as a one-to-many Linear Assignment Problem (LAP) and dynamically assign gold entities to instance queries with minimal assignment cost. Experiments on both nested and flat NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2203.10545",
    "authors": [
      "Yongliang Shen",
      "Xiaobin Wang",
      "Zeqi Tan",
      "Guangwei Xu",
      "Pengjun Xie",
      "Fei Huang",
      "Weiming Lu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10552",
    "title": "A Learning Convolutional Neural Network Approach for Network Robustness  Prediction",
    "abstract": "Network robustness is critical for various societal and industrial networks again malicious attacks. In particular, connectivity robustness and controllability robustness reflect how well a networked system can maintain its connectedness and controllability against destructive attacks, which can be quantified by a sequence of values that record the remaining connectivity and controllability of the network after a sequence of node- or edge-removal attacks. Traditionally, robustness is determined by attack simulations, which are computationally very time-consuming or even practically infeasible. In this paper, an improved method for network robustness prediction is developed based on learning feature representation using convolutional neural network (LFR-CNN). In this scheme, higher-dimensional network data are compressed to lower-dimensional representations, and then passed to a CNN to perform robustness prediction. Extensive experimental studies on both synthetic and real-world networks, both directed and undirected, demonstrate that 1) the proposed LFR-CNN performs better than other two state-of-the-art prediction methods, with significantly lower prediction errors; 2) LFR-CNN is insensitive to the variation of the network size, which significantly extends its applicability; 3) although LFR-CNN needs more time to perform feature learning, it can achieve accurate prediction faster than attack simulations; 4) LFR-CNN not only can accurately predict network robustness, but also provides a good indicator for connectivity robustness, better than the classical spectral measures. ",
    "url": "https://arxiv.org/abs/2203.10552",
    "authors": [
      "Yang Lou",
      "Ruizi Wu",
      "Junli Li",
      "Lin Wang",
      "Xiang Li",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.10554",
    "title": "3D Human Pose Estimation Using M\u00f6bius Graph Convolutional Networks",
    "abstract": "3D human pose estimation is fundamental to understanding human behavior. Recently, promising results have been achieved by graph convolutional networks (GCNs), which achieve state-of-the-art performance and provide rather light-weight architectures. However, a major limitation of GCNs is their inability to encode all the transformations between joints explicitly. To address this issue, we propose a novel spectral GCN using the M\\\"obius transformation (M\\\"obiusGCN). In particular, this allows us to directly and explicitly encode the transformation between joints, resulting in a significantly more compact representation. Compared to even the lightest architectures so far, our novel approach requires 90-98% fewer parameters, i.e. our lightest M\\\"obiusGCN uses only 0.042M trainable parameters. Besides the drastic parameter reduction, explicitly encoding the transformation of joints also enables us to achieve state-of-the-art results. We evaluate our approach on the two challenging pose estimation benchmarks, Human3.6M and MPI-INF-3DHP, demonstrating both state-of-the-art results and the generalization capabilities of M\\\"obiusGCN. ",
    "url": "https://arxiv.org/abs/2203.10554",
    "authors": [
      "Niloofar Azizi",
      "Horst Possegger",
      "Emanuele Rodol\u00e0",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10565",
    "title": "LEReg: Empower Graph Neural Networks with Local Energy Regularization",
    "abstract": "Researches on analyzing graphs with Graph Neural Networks (GNNs) have been receiving more and more attention because of the great expressive power of graphs. GNNs map the adjacency matrix and node features to node representations by message passing through edges on each convolution layer. However, the message passed through GNNs is not always beneficial for all parts in a graph. Specifically, as the data distribution is different over the graph, the receptive field (the farthest nodes that a node can obtain information from) needed to gather information is also different. Existing GNNs treat all parts of the graph uniformly, which makes it difficult to adaptively pass the most informative message for each unique part. To solve this problem, we propose two regularization terms that consider message passing locally: (1) Intra-Energy Reg and (2) Inter-Energy Reg. Through experiments and theoretical discussion, we first show that the speed of smoothing of different parts varies enormously and the topology of each part affects the way of smoothing. With Intra-Energy Reg, we strengthen the message passing within each part, which is beneficial for getting more useful information. With Inter-Energy Reg, we improve the ability of GNNs to distinguish different nodes. With the proposed two regularization terms, GNNs are able to filter the most useful information adaptively, learn more robustly and gain higher expressiveness. Moreover, the proposed LEReg can be easily applied to other GNN models with plug-and-play characteristics. Extensive experiments on several benchmarks verify that GNNs with LEReg outperform or match the state-of-the-art methods. The effectiveness and efficiency are also empirically visualized with elaborate experiments. ",
    "url": "https://arxiv.org/abs/2203.10565",
    "authors": [
      "Xiaojun Ma",
      "Hanyue Chen",
      "Guojie Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10568",
    "title": "Accelerating Integrated Task and Motion Planning with Neural Feasibility  Checking",
    "abstract": "As robots play an increasingly important role in the industrial, the expectations about their applications for everyday living tasks are getting higher. Robots need to perform long-horizon tasks that consist of several sub-tasks that need to be accomplished. Task and Motion Planning (TAMP) provides a hierarchical framework to handle the sequential nature of manipulation tasks by interleaving a symbolic task planner that generates a possible action sequence, with a motion planner that checks the kinematic feasibility in the geometric world, generating robot trajectories if several constraints are satisfied, e.g., a collision-free trajectory from one state to another. Hence, the reasoning about the task plan's geometric grounding is taken over by the motion planner. However, motion planning is computationally intense and is usability as feasibility checker casts TAMP methods inapplicable to real-world scenarios. In this paper, we introduce neural feasibility classifier (NFC), a simple yet effective visual heuristic for classifying the feasibility of proposed actions in TAMP. Namely, NFC will identify infeasible actions of the task planner without the need for costly motion planning, hence reducing planning time in multi-step manipulation tasks. NFC encodes the image of the robot's workspace into a feature map thanks to convolutional neural network (CNN). We train NFC using simulated data from TAMP problems and label the instances based on IK feasibility checking. Our empirical results in different simulated manipulation tasks show that our NFC generalizes to the entire robot workspace and has high prediction accuracy even in scenes with multiple obstructions. When combined with state-of-the-art integrated TAMP, our NFC enhances its performance while reducing its planning time. ",
    "url": "https://arxiv.org/abs/2203.10568",
    "authors": [
      "Lei Xu",
      "Tianyu Ren",
      "Georgia Chalvatzaki",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10569",
    "title": "Self-supervised Point Cloud Completion on Real Traffic Scenes via  Scene-concerned Bottom-up Mechanism",
    "abstract": "Real scans always miss partial geometries of objects due to the self-occlusions, external-occlusions, and limited sensor resolutions. Point cloud completion aims to refer the complete shapes for incomplete 3D scans of objects. Current deep learning-based approaches rely on large-scale complete shapes in the training process, which are usually obtained from synthetic datasets. It is not applicable for real-world scans due to the domain gap. In this paper, we propose a self-supervised point cloud completion method (TraPCC) for vehicles in real traffic scenes without any complete data. Based on the symmetry and similarity of vehicles, we make use of consecutive point cloud frames to construct vehicle memory bank as reference. We design a bottom-up mechanism to focus on both local geometry details and global shape features of inputs. In addition, we design a scene-graph in the network to pay attention to the missing parts by the aid of neighboring vehicles. Experiments show that TraPCC achieve good performance for real-scan completion on KITTI and nuScenes traffic datasets even without any complete data in training. We also show a downstream application of 3D detection, which benefits from our completion approach. ",
    "url": "https://arxiv.org/abs/2203.10569",
    "authors": [
      "Yiming Ren",
      "Peishan Cong",
      "Xinge Zhu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10579",
    "title": "Small Batch Sizes Improve Training of Low-Resource Neural MT",
    "abstract": "We study the role of an essential hyper-parameter that governs the training of Transformers for neural machine translation in a low-resource setting: the batch size. Using theoretical insights and experimental evidence, we argue against the widespread belief that batch size should be set as large as allowed by the memory of the GPUs. We show that in a low-resource setting, a smaller batch size leads to higher scores in a shorter training time, and argue that this is due to better regularization of the gradients during training. ",
    "url": "https://arxiv.org/abs/2203.10579",
    "authors": [
      "\u00c0lex R. Atrio",
      "Andrei Popescu-Belis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10593",
    "title": "Open-Vocabulary One-Stage Detection with Hierarchical Visual-Language  Knowledge Distillation",
    "abstract": "Open-vocabulary object detection aims to detect novel object categories beyond the training set. The advanced open-vocabulary two-stage detectors employ instance-level visual-to-visual knowledge distillation to align the visual space of the detector with the semantic space of the Pre-trained Visual-Language Model (PVLM). However, in the more efficient one-stage detector, the absence of class-agnostic object proposals hinders the knowledge distillation on unseen objects, leading to severe performance degradation. In this paper, we propose a hierarchical visual-language knowledge distillation method, i.e., HierKD, for open-vocabulary one-stage detection. Specifically, a global-level knowledge distillation is explored to transfer the knowledge of unseen categories from the PVLM to the detector. Moreover, we combine the proposed global-level knowledge distillation and the common instance-level knowledge distillation to learn the knowledge of seen and unseen categories simultaneously. Extensive experiments on MS-COCO show that our method significantly surpasses the previous best one-stage detector with 11.9\\% and 6.7\\% $AP_{50}$ gains under the zero-shot detection and generalized zero-shot detection settings, and reduces the $AP_{50}$ performance gap from 14\\% to 7.3\\% compared to the best two-stage detector. ",
    "url": "https://arxiv.org/abs/2203.10593",
    "authors": [
      "Zongyang Ma",
      "Guan Luo",
      "Jin Gao",
      "Liang Li",
      "Yuxin Chen",
      "Shaoru Wang",
      "Congxuan Zhang",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10609",
    "title": "Transparency strategy-based data augmentation for BI-RADS classification  of mammograms",
    "abstract": "Image augmentation techniques have been widely investigated to improve the performance of deep learning (DL) algorithms on mammography classification tasks. Recent methods have proved the efficiency of image augmentation on data deficiency or data imbalance issues. In this paper, we propose a novel transparency strategy to boost the Breast Imaging Reporting and Data System (BI-RADS) scores of mammograms classifier. The proposed approach utilizes the Region of Interest (ROI) information to generate more high-risk training examples from original images. Our extensive experiments were conducted on our benchmark mammography dataset. The experiment results show that the proposed approach surpasses current state-of-the-art data augmentation techniques such as Upsampling or CutMix. The study highlights that the transparency method is more effective than other augmentation strategies for BI-RADS classification and can be widely applied for our computer vision tasks. ",
    "url": "https://arxiv.org/abs/2203.10609",
    "authors": [
      "Sam B. Tran",
      "Huyen T. X. Nguyen",
      "Hieu H. Pham",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10610",
    "title": "Towards Large-Scale Interpretable Knowledge Graph Reasoning for Dialogue  Systems",
    "abstract": "Users interacting with voice assistants today need to phrase their requests in a very specific manner to elicit an appropriate response. This limits the user experience, and is partly due to the lack of reasoning capabilities of dialogue platforms and the hand-crafted rules that require extensive labor. One possible way to improve user experience and relieve the manual efforts of designers is to build an end-to-end dialogue system that can do reasoning itself while perceiving user's utterances. In this work, we propose a novel method to incorporate the knowledge reasoning capability into dialogue systems in a more scalable and generalizable manner. Our proposed method allows a single transformer model to directly walk on a large-scale knowledge graph to generate responses. To the best of our knowledge, this is the first work to have transformer models generate responses by reasoning over differentiable knowledge graphs. We investigate the reasoning abilities of the proposed method on both task-oriented and domain-specific chit-chat dialogues. Empirical results show that this method can effectively and efficiently incorporate a knowledge graph into a dialogue system with fully-interpretable reasoning paths. ",
    "url": "https://arxiv.org/abs/2203.10610",
    "authors": [
      "Yi-Lin Tuan",
      "Sajjad Beygi",
      "Maryam Fazel-Zarandi",
      "Qiaozi Gao",
      "Alessandra Cervone",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10611",
    "title": "Learning from Multiple Expert Annotators for Enhancing Anomaly Detection  in Medical Image Analysis",
    "abstract": "Building an accurate computer-aided diagnosis system based on data-driven approaches requires a large amount of high-quality labeled data. In medical imaging analysis, multiple expert annotators often produce subjective estimates about \"ground truth labels\" during the annotation process, depending on their expertise and experience. As a result, the labeled data may contain a variety of human biases with a high rate of disagreement among annotators, which significantly affect the performance of supervised machine learning algorithms. To tackle this challenge, we propose a simple yet effective approach to combine annotations from multiple radiology experts for training a deep learning-based detector that aims to detect abnormalities on medical scans. The proposed method first estimates the ground truth annotations and confidence scores of training examples. The estimated annotations and their scores are then used to train a deep learning detector with a re-weighted loss function to localize abnormal findings. We conduct an extensive experimental evaluation of the proposed approach on both simulated and real-world medical imaging datasets. The experimental results show that our approach significantly outperforms baseline approaches that do not consider the disagreements among annotators, including methods in which all of the noisy annotations are treated equally as ground truth and the ensemble of different models trained on different label sets provided separately by annotators. ",
    "url": "https://arxiv.org/abs/2203.10611",
    "authors": [
      "Khiem H. Le",
      "Tuan V. Tran",
      "Hieu H. Pham",
      "Hieu T. Nguyen",
      "Tung T. Le",
      "Ha Q. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10614",
    "title": "Does DQN really learn? Exploring adversarial training schemes in Pong",
    "abstract": "In this work, we study two self-play training schemes, Chainer and Pool, and show they lead to improved agent performance in Atari Pong compared to a standard DQN agent -- trained against the built-in Atari opponent. To measure agent performance, we define a robustness metric that captures how difficult it is to learn a strategy that beats the agent's learned policy. Through playing past versions of themselves, Chainer and Pool are able to target weaknesses in their policies and improve their resistance to attack. Agents trained using these methods score well on our robustness metric and can easily defeat the standard DQN agent. We conclude by using linear probing to illuminate what internal structures the different agents develop to play the game. We show that training agents with Chainer or Pool leads to richer network activations with greater predictive power to estimate critical game-state features compared to the standard DQN agent. ",
    "url": "https://arxiv.org/abs/2203.10614",
    "authors": [
      "Bowen He",
      "Sreehari Rammohan",
      "Jessica Forde",
      "Michael Littman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10620",
    "title": "Differentiable Reasoning over Long Stories -- Assessing Systematic  Generalisation in Neural Models",
    "abstract": "Contemporary neural networks have achieved a series of developments and successes in many aspects; however, when exposed to data outside the training distribution, they may fail to predict correct answers. In this work, we were concerned about this generalisation issue and thus analysed a broad set of models systematically and robustly over long stories. Related experiments were conducted based on the CLUTRR, which is a diagnostic benchmark suite that can analyse generalisation of natural language understanding (NLU) systems by training over small story graphs and testing on larger ones. In order to handle the multi-relational story graph, we consider two classes of neural models: \"E-GNN\", the graph-based models that can process graph-structured data and consider the edge attributes simultaneously; and \"L-Graph\", the sequence-based models which can process linearized version of the graphs. We performed an extensive empirical evaluation, and we found that the modified recurrent neural network yield surprisingly accurate results across every systematic generalisation tasks which outperform the modified graph neural network, while the latter produced more robust models. ",
    "url": "https://arxiv.org/abs/2203.10620",
    "authors": [
      "Wanshui Li",
      "Pasquale Minervini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10626",
    "title": "Automated Detection of Acute Promyelocytic Leukemia in Blood Films and  Bone Marrow Aspirates with Annotation-free Deep Learning",
    "abstract": "While optical microscopy inspection of blood films and bone marrow aspirates by a hematologist is a crucial step in establishing diagnosis of acute leukemia, especially in low-resource settings where other diagnostic modalities might not be available, the task remains time-consuming and prone to human inconsistencies. This has an impact especially in cases of Acute Promyelocytic Leukemia (APL) that require urgent treatment. Integration of automated computational hematopathology into clinical workflows can improve the throughput of these services and reduce cognitive human error. However, a major bottleneck in deploying such systems is a lack of sufficient cell morphological object-labels annotations to train deep learning models. We overcome this by leveraging patient diagnostic labels to train weakly-supervised models that detect different types of acute leukemia. We introduce a deep learning approach, Multiple Instance Learning for Leukocyte Identification (MILLIE), able to perform automated reliable analysis of blood films with minimal supervision. Without being trained to classify individual cells, MILLIE differentiates between acute lymphoblastic and myeloblastic leukemia in blood films. More importantly, MILLIE detects APL in blood films (AUC 0.94+/-0.04) and in bone marrow aspirates (AUC 0.99+/-0.01). MILLIE is a viable solution to augment the throughput of clinical pathways that require assessment of blood film microscopy. ",
    "url": "https://arxiv.org/abs/2203.10626",
    "authors": [
      "Petru Manescu",
      "Priya Narayanan",
      "Christopher Bendkowski",
      "Muna Elmi",
      "Remy Claveau",
      "Vijay Pawar",
      "Biobele J. Brown",
      "Mike Shaw",
      "Anupama Rao",
      "Delmiro Fernandez-Reyes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10627",
    "title": "Enriching Unsupervised User Embedding via Medical Concepts",
    "abstract": "Clinical notes in Electronic Health Records (EHR) present rich documented information of patients to inference phenotype for disease diagnosis and study patient characteristics for cohort selection. Unsupervised user embedding aims to encode patients into fixed-length vectors without human supervisions. Medical concepts extracted from the clinical notes contain rich connections between patients and their clinical categories. However, existing unsupervised approaches of user embeddings from clinical notes do not explicitly incorporate medical concepts. In this study, we propose a concept-aware unsupervised user embedding that jointly leverages text documents and medical concepts from two clinical corpora, MIMIC-III and Diabetes. We evaluate user embeddings on both extrinsic and intrinsic tasks, including phenotype classification, in-hospital mortality prediction, patient retrieval, and patient relatedness. Experiments on the two clinical corpora show our approach exceeds unsupervised baselines, and incorporating medical concepts can significantly improve the baseline performance. ",
    "url": "https://arxiv.org/abs/2203.10627",
    "authors": [
      "Xiaolei Huang",
      "Franck Dernoncourt",
      "Mark Dredze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10630",
    "title": "Red Domination in Perfect Elimination Bipartite Graphs",
    "abstract": "The $k$ red domination problem for a bipartite graph $G=(X,Y,E)$ is to find a subset $D \\subseteq X$ of cardinality at most $k$ that dominates vertices of $Y$. The decision version of this problem is NP-complete for general bipartite graphs but solvable in polynomial time for chordal bipartite graphs. We strengthen that result by showing that it is NP-complete for perfect elimination bipartite graphs. We present a tight upper bound on the number of such sets in bipartite graphs, and show that we can calculate that number in linear time for convex bipartite graphs. We present a linear space linear delay enumeration algorithm that needs only linear preprocessing time. ",
    "url": "https://arxiv.org/abs/2203.10630",
    "authors": [
      "Nesrine Abbas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.10642",
    "title": "FUTR3D: A Unified Sensor Fusion Framework for 3D Detection",
    "abstract": "Sensor fusion is an essential topic in many perception systems, such as autonomous driving and robotics. Existing multi-modal 3D detection models usually involve customized designs depending on the sensor combinations or setups. In this work, we propose the first unified end-to-end sensor fusion framework for 3D detection, named FUTR3D, which can be used in (almost) any sensor configuration. FUTR3D employs a query-based Modality-Agnostic Feature Sampler (MAFS), together with a transformer decoder with a set-to-set loss for 3D detection, thus avoiding using late fusion heuristics and post-processing tricks. We validate the effectiveness of our framework on various combinations of cameras, low-resolution LiDARs, high-resolution LiDARs, and Radars. On NuScenes dataset, FUTR3D achieves better performance over specifically designed methods across different sensor combinations. Moreover, FUTR3D achieves great flexibility with different sensor configurations and enables low-cost autonomous driving. For example, only using a 4-beam LiDAR with cameras, FUTR3D (56.8 mAP) achieves on par performance with state-of-the-art 3D detection model CenterPoint (56.6 mAP) using a 32-beam LiDAR. ",
    "url": "https://arxiv.org/abs/2203.10642",
    "authors": [
      "Xuanyao Chen",
      "Tianyuan Zhang",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10645",
    "title": "Breast Cancer Induced Bone Osteolysis Prediction Using Temporal  Variational Auto-Encoders",
    "abstract": "Objective and Impact Statement. We adopt a deep learning model for bone osteolysis prediction on computed tomography (CT) images of murine breast cancer bone metastases. Given the bone CT scans at previous time steps, the model incorporates the bone-cancer interactions learned from the sequential images and generates future CT images. Its ability of predicting the development of bone lesions in cancer-invading bones can assist in assessing the risk of impending fractures and choosing proper treatments in breast cancer bone metastasis. Introduction. Breast cancer often metastasizes to bone, causes osteolytic lesions, and results in skeletal related events (SREs) including severe pain and even fatal fractures. Although current imaging techniques can detect macroscopic bone lesions, predicting the occurrence and progression of bone lesions remains a challenge. Methods. We adopt a temporal variational auto-encoder (T-VAE) model that utilizes a combination of variational auto-encoders and long short-term memory networks to predict bone lesion emergence on our micro-CT dataset containing sequential images of murine tibiae. Given the CT scans of murine tibiae at early weeks, our model can learn the distribution of their future states from data. Results. We test our model against other deep learning-based prediction models on the bone lesion progression prediction task. Our model produces much more accurate predictions than existing models under various evaluation metrics. Conclusion. We develop a deep learning framework that can accurately predict and visualize the progression of osteolytic bone lesions. It will assist in planning and evaluating treatment strategies to prevent SREs in breast cancer patients. ",
    "url": "https://arxiv.org/abs/2203.10645",
    "authors": [
      "Wei Xiong",
      "Neil Yeung",
      "Shubo Wang",
      "Haofu Liao",
      "Liyun Wang",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10647",
    "title": "A Framework for Automating Deployment and Evaluation of Blockchain  Network",
    "abstract": "Blockchain network deployment and evaluation have become prevalent due to the demand for private blockchains by enterprises, governments, and edge computing systems. Whilst a blockchain network's deployment and evaluation are driven by its architecture, practitioners still need to learn and carry out many repetitive and error-prone activities to transform architecture into an operational blockchain network and evaluate it. Greater efficiency could be gained if practitioners focus solely on the architecture design, a valuable and hard-to-automate activity, and leave the implementation steps to an automation framework. This paper proposes an automation framework called NVAL (Network Deployment and Evaluation Framework), which can deploy and evaluate blockchain networks based on their architecture specifications. The key idea of NVAL is reusing and combining the existing automation scripts and utilities of various blockchain types to deploy and evaluate incoming blockchain network architectures. We propose a novel meta-model to capture blockchain network architectures as computer-readable artefacts and employ a state-space search approach to plan and conduct their deployment and evaluation. An evaluative case study shows that NVAL successfully combines seven deployment and evaluation procedures to deploy 65 networks with 12 different architectures and generate 295 evaluation datasets whilst incurring a negligible processing time overhead. ",
    "url": "https://arxiv.org/abs/2203.10647",
    "authors": [
      "Nguyen Khoi Tran",
      "M. Ali Babar",
      "Andrew Walters"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.10670",
    "title": "Fully Convolutional Fractional Scaling",
    "abstract": "We introduce a fully convolutional fractional scaling component, FCFS. Fully convolutional networks can be applied to any size input and previously did not support non-integer scaling. Our architecture is simple with an efficient single layer implementation. Examples and code implementations of three common scaling methods are published. ",
    "url": "https://arxiv.org/abs/2203.10670",
    "authors": [
      "Michael Soloveitchik",
      "Michael Werman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10675",
    "title": "Mitigating Gender Bias in Machine Translation through Adversarial  Learning",
    "abstract": "Machine translation and other NLP systems often contain significant biases regarding sensitive attributes, such as gender or race, that worsen system performance and perpetuate harmful stereotypes. Recent preliminary research suggests that adversarial learning can be used as part of a model-agnostic bias mitigation method that requires no data modifications. However, adapting this strategy for machine translation and other modern NLP domains requires (1) restructuring training objectives in the context of fine-tuning pretrained large language models and (2) developing measures for gender or other protected variables for tasks in which these attributes must be deduced from the data itself. We present an adversarial learning framework that addresses these challenges to mitigate gender bias in seq2seq machine translation. Our framework improves the disparity in translation quality for sentences with male vs. female entities by 86% for English-German translation and 91% for English-French translation, with minimal effect on translation quality. The results suggest that adversarial learning is a promising technique for mitigating gender bias in machine translation. ",
    "url": "https://arxiv.org/abs/2203.10675",
    "authors": [
      "Eve Fleisig",
      "Christiane Fellbaum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10692",
    "title": "Better Language Model with Hypernym Class Prediction",
    "abstract": "Class-based language models (LMs) have been long devised to address context sparsity in $n$-gram LMs. In this study, we revisit this approach in the context of neural LMs. We hypothesize that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words. We map words that have a common WordNet hypernym to the same class and train large neural LMs by gradually annealing from predicting the class to token prediction during training. Empirically, this curriculum learning strategy consistently improves perplexity over various large, highly-performant state-of-the-art Transformer-based models on two datasets, WikiText-103 and Arxiv. Our analysis shows that the performance improvement is achieved without sacrificing performance on rare words. Finally, we document other attempts that failed to yield empirical gains, and discuss future directions for the adoption of class-based LMs on a larger scale. ",
    "url": "https://arxiv.org/abs/2203.10692",
    "authors": [
      "He Bai",
      "Tong Wang",
      "Alessandro Sordoni",
      "Peng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10693",
    "title": "Leveraging Expert Guided Adversarial Augmentation For Improving  Generalization in Named Entity Recognition",
    "abstract": "Named Entity Recognition (NER) systems often demonstrate great performance on in-distribution data, but perform poorly on examples drawn from a shifted distribution. One way to evaluate the generalization ability of NER models is to use adversarial examples, on which the specific variations associated with named entities are rarely considered. To this end, we propose leveraging expert-guided heuristics to change the entity tokens and their surrounding contexts thereby altering their entity types as adversarial attacks. Using expert-guided heuristics, we augmented the CoNLL 2003 test set and manually annotated it to construct a high-quality challenging set. We found that state-of-the-art NER systems trained on CoNLL 2003 training data drop performance dramatically on our challenging set. By training on adversarial augmented training examples and using mixup for regularization, we were able to significantly improve the performance on the challenging set as well as improve out-of-domain generalization which we evaluated by using OntoNotes data. We have publicly released our dataset and code at https://github.com/GT-SALT/Guided-Adversarial-Augmentation. ",
    "url": "https://arxiv.org/abs/2203.10693",
    "authors": [
      "Aaron Reich",
      "Jiaao Chen",
      "Aastha Agrawal",
      "Yanzhe Zhang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10699",
    "title": "HP-Capsule: Unsupervised Face Part Discovery by Hierarchical Parsing  Capsule Network",
    "abstract": "Capsule networks are designed to present the objects by a set of parts and their relationships, which provide an insight into the procedure of visual perception. Although recent works have shown the success of capsule networks on simple objects like digits, the human faces with homologous structures, which are suitable for capsules to describe, have not been explored. In this paper, we propose a Hierarchical Parsing Capsule Network (HP-Capsule) for unsupervised face subpart-part discovery. When browsing large-scale face images without labels, the network first encodes the frequently observed patterns with a set of explainable subpart capsules. Then, the subpart capsules are assembled into part-level capsules through a Transformer-based Parsing Module (TPM) to learn the compositional relations between them. During training, as the face hierarchy is progressively built and refined, the part capsules adaptively encode the face parts with semantic consistency. HP-Capsule extends the application of capsule networks from digits to human faces and takes a step forward to show how the neural networks understand homologous objects without human intervention. Besides, HP-Capsule gives unsupervised face segmentation results by the covered regions of part capsules, enabling qualitative and quantitative evaluation. Experiments on BP4D and Multi-PIE datasets show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2203.10699",
    "authors": [
      "Chang Yu",
      "Xiangyu Zhu",
      "Xiaomei Zhang",
      "Zidu Wang",
      "Zhaoxiang Zhang",
      "Zhen Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10707",
    "title": "Monocular Vision-based Prediction of Cut-in Maneuvers with LSTM Networks",
    "abstract": "Advanced driver assistance and automated driving systems should be capable of predicting and avoiding dangerous situations. This study proposes a method to predict potentially dangerous cut-in maneuvers happening in the ego lane. We follow a computer vision-based approach that only employs a single in-vehicle RGB camera, and we classify the target vehicle's maneuver based on the recent video frames. Our algorithm consists of a CNN-based vehicle detection and tracking step and an LSTM-based maneuver classification step. It is more computationally efficient than other vision-based methods since it exploits a small number of features for the classification step rather than feeding CNNs with RGB frames. We evaluated our approach on a publicly available driving dataset and a lane change detection dataset. We obtained 0.9585 accuracy with side-aware two-class (cut-in vs. lane-pass) classification models. Experiment results also reveal that our approach outperforms state-of-the-art approaches when used for lane change detection. ",
    "url": "https://arxiv.org/abs/2203.10707",
    "authors": [
      "Yagiz Nalcakan",
      "Yalin Bastanlar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10714",
    "title": "A Prompting-based Approach for Adversarial Example Generation and  Robustness Enhancement",
    "abstract": "Recent years have seen the wide application of NLP models in crucial areas such as finance, medical treatment, and news media, raising concerns of the model robustness and vulnerabilities. In this paper, we propose a novel prompt-based adversarial attack to compromise NLP models and robustness enhancement technique. We first construct malicious prompts for each instance and generate adversarial examples via mask-and-filling under the effect of a malicious purpose. Our attack technique targets the inherent vulnerabilities of NLP models, allowing us to generate samples even without interacting with the victim NLP model, as long as it is based on pre-trained language models (PLMs). Furthermore, we design a prompt-based adversarial training method to improve the robustness of PLMs. As our training method does not actually generate adversarial samples, it can be applied to large-scale training sets efficiently. The experimental results show that our attack method can achieve a high attack success rate with more diverse, fluent and natural adversarial examples. In addition, our robustness enhancement method can significantly improve the robustness of models to resist adversarial attacks. Our work indicates that prompting paradigm has great potential in probing some fundamental flaws of PLMs and fine-tuning them for downstream tasks. ",
    "url": "https://arxiv.org/abs/2203.10714",
    "authors": [
      "Yuting Yang",
      "Pei Huang",
      "Juan Cao",
      "Jintao Li",
      "Yun Lin",
      "Jin Song Dong",
      "Feifei Ma",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10718",
    "title": "Prediction Algorithm for Heat Demand of Science and Technology Topics  Based on Time Convolution Network",
    "abstract": "Thanks to the rapid development of deep learning, big data analysis technology is not only widely used in the field of natural language processing, but also more mature in the field of numerical prediction. It is of great significance for the subject heat prediction and analysis of science and technology demand data. How to apply theme features to accurately predict the theme heat of science and technology demand is the core to solve this problem. In this paper, a prediction method of subject heat of science and technology demand based on time convolution network (TCN) is proposed to obtain the subject feature representation of science and technology demand. Time series prediction is carried out based on TCN network and self attention mechanism, which increases the accuracy of subject heat prediction of science and technology demand data Experiments show that the prediction accuracy of this algorithm is better than other time series prediction methods on the real science and technology demand datasets. ",
    "url": "https://arxiv.org/abs/2203.10718",
    "authors": [
      "Cui Haiyan",
      "Li Yawen",
      "Xu Xin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10723",
    "title": "An Intermediate-level Attack Framework on The Basis of Linear Regression",
    "abstract": "This paper substantially extends our work published at ECCV, in which an intermediate-level attack was proposed to improve the transferability of some baseline adversarial examples. We advocate to establish a direct linear mapping from the intermediate-level discrepancies (between adversarial features and benign features) to classification prediction loss of the adversarial example. In this paper, we delve deep into the core components of such a framework by performing comprehensive studies and extensive experiments. We show that 1) a variety of linear regression models can all be considered in order to establish the mapping, 2) the magnitude of the finally obtained intermediate-level discrepancy is linearly correlated with adversarial transferability, 3) further boost of the performance can be achieved by performing multiple runs of the baseline attack with random initialization. By leveraging these findings, we achieve new state-of-the-arts on transfer-based $\\ell_\\infty$ and $\\ell_2$ attacks. ",
    "url": "https://arxiv.org/abs/2203.10723",
    "authors": [
      "Yiwen Guo",
      "Qizhang Li",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.10731",
    "title": "Research Scholar Interest Mining Method based on Load Centrality",
    "abstract": "In the era of big data, it is possible to carry out cooperative research on the research results of researchers through papers, patents and other data, so as to study the role of researchers, and produce results in the analysis of results. For the important problems found in the research and application of reality, this paper also proposes a research scholar interest mining algorithm based on load centrality (LCBIM), which can accurately solve the problem according to the researcher's research papers and patent data. Graphs of creative algorithms in various fields of the study aggregated ideas, generated topic graphs by aggregating neighborhoods, used the generated topic information to construct with similar or similar topic spaces, and utilize keywords to construct one or more topics. The regional structure of each topic can be used to closely calculate the weight of the centrality research model of the node, which can analyze the field in the complete coverage principle. The scientific research cooperation based on the load rate center proposed in this paper can effectively extract the interests of scientific research scholars from papers and corpus. ",
    "url": "https://arxiv.org/abs/2203.10731",
    "authors": [
      "Yang Jiang",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10734",
    "title": "Defending against Co-residence Attack in Energy-Efficient Cloud: An  Optimization based Real-time Secure VM Allocation Strategy",
    "abstract": "Resource sharing among users serves as the foundation of cloud computing, which, however, may also cause vulnerabilities to diverse co-residence attacks launched by malicious virtual machines (VM) residing in the same physical server with the victim VMs. In this paper, we aim to defend against such co-residence attacks through a secure, workload-balanced, and energy-efficient VM allocation strategy. Specifically, we model the problem as an optimization problem by quantifying and minimizing three key factors: (1) the security risks, (2) the power consumption and (3) the unbalanced workloads among different physical servers. Furthermore, this work considers a realistic environmental setting by assuming a random number of VMs from different users arriving at random timings, which requires the optimization solution to be continuously evolving. As the optimization problem is NP-hard, we propose to first cluster VMs in time windows, and further adopt the Ant Colony Optimization (ACO) algorithm to identify the optimal allocation strategy for each time window. Comprehensive experimental results based on real world cloud traces validates the effectiveness of the proposed scheme. ",
    "url": "https://arxiv.org/abs/2203.10734",
    "authors": [
      "Lu Cao",
      "Ruiwen Li",
      "Xiaojun Ruan",
      "Yuhong Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.10736",
    "title": "The activity-weight duality in feed forward neural networks: The  geometric determinants of generalization",
    "abstract": "One of the fundamental problems in machine learning is generalization. In neural network models with a large number of weights (parameters), many solutions can be found to fit the training data equally well. The key question is which solution can describe testing data not in the training set. Here, we report the discovery of an exact duality (equivalence) between changes in activities in a given layer of neurons and changes in weights that connect to the next layer of neurons in a densely connected layer in any feed forward neural network. The activity-weight (A-W) duality allows us to map variations in inputs (data) to variations of the corresponding dual weights. By using this mapping, we show that the generalization loss can be decomposed into a sum of contributions from different eigen-directions of the Hessian matrix of the loss function at the solution in weight space. The contribution from a given eigen-direction is the product of two geometric factors (determinants): the sharpness of the loss landscape and the standard deviation of the dual weights, which is found to scale with the weight norm of the solution. Our results provide an unified framework, which we used to reveal how different regularization schemes (weight decay, stochastic gradient descent with different batch sizes and learning rates, dropout), training data size, and labeling noise affect generalization performance by controlling either one or both of these two geometric determinants for generalization. These insights can be used to guide development of algorithms for finding more generalizable solutions in overparametrized neural networks. ",
    "url": "https://arxiv.org/abs/2203.10736",
    "authors": [
      "Yu Feng",
      "Yuhai Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.10744",
    "title": "Programming Language Agnostic Mining of Code and Language Pairs with  Sequence Labeling Based Question Answering",
    "abstract": "Mining aligned natural language (NL) and programming language (PL) pairs is a critical task to NL-PL understanding. Existing methods applied specialized hand-crafted features or separately-trained models for each PL. However, they usually suffered from low transferability across multiple PLs, especially for niche PLs with less annotated data. Fortunately, a Stack Overflow answer post is essentially a sequence of text and code blocks and its global textual context can provide PL-agnostic supplementary information. In this paper, we propose a Sequence Labeling based Question Answering (SLQA) method to mine NL-PL pairs in a PL-agnostic manner. In particular, we propose to apply the BIO tagging scheme instead of the conventional binary scheme to mine the code solutions which are often composed of multiple blocks of a post. Experiments on current single-PL single-block benchmarks and a manually-labeled cross-PL multi-block benchmark prove the effectiveness and transferability of SLQA. We further present a parallel NL-PL corpus named Lang2Code automatically mined with SLQA, which contains about 1.4M pairs on 6 PLs. Under statistical analysis and downstream evaluation, we demonstrate that Lang2Code is a large-scale high-quality data resource for further NL-PL research. ",
    "url": "https://arxiv.org/abs/2203.10744",
    "authors": [
      "Changran Hu",
      "Akshara Reddi Methukupalli",
      "Yutong Zhou",
      "Chen Wu",
      "Yubo Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2203.10747",
    "title": "EAutoDet: Efficient Architecture Search for Object Detection",
    "abstract": "Training CNN for detection is time-consuming due to the large dataset and complex network modules, making it hard to search architectures on detection datasets directly, which usually requires vast search costs (usually tens and even hundreds of GPU-days). In contrast, this paper introduces an efficient framework, named EAutoDet, that can discover practical backbone and FPN architectures for object detection in 1.4 GPU-days. Specifically, we construct a supernet for both backbone and FPN modules and adopt the differentiable method. To reduce the GPU memory requirement and computational cost, we propose a kernel reusing technique by sharing the weights of candidate operations on one edge and consolidating them into one convolution. A dynamic channel refinement strategy is also introduced to search channel numbers. Extensive experiments show significant efficacy and efficiency of our method. In particular, the discovered architectures surpass state-of-the-art object detection NAS methods and achieve 40.1 mAP with 120 FPS and 49.2 mAP with 41.3 FPS on COCO test-dev set. We also transfer the discovered architectures to rotation detection task, which achieve 77.05 mAP$_{\\text{50}}$ on DOTA-v1.0 test set with 21.1M parameters. ",
    "url": "https://arxiv.org/abs/2203.10747",
    "authors": [
      "Xiaoxing Wang",
      "Jiale Lin",
      "Junchi Yan",
      "Juanping Zhao",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10749",
    "title": "STCGAT: Spatial-temporal causal networks for complex urban road traffic  flow prediction",
    "abstract": "Traffic forecasting is an essential component of intelligent transportation systems. However, traffic data are highly nonlinear and have complex spatial correlations between road nodes. Therefore, it is incredibly challenging to dig deeper into the underlying Spatial-temporal relationships from the complex traffic data. Existing approaches usually use fixed traffic road network topology maps and independent time series modules to capture Spatial-temporal correlations, ignoring the dynamic changes of traffic road networks and the inherent temporal causal relationships between traffic events. Therefore, a new prediction model is proposed in this study. The model dynamically captures the spatial dependence of the traffic network through a Graph Attention Network(GAT) and then analyzes the causal relationship of the traffic data using our proposed Causal Temporal Convolutional Network(CTCN) to obtain the overall temporal dependence. We conducted extensive comparison experiments with other traffic prediction methods on two real traffic datasets to evaluate the model's prediction performance. Compared with the best experimental results of different prediction methods, the prediction performance of our approach is improved by more than 50%. You can get our source code and data through https://github.com/zhangshqii/STCGAT. ",
    "url": "https://arxiv.org/abs/2203.10749",
    "authors": [
      "Wei Zhao",
      "Shiqi Zhang",
      "Bing Zhou",
      "Bei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10763",
    "title": "Performance-Robustness Tradeoffs in Adversarially Robust  Linear-Quadratic Control",
    "abstract": "While $\\mathcal{H}_\\infty$ methods can introduce robustness against worst-case perturbations, their nominal performance under conventional stochastic disturbances is often drastically reduced. Though this fundamental tradeoff between nominal performance and robustness is known to exist, it is not well-characterized in quantitative terms. Toward addressing this issue, we borrow from the increasingly ubiquitous notion of adversarial training from machine learning to construct a class of controllers which are optimized for disturbances consisting of mixed stochastic and worst-case components. We find that this problem admits a stationary optimal controller that has a simple analytic form closely related to suboptimal $\\mathcal{H}_\\infty$ solutions. We then provide a quantitative performance-robustness tradeoff analysis, in which system-theoretic properties such as controllability and stability explicitly manifest in an interpretable manner. This provides practitioners with general guidance for determining how much robustness to incorporate based on a priori system knowledge. We empirically validate our results by comparing the performance of our controller against standard baselines, and plotting tradeoff curves. ",
    "url": "https://arxiv.org/abs/2203.10763",
    "authors": [
      "Bruce D. Lee",
      "Thomas T.C.K. Zhang",
      "Hamed Hassani",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.10768",
    "title": "Upsampling Autoencoder for Self-Supervised Point Cloud Learning",
    "abstract": "In computer-aided design (CAD) community, the point cloud data is pervasively applied in reverse engineering, where the point cloud analysis plays an important role. While a large number of supervised learning methods have been proposed to handle the unordered point clouds and demonstrated their remarkable success, their performance and applicability are limited to the costly data annotation. In this work, we propose a novel self-supervised pretraining model for point cloud learning without human annotations, which relies solely on upsampling operation to perform feature learning of point cloud in an effective manner. The key premise of our approach is that upsampling operation encourages the network to capture both high-level semantic information and low-level geometric information of the point cloud, thus the downstream tasks such as classification and segmentation will benefit from the pre-trained model. Specifically, our method first conducts the random subsampling from the input point cloud at a low proportion e.g., 12.5%. Then, we feed them into an encoder-decoder architecture, where an encoder is devised to operate only on the subsampled points, along with a upsampling decoder is adopted to reconstruct the original point cloud based on the learned features. Finally, we design a novel joint loss function which enforces the upsampled points to be similar with the original point cloud and uniformly distributed on the underlying shape surface. By adopting the pre-trained encoder weights as initialisation of models for downstream tasks, we find that our UAE outperforms previous state-of-the-art methods in shape classification, part segmentation and point cloud upsampling tasks. Code will be made publicly available upon acceptance. ",
    "url": "https://arxiv.org/abs/2203.10768",
    "authors": [
      "Cheng Zhang",
      "Jian Shi",
      "Xuan Deng",
      "Zizhao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10771",
    "title": "Intelligent control of a single-link flexible manipulator using sliding  modes and artificial neural networks",
    "abstract": "This letter presents a new intelligent control scheme for the accurate trajectory tracking of flexible link manipulators. The proposed approach is mainly based on a sliding mode controller for underactuated systems with an embedded artificial neural network to deal with modeling inaccuracies. The adopted neural network only needs a single input and one hidden layer, which drastically reduces the computational complexity of the control law and allows its implementation in low-power microcontrollers. Online learning, rather than supervised offline training, is chosen to allow the weights of the neural network to be adjusted in real time during the tracking. Therefore, the resulting controller is able to cope with the underactuating issues and to adapt itself by learning from experience, which grants the capacity to deal with plant dynamics properly. The boundedness and convergence properties of the tracking error are proved by evoking Barbalat's lemma in a Lyapunov-like stability analysis. Experimental results obtained with a small single-link flexible manipulator show the efficacy of the proposed control scheme, even in the presence of a high level of uncertainty and noisy signals. ",
    "url": "https://arxiv.org/abs/2203.10771",
    "authors": [
      "Gabriel da Silva Lima",
      "Diego Rolim Porto",
      "Adilson Jose de Oliveira",
      "Wallace Moreira Bessa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.10778",
    "title": "Delving into the Estimation Shift of Batch Normalization in a Network",
    "abstract": "Batch normalization (BN) is a milestone technique in deep learning. It normalizes the activation using mini-batch statistics during training but the estimated population statistics during inference. This paper focuses on investigating the estimation of population statistics. We define the estimation shift magnitude of BN to quantitatively measure the difference between its estimated population statistics and expected ones. Our primary observation is that the estimation shift can be accumulated due to the stack of BN in a network, which has detriment effects for the test performance. We further find a batch-free normalization (BFN) can block such an accumulation of estimation shift. These observations motivate our design of XBNBlock that replace one BN with BFN in the bottleneck block of residual-style networks. Experiments on the ImageNet and COCO benchmarks show that XBNBlock consistently improves the performance of different architectures, including ResNet and ResNeXt, by a significant margin and seems to be more robust to distribution shift. ",
    "url": "https://arxiv.org/abs/2203.10778",
    "authors": [
      "Lei Huang",
      "Yi Zhou",
      "Tian Wang",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10785",
    "title": "GroupTransNet: Group Transformer Network for RGB-D Salient Object  Detection",
    "abstract": "Salient object detection on RGB-D images is an active topic in computer vision. Although the existing methods have achieved appreciable performance, there are still some challenges. The locality of convolutional neural network requires that the model has a sufficiently deep global receptive field, which always leads to the loss of local details. To address the challenge, we propose a novel Group Transformer Network (GroupTransNet) for RGB-D salient object detection. This method is good at learning the long-range dependencies of cross layer features to promote more perfect feature expression. At the beginning, the features of the slightly higher classes of the middle three levels and the latter three levels are soft grouped to absorb the advantages of the high-level features. The input features are repeatedly purified and enhanced by the attention mechanism to purify the cross modal features of color modal and depth modal. The features of the intermediate process are first fused by the features of different layers, and then processed by several transformers in multiple groups, which not only makes the size of the features of each scale unified and interrelated, but also achieves the effect of sharing the weight of the features within the group. The output features in different groups complete the clustering staggered by two owing to the level difference, and combine with the low-level features. Extensive experiments demonstrate that GroupTransNet outperforms the comparison models and achieves the new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2203.10785",
    "authors": [
      "Xian Fang",
      "Jinshao Zhu",
      "Xiuli Shao",
      "Hongpeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10793",
    "title": "Phase-Aware Spoof Speech Detection Based on Res2Net with Phase Network",
    "abstract": "The spoof speech detection (SSD) is the essential countermeasure for automatic speaker verification systems. Although SSD with magnitude features in the frequency domain has shown promising results, the phase information also can be important to capture the artefacts of certain types of spoofing attacks. Thus, both magnitude and phase features must be considered to ensure the generalization ability to diverse types of spoofing attacks. In this paper, we investigate the failure reason of feature-level fusion of the previous works through the entropy analysis from which we found that the randomness difference between magnitude and phase features is large, which can interrupt the feature-level fusion via backend neural network; thus, we propose a phase network to reduce that difference. Our SSD system: phase network equipped Res2Net achieved significant performance improvement, specifically in the spoofing attack for which the phase information is considered to be important. Also, we demonstrate our SSD system in both known- and unknown-kind SSD scenarios for practical applications. ",
    "url": "https://arxiv.org/abs/2203.10793",
    "authors": [
      "Juntae Kim",
      "Sung Min Ban"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.10796",
    "title": "Effective Token Graph Modeling using a Novel Labeling Strategy for  Structured Sentiment Analysis",
    "abstract": "The state-of-the-art model for structured sentiment analysis casts the task as a dependency parsing problem, which has some limitations: (1) The label proportions for span prediction and span relation prediction are imbalanced. (2) The span lengths of sentiment tuple components may be very large in this task, which will further exacerbate the imbalance problem. (3) Two nodes in a dependency graph cannot have multiple arcs, therefore some overlapped sentiment tuples cannot be recognized. In this work, we propose nichetargeting solutions for these issues. First, we introduce a novel labeling strategy, which contains two sets of token pair labels, namely essential label set and whole label set. The essential label set consists of the basic labels for this task, which are relatively balanced and applied in the prediction layer. The whole label set includes rich labels to help our model capture various token relations, which are applied in the hidden layer to softly influence our model. Moreover, we also propose an effective model to well collaborate with our labeling strategy, which is equipped with the graph attention networks to iteratively refine token representations, and the adaptive multi-label classifier to dynamically predict multiple relations between token pairs. We perform extensive experiments on 5 benchmark datasets in four languages. Experimental results show that our model outperforms previous SOTA models by a large margin. ",
    "url": "https://arxiv.org/abs/2203.10796",
    "authors": [
      "Wenxuan Shi",
      "Fei Li",
      "Jingye Li",
      "Hao Fei",
      "Donghong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10800",
    "title": "Graph Neural Networks for Wireless Communications: From Theory to  Practice",
    "abstract": "Deep learning-based approaches have been developed to solve challenging problems in wireless communications, leading to promising results. Early attempts adopted neural network architectures inherited from applications such as computer vision. They often require huge amounts of training samples (i.e., poor generalization), and yield poor performance in large-scale networks (i.e., poor scalability). To resolve these issues, graph neural networks (GNNs) have been recently adopted, as they can effectively exploit the domain knowledge, i.e., the graph topology in wireless communication problems. GNN-based methods can achieve near-optimal performance in large-scale networks and generalize well under different system settings, but the theoretical underpinnings and design guidelines remain elusive, which may hinder their practical implementations. This paper endeavors to fill both the theoretical and practical gaps. For theoretical guarantees, we prove that GNNs achieve near-optimal performance in wireless networks with much fewer training samples than traditional neural architectures. Specifically, to solve an optimization problem on an $n$-node graph (where the nodes may represent users, base stations, or antennas), GNNs' generalization error and required number of training samples are $\\mathcal{O}(n)$ and $\\mathcal{O}(n^2)$ times lower than the unstructured multi-layer perceptrons. For design guidelines, we propose a unified framework that is applicable to general design problems in wireless networks, which includes graph modeling, neural architecture design, and theory-guided performance enhancement. Extensive simulations, which cover a variety of important problems and network settings, verify our theory and effectiveness of the proposed design framework. ",
    "url": "https://arxiv.org/abs/2203.10800",
    "authors": [
      "Yifei Shen",
      "Jun Zhang",
      "S.H. Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.10808",
    "title": "AnoViT: Unsupervised Anomaly Detection and Localization with Vision  Transformer-based Encoder-Decoder",
    "abstract": "Image anomaly detection problems aim to determine whether an image is abnormal, and to detect anomalous areas. These methods are actively used in various fields such as manufacturing, medical care, and intelligent information. Encoder-decoder structures have been widely used in the field of anomaly detection because they can easily learn normal patterns in an unsupervised learning environment and calculate a score to identify abnormalities through a reconstruction error indicating the difference between input and reconstructed images. Therefore, current image anomaly detection methods have commonly used convolutional encoder-decoders to extract normal information through the local features of images. However, they are limited in that only local features of the image can be utilized when constructing a normal representation owing to the characteristics of convolution operations using a filter of fixed size. Therefore, we propose a vision transformer-based encoder-decoder model, named AnoViT, designed to reflect normal information by additionally learning the global relationship between image patches, which is capable of both image anomaly detection and localization. The proposed approach constructs a feature map that maintains the existing location information of individual patches by using the embeddings of all patches passed through multiple self-attention layers. The proposed AnoViT model performed better than the convolution-based model on three benchmark datasets. In MVTecAD, which is a representative benchmark dataset for anomaly localization, it showed improved results on 10 out of 15 classes compared with the baseline. Furthermore, the proposed method showed good performance regardless of the class and type of the anomalous area when localization results were evaluated qualitatively. ",
    "url": "https://arxiv.org/abs/2203.10808",
    "authors": [
      "Yunseung Lee",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10821",
    "title": "Sem2NeRF: Converting Single-View Semantic Masks to Neural Radiance  Fields",
    "abstract": "Image translation and manipulation have gain increasing attention along with the rapid development of deep generative models. Although existing approaches have brought impressive results, they mainly operated in 2D space. In light of recent advances in NeRF-based 3D-aware generative models, we introduce a new task, Semantic-to-NeRF translation, that aims to reconstruct a 3D scene modelled by NeRF, conditioned on one single-view semantic mask as input. To kick-off this novel task, we propose the Sem2NeRF framework. In particular, Sem2NeRF addresses the highly challenging task by encoding the semantic mask into the latent code that controls the 3D scene representation of a pretrained decoder. To further improve the accuracy of the mapping, we integrate a new region-aware learning strategy into the design of both the encoder and the decoder. We verify the efficacy of the proposed Sem2NeRF and demonstrate that it outperforms several strong baselines on two benchmark datasets. ",
    "url": "https://arxiv.org/abs/2203.10821",
    "authors": [
      "Yuedong Chen",
      "Qianyi Wu",
      "Chuanxia Zheng",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.10844",
    "title": "Lean Evolutionary Reinforcement Learning by Multitasking with Importance  Sampling",
    "abstract": "Studies have shown evolution strategies (ES) to be a promising approach for reinforcement learning (RL) with deep neural networks. However, the issue of high sample complexity persists in applications of ES to deep RL. In this paper, we address the shortcoming of today's methods via a novel neuroevolutionary multitasking (NuEMT) algorithm, designed to transfer information from a set of auxiliary tasks (of short episode length) to the target (full length) RL task at hand. The artificially generated auxiliary tasks allow an agent to update and quickly evaluate policies on shorter time horizons. The evolved skills are then transferred to guide the longer and harder task towards an optimal policy. We demonstrate that the NuEMT algorithm achieves data-lean evolutionary RL, reducing expensive agent-environment interaction data requirements. Our key algorithmic contribution in this setting is to introduce, for the first time, a multitask information transfer mechanism based on the statistical importance sampling technique. In addition, an adaptive resource allocation strategy is utilized to assign computational resources to auxiliary tasks based on their gleaned usefulness. Experiments on a range of continuous control tasks from the OpenAI Gym confirm that our proposed algorithm is efficient compared to recent ES baselines. ",
    "url": "https://arxiv.org/abs/2203.10844",
    "authors": [
      "Nick Zhang",
      "Abhishek Gupta",
      "Zefeng Chen",
      "Yew-Soon Ong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10845",
    "title": "Neural Token Segmentation for High Token-Internal Complexity",
    "abstract": "Tokenizing raw texts into word units is an essential pre-processing step for critical tasks in the NLP pipeline such as tagging, parsing, named entity recognition, and more. For most languages, this tokenization step straightforward. However, for languages with high token-internal complexity, further token-to-word segmentation is required. Previous canonical segmentation studies were based on character-level frameworks, with no contextualised representation involved. Contextualized vectors a la BERT show remarkable results in many applications, but were not shown to improve performance on linguistic segmentation per se. Here we propose a novel neural segmentation model which combines the best of both worlds, contextualised token representation and char-level decoding, which is particularly effective for languages with high token-internal complexity and extreme morphological ambiguity. Our model shows substantial improvements in segmentation accuracy on Hebrew and Arabic compared to the state-of-the-art, and leads to further improvements on downstream tasks such as Part-of-Speech Tagging, Dependency Parsing and Named-Entity Recognition, over existing pipelines. When comparing our segmentation-first pipeline with joint segmentation and labeling in the same settings, we show that, contrary to pre-neural studies, the pipeline performance is superior. ",
    "url": "https://arxiv.org/abs/2203.10845",
    "authors": [
      "Idan Brusilovsky",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.10866",
    "title": "Unsupervised Heterophilous Network Embedding via $r$-Ego Network  Discrimination",
    "abstract": "Recently, supervised network embedding (NE) has emerged as a predominant technique for representing complex systems that take the form of networks, and various downstream node- and network-level tasks have benefited from its remarkable developments. However, unsupervised NE still remains challenging due to the uncertainty in defining a learning objective. In addition, it is still an unexplored research question \\textit{whether existing NE methods adapt well to heterophilous networks}. This paper introduces the first empirical study on the influence of homophily ratio on the performance of existing unsupervised NE methods and reveals their limitations. Inspired by our empirical findings, we design unsupervised NE task as an $r$-ego network discrimination problem and further develop a \\underline{SEL}f-sup\\underline{E}rvised \\underline{N}etwork \\underline{E}mbedding (Selene) framework for learning useful node representations for both homophilous and heterophilous networks. Specifically, we propose a dual-channel feature embedding mechanism to fuse node attributes and network structure information and leverage a sampling and anonymisation strategy to break the implicit homophily assumption of existing embedding mechanisms. Lastly, we introduce a negative-sample-free SSL objective function to optimise the framework. We conduct extensive experiments and a series of ablation studies on $12$ real-world datasets and $20$ synthetic networks. Results demonstrate Selene's superior performance and confirm the effectiveness of each component. Code and data are available at \\url{https://github.com/zhiqiangzhongddu/Selene}. ",
    "url": "https://arxiv.org/abs/2203.10866",
    "authors": [
      "Zhiqiang Zhong",
      "Guadalupe Gonzalez",
      "Daniele Grattarola",
      "Jun Pang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10885",
    "title": "Zoom Out and Observe: News Environment Perception for Fake News  Detection",
    "abstract": "Fake news detection is crucial for preventing the dissemination of misinformation on social media. To differentiate fake news from real ones, existing methods observe the language patterns of the news post and \"zoom in\" to verify its content with knowledge sources or check its readers' replies. However, these methods neglect the information in the external news environment where a fake news post is created and disseminated. The news environment represents recent mainstream media opinion and public attention, which is an important inspiration of fake news fabrication because fake news is often designed to ride the wave of popular events and catch public attention with unexpected novel content for greater exposure and spread. To capture the environmental signals of news posts, we \"zoom out\" to observe the news environment and propose the News Environment Perception Framework (NEP). For each post, we construct its macro and micro news environment from recent mainstream news. Then we design a popularity-oriented and a novelty-oriented module to perceive useful signals and further assist final prediction. Experiments on our newly built datasets show that the NEP can efficiently improve the performance of basic fake news detectors. ",
    "url": "https://arxiv.org/abs/2203.10885",
    "authors": [
      "Qiang Sheng",
      "Juan Cao",
      "Xueyao Zhang",
      "Rundong Li",
      "Danding Wang",
      "Yongchun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.10887",
    "title": "Revisiting Domain Generalized Stereo Matching Networks from a Feature  Consistency Perspective",
    "abstract": "Despite recent stereo matching networks achieving impressive performance given sufficient training data, they suffer from domain shifts and generalize poorly to unseen domains. We argue that maintaining feature consistency between matching pixels is a vital factor for promoting the generalization capability of stereo matching networks, which has not been adequately considered. Here we address this issue by proposing a simple pixel-wise contrastive learning across the viewpoints. The stereo contrastive feature loss function explicitly constrains the consistency between learned features of matching pixel pairs which are observations of the same 3D points. A stereo selective whitening loss is further introduced to better preserve the stereo feature consistency across domains, which decorrelates stereo features from stereo viewpoint-specific style information. Counter-intuitively, the generalization of feature consistency between two viewpoints in the same scene translates to the generalization of stereo matching performance to unseen domains. Our method is generic in nature as it can be easily embedded into existing stereo networks and does not require access to the samples in the target domain. When trained on synthetic data and generalized to four real-world testing sets, our method achieves superior performance over several state-of-the-art networks. ",
    "url": "https://arxiv.org/abs/2203.10887",
    "authors": [
      "Jiawei Zhang",
      "Xiang Wang",
      "Xiao Bai",
      "Chen Wang",
      "Lei Huang",
      "Yimin Chen",
      "Lin Gu",
      "Jun Zhou",
      "Tatsuya Harada",
      "Edwin R. Hancock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10892",
    "title": "OWC-enabled Spine and Leaf Architecture Towards Energy Efficient Data  Center Networks",
    "abstract": "Due to the emergence of new paradigms and services such as 5G/6G, IoT, and more, current deployed wired Data Center Networks (DCNs) are not meeting the required performance metrics due to their limited reconfigurability, scalability, and throughput. To that end, wireless DCNs using technologies such as Optical Wireless Communication (OWC) have become viable and costeffective solutions as they offer higher capacity, better energy efficiency, and better scalability. This paper proposes an OWC-based spine and leaf DCNs where the leaf switches are enabled with OWC transceivers, and the spine switches are replaced by Access Points (APs) in the ceiling connected to a backbone network. The APs are interconnected through a Passive Optical Network (PON) that also connects the architecture with upper network layers. An Infrared (IR) OWC system that employs Wavelength Division Multiplexing (WDM) is proposed to enhance the DCN downlink communication. The simulation (i.e., channel modeling) results show that our proposed data center links achieve good data rates in the data center up to 15 Gbps. For the PON, Arrayed Waveguide Grating Routers (AWGRs) that enable WDM are proposed to connect the APs. We evaluate the performance of the considered architecture in term of its power efficiency compared to traditional spine and leaf data centers. The results show that the OWC-enabled DCN reduces the power consumption by 42% compared to traditional the spine and leaf architecture. ",
    "url": "https://arxiv.org/abs/2203.10892",
    "authors": [
      "Abrar S. Alhazmi",
      "Sanaa H. Mohamed",
      "T. E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.10897",
    "title": "Unified Multivariate Gaussian Mixture for Efficient Neural Image  Compression",
    "abstract": "Modeling latent variables with priors and hyperpriors is an essential problem in variational image compression. Formally, trade-off between rate and distortion is handled well if priors and hyperpriors precisely describe latent variables. Current practices only adopt univariate priors and process each variable individually. However, we find inter-correlations and intra-correlations exist when observing latent variables in a vectorized perspective. These findings reveal visual redundancies to improve rate-distortion performance and parallel processing ability to speed up compression. This encourages us to propose a novel vectorized prior. Specifically, a multivariate Gaussian mixture is proposed with means and covariances to be estimated. Then, a novel probabilistic vector quantization is utilized to effectively approximate means, and remaining covariances are further induced to a unified mixture and solved by cascaded estimation without context models involved. Furthermore, codebooks involved in quantization are extended to multi-codebooks for complexity reduction, which formulates an efficient compression procedure. Extensive experiments on benchmark datasets against state-of-the-art indicate our model has better rate-distortion performance and an impressive $3.18\\times$ compression speed up, giving us the ability to perform real-time, high-quality variational image compression in practice. Our source code is publicly available at \\url{https://github.com/xiaosu-zhu/McQuic}. ",
    "url": "https://arxiv.org/abs/2203.10897",
    "authors": [
      "Xiaosu Zhu",
      "Jingkuan Song",
      "Lianli Gao",
      "Feng Zheng",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.10912",
    "title": "Depth Completion using Geometry-Aware Embedding",
    "abstract": "Exploiting internal spatial geometric constraints of sparse LiDARs is beneficial to depth completion, however, has been not explored well. This paper proposes an efficient method to learn geometry-aware embedding, which encodes the local and global geometric structure information from 3D points, e.g., scene layout, object's sizes and shapes, to guide dense depth estimation. Specifically, we utilize the dynamic graph representation to model generalized geometric relationship from irregular point clouds in a flexible and efficient manner. Further, we joint this embedding and corresponded RGB appearance information to infer missing depths of the scene with well structure-preserved details. The key to our method is to integrate implicit 3D geometric representation into a 2D learning architecture, which leads to a better trade-off between the performance and efficiency. Extensive experiments demonstrate that the proposed method outperforms previous works and could reconstruct fine depths with crisp boundaries in regions that are over-smoothed by them. The ablation study gives more insights into our method that could achieve significant gains with a simple design, while having better generalization capability and stability. The code is available at https://github.com/Wenchao-Du/GAENet. ",
    "url": "https://arxiv.org/abs/2203.10912",
    "authors": [
      "Wenchao Du",
      "Hu Chen",
      "Hongyu Yang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10920",
    "title": "Towards integrating hardware Data Plane acceleration in Network  Functions Virtualization",
    "abstract": "This paper proposes a framework for integrating data plane (DP) acceleration within the Network Functions Virtualization (NFV) architecture. Data plane programming (DPP) proves to be beneficial for NFV environments, as it provides full packet forwarding flexibility through the use of self-designed algorithms. Additionally, DPP provides high-performance networking, as the DP can be configured to execute specific functions on dedicated hardware. We present an integration of the DP acceleration within the ETSI NFV architecture that leverages custom DP functions implemented in hardware switches using P4 language. Besides, OpenStack and Kubernetes are used as Virtualized Infrastructure Managers (VIMs) and Open Source MANO (OSM) as the Management and Orchestration (MANO) element. ",
    "url": "https://arxiv.org/abs/2203.10920",
    "authors": [
      "David Franco",
      "Asier Atutxa",
      "Jorge Sasiain",
      "Eder Ollora",
      "Marivi Higuero",
      "Jasone Astorga",
      "Eduardo Jacob"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.10922",
    "title": "Who Should Review Your Proposal? Interdisciplinary Topic Path Detection  for Research Proposals",
    "abstract": "The peer merit review of research proposals has been the major mechanism to decide grant awards. Nowadays, research proposals have become increasingly interdisciplinary. It has been a longstanding challenge to assign proposals to appropriate reviewers. One of the critical steps in reviewer assignment is to generate accurate interdisciplinary topic labels for proposals. Existing systems mainly collect topic labels manually reported by discipline investigators. However, such human-reported labels can be non-accurate and incomplete. What role can AI play in developing a fair and precise proposal review system? In this evidential study, we collaborate with the National Science Foundation of China to address the task of automated interdisciplinary topic path detection. For this purpose, we develop a deep Hierarchical Interdisciplinary Research Proposal Classification Network (HIRPCN). We first propose a hierarchical transformer to extract the textual semantic information of proposals. We then design an interdisciplinary graph and leverage GNNs to learn representations of each discipline in order to extract interdisciplinary knowledge. After extracting the semantic and interdisciplinary knowledge, we design a level-wise prediction component to fuse the two types of knowledge representations and detect interdisciplinary topic paths for each proposal. We conduct extensive experiments and expert evaluations on three real-world datasets to demonstrate the effectiveness of our proposed model. ",
    "url": "https://arxiv.org/abs/2203.10922",
    "authors": [
      "Meng Xiao",
      "Ziyue Qiao",
      "Yanjie Fu",
      "Hao Dong",
      "Yi Du",
      "Pengyang Wang",
      "Dong Li",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10925",
    "title": "Learning Occlusion-Aware Coarse-to-Fine Depth Map for Self-supervised  Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation, aiming to learn scene depths from single images in a self-supervised manner, has received much attention recently. In spite of recent efforts in this field, how to learn accurate scene depths and alleviate the negative influence of occlusions for self-supervised depth estimation, still remains an open problem. Addressing this problem, we firstly empirically analyze the effects of both the continuous and discrete depth constraints which are widely used in the training process of many existing works. Then inspired by the above empirical analysis, we propose a novel network to learn an Occlusion-aware Coarse-to-Fine Depth map for self-supervised monocular depth estimation, called OCFD-Net. Given an arbitrary training set of stereo image pairs, the proposed OCFD-Net does not only employ a discrete depth constraint for learning a coarse-level depth map, but also employ a continuous depth constraint for learning a scene depth residual, resulting in a fine-level depth map. In addition, an occlusion-aware module is designed under the proposed OCFD-Net, which is able to improve the capability of the learnt fine-level depth map for handling occlusions. Extensive experimental results on the public KITTI and Make3D datasets demonstrate that the proposed method outperforms 20 existing state-of-the-art methods in most cases. ",
    "url": "https://arxiv.org/abs/2203.10925",
    "authors": [
      "Zhengming Zhou",
      "Qiulei Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10926",
    "title": "3D Multi-Object Tracking Using Graph Neural Networks with Cross-Edge  Modality Attention",
    "abstract": "Online 3D multi-object tracking (MOT) has witnessed significant research interest in recent years, largely driven by demand from the autonomous systems community. However, 3D offline MOT is relatively less explored. Labeling 3D trajectory scene data at a large scale while not relying on high-cost human experts is still an open research question. In this work, we propose Batch3DMOT that follows the tracking-by-detection paradigm and represents real-world scenes as directed, acyclic, and category-disjoint tracking graphs that are attributed using various modalities such as camera, LiDAR, and radar. We present a multi-modal graph neural network that uses a cross-edge attention mechanism mitigating modality intermittence, which translates into sparsity in the graph domain. Additionally, we present attention-weighted convolutions over frame-wise k-NN neighborhoods as suitable means to allow information exchange across disconnected graph components. We evaluate our approach using various sensor modalities and model configurations on the challenging nuScenes and KITTI datasets. Extensive experiments demonstrate that our proposed approach yields an overall improvement of 2.8% in the AMOTA score on nuScenes thereby setting a new benchmark for 3D tracking methods and successfully enhances false positive filtering. ",
    "url": "https://arxiv.org/abs/2203.10926",
    "authors": [
      "Martin Buchner",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.10930",
    "title": "An integrated Auto Encoder-Block Switching defense approach to prevent  adversarial attacks",
    "abstract": "According to recent studies, the vulnerability of state-of-the-art Neural Networks to adversarial input samples has increased drastically. A neural network is an intermediate path or technique by which a computer learns to perform tasks using Machine learning algorithms. Machine Learning and Artificial Intelligence model has become a fundamental aspect of life, such as self-driving cars [1], smart home devices, so any vulnerability is a significant concern. The smallest input deviations can fool these extremely literal systems and deceive their users as well as administrator into precarious situations. This article proposes a defense algorithm that utilizes the combination of an auto-encoder [3] and block-switching architecture. Auto-coder is intended to remove any perturbations found in input images whereas the block switching method is used to make it more robust against White-box attacks. The attack is planned using FGSM [9] model, and the subsequent counter-attack by the proposed architecture will take place thereby demonstrating the feasibility and security delivered by the algorithm. ",
    "url": "https://arxiv.org/abs/2203.10930",
    "authors": [
      "Anirudh Yadav",
      "Ashutosh Upadhyay",
      "S.Sharanya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.10941",
    "title": "Transfer Dynamics in Emergent Evolutionary Curricula",
    "abstract": "PINSKY is a system for open-ended learning through neuroevolution in game-based domains. It builds on the Paired Open-Ended Trailblazer (POET) system, which originally explored learning and environment generation for bipedal walkers, and adapts it to games in the General Video Game AI (GVGAI) system. Previous work showed that by co-evolving levels and neural network policies, levels could be found for which successful policies could not be created via optimization alone. Studied in the realm of Artificial Life as a potentially open-ended alternative to gradient-based fitness, minimal criteria (MC)-based selection helps foster diversity in evolutionary populations. The main question addressed by this paper is how the open-ended learning actually works, focusing in particular on the role of transfer of policies from one evolutionary branch (\"species\") to another. We analyze the dynamics of the system through creating phylogenetic trees, analyzing evolutionary trajectories of policies, and temporally breaking down transfers according to species type. Furthermore, we analyze the impact of the minimal criterion on generated level diversity and inter-species transfer. The most insightful finding is that inter-species transfer, while rare, is crucial to the system's success. ",
    "url": "https://arxiv.org/abs/2203.10941",
    "authors": [
      "Aaron Dharna",
      "Amy K Hoover",
      "Julian Togelius",
      "L. B. Soros"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.10961",
    "title": "Bike Sharing Demand Prediction based on Knowledge Sharing across Modes:  A Graph-based Deep Learning Approach",
    "abstract": "Bike sharing is an increasingly popular part of urban transportation systems. Accurate demand prediction is the key to support timely re-balancing and ensure service efficiency. Most existing models of bike-sharing demand prediction are solely based on its own historical demand variation, essentially regarding bike sharing as a closed system and neglecting the interaction between different transport modes. This is particularly important because bike sharing is often used to complement travel through other modes (e.g., public transit). Despite some recent efforts, there is no existing method capable of leveraging spatiotemporal information from multiple modes with heterogeneous spatial units. To address this research gap, this study proposes a graph-based deep learning approach for bike sharing demand prediction (B-MRGNN) with multimodal historical data as input. The spatial dependencies across modes are encoded with multiple intra- and inter-modal graphs. A multi-relational graph neural network (MRGNN) is introduced to capture correlations between spatial units across modes, such as bike sharing stations, subway stations, or ride-hailing zones. Extensive experiments are conducted using real-world bike sharing, subway and ride-hailing data from New York City, and the results demonstrate the superior performance of our proposed approach compared to existing methods. ",
    "url": "https://arxiv.org/abs/2203.10961",
    "authors": [
      "Yuebing Liang",
      "Guan Huang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10970",
    "title": "SOLIS: Autonomous Solubility Screening using Deep Neural Networks",
    "abstract": "Accelerating material discovery has tremendous societal and industrial impact, particularly for pharmaceuticals and clean energy production. Many experimental instruments have some degree of automation, facilitating continuous running and higher throughput. However, it is common that sample preparation is still carried out manually. This can result in researchers spending a significant amount of their time on repetitive tasks, which introduces errors and can prohibit production of statistically relevant data. Crystallisation experiments are common in many chemical fields, both for purification and in polymorph screening experiments. The initial step often involves a solubility screen of the molecule; that is, understanding whether molecular compounds have dissolved in a particular solvent. This usually can be time consuming and work intensive. Moreover, accurate knowledge of the precise solubility limit of the molecule is often not required, and simply measuring a threshold of solubility in each solvent would be sufficient.To address this, we propose a novel cascaded deep model that is inspired by how a human chemist would visually assess a sample to determine whether the solid has completely dissolved in the solution. In this paper, we design, develop, and evaluate the first fully autonomous solubility screening framework, which leverages state-of-the-art methods for image segmentation and convolutional neural networks for image classification.To realise that, we first create a dataset comprising different molecules and solvents, which is collected in a real-world chemistry laboratory. We then evaluated our method on the data recorded through an eye-in-hand camera mounted on a seven degree-of-freedom robotic manipulator, and show that our model can achieve 99.13% test accuracy across various setups. ",
    "url": "https://arxiv.org/abs/2203.10970",
    "authors": [
      "Gabriella Pizzuto",
      "Jacopo de Berardinis",
      "Louis Longley",
      "Hatem Fakhruldeen",
      "Andrew I. Cooper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.10974",
    "title": "Towards Self-Supervised Gaze Estimation",
    "abstract": "Recent joint embedding-based self-supervised methods have surpassed standard supervised approaches on various image recognition tasks such as image classification. These self-supervised methods aim at maximizing agreement between features extracted from two differently transformed views of the same image, which results in learning an invariant representation with respect to appearance and geometric image transformations. However, the effectiveness of these approaches remains unclear in the context of gaze estimation, a structured regression task that requires equivariance under geometric transformations (e.g., rotations, horizontal flip). In this work, we propose SwAT, an equivariant version of the online clustering-based self-supervised approach SwAV, to learn more informative representations for gaze estimation. We identify the most effective image transformations for self-supervised pretraining and demonstrate that SwAT, with ResNet-50 and supported with uncurated unlabeled face images, outperforms state-of-the-art gaze estimation methods and supervised baselines in various experiments. In particular, we achieve up to 57% and 25% improvements in cross-dataset and within-dataset evaluation tasks on existing benchmarks (ETH-XGaze, Gaze360, and MPIIFaceGaze). ",
    "url": "https://arxiv.org/abs/2203.10974",
    "authors": [
      "Arya Farkhondeh",
      "Cristina Palmero",
      "Simone Scardapane",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10977",
    "title": "Improving anatomical plausibility in medical image segmentation via  hybrid graph neural networks: applications to chest x-ray analysis",
    "abstract": "Anatomical segmentation is a fundamental task in medical image computing, generally tackled with fully convolutional neural networks which produce dense segmentation masks. These models are often trained with loss functions such as cross-entropy or Dice, which assume pixels to be independent of each other, thus ignoring topological errors and anatomical inconsistencies. We address this limitation by moving from pixel-level to graph representations, which allow to naturally incorporate anatomical constraints by construction. To this end, we introduce HybridGNet, an encoder-decoder neural architecture that leverages standard convolutions for image feature encoding and graph convolutional neural networks (GCNNs) to decode plausible representations of anatomical structures. We also propose a novel image-to-graph skip connection layer which allows localized features to flow from standard convolutional blocks to GCNN blocks, and show that it improves segmentation accuracy. The proposed architecture is extensively evaluated in a variety of domain shift and image occlusion scenarios, and audited considering different types of demographic domain shift. Our comprehensive experimental setup compares HybridGNet with other landmark and pixel-based models for anatomical segmentation in chest x-ray images, and shows that it produces anatomically plausible results in challenging scenarios where other models tend to fail. ",
    "url": "https://arxiv.org/abs/2203.10977",
    "authors": [
      "Nicol\u00e1s Gaggion",
      "Lucas Mansilla",
      "Candelaria Mosquera",
      "Diego H. Milone",
      "Enzo Ferrante"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10981",
    "title": "MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer",
    "abstract": "Monocular 3D object detection is an important yet challenging task in autonomous driving. Some existing methods leverage depth information from an off-the-shelf depth estimator to assist 3D detection, but suffer from the additional computational burden and achieve limited performance caused by inaccurate depth priors. To alleviate this, we propose MonoDTR, a novel end-to-end depth-aware transformer network for monocular 3D object detection. It mainly consists of two components: (1) the Depth-Aware Feature Enhancement (DFE) module that implicitly learns depth-aware features with auxiliary supervision without requiring extra computation, and (2) the Depth-Aware Transformer (DTR) module that globally integrates context- and depth-aware features. Moreover, different from conventional pixel-wise positional encodings, we introduce a novel depth positional encoding (DPE) to inject depth positional hints into transformers. Our proposed depth-aware modules can be easily plugged into existing image-only monocular 3D object detectors to improve the performance. Extensive experiments on the KITTI dataset demonstrate that our approach outperforms previous state-of-the-art monocular-based methods and achieves real-time detection. Code is available at https://github.com/kuanchihhuang/MonoDTR ",
    "url": "https://arxiv.org/abs/2203.10981",
    "authors": [
      "Kuan-Chih Huang",
      "Tsung-Han Wu",
      "Hung-Ting Su",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10983",
    "title": "BNS-GCN: Efficient Full-Graph Training of Graph Convolutional Networks  with Boundary Node Sampling",
    "abstract": "Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art method for graph-based learning tasks. However, training GCNs at scale is still challenging, hindering both the exploration of more sophisticated GCN architectures and their applications to real-world large graphs. While it might be natural to consider graph partition and distributed training for tackling this challenge, this direction has only been slightly scratched the surface in the previous works due to the limitations of existing designs. In this work, we first analyze why distributed GCN training is ineffective and identify the underlying cause to be the excessive number of boundary nodes of each partitioned subgraph, which easily explodes the memory and communication costs for GCN training. Furthermore, we propose a simple yet effective method dubbed BNS-GCN that adopts random Boundary-Node-Sampling to enable efficient and scalable distributed GCN training. Experiments and ablation studies consistently validate the effectiveness of BNS-GCN, e.g., boosting the throughput by up to 16.2x and reducing the memory usage by up to 58%, while maintaining a full-graph accuracy. Furthermore, both theoretical and empirical analysis show that BNS-GCN enjoys a better convergence than existing sampling-based methods. We believe that our BNS-GCN has opened up a new paradigm for enabling GCN training at scale. The code is available at https://github.com/RICE-EIC/BNS-GCN. ",
    "url": "https://arxiv.org/abs/2203.10983",
    "authors": [
      "Cheng Wan",
      "Youjie Li",
      "Ang Li",
      "Nam Sung Kim",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10984",
    "title": "Brooks' Theorem in Graph Streams: A Single-Pass Semi-Streaming Algorithm  for $\u0394$-Coloring",
    "abstract": "Every graph with maximum degree $\\Delta$ can be colored with $(\\Delta+1)$ colors using a simple greedy algorithm. Remarkably, recent work has shown that one can find such a coloring even in the semi-streaming model. But, in reality, one almost never needs $(\\Delta+1)$ colors to properly color a graph. Indeed, the celebrated \\Brooks' theorem states that every (connected) graph beside cliques and odd cycles can be colored with $\\Delta$ colors. Can we find a $\\Delta$-coloring in the semi-streaming model as well? We settle this key question in the affirmative by designing a randomized semi-streaming algorithm that given any graph, with high probability, either correctly declares that the graph is not $\\Delta$-colorable or outputs a $\\Delta$-coloring of the graph. The proof of this result starts with a detour. We first (provably) identify the extent to which the previous approaches for streaming coloring fail for $\\Delta$-coloring: for instance, all these approaches can handle streams with repeated edges and they can run in $o(n^2)$ time -- we prove that neither of these tasks is possible for $\\Delta$-coloring. These impossibility results however pinpoint exactly what is missing from prior approaches when it comes to $\\Delta$-coloring. We then build on these insights to design a semi-streaming algorithm that uses $(i)$ a novel sparse-recovery approach based on sparse-dense decompositions to (partially) recover the \"problematic\" subgraphs of the input -- the ones that form the basis of our impossibility results -- and $(ii)$ a new coloring approach for these subgraphs that allows for recoloring of other vertices in a controlled way without relying on local explorations or finding \"augmenting paths\" that are generally impossible for semi-streaming algorithms. We believe both these techniques can be of independent interest. ",
    "url": "https://arxiv.org/abs/2203.10984",
    "authors": [
      "Sepehr Assadi",
      "Pankaj Kumar",
      "Parth Mittal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.10991",
    "title": "Optimal Fine-Grained N:M sparsity for Activations and Neural Gradients",
    "abstract": "In deep learning, fine-grained N:M sparsity reduces the data footprint and bandwidth of a General Matrix multiply (GEMM) by x2, and doubles throughput by skipping computation of zero values. So far, it was only used to prune weights. We examine how this method can be used also for activations and their gradients (i.e., \"neural gradients\"). To this end, we first establish tensor-level optimality criteria. Previous works aimed to minimize the mean-square-error (MSE) of each pruned block. We show that while minimization of the MSE works fine for pruning the activations, it catastrophically fails for the neural gradients. Instead, we show that optimal pruning of the neural gradients requires an unbiased minimum-variance pruning mask. We design such specialized masks, and find that in most cases, 1:2 sparsity is sufficient for training, and 2:4 sparsity is usually enough when this is not the case. Further, we suggest combining several such methods together in order to speed up training even more. A reference implementation is supplied in https://github.com/brianchmiel/Act-and-Grad-structured-sparsity. ",
    "url": "https://arxiv.org/abs/2203.10991",
    "authors": [
      "Brian Chmiel",
      "Itay Hubara",
      "Ron Banner",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.10996",
    "title": "Technologies for AI-Driven Fashion Social Networking Service with  E-Commerce",
    "abstract": "The rapid growth of the online fashion market brought demands for innovative fashion services and commerce platforms. With the recent success of deep learning, many applications employ AI technologies such as visual search and recommender systems to provide novel and beneficial services. In this paper, we describe applied technologies for AI-driven fashion social networking service that incorporate fashion e-commerce. In the application, people can share and browse their outfit-of-the-day (OOTD) photos, while AI analyzes them and suggests similar style OOTDs and related products. To this end, we trained deep learning based AI models for fashion and integrated them to build a fashion visual search system and a recommender system for OOTD. With aforementioned technologies, the AI-driven fashion SNS platform, iTOO, has been successfully launched. ",
    "url": "https://arxiv.org/abs/2203.10996",
    "authors": [
      "Jinseok Seol",
      "Seongjae Kim",
      "Sungchan Park",
      "Holim Lim",
      "Hyunsoo Na",
      "Eunyoung Park",
      "Dohee Jung",
      "Soyoung Park",
      "Kangwoo Lee",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.11000",
    "title": "Self-Supervised Road Layout Parsing with Graph Auto-Encoding",
    "abstract": "Aiming for higher-level scene understanding, this work presents a neural network approach that takes a road-layout map in bird's eye view as input, and predicts a human-interpretable graph that represents the road's topological layout. Our approach elevates the understanding of road layouts from pixel level to the level of graphs. To achieve this goal, an image-graph-image auto-encoder is utilized. The network is designed to learn to regress the graph representation at its auto-encoder bottleneck. This learning is self-supervised by an image reconstruction loss, without needing any external manual annotations. We create a synthetic dataset containing common road layout patterns and use it for training of the auto-encoder in addition to the real-world Argoverse dataset. By using this additional synthetic dataset, which conceptually captures human knowledge of road layouts and makes this available to the network for training, we are able to stabilize and further improve the performance of topological road layout understanding on the real-world Argoverse dataset. The evaluation shows that our approach exhibits comparable performance to a strong fully-supervised baseline. ",
    "url": "https://arxiv.org/abs/2203.11000",
    "authors": [
      "Chenyang Lu",
      "Gijs Dubbelman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.11006",
    "title": "Underwater Light Field Retention : Neural Rendering for Underwater  Imaging",
    "abstract": "Underwater Image Rendering aims to generate a true-to-life underwater image from a given clean one, which could be applied to various practical applications such as underwater image enhancement, camera filter, and virtual gaming. We explore two less-touched but challenging problems in underwater image rendering, namely, i) how to render diverse underwater scenes by a single neural network? ii) how to adaptively learn the underwater light fields from natural exemplars, \\textit{i,e.}, realistic underwater images? To this end, we propose a neural rendering method for underwater imaging, dubbed UWNR (Underwater Neural Rendering). Specifically, UWNR is a data-driven neural network that implicitly learns the natural degenerated model from authentic underwater images, avoiding introducing erroneous biases by hand-craft imaging models. Compared with existing underwater image generation methods, UWNR utilizes the natural light field to simulate the main characteristics of the underwater scene. Thus, it is able to synthesize a wide variety of underwater images from one clean image with various realistic underwater images. Extensive experiments demonstrate that our approach achieves better visual effects and quantitative metrics over previous methods. Moreover, we adopt UWNR to build an open Large Neural Rendering Underwater Dataset containing various types of water quality, dubbed LNRUD. ",
    "url": "https://arxiv.org/abs/2203.11006",
    "authors": [
      "Tian Ye",
      "Sixiang Chen",
      "Yun Liu",
      "Erkang Chen",
      "Yi Ye",
      "Yuche Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.11009",
    "title": "Online Skeleton-based Action Recognition with Continual Spatio-Temporal  Graph Convolutional Networks",
    "abstract": "Graph-based reasoning over skeleton data has emerged as a promising approach for human action recognition. However, the application of prior graph-based methods, which predominantly employ whole temporal sequences as their input, to the setting of online inference entails considerable computational redundancy. In this paper, we tackle this issue by reformulating the Spatio-Temporal Graph Convolutional Neural Network as a Continual Inference Network, which can perform step-by-step predictions in time without repeat frame processing. To evaluate our method, we create a continual version of ST-GCN, CoST-GCN, alongside two derived methods with different self-attention mechanisms, CoAGCN and CoS-TR. We investigate weight transfer strategies and architectural modifications for inference acceleration, and perform experiments on the NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets. Retaining similar predictive accuracy, we observe up to 109x reduction in time complexity, on-hardware accelerations of 26x, and reductions in maximum allocated memory of 52% during online inference. ",
    "url": "https://arxiv.org/abs/2203.11009",
    "authors": [
      "Lukas Hedegaard",
      "Negar Heidari",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11011",
    "title": "Reinforced MOOCs Concept Recommendation in Heterogeneous Information  Networks",
    "abstract": "Massive open online courses (MOOCs), which provide a large-scale interactive participation and open access via the web, are becoming a modish way for online and distance education. To help users have a better study experience, many MOOC platforms have provided the services of recommending courses to users. However, we argue that directly recommending a course to users will ignore the expertise levels of different users. To fill this gap, this paper studies the problem of concept recommendation in a more fine-grained view. We propose a novel Heterogeneous Information Networks based Concept Recommender with Reinforcement Learning (HinCRec-RL) incorporated for concept recommendation in MOOCs. Specifically, we first formulate the concept recommendation in MOOCs as a reinforcement learning problem to better model the dynamic interaction among users and knowledge concepts. In addition, to mitigate the data sparsity issue which also exists in many other recommendation tasks, we consider a heterogeneous information network (HIN) among users, courses, videos and concepts, to better learn the semantic representation of users. In particular, we use the meta-paths on HIN to guide the propagation of users' preferences and propose a heterogeneous graph attention network to represent the meta-paths. To validate the effectiveness of our proposed approach, we conduct comprehensive experiments on a real-world dataset from XuetangX, a popular MOOC platform from China. The promising results show that our proposed approach can outperform other baselines. ",
    "url": "https://arxiv.org/abs/2203.11011",
    "authors": [
      "Jibing Gong",
      "Yao Wan",
      "Ye Liu",
      "Xuewen Li",
      "Yi Zhao",
      "Cheng Wang",
      "Qing Li",
      "Wenzheng Feng",
      "Jie Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11014",
    "title": "DHEN: A Deep and Hierarchical Ensemble Network for Large-Scale  Click-Through Rate Prediction",
    "abstract": "Learning feature interactions is important to the model performance of online advertising services. As a result, extensive efforts have been devoted to designing effective architectures to learn feature interactions. However, we observe that the practical performance of those designs can vary from dataset to dataset, even when the order of interactions claimed to be captured is the same. That indicates different designs may have different advantages and the interactions captured by them have non-overlapping information. Motivated by this observation, we propose DHEN - a deep and hierarchical ensemble architecture that can leverage strengths of heterogeneous interaction modules and learn a hierarchy of the interactions under different orders. To overcome the challenge brought by DHEN's deeper and multi-layer structure in training, we propose a novel co-designed training system that can further improve the training efficiency of DHEN. Experiments of DHEN on large-scale dataset from CTR prediction tasks attained 0.27\\% improvement on the Normalized Entropy (NE) of prediction and 1.2x better training throughput than state-of-the-art baseline, demonstrating their effectiveness in practice. ",
    "url": "https://arxiv.org/abs/2203.11014",
    "authors": [
      "Buyun Zhang",
      "Liang Luo",
      "Xi Liu",
      "Jay Li",
      "Zeliang Chen",
      "Weilin Zhang",
      "Xiaohan Wei",
      "Yuchen Hao",
      "Michael Tsang",
      "Wenjun Wang",
      "Yang Liu",
      "Huayu Li",
      "Yasmine Badr",
      "Jongsoo Park",
      "Jiyan Yang",
      "Dheevatsa Mudigere",
      "Ellie Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11016",
    "title": "Linking Theories and Methods in Cognitive Sciences via Joint Embedding  of the Scientific Literature: The Example of Cognitive Control",
    "abstract": "Traditionally, theory and practice of Cognitive Control are linked via literature reviews by human domain experts. This approach, however, is inadequate to track the ever-growing literature. It may also be biased, and yield redundancies and confusion. Here we present an alternative approach. We performed automated text analyses on a large body of scientific texts to create a joint representation of tasks and constructs. More specifically, 531,748 scientific abstracts were first mapped into an embedding space using a transformers-based language model. Document embeddings were then used to identify a task-construct graph embedding that grounds constructs on tasks and supports nuanced meaning of the constructs by taking advantage of constrained random walks in the graph. This joint task-construct graph embedding, can be queried to generate task batteries targeting specific constructs, may reveal knowledge gaps in the literature, and inspire new tasks and novel hypotheses. ",
    "url": "https://arxiv.org/abs/2203.11016",
    "authors": [
      "Morteza Ansarinia",
      "Paul Schrater",
      "Pedro Cardoso-Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2203.11018",
    "title": "Stereo Neural Vernier Caliper",
    "abstract": "We propose a new object-centric framework for learning-based stereo 3D object detection. Previous studies build scene-centric representations that do not consider the significant variation among outdoor instances and thus lack the flexibility and functionalities that an instance-level model can offer. We build such an instance-level model by formulating and tackling a local update problem, i.e., how to predict a refined update given an initial 3D cuboid guess. We demonstrate how solving this problem can complement scene-centric approaches in (i) building a coarse-to-fine multi-resolution system, (ii) performing model-agnostic object location refinement, and (iii) conducting stereo 3D tracking-by-detection. Extensive experiments demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on the KITTI benchmark. Code and pre-trained models are available at https://github.com/Nicholasli1995/SNVC. ",
    "url": "https://arxiv.org/abs/2203.11018",
    "authors": [
      "Shichao Li",
      "Zechun Liu",
      "Zhiqiang Shen",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.11048",
    "title": "How Do We Answer Complex Questions: Discourse Structure of Long-form  Answers",
    "abstract": "Long-form answers, consisting of multiple sentences, can provide nuanced and comprehensive answers to a broader set of questions. To better understand this complex and understudied task, we study the functional structure of long-form answers collected from three datasets, ELI5, WebGPT and Natural Questions. Our main goal is to understand how humans organize information to craft complex answers. We develop an ontology of six sentence-level functional roles for long-form answers, and annotate 3.9k sentences in 640 answer paragraphs. Different answer collection methods manifest in different discourse structures. We further analyze model-generated answers -- finding that annotators agree less with each other when annotating model-generated answers compared to annotating human-written answers. Our annotated data enables training a strong classifier that can be used for automatic analysis. We hope our work can inspire future research on discourse-level modeling and evaluation of long-form QA systems. ",
    "url": "https://arxiv.org/abs/2203.11048",
    "authors": [
      "Fangyuan Xu",
      "Junyi Jessy Li",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11055",
    "title": "backbone: An R package to extract network backbones",
    "abstract": "Networks are useful for representing phenomena in a broad range of domains. Although their ability to represent complexity can be a virtue, it is sometimes useful to focus on a simplified network that contains only the most important edges: the backbone. This paper introduces and demonstrates the `backbone' package for R, which implements methods for extracting the backbone from weighted networks, weighted bipartite projections, and unweighted networks. For each type of network, fully replicable code is presented first for small toy examples, then for complete empirical examples using transportation, political, and social networks. The paper also demonstrates the implications of several issues of statistical inference that arise in backbone extraction. It concludes by briefly reviewing existing applications of backbone extraction using the `backbone' package, and future directions for research on network backbone extraction. ",
    "url": "https://arxiv.org/abs/2203.11055",
    "authors": [
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.11075",
    "title": "Dense Siamese Network",
    "abstract": "This paper presents Dense Siamese Network (DenseSiam), a simple unsupervised learning framework for dense prediction tasks. It learns visual representations by maximizing the similarity between two views of one image with two types of consistency, i.e., pixel consistency and region consistency. Concretely, DenseSiam first maximizes the pixel level spatial consistency according to the exact location correspondence in the overlapped area. It also extracts a batch of region embeddings that correspond to some sub-regions in the overlapped area to be contrasted for region consistency. In contrast to previous methods that require negative pixel pairs, momentum encoders, or heuristic masks, DenseSiam benefits from the simple Siamese network and optimizes the consistency of different granularities. It also proves that the simple location correspondence and interacted region embeddings are effective enough to learn the similarity. We apply DenseSiam on ImageNet and obtain competitive improvements on various downstream tasks. We also show that only with some extra task-specific losses, the simple framework can directly conduct dense prediction tasks. On an existing unsupervised semantic segmentation benchmark, it surpasses state-of-the-art segmentation methods by 2.1 mIoU with 28% training costs. ",
    "url": "https://arxiv.org/abs/2203.11075",
    "authors": [
      "Wenwei Zhang",
      "Jiangmiao Pang",
      "Kai Chen",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11076",
    "title": "Collaborative Learning for Cyberattack Detection in Blockchain Networks",
    "abstract": "This article aims to study intrusion attacks and then develop a novel cyberattack detection framework for blockchain networks. Specifically, we first design and implement a blockchain network in our laboratory. This blockchain network will serve two purposes, i.e., generate the real traffic data (including both normal data and attack data) for our learning models and implement real-time experiments to evaluate the performance of our proposed intrusion detection framework. To the best of our knowledge, this is the first dataset that is synthesized in a laboratory for cyberattacks in a blockchain network. We then propose a novel collaborative learning model that allows efficient deployment in the blockchain network to detect attacks. The main idea of the proposed learning model is to enable blockchain nodes to actively collect data, share the knowledge learned from its data, and then exchange the knowledge with other blockchain nodes in the network. In this way, we can not only leverage the knowledge from all the nodes in the network but also do not need to gather all raw data for training at a centralized node like conventional centralized learning solutions. Such a framework can also avoid the risk of exposing local data's privacy as well as the excessive network overhead/congestion. Both intensive simulations and real-time experiments clearly show that our proposed collaborative learning-based intrusion detection framework can achieve an accuracy of up to 97.7% in detecting attacks. ",
    "url": "https://arxiv.org/abs/2203.11076",
    "authors": [
      "Tran Viet Khoa",
      "Do Hai Son",
      "Dinh Thai Hoang",
      "Nguyen Linh Trung",
      "Tran Thi Thuy Quynh",
      "Diep N. Nguyen",
      "Nguyen Viet Ha",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11081",
    "title": "Image Classification on Accelerated Neural Networks",
    "abstract": "For image classification problems, various neural network models are commonly used due to their success in yielding high accuracies. Convolutional Neural Network (CNN) is one of the most frequently used deep learning methods for image classification applications. It may produce extraordinarily accurate results with regard to its complexity. However, the more complex the model is the longer it takes to train. In this paper, an acceleration design that uses the power of FPGA is given for a basic CNN model which consists of one convolutional layer and one fully connected layer for the training phase of the fully connected layer. Nonetheless, inference phase is also accelerated automatically due to the fact that training phase includes inference. In this design, the convolutional layer is calculated by the host computer and the fully connected layer is calculated by an FPGA board. It should be noted that the training of convolutional layer is not taken into account in this design and is left for future research. The results are quite encouraging as this FPGA design tops the performance of some of the state-of-the-art deep learning platforms such as Tensorflow on the host computer approximately 2 times in both training and inference. ",
    "url": "https://arxiv.org/abs/2203.11081",
    "authors": [
      "Ilkay Sikdokur",
      "Inci Baytas",
      "Arda Yurdakul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.11087",
    "title": "Ovid: A Machine Learning Approach for Automated Vandalism Detection in  OpenStreetMap",
    "abstract": "OpenStreetMap is a unique source of openly available worldwide map data, increasingly adopted in real-world applications. Vandalism detection in OpenStreetMap is critical and remarkably challenging due to the large scale of the dataset, the sheer number of contributors, various vandalism forms, and the lack of annotated data to train machine learning algorithms. This paper presents Ovid - a novel machine learning method for vandalism detection in OpenStreetMap. Ovid relies on a neural network architecture that adopts a multi-head attention mechanism to effectively summarize information indicating vandalism from OpenStreetMap changesets. To facilitate automated vandalism detection, we introduce a set of original features that capture changeset, user, and edit information. Our evaluation results on real-world vandalism data demonstrate that the proposed Ovid method outperforms the baselines by 4.7 percentage points in F1 score. ",
    "url": "https://arxiv.org/abs/2203.11087",
    "authors": [
      "Nicolas Tempelmeier",
      "Elena Demidova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.11089",
    "title": "PersFormer: 3D Lane Detection via Perspective Transformer and the  OpenLane Benchmark",
    "abstract": "Methods for 3D lane detection have been recently proposed to address the issue of inaccurate lane layouts in many autonomous driving scenarios (uphill/downhill, bump, etc.). Previous work struggled in complex cases due to their simple designs of the spatial transformation between front view and bird's eye view (BEV) and the lack of a realistic dataset. Towards these issues, we present PersFormer: an end-to-end monocular 3D lane detector with a novel Transformer-based spatial feature transformation module. Our model generates BEV features by attending to related front-view local regions with camera parameters as a reference. PersFormer adopts a unified 2D/3D anchor design and an auxiliary task to detect 2D/3D lanes simultaneously, enhancing the feature consistency and sharing the benefits of multi-task learning. Moreover, we release one of the first large-scale real-world 3D lane datasets, which is called OpenLane, with high-quality annotation and scenario diversity. OpenLane contains 200,000 frames, over 880,000 instance-level lanes, 14 lane categories, along with scene tags and the closed-in-path object annotations to encourage the development of lane detection and more industrial-related autonomous driving methods. We show that PersFormer significantly outperforms competitive baselines in the 3D lane detection task on our new OpenLane dataset as well as Apollo 3D Lane Synthetic dataset, and is also on par with state-of-the-art algorithms in the 2D task on OpenLane. The project page is available at https://github.com/OpenPerceptionX/OpenLane. ",
    "url": "https://arxiv.org/abs/2203.11089",
    "authors": [
      "Li Chen",
      "Chonghao Sima",
      "Yang Li",
      "Zehan Zheng",
      "Jiajie Xu",
      "Xiangwei Geng",
      "Hongyang Li",
      "Conghui He",
      "Jianping Shi",
      "Yu Qiao",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11103",
    "title": "Diverse Counterfactual Explanations for Anomaly Detection in Time Series",
    "abstract": "Data-driven methods that detect anomalies in times series data are ubiquitous in practice, but they are in general unable to provide helpful explanations for the predictions they make. In this work we propose a model-agnostic algorithm that generates counterfactual ensemble explanations for time series anomaly detection models. Our method generates a set of diverse counterfactual examples, i.e, multiple perturbed versions of the original time series that are not considered anomalous by the detection model. Since the magnitude of the perturbations is limited, these counterfactuals represent an ensemble of inputs similar to the original time series that the model would deem normal. Our algorithm is applicable to any differentiable anomaly detection model. We investigate the value of our method on univariate and multivariate real-world datasets and two deep-learning-based anomaly detection models, under several explainability criteria previously proposed in other data domains such as Validity, Plausibility, Closeness and Diversity. We show that our algorithm can produce ensembles of counterfactual examples that satisfy these criteria and thanks to a novel type of visualisation, can convey a richer interpretation of a model's internal mechanism than existing methods. Moreover, we design a sparse variant of our method to improve the interpretability of counterfactual explanations for high-dimensional time series anomalies. In this setting, our explanation is localised on only a few dimensions and can therefore be communicated more efficiently to the model's user. ",
    "url": "https://arxiv.org/abs/2203.11103",
    "authors": [
      "Deborah Sulem",
      "Michele Donini",
      "Muhammad Bilal Zafar",
      "Francois-Xavier Aubet",
      "Jan Gasthaus",
      "Tim Januschowski",
      "Sanjiv Das",
      "Krishnaram Kenthapadi",
      "Cedric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11106",
    "title": "FGAN: Federated Generative Adversarial Networks for Anomaly Detection in  Network Traffic",
    "abstract": "Over the last two decades, a lot of work has been done in improving network security, particularly in intrusion detection systems (IDS) and anomaly detection. Machine learning solutions have also been employed in IDSs to detect known and plausible attacks in incoming traffic. Parameters such as packet contents, sender IP and sender port, connection duration, etc. have been previously used to train these machine learning models to learn to differentiate genuine traffic from malicious ones. Generative Adversarial Networks (GANs) have been significantly successful in detecting such anomalies, mostly attributed to the adversarial training of the generator and discriminator in an attempt to bypass each other and in turn increase their own power and accuracy. However, in large networks having a wide variety of traffic at possibly different regions of the network and susceptible to a large number of potential attacks, training these GANs for a particular kind of anomaly may make it oblivious to other anomalies and attacks. In addition, the dataset required to train these models has to be made centrally available and publicly accessible, posing the obvious question of privacy of the communications of the respective participants of the network. The solution proposed in this work aims at tackling the above two issues by using GANs in a federated architecture in networks of such scale and capacity. In such a setting, different users of the network will be able to train and customize a centrally available adversarial model according to their own frequently faced conditions. Simultaneously, the member users of the network will also able to gain from the experiences of the other users in the network. ",
    "url": "https://arxiv.org/abs/2203.11106",
    "authors": [
      "Sankha Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11111",
    "title": "Facial Expression Analysis Using Decomposed Multiscale Spatiotemporal  Networks",
    "abstract": "Video-based analysis of facial expressions has been increasingly applied to infer health states of individuals, such as depression and pain. Among the existing approaches, deep learning models composed of structures for multiscale spatiotemporal processing have shown strong potential for encoding facial dynamics. However, such models have high computational complexity, making for a difficult deployment of these solutions. To address this issue, we introduce a new technique to decompose the extraction of multiscale spatiotemporal features. Particularly, a building block structure called Decomposed Multiscale Spatiotemporal Network (DMSN) is presented along with three variants: DMSN-A, DMSN-B, and DMSN-C blocks. The DMSN-A block generates multiscale representations by analyzing spatiotemporal features at multiple temporal ranges, while the DMSN-B block analyzes spatiotemporal features at multiple ranges, and the DMSN-C block analyzes spatiotemporal features at multiple spatial sizes. Using these variants, we design our DMSN architecture which has the ability to explore a variety of multiscale spatiotemporal features, favoring the adaptation to different facial behaviors. Our extensive experiments on challenging datasets show that the DMSN-C block is effective for depression detection, whereas the DMSN-A block is efficient for pain estimation. Results also indicate that our DMSN architecture provides a cost-effective solution for expressions that range from fewer facial variations over time, as in depression detection, to greater variations, as in pain estimation. ",
    "url": "https://arxiv.org/abs/2203.11111",
    "authors": [
      "Wheidima Carneiro de Melo",
      "Eric Granger",
      "Miguel Bordallo Lopez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11117",
    "title": "L-MAC: Location-aware MAC Protocol for Wireless Sensor Networks",
    "abstract": "This paper presents the design, implementation and performance evaluation of a location MAC protocol, called L-MAC, for wireless sensor networks. L-MAC is a combination of TDMA and CSMA while offsetting the high overhead of time slot assignment by allocating the time slots to sensor nodes based on their location information. This design avoids high computation complexity of time slot assignment incurred by node mobility and node failure. The area which the wireless sensor network occupies is divided into blocks and each block is associated with an inter-block time slot and an intra-block time slot. In the inter-block time slot, the sensor nodes stay active and receive the packets from nodes outside of the block. In the intra-block time slot, the sensor nodes communicate with peer nodes in the same block under CSMA. Sensor nodes stay sleep in all other time slots unless they have traffic to send. L-MAC is implemented and evaluated in NS-2. ",
    "url": "https://arxiv.org/abs/2203.11117",
    "authors": [
      "Jason Chen",
      "Yang Xi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.11151",
    "title": "Prediction of chaotic attractors in quasiperiodically forced logistic  map using deep learning",
    "abstract": "We forecast two different chaotic dynamics of the quasiperiodically forced logistic map using the well-known deep learning framework Long Short-Term Memory. We generate two data sets and use one in the training process and the other in the testing process. The predicted values are evaluated using the metric called Root Mean Square Error and visualized using the scatter plots. The robustness of the Long Short-Term Memory model is evaluated using the number of units in the layers of the model. We also make multi-step forecasting of the considered system. We show that the considered Long Short-Term Memory model performs well in predicting chaotic attractors upto three steps. ",
    "url": "https://arxiv.org/abs/2203.11151",
    "authors": [
      "J. Meiyazhagan",
      "M. Senthilvelan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2203.11156",
    "title": "Operator Sketching for Deep Unrolling Networks",
    "abstract": "In this work we propose a new paradigm for designing efficient deep unrolling networks using operator sketching. The deep unrolling networks are currently the state-of-the-art solutions for imaging inverse problems. However, for high-dimensional imaging tasks, especially the 3D cone-beam X-ray CT and 4D MRI imaging, the deep unrolling schemes typically become inefficient both in terms of memory and computation, due to the need of computing multiple times the high-dimensional forward and adjoint operators. Recently researchers have found that such limitations can be partially addressed by stochastic unrolling with subsets of operators, inspired by the success of stochastic first-order optimization. In this work, we propose a further acceleration upon stochastic unrolling, using sketching techniques to approximate products in the high-dimensional image space. The operator sketching can be jointly applied with stochastic unrolling for the best acceleration and compression performance. Our numerical experiments on X-ray CT image reconstruction demonstrate the remarkable effectiveness of our sketched unrolling schemes. ",
    "url": "https://arxiv.org/abs/2203.11156",
    "authors": [
      "Junqi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.11183",
    "title": "Masked Discrimination for Self-Supervised Learning on Point Clouds",
    "abstract": "Masked autoencoding has achieved great success for self-supervised learning in the image and language domains. However, mask based pretraining has yet to show benefits for point cloud understanding, likely due to standard backbones like PointNet being unable to properly handle the training versus testing distribution mismatch introduced by masking during training. In this paper, we bridge this gap by proposing a discriminative mask pretraining Transformer framework, MaskPoint}, for point clouds. Our key idea is to represent the point cloud as discrete occupancy values (1 if part of the point cloud; 0 if not), and perform simple binary classification between masked object points and sampled noise points as the proxy task. In this way, our approach is robust to the point sampling variance in point clouds, and facilitates learning rich representations. We evaluate our pretrained models across several downstream tasks, including 3D shape classification, segmentation, and real-word object detection, and demonstrate state-of-the-art results while achieving a significant pretraining speedup (e.g., 4.1x on ScanNet) compared to the prior state-of-the-art Transformer baseline. Code will be publicly available at https://github.com/haotian-liu/MaskPoint. ",
    "url": "https://arxiv.org/abs/2203.11183",
    "authors": [
      "Haotian Liu",
      "Mu Cai",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11191",
    "title": "Robust Visual Tracking by Segmentation",
    "abstract": "Estimating the target extent poses a fundamental challenge in visual object tracking. Typically, trackers are box-centric and fully rely on a bounding box to define the target in the scene. In practice, objects often have complex shapes and are not aligned with the image axis. In these cases, bounding boxes do not provide an accurate description of the target and often contain a majority of background pixels. We propose a segmentation-centric tracking pipeline that not only produces a highly accurate segmentation mask, but also works internally with segmentation masks instead of bounding boxes. Thus, our tracker is able to better learn a target representation that clearly differentiates the target in the scene from background content. In order to achieve the necessary robustness for the challenging tracking scenario, we propose a separate instance localization component that is used to condition the segmentation decoder when producing the output mask. We infer a bounding box from the segmentation mask and validate our tracker on challenging tracking datasets and achieve the new state of the art on LaSOT with a success AUC score of 69.7%. Since fully evaluating the predicted masks on tracking datasets is not possible due to the missing mask annotations, we further validate our segmentation quality on two popular video object segmentation datasets. ",
    "url": "https://arxiv.org/abs/2203.11191",
    "authors": [
      "Matthieu Paul",
      "Martin Danelljan",
      "Christoph Mayer",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11192",
    "title": "Transforming Model Prediction for Tracking",
    "abstract": "Optimization based tracking methods have been widely successful by integrating a target model prediction module, providing effective global reasoning by minimizing an objective function. While this inductive bias integrates valuable domain knowledge, it limits the expressivity of the tracking network. In this work, we therefore propose a tracker architecture employing a Transformer-based model prediction module. Transformers capture global relations with little inductive bias, allowing it to learn the prediction of more powerful target models. We further extend the model predictor to estimate a second set of weights that are applied for accurate bounding box regression. The resulting tracker relies on training and on test frame information in order to predict all weights transductively. We train the proposed tracker end-to-end and validate its performance by conducting comprehensive experiments on multiple tracking datasets. Our tracker sets a new state of the art on three benchmarks, achieving an AUC of 68.5% on the challenging LaSOT dataset. ",
    "url": "https://arxiv.org/abs/2203.11192",
    "authors": [
      "Christoph Mayer",
      "Martin Danelljan",
      "Goutam Bhat",
      "Matthieu Paul",
      "Danda Pani Paudel",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10115",
    "title": "Introducing causal inference in the energy-efficient building design  process",
    "abstract": "\"What-if\" questions are intuitively generated during the design process. Engineers and architects need to inherently conduct design decisions, progressing from one phase to another. They either use empirical domain experience, simulations, or data-driven methods to conduct consequential feedback. We take an example in an interdisciplinary domain, energy-efficient building design scenario, to argue that the current methods for decision support have four limitations: 1. Less carefully inspected parametric independence raise risks of biased results and spurious relationships. 2. The integration gap between data-driven methods and knowledge-based approaches. 3. Less explicit model interpretability for informed decision-making. 4. Ambiguous boundaries for machine assistance during the design process. In this paper, we first clarify the nature of dynamic personal experience and constant principal knowledge in design. Sequentially, we introduce the causal inference into the energy-efficient design domain by proposing a two-step process to reveal and analyze the parametric dependencies within the design space by identifying the design causal diagram with interventions. The causal diagram provides a nexus for integrating domain knowledge with data-driven methods and allows for interpretability and testability against domain experience. The extraction of causal structures from the data is close to the common design reasoning process. As an illustration, we applied the properties of the proposed estimators through simulations. The paper is concluded with a feasibility study that demonstrates the realization of the proposed framework. ",
    "url": "https://arxiv.org/abs/2203.10115",
    "authors": [
      "Xia Chen",
      "Jimmy Abualdenien",
      "Manav Mahan Singh",
      "Andr\u00e9 Borrmann",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2203.10200",
    "title": "Emulating Quantum Dynamics with Neural Networks via Knowledge  Distillation",
    "abstract": "High-fidelity quantum dynamics emulators can be used to predict the time evolution of complex physical systems. Here, we introduce an efficient training framework for constructing machine learning-based emulators. Our approach is based on the idea of knowledge distillation and uses elements of curriculum learning. It works by constructing a set of simple, but rich-in-physics training examples (a curriculum). These examples are used by the emulator to learn the general rules describing the time evolution of a quantum system (knowledge distillation). The goal is not only to obtain high-quality predictions, but also to examine the process of how the emulator learns the physics of the underlying problem. This allows us to discover new facts about the physical system, detect symmetries, and measure relative importance of the contributing physical processes. We illustrate this approach by training an artificial neural network to predict the time evolution of quantum wave packages propagating through a potential landscape. We focus on the question of how the emulator learns the rules of quantum dynamics from the curriculum of simple training examples and to which extent it can generalize the acquired knowledge to solve more challenging cases. ",
    "url": "https://arxiv.org/abs/2203.10200",
    "authors": [
      "Yu Yao",
      "Chao Cao",
      "Stephan Haas",
      "Mahak Agarwal",
      "Divyam Khanna",
      "Marcin Abram"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10201",
    "title": "A Quantum Algorithm for Network Reliability",
    "abstract": "Building a network that is resilient to a component failure is vital. Our access to electricity and telecommunications or the internet of things all hinge on an uninterrupted service provided by a robust network. Calculating the network reliability $R$ is $\\sharp$P-complete and intractable to calculate exactly for medium and large networks. Here, we present an explicit, circuit-level implementation of a quantum algorithm that computes $R$. Our algorithm requires $O(EV/\\epsilon)$ gate operations and $O(E)$ qubits, where $V$ and $E$ are the number of nodes and edges in the graph and $\\epsilon$ is the uncertainty in the reliability estimation. This constitutes a significant polynomial speedup over the best classical approaches currently known. We further provide quantum gate counts, relevant for both pre-fault-tolerant and fault-tolerant regimes, sufficient to compute $R$. ",
    "url": "https://arxiv.org/abs/2203.10201",
    "authors": [
      "Stefan Pabst",
      "Yunseong Nam"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2203.10204",
    "title": "Inferring topological transitions in pattern-forming processes with  self-supervised learning",
    "abstract": "The identification and classification of transitions in topological and microstructural regimes in pattern-forming processes is critical for understanding and fabricating microstructurally precise novel materials in many application domains. Unfortunately, relevant microstructure transitions may depend on process parameters in subtle and complex ways that are not captured by the classic theory of phase transition. While supervised machine learning methods may be useful for identifying transition regimes, they need labels which require prior knowledge of order parameters or relevant structures. Motivated by the universality principle for dynamical systems, we instead use a self-supervised approach to solve the inverse problem of predicting process parameters from observed microstructures using neural networks. This approach does not require labeled data about the target task of predicting microstructure transitions. We show that the difficulty of performing this prediction task is related to the goal of discovering microstructure regimes, because qualitative changes in microstructural patterns correspond to changes in uncertainty for our self-supervised prediction problem. We demonstrate the value of our approach by automatically discovering transitions in microstructural regimes in two distinct pattern-forming processes: the spinodal decomposition of a two-phase mixture and the formation of concentration modulations of binary alloys during physical vapor deposition of thin films. This approach opens a promising path forward for discovering and understanding unseen or hard-to-detect transition regimes, and ultimately for controlling complex pattern-forming processes. ",
    "url": "https://arxiv.org/abs/2203.10204",
    "authors": [
      "Marcin Abram",
      "Keith Burghardt",
      "Greg Ver Steeg",
      "Aram Galstyan",
      "Remi Dingreville"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10292",
    "title": "Quantum Neural Networks -- Computational Field Theory and Dynamics",
    "abstract": "To address Quantum Artificial Neural Networks as quantum dynamical computing systems, a formalization of quantum artificial neural networks as dynamical systems is developed, expanding the concept of unitary map to the neural computation setting and introducing a quantum computing field theory on the network. The formalism is illustrated in a simulation of a quantum recurrent neural network and the resulting field dynamics is researched upon, showing emergent neural waves with excitation and relaxation cycles at the level of the quantum neural activity field, as well as edge of chaos signatures, with the local neurons operating as far-from-equilibrium open quantum systems, exhibiting entropy fluctuations with complex dynamics including complex quasiperiodic patterns and power law signatures. The implications for quantum computer science, quantum complexity research, quantum technologies and neuroscience are also addressed. ",
    "url": "https://arxiv.org/abs/2203.10292",
    "authors": [
      "Carlos Pedro Gon\u00e7alves"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2203.10596",
    "title": "Towards Clinical Practice: Design and Implementation of Convolutional  Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection  from Chest X-Ray Images",
    "abstract": "One of the critical tools for early detection and subsequent evaluation of the incidence of lung diseases is chest radiography. This study presents a real-world implementation of a convolutional neural network (CNN) based Carebot Covid app to detect COVID-19 from chest X-ray (CXR) images. Our proposed model takes the form of a simple and intuitive application. Used CNN can be deployed as a STOW-RS prediction endpoint for direct implementation into DICOM viewers. The results of this study show that the deep learning model based on DenseNet and ResNet architecture can detect SARS-CoV-2 from CXR images with precision of 0.981, recall of 0.962 and AP of 0.993. ",
    "url": "https://arxiv.org/abs/2203.10596",
    "authors": [
      "Daniel Kvak",
      "Marian Bendik",
      "Anna Chromcova"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10637",
    "title": "Vocal effort modeling in neural TTS for improving the intelligibility of  synthetic speech in noise",
    "abstract": "We present a neural text-to-speech (TTS) method that models natural vocal effort variation to improve the intelligibility of synthetic speech in the presence of noise. The method consists of first measuring the spectral tilt of unlabeled conventional speech data, and then conditioning a neural TTS model with normalized spectral tilt among other prosodic factors. Changing spectral tilt and keeping other prosodic factors unchanged enables effective vocal effort control at synthesis time independent of other prosodic factors. By extrapolation of the spectral tilt values beyond what has been seen in the original data, we can generate speech with high vocal effort levels, thus improving the intelligibility of speech in the presence of masking noise. We evaluate the intelligibility and quality of normal speech and speech with increased vocal effort in the presence of various masking noise conditions, and compare these to well-known speech intelligibility-enhancing algorithms. The evaluations show that the proposed method can improve the intelligibility of synthetic speech with little loss in speech quality. ",
    "url": "https://arxiv.org/abs/2203.10637",
    "authors": [
      "Tuomo Raitio",
      "Petko Petkov",
      "Jiangchuan Li",
      "Muhammed Shifas",
      "Andrea Davis",
      "Yannis Stylianou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.10679",
    "title": "Learning latent causal relationships in multiple time series",
    "abstract": "Identifying the causal structure of systems with multiple dynamic elements is critical to several scientific disciplines. The conventional approach is to conduct statistical tests of causality, for example with Granger Causality, between observed signals that are selected a priori. Here it is posited that, in many systems, the causal relations are embedded in a latent space that is expressed in the observed data as a linear mixture. A technique for blindly identifying the latent sources is presented: the observations are projected into pairs of components -- driving and driven -- to maximize the strength of causality between the pairs. This leads to an optimization problem with closed form expressions for the objective function and gradient that can be solved with off-the-shelf techniques. After demonstrating proof-of-concept on synthetic data with known latent structure, the technique is applied to recordings from the human brain and historical cryptocurrency prices. In both cases, the approach recovers multiple strong causal relationships that are not evident in the observed data. The proposed technique is unsupervised and can be readily applied to any multiple time series to shed light on the causal relationships underlying the data. ",
    "url": "https://arxiv.org/abs/2203.10679",
    "authors": [
      "Jacek P. Dmochowski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.10810",
    "title": "Information-theoretic analyses of neural data to minimize the effect of  researchers' assumptions in predictive coding studies",
    "abstract": "Studies investigating neural information processing often implicitly ask both, which processing strategy out of several alternatives is used and how this strategy is implemented in neural dynamics. A prime example are studies on predictive coding. These often ask if confirmed predictions about inputs or predictions errors between internal predictions and inputs are passed on in a hierarchical neural system-while at the same time looking for the neural correlates of coding for errors and predictions. If we do not know exactly what a neural system predicts at any given moment, this results in a circular analysis-as has been criticized correctly. To circumvent such circular analysis, we propose to express information processing strategies (such as predictive coding) by local information-theoretic quantities, such that they can be estimated directly from neural data. We demonstrate our approach by investigating two opposing accounts of predictive coding-like processing strategies, where we quantify the building blocks of predictive coding, namely predictability of inputs and transfer of information, by local active information storage and local transfer entropy. We define testable hypotheses on the relationship of both quantities to identify which of the assumed strategies was used. We demonstrate our approach on spiking data from the retinogeniculate synapse of the cat. Applying our local information dynamics framework, we are able to show that the synapse codes for predictable rather than surprising input. To support our findings, we apply measures from partial information decomposition, which allow to differentiate if the transferred information is primarily bottom-up sensory input or information transferred conditionally on the current state of the synapse. Supporting our local information-theoretic results, we find that the synapse preferentially transfers bottom-up information. ",
    "url": "https://arxiv.org/abs/2203.10810",
    "authors": [
      "Patricia Wollstadt",
      "Daniel L. Rathbun",
      "W. Martin Usrey and",
      "Andr\u00e9 Moraes Bastos",
      "Michael Lindner",
      "Viola Priesemann",
      "Michael Wibral"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.10975",
    "title": "GCF: Generalized Causal Forest for Heterogeneous Treatment Effect  Estimation in Online Marketplace",
    "abstract": "Uplift modeling is a rapidly growing approach that utilizes machine learning and causal inference methods to estimate the heterogeneous treatment effects. It has been widely adopted and applied to online marketplaces to assist large-scale decision-making in recent years. The existing popular methods, like forest-based modeling, either work only for discrete treatments or make partially linear or parametric assumptions that may suffer from model misspecification. To alleviate these problems, we extend causal forest (CF) with non-parametric dose-response functions (DRFs) that can be estimated locally using a kernel-based doubly robust estimator. Moreover, we propose a distance-based splitting criterion in the functional space of conditional DRFs to capture the heterogeneity for the continuous treatments. We call the proposed algorithm generalized causal forest (GCF) as it generalizes the use case of CF to a much broader setup. We show the effectiveness of GCF by comparing it to popular uplift modeling models on both synthetic and real-world datasets. We implement GCF in Spark and successfully deploy it into DiDi's real-time pricing system. Online A/B testing results further validate the superiority of GCF. ",
    "url": "https://arxiv.org/abs/2203.10975",
    "authors": [
      "Shu Wan",
      "Chen Zheng",
      "Zhonggen Sun",
      "Mengfan Xu",
      "Xiaoqing Yang",
      "Hongtu Zhu",
      "Jiecheng Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.10989",
    "title": "Hierarchical autoregressive neural networks for statistical systems",
    "abstract": "It was recently proposed that neural networks could be used to approximate many-dimensional probability distributions that appear e.g. in lattice field theories or statistical mechanics. Subsequently they can be used as variational approximators to asses extensive properties of statistical systems, like free energy, and also as neural samplers used in Monte Carlo simulations. The practical application of this approach is unfortunately limited by its unfavorable scaling both of the numerical cost required for training, and the memory requirements with the system size. This is due to the fact that the original proposition involved a neural network of width which scaled with the total number of degrees of freedom, e.g. $L^2$ in case of a two dimensional $L\\times L$ lattice. In this work we propose a hierarchical association of physical degrees of freedom, for instance spins, to neurons which replaces it with the scaling with the linear extent $L$ of the system. We demonstrate our approach on the two-dimensional Ising model by simulating lattices of various sizes up to $128 \\times 128$ spins, with time benchmarks reaching lattices of size $512 \\times 512$. We observe that our proposal improves the quality of neural network training, i.e. the approximated probability distribution is closer to the target that could be previously achieved. As a consequence, the variational free energy reaches a value closer to its theoretical expectation and, if applied in a Markov Chain Monte Carlo algorithm, the resulting autocorrelation time is smaller. Finally, the replacement of a single neural network by a hierarchy of smaller networks considerably reduces the memory requirements. ",
    "url": "https://arxiv.org/abs/2203.10989",
    "authors": [
      "Piotr Bia\u0142as",
      "Piotr Korcyl",
      "Tomasz Stebel"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11012",
    "title": "Learning Resilient Radio Resource Management Policies with Graph Neural  Networks",
    "abstract": "We consider the problems of downlink user selection and power control in wireless networks, comprising multiple transmitters and receivers communicating with each other over a shared wireless medium. To achieve a high aggregate rate, while ensuring fairness across all the receivers, we formulate a resilient radio resource management (RRM) policy optimization problem with per-user minimum-capacity constraints that adapt to the underlying network conditions via learnable slack variables. We reformulate the problem in the Lagrangian dual domain, and show that we can parameterize the user selection and power control policies using a finite set of parameters, which can be trained alongside the slack and dual variables via an unsupervised primal-dual approach thanks to a provably small duality gap. We use a scalable and permutation-equivariant graph neural network (GNN) architecture to parameterize the RRM policies based on a graph topology derived from the instantaneous channel conditions. Through experimental results, we verify that the minimum-capacity constraints adapt to the underlying network configurations and channel conditions. We further demonstrate that, thanks to such adaptation, our proposed method achieves a superior tradeoff between the average rate and the 5th percentile rate -- a metric that quantifies the level of fairness in the resource allocation decisions -- as compared to baseline algorithms. ",
    "url": "https://arxiv.org/abs/2203.11012",
    "authors": [
      "Navid NaderiAlizadeh",
      "Mark Eisen",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11091",
    "title": "GCNET: graph-based prediction of stock price movement using graph  convolutional network",
    "abstract": "The prediction of stocks' direction of movement using the historical price information has attracted considerable attention as a challenging problem in the field of machine learning. However, modeling and analyzing the hidden relations among stock prices as an important source of information for the prediction of their future behavior has not been explored well yet. The existing methods in this domain suffer from the lack of generality and flexibility and cannot be easily applied on any set of inter-related stocks. The main challenges in this domain are to find a way for modeling the existing relations among an arbitrary set of stocks and to exploit such a model for improving the prediction performance for those stocks. In this paper, we introduce a novel framework, called GCNET that models the relations among an arbitrary set of stocks as a graph structure called influence network and uses a set of history-based prediction models to infer plausible initial labels for a subset of the stock nodes in the graph. Finally, GCNET uses the Graph Convolutional Network algorithm to analyzes this partially labeled graph and predicts the next price direction of movement for each stock in the graph. GCNET is a general prediction framework that can be applied for the prediction of the price fluctuations for any set of interacting stocks based on their historical data. Our experiments and evaluations on sets of stocks from S\\&P500 and NASDAQ show that GCNET significantly improves the performance of SOTA in terms of accuracy and MCC measures. ",
    "url": "https://arxiv.org/abs/2203.11091",
    "authors": [
      "Alireza Jafari",
      "Saman Haratizadeh"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1612.06473",
    "title": "Sorting Networks On Restricted Topologies",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/1612.06473",
    "authors": [
      "Indranil Banerjee",
      "Dana Richards",
      "Igor Shinkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1706.09355",
    "title": "New Results On Routing Via Matchings On Graphs",
    "abstract": " Comments: 15 Pages, 5 Figures , 21st International Symposium on Fundamentals of Computation Theory. arXiv admin note: text overlap with arXiv:1604.04978 ",
    "url": "https://arxiv.org/abs/1706.09355",
    "authors": [
      "Indranil Banerjee",
      "Dana Richards"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1804.06039",
    "title": "Real-Time Rotation-Invariant Face Detection with Progressive Calibration  Networks",
    "abstract": " Comments: Accepted to CVPR 2018. Code: this https URL ",
    "url": "https://arxiv.org/abs/1804.06039",
    "authors": [
      "Xuepeng Shi",
      "Shiguang Shan",
      "Meina Kan",
      "Shuzhe Wu",
      "Xilin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1904.09954",
    "title": "Communication and Code Dependency Effects on Software Code Quality: An  Empirical Analysis of Herbsleb Hypothesis",
    "abstract": " Comments: 12 pages, 7 figures, 2 tables ",
    "url": "https://arxiv.org/abs/1904.09954",
    "authors": [
      "Suvodeep Majumder",
      "Joymallya Chakraborty",
      "Amritanshu Agrawal",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:1907.04793",
    "title": "Uniform stability of some large-scale parallel server networks",
    "abstract": " Comments: 32 pages ",
    "url": "https://arxiv.org/abs/1907.04793",
    "authors": [
      "Hassan Hmedi",
      "Ari Arapostathis",
      "Guodong Pang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:1911.00620",
    "title": "Improved bounds on the size of the smallest representation of relation  algebra $32_{65}$",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/1911.00620",
    "authors": [
      "Jeremy F. Alm",
      "Michael Levet",
      "Saeed Moazami",
      "Jorge Montero-Vallejo",
      "Linda Pham",
      "Dave Sexton",
      "Xiaonan Xu"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:1911.01258",
    "title": "SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural  Network",
    "abstract": " Title: SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural  Network ",
    "url": "https://arxiv.org/abs/1911.01258",
    "authors": [
      "Reza Yazdani",
      "Olatunji Ruwase",
      "Minjia Zhang",
      "Yuxiong He",
      "Jose-Maria Arnau",
      "Antonio Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2005.06092",
    "title": "Adaptive Double-Exploration Tradeoff for Outlier Detection",
    "abstract": " Title: Adaptive Double-Exploration Tradeoff for Outlier Detection ",
    "url": "https://arxiv.org/abs/2005.06092",
    "authors": [
      "Xiaojin Zhang",
      "Honglei Zhuang",
      "Shengyu Zhang",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.06767",
    "title": "Heterogeneous Federated Learning",
    "abstract": " Comments: Full version [Fed2: Feature-Aligned Federated Learning] accepted in KDD'2021 ",
    "url": "https://arxiv.org/abs/2008.06767",
    "authors": [
      "Fuxun Yu",
      "Weishan Zhang",
      "Zhuwei Qin",
      "Zirui Xu",
      "Di Wang",
      "Chenchen Liu",
      "Zhi Tian",
      "Xiang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.12871",
    "title": "Data-Driven Models of Selfish Routing: Why Price of Anarchy Does Depend  on Network Topology",
    "abstract": " Comments: Extended version of the conference paper presented in WINE 2020: The 16th Conference on Web and Internet Economics ",
    "url": "https://arxiv.org/abs/2009.12871",
    "authors": [
      "Francisco Benita",
      "Vittorio Bil\u00f2",
      "Barnab\u00e9 Monnot",
      "Georgios Piliouras",
      "Cosimo Vinci"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2011.06247",
    "title": "Optimal Collaterals in Multi-Enterprise Investment Networks",
    "abstract": " Comments: Published in Proceedings of the ACM Web Conference 2022 (WWW'22). this https URL ",
    "url": "https://arxiv.org/abs/2011.06247",
    "authors": [
      "Moshe Babaioff",
      "Yoav Kolumbus",
      "Eyal Winter"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2012.02950",
    "title": "Deep Depression Prediction on Longitudinal Data via Joint Anomaly  Ranking and Classification",
    "abstract": " Comments: Accepted to PAKDD 2022 ",
    "url": "https://arxiv.org/abs/2012.02950",
    "authors": [
      "Guansong Pang",
      "Ngoc Thien Anh Pham",
      "Emma Baker",
      "Rebecca Bentley",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2012.11793",
    "title": "Optimum Reconfigurable Intelligent Surface Selection for Wireless  Networks",
    "abstract": " Comments: 34 pages; submitted for possible IEEE publications ",
    "url": "https://arxiv.org/abs/2012.11793",
    "authors": [
      "Yuting Fang",
      "Saman Atapattu",
      "Hazer Inaltekin",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2101.11906",
    "title": "Development of a Vertex Finding Algorithm using Recurrent Neural Network",
    "abstract": " Comments: 8 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2101.11906",
    "authors": [
      "Kiichi Goto",
      "Taikan Suehara",
      "Tamaki Yoshioka",
      "Masakazu Kurata",
      "Hajime Nagahara",
      "Yuta Nakashima",
      "Noriko Takemura",
      "Masako Iwasaki"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2102.10032",
    "title": "Approximation and Learning with Deep Convolutional Models: a Kernel  Perspective",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2102.10032",
    "authors": [
      "Alberto Bietti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.16398",
    "title": "Percolation and Epidemic Processes in One-Dimensional Small-World  Networks",
    "abstract": " Title: Percolation and Epidemic Processes in One-Dimensional Small-World  Networks ",
    "url": "https://arxiv.org/abs/2103.16398",
    "authors": [
      "Luca Becchetti",
      "Andrea Clementi",
      "Riccardo Denni",
      "Francesco Pasquale",
      "Luca Trevisan",
      "Isabella Ziccardi"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2104.08793",
    "title": "SalKG: Learning From Knowledge Graph Explanations for Commonsense  Reasoning",
    "abstract": " Comments: NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2104.08793",
    "authors": [
      "Aaron Chan",
      "Jiashu Xu",
      "Boyuan Long",
      "Soumya Sanyal",
      "Tanishq Gupta",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2104.12081",
    "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
    "abstract": " Comments: Accepted to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2104.12081",
    "authors": [
      "Dapeng Hu",
      "Shipeng Yan",
      "Qizhengqiu Lu",
      "Lanqing Hong",
      "Hailin Hu",
      "Yifan Zhang",
      "Zhenguo Li",
      "Xinchao Wang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05113",
    "title": "More Than Meets the Eye: Self-Supervised Depth Reconstruction from Brain  Activity",
    "abstract": " Title: More Than Meets the Eye: Self-Supervised Depth Reconstruction from Brain  Activity ",
    "url": "https://arxiv.org/abs/2106.05113",
    "authors": [
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.10422",
    "title": "From Coarse to Fine: Global Guided Patch-based Robust Tensor Completion  for Visual Data",
    "abstract": " Title: From Coarse to Fine: Global Guided Patch-based Robust Tensor Completion  for Visual Data ",
    "url": "https://arxiv.org/abs/2106.10422",
    "authors": [
      "Yicong He",
      "George K. Atia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.09203",
    "title": "Wide and Deep Graph Neural Network with Distributed Online Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2006.06376 ",
    "url": "https://arxiv.org/abs/2107.09203",
    "authors": [
      "Zhan Gao",
      "Fernando Gama",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2107.09639",
    "title": "Toward Structural Controllability and Predictability in Directed  Networks",
    "abstract": " Comments: some co-author perfers not to publish online before formal publication ",
    "url": "https://arxiv.org/abs/2107.09639",
    "authors": [
      "Fei Jing",
      "Chuang Liu",
      "Yi-Cheng Zhang",
      "Jian-Liang Wu",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.11216",
    "title": "The complexity of the bondage problem in planar graphs",
    "abstract": " Comments: 24 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2107.11216",
    "authors": [
      "Valentin Bouquet"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2107.14742",
    "title": "Connections between Numerical Algorithms for PDEs and Neural Networks",
    "abstract": " Title: Connections between Numerical Algorithms for PDEs and Neural Networks ",
    "url": "https://arxiv.org/abs/2107.14742",
    "authors": [
      "Tobias Alt",
      "Karl Schrader",
      "Matthias Augustin",
      "Pascal Peter",
      "Joachim Weickert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.06227",
    "title": "SimCVD: Simple Contrastive Voxel-Wise Representation Distillation for  Semi-Supervised Medical Image Segmentation",
    "abstract": " Comments: IEEE Transactions on Medical Imaging (IEEE-TMI) 2022 ",
    "url": "https://arxiv.org/abs/2108.06227",
    "authors": [
      "Chenyu You",
      "Yuan Zhou",
      "Ruihan Zhao",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.08736",
    "title": "Forced Oscillation Identification and Filtering from Multi-Channel  Time-Frequency Representation",
    "abstract": " Comments: Submitted to IEEE Transactions on Power Systems ",
    "url": "https://arxiv.org/abs/2108.08736",
    "authors": [
      "Pablo Gill Estevez",
      "Pablo Marchi",
      "Francisco Messina",
      "Cecilia Galarza"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2108.09128",
    "title": "Semi-supervised Network Embedding with Differentiable Deep Quantisation",
    "abstract": " Title: Semi-supervised Network Embedding with Differentiable Deep Quantisation ",
    "url": "https://arxiv.org/abs/2108.09128",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2108.11663",
    "title": "Convolutional Neural Networks Demystified: A Matched Filtering  Perspective Based Tutorial",
    "abstract": " Comments: 21 pages, 9 figures. arXiv admin note: text overlap with arXiv:2108.10751 ",
    "url": "https://arxiv.org/abs/2108.11663",
    "authors": [
      "Ljubisa Stankovic",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2108.13011",
    "title": "Robust Tube-based Model Predictive Control with Koopman  Operators--Extended Version",
    "abstract": " Comments: 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2108.13011",
    "authors": [
      "Xinglong Zhang",
      "Wei Pan",
      "Riccardo Scattolini",
      "Shuyou Yu",
      "Xin Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.04200",
    "title": "Double-Scale Self-Supervised Hypergraph Learning for Group  Recommendation",
    "abstract": " Comments: 11 pages, 6 figures, CIKM 2021 ",
    "url": "https://arxiv.org/abs/2109.04200",
    "authors": [
      "Junwei Zhang",
      "Min Gao",
      "Junliang Yu",
      "Lei Guo",
      "Jundong Li",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.04684",
    "title": "Enhancing Unsupervised Anomaly Detection with Score-Guided Network",
    "abstract": " Title: Enhancing Unsupervised Anomaly Detection with Score-Guided Network ",
    "url": "https://arxiv.org/abs/2109.04684",
    "authors": [
      "Zongyuan Huang",
      "Baohua Zhang",
      "Guoqiang Hu",
      "Longyuan Li",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.04983",
    "title": "A Neural Tangent Kernel Perspective of Infinite Tree Ensembles",
    "abstract": " Comments: Accepted to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2109.04983",
    "authors": [
      "Ryuichi Kanoh",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2109.05491",
    "title": "DynSTGAT: Dynamic Spatial-Temporal Graph Attention Network for Traffic  Signal Control",
    "abstract": " Comments: I need to revise it ",
    "url": "https://arxiv.org/abs/2109.05491",
    "authors": [
      "Libing Wu",
      "Min Wang",
      "Dan Wu",
      "Jia Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2109.13748",
    "title": "Improving Autoencoder Training Performance for Hyperspectral Unmixing  with Network Reinitialisation",
    "abstract": " Title: Improving Autoencoder Training Performance for Hyperspectral Unmixing  with Network Reinitialisation ",
    "url": "https://arxiv.org/abs/2109.13748",
    "authors": [
      "Kamil Ksi\u0105\u017cek",
      "Przemys\u0142aw G\u0142omb",
      "Micha\u0142 Romaszewski",
      "Micha\u0142 Cholewa",
      "Bartosz Grabowski",
      "Kriszti\u00e1n B\u00faza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.01077",
    "title": "Multi-task Voice Activated Framework using Self-supervised Learning",
    "abstract": " Comments: Accepted at ICASSP 2022 ",
    "url": "https://arxiv.org/abs/2110.01077",
    "authors": [
      "Shehzeen Hussain",
      "Van Nguyen",
      "Shuhua Zhang",
      "Erik Visser"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.03868",
    "title": "Towards Learning (Dis)-Similarity of Source Code from Program Contrasts",
    "abstract": " Comments: ACL 2022 Camera-Ready ",
    "url": "https://arxiv.org/abs/2110.03868",
    "authors": [
      "Yangruibo Ding",
      "Luca Buratti",
      "Saurabh Pujar",
      "Alessandro Morari",
      "Baishakhi Ray",
      "Saikat Chakraborty"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2110.05283",
    "title": "Phase Collapse in Neural Networks",
    "abstract": " Comments: 17 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2110.05283",
    "authors": [
      "Florentin Guth",
      "John Zarka",
      "St\u00e9phane Mallat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.06786",
    "title": "Optical-Flow-Reuse-Based Bidirectional Recurrent Network for Space-Time  Video Super-Resolution",
    "abstract": " Comments: We use bicubic downsampling to facilitate fair comparison ",
    "url": "https://arxiv.org/abs/2110.06786",
    "authors": [
      "Yuantong Zhang",
      "Huairui Wang",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.10942",
    "title": "Generalization of Neural Combinatorial Solvers Through the Lens of  Adversarial Robustness",
    "abstract": " Title: Generalization of Neural Combinatorial Solvers Through the Lens of  Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2110.10942",
    "authors": [
      "Simon Geisler",
      "Johanna Sommer",
      "Jan Schuchardt",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14369",
    "title": "ConAM: Confidence Attention Module for Convolutional Neural Networks",
    "abstract": " Comments: We need to withdraw this article due to a conflict of interest ",
    "url": "https://arxiv.org/abs/2110.14369",
    "authors": [
      "Yu Xue",
      "Ziming Yuan",
      "Ferrante Neri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.15277",
    "title": "A Novel Sleep Stage Classification Using CNN Generated by an Efficient  Neural Architecture Search with a New Data Processing Trick",
    "abstract": " Comments: We need to withdraw this article due to a conflict of interest ",
    "url": "https://arxiv.org/abs/2110.15277",
    "authors": [
      "Yu Xue",
      "Ziming Yuan",
      "Adam Slowik"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.02215",
    "title": "How Neural Architectures Affect Deep Learning for Communication  Networks?",
    "abstract": " Title: How Neural Architectures Affect Deep Learning for Communication  Networks? ",
    "url": "https://arxiv.org/abs/2111.02215",
    "authors": [
      "Yifei Shen",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.07401",
    "title": "Neural Capacity Estimators: How Reliable Are They?",
    "abstract": " Comments: 7 pages, accepted for publication at the 2022 IEEE International Conference on Communications (ICC) ",
    "url": "https://arxiv.org/abs/2111.07401",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini",
      "Nariman Farsad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2111.09489",
    "title": "Data-driven discoveries of B\u00e4cklund transforms and soliton evolution  equations via deep neural network learning schemes",
    "abstract": " Comments: 25 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2111.09489",
    "authors": [
      "Zijian Zhou",
      "Li Wang",
      "Weifang Weng",
      "Zhenya Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Pattern Formation and Solitons (nlin.PS)",
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ]
  },
  {
    "id": "arXiv:2111.10545",
    "title": "RDF-to-Text Generation with Reinforcement Learning Based Graph-augmented  Structural Neural Encoders",
    "abstract": " Title: RDF-to-Text Generation with Reinforcement Learning Based Graph-augmented  Structural Neural Encoders ",
    "url": "https://arxiv.org/abs/2111.10545",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Hongyun Zhang",
      "Zhihua Wei",
      "Po Hu",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.10639",
    "title": "Implicit Acoustic Echo Cancellation for Keyword Spotting and  Device-Directed Speech Detection",
    "abstract": " Comments: Submitted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2111.10639",
    "authors": [
      "Samuele Cornell",
      "Thomas Balestri",
      "Thibaud S\u00e9n\u00e9chal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.11017",
    "title": "Benchmarking emergency department triage prediction models with machine  learning and large public electronic health records",
    "abstract": " Title: Benchmarking emergency department triage prediction models with machine  learning and large public electronic health records ",
    "url": "https://arxiv.org/abs/2111.11017",
    "authors": [
      "Feng Xie",
      "Jun Zhou",
      "Jin Wee Lee",
      "Mingrui Tan",
      "Siqi Li",
      "Logasan S/O Rajnthern",
      "Marcel Lucas Chee",
      "Bibhas Chakraborty",
      "An-Kwok Ian Wong",
      "Alon Dagan",
      "Marcus Eng Hock Ong",
      "Fei Gao",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.11949",
    "title": "Consensus formation on heterogeneous networks",
    "abstract": " Comments: 7 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2111.11949",
    "authors": [
      "Edoardo Fadda",
      "Junda He",
      "Claudio Tessone",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.12066",
    "title": "Physics Informed Neural Networks for Control Oriented Thermal Modeling  of Buildings",
    "abstract": " Comments: 14 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2111.12066",
    "authors": [
      "Gargya Gokhale",
      "Bert Claessens",
      "Chris Develder"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2111.13723",
    "title": "SARS-CoV-2 Dissemination using a Network of the United States Counties",
    "abstract": " Title: SARS-CoV-2 Dissemination using a Network of the United States Counties ",
    "url": "https://arxiv.org/abs/2111.13723",
    "authors": [
      "Patrick Urrutia",
      "David Wren",
      "Chrysafis Vogiatzis",
      "Ruriko Yoshida"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2111.14517",
    "title": "Robust and Accurate Superquadric Recovery: a Probabilistic Approach",
    "abstract": " Comments: Accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2111.14517",
    "authors": [
      "Weixiao Liu",
      "Yuwei Wu",
      "Sipu Ruan",
      "Gregory S. Chirikjian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.15490",
    "title": "FENeRF: Face Editing in Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2022. Project: this https URL ",
    "url": "https://arxiv.org/abs/2111.15490",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Yong Zhang",
      "Xiaoyu Li",
      "Qi Zhang",
      "Yebin Liu",
      "Jue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00434",
    "title": "Training Experimentally Robust and Interpretable Binarized Regression  Models Using Mixed-Integer Programming",
    "abstract": " Title: Training Experimentally Robust and Interpretable Binarized Regression  Models Using Mixed-Integer Programming ",
    "url": "https://arxiv.org/abs/2112.00434",
    "authors": [
      "Sanjana Tule",
      "Nhi Ha Lan Le",
      "Buser Say"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01514",
    "title": "Self-supervised Video Transformer",
    "abstract": " Comments: Accepted to CVPR '22 ",
    "url": "https://arxiv.org/abs/2112.01514",
    "authors": [
      "Kanchana Ranasinghe",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Michael Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01518",
    "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting",
    "abstract": " Comments: Accepted to CVPR2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.01518",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Guangyi Chen",
      "Yansong Tang",
      "Zheng Zhu",
      "Guan Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01945",
    "title": "A Study of the Impact of the Contention Window on the Performance of  IEEE 802.11bd Networks with Channel Bonding",
    "abstract": " Comments: 5 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2112.01945",
    "authors": [
      "Viktor Torgunakov",
      "Vyacheslav Loginov",
      "Evgeny Khorov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.02362",
    "title": "Order in the chaos with examples from graph theory",
    "abstract": " Comments: 2 pages English abstract, 20 pages in Hungarian (Rend a rendezetlens\\'egben -- gr\\'afelm\\'eleti p\\'eld\\'akkal) ",
    "url": "https://arxiv.org/abs/2112.02362",
    "authors": [
      "Zolt\u00e1n K\u00e1sa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.02962",
    "title": "DANets: Deep Abstract Networks for Tabular Data Classification and  Regression",
    "abstract": " Comments: @inproceedings{danets, title={DANets: Deep Abstract Networks for Tabular Data Classification and Regression}, author={Chen, Jintai and Liao, Kuanlun and Wan, Yao and Chen, Danny Z and Wu, Jian}, booktitle={AAAI}, year={2022} } ",
    "url": "https://arxiv.org/abs/2112.02962",
    "authors": [
      "Jintai Chen",
      "Kuanlun Liao",
      "Yao Wan",
      "Danny Z. Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.03383",
    "title": "Graph Neural Networks Accelerated Molecular Dynamics",
    "abstract": " Comments: preprint ",
    "url": "https://arxiv.org/abs/2112.03383",
    "authors": [
      "Zijie Li",
      "Kazem Meidani",
      "Prakarsh Yadav",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2112.03549",
    "title": "GaTector: A Unified Framework for Gaze Object Prediction",
    "abstract": " Comments: CVPR 2022, camera ready ",
    "url": "https://arxiv.org/abs/2112.03549",
    "authors": [
      "Binglu Wang",
      "Tao Hu",
      "Baoshan Li",
      "Xiaojuan Chen",
      "Zhijie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04314",
    "title": "A systematic approach to random data augmentation on graph neural  networks",
    "abstract": " Title: A systematic approach to random data augmentation on graph neural  networks ",
    "url": "https://arxiv.org/abs/2112.04314",
    "authors": [
      "Billy Joe Franks",
      "Markus Anders",
      "Marius Kloft",
      "Pascal Schweitzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.06386",
    "title": "Sparse Structure Learning via Graph Neural Networks for Inductive  Document Classification",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2112.06386",
    "authors": [
      "Yinhua Piao",
      "Sangseon Lee",
      "Dohoon Lee",
      "Sun Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.08831",
    "title": "Bridging between Cognitive Processing Signals and Linguistic Features  via a Unified Attentional Network",
    "abstract": " Title: Bridging between Cognitive Processing Signals and Linguistic Features  via a Unified Attentional Network ",
    "url": "https://arxiv.org/abs/2112.08831",
    "authors": [
      "Yuqi Ren",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11243",
    "title": "Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images  Anomaly Detection",
    "abstract": " Comments: I need revise this paper ",
    "url": "https://arxiv.org/abs/2112.11243",
    "authors": [
      "Yurong Chen",
      "Hui Zhang",
      "Yaonan Wang",
      "Q. M. Jonathan Wu",
      "Yimin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03019",
    "title": "Robust and Resource-Efficient Data-Free Knowledge Distillation by  Generative Pseudo Replay",
    "abstract": " Comments: Accepted by the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22) ",
    "url": "https://arxiv.org/abs/2201.03019",
    "authors": [
      "Kuluhan Binici",
      "Shivam Aggarwal",
      "Nam Trung Pham",
      "Karianto Leman",
      "Tulika Mitra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.07428",
    "title": "Variable Augmented Network for Invertible MR Coil Compression",
    "abstract": " Title: Variable Augmented Network for Invertible MR Coil Compression ",
    "url": "https://arxiv.org/abs/2201.07428",
    "authors": [
      "Xianghao Liao",
      "Shanshan Wang",
      "Lanlan Tu",
      "Yuhao Wang",
      "Dong Liang",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2201.07540",
    "title": "Virtual Coil Augmentation Technology for MR Coil Extrapolation via Deep  Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2103.15061, arXiv:1907.03063, arXiv:1807.03039 by other authors ",
    "url": "https://arxiv.org/abs/2201.07540",
    "authors": [
      "Cailian Yang",
      "Xianghao Liao",
      "Yuhao Wang",
      "Minghui Zhang",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08780",
    "title": "Real-Time Seizure Detection using EEG: A Comprehensive Comparison of  Recent Approaches under a Realistic Setting",
    "abstract": " Comments: Real-Time Seizure Detection with EEG ",
    "url": "https://arxiv.org/abs/2201.08780",
    "authors": [
      "Kwanhyung Lee",
      "Hyewon Jeong",
      "Seyun Kim",
      "Donghwa Yang",
      "Hoon-Chul Kang",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2201.08845",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.09910",
    "title": "Learning Neural Contextual Bandits Through Perturbed Rewards",
    "abstract": " Title: Learning Neural Contextual Bandits Through Perturbed Rewards ",
    "url": "https://arxiv.org/abs/2201.09910",
    "authors": [
      "Yiling Jia",
      "Weitong Zhang",
      "Dongruo Zhou",
      "Quanquan Gu",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11871",
    "title": "Infrastructure-Based Object Detection and Tracking for Cooperative  Driving Automation: A Survey",
    "abstract": " Title: Infrastructure-Based Object Detection and Tracking for Cooperative  Driving Automation: A Survey ",
    "url": "https://arxiv.org/abs/2201.11871",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Xuewei Qi",
      "Yongkang Liu",
      "Kentaro Oguchi",
      "Matthew J. Barth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.13299",
    "title": "Directed Weight Neural Networks for Protein Structure Representation  Learning",
    "abstract": " Title: Directed Weight Neural Networks for Protein Structure Representation  Learning ",
    "url": "https://arxiv.org/abs/2201.13299",
    "authors": [
      "Jiahan Li",
      "Shitong Luo",
      "Congyue Deng",
      "Chaoran Cheng",
      "Jiaqi Guan",
      "Leonidas Guibas",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.03181",
    "title": "On chromatic parameters of some Regular graphs",
    "abstract": " Comments: 6 pages ",
    "url": "https://arxiv.org/abs/2202.03181",
    "authors": [
      "Prajnanaswaroopa S"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2202.09556",
    "title": "HDAM: Heuristic Difference Attention Module for Convolutional Neural  Networks",
    "abstract": " Comments: We need to withdraw this article due to a conflict of interest ",
    "url": "https://arxiv.org/abs/2202.09556",
    "authors": [
      "Yu Xue",
      "Ziming Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13248",
    "title": "Automated Data Augmentations for Graph Classification",
    "abstract": " Title: Automated Data Augmentations for Graph Classification ",
    "url": "https://arxiv.org/abs/2202.13248",
    "authors": [
      "Youzhi Luo",
      "Michael McThrow",
      "Wing Yee Au",
      "Tao Komikado",
      "Kanji Uchino",
      "Koji Maruhash",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.13590",
    "title": "LCP-dropout: Compression-based Multiple Subword Segmentation for Neural  Machine Translation",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2202.13590",
    "authors": [
      "Keita Nonaka",
      "Kazutaka Yamanouchi",
      "Tomohiro I",
      "Tsuyoshi Okita",
      "Kazutaka Shimada",
      "Hiroshi Sakamoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00725",
    "title": "A Conformer Based Acoustic Model for Robust Automatic Speech Recognition",
    "abstract": " Comments: 5 pages, 2 figures, submitted to Interspeech 2022 ",
    "url": "https://arxiv.org/abs/2203.00725",
    "authors": [
      "Yufeng Yang",
      "Peidong Wang",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01910",
    "title": "Efficient Data Structures for Exploiting Sparsity and Structure in  Representation of Polynomial Optimization Problems: Implementation in  SOSTOOLS",
    "abstract": " Title: Efficient Data Structures for Exploiting Sparsity and Structure in  Representation of Polynomial Optimization Problems: Implementation in  SOSTOOLS ",
    "url": "https://arxiv.org/abs/2203.01910",
    "authors": [
      "Declan Jagt",
      "Sachin Shivakumar",
      "Peter Seiler",
      "Matthew Peet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2203.02622",
    "title": "Scaling R-GCN Training with Graph Summarization",
    "abstract": " Comments: Companion Proceedings of the Web Conference 2022, April 25-29, 2022 ",
    "url": "https://arxiv.org/abs/2203.02622",
    "authors": [
      "Alessandro Generale",
      "Till Blume",
      "Michael Cochez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04421",
    "title": "Leveraging Smooth Attention Prior for Multi-Agent Trajectory Prediction",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2203.04421",
    "authors": [
      "Zhangjie Cao",
      "Erdem B\u0131y\u0131k",
      "Guy Rosman",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.04771",
    "title": "Multiscale Convolutional Transformer with Center Mask Pretraining for  Hyperspectral Image Classification",
    "abstract": " Comments: 8 pages, 26 figures, conference paper ",
    "url": "https://arxiv.org/abs/2203.04771",
    "authors": [
      "Sen Jia",
      "Yifan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05151",
    "title": "Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity",
    "abstract": " Comments: 10 pages, 7 figure, CVPR 2022 conference (accepted) ",
    "url": "https://arxiv.org/abs/2203.05151",
    "authors": [
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Bizhu Wu",
      "Jinheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05903",
    "title": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models",
    "abstract": " Title: Formal Control Synthesis for Stochastic Neural Network Dynamic Models ",
    "url": "https://arxiv.org/abs/2203.05903",
    "authors": [
      "Steven Adams",
      "Morteza Lahijanian",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.06319",
    "title": "PillarGrid: Deep Learning-based Cooperative Perception for 3D Object  Detection from Onboard-Roadside LiDAR",
    "abstract": " Comments: Submitted to The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022) ",
    "url": "https://arxiv.org/abs/2203.06319",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Yongkang Liu",
      "Emrah Akin Sisbot",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.06907",
    "title": "Hierarchical Memory Learning for Fine-Grained Scene Graph Generation",
    "abstract": " Title: Hierarchical Memory Learning for Fine-Grained Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2203.06907",
    "authors": [
      "Youming Deng",
      "Yansheng Li",
      "Yongjun Zhang",
      "Xiang Xiang",
      "Jian Wang",
      "Jingdong Chen",
      "Jiayi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07669",
    "title": "Progressive End-to-End Object Detection in Crowded Scenes",
    "abstract": " Title: Progressive End-to-End Object Detection in Crowded Scenes ",
    "url": "https://arxiv.org/abs/2203.07669",
    "authors": [
      "Anlin Zheng",
      "Yuang Zhang",
      "Xiangyu Zhang",
      "Xiaojuan Qi",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07772",
    "title": "Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy",
    "abstract": " Title: Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy ",
    "url": "https://arxiv.org/abs/2203.07772",
    "authors": [
      "St\u00e9phane Cuenat",
      "Louis Andr\u00e9oli",
      "Antoine N. Andr\u00e9",
      "Patrick Sandoz",
      "Guillaume J. Laurent",
      "Rapha\u00ebl Couturier",
      "Maxime Jacquot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.07782",
    "title": "Complex Evolutional Pattern Learning for Temporal Knowledge Graph  Reasoning",
    "abstract": " Comments: ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2203.07782",
    "authors": [
      "Zixuan Li",
      "Saiping Guan",
      "Xiaolong Jin",
      "Weihua Peng",
      "Yajuan Lyu",
      "Yong Zhu",
      "Long Bai",
      "Wei Li",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07788",
    "title": "Scalable Penalized Regression for Noise Detection in Learning with Noisy  Labels",
    "abstract": " Comments: To appear in CVPR2022. Code and pretrained models will be released after going through necessary procedures ",
    "url": "https://arxiv.org/abs/2203.07788",
    "authors": [
      "Yikai Wang",
      "Xinwei Sun",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07860",
    "title": "Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models  Robust with Little Cost",
    "abstract": " Comments: Long paper accepted by ACL main conference. 17 pages ",
    "url": "https://arxiv.org/abs/2203.07860",
    "authors": [
      "Lihu Chen",
      "Ga\u00ebl Varoquaux",
      "Fabian M. Suchanek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08280",
    "title": "Data Transfer and Network Services management for Domain Science  Workflows",
    "abstract": " Comments: contribution to Snowmass 2022 ",
    "url": "https://arxiv.org/abs/2203.08280",
    "authors": [
      "Tom Lehman",
      "Xi Yang",
      "Chin Guok",
      "Frank Wuerthwein",
      "Igor Sfiligoi",
      "John Graham",
      "Aashay Arora",
      "Dima Mishin",
      "Diego Davila",
      "Jonathan Guiang",
      "Tom Hutton",
      "Harvey Newman",
      "Justas Balcas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.08394",
    "title": "Bridging the Data Gap between Training and Inference for Unsupervised  Neural Machine Translation",
    "abstract": " Comments: 13 pages, ACL 2022 ",
    "url": "https://arxiv.org/abs/2203.08394",
    "authors": [
      "Zhiwei He",
      "Xing Wang",
      "Rui Wang",
      "Shuming Shi",
      "Zhaopeng Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08959",
    "title": "Robustness through Cognitive Dissociation Mitigation in Contrastive  Adversarial Training",
    "abstract": " Title: Robustness through Cognitive Dissociation Mitigation in Contrastive  Adversarial Training ",
    "url": "https://arxiv.org/abs/2203.08959",
    "authors": [
      "Adir Rahamim",
      "Itay Naeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09093",
    "title": "Semantic-aligned Fusion Transformer for One-shot Object Detection",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.09093",
    "authors": [
      "Yizhou Zhao",
      "Xun Guo",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09096",
    "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "abstract": " Title: DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications ",
    "url": "https://arxiv.org/abs/2203.09096",
    "authors": [
      "Claudia Iriondo",
      "Evan Casey",
      "Mohsen Hejrati",
      "Somaye Hashemifar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.09210",
    "title": "Universal Conditional Masked Language Pre-training for Neural Machine  Translation",
    "abstract": " Comments: Accepted to ACL 2022 Main conference ",
    "url": "https://arxiv.org/abs/2203.09210",
    "authors": [
      "Pengfei Li",
      "Liangyou Li",
      "Meng Zhang",
      "Minghao Wu",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.09354",
    "title": "Context-Dependent Anomaly Detection with Knowledge Graph Embedding  Models",
    "abstract": " Title: Context-Dependent Anomaly Detection with Knowledge Graph Embedding  Models ",
    "url": "https://arxiv.org/abs/2203.09354",
    "authors": [
      "Nathan Vaska",
      "Kevin Leahy",
      "Victoria Helus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09507",
    "title": "Towards Data-Efficient Detection Transformers",
    "abstract": " Comments: Code is available at this https URL and this https URL ",
    "url": "https://arxiv.org/abs/2203.09507",
    "authors": [
      "Wen Wang",
      "Jing Zhang",
      "Yang Cao",
      "Yongliang Shen",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09672",
    "title": "Multi-Modal Causal Inference with Deep Structural Equation Models",
    "abstract": " Title: Multi-Modal Causal Inference with Deep Structural Equation Models ",
    "url": "https://arxiv.org/abs/2203.09672",
    "authors": [
      "Shachi Deshpande",
      "Zheng Li",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]