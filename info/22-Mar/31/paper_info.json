[
  {
    "id": "arXiv:2203.15802",
    "title": "Shift-Robust Node Classification via Graph Adversarial Clustering",
    "abstract": "Graph Neural Networks (GNNs) are de facto node classification models in graph structured data. However, during testing-time, these algorithms assume no data shift, i.e., $\\Pr_\\text{train}(X,Y) = \\Pr_\\text{test}(X,Y)$. Domain adaption methods can be adopted for data shift, yet most of them are designed to only encourage similar feature distribution between source and target data. Conditional shift on classes can still affect such adaption. Fortunately, graph yields graph homophily across different data distributions. In response, we propose Shift-Robust Node Classification (SRNC) to address these limitations. We introduce an unsupervised cluster GNN on target graph to group the similar nodes by graph homophily. An adversarial loss with label information on source graph is used upon clustering objective. Then a shift-robust classifier is optimized on training graph and adversarial samples on target graph, which are generated by cluster GNN. We conduct experiments on both open-set shift and representation-shift, which demonstrates the superior accuracy of SRNC on generalizing to test graph with data shift. SRNC is consistently better than previous SoTA domain adaption algorithm on graph that progressively use model predictions on target graph for training. ",
    "url": "https://arxiv.org/abs/2203.15802",
    "authors": [
      "Qi Zhu",
      "Chao Zhang",
      "Chanyoung Park",
      "Carl Yang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15806",
    "title": "Bayesian Photonic Accelerators for Energy Efficient and Noise Robust  Neural Processing",
    "abstract": "Artificial neural networks are efficient computing platforms inspired by the brain. Such platforms can tackle a vast area of real-life tasks ranging from image processing to language translation. Silicon photonic integrated chips (PICs), by employing coherent interactions in Mach-Zehnder interferometers, are promising accelerators offering record low power consumption and ultra-fast matrix multiplication. Such photonic accelerators, however, suffer from phase uncertainty due to fabrication errors and crosstalk effects that inhibit the development of high-density implementations. In this work, we present a Bayesian learning framework for such photonic accelerators. In addition to the conventional log-likelihood optimization path, two novel training schemes are derived, namely a regularized version and a fully Bayesian learning scheme. They are applied on a photonic neural network with 512 phase shifters targeting the MNIST dataset. The new schemes, when combined with a pre-characterization stage that provides the passive offsets, are able to dramatically decrease the operational power of the PIC beyond 70%, with just a slight loss in classification accuracy. The full Bayesian scheme, apart from this energy reduction, returns information with respect to the sensitivity of the phase shifters. This information is used to de-activate 31% of the phase actuators and, thus, significantly simplify the driving system. ",
    "url": "https://arxiv.org/abs/2203.15806",
    "authors": [
      "George Sarantoglou",
      "Adonis Bogris",
      "Charis Mesaritakis",
      "Sergios Theodoridis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.15807",
    "title": "High Speed Photonic Neuromorphic Computing Using Recurrent Optical  Spectrum Slicing Neural Networks",
    "abstract": "Neuromorphic Computing implemented in photonic hardware is one of the most promising routes towards achieving machine learning processing at the picosecond scale, with minimum power consumption. In this work, we present a new concept for realizing photonic recurrent neural networks and reservoir computing architectures with the use of recurrent optical spectrum slicing. This is accomplished through simple optical filters placed in an loop, where each filter processes a specific spectral slice of the incoming optical signal. The synaptic weights in our scheme are equivalent to filters central frequencies and bandwidths. This new method for implementing recurrent neural processing in the photonic domain, which we call Recurrent Optical Spectrum Slicing Neural Networks, is numerically evaluated on a demanding, industry-relevant task such as high baud rate optical signal equalization 100 Gbaud, exhibiting ground-breaking performance. The performance enhancement surpasses state-of-the-art digital processing techniques by doubling the reach while minimizing complexity and power consumption by a factor of 10 compared to state-of-the-art solutions. In this respect, ROSS-NNs can pave the way for the implementation of ultra-efficient photonic hardware accelerators tailored for processing high-bandwidth optical signals in optical communication and high-speed imaging applications ",
    "url": "https://arxiv.org/abs/2203.15807",
    "authors": [
      "K. Sozos",
      "A. Bogris",
      "P. Bienstman",
      "G. Sarantoglou",
      "S. Deligiannidis",
      "C. Mesaritakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computational Physics (physics.comp-ph)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.15836",
    "title": "VPTR: Efficient Transformers for Video Prediction",
    "abstract": "In this paper, we propose a new Transformer block for video future frames prediction based on an efficient local spatial-temporal separation attention mechanism. Based on this new Transformer block, a fully autoregressive video future frames prediction Transformer is proposed. In addition, a non-autoregressive video prediction Transformer is also proposed to increase the inference speed and reduce the accumulated inference errors of its autoregressive counterpart. In order to avoid the prediction of very similar future frames, a contrastive feature loss is applied to maximize the mutual information between predicted and ground-truth future frame features. This work is the first that makes a formal comparison of the two types of attention-based video future frames prediction models over different scenarios. The proposed models reach a performance competitive with more complex state-of-the-art models. The source code is available at \\emph{https://github.com/XiYe20/VPTR}. ",
    "url": "https://arxiv.org/abs/2203.15836",
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15841",
    "title": "NNLander-VeriF: A Neural Network Formal Verification Framework for  Vision-Based Autonomous Aircraft Landing",
    "abstract": "In this paper, we consider the problem of formally verifying a Neural Network (NN) based autonomous landing system. In such a system, a NN controller processes images from a camera to guide the aircraft while approaching the runway. A central challenge for the safety and liveness verification of vision-based closed-loop systems is the lack of mathematical models that captures the relation between the system states (e.g., position of the aircraft) and the images processed by the vision-based NN controller. Another challenge is the limited abilities of state-of-the-art NN model checkers. Such model checkers can reason only about simple input-output robustness properties of neural networks. This limitation creates a gap between the NN model checker abilities and the need to verify a closed-loop system while considering the aircraft dynamics, the perception components, and the NN controller. To this end, this paper presents NNLander-VeriF, a framework to verify vision-based NN controllers used for autonomous landing. NNLander-VeriF addresses the challenges above by exploiting geometric models of perspective cameras to obtain a mathematical model that captures the relation between the aircraft states and the inputs to the NN controller. By converting this model into a NN (with manually assigned weights) and composing it with the NN controller, one can capture the relation between aircraft states and control actions using one augmented NN. Such an augmented NN model leads to a natural encoding of the closed-loop verification into several NN robustness queries, which state-of-the-art NN model checkers can handle. Finally, we evaluate our framework to formally verify the properties of a trained NN and we show its efficiency. ",
    "url": "https://arxiv.org/abs/2203.15841",
    "authors": [
      "Ulices Santa Cruz",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.15850",
    "title": "Fault Detection and Isolation of Uncertain Nonlinear Parabolic PDE  Systems",
    "abstract": "This paper proposes a novel fault detection and isolation (FDI) scheme for distributed parameter systems modeled by a class of parabolic partial differential equations (PDEs) with nonlinear uncertain dynamics. A key feature of the proposed FDI scheme is its capability of dealing with the effects of system uncertainties for accurate FDI. Specifically, an approximate ordinary differential equation (ODE) system is first derived to capture the dominant dynamics of the original PDE system. An adaptive dynamics identification approach using radial basis function neural network is then proposed based on this ODE system, so as to achieve locally-accurate identification of the uncertain system dynamics under normal and faulty modes. A bank of FDI estimators with associated adaptive thresholds are finally designed for real-time FDI decision making. Rigorous analysis on the FDI performance in terms of fault detectability and isolatability is provided. Simulation study on a representative transport-reaction process is conducted to demonstrate the effectiveness and advantage of the proposed approach. ",
    "url": "https://arxiv.org/abs/2203.15850",
    "authors": [
      "Jingting Zhang",
      "Chengzhi Yuan",
      "Wei Zeng",
      "Cong Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15851",
    "title": "Neural Inertial Localization",
    "abstract": "This paper proposes the inertial localization problem, the task of estimating the absolute location from a sequence of inertial sensor measurements. This is an exciting and unexplored area of indoor localization research, where we present a rich dataset with 53 hours of inertial sensor data and the associated ground truth locations. We developed a solution, dubbed neural inertial localization (NILoc) which 1) uses a neural inertial navigation technique to turn inertial sensor history to a sequence of velocity vectors; then 2) employs a transformer-based neural architecture to find the device location from the sequence of velocities. We only use an IMU sensor, which is energy efficient and privacy preserving compared to WiFi, cameras, and other data sources. Our approach is significantly faster and achieves competitive results even compared with state-of-the-art methods that require a floorplan and run 20 to 30 times slower. We share our code, model and data at https://sachini.github.io/niloc. ",
    "url": "https://arxiv.org/abs/2203.15851",
    "authors": [
      "Sachini Herath",
      "David Caruso",
      "Chen Liu",
      "Yufan Chen",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15854",
    "title": "Locomotion Policy Guided Traversability Learning using Volumetric  Representations of Complex Environments",
    "abstract": "Despite the progress in legged robotic locomotion, autonomous navigation in unknown environments remains an open problem. Ideally, the navigation system utilizes the full potential of the robots' locomotion capabilities while operating within safety limits under uncertainty. The robot must sense and analyze the traversability of the surrounding terrain, which depends on the hardware, locomotion control, and terrain properties. It may contain information about the risk, energy, or time consumption needed to traverse the terrain. To avoid hand-crafted traversability cost functions we propose to collect traversability information about the robot and locomotion policy by simulating the traversal over randomly generated terrains using a physics simulator. Thousand of robots are simulated in parallel controlled by the same locomotion policy used in reality to acquire 57 years of real-world locomotion experience equivalent. For deployment on the real robot, a sparse convolutional network is trained to predict the simulated traversability cost, which is tailored to the deployed locomotion policy, from an entirely geometric representation of the environment in the form of a 3D voxel-occupancy map. This representation avoids the need for commonly used elevation maps, which are error-prone in the presence of overhanging obstacles and multi-floor or low-ceiling scenarios. The effectiveness of the proposed traversability prediction network is demonstrated for path planning for the legged robot ANYmal in various indoor and natural environments. ",
    "url": "https://arxiv.org/abs/2203.15854",
    "authors": [
      "Jonas Frey",
      "David Hoeller",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15859",
    "title": "NICGSlowDown: Evaluating the Efficiency Robustness of Neural Image  Caption Generation Models",
    "abstract": "Neural image caption generation (NICG) models have received massive attention from the research community due to their excellent performance in visual understanding. Existing work focuses on improving NICG model accuracy while efficiency is less explored. However, many real-world applications require real-time feedback, which highly relies on the efficiency of NICG models. Recent research observed that the efficiency of NICG models could vary for different inputs. This observation brings in a new attack surface of NICG models, i.e., An adversary might be able to slightly change inputs to cause the NICG models to consume more computational resources. To further understand such efficiency-oriented threats, we propose a new attack approach, NICGSlowDown, to evaluate the efficiency robustness of NICG models. Our experimental results show that NICGSlowDown can generate images with human-unnoticeable perturbations that will increase the NICG model latency up to 483.86%. We hope this research could raise the community's concern about the efficiency robustness of NICG models. ",
    "url": "https://arxiv.org/abs/2203.15859",
    "authors": [
      "Simin Chen",
      "Zihe Song",
      "Mirazul Haque",
      "Cong Liu",
      "Wei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15872",
    "title": "Protective Mission against a Highly Maneuverable Rogue Drone Using  Defense Margin Strategy",
    "abstract": "The current paper studies a protective mission to defend a domain called the safe zone from a rogue drone invasion. We consider a one attacker and one defender drone scenario where only a noisy observation of the attacker at every time step is accessible to the defender. Directly applying strategies used in existing problems such as pursuit-evasion games are shown to be insufficient for our mission. We introduce a new concept of defense margin to complement an existing strategy and construct a control strategy that successfully solves our problem. We provide analytical proofs to point out the limitations of the existing strategy and how our defense margin strategy can be used to enhance performance. Simulation results show that our suggested strategy outperforms that of the existing strategy at least by 36.0%p in terms of mission success. ",
    "url": "https://arxiv.org/abs/2203.15872",
    "authors": [
      "Minjun Sung",
      "Christophe Johannes Hiltebrandt-McIntosh",
      "Hunmin Kim",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15876",
    "title": "Self-Supervised Learning for Recommender Systems: A Survey",
    "abstract": "Neural architecture-based recommender systems have achieved tremendous success in recent years. However, when dealing with highly sparse data, they still fall short of expectation. Self-supervised learning (SSL), as an emerging technique to learn with unlabeled data, recently has drawn considerable attention in many fields. There is also a growing body of research proceeding towards applying SSL to recommendation for mitigating the data sparsity issue. In this survey, a timely and systematical review of the research efforts on self-supervised recommendation (SSR) is presented. Specifically, we propose an exclusive definition of SSR, on top of which we build a comprehensive taxonomy to divide existing SSR methods into four categories: contrastive, generative, predictive, and hybrid. For each category, the narrative unfolds along its concept and formulation, the involved methods, and its pros and cons. Meanwhile, to facilitate the development and evaluation of SSR models, we release an open-source library SELFRec, which incorporates multiple benchmark datasets and evaluation metrics, and has implemented a number of state-of-the-art SSR models for empirical comparison. Finally, we shed light on the limitations in the current research and outline the future research directions. ",
    "url": "https://arxiv.org/abs/2203.15876",
    "authors": [
      "Junliang Yu",
      "Hongzhi Yin",
      "Xin Xia",
      "Tong Chen",
      "Jundong Li",
      "Zi Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.15878",
    "title": "Characterizations of graph classes via convex geometries: A survey",
    "abstract": "Graph convexity has been used as an important tool to better understand the structure of classes of graphs. Many studies are devoted to determine if a graph equipped with a convexity is a {\\em convex geometry}. In this work we survey results on characterizations of well-known classes of graphs via convex geometries. We also give some contributions to this subject. ",
    "url": "https://arxiv.org/abs/2203.15878",
    "authors": [
      "Mitre C. Dourado",
      "F\u00e1bio Protti",
      "Rudini Sampaio"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2203.15880",
    "title": "Proactive Image Manipulation Detection",
    "abstract": "Image manipulation detection algorithms are often trained to discriminate between images manipulated with particular Generative Models (GMs) and genuine/real images, yet generalize poorly to images manipulated with GMs unseen in the training. Conventional detection algorithms receive an input image passively. By contrast, we propose a proactive scheme to image manipulation detection. Our key enabling technique is to estimate a set of templates which when added onto the real image would lead to more accurate manipulation detection. That is, a template protected real image, and its manipulated version, is better discriminated compared to the original real image vs. its manipulated one. These templates are estimated using certain constraints based on the desired properties of templates. For image manipulation detection, our proposed approach outperforms the prior work by an average precision of 16% for CycleGAN and 32% for GauGAN. Our approach is generalizable to a variety of GMs showing an improvement over prior work by an average precision of 10% averaged across 12 GMs. Our code is available at https://www.github.com/vishal3477/proactive_IMD. ",
    "url": "https://arxiv.org/abs/2203.15880",
    "authors": [
      "Vishal Asnani",
      "Xi Yin",
      "Tal Hassner",
      "Sijia Liu",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15884",
    "title": "Radial Autoencoders for Enhanced Anomaly Detection",
    "abstract": "In classification problems, supervised machine-learning methods outperform traditional algorithms, thanks to the ability of neural networks to learn complex patterns. However, in two-class classification tasks like anomaly or fraud detection, unsupervised methods could do even better, because their prediction is not limited to previously learned types of anomalies. An intuitive approach of anomaly detection can be based on the distances from the centers of mass of the two respective classes. Autoencoders, although trained without supervision, can also detect anomalies: considering the center of mass of the normal points, reconstructions have now radii, with largest radii most likely indicating anomalous points. Of course, radii-based classification were already possible without interposing an autoencoder. In any space, radial classification can be operated, to some extent. In order to outperform it, we proceed to radial deformations of data (i.e. centric compression or expansions of axes) and autoencoder training. Any autoencoder that makes use of a data center is here baptized a centric autoencoder (cAE). A special type is the cAE trained with a uniformly compressed dataset, named the centripetal autoencoder (cpAE). The new concept is studied here in relation with a schematic artificial dataset, and the derived methods show consistent score improvements. But tested on real banking data, our radial deformation supervised algorithms alone still perform better that cAEs, as expected from most supervised methods; nonetheless, in hybrid approaches, cAEs can be combined with a radial deformation of space, improving its classification score. We expect that centric autoencoders will become irreplaceable objects in anomaly live detection based on geometry, thanks to their ability to stem naturally on geometrical algorithms and to their native capability of detecting unknown anomaly types. ",
    "url": "https://arxiv.org/abs/2203.15884",
    "authors": [
      "Mihai-Cezar Augustin",
      "Vivien Bonvin",
      "Regis Houssou",
      "Efstratios Rappos",
      "Stephan Robert-Nicoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15913",
    "title": "Pretraining Graph Neural Networks for few-shot Analog Circuit Modeling  and Design",
    "abstract": "Being able to predict the performance of circuits without running expensive simulations is a desired capability that can catalyze automated design. In this paper, we present a supervised pretraining approach to learn circuit representations that can be adapted to new circuit topologies or unseen prediction tasks. We hypothesize that if we train a neural network (NN) that can predict the output DC voltages of a wide range of circuit instances it will be forced to learn generalizable knowledge about the role of each circuit element and how they interact with each other. The dataset for this supervised learning objective can be easily collected at scale since the required DC simulation to get ground truth labels is relatively cheap. This representation would then be helpful for few-shot generalization to unseen circuit metrics that require more time consuming simulations for obtaining the ground-truth labels. To cope with the variable topological structure of different circuits we describe each circuit as a graph and use graph neural networks (GNNs) to learn node embeddings. We show that pretraining GNNs on prediction of output node voltages can encourage learning representations that can be adapted to new unseen topologies or prediction of new circuit level properties with up to 10x more sample efficiency compared to a randomly initialized model. We further show that we can improve sample efficiency of prior SoTA model-based optimization methods by 2x (almost as good as using an oracle model) via fintuning pretrained GNNs as the feature extractor of the learned models. ",
    "url": "https://arxiv.org/abs/2203.15913",
    "authors": [
      "Kourosh Hakhamaneshi",
      "Marcel Nassar",
      "Mariano Phielipp",
      "Pieter Abbeel",
      "Vladimir Stojanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15924",
    "title": "Hybrid of monolithic and staggered solution techniques for the  computational analysis of fracture, assessed on fibrous network mechanics",
    "abstract": "The computational analysis of fiber network fracture is an emerging field with application to paper, rubber-like materials, hydrogels, soft biological tissue, and composites. Fiber networks are often described as probabilistic structures of interacting one-dimensional elements, such as truss-bars and beams. Failure may then be modeled as strong discontinuities in the displacement field that are directly embedded within the structural finite elements. As for other strain-softening materials, the tangent stiffness matrix can be non-positive definite, which diminishes the robustness of the solution of the coupled (monolithic) two-field problem. Its uncoupling, and thus the use of a staggered solution method where the field variables are solved alternatingly, avoids such difficulties and results in a stable, but sub-optimally converging solution method. In the present work, we evaluate the staggered against the monolithic solution approach and assess their computational performance in the analysis of fiber network failure. We then propose a hybrid solution technique that optimizes the performance and robustness of the computational analysis. It represents a matrix regularization technique that retains a positive definite element stiffness matrix while approaching the tangent stiffness matrix of the monolithic problem. The approach is general and may also accelerate the computational analysis of other failure problems. ",
    "url": "https://arxiv.org/abs/2203.15924",
    "authors": [
      "Vedad Tojaga",
      "Artem Kulachenko",
      "Soren Ostlund",
      "T. Christian Gasser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.15935",
    "title": "Graph Neural Networks in IoT: A Survey",
    "abstract": "The Internet of Things (IoT) boom has revolutionized almost every corner of people's daily lives: healthcare, home, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technologies, IoT devices including smart wearables, cameras, smartwatches, and autonomous vehicles can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph Neural Networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art results in numerous IoT learning tasks. In this survey, we present a comprehensive review of recent advances in the application of GNNs to the IoT field, including a deep dive analysis of GNN design in various IoT sensing environments, an overarching list of public data and source code from the collected publications, and future research directions. To keep track of newly published works, we collect representative papers and their open-source implementations and create a Github repository at https://github.com/GuiminDong/GNN4IoT. ",
    "url": "https://arxiv.org/abs/2203.15935",
    "authors": [
      "Guimin Dong",
      "Mingyue Tang",
      "Zhiyuan Wang",
      "Jiechao Gao",
      "Sikun Guo",
      "Lihua Cai",
      "Robert Gutierrez",
      "Bradford Campbell",
      "Laura E. Barnes",
      "Mehdi Boukhechba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15936",
    "title": "A Simple Yet Effective Pretraining Strategy for Graph Few-shot Learning",
    "abstract": "Recently, increasing attention has been devoted to the graph few-shot learning problem, where the target novel classes only contain a few labeled nodes. Among many existing endeavors, episodic meta-learning has become the most prevailing paradigm, and its episodic emulation of the test environment is believed to equip the graph neural network models with adaptability to novel node classes. However, in the image domain, recent results have shown that feature reuse is more likely to be the key of meta-learning to few-shot extrapolation. Based on such observation, in this work, we propose a simple transductive fine-tuning based framework as a new paradigm for graph few-shot learning. In the proposed paradigm, a graph encoder backbone is pretrained with base classes, and a simple linear classifier is fine-tuned by the few labeled samples and is tasked to classify the unlabeled ones. For pretraining, we propose a supervised contrastive learning framework with data augmentation strategies specific for few-shot node classification to improve the extrapolation of a GNN encoder. Finally, extensive experiments conducted on three benchmark datasets demonstrate the superior advantage of our framework over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.15936",
    "authors": [
      "Zhen Tan",
      "Kaize Ding",
      "Ruocheng Guo",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15943",
    "title": "Self-Supervised Leaf Segmentation under Complex Lighting Conditions",
    "abstract": "As an essential prerequisite task in image-based plant phenotyping, leaf segmentation has garnered increasing attention in recent years. While self-supervised learning is emerging as an effective alternative to various computer vision tasks, its adaptation for image-based plant phenotyping remains rather unexplored. In this work, we present a self-supervised leaf segmentation framework consisting of a self-supervised semantic segmentation model, a color-based leaf segmentation algorithm, and a self-supervised color correction model. The self-supervised semantic segmentation model groups the semantically similar pixels by iteratively referring to the self-contained information, allowing the pixels of the same semantic object to be jointly considered by the color-based leaf segmentation algorithm for identifying the leaf regions. Additionally, we propose to use a self-supervised color correction model for images taken under complex illumination conditions. Experimental results on datasets of different plant species demonstrate the potential of the proposed self-supervised framework in achieving effective and generalizable leaf segmentation. ",
    "url": "https://arxiv.org/abs/2203.15943",
    "authors": [
      "Xufeng Lin",
      "Chang-Tsun Li",
      "Scott Adams",
      "Abbas Kouzani",
      "Richard Jiang",
      "Ligang He",
      "Yongjian Hu",
      "Michael Vernon",
      "Egan Doeven",
      "Lawrence Webb",
      "Todd Mcclellan",
      "Adam Guskic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.15946",
    "title": "Towards Learning Neural Representations from Shadows",
    "abstract": "We present a method that learns neural scene representations from only shadows present in the scene. While traditional shape-from-shadow (SfS) algorithms reconstruct geometry from shadows, they assume a fixed scanning setup and fail to generalize to complex scenes. Neural rendering algorithms, on the other hand, rely on photometric consistency between RGB images but largely ignore physical cues such as shadows, which have been shown to provide valuable information about the scene. We observe that shadows are a powerful cue that can constrain neural scene representations to learn SfS, and even outperform NeRF to reconstruct otherwise hidden geometry. We propose a graphics-inspired differentiable approach to render accurate shadows with volumetric rendering, predicting a shadow map that can be compared to the ground truth shadow. Even with just binary shadow maps, we show that neural rendering can localize the object and estimate coarse geometry. Our approach reveals that sparse cues in images can be used to estimate geometry using differentiable volumetric rendering. Moreover, our framework is highly generalizable and can work alongside existing 3D reconstruction techniques that otherwise only use photometric consistency. Our code is made available in our supplementary materials. ",
    "url": "https://arxiv.org/abs/2203.15946",
    "authors": [
      "Kushagra Tiwary",
      "Tzofi Klinghoffer",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.15948",
    "title": "Leveraging Evolutionary Algorithms for Feasible Hexapod Locomotion  Across Uneven Terrain",
    "abstract": "Optimizing gait stability for legged robots is a difficult problem. Even on level surfaces, effectively traversing across different textures (e.g., carpet) rests on dynamically tuning parameters in multidimensional space. Inspired by biology, evolutionary algorithms (EA) remain an attractive solution for feasibly implementing robotic locomotion with both energetic economy and rapid parameter convergence. Here, we leveraged this class of algorithms to evolve a stable hexapod gait controller capable of traversing uneven terrain and obstacles. Gait parameters were evolved in a rigid body dynamics simulation on an 8 x 3 meter obstacle course comprised of random step field, linear obstacles and inclined surfaces. Using a fitness function that jointly optimized locomotion velocity and stability, we found that multiple successful gait parameter evolutions yielded specialized functionality for each leg. Specific gait parameters were identified as critical to developing a rough terrain gait. ",
    "url": "https://arxiv.org/abs/2203.15948",
    "authors": [
      "Jack Vice",
      "Gita Sukthankar",
      "Pamela K. Douglas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.15950",
    "title": "Empirical Standards for Repository Mining",
    "abstract": "The purpose of scholarly peer review is to evaluate the quality of scientific manuscripts. However, study after study demonstrates that peer review neither effectively nor reliably assesses research quality. Empirical standards attempt to address this problem by modelling a scientific community's expectations for each kind of empirical study conducted in that community. This should enhance not only the quality of research but also the reliability and predictability of peer review, as scientists adopt the standards in both their researcher and reviewer roles. However, these improvements depend on the quality and adoption of the standards. This tutorial will therefore present the empirical standard for mining software repositories, both to communicate its contents and to get feedback from the attendees. The tutorial will be organized into three parts: (1) brief overview of the empirical standards project; (2) detailed presentation of the repository mining standard; (3) discussion and suggestions for improvement. ",
    "url": "https://arxiv.org/abs/2203.15950",
    "authors": [
      "Preetha Chatterjee",
      "Tushar Sharma",
      "Paul Ralph"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.15955",
    "title": "Investigating the Properties of Neural Network Representations in  Reinforcement Learning",
    "abstract": "In this paper we investigate the properties of representations learned by deep reinforcement learning systems. Much of the earlier work in representation learning for reinforcement learning focused on designing fixed-basis architectures to achieve properties thought to be desirable, such as orthogonality and sparsity. In contrast, the idea behind deep reinforcement learning methods is that the agent designer should not encode representational properties, but rather that the data stream should determine the properties of the representation -- good representations emerge under appropriate training schemes. In this paper we bring these two perspectives together, empirically investigating the properties of representations that support transfer in reinforcement learning. This analysis allows us to provide novel hypotheses regarding impact of auxiliary tasks in end-to-end training of non-linear reinforcement learning methods. We introduce and measure six representational properties over more than 25 thousand agent-task settings. We consider DQN agents with convolutional networks in a pixel-based navigation environment. We develop a method to better understand \\emph{why} some representations work better for transfer, through a systematic approach varying task similarity and measuring and correlating representation properties with transfer performance. ",
    "url": "https://arxiv.org/abs/2203.15955",
    "authors": [
      "Han Wang",
      "Erfan Miahi",
      "Martha White",
      "Marlos C. Machado",
      "Zaheer Abbas",
      "Raksha Kumaraswamy",
      "Vincent Liu",
      "Adam White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15965",
    "title": "PSMNet: Position-aware Stereo Merging Network for Room Layout Estimation",
    "abstract": "In this paper, we propose a new deep learning-based method for estimating room layout given a pair of 360 panoramas. Our system, called Position-aware Stereo Merging Network or PSMNet, is an end-to-end joint layout-pose estimator. PSMNet consists of a Stereo Pano Pose (SP2) transformer and a novel Cross-Perspective Projection (CP2) layer. The stereo-view SP2 transformer is used to implicitly infer correspondences between views, and can handle noisy poses. The pose-aware CP2 layer is designed to render features from the adjacent view to the anchor (reference) view, in order to perform view fusion and estimate the visible layout. Our experiments and analysis validate our method, which significantly outperforms the state-of-the-art layout estimators, especially for large and complex room spaces. ",
    "url": "https://arxiv.org/abs/2203.15965",
    "authors": [
      "Haiyan Wang",
      "Will Hutchcroft",
      "Yuguang Li",
      "Zhiqiang Wan",
      "Ivaylo Boyadzhiev",
      "Yingli Tian",
      "Sing Bing Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15981",
    "title": "Spy in the GPU-box: Covert and Side Channel Attacks on Multi-GPU Systems",
    "abstract": "The deep learning revolution has been enabled in large part by GPUs, and more recently accelerators, which make it possible to carry out computationally demanding training and inference in acceptable times. As the size of machine learning networks and workloads continues to increase, multi-GPU machines have emerged as an important platform offered on High Performance Computing and cloud data centers. As these machines are shared between multiple users, it becomes increasingly important to protect applications against potential attacks. In this paper, we explore the vulnerability of Nvidia's DGX multi-GPU machines to covert and side channel attacks. These machines consist of a number of discrete GPUs that are interconnected through a combination of custom interconnect (NVLink) and PCIe connections. We reverse engineer the cache hierarchy and show that it is possible for an attacker on one GPU to cause contention on the L2 cache of another GPU. We use this observation to first develop a covert channel attack across two GPUs, achieving the best bandwidth of 3.95 MB/s. We also develop a prime and probe attack on a remote GPU allowing an attacker to recover the cache hit and miss behavior of another workload. This basic capability can be used in any number of side channel attacks: we demonstrate a proof of concept attack that fingerprints the application running on the remote GPU, with high accuracy. Our work establishes for the first time the vulnerability of these machines to microarchitectural attacks, and we hope that it guides future research to improve their security. ",
    "url": "https://arxiv.org/abs/2203.15981",
    "authors": [
      "Sankha Baran Dutta",
      "Hoda Naghibijouybari",
      "Arjun Gupta",
      "Nael Abu-Ghazaleh",
      "Andres Marquez",
      "Kevin Barker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.15987",
    "title": "Fine-Grained Object Classification via Self-Supervised Pose Alignment",
    "abstract": "Semantic patterns of fine-grained objects are determined by subtle appearance difference of local parts, which thus inspires a number of part-based methods. However, due to uncontrollable object poses in images, distinctive details carried by local regions can be spatially distributed or even self-occluded, leading to a large variation on object representation. For discounting pose variations, this paper proposes to learn a novel graph based object representation to reveal a global configuration of local parts for self-supervised pose alignment across classes, which is employed as an auxiliary feature regularization on a deep representation learning network.Moreover, a coarse-to-fine supervision together with the proposed pose-insensitive constraint on shallow-to-deep sub-networks encourages discriminative features in a curriculum learning manner. We evaluate our method on three popular fine-grained object classification benchmarks, consistently achieving the state-of-the-art performance. Source codes are available at https://github.com/yangxh11/P2P-Net. ",
    "url": "https://arxiv.org/abs/2203.15987",
    "authors": [
      "Xuhui Yang",
      "Yaowei Wang",
      "Ke Chen",
      "Yong Xu",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15990",
    "title": "pycefr: Python Competency Level through Code Analysis",
    "abstract": "Python is known to be a versatile language, well suited both for beginners and advanced users. Some elements of the language are easier to understand than others: some are found in any kind of code, while some others are used only by experienced programmers. The use of these elements lead to different ways to code, depending on the experience with the language and the knowledge of its elements, the general programming competence and programming skills, etc. In this paper, we present pycefr, a tool that detects the use of the different elements of the Python language, effectively measuring the level of Python proficiency required to comprehend and deal with a fragment of Python code. Following the well-known Common European Framework of Reference for Languages (CEFR), widely used for natural languages, pycefr categorizes Python code in six levels, depending on the proficiency required to create and understand it. We also discuss different use cases for pycefr: identifying code snippets that can be understood by developers with a certain proficiency, labeling code examples in online resources such as Stackoverflow and GitHub to suit them to a certain level of competency, helping in the onboarding process of new developers in Open Source Software projects, etc. A video shows availability and usage of the tool: https://tinyurl.com/ypdt3fwe. ",
    "url": "https://arxiv.org/abs/2203.15990",
    "authors": [
      "Gregorio Robles",
      "Raula Gaikovina Kula",
      "Chaiyong Ragkhitwetsagul",
      "Tattiya Sakulniwat",
      "Kenichi Matsumoto",
      "Jesus M. Gonzalez-Barahona"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.16006",
    "title": "Prognosis of Rotor Parts Fly-off Based on Cascade Classification and  Online Prediction Ability Index",
    "abstract": "Large rotating machines, e.g., compressors, steam turbines, gas turbines, are critical equipment in many process industries such as energy, chemical, and power generation. Due to high rotating speed and tremendous momentum of the rotor, the centrifugal force may lead to flying apart of the rotor parts, which brings a great threat to the operation safety. Early detection and prediction of potential failures could prevent the catastrophic plant downtime and economic loss. In this paper, we divide the operational states of a rotating machine into normal, risky, and high-risk ones based on the time to the moment of failure. Then a cascade classifying algorithm is proposed to predict the states in two steps, first we judge whether the machine is in normal or abnormal condition; for time periods which are predicted as abnormal we further classify them into risky or high-risk states. Moreover, traditional classification model evaluation metrics, such as confusion matrix, true-false accuracy, are static and neglect the online prediction dynamics and uneven wrong-prediction prices. An Online Prediction Ability Index (OPAI) is proposed to select prediction models with consistent online predictions and smaller close-to-downtime prediction errors. Real-world data sets and computational experiments are used to verify the effectiveness of proposed methods. ",
    "url": "https://arxiv.org/abs/2203.16006",
    "authors": [
      "Yingjun Shen",
      "Zhe Song",
      "Andrew Kusiak"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16027",
    "title": "Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension",
    "abstract": "Task-adaptive pre-training (TAPT) alleviates the lack of labelled data and provides performance lift by adapting unlabelled data to downstream task. Unfortunately, existing adaptations mainly involve deterministic rules that cannot generalize well. Here, we propose Clozer, a sequence-tagging based cloze answer extraction method used in TAPT that is extendable for adaptation on any cloze-style machine reading comprehension (MRC) downstream tasks. We experiment on multiple-choice cloze-style MRC tasks, and show that Clozer performs significantly better compared to the oracle and state-of-the-art in escalating TAPT effectiveness in lifting model performance, and prove that Clozer is able to recognize the gold answers independently of any heuristics. ",
    "url": "https://arxiv.org/abs/2203.16027",
    "authors": [
      "Holy Lovenia",
      "Bryan Wilie",
      "Willy Chung",
      "Min Zeng",
      "Samuel Cahyawijaya",
      "Su Dan",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16028",
    "title": "Span Classification with Structured Information for Disfluency Detection  in Spoken Utterances",
    "abstract": "Existing approaches in disfluency detection focus on solving a token-level classification task for identifying and removing disfluencies in text. Moreover, most works focus on leveraging only contextual information captured by the linear sequences in text, thus ignoring the structured information in text which is efficiently captured by dependency trees. In this paper, building on the span classification paradigm of entity recognition, we propose a novel architecture for detecting disfluencies in transcripts from spoken utterances, incorporating both contextual information through transformers and long-distance structured information captured by dependency trees, through graph convolutional networks (GCNs). Experimental results show that our proposed model achieves state-of-the-art results on the widely used English Switchboard for disfluency detection and outperforms prior-art by a significant margin. We make all our codes publicly available on GitHub (https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification) ",
    "url": "https://arxiv.org/abs/2203.16028",
    "authors": [
      "Sreyan Ghosh",
      "Sonal Kumar",
      "Yaman Kumar Singla",
      "Rajiv Ratn Shah",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16031",
    "title": "How Deep is Your Art: An Experimental Study on the Limits of Artistic  Understanding in a Single-Task, Single-Modality Neural Network",
    "abstract": "Mathematical modeling and aesthetic rule extraction of works of art are complex activities. This is because art is a multidimensional, subjective discipline. Perception and interpretation of art are, to many extents, relative and open-ended rather than measurable. Following the explainable Artificial Intelligence paradigm, this paper investigated in a human-understandable fashion the limits to which a single-task, single-modality benchmark computer vision model performs in classifying contemporary 2D visual arts. It is important to point out that this work does not introduce an interpreting method to open the black box of Deep Neural Networks, instead it uses existing evaluating metrics derived from the confusion matrix to try to uncover the mechanism with which Deep Neural Networks understand art. To achieve so, VGG-11, pre-trained on ImageNet and discriminatively fine-tuned, was used on handcrafted small-data datasets designed from real-world photography gallery shows. We demonstrated that the artwork's Exhibited Properties or formal factors such as shape and color, rather than Non-Exhibited Properties or content factors such as history and intention, have much higher potential to be the determinant when art pieces have very similar Exhibited Properties. We also showed that a single-task and single-modality model's understanding of art is inadequate as it largely ignores Non-Exhibited Properties. ",
    "url": "https://arxiv.org/abs/2203.16031",
    "authors": [
      "Mahan Agha Zahedi",
      "Niloofar Gholamrezaei",
      "Alex Doboli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16040",
    "title": "Disentangling the Impacts of Language and Channel Variability on Speech  Separation Networks",
    "abstract": "Because the performance of speech separation is excellent for speech in which two speakers completely overlap, research attention has been shifted to dealing with more realistic scenarios. However, domain mismatch between training/test situations due to factors, such as speaker, content, channel, and environment, remains a severe problem for speech separation. Speaker and environment mismatches have been studied in the existing literature. Nevertheless, there are few studies on speech content and channel mismatches. Moreover, the impacts of language and channel in these studies are mostly tangled. In this study, we create several datasets for various experiments. The results show that the impacts of different languages are small enough to be ignored compared to the impacts of different channels. In our experiments, training on data recorded by Android phones leads to the best generalizability. Moreover, we provide a new solution for channel mismatch by evaluating projection, where the channel similarity can be measured and used to effectively select additional training data to improve the performance of in-the-wild test data. ",
    "url": "https://arxiv.org/abs/2203.16040",
    "authors": [
      "Fan-Lin Wang",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16045",
    "title": "Threshold Matters in WSSS: Manipulating the Activation for the Robust  and Accurate Segmentation Model Against Thresholds",
    "abstract": "Weakly-supervised semantic segmentation (WSSS) has recently gained much attention for its promise to train segmentation models only with image-level labels. Existing WSSS methods commonly argue that the sparse coverage of CAM incurs the performance bottleneck of WSSS. This paper provides analytical and empirical evidence that the actual bottleneck may not be sparse coverage but a global thresholding scheme applied after CAM. Then, we show that this issue can be mitigated by satisfying two conditions; 1) reducing the imbalance in the foreground activation and 2) increasing the gap between the foreground and the background activation. Based on these findings, we propose a novel activation manipulation network with a per-pixel classification loss and a label conditioning module. Per-pixel classification naturally induces two-level activation in activation maps, which can penalize the most discriminative parts, promote the less discriminative parts, and deactivate the background regions. Label conditioning imposes that the output label of pseudo-masks should be any of true image-level labels; it penalizes the wrong activation assigned to non-target classes. Based on extensive analysis and evaluations, we demonstrate that each component helps produce accurate pseudo-masks, achieving the robustness against the choice of the global threshold. Finally, our model achieves state-of-the-art records on both PASCAL VOC 2012 and MS COCO 2014 datasets. ",
    "url": "https://arxiv.org/abs/2203.16045",
    "authors": [
      "Minhyun Lee",
      "Dongseob Kim",
      "Hyunjung Shim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16051",
    "title": "Progressively Generating Better Initial Guesses Towards Next Stages for  High-Quality Human Motion Prediction",
    "abstract": "This paper presents a high-quality human motion prediction method that accurately predicts future human poses given observed ones. Our method is based on the observation that a good initial guess of the future poses is very helpful in improving the forecasting accuracy. This motivates us to propose a novel two-stage prediction framework, including an init-prediction network that just computes the good guess and then a formal-prediction network that predicts the target future poses based on the guess. More importantly, we extend this idea further and design a multi-stage prediction framework where each stage predicts initial guess for the next stage, which brings more performance gain. To fulfill the prediction task at each stage, we propose a network comprising Spatial Dense Graph Convolutional Networks (S-DGCN) and Temporal Dense Graph Convolutional Networks (T-DGCN). Alternatively executing the two networks helps extract spatiotemporal features over the global receptive field of the whole pose sequence. All the above design choices cooperating together make our method outperform previous approaches by large margins: 6%-7% on Human3.6M, 5%-10% on CMU-MoCap, and 13%-16% on 3DPW. ",
    "url": "https://arxiv.org/abs/2203.16051",
    "authors": [
      "Tiezheng Ma",
      "Yongwei Nie",
      "Chengjiang Long",
      "Qing Zhang",
      "Guiqing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16056",
    "title": "Automatic Facial Skin Feature Detection for Everyone",
    "abstract": "Automatic assessment and understanding of facial skin condition have several applications, including the early detection of underlying health problems, lifestyle and dietary treatment, skin-care product recommendation, etc. Selfies in the wild serve as an excellent data resource to democratize skin quality assessment, but suffer from several data collection challenges.The key to guaranteeing an accurate assessment is accurate detection of different skin features. We present an automatic facial skin feature detection method that works across a variety of skin tones and age groups for selfies in the wild. To be specific, we annotate the locations of acne, pigmentation, and wrinkle for selfie images with different skin tone colors, severity levels, and lighting conditions. The annotation is conducted in a two-phase scheme with the help of a dermatologist to train volunteers for annotation. We employ Unet++ as the network architecture for feature detection. This work shows that the two-phase annotation scheme can robustly detect the accurate locations of acne, pigmentation, and wrinkle for selfie images with different ethnicities, skin tone colors, severity levels, age groups, and lighting conditions. ",
    "url": "https://arxiv.org/abs/2203.16056",
    "authors": [
      "Qian Zheng",
      "Ankur Purwar",
      "Heng Zhao",
      "Guang Liang Lim",
      "Ling Li",
      "Debasish Behera",
      "Qian Wang",
      "Min Tan",
      "Rizhao Cai",
      "Jennifer Werner",
      "Dennis Sng",
      "Maurice van Steensel",
      "Weisi Lin",
      "Alex C Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16057",
    "title": "Self-supervised 360$^{\\circ}$ Room Layout Estimation",
    "abstract": "We present the first self-supervised method to train panoramic room layout estimation models without any labeled data. Unlike per-pixel dense depth that provides abundant correspondence constraints, layout representation is sparse and topological, hindering the use of self-supervised reprojection consistency on images. To address this issue, we propose Differentiable Layout View Rendering, which can warp a source image to the target camera pose given the estimated layout from the target image. As each rendered pixel is differentiable with respect to the estimated layout, we can now train the layout estimation model by minimizing reprojection loss. Besides, we introduce regularization losses to encourage Manhattan alignment, ceiling-floor alignment, cycle consistency, and layout stretch consistency, which further improve our predictions. Finally, we present the first self-supervised results on ZilloIndoor and MatterportLayout datasets. Our approach also shows promising solutions in data-scarce scenarios and active learning, which would have an immediate value in the real estate virtual tour software. Code is available at https://github.com/joshua049/Stereo-360-Layout. ",
    "url": "https://arxiv.org/abs/2203.16057",
    "authors": [
      "Hao-Wen Ting",
      "Cheng Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16060",
    "title": "Understanding Graph Convolutional Networks for Text Classification",
    "abstract": "Graph Convolutional Networks (GCN) have been effective at tasks that have rich relational structure and can preserve global structure information of a dataset in graph embeddings. Recently, many researchers focused on examining whether GCNs could handle different Natural Language Processing tasks, especially text classification. While applying GCNs to text classification is well-studied, its graph construction techniques, such as node/edge selection and their feature representation, and the optimal GCN learning mechanism in text classification is rather neglected. In this paper, we conduct a comprehensive analysis of the role of node and edge embeddings in a graph and its GCN learning techniques in text classification. Our analysis is the first of its kind and provides useful insights into the importance of each graph node/edge construction mechanism when applied at the GCN training/testing in different text classification benchmarks, as well as under its semi-supervised environment. ",
    "url": "https://arxiv.org/abs/2203.16060",
    "authors": [
      "Soyeon Caren Han",
      "Zihan Yuan",
      "Kunze Wang",
      "Siqu Long",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16063",
    "title": "Pay Attention to Hidden States for Video Deblurring: Ping-Pong Recurrent  Neural Networks and Selective Non-Local Attention",
    "abstract": "Video deblurring models exploit information in the neighboring frames to remove blur caused by the motion of the camera and the objects. Recurrent Neural Networks~(RNNs) are often adopted to model the temporal dependency between frames via hidden states. When motion blur is strong, however, hidden states are hard to deliver proper information due to the displacement between different frames. While there have been attempts to update the hidden states, it is difficult to handle misaligned features beyond the receptive field of simple modules. Thus, we propose 2 modules to supplement the RNN architecture for video deblurring. First, we design Ping-Pong RNN~(PPRNN) that acts on updating the hidden states by referring to the features from the current and the previous time steps alternately. PPRNN gathers relevant information from the both features in an iterative and balanced manner by utilizing its recurrent architecture. Second, we use a Selective Non-Local Attention~(SNLA) module to additionally refine the hidden state by aligning it with the positional information from the input frame feature. The attention score is scaled by the relevance to the input feature to focus on the necessary information. By paying attention to hidden states with both modules, which have strong synergy, our PAHS framework improves the representation powers of RNN structures and achieves state-of-the-art deblurring performance on standard benchmarks and real-world videos. ",
    "url": "https://arxiv.org/abs/2203.16063",
    "authors": [
      "JoonKyu Park",
      "Seungjun Nah",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16074",
    "title": "An Efficient Anchor-free Universal Lesion Detection in CT-scans",
    "abstract": "Existing universal lesion detection (ULD) methods utilize compute-intensive anchor-based architectures which rely on predefined anchor boxes, resulting in unsatisfactory detection performance, especially in small and mid-sized lesions. Further, these default fixed anchor-sizes and ratios do not generalize well to different datasets. Therefore, we propose a robust one-stage anchor-free lesion detection network that can perform well across varying lesions sizes by exploiting the fact that the box predictions can be sorted for relevance based on their center rather than their overlap with the object. Furthermore, we demonstrate that the ULD can be improved by explicitly providing it the domain-specific information in the form of multi-intensity images generated using multiple HU windows, followed by self-attention based feature-fusion and backbone initialization using weights learned via self-supervision over CT-scans. We obtain comparable results to the state-of-the-art methods, achieving an overall sensitivity of 86.05% on the DeepLesion dataset, which comprises of approximately 32K CT-scans with lesions annotated across various body organs. ",
    "url": "https://arxiv.org/abs/2203.16074",
    "authors": [
      "Manu Sheoran",
      "Meghal Dani",
      "Monika Sharma",
      "Lovekesh Vig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16084",
    "title": "STRPM: A Spatiotemporal Residual Predictive Model for High-Resolution  Video Prediction",
    "abstract": "Although many video prediction methods have obtained good performance in low-resolution (64$\\sim$128) videos, predictive models for high-resolution (512$\\sim$4K) videos have not been fully explored yet, which are more meaningful due to the increasing demand for high-quality videos. Compared with low-resolution videos, high-resolution videos contain richer appearance (spatial) information and more complex motion (temporal) information. In this paper, we propose a Spatiotemporal Residual Predictive Model (STRPM) for high-resolution video prediction. On the one hand, we propose a Spatiotemporal Encoding-Decoding Scheme to preserve more spatiotemporal information for high-resolution videos. In this way, the appearance details for each frame can be greatly preserved. On the other hand, we design a Residual Predictive Memory (RPM) which focuses on modeling the spatiotemporal residual features (STRF) between previous and future frames instead of the whole frame, which can greatly help capture the complex motion information in high-resolution videos. In addition, the proposed RPM can supervise the spatial encoder and temporal encoder to extract different features in the spatial domain and the temporal domain, respectively. Moreover, the proposed model is trained using generative adversarial networks (GANs) with a learned perceptual loss (LP-loss) to improve the perceptual quality of the predictions. Experimental results show that STRPM can generate more satisfactory results compared with various existing methods. ",
    "url": "https://arxiv.org/abs/2203.16084",
    "authors": [
      "Zheng Chang",
      "Xinfeng Zhang",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16089",
    "title": "Omni-DETR: Omni-Supervised Object Detection with Transformers",
    "abstract": "We consider the problem of omni-supervised object detection, which can use unlabeled, fully labeled and weakly labeled annotations, such as image tags, counts, points, etc., for object detection. This is enabled by a unified architecture, Omni-DETR, based on the recent progress on student-teacher framework and end-to-end transformer based object detection. Under this unified architecture, different types of weak labels can be leveraged to generate accurate pseudo labels, by a bipartite matching based filtering mechanism, for the model to learn. In the experiments, Omni-DETR has achieved state-of-the-art results on multiple datasets and settings. And we have found that weak annotations can help to improve detection performance and a mixture of them can achieve a better trade-off between annotation cost and accuracy than the standard complete annotation. These findings could encourage larger object detection datasets with mixture annotations. The code is available at https://github.com/amazon-research/omni-detr. ",
    "url": "https://arxiv.org/abs/2203.16089",
    "authors": [
      "Pei Wang",
      "Zhaowei Cai",
      "Hao Yang",
      "Gurumurthy Swaminathan",
      "Nuno Vasconcelos",
      "Bernt Schiele",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16090",
    "title": "A simple suboptimal moving horizon estimation scheme with guaranteed  robust stability",
    "abstract": "We propose a suboptimal moving horizon estimation (MHE) scheme for a general class of nonlinear systems. To this end, we consider an MHE formulation that optimizes over the trajectory of a robustly stable observer. Assuming that the observer admits a Lyapunov function, we show that this Lyapunov function is an M-step Lyapunov function for suboptimal MHE. The presented sufficient conditions can be easily verified in practice. We illustrate the practicability of the proposed suboptimal MHE scheme with a standard nonlinear benchmark example. Here, performing a single iteration is sufficient to significantly improve the observer's estimation results under valid theoretical guarantees. ",
    "url": "https://arxiv.org/abs/2203.16090",
    "authors": [
      "Julian D. Schiller",
      "Boyang Wu",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.16097",
    "title": "Neighbor Enhanced Graph Convolutional Networks for Node Classification  and Recommendation",
    "abstract": "The recently proposed Graph Convolutional Networks (GCNs) have achieved significantly superior performance on various graph-related tasks, such as node classification and recommendation. However, currently researches on GCN models usually recursively aggregate the information from all the neighbors or randomly sampled neighbor subsets, without explicitly identifying whether the aggregated neighbors provide useful information during the graph convolution. In this paper, we theoretically analyze the affection of the neighbor quality over GCN models' performance and propose the Neighbor Enhanced Graph Convolutional Network (NEGCN) framework to boost the performance of existing GCN models. Our contribution is three-fold. First, we at the first time propose the concept of neighbor quality for both node classification and recommendation tasks in a general theoretical framework. Specifically, for node classification, we propose three propositions to theoretically analyze how the neighbor quality affects the node classification performance of GCN models. Second, based on the three proposed propositions, we introduce the graph refinement process including specially designed neighbor evaluation methods to increase the neighbor quality so as to boost both the node classification and recommendation tasks. Third, we conduct extensive node classification and recommendation experiments on several benchmark datasets. The experimental results verify that our proposed NEGCN framework can significantly enhance the performance for various typical GCN models on both node classification and recommendation tasks. ",
    "url": "https://arxiv.org/abs/2203.16097",
    "authors": [
      "Hao Chen",
      "Zhong Huang",
      "Yue Xu",
      "Zengde Deng",
      "Feiran Huang",
      "Peng He",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16104",
    "title": "Improving Distortion Robustness of Self-supervised Speech Processing  Tasks with Domain Adaptation",
    "abstract": "Speech distortions are a long-standing problem that degrades the performance of supervisely trained speech processing models. It is high time that we enhance the robustness of speech processing models to obtain good performance when encountering speech distortions while not hurting the original performance on clean speech. In this work, we propose to improve the robustness of speech processing models by domain adversarial training (DAT). We conducted experiments based on the SUPERB framework on five different speech processing tasks. In case we do not always have knowledge of the distortion types for speech data, we analyzed the binary-domain and multi-domain settings, where the former treats all distorted speech as one domain, and the latter views different distortions as different domains. In contrast to supervised training methods, we obtained promising results in target domains where speech data is distorted with different distortions including new unseen distortions introduced during testing. ",
    "url": "https://arxiv.org/abs/2203.16104",
    "authors": [
      "Kuan Po Huang",
      "Yu-Kuan Fu",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16110",
    "title": "Weakly-supervised Temporal Path Representation Learning with Contrastive  Curriculum Learning -- Extended Version",
    "abstract": "In step with the digitalization of transportation, we are witnessing a growing range of path-based smart-city applications, e.g., travel-time estimation and travel path ranking. A temporal path~(TP) that includes temporal information, e.g., departure time, into the path is of fundamental to enable such applications. In this setting, it is essential to learn generic temporal path representations~(TPRs) that consider spatial and temporal correlations simultaneously and that can be used in different applications, i.e., downstream tasks. Existing methods fail to achieve the goal since (i) supervised methods require large amounts of task-specific labels when training and thus fail to generalize the obtained TPRs to other tasks; (ii) though unsupervised methods can learn generic representations, they disregard the temporal aspect, leading to sub-optimal results. To contend with the limitations of existing solutions, we propose a Weakly-Supervised Contrastive (WSC) learning model. We first propose a temporal path encoder that encodes both the spatial and temporal information of a temporal path into a TPR. To train the encoder, we introduce weak labels that are easy and inexpensive to obtain, and are relevant to different tasks, e.g., temporal labels indicating peak vs. off-peak hour from departure times. Based on the weak labels, we construct meaningful positive and negative temporal path samples by considering both spatial and temporal information, which facilities training the encoder using contrastive learning by pulling closer the positive samples' representations while pushing away the negative samples' representations. To better guide the contrastive learning, we propose a learning strategy based on Curriculum Learning such that the learning performs from easy to hard training instances. Experiments studies verify the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2203.16110",
    "authors": [
      "Sean Bin Yang",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang",
      "Jian Tang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16117",
    "title": "SIT: A Bionic and Non-Linear Neuron for Spiking Neural Network",
    "abstract": "Spiking Neural Networks (SNNs) have piqued researchers' interest because of their capacity to process temporal information and low power consumption. However, current state-of-the-art methods limited their biological plausibility and performance because their neurons are generally built on the simple Leaky-Integrate-and-Fire (LIF) model. Due to the high level of dynamic complexity, modern neuron models have seldom been implemented in SNN practice. In this study, we adopt the Phase Plane Analysis (PPA) technique, a technique often utilized in neurodynamics field, to integrate a recent neuron model, namely, the Izhikevich neuron. Based on the findings in the advancement of neuroscience, the Izhikevich neuron model can be biologically plausible while maintaining comparable computational cost with LIF neurons. By utilizing the adopted PPA, we have accomplished putting neurons built with the modified Izhikevich model into SNN practice, dubbed as the Standardized Izhikevich Tonic (SIT) neuron. For performance, we evaluate the suggested technique for image classification tasks in self-built LIF-and-SIT-consisted SNNs, named Hybrid Neural Network (HNN) on static MNIST, Fashion-MNIST, CIFAR-10 datasets and neuromorphic N-MNIST, CIFAR10-DVS, and DVS128 Gesture datasets. The experimental results indicate that the suggested method achieves comparable accuracy while exhibiting more biologically realistic behaviors on nearly all test datasets, demonstrating the efficiency of this novel strategy in bridging the gap between neurodynamics and SNN practice. ",
    "url": "https://arxiv.org/abs/2203.16117",
    "authors": [
      "Cheng Jin",
      "Rui-Jie Zhu",
      "Xiao Wu",
      "Liang-Jian Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.16123",
    "title": "An I/O-Efficient Disk-based Graph System for Scalable Second-Order  Random Walk of Large Graphs",
    "abstract": "Random walk is widely used in many graph analysis tasks, especially the first-order random walk. However, as a simplification of real-world problems, the first-order random walk is poor at modeling higher-order structures in the data. Recently, second-order random walk-based applications (e.g., Node2vec, Second-order PageRank) have become attractive. Due to the complexity of the second-order random walk models and memory limitations, it is not scalable to run second-order random walk-based applications on a single machine. Existing disk-based graph systems are only friendly to the first-order random walk models and suffer from expensive disk I/Os when executing the second-order random walks. This paper introduces an I/O-efficient disk-based graph system for the scalable second-order random walk of large graphs, called GraSorw. First, to eliminate massive light vertex I/Os, we develop a bi-block execution engine that converts random I/Os into sequential I/Os by applying a new triangular bi-block scheduling strategy, the bucket-based walk management, and the skewed walk storage. Second, to improve the I/O utilization, we design a learning-based block loading model to leverage the advantages of the full-load and on-demand load methods. Finally, we conducted extensive experiments on six large real datasets as well as several synthetic datasets. The empirical results demonstrate that the end-to-end time cost of popular tasks in GraSorw is reduced by more than one order of magnitude compared to the existing disk-based graph systems. ",
    "url": "https://arxiv.org/abs/2203.16123",
    "authors": [
      "Hongzheng Li",
      "Yingxia Shao",
      "Junping Du",
      "Bin Cui",
      "Lei Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.16135",
    "title": "Kron-based Model-order Reduction of Open Mass-action Kinetics Chemical  Reaction Networks",
    "abstract": "We propose a Kron-based model-order reduction method for mass-action kinetics chemical reaction networks (CRN) with constant inflow and proportional outflow. The reduced-order models preserve the CRN structure and we establish that the resulting reduced-order models have the same DC-gain or zero-moment as that of the full-order ones. Subsequently, we present the spectrum interlacing property of the Kron-reduced open CRN and propose the use of Gramians-based approach for single-species single-substrate chemical network to get the upper-bound of approximation error and to use it in determining a good set of nodes to be removed systematically. Finally, we evaluate the applicability and efficacy of our results in two well-known biochemical kinetic models: the activated sludge model (ASM) 1 and McKeithan's T-cell receptor model. ",
    "url": "https://arxiv.org/abs/2203.16135",
    "authors": [
      "Mohamad Agung Prawira Negara",
      "Azka Muji Burohman",
      "Bayu Jayawardhana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.16141",
    "title": "Example-based Explanations with Adversarial Attacks for Respiratory  Sound Analysis",
    "abstract": "Respiratory sound classification is an important tool for remote screening of respiratory-related diseases such as pneumonia, asthma, and COVID-19. To facilitate the interpretability of classification results, especially ones based on deep learning, many explanation methods have been proposed using prototypes. However, existing explanation techniques often assume that the data is non-biased and the prediction results can be explained by a set of prototypical examples. In this work, we develop a unified example-based explanation method for selecting both representative data (prototypes) and outliers (criticisms). In particular, we propose a novel application of adversarial attacks to generate an explanation spectrum of data instances via an iterative fast gradient sign method. Such unified explanation can avoid over-generalisation and bias by allowing human experts to assess the model mistakes case by case. We performed a wide range of quantitative and qualitative evaluations to show that our approach generates effective and understandable explanation and is robust with many deep learning models ",
    "url": "https://arxiv.org/abs/2203.16141",
    "authors": [
      "Yi Chang",
      "Zhao Ren",
      "Thanh Tam Nguyen",
      "Wolfgang Nejdl",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16151",
    "title": "Manipulative Attacks and Group Identification",
    "abstract": "The group identification problem asks to identify a socially qualified subgroup among a group of individuals based on their pairwise valuations. There are several different rules that can be used to determine the social qualification status. In this work, we consider the consent rules, the consensus-start-respecting rule, and the liberal-start-respecting rule. In the context of group identification, a manipulative attack is the attempt by an outsider to influence the outcome of the selection process through certain means of manipulation. These means include adding, removing, or partitioning individuals, as well as bribing individuals to change their opinion. In this work, we provide an overview of manipulative attacks in group identification as well as group identification with partial profiles. In particular, we study the computational complexity of the corresponding problems. Most results presented in this work are aggregated from the literature, but we also show results for previously unstudied problems; these include general and exact group control in binary profiles and in ternary profiles, as well as constructive group control in $r$-profiles. For many considered problems, we also study the parameterized complexity. ",
    "url": "https://arxiv.org/abs/2203.16151",
    "authors": [
      "Emil Junker"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2203.16162",
    "title": "AdaGrid: Adaptive Grid Search for Link Prediction Training Objective",
    "abstract": "One of the most important factors that contribute to the success of a machine learning model is a good training objective. Training objective crucially influences the model's performance and generalization capabilities. This paper specifically focuses on graph neural network training objective for link prediction, which has not been explored in the existing literature. Here, the training objective includes, among others, a negative sampling strategy, and various hyperparameters, such as edge message ratio which controls how training edges are used. Commonly, these hyperparameters are fine-tuned by complete grid search, which is very time-consuming and model-dependent. To mitigate these limitations, we propose Adaptive Grid Search (AdaGrid), which dynamically adjusts the edge message ratio during training. It is model agnostic and highly scalable with a fully customizable computational budget. Through extensive experiments, we show that AdaGrid can boost the performance of the models up to $1.9\\%$ while being nine times more time-efficient than a complete search. Overall, AdaGrid represents an effective automated algorithm for designing machine learning training objectives. ",
    "url": "https://arxiv.org/abs/2203.16162",
    "authors": [
      "Tim Po\u0161tuvan",
      "Jiaxuan You",
      "Mohammadreza Banaei",
      "R\u00e9mi Lebret",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.16187",
    "title": "Auto-MLM: Improved Contrastive Learning for Self-supervised  Multi-lingual Knowledge Retrieval",
    "abstract": "Contrastive learning (CL) has become a ubiquitous approach for several natural language processing (NLP) downstream tasks, especially for question answering (QA). However, the major challenge, how to efficiently train the knowledge retrieval model in an unsupervised manner, is still unresolved. Recently the commonly used methods are composed of CL and masked language model (MLM). Unexpectedly, MLM ignores the sentence-level training, and CL also neglects extraction of the internal info from the query. To optimize the CL hardly obtain internal information from the original query, we introduce a joint training method by combining CL and Auto-MLM for self-supervised multi-lingual knowledge retrieval. First, we acquire the fixed dimensional sentence vector. Then, mask some words among the original sentences with random strategy. Finally, we generate a new token representation for predicting the masked tokens. Experimental results show that our proposed approach consistently outperforms all the previous SOTA methods on both AliExpress $\\&$ LAZADA service corpus and openly available corpora in 8 languages. ",
    "url": "https://arxiv.org/abs/2203.16187",
    "authors": [
      "Wenshen Xu",
      "Mieradilijiang Maimaiti",
      "Yuanhang Zheng",
      "Xin Tang",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16210",
    "title": "Learning of Global Objective for Network Flow in Multi-Object Tracking",
    "abstract": "This paper concerns the problem of multi-object tracking based on the min-cost flow (MCF) formulation, which is conventionally studied as an instance of linear program. Given its computationally tractable inference, the success of MCF tracking largely relies on the learned cost function of underlying linear program. Most previous studies focus on learning the cost function by only taking into account two frames during training, therefore the learned cost function is sub-optimal for MCF where a multi-frame data association must be considered during inference. In order to address this problem, in this paper we propose a novel differentiable framework that ties training and inference together during learning by solving a bi-level optimization problem, where the lower-level solves a linear program and the upper-level contains a loss function that incorporates global tracking result. By back-propagating the loss through differentiable layers via gradient descent, the globally parameterized cost function is explicitly learned and regularized. With this approach, we are able to learn a better objective for global MCF tracking. As a result, we achieve competitive performances compared to the current state-of-the-art methods on the popular multi-object tracking benchmarks such as MOT16, MOT17 and MOT20. ",
    "url": "https://arxiv.org/abs/2203.16210",
    "authors": [
      "Shuai Li",
      "Yu Kong",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16218",
    "title": "APG: Adaptive Parameter Generation Network for Click-Through Rate  Prediction",
    "abstract": "In many web applications, deep learning-based CTR prediction models (deep CTR models for short) are widely adopted. Traditional deep CTR models learn patterns in a static manner, i.e., the network parameters are the same across all the instances. However, such a manner can hardly characterize each of the instances which may have different underlying distribution. It actually limits the representation power of deep CTR models, leading to sub-optimal results. In this paper, we propose an efficient, effective, and universal module, Adaptive Parameter Generation network (APG), where the parameters of deep CTR models are dynamically generated on-the-fly based on different instances. Extensive experimental evaluation results show that APG can be applied to a variety of deep CTR models and significantly improve their performance. We have deployed APG in the Taobao sponsored search system and achieved 3\\% CTR gain and 1\\% RPM gain respectively. ",
    "url": "https://arxiv.org/abs/2203.16218",
    "authors": [
      "Bencheng Yan",
      "Pengjie Wang",
      "Kai Zhang",
      "Feng Li",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16220",
    "title": "Target-aware Dual Adversarial Learning and a Multi-scenario  Multi-Modality Benchmark to Fuse Infrared and Visible for Object Detection",
    "abstract": "This study addresses the issue of fusing infrared and visible images that appear differently for object detection. Aiming at generating an image of high visual quality, previous approaches discover commons underlying the two modalities and fuse upon the common space either by iterative optimization or deep networks. These approaches neglect that modality differences implying the complementary information are extremely important for both fusion and subsequent detection task. This paper proposes a bilevel optimization formulation for the joint problem of fusion and detection, and then unrolls to a target-aware Dual Adversarial Learning (TarDAL) network for fusion and a commonly used detection network. The fusion network with one generator and dual discriminators seeks commons while learning from differences, which preserves structural information of targets from the infrared and textural details from the visible. Furthermore, we build a synchronized imaging system with calibrated infrared and optical sensors, and collect currently the most comprehensive benchmark covering a wide range of scenarios. Extensive experiments on several public datasets and our benchmark demonstrate that our method outputs not only visually appealing fusion but also higher detection mAP than the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2203.16220",
    "authors": [
      "Jinyuan Liu",
      "Xin Fan",
      "Zhanbo Huang",
      "Guanyao Wu",
      "Risheng Liu",
      "Wei Zhong",
      "Zhongxuan Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16221",
    "title": "On the Performance of Co-existence between Public eMBB and Non-public  URLLC Networks",
    "abstract": "To ensure the high level of automation required in today's industrial applications, next-generation wireless networks must enable real-time control and automation of dynamic processes with the requirements of extreme low-latency and ultra-reliable communications. In this paper, we provide a performance assessment for the co-existence of a public enhanced mobile broadband (eMBB) and a local non-public factory (URLLC) network and evaluate the network conditions under which the stringent latency and reliability requirements of factory automation applications are met. The evaluations consider both an unsynchronized and a synchronized time division duplexing (TDD) deployment between the networks, as well as scenarios both with and without any macro eMBB traffic located inside the factory. The results show that an unsynchronized deployment is possible if the isolation between the networks is sufficiently high, either as a result of a separation distance, wall loss or the use of separate frequencies for the networks. A synchronized deployment will avoid the cross-link interference, but it will not resolve the problems related to the closed access and the near-far interference. If the factory contains eMBB traffic served by the overlaid macro cells, the performance of both networks will suffer due to a high level of cross-link and near-far interference. The problems related to the cross-link interference can be resolved by synchronizing the networks, while the level of the near-far interference can be reduced by allowing the eMBB users to be connected to base stations located inside the factory. Finally, if an unsynchronized deployment is desired, the factory should be deployed on an isolated frequency. ",
    "url": "https://arxiv.org/abs/2203.16221",
    "authors": [
      "Yanpeng Yang",
      "Kimmo Hiltunen",
      "Fedor Chernogorov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.16246",
    "title": "Co-Membership-based Generic Anomalous Communities Detection",
    "abstract": "Nowadays, detecting anomalous communities in networks is an essential task in research, as it helps discover insights into community-structured networks. Most of the existing methods leverage either information regarding attributes of vertices or the topological structure of communities. In this study, we introduce the Co-Membership-based Generic Anomalous Communities Detection Algorithm (referred as to CMMAC), a novel and generic method that utilizes the information of vertices co-membership in multiple communities. CMMAC is domain-free and almost unaffected by communities' sizes and densities. Specifically, we train a classifier to predict the probability of each vertex in a community being a member of the community. We then rank the communities by the aggregated membership probabilities of each community's vertices. The lowest-ranked communities are considered to be anomalous. Furthermore, we present an algorithm for generating a community-structured random network enabling the infusion of anomalous communities to facilitate research in the field. We utilized it to generate two datasets, composed of thousands of labeled anomaly-infused networks, and published them. We experimented extensively on thousands of simulated, and real-world networks, infused with artificial anomalies. CMMAC outperformed other existing methods in a range of settings. Additionally, we demonstrated that CMMAC can identify abnormal communities in real-world unlabeled networks in different domains, such as Reddit and Wikipedia. ",
    "url": "https://arxiv.org/abs/2203.16246",
    "authors": [
      "Shay Lapid",
      "Dima Kagan",
      "Michael Fire"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16255",
    "title": "Physics Community Needs, Tools, and Resources for Machine Learning",
    "abstract": "Machine learning (ML) is becoming an increasingly important component of cutting-edge physics research, but its computational requirements present significant challenges. In this white paper, we discuss the needs of the physics community regarding ML across latency and throughput regimes, the tools and resources that offer the possibility of addressing these needs, and how these can be best utilized and accessed in the coming years. ",
    "url": "https://arxiv.org/abs/2203.16255",
    "authors": [
      "Philip Harris",
      "Erik Katsavounidis",
      "William Patrick McCormack",
      "Dylan Rankin",
      "Yongbin Feng",
      "Abhijith Gandrakota",
      "Christian Herwig",
      "Burt Holzman",
      "Kevin Pedro",
      "Nhan Tran",
      "Tingjun Yang",
      "Jennifer Ngadiuba",
      "Michael Coughlin",
      "Scott Hauck",
      "Shih-Chieh Hsu",
      "Elham E Khoda",
      "Deming Chen",
      "Mark Neubauer",
      "Javier Duarte",
      "Georgia Karagiorgi",
      "Mia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2203.16256",
    "title": "Research topic trend prediction of scientific papers based on spatial  enhancement and dynamic graph convolution network",
    "abstract": "In recent years, with the increase of social investment in scientific research, the number of research results in various fields has increased significantly. Accurately and effectively predicting the trends of future research topics can help researchers discover future research hotspots. However, due to the increasingly close correlation between various research themes, there is a certain dependency relationship between a large number of research themes. Viewing a single research theme in isolation and using traditional sequence problem processing methods cannot effectively explore the spatial dependencies between these research themes. To simultaneously capture the spatial dependencies and temporal changes between research topics, we propose a deep neural network-based research topic hotness prediction algorithm, a spatiotemporal convolutional network model. Our model combines a graph convolutional neural network (GCN) and Temporal Convolutional Network (TCN), specifically, GCNs are used to learn the spatial dependencies of research topics a and use space dependence to strengthen spatial characteristics. TCN is used to learn the dynamics of research topics' trends. Optimization is based on the calculation of weighted losses based on time distance. Compared with the current mainstream sequence prediction models and similar spatiotemporal models on the paper datasets, experiments show that, in research topic prediction tasks, our model can effectively capture spatiotemporal relationships and the predictions outperform state-of-art baselines. ",
    "url": "https://arxiv.org/abs/2203.16256",
    "authors": [
      "Changwei Zheng",
      "Zhe Xue",
      "Meiyu Liang",
      "Feifei Kou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.16258",
    "title": "Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data",
    "abstract": "Segmenting or detecting objects in sparse Lidar point clouds are two important tasks in autonomous driving to allow a vehicle to act safely in its 3D environment. The best performing methods in 3D semantic segmentation or object detection rely on a large amount of annotated data. Yet annotating 3D Lidar data for these tasks is tedious and costly. In this context, we propose a self-supervised pre-training method for 3D perception models that is tailored to autonomous driving data. Specifically, we leverage the availability of synchronized and calibrated image and Lidar sensors in autonomous driving setups for distilling self-supervised pre-trained image representations into 3D models. Hence, our method does not require any point cloud nor image annotations. The key ingredient of our method is the use of superpixels which are used to pool 3D point features and 2D pixel features in visually similar regions. We then train a 3D network on the self-supervised task of matching these pooled point features with the corresponding pooled image pixel features. The advantages of contrasting regions obtained by superpixels are that: (1) grouping together pixels and points of visually coherent regions leads to a more meaningful contrastive task that produces features well adapted to 3D semantic segmentation and 3D object detection; (2) all the different regions have the same weight in the contrastive loss regardless of the number of 3D points sampled in these regions; (3) it mitigates the noise produced by incorrect matching of points and pixels due to occlusions between the different sensors. Extensive experiments on autonomous driving datasets demonstrate the ability of our image-to-Lidar distillation strategy to produce 3D representations that transfer well on semantic segmentation and object detection tasks. ",
    "url": "https://arxiv.org/abs/2203.16258",
    "authors": [
      "Corentin Sautier",
      "Gilles Puy",
      "Spyros Gidaris",
      "Alexandre Boulch",
      "Andrei Bursuc",
      "Renaud Marlet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16262",
    "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified  Understanding with Self-supervised Contrastive Learning",
    "abstract": "To avoid collapse in self-supervised learning (SSL), a contrastive loss is widely used but often requires a large number of negative samples. Without negative samples yet achieving competitive performance, a recent work has attracted significant attention for providing a minimalist simple Siamese (SimSiam) method to avoid collapse. However, the reason for how it avoids collapse without negative samples remains not fully clear and our investigation starts by revisiting the explanatory claims in the original SimSiam. After refuting their claims, we introduce vector decomposition for analyzing the collapse based on the gradient analysis of the $l_2$-normalized representation vector. This yields a unified perspective on how negative samples and SimSiam alleviate collapse. Such a unified perspective comes timely for understanding the recent progress in SSL. ",
    "url": "https://arxiv.org/abs/2203.16262",
    "authors": [
      "Chaoning Zhang",
      "Kang Zhang",
      "Chenshuang Zhang",
      "Trung X. Pham",
      "Chang D. Yoo",
      "In So Kweon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16263",
    "title": "Does Audio Deepfake Detection Generalize?",
    "abstract": "Current text-to-speech algorithms produce realistic fakes of human voices, making deepfake detection a much-needed area of research. While researchers have presented various techniques for detecting audio spoofs, it is often unclear exactly why these architectures are successful: Preprocessing steps, hyperparameter settings, and the degree of fine-tuning are not consistent across related work. Which factors contribute to success, and which are accidental? In this work, we address this problem: We systematize audio spoofing detection by re-implementing and uniformly evaluating architectures from related work. We identify overarching features for successful audio deepfake detection, such as using cqtspec or logspec features instead of melspec features, which improves performance by 37% EER on average, all other factors constant. Additionally, we evaluate generalization capabilities: We collect and publish a new dataset consisting of 37.9 hours of found audio recordings of celebrities and politicians, of which 17.2 hours are deepfakes. We find that related work performs poorly on such real-world data (performance degradation of up to one thousand percent). This may suggest that the community has tailored its solutions too closely to the prevailing ASVSpoof benchmark and that deepfakes are much harder to detect outside the lab than previously thought. ",
    "url": "https://arxiv.org/abs/2203.16263",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Pavel Czempin",
      "Franziska Dieckmann",
      "Adam Froghyar",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.16265",
    "title": "SeqTR: A Simple yet Universal Network for Visual Grounding",
    "abstract": "In this paper, we propose a simple yet universal network termed SeqTR for visual grounding tasks, e.g., phrase localization, referring expression comprehension (REC) and segmentation (RES). The canonical paradigms for visual grounding often require substantial expertise in designing network architectures and loss functions, making them hard to generalize across tasks. To simplify and unify the modeling, we cast visual grounding as a point prediction problem conditioned on image and text inputs, where either the bounding box or binary mask is represented as a sequence of discrete coordinate tokens. Under this paradigm, visual grounding tasks are unified in our SeqTR network without task-specific branches or heads, e.g., the convolutional mask decoder for RES, which greatly reduces the complexity of multi-task modeling. In addition, SeqTR also shares the same optimization objective for all tasks with a simple cross-entropy loss, further reducing the complexity of deploying hand-crafted loss functions. Experiments on five benchmark datasets demonstrate that the proposed SeqTR outperforms (or is on par with) the existing state-of-the-arts, proving that a simple yet universal approach for visual grounding is indeed feasible. ",
    "url": "https://arxiv.org/abs/2203.16265",
    "authors": [
      "Chaoyang Zhu",
      "Yiyi Zhou",
      "Yunhang Shen",
      "Gen Luo",
      "Xingjia Pan",
      "Mingbao Lin",
      "Chao Chen",
      "Liujuan Cao",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16279",
    "title": "Neural Pipeline for Zero-Shot Data-to-Text Generation",
    "abstract": "In data-to-text (D2T) generation, training on in-domain data leads to overfitting to the data representation and repeating training data noise. We examine how to avoid finetuning pretrained language models (PLMs) on D2T generation datasets while still taking advantage of surface realization capabilities of PLMs. Inspired by pipeline approaches, we propose to generate text by transforming single-item descriptions with a sequence of modules trained on general-domain text-based operations: ordering, aggregation, and paragraph compression. We train PLMs for performing these operations on a synthetic corpus WikiFluent which we build from English Wikipedia. Our experiments on two major triple-to-text datasets -- WebNLG and E2E -- show that our approach enables D2T generation from RDF triples in zero-shot settings. ",
    "url": "https://arxiv.org/abs/2203.16279",
    "authors": [
      "Zden\u011bk Kasner",
      "Ond\u0159ej Du\u0161ek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16289",
    "title": "One-Step Two-Critic Deep Reinforcement Learning for Inverter-based  Volt-Var Control in Active Distribution Networks",
    "abstract": "A one-step two-critic deep reinforcement learning (OSTC-DRL) approach for inverter-based volt-var control (IB-VVC) in active distribution networks is proposed in this paper. Firstly, considering IB-VVC can be formulated as a single-period optimization problem, we formulate the IB-VVC as a one-step Markov decision process rather than the standard Markov decision process, which simplifies the DRL learning task. Then we design the one-step actor-critic DRL scheme which is a simplified version of recent DRL algorithms, and it avoids the issue of Q value overestimation successfully. Furthermore, considering two objectives of VVC: minimizing power loss and eliminating voltage violation, we utilize two critics to approximate the rewards of two objectives separately. It simplifies the approximation tasks of each critic, and avoids the interaction effect between two objectives in the learning process of critic. The OSTC-DRL approach integrates the one-step actor-critic DRL scheme and the two-critic technology. Based on the OSTC-DRL, we design two centralized DRL algorithms. Further, we extend the OSTC-DRL to multi-agent OSTC-DRL for decentralized IB-VVC and design two multi-agent DRL algorithms. Simulations demonstrate that the proposed OSTC-DRL has a faster convergence rate and a better control performance, and the multi-agent OSTC-DRL works well for decentralized IB-VVC problems. ",
    "url": "https://arxiv.org/abs/2203.16289",
    "authors": [
      "Qiong Liu",
      "Ye Guo",
      "Lirong Deng",
      "Haotian Liu",
      "Dongyu Li",
      "Hongbin Sun",
      "Wenqi Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16290",
    "title": "An Offset-Free Nonlinear MPC scheme for systems learned by Neural NARX  models",
    "abstract": "This paper deals with the design of nonlinear MPC controllers that provide offset-free setpoint tracking for models described by Neural Nonlinear AutoRegressive eXogenous (NNARX) networks. The NNARX model is identified from input-output data collected from the plant, and can be given a state-space representation with known measurable states made by past input and output variables, so that a state observer is not required. In the training phase, the Incremental Input-to-State Stability ({\\delta}ISS) property can be forced when consistent with the behavior of the plant. The {\\delta}ISS property is then leveraged to augment the model with an explicit integral action on the output tracking error, which allows to achieve offset-free tracking capabilities to the designed control scheme. The proposed control architecture is numerically tested on a water heating system and the achieved results are compared to those scored by another popular offset-free MPC method, showing that the proposed scheme attains remarkable performances even in presence of disturbances acting on the plant. ",
    "url": "https://arxiv.org/abs/2203.16290",
    "authors": [
      "Fabio Bonassi",
      "Jing Xie",
      "Marcello Farina",
      "Riccardo Scattolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.16297",
    "title": "Forecasting from LiDAR via Future Object Detection",
    "abstract": "Object detection and forecasting are fundamental components of embodied perception. These two problems, however, are largely studied in isolation by the community. In this paper, we propose an end-to-end approach for detection and motion forecasting based on raw sensor measurement as opposed to ground truth tracks. Instead of predicting the current frame locations and forecasting forward in time, we directly predict future object locations and backcast to determine where each trajectory began. Our approach not only improves overall accuracy compared to other modular or end-to-end baselines, it also prompts us to rethink the role of explicit tracking for embodied perception. Additionally, by linking future and current locations in a many-to-one manner, our approach is able to reason about multiple futures, a capability that was previously considered difficult for end-to-end approaches. We conduct extensive experiments on the popular nuScenes dataset and demonstrate the empirical effectiveness of our approach. In addition, we investigate the appropriateness of reusing standard forecasting metrics for an end-to-end setup, and find a number of limitations which allow us to build simple baselines to game these metrics. We address this issue with a novel set of joint forecasting and detection metrics that extend the commonly used AP metrics from the detection community to measuring forecasting accuracy. Our code is available on \\href{https://github.com/neeharperi/FutureDet}{GitHub}. ",
    "url": "https://arxiv.org/abs/2203.16297",
    "authors": [
      "Neehar Peri",
      "Jonathon Luiten",
      "Mengtian Li",
      "Aljo\u0161a O\u0161ep",
      "Laura Leal-Taix\u00e9",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.16317",
    "title": "PseCo: Pseudo Labeling and Consistency Training for Semi-Supervised  Object Detection",
    "abstract": "In this paper, we delve into two key techniques in Semi-Supervised Object Detection (SSOD), namely pseudo labeling and consistency training. We observe that these two techniques currently neglect some important properties of object detection, hindering efficient learning on unlabeled data. Specifically, for pseudo labeling, existing works only focus on the classification score yet fail to guarantee the localization precision of pseudo boxes; For consistency training, the widely adopted random-resize training only considers the label-level consistency but misses the feature-level one, which also plays an important role in ensuring the scale invariance. To address the problems incurred by noisy pseudo boxes, we design Noisy Pseudo box Learning (NPL) that includes Prediction-guided Label Assignment (PLA) and Positive-proposal Consistency Voting (PCV). PLA relies on model predictions to assign labels and makes it robust to even coarse pseudo boxes; while PCV leverages the regression consistency of positive proposals to reflect the localization quality of pseudo boxes. Furthermore, in consistency training, we propose Multi-view Scale-invariant Learning (MSL) that includes mechanisms of both label- and feature-level consistency, where feature consistency is achieved by aligning shifted feature pyramids between two images with identical content but varied scales. On COCO benchmark, our method, termed PSEudo labeling and COnsistency training (PseCo), outperforms the SOTA (Soft Teacher) by 2.0, 1.8, 2.0 points under 1%, 5%, and 10% labelling ratios, respectively. It also significantly improves the learning efficiency for SSOD, e.g., PseCo halves the training time of the SOTA approach but achieves even better performance. ",
    "url": "https://arxiv.org/abs/2203.16317",
    "authors": [
      "Gang Li",
      "Xiang Li",
      "Yujie Wang",
      "Shanshan Zhang",
      "Yichao Wu",
      "Ding Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.16319",
    "title": "Multi-Robot Active Mapping via Neural Bipartite Graph Matching",
    "abstract": "We study the problem of multi-robot active mapping, which aims for complete scene map construction in minimum time steps. The key to this problem lies in the goal position estimation to enable more efficient robot movements. Previous approaches either choose the frontier as the goal position via a myopic solution that hinders the time efficiency, or maximize the long-term value via reinforcement learning to directly regress the goal position, but does not guarantee the complete map construction. In this paper, we propose a novel algorithm, namely NeuralCoMapping, which takes advantage of both approaches. We reduce the problem to bipartite graph matching, which establishes the node correspondences between two graphs, denoting robots and frontiers. We introduce a multiplex graph neural network (mGNN) that learns the neural distance to fill the affinity matrix for more effective graph matching. We optimize the mGNN with a differentiable linear assignment layer by maximizing the long-term values that favor time efficiency and map completeness via reinforcement learning. We compare our algorithm with several state-of-the-art multi-robot active mapping approaches and adapted reinforcement-learning baselines. Experimental results demonstrate the superior performance and exceptional generalization ability of our algorithm on various indoor scenes and unseen number of robots, when only trained with 9 indoor scenes. ",
    "url": "https://arxiv.org/abs/2203.16319",
    "authors": [
      "Kai Ye",
      "Siyan Dong",
      "Qingnan Fan",
      "He Wang",
      "Li Yi",
      "Fei Xia",
      "Jue Wang",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.16328",
    "title": "Smooth Robust Tensor Completion for Background/Foreground Separation  with Missing Pixels: Novel Algorithm with Convergence Guarantee",
    "abstract": "The objective of this study is to address the problem of background/foreground separation with missing pixels by combining the video acquisition, video recovery, background/foreground separation into a single framework. To achieve this, a smooth robust tensor completion (SRTC) model is proposed to recover the data and decompose it into the static background and smooth foreground, respectively. Specifically, the static background is modeled by the low-rank tucker decomposition and the smooth foreground (moving objects) is modeled by the spatiotemporal continuity, which is enforced by the total variation regularization. An efficient algorithm based on tensor proximal alternating minimization (tenPAM) is implemented to solve the proposed model with global convergence guarantee under very mild conditions. Extensive experiments on real data demonstrate that the proposed method significantly outperforms the state-of-the-art approaches for background/foreground separation with missing pixels. ",
    "url": "https://arxiv.org/abs/2203.16328",
    "authors": [
      "Bo Shen",
      "Weijun Xie",
      "Zhenyu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.16338",
    "title": "Stack operation of tensor networks",
    "abstract": "The tensor network, as a facterization of tensors, aims at performing the operations that are common for normal tensors, such as addition, contraction and stacking. However, due to its non-unique network structure, only the tensor network contraction is so far well defined. In this paper, we propose a mathematically rigorous definition for the tensor network stack approach, that compress a large amount of tensor networks into a single one without changing their structures and configurations. We illustrate the main ideas with the matrix product states based machine learning as an example. Our results are compared with the for loop and the efficient coding method on both CPU and GPU. ",
    "url": "https://arxiv.org/abs/2203.16338",
    "authors": [
      "Tianning Zhang",
      "L. K. Ang",
      "Tianqi Chen",
      "Bo Yang",
      "Erping Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2203.16349",
    "title": "The Block-based Mobile PDE Systems Are Not Secure -- Experimental  Attacks",
    "abstract": "Nowadays, mobile devices have been used broadly to store and process sensitive data. To ensure confidentiality of the sensitive data, Full Disk Encryption (FDE) is often integrated in mainstream mobile operating systems like Android and iOS. FDE however cannot defend against coercive attacks in which the adversary can force the device owner to disclose the decryption key. To combat the coercive attacks, Plausibly Deniable Encryption (PDE) is leveraged to plausibly deny the very existence of sensitive data. However, most of the existing PDE systems for mobile devices are deployed at the block layer and suffer from deniability compromises. Having observed that none of existing works in the literature have experimentally demonstrated the aforementioned compromises, our work bridges this gap by experimentally confirming the deniability compromises of the block-layer mobile PDE systems. We have built a mobile device testbed, which consists of a host computing device and a flash storage device. Additionally, we have deployed both the hidden volume PDE and the steganographic file system at the block layer of the testbed and performed disk forensics to assess potential compromises on the raw NAND flash. Our experimental results confirm it is indeed possible for the adversary to compromise the block-layer PDE systems by accessing the raw NAND flash in practice. We also discuss potential issues when performing such attacks in real world. ",
    "url": "https://arxiv.org/abs/2203.16349",
    "authors": [
      "Niusen Chen",
      "Bo Chen",
      "Weisong Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.16365",
    "title": "IGRF-RFE: A Hybrid Feature Selection Method for MLP-based Network  Intrusion Detection on UNSW-NB15 Dataset",
    "abstract": "The effectiveness of machine learning models is significantly affected by the size of the dataset and the quality of features as redundant and irrelevant features can radically degrade the performance. This paper proposes IGRF-RFE: a hybrid feature selection method tasked for multi-class network anomalies using a Multilayer perceptron (MLP) network. IGRF-RFE can be considered as a feature reduction technique based on both the filter feature selection method and the wrapper feature selection method. In our proposed method, we use the filter feature selection method, which is the combination of Information Gain and Random Forest Importance, to reduce the feature subset search space. Then, we apply recursive feature elimination(RFE) as a wrapper feature selection method to further eliminate redundant features recursively on the reduced feature subsets. Our experimental results obtained based on the UNSW-NB15 dataset confirm that our proposed method can improve the accuracy of anomaly detection while reducing the feature dimension. The results show that the feature dimension is reduced from 42 to 23 while the multi-classification accuracy of MLP is improved from 82.25% to 84.24%. ",
    "url": "https://arxiv.org/abs/2203.16365",
    "authors": [
      "Yuhua Yin",
      "Julian Jang-Jaccard",
      "Wen Xu",
      "Amardeep Singh",
      "Jinting Zhu",
      "Fariza Sabrina",
      "Jin Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.16373",
    "title": "Slow-varying Dynamics Assisted Temporal Capsule Network for Machinery  Remaining Useful Life Estimation",
    "abstract": "Capsule network (CapsNet) acts as a promising alternative to the typical convolutional neural network, which is the dominant network to develop the remaining useful life (RUL) estimation models for mechanical equipment. Although CapsNet comes with an impressive ability to represent the entities' hierarchical relationships through a high-dimensional vector embedding, it fails to capture the long-term temporal correlation of run-to-failure time series measured from degraded mechanical equipment. On the other hand, the slow-varying dynamics, which reveals the low-frequency information hidden in mechanical dynamical behaviour, is overlooked in the existing RUL estimation models, limiting the utmost ability of advanced networks. To address the aforementioned concerns, we propose a Slow-varying Dynamics assisted Temporal CapsNet (SD-TemCapsNet) to simultaneously learn the slow-varying dynamics and temporal dynamics from measurements for accurate RUL estimation. First, in light of the sensitivity of fault evolution, slow-varying features are decomposed from normal raw data to convey the low-frequency components corresponding to the system dynamics. Next, the long short-term memory (LSTM) mechanism is introduced into CapsNet to capture the temporal correlation of time series. To this end, experiments conducted on an aircraft engine and a milling machine verify that the proposed SD-TemCapsNet outperforms the mainstream methods. In comparison with CapsNet, the estimation accuracy of the aircraft engine with four different scenarios has been improved by 10.17%, 24.97%, 3.25%, and 13.03% concerning the index root mean squared error, respectively. Similarly, the estimation accuracy of the milling machine has been improved by 23.57% compared to LSTM and 19.54% compared to CapsNet. ",
    "url": "https://arxiv.org/abs/2203.16373",
    "authors": [
      "Yan Qin",
      "Chau Yuen",
      "Yimin Shao",
      "Bo Qin",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16417",
    "title": "Low-complexity Near-optimum Symbol Detection Based on Neural Enhancement  of Factor Graphs",
    "abstract": "We consider the application of the factor graph framework for symbol detection on linear inter-symbol interference channels. Based on the Ungerboeck observation model, a detection algorithm with appealing complexity properties can be derived. However, since the underlying factor graph contains cycles, the sum-product algorithm (SPA) yields a suboptimal algorithm. In this paper, we develop and evaluate efficient strategies to improve the performance of the factor graph-based symbol detection by means of neural enhancement. In particular, we consider neural belief propagation as an effective way to mitigate the effect of cycles within the factor graph. We also investigate the application of factor node generalizations and pruning techniques. By applying a generic preprocessor to the channel output, we propose a simple technique to vary the underlying factor graph in every SPA iteration. Using this dynamic factor graph transition, we intend to preserve the extrinsic nature of the SPA messages which is otherwise impaired due to cycles. Simulation results show that the proposed methods can massively improve the detection performance, even approaching the maximum a posteriori performance for various transmission scenarios, while preserving a complexity which is linear in both the block length and the channel memory. ",
    "url": "https://arxiv.org/abs/2203.16417",
    "authors": [
      "Luca Schmid",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.16419",
    "title": "Intelligent Blockage Prediction and Proactive Handover for Seamless  Connectivity in Vision-Aided 5G/6G UDNs",
    "abstract": "The upsurge in wireless devices and real-time service demands force the move to a higher frequency spectrum. Millimetre-wave (mmWave) and terahertz (THz) bands combined with the beamforming technology offer significant performance enhancements for ultra-dense networks (UDNs). Unfortunately, shrinking cell coverage and severe penetration loss experienced at higher spectrum render mobility management a critical issue in UDNs, especially optimizing beam blockages and frequent handover (HO). Mobility management challenges have become prevalent in city centres and urban areas. To address this, we propose a novel mechanism driven by exploiting wireless signals and on-road surveillance systems to intelligently predict possible blockages in advance and perform timely HO. This paper employs computer vision (CV) to determine obstacles and users' location and speed. In addition, this study introduces a new HO event, called block event {BLK}, defined by the presence of a blocking object and a user moving towards the blocked area. Moreover, the multivariate regression technique predicts the remaining time until the user reaches the blocked area, hence determining best HO decision. Compared to typical wireless networks without blockage prediction, simulation results show that our BLK detection and PHO algorithm achieves 40\\% improvement in maintaining user connectivity and the required quality of experience (QoE). ",
    "url": "https://arxiv.org/abs/2203.16419",
    "authors": [
      "Mohammad Al-Quraan",
      "Ahsan Khan",
      "Lina Mohjazi",
      "Anthony Centeno",
      "Ahmed Zoha",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.16421",
    "title": "OPD: Single-view 3D Openable Part Detection",
    "abstract": "We address the task of predicting what parts of an object can open and how they move when they do so. The input is a single image of an object, and as output we detect what parts of the object can open, and the motion parameters describing the articulation of each openable part. To tackle this task, we create two datasets of 3D objects: OPDSynth based on existing synthetic objects, and OPDReal based on RGBD reconstructions of real objects. We then design OPDRCNN, a neural architecture that detects openable parts and predicts their motion parameters. Our experiments show that this is a challenging task especially when considering generalization across object categories, and the limited amount of information in a single image. Our architecture outperforms baselines and prior work especially for RGB image inputs. Short video summary at https://www.youtube.com/watch?v=P85iCaD0rfc ",
    "url": "https://arxiv.org/abs/2203.16421",
    "authors": [
      "Hanxiao Jiang",
      "Yongsen Mao",
      "Manolis Savva",
      "Angel X. Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16428",
    "title": "Vulnerability Detection in Open Source Software: An Introduction",
    "abstract": "This paper is an introductory discussion on the cause of open source software vulnerabilities, their importance in the cybersecurity ecosystem, and a selection of detection methods. A recent application security report showed 44% of applications contain critical vulnerabilities in an open source component, a concerning proportion. Most companies do not have a reliable way of being directly and promptly notified when zero-day vulnerabilities are found and then when patches are made available. This means attack vectors in open source exist longer than necessary. Conventional approaches to vulnerability detection are outlined alongside some newer research trends. A conclusion is made that it may not be possible to entirely replace expert human inspection of open source software, although it can be effectively augmented with techniques such as machine learning, IDE plug-ins and repository linking to make implementation and review less time intensive. Underpinning any technological advances should be better knowledge at the human level. Development teams need trained, coached and improved so they can implement open source more securely, know what vulnerabilities to look for and how to handle them. It is the use of this blended approach to detection which is key. ",
    "url": "https://arxiv.org/abs/2203.16428",
    "authors": [
      "Stuart Millar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.16454",
    "title": "A New Diffusive Representation for Fractional Derivatives, Part II:  Convergence Analysis of the Numerical Scheme",
    "abstract": "Recently, we have proposed a new diffusive representation for fractional derivatives and, based on this representation, suggested an algorithm for their numerical computation. From the construction of the algorithm, it is immediately evident that the method is fast and memory efficient. Moreover, the method's design is such that good convergence properties may be expected. This paper here starts a systematic investigation of these convergence properties. ",
    "url": "https://arxiv.org/abs/2203.16454",
    "authors": [
      "Kai Diethelm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.16455",
    "title": "Explicitising The Implicit Intrepretability of Deep Neural Networks Via  Duality",
    "abstract": "Recent work by Lakshminarayanan and Singh [2020] provided a dual view for fully connected deep neural networks (DNNs) with rectified linear units (ReLU). It was shown that (i) the information in the gates is analytically characterised by a kernel called the neural path kernel (NPK) and (ii) most critical information is learnt in the gates, in that, given the learnt gates, the weights can be retrained from scratch without significant loss in performance. Using the dual view, in this paper, we rethink the conventional interpretations of DNNs thereby explicitsing the implicit interpretability of DNNs. Towards this, we first show new theoretical properties namely rotational invariance and ensemble structure of the NPK in the presence of convolutional layers and skip connections respectively. Our theory leads to two surprising empirical results that challenge conventional wisdom: (i) the weights can be trained even with a constant 1 input, (ii) the gating masks can be shuffled, without any significant loss in performance. These results motivate a novel class of networks which we call deep linearly gated networks (DLGNs). DLGNs using the phenomenon of dual lifting pave way to more direct and simpler interpretation of DNNs as opposed to conventional interpretations. We show via extensive experiments on CIFAR-10 and CIFAR-100 that these DLGNs lead to much better interpretability-accuracy tradeoff. ",
    "url": "https://arxiv.org/abs/2203.16455",
    "authors": [
      "Chandrashekar Lakshminarayanan",
      "Amit Vikram Singh",
      "Arun Rajkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16460",
    "title": "Ordered community detection in directed networks",
    "abstract": "We develop a method to infer community structure in directed networks where the groups are ordered in a latent one-dimensional hierarchy that determines the preferred edge direction. Our nonparametric Bayesian approach is based on a modification of the stochastic block model (SBM), which can take advantage of rank alignment and coherence to produce parsimonious descriptions of networks that combine ordered hierarchies with arbitrary mixing patterns between groups. Since our model also includes directed degree correction, we can use it to distinguish non-local hierarchical structure from local in- and out-degree imbalance -- thus removing a source of conflation present in most ranking methods. We also demonstrate how we can reliably compare with the results obtained with the unordered SBM variant to determine whether a hierarchical ordering is statistically warranted in the first place. We illustrate the application of our method on a wide variety of empirical networks across several domains. ",
    "url": "https://arxiv.org/abs/2203.16460",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.16462",
    "title": "Convergence of gradient descent for deep neural networks",
    "abstract": "Optimization by gradient descent has been one of main drivers of the \"deep learning revolution\". Yet, despite some recent progress for extremely wide networks, it remains an open problem to understand why gradient descent often converges to global minima when training deep neural networks. This article presents a new criterion for convergence of gradient descent to a global minimum, which is provably more powerful than the best available criteria from the literature, namely, the Lojasiewicz inequality and its generalizations. This criterion is used to show that gradient descent with proper initialization converges to a global minimum when training any feedforward neural network with smooth and strictly increasing activation functions, provided that the input dimension is greater than or equal to the number of data points. ",
    "url": "https://arxiv.org/abs/2203.16462",
    "authors": [
      "Sourav Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.16474",
    "title": "Zero Shot Crosslingual Eye-Tracking Data Prediction using Multilingual  Transformer Models",
    "abstract": "Eye tracking data during reading is a useful source of information to understand the cognitive processes that take place during language comprehension processes. Different languages account for different brain triggers , however there seems to be some uniform indicators. In this paper, we describe our submission to the CMCL 2022 shared task on predicting human reading patterns for multi-lingual dataset. Our model uses text representations from transformers and some hand engineered features with a regression layer on top to predict statistical measures of mean and standard deviation for 2 main eye-tracking features. We train an end to end model to extract meaningful information from different languages and test our model on two seperate datasets. We compare different transformer models and show ablation studies affecting model performance. Our final submission ranked 4th place for SubTask-1 and 1st place for SubTask-2 for the shared task. ",
    "url": "https://arxiv.org/abs/2203.16474",
    "authors": [
      "Harshvardhan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16481",
    "title": "On Uncertainty, Tempering, and Data Augmentation in Bayesian  Classification",
    "abstract": "Aleatoric uncertainty captures the inherent randomness of the data, such as measurement noise. In Bayesian regression, we often use a Gaussian observation model, where we control the level of aleatoric uncertainty with a noise variance parameter. By contrast, for Bayesian classification we use a categorical distribution with no mechanism to represent our beliefs about aleatoric uncertainty. Our work shows that explicitly accounting for aleatoric uncertainty significantly improves the performance of Bayesian neural networks. We note that many standard benchmarks, such as CIFAR, have essentially no aleatoric uncertainty. Moreover, we show data augmentation in approximate inference has the effect of softening the likelihood, leading to underconfidence and profoundly misrepresenting our honest beliefs about aleatoric uncertainty. Accordingly, we find that a cold posterior, tempered by a power greater than one, often more honestly reflects our beliefs about aleatoric uncertainty than no tempering -- providing an explicit link between data augmentation and cold posteriors. We show that we can match or exceed the performance of posterior tempering by using a Dirichlet observation model, where we explicitly control the level of aleatoric uncertainty, without any need for tempering. ",
    "url": "https://arxiv.org/abs/2203.16481",
    "authors": [
      "Sanyam Kapoor",
      "Wesley J. Maddox",
      "Pavel Izmailov",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.16506",
    "title": "An Improved Lightweight YOLOv5 Model Based on Attention Mechanism for  Face Mask Detection",
    "abstract": "Coronavirus 2019 has brought severe challenges to social stability and public health worldwide. One effective way of curbing the epidemic is to require people to wear masks in public places and monitor mask-wearing states by utilizing suitable automatic detectors. However, existing deep learning based models struggle to simultaneously achieve the requirements of both high precision and real-time performance. To solve this problem, we propose an improved lightweight face mask detector based on YOLOv5, which can achieve an excellent balance of precision and speed. Firstly, a novel backbone ShuffleCANet that combines ShuffleNetV2 network with Coordinate Attention mechanism is proposed as the backbone. Then we use BiFPN as the feature fusion neck. Furthermore, we replace the loss function of localization with -CIoU to obtain higher-quality anchors. Some valuable strategies such as data augmentation, adaptive image scaling, and anchor cluster operation are also utilized. Experimental results show the performance and effectiveness of the proposed model. On the basis of the original YOLOv5 model, our work increases the inference speed by 28.3% while still improving the precision by 0.58% on the AIZOO face mask dataset. It achieves a mean average precision of 95.2%, which is 4.4% higher than the baseline and is also more accurate compared with other existing models. ",
    "url": "https://arxiv.org/abs/2203.16506",
    "authors": [
      "Sheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16521",
    "title": "CoordGAN: Self-Supervised Dense Correspondences Emerge from GANs",
    "abstract": "Recent advances show that Generative Adversarial Networks (GANs) can synthesize images with smooth variations along semantically meaningful latent directions, such as pose, expression, layout, etc. While this indicates that GANs implicitly learn pixel-level correspondences across images, few studies explored how to extract them explicitly. In this work, we introduce Coordinate GAN (CoordGAN), a structure-texture disentangled GAN that learns a dense correspondence map for each generated image. We represent the correspondence maps of different images as warped coordinate frames transformed from a canonical coordinate frame, i.e., the correspondence map, which describes the structure (e.g., the shape of a face), is controlled via a transformation. Hence, finding correspondences boils down to locating the same coordinate in different correspondence maps. In CoordGAN, we sample a transformation to represent the structure of a synthesized instance, while an independent texture branch is responsible for rendering appearance details orthogonal to the structure. Our approach can also extract dense correspondence maps for real images by adding an encoder on top of the generator. We quantitatively demonstrate the quality of the learned dense correspondences through segmentation mask transfer on multiple datasets. We also show that the proposed generator achieves better structure and texture disentanglement compared to existing approaches. Project page: https://jitengmu.github.io/CoordGAN/ ",
    "url": "https://arxiv.org/abs/2203.16521",
    "authors": [
      "Jiteng Mu",
      "Shalini De Mello",
      "Zhiding Yu",
      "Nuno Vasconcelos",
      "Xiaolong Wang",
      "Jan Kautz",
      "Sifei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16527",
    "title": "Exploring Plain Vision Transformer Backbones for Object Detection",
    "abstract": "We explore the plain, non-hierarchical Vision Transformer (ViT) as a backbone network for object detection. This design enables the original ViT architecture to be fine-tuned for object detection without needing to redesign a hierarchical backbone for pre-training. With minimal adaptations for fine-tuning, our plain-backbone detector can achieve competitive results. Surprisingly, we observe: (i) it is sufficient to build a simple feature pyramid from a single-scale feature map (without the common FPN design) and (ii) it is sufficient to use window attention (without shifting) aided with very few cross-window propagation blocks. With plain ViT backbones pre-trained as Masked Autoencoders (MAE), our detector, named ViTDet, can compete with the previous leading methods that were all based on hierarchical backbones, reaching up to 61.3 box AP on the COCO dataset using only ImageNet-1K pre-training. We hope our study will draw attention to research on plain-backbone detectors. Code will be made available. ",
    "url": "https://arxiv.org/abs/2203.16527",
    "authors": [
      "Yanghao Li",
      "Hanzi Mao",
      "Ross Girshick",
      "Kaiming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16529",
    "title": "CaDeX: Learning Canonical Deformation Coordinate Space for Dynamic  Surface Representation via Neural Homeomorphism",
    "abstract": "While neural representations for static 3D shapes are widely studied, representations for deformable surfaces are limited to be template-dependent or lack efficiency. We introduce Canonical Deformation Coordinate Space (CaDeX), a unified representation of both shape and nonrigid motion. Our key insight is the factorization of the deformation between frames by continuous bijective canonical maps (homeomorphisms) and their inverses that go through a learned canonical shape. Our novel deformation representation and its implementation are simple, efficient, and guarantee cycle consistency, topology preservation, and, if needed, volume conservation. Our modelling of the learned canonical shapes provides a flexible and stable space for shape prior learning. We demonstrate state-of-the-art performance in modelling a wide range of deformable geometries: human bodies, animal bodies, and articulated objects. ",
    "url": "https://arxiv.org/abs/2203.16529",
    "authors": [
      "Jiahui Lei",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12277",
    "title": "On-Demand AoI Minimization in Resource-Constrained Cache-Enabled IoT  Networks with Energy Harvesting Sensors",
    "abstract": "We consider a resource-constrained IoT network, where multiple users make on-demand requests to a cache-enabled edge node to send status updates about various random processes, each monitored by an energy harvesting sensor. The edge node serves users' requests by deciding whether to command the corresponding sensor to send a fresh status update or retrieve the most recently received measurement from the cache. Our objective is to find the best actions of the edge node to minimize the average age of information (AoI) of the received measurements upon request, i.e., average on-demand AoI, subject to per-slot transmission and energy constraints. First, we derive a Markov decision process model and propose an iterative algorithm that obtains an optimal policy. Then, we develop an asymptotically optimal low-complexity algorithm -- termed relax-then-truncate -- and prove that it is optimal as the number of sensors goes to infinity. Simulation results illustrate that the proposed relax-then-truncate approach significantly reduces the average on-demand AoI compared to a request-aware greedy (myopic) policy and also depict that it performs close to the optimal solution even for moderate numbers of sensors. ",
    "url": "https://arxiv.org/abs/2201.12277",
    "authors": [
      "Mohammad Hatami",
      "Markus Leinonen",
      "Zheng Chen",
      "Nikolaos Pappas",
      "Marian Codreanu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15927",
    "title": "The DESC Stellarator Code Suite Part II: Perturbation and continuation  methods",
    "abstract": "A new perturbation and continuation method is presented for computing and analyzing stellarator equilibria. The method is formally derived from a series expansion about the equilibrium condition $F \\equiv J \\times B - \\nabla p = 0$, and an efficient algorithm for computing solutions to 2nd and 3rd order perturbations is developed. The method has been implemented in the DESC stellarator equilibrium code, using automatic differentiation to compute the required derivatives. Examples are shown demonstrating its use for computing complicated equilibria, perturbing a tokamak into a stellarator, and performing parameter scans in pressure, rotational transform and boundary shape in a fraction of the time required for a full solution. ",
    "url": "https://arxiv.org/abs/2203.15927",
    "authors": [
      "Rory Conlin",
      "Daniel W. Dudt",
      "Dario Panici",
      "Egemen Kolemen"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.15937",
    "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum  Pseudo-Labeling for Accentedness and Intelligibility Assessment",
    "abstract": "Current leading mispronunciation detection and diagnosis (MDD) systems achieve promising performance via end-to-end phoneme recognition. One challenge of such end-to-end solutions is the scarcity of human-annotated phonemes on natural L2 speech. In this work, we leverage unlabeled L2 speech via a pseudo-labeling (PL) procedure and extend the fine-tuning approach based on pre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec 2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples plus the created pseudo-labeled L2 speech samples. Our pseudo labels are dynamic and are produced by an ensemble of the online model on-the-fly, which ensures that our model is robust to pseudo label noise. We show that fine-tuning with pseudo labels gains a 5.35% phoneme error rate reduction and 2.48% MDD F1 score improvement over a labeled-samples-only fine-tuning baseline. The proposed PL method is also shown to outperform conventional offline PL methods. Compared to the state-of-the-art MDD systems, our MDD solution achieves a more accurate and consistent phonetic error diagnosis. In addition, we conduct an open test on a separate UTD-4Accents dataset, where our system recognition outputs show a strong correlation with human perception, based on accentedness and intelligibility. ",
    "url": "https://arxiv.org/abs/2203.15937",
    "authors": [
      "Mu Yang",
      "Kevin Hirschi",
      "Stephen D. Looney",
      "Okim Kang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16087",
    "title": "Polarized deep diffractive neural network for classification,  generation, multiplexing and de-multiplexing of orbital angular momentum  modes",
    "abstract": "The multiplexing and de-multiplexing of orbital angular momentum (OAM) beams are critical issues in optical communication. Optical diffractive neural networks have been introduced to perform classification, generation, multiplexing and de-multiplexing of OAM beams. However, conventional diffractive neural networks cannot handle OAM modes with a varying spatial distribution of polarization directions. Herein, we propose a polarized optical deep diffractive neural network that is designed based on the concept of rectangular micro-structure meta-material. Our proposed polarized optical diffractive neural network is trained to classify, generate, multiplex and de-multiplex polarized OAM beams.The simulation results show that our network framework can successfully classify 14 kinds of orthogonally polarized vortex beams and de-multiplex the hybrid OAM beams into Gauss beams at two, three and four spatial positions respectively. 6 polarized OAM beams with identical total intensity and 8 cylinder vector beams with different topology charges also have been classified effectively. Additionally, results reveal that the network can generate hybrid OAM beams with high quality and multiplex two polarized linear beams into 8 kinds of cylinder vector beams. ",
    "url": "https://arxiv.org/abs/2203.16087",
    "authors": [
      "Jiaqi Zhang",
      "Zhiyuan Ye",
      "Jianhua Yin",
      "Liying Lang",
      "Shuming Jiao"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16157",
    "title": "Centralised multi link measurement compression with side information",
    "abstract": "We prove new one shot achievability results for measurement compression of quantum instruments with side information at the receiver. Unlike previous one shot results for this problem, our one shot bounds are nearly optimal and do not need catalytic randomness. In fact, we state a more general problem called centralised multi link measurement compression with quantum side information and provide one shot achievability results for it. As a simple corollary, we obtain one shot measurement compression results for quantum instruments with side information that we mentioned earlier. All our one shot results lead to the standard results for this problem in the asymptotic iid setting. We prove our achievability bounds by first proving a novel sequential classical quantum multipartite covering lemma, which should be of independent interest. ",
    "url": "https://arxiv.org/abs/2203.16157",
    "authors": [
      "Sayantan Chakraborty",
      "Arun Padakandla",
      "Pranab Sen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.16251",
    "title": "Robust Generation Dispatch with Strategic Renewable Power Curtailment  and Decision-Dependent Uncertainty",
    "abstract": "As renewable energy sources replace traditional power sources (such as thermal generators), uncertainty grows while there are fewer controllable units. To reduce operational risks and avoid frequent real-time emergency controls, a preparatory schedule of renewable generation curtailment is required. This paper proposes a novel two-stage robust generation dispatch (RGD) model, where the curtailment strategy is optimized in the pre-dispatch stage. The curtailment strategy will then influence the real-time renewable power output, resulting in a decision-dependent uncertainty (DDU) set. In the re-dispatch stage, the controllable units adjust their outputs within the reserve capacities to maintain power balancing. To overcome the difficulty in solving the RGD with DDU, an adaptive column-and-constraint generation (AC&CG) algorithm is developed. We prove that the proposed algorithm can generate the optimal strategy in finite iterations. Numerical examples validate the practicability and scalability of the proposed model and algorithm. ",
    "url": "https://arxiv.org/abs/2203.16251",
    "authors": [
      "Yue Chen",
      "Wei Wei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.16288",
    "title": "Region of Interest focused MRI to Synthetic CT Translation using  Regression and Classification Multi-task Network",
    "abstract": "In this work, we present a method for synthetic CT (sCT) generation from zero-echo-time (ZTE) MRI aimed at structural and quantitative accuracies of the image, with a particular focus on the accurate bone density value prediction. We propose a loss function that favors a spatially sparse region in the image. We harness the ability of a multi-task network to produce correlated outputs as a framework to enable localisation of region of interest (RoI) via classification, emphasize regression of values within RoI and still retain the overall accuracy via global regression. The network is optimized by a composite loss function that combines a dedicated loss from each task. We demonstrate how the multi-task network with RoI focused loss offers an advantage over other configurations of the network to achieve higher accuracy of performance. This is relevant to sCT where failure to accurately estimate high Hounsfield Unit values of bone could lead to impaired accuracy in clinical applications. We compare the dose calculation maps from the proposed sCT and the real CT in a radiation therapy treatment planning setup. ",
    "url": "https://arxiv.org/abs/2203.16288",
    "authors": [
      "Sandeep Kaushik",
      "Mikael Bylund",
      "Cristina Cozzini",
      "Dattesh Shanbhag",
      "Steven F Petit",
      "Jonathan J Wyatt",
      "Marion I Menzel",
      "Carolin Pirkl",
      "Bhairav Mehta",
      "Vikas Chauhan",
      "Kesavadas Chandrasekharan",
      "Joakim Jonsson",
      "Tufve Nyholm",
      "Florian Wiesinger",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2203.16339",
    "title": "Robust and Energy-efficient PPG-based Heart-Rate Monitoring",
    "abstract": "A wrist-worn PPG sensor coupled with a lightweight algorithm can run on a MCU to enable non-invasive and comfortable monitoring, but ensuring robust PPG-based heart-rate monitoring in the presence of motion artifacts is still an open challenge. Recent state-of-the-art algorithms combine PPG and inertial signals to mitigate the effect of motion artifacts. However, these approaches suffer from limited generality. Moreover, their deployment on MCU-based edge nodes has not been investigated. In this work, we tackle both the aforementioned problems by proposing the use of hardware-friendly Temporal Convolutional Networks (TCN) for PPG-based heart estimation. Starting from a single \"seed\" TCN, we leverage an automatic Neural Architecture Search (NAS) approach to derive a rich family of models. Among them, we obtain a TCN that outperforms the previous state-of-the-art on the largest PPG dataset available (PPGDalia), achieving a Mean Absolute Error (MAE) of just 3.84 Beats Per Minute (BPM). Furthermore, we tested also a set of smaller yet still accurate (MAE of 5.64 - 6.29 BPM) networks that can be deployed on a commercial MCU (STM32L4) which require as few as 5k parameters and reach a latency of 17.1 ms consuming just 0.21 mJ per inference. ",
    "url": "https://arxiv.org/abs/2203.16339",
    "authors": [
      "Matteo Risso",
      "Alessio Burrello",
      "Daniele Jahier Pagliari",
      "Simone Benatti",
      "Enrico Macii",
      "Luca Benini",
      "Massimo Poncino"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16355",
    "title": "Generative Adversarial Networks for the fast simulation of the Time  Projection Chamber responses at the MPD detector",
    "abstract": "The detailed detector simulation models are vital for the successful operation of modern high-energy physics experiments. In most cases, such detailed models require a significant amount of computing resources to run. Often this may not be afforded and less resource-intensive approaches are desired. In this work, we demonstrate the applicability of Generative Adversarial Networks (GAN) as the basis for such fast-simulation models for the case of the Time Projection Chamber (TPC) at the MPD detector at the NICA accelerator complex. Our prototype GAN-based model of TPC works more than an order of magnitude faster compared to the detailed simulation without any noticeable drop in the quality of the high-level reconstruction characteristics for the generated data. Approaches with direct and indirect quality metrics optimization are compared. ",
    "url": "https://arxiv.org/abs/2203.16355",
    "authors": [
      "A. Maevskiy",
      "F. Ratnikov",
      "A. Zinchenko",
      "V. Riabov",
      "A. Sukhorosov",
      "D. Evdokimov"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.16437",
    "title": "Weakly supervised causal representation learning",
    "abstract": "Learning high-level causal representations together with a causal model from unstructured low-level data such as pixels is impossible from observational data alone. We prove under mild assumptions that this representation is identifiable in a weakly supervised setting. This requires a dataset with paired samples before and after random, unknown interventions, but no further labels. Finally, we show that we can infer the representation and causal graph reliably in a simple synthetic domain using a variational autoencoder with a structural causal model as prior. ",
    "url": "https://arxiv.org/abs/2203.16437",
    "authors": [
      "Johann Brehmer",
      "Pim de Haan",
      "Phillip Lippe",
      "Taco Cohen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1511.06987",
    "title": "Evolutionary algorithms",
    "abstract": " Comments: Outline of lectures course \"Evolutionary Algorithms\" (in Russian) ",
    "url": "https://arxiv.org/abs/1511.06987",
    "authors": [
      "Anton V. Eremeev"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2002.00840",
    "title": "When Less Is More: Systematic Analysis of Cascade-Based Community  Detection",
    "abstract": " Title: When Less Is More: Systematic Analysis of Cascade-Based Community  Detection ",
    "url": "https://arxiv.org/abs/2002.00840",
    "authors": [
      "Liudmila Prokhorenkova",
      "Alexey Tikhonov",
      "Nelly Litvak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2003.10774",
    "title": "Notes on Equitable Partitions into Matching Forests in Mixed Graphs and  into $b$-branchings in Digraphs",
    "abstract": " Title: Notes on Equitable Partitions into Matching Forests in Mixed Graphs and  into $b$-branchings in Digraphs ",
    "url": "https://arxiv.org/abs/2003.10774",
    "authors": [
      "Kenjiro Takazawa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2012.04882",
    "title": "Emotional Conversation Generation with Heterogeneous Graph Neural  Network",
    "abstract": " Comments: Accepted at Artificial Intelligence as an extension of the AAAI conference version ",
    "url": "https://arxiv.org/abs/2012.04882",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Ying Zhang",
      "Jinan Xu",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2012.07751",
    "title": "Near Real-Time Social Distance Estimation in London",
    "abstract": " Comments: Incorporating work and results from the last year ",
    "url": "https://arxiv.org/abs/2012.07751",
    "authors": [
      "James Walsh",
      "Oluwafunmilola Kesa",
      "Andrew Wang",
      "Mihai Ilas",
      "Patrick O'Hara",
      "Oscar Giles",
      "Neil Dhir",
      "Theodoros Damoulas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.07974",
    "title": "TCLR: Temporal Contrastive Learning for Video Representation",
    "abstract": " Comments: Accepted to Computer Vision and Image Understanding (CVIU) Journal ",
    "url": "https://arxiv.org/abs/2101.07974",
    "authors": [
      "Ishan Dave",
      "Rohit Gupta",
      "Mamshad Nayeem Rizve",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.09486",
    "title": "Convolutional codes over finite chain rings, MDP codes and their  characterization",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2104.09486",
    "authors": [
      "Gianira N. Alfarano",
      "Anina Gruica",
      "Julia Lieb",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2105.00419",
    "title": "Graph Vulnerability and Robustness: A Survey",
    "abstract": " Comments: Accepted into Transactions on Knowledge and Data Engineering (TKDE) 2022 ",
    "url": "https://arxiv.org/abs/2105.00419",
    "authors": [
      "Scott Freitas",
      "Diyi Yang",
      "Srijan Kumar",
      "Hanghang Tong",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2105.06561",
    "title": "Equilibria in Schelling Games: Computational Hardness and Robustness",
    "abstract": " Comments: Accepted to AAMAS'22 ",
    "url": "https://arxiv.org/abs/2105.06561",
    "authors": [
      "Luca Kreisel",
      "Niclas Boehmer",
      "Vincent Froese",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2105.08825",
    "title": "Multi-Person Extreme Motion Prediction",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2105.08825",
    "authors": [
      "Wen Guo",
      "Xiaoyu Bie",
      "Xavier Alameda-Pineda",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.01917",
    "title": "SpecRepair: Counter-Example Guided Safety Repair of Deep Neural Networks",
    "abstract": " Title: SpecRepair: Counter-Example Guided Safety Repair of Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2106.01917",
    "authors": [
      "Fabian Bauer-Marquart",
      "David Boetius",
      "Stefan Leue",
      "Christian Schilling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2107.09639",
    "title": "Toward Structural Controllability and Predictability in Directed  Networks",
    "abstract": " Comments: some co-author perfers not to publish online before formal publication ",
    "url": "https://arxiv.org/abs/2107.09639",
    "authors": [
      "Fei Jing",
      "Chuang Liu",
      "Jian-Liang Wu",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2107.11868",
    "title": "In Defense of Liquid Democracy",
    "abstract": " Title: In Defense of Liquid Democracy ",
    "url": "https://arxiv.org/abs/2107.11868",
    "authors": [
      "Daniel Halpern",
      "Joseph Y. Halpern",
      "Ali Jadbabaie",
      "Elchanan Mossel",
      "Ariel D. Procaccia",
      "Manon Revel"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2108.01036",
    "title": "Optimal Solving of Constrained Path-Planning Problems with Graph  Convolutional Networks and Optimized Tree Search",
    "abstract": " Comments: Complete version with full references ",
    "url": "https://arxiv.org/abs/2108.01036",
    "authors": [
      "Kevin Osanlou",
      "Andrei Bursuc",
      "Christophe Guettier",
      "Tristan Cazenave",
      "Eric Jacopin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.08760",
    "title": "Robust outlier detection by de-biasing VAE likelihoods",
    "abstract": " Comments: To appear at CVPR 2022. 20 pages and 19 figures ",
    "url": "https://arxiv.org/abs/2108.08760",
    "authors": [
      "Kushal Chauhan",
      "Barath Mohan U",
      "Pradeep Shenoy",
      "Manish Gupta",
      "Devarajan Sridharan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.07217",
    "title": "Progressive Hard-case Mining across Pyramid Levels for Object Detection",
    "abstract": " Title: Progressive Hard-case Mining across Pyramid Levels for Object Detection ",
    "url": "https://arxiv.org/abs/2109.07217",
    "authors": [
      "Binghong Wu",
      "Yehui Yang",
      "Dalu Yang",
      "Junde Wu",
      "Xiaorong Wang",
      "Haifeng Huang",
      "Lei Wang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.11438",
    "title": "A special case of Vu's conjecture: Coloring nearly disjoint graphs of  bounded maximum degree",
    "abstract": " Comments: 14 pages with one-page appendix; this version adds Theorem 1.5 due to L. Postle ",
    "url": "https://arxiv.org/abs/2109.11438",
    "authors": [
      "Tom Kelly",
      "Daniela K\u00fchn",
      "Deryk Osthus"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2110.04667",
    "title": "Competitive Perimeter Defense of Conical Environments",
    "abstract": " Comments: Version 2 has additional images ",
    "url": "https://arxiv.org/abs/2110.04667",
    "authors": [
      "Shivam Bajaj",
      "Eric Torng",
      "Shaunak D. Bopardikar",
      "Alexander Von Moll",
      "Isaac Weintraub",
      "Eloy Garcia",
      "David W. Casbeer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2110.06537",
    "title": "Well-classified Examples are Underestimated in Classification with Deep  Neural Networks",
    "abstract": " Comments: Accepted by AAAI 2022; 17 pages, 11 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2110.06537",
    "authors": [
      "Guangxiang Zhao",
      "Wenkai Yang",
      "Xuancheng Ren",
      "Lei Li",
      "Yunfang Wu",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.10323",
    "title": "Computational Graph Completion",
    "abstract": " Comments: 34 pages. To appear in Research in the Mathematical Sciences ",
    "url": "https://arxiv.org/abs/2110.10323",
    "authors": [
      "Houman Owhadi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.00195",
    "title": "Learning Continuous Representation of Audio for Arbitrary Scale Super  Resolution",
    "abstract": " Comments: Accepted by ICASSP 2022. The source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2111.00195",
    "authors": [
      "Jaechang Kim",
      "Yunjoo Lee",
      "Seunghoon Hong",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.00600",
    "title": "Minimum Description Length Recurrent Neural Networks",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2111.00600",
    "authors": [
      "Nur Lan",
      "Michal Geyer",
      "Emmanuel Chemla",
      "Roni Katzir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2111.05849",
    "title": "Advances in Neural Rendering",
    "abstract": " Comments: 33 pages, 14 figures, 5 tables; State of the Art Report at EUROGRAPHICS 2022 ",
    "url": "https://arxiv.org/abs/2111.05849",
    "authors": [
      "Ayush Tewari",
      "Justus Thies",
      "Ben Mildenhall",
      "Pratul Srinivasan",
      "Edgar Tretschk",
      "Yifan Wang",
      "Christoph Lassner",
      "Vincent Sitzmann",
      "Ricardo Martin-Brualla",
      "Stephen Lombardi",
      "Tomas Simon",
      "Christian Theobalt",
      "Matthias Niessner",
      "Jonathan T. Barron",
      "Gordon Wetzstein",
      "Michael Zollhoefer",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.05947",
    "title": "Privacy signaling games with binary alphabets",
    "abstract": " Comments: 11 pages, 9 figures, European Control Conference 2022 (accepted) ",
    "url": "https://arxiv.org/abs/2111.05947",
    "authors": [
      "Photios A. Stavrou",
      "Serkan Sar\u0131ta\u015f",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2111.08831",
    "title": "HARA: A Hierarchical Approach for Robust Rotation Averaging",
    "abstract": " Comments: Accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2111.08831",
    "authors": [
      "Seong Hun Lee",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14712",
    "title": "Prediction of Large Magnetic Moment Materials With Graph Neural Networks  and Random Forests",
    "abstract": " Comments: This paper is withdrawn because a bug was found in the code. Updated results and conclusions will be posted in a new version at a later date ",
    "url": "https://arxiv.org/abs/2111.14712",
    "authors": [
      "S\u00e9kou-Oumar Kaba",
      "Benjamin Groleau-Par\u00e9",
      "Marc-Antoine Gauthier",
      "Andr\u00e9-Marie Tremblay",
      "Simon Verret",
      "Chlo\u00e9 Gauvin-Ndiaye"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.14893",
    "title": "Learning Multiple Dense Prediction Tasks from Partially Annotated Data",
    "abstract": " Comments: Multi-task Partially-supervised Learning, Code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2111.14893",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.15362",
    "title": "ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image  Prior",
    "abstract": " Title: ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image  Prior ",
    "url": "https://arxiv.org/abs/2111.15362",
    "authors": [
      "Metin Ersin Arican",
      "Ozgur Kara",
      "Gustav Bredell",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.15430",
    "title": "The Devil is in the Margin: Margin-based Label Smoothing for Network  Calibration",
    "abstract": " Comments: To Appear at CVPR 2022. Code: this https URL ",
    "url": "https://arxiv.org/abs/2111.15430",
    "authors": [
      "Bingyuan Liu",
      "Ismail Ben Ayed",
      "Adrian Galdran",
      "Jose Dolz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.15483",
    "title": "ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation",
    "abstract": " Comments: Accepted in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2111.15483",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.00585",
    "title": "Neural Emotion Director: Speech-preserving semantic control of facial  expressions in \"in-the-wild\" videos",
    "abstract": " Comments: CVPR 2022 (oral). Project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.00585",
    "authors": [
      "Foivos Paraperas Papantoniou",
      "Panagiotis P. Filntisis",
      "Petros Maragos",
      "Anastasios Roussos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01526",
    "title": "MViTv2: Improved Multiscale Vision Transformers for Classification and  Detection",
    "abstract": " Comments: CVPR 2022 Camera Ready ",
    "url": "https://arxiv.org/abs/2112.01526",
    "authors": [
      "Yanghao Li",
      "Chao-Yuan Wu",
      "Haoqi Fan",
      "Karttikeya Mangalam",
      "Bo Xiong",
      "Jitendra Malik",
      "Christoph Feichtenhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01635",
    "title": "A Grounded Theory Based Approach to Characterize Software Attack  Surfaces",
    "abstract": " Comments: This paper has been accepted in the IEEE/ACM International Conference on Software Engineering (ICSE 2022) and is going to be published. Please feel free to cite it ",
    "url": "https://arxiv.org/abs/2112.01635",
    "authors": [
      "Sara Moshtari",
      "Ahmet Okutan",
      "Mehdi Mirakhorli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.02805",
    "title": "Forward Compatible Training for Large-Scale Embedding Retrieval Systems",
    "abstract": " Comments: 14 pages with appendix. In proceedings at the conference on Computer Vision and Pattern Recognition 2022 ",
    "url": "https://arxiv.org/abs/2112.02805",
    "authors": [
      "Vivek Ramanujan",
      "Pavan Kumar Anasosalu Vasu",
      "Ali Farhadi",
      "Oncel Tuzel",
      "Hadi Pouransari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04312",
    "title": "Geometry-Guided Progressive NeRF for Generalizable and Efficient Neural  Human Rendering",
    "abstract": " Title: Geometry-Guided Progressive NeRF for Generalizable and Efficient Neural  Human Rendering ",
    "url": "https://arxiv.org/abs/2112.04312",
    "authors": [
      "Mingfei Chen",
      "Jianfeng Zhang",
      "Xiangyu Xu",
      "Lijuan Liu",
      "Yujun Cai",
      "Jiashi Feng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2112.04605",
    "title": "Prediction of Adverse Biological Effects of Chemicals Using Knowledge  Graph Embeddings",
    "abstract": " Comments: Semantic Web, vol. Pre-press, no. Pre-press, pp. 1-40, 2022 ",
    "url": "https://arxiv.org/abs/2112.04605",
    "authors": [
      "Erik B. Myklebust",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Jiaoyan Chen",
      "Raoul Wolf",
      "Knut Erik Tollefsen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04905",
    "title": "i-SpaSP: Structured Neural Pruning via Sparse Signal Recovery",
    "abstract": " Comments: 29 pages, 4 figures, 4th Annual Conference on Learning for Dynamics and Control ",
    "url": "https://arxiv.org/abs/2112.04905",
    "authors": [
      "Cameron R. Wolfe",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.05381",
    "title": "UNIST: Unpaired Neural Implicit Shape Translation Network",
    "abstract": " Comments: CVPR 2022. project page: this https URL ",
    "url": "https://arxiv.org/abs/2112.05381",
    "authors": [
      "Qimin Chen",
      "Johannes Merz",
      "Aditya Sanghi",
      "Hooman Shayani",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2112.06887",
    "title": "Nonideality-Aware Training for Accurate and Robust Low-Power Memristive  Neural Networks",
    "abstract": " Comments: 29 pages, 20 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2112.06887",
    "authors": [
      "Dovydas Joksas",
      "Erwei Wang",
      "Nikolaos Barmpatsalos",
      "Wing H. Ng",
      "Anthony J. Kenyon",
      "George A. Constantinides",
      "Adnan Mehonic"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2112.07158",
    "title": "Hop-Spanners for Geometric Intersection Graphs",
    "abstract": " Comments: 32 pages, 18 figures, full version of an extended abstract in the Proceedings of SoCG 2022 ",
    "url": "https://arxiv.org/abs/2112.07158",
    "authors": [
      "Jonathan B. Conroy",
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2112.10155",
    "title": "Topology Preserving Local Road Network Estimation from Single Onboard  Camera Image",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2112.10155",
    "authors": [
      "Yigit Baran Can",
      "Alexander Liniger",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01647",
    "title": "Relationship extraction for knowledge graph creation from biomedical  literature",
    "abstract": " Comments: Paper submitted to Journal of Semantic Web ",
    "url": "https://arxiv.org/abs/2201.01647",
    "authors": [
      "Nikola Milosevic",
      "Wolfgang Thielemann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.01804",
    "title": "Fast and accurate numerical simulations for the study of coronary artery  bypass grafts by artificial neural network",
    "abstract": " Title: Fast and accurate numerical simulations for the study of coronary artery  bypass grafts by artificial neural network ",
    "url": "https://arxiv.org/abs/2201.01804",
    "authors": [
      "Pierfrancesco Siena",
      "Michele Girfoglio",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2201.02863",
    "title": "PocketNN: Integer-only Training and Inference of Neural Networks without  Quantization via Direct Feedback Alignment and Pocket Activations in Pure C++",
    "abstract": " Comments: Accepted in tinyML Research Symposium '22, March 2022, San Jose, CA (TinyML 2022). 7 pages, 4 figures, 2 tables. [v5] title is modified ",
    "url": "https://arxiv.org/abs/2201.02863",
    "authors": [
      "Jaewoo Song",
      "Fangzhen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.04584",
    "title": "ECONet: Efficient Convolutional Online Likelihood Network for  Scribble-based Interactive Segmentation",
    "abstract": " Comments: Accepted at MIDL 2022 ",
    "url": "https://arxiv.org/abs/2201.04584",
    "authors": [
      "Muhammad Asad",
      "Lucas Fidon",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06700",
    "title": "Benchmarking Subset Selection from Large Candidate Solution Sets in  Evolutionary Multi-objective Optimization",
    "abstract": " Title: Benchmarking Subset Selection from Large Candidate Solution Sets in  Evolutionary Multi-objective Optimization ",
    "url": "https://arxiv.org/abs/2201.06700",
    "authors": [
      "Ke Shang",
      "Tianye Shu",
      "Hisao Ishibuchi",
      "Yang Nan",
      "Lie Meng Pang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.06971",
    "title": "Identification for Accountability vs Privacy",
    "abstract": " Comments: 4 pages plus appendix, 9 pages total ",
    "url": "https://arxiv.org/abs/2201.06971",
    "authors": [
      "Nick Pope",
      "Geoffrey Goodell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.07532",
    "title": "Consensus of Network of Homogeneous Agents with General Linear Dynamics",
    "abstract": " Comments: added references ",
    "url": "https://arxiv.org/abs/2201.07532",
    "authors": [
      "Chong Jin Ong",
      "Ilayda Canyakmaz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.08452",
    "title": "npm-filter: Automating the mining of dynamic information from npm  packages",
    "abstract": " Comments: 5 pages. To appear in In 19th International Conference on Mining Software Repositories (MSR '22), May 23-24, 2022, Pittsburgh, PA, USA ",
    "url": "https://arxiv.org/abs/2201.08452",
    "authors": [
      "Ellen Arteca",
      "Alexi Turcotte"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.10943",
    "title": "Event-based Video Reconstruction via Potential-assisted Spiking Neural  Network",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2201.10943",
    "authors": [
      "Lin Zhu",
      "Xiao Wang",
      "Yi Chang",
      "Jianing Li",
      "Tiejun Huang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.03278",
    "title": "Crafting Better Contrastive Views for Siamese Representation Learning",
    "abstract": " Comments: Accepted by CVPR 2022 as an oral paper ",
    "url": "https://arxiv.org/abs/2202.03278",
    "authors": [
      "Xiangyu Peng",
      "Kai Wang",
      "Zheng Zhu",
      "Mang Wang",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11301",
    "title": "End-to-end LPCNet: A Neural Vocoder With Fully-Differentiable LPC  Estimation",
    "abstract": " Comments: Submitted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2202.11301",
    "authors": [
      "Krishna Subramani",
      "Jean-Marc Valin",
      "Umut Isik",
      "Paris Smaragdis",
      "Arvindh Krishnaswamy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.00438",
    "title": "An Analytical Approach to Compute the Exact Preimage of Feed-Forward  Neural Networks",
    "abstract": " Title: An Analytical Approach to Compute the Exact Preimage of Feed-Forward  Neural Networks ",
    "url": "https://arxiv.org/abs/2203.00438",
    "authors": [
      "Th\u00e9o Nancy",
      "Vassili Maillet",
      "Johann Barbier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00998",
    "title": "Adorned in Memes: Exploring the Adoption of Social Wearables in Nordic  Student Culture",
    "abstract": " Comments: Conditionally Accepted Preprint to CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 18 pages ",
    "url": "https://arxiv.org/abs/2203.00998",
    "authors": [
      "Felix Anand Epp",
      "Anna Kantosalo",
      "Nehal Jain",
      "Andr\u00e9s Lucero",
      "Elisa D Mekler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.01391",
    "title": "DDL-MVS: Depth Discontinuity Learning for MVS Networks",
    "abstract": " Title: DDL-MVS: Depth Discontinuity Learning for MVS Networks ",
    "url": "https://arxiv.org/abs/2203.01391",
    "authors": [
      "Nail Ibrahimli",
      "Hugo Ledoux",
      "Julian Kooij",
      "Liangliang Nan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04356",
    "title": "Which side are you on? Insider-Outsider classification in  conspiracy-theoretic social media",
    "abstract": " Comments: ACL 2022: 60th Annual Meeting of the Association for Computational Linguistics 8+4 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2203.04356",
    "authors": [
      "Pavan Holur",
      "Tianyi Wang",
      "Shadi Shahsavari",
      "Timothy Tangherlini",
      "Vwani Roychowdhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.04963",
    "title": "Neural Data-Dependent Transform for Learned Image Compression",
    "abstract": " Comments: Accepted by CVPR 2022. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2203.04963",
    "authors": [
      "Dezhao Wang",
      "Wenhan Yang",
      "Yueyu Hu",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07736",
    "title": "CSRS: Code Search with Relevance Matching and Semantic Matching",
    "abstract": " Title: CSRS: Code Search with Relevance Matching and Semantic Matching ",
    "url": "https://arxiv.org/abs/2203.07736",
    "authors": [
      "Yi Cheng",
      "Li Kuang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.07772",
    "title": "Fast Autofocusing using Tiny Transformer Networks for Digital  Holographic Microscopy",
    "abstract": " Title: Fast Autofocusing using Tiny Transformer Networks for Digital  Holographic Microscopy ",
    "url": "https://arxiv.org/abs/2203.07772",
    "authors": [
      "St\u00e9phane Cuenat",
      "Louis Andr\u00e9oli",
      "Antoine N. Andr\u00e9",
      "Patrick Sandoz",
      "Guillaume J. Laurent",
      "Rapha\u00ebl Couturier",
      "Maxime Jacquot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.11490",
    "title": "SSD-KD: A Self-supervised Diverse Knowledge Distillation Method for  Lightweight Skin Lesion Classification Using Dermoscopic Images",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2203.11490",
    "authors": [
      "Yongwei Wang",
      "Yuheng Wang",
      "Tim K. Lee",
      "Chunyan Miao",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.12980",
    "title": "MERLIN -- Malware Evasion with Reinforcement LearnINg",
    "abstract": " Title: MERLIN -- Malware Evasion with Reinforcement LearnINg ",
    "url": "https://arxiv.org/abs/2203.12980",
    "authors": [
      "Tony Quertier",
      "Benjamin Marais",
      "St\u00e9phane Morucci",
      "Bertrand Fournel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.13746",
    "title": "Code Smells for Machine Learning Applications",
    "abstract": " Comments: Accepted at CAIN ",
    "url": "https://arxiv.org/abs/2203.13746",
    "authors": [
      "Haiyin Zhang",
      "Lu\u00eds Cruz",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.14048",
    "title": "Learning Deep Implicit Functions for 3D Shapes with Dynamic Code Clouds",
    "abstract": " Comments: Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.14048",
    "authors": [
      "Tianyang Li",
      "Xin Wen",
      "Yu-Shen Liu",
      "Hua Su",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14681",
    "title": "ObjectFormer for Image Manipulation Detection and Localization",
    "abstract": " Comments: accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.14681",
    "authors": [
      "Junke Wang",
      "Zuxuan Wu",
      "Jingjing Chen",
      "Xintong Han",
      "Abhinav Shrivastava",
      "Ser-Nam Lim",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14856",
    "title": "WSEBP: A Novel Width-depth Synchronous Extension-based Basis Pursuit  Algorithm for Multi-Layer Convolutional Sparse Coding",
    "abstract": " Title: WSEBP: A Novel Width-depth Synchronous Extension-based Basis Pursuit  Algorithm for Multi-Layer Convolutional Sparse Coding ",
    "url": "https://arxiv.org/abs/2203.14856",
    "authors": [
      "Haitong Tang",
      "Shuang He",
      "Lingbin Bian",
      "Zhiming Cui",
      "Nizhuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15030",
    "title": "Solving Disjunctive Temporal Networks with Uncertainty under Restricted  Time-Based Controllability using Tree Search and Graph Neural Networks",
    "abstract": " Comments: Thirty-Sixth AAAI Conference on Artificial Intelligence. This version includes the technical appendix. arXiv admin note: substantial text overlap with arXiv:2108.01068 ",
    "url": "https://arxiv.org/abs/2203.15030",
    "authors": [
      "Kevin Osanlou",
      "Jeremy Frank",
      "Andrei Bursuc",
      "Tristan Cazenave",
      "Eric Jacopin",
      "Christophe Guettier",
      "J. Benton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.15212",
    "title": "Are Edge Weights in Summary Graphs Useful? -- A Comparative Study",
    "abstract": " Comments: To be published in the 26th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2022) ",
    "url": "https://arxiv.org/abs/2203.15212",
    "authors": [
      "Shinhwan Kang",
      "Kyuhan Lee",
      "Kijung Shin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.15221",
    "title": "Few Could Be Better Than All: Feature Sampling and Grouping for Scene  Text Detection",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.15221",
    "authors": [
      "Jingqun Tang",
      "Wenqing Zhang",
      "Hongye Liu",
      "MingKun Yang",
      "Bo Jiang",
      "Guanglong Hu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15319",
    "title": "Can NMT Understand Me? Towards Perturbation-based Evaluation of NMT  Models for Code Generation",
    "abstract": " Comments: Paper accepted for publication in the proceedings of The 1st Intl. Workshop on Natural Language-based Software Engineering (NLBSE) to be held with ICSE 2022 ",
    "url": "https://arxiv.org/abs/2203.15319",
    "authors": [
      "Pietro Liguori",
      "Cristina Improta",
      "Simona De Vivo",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.15353",
    "title": "SIOD: Single Instance Annotated Per Category Per Image for Object  Detection",
    "abstract": " Comments: CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.15353",
    "authors": [
      "Hanjun Li",
      "Xingjia Pan",
      "Ke Yan",
      "Fan Tang",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15406",
    "title": "TransductGAN: a Transductive Adversarial Model for Novelty Detection",
    "abstract": " Title: TransductGAN: a Transductive Adversarial Model for Novelty Detection ",
    "url": "https://arxiv.org/abs/2203.15406",
    "authors": [
      "Najiba Toron",
      "Janaina Mourao-Miranda",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15431",
    "title": "Investigating Self-supervised Pretraining Frameworks for Pathological  Speech Recognition",
    "abstract": " Comments: Submitted to INTERSPEECH 2022 ",
    "url": "https://arxiv.org/abs/2203.15431",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.15547",
    "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism",
    "abstract": " Comments: 6 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2203.15547",
    "authors": [
      "Jerrin Bright",
      "Suryaprakash Rajkumar",
      "Arockia Selvakumar Arockia Doss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15577",
    "title": "Understanding Code Snippets in Code Reviews: A Preliminary Study of the  OpenStack Community",
    "abstract": " Comments: The 30th IEEE/ACM International Conference on Program Comprehension (ICPC) ERA Track ",
    "url": "https://arxiv.org/abs/2203.15577",
    "authors": [
      "Liming Fu",
      "Peng Liang",
      "Beiqi Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  }
]