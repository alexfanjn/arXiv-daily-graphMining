[
  {
    "id": "arXiv:2203.11199",
    "title": "Distinguishing Non-natural from Natural Adversarial Samples for More  Robust Pre-trained Language Model",
    "abstract": "Recently, the problem of robustness of pre-trained language models (PrLMs) has received increasing research interest. Latest studies on adversarial attacks achieve high attack success rates against PrLMs, claiming that PrLMs are not robust. However, we find that the adversarial samples that PrLMs fail are mostly non-natural and do not appear in reality. We question the validity of current evaluation of robustness of PrLMs based on these non-natural adversarial samples and propose an anomaly detector to evaluate the robustness of PrLMs with more natural adversarial samples. We also investigate two applications of the anomaly detector: (1) In data augmentation, we employ the anomaly detector to force generating augmented data that are distinguished as non-natural, which brings larger gains to the accuracy of PrLMs. (2) We apply the anomaly detector to a defense framework to enhance the robustness of PrLMs. It can be used to defend all types of attacks and achieves higher accuracy on both adversarial samples and compliant samples than other defense frameworks. ",
    "url": "https://arxiv.org/abs/2203.11199",
    "authors": [
      "Jiayi Wang",
      "Rongzhou Bao",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.11200",
    "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily",
    "abstract": "Due to the homophily assumption of graph convolution networks, a common consensus is that graph neural networks (GNNs) perform well on homophilic graphs but may fail on the heterophilic graphs with many inter-class edges. In this work, we re-examine the heterophily problem of GNNs and investigate the feature aggregation of inter-class neighbors. To better evaluate whether the neighbor is helpful for the downstream tasks, we present the concept of the neighbor effect of each node and use the von Neumann entropy to measure the randomness/identifiability of the neighbor distribution for each class. Moreover, we propose a Conv-Agnostic GNNs framework (CAGNNs) to enhance the performance of GNNs on heterophily datasets by learning the neighbor effect for each node. Specifically, we first decouple the feature of each node into the discriminative feature for downstream tasks and the aggregation feature for graph convolution. Then, we propose a shared mixer module for all layers to adaptively evaluate the neighbor effect of each node to incorporate the neighbor information. Experiments are performed on nine well-known benchmark datasets for the node classification task. The results indicate that our framework is able to improve the average prediction performance by 9.81\\%, 25.81\\%, and 20.61\\% for GIN, GAT, and GCN, respectively. Extensive ablation studies and robustness analysis further verify the effectiveness, robustness, and interpretability of our framework. ",
    "url": "https://arxiv.org/abs/2203.11200",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Zengfeng Huang",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11201",
    "title": "Efficient Neural Network Analysis with Sum-of-Infeasibilities",
    "abstract": "Inspired by sum-of-infeasibilities methods in convex optimization, we propose a novel procedure for analyzing verification queries on neural networks with piecewise-linear activation functions. Given a convex relaxation which over-approximates the non-convex activation functions, we encode the violations of activation functions as a cost function and optimize it with respect to the convex relaxation. The cost function, referred to as the Sum-of-Infeasibilities (SoI), is designed so that its minimum is zero and achieved only if all the activation functions are satisfied. We propose a stochastic procedure, DeepSoI, to efficiently minimize the SoI. An extension to a canonical case-analysis-based complete search procedure can be achieved by replacing the convex procedure executed at each search state with DeepSoI. Extending the complete search with DeepSoI achieves multiple simultaneous goals: 1) it guides the search towards a counter-example; 2) it enables more informed branching decisions; and 3) it creates additional opportunities for bound derivation. An extensive evaluation across different benchmarks and solvers demonstrates the benefit of the proposed techniques. In particular, we demonstrate that SoI significantly improves the performance of an existing complete search procedure. Moreover, the SoI-based implementation outperforms other state-of-the-art complete verifiers. We also show that our technique can efficiently improve upon the perturbation bound derived by a recent adversarial attack algorithm. ",
    "url": "https://arxiv.org/abs/2203.11201",
    "authors": [
      "Haoze Wu",
      "Aleksandar Zelji\u0107",
      "Guy Katz",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.11207",
    "title": "Hybrid training of optical neural networks",
    "abstract": "Optical neural networks are emerging as a promising type of machine learning hardware capable of energy-efficient, parallel computation. Today's optical neural networks are mainly developed to perform optical inference after in silico training on digital simulators. However, various physical imperfections that cannot be accurately modelled may lead to the notorious reality gap between the digital simulator and the physical system. To address this challenge, we demonstrate hybrid training of optical neural networks where the weight matrix is trained with neuron activation functions computed optically via forward propagation through the network. We examine the efficacy of hybrid training with three different networks: an optical linear classifier, a hybrid opto-electronic network, and a complex-valued optical network. We perform a comparative study to in silico training, and our results show that hybrid training is robust against different kinds of static noise. Our platform-agnostic hybrid training scheme can be applied to a wide variety of optical neural networks, and this work paves the way towards advanced all-optical training in machine intelligence. ",
    "url": "https://arxiv.org/abs/2203.11207",
    "authors": [
      "James Spall",
      "Xianxin Guo",
      "A. I. Lvovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.11211",
    "title": "ReCCoVER: Detecting Causal Confusion for Explainable Reinforcement  Learning",
    "abstract": "Despite notable results in various fields over the recent years, deep reinforcement learning (DRL) algorithms lack transparency, affecting user trust and hindering their deployment to high-risk tasks. Causal confusion refers to a phenomenon where an agent learns spurious correlations between features which might not hold across the entire state space, preventing safe deployment to real tasks where such correlations might be broken. In this work, we examine whether an agent relies on spurious correlations in critical states, and propose an alternative subset of features on which it should base its decisions instead, to make it less susceptible to causal confusion. Our goal is to increase transparency of DRL agents by exposing the influence of learned spurious correlations on its decisions, and offering advice to developers about feature selection in different parts of state space, to avoid causal confusion. We propose ReCCoVER, an algorithm which detects causal confusion in agent's reasoning before deployment, by executing its policy in alternative environments where certain correlations between features do not hold. We demonstrate our approach in taxi and grid world environments, where ReCCoVER detects states in which an agent relies on spurious correlations and offers a set of features that should be considered instead. ",
    "url": "https://arxiv.org/abs/2203.11211",
    "authors": [
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11275",
    "title": "Liars are more influential: Effect of Deception in Influence  Maximization on Social Networks",
    "abstract": "Detecting influential users, called the influence maximization problem on social networks, is an important graph mining problem with many diverse applications such as information propagation, market advertising, and rumor controlling. There are many studies in the literature for influential users detection problem in social networks. Although the current methods are successfully used in many different applications, they assume that users are honest with each other and ignore the role of deception on social networks. On the other hand, deception appears to be surprisingly common among humans within social networks. In this paper, we study the effect of deception in influence maximization on social networks. We first model deception in social networks. Then, we model the opinion dynamics on these networks taking the deception into consideration thanks to a recent opinion dynamics model via sheaf Laplacian. We then extend two influential node detection methods, namely Laplacian centrality and DFF centrality, for the sheaf Laplacian to measure the effect of deception in influence maximization. Our experimental results on synthetic and real-world networks suggest that liars are more influential than honest users in social networks. ",
    "url": "https://arxiv.org/abs/2203.11275",
    "authors": [
      "Mehmet Emin Aktas",
      "Esra Akbas",
      "Ashley Hahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2203.11287",
    "title": "PCA-RF: An Efficient Parkinson's Disease Prediction Model based on  Random Forest Classification",
    "abstract": "In this modern era of overpopulation disease prediction is a crucial step in diagnosing various diseases at an early stage. With the advancement of various machine learning algorithms, the prediction has become quite easy. However, the complex and the selection of an optimal machine learning technique for the given dataset greatly affects the accuracy of the model. A large amount of datasets exists globally but there is no effective use of it due to its unstructured format. Hence, a lot of different techniques are available to extract something useful for the real world to implement. Therefore, accuracy becomes a major metric in evaluating the model. In this paper, a disease prediction approach is proposed that implements a random forest classifier on Parkinson's disease. We compared the accuracy of this model with the Principal Component Analysis (PCA) applied Artificial Neural Network (ANN) model and captured a visible difference. The model secured a significant accuracy of up to 90%. ",
    "url": "https://arxiv.org/abs/2203.11287",
    "authors": [
      "Ishu Gupta",
      "Vartika Sharma",
      "Sizman Kaur",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.11294",
    "title": "Automated detection of foreground speech with wearable sensing in  everyday home environments: A transfer learning approach",
    "abstract": "Acoustic sensing has proved effective as a foundation for numerous applications in health and human behavior analysis. In this work, we focus on the problem of detecting in-person social interactions in naturalistic settings from audio captured by a smartwatch. As a first step towards detecting social interactions, it is critical to distinguish the speech of the individual wearing the watch from all other sounds nearby, such as speech from other individuals and ambient sounds. This is very challenging in realistic settings, where interactions take place spontaneously and supervised models cannot be trained apriori to recognize the full complexity of dynamic social environments. In this paper, we introduce a transfer learning-based approach to detect foreground speech of users wearing a smartwatch. A highlight of the method is that it does not depend on the collection of voice samples to build user-specific models. Instead, the approach is based on knowledge transfer from general-purpose speaker representations derived from public datasets. Our experiments demonstrate that our approach performs comparably to a fully supervised model, with 80% F1 score. To evaluate the method, we collected a dataset of 31 hours of smartwatch-recorded audio in 18 homes with a total of 39 participants performing various semi-controlled tasks. ",
    "url": "https://arxiv.org/abs/2203.11294",
    "authors": [
      "Dawei Liang",
      "Zifan Xu",
      "Yinuo Chen",
      "Rebecca Adaimi",
      "David Harwath",
      "Edison Thomaz"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.11295",
    "title": "Benchmarking Test-Time Unsupervised Deep Neural Network Adaptation on  Edge Devices",
    "abstract": "The prediction accuracy of the deep neural networks (DNNs) after deployment at the edge can suffer with time due to shifts in the distribution of the new data. To improve robustness of DNNs, they must be able to update themselves to enhance their prediction accuracy. This adaptation at the resource-constrained edge is challenging as: (i) new labeled data may not be present; (ii) adaptation needs to be on device as connections to cloud may not be available; and (iii) the process must not only be fast but also memory- and energy-efficient. Recently, lightweight prediction-time unsupervised DNN adaptation techniques have been introduced that improve prediction accuracy of the models for noisy data by re-tuning the batch normalization (BN) parameters. This paper, for the first time, performs a comprehensive measurement study of such techniques to quantify their performance and energy on various edge devices as well as find bottlenecks and propose optimization opportunities. In particular, this study considers CIFAR-10-C image classification dataset with corruptions, three robust DNNs (ResNeXt, Wide-ResNet, ResNet-18), two BN adaptation algorithms (one that updates normalization statistics and the other that also optimizes transformation parameters), and three edge devices (FPGA, Raspberry-Pi, and Nvidia Xavier NX). We find that the approach that only updates the normalization parameters with Wide-ResNet, running on Xavier GPU, to be overall effective in terms of balancing multiple cost metrics. However, the adaptation overhead can still be significant (around 213 ms). The results strongly motivate the need for algorithm-hardware co-design for efficient on-device DNN adaptation. ",
    "url": "https://arxiv.org/abs/2203.11295",
    "authors": [
      "Kshitij Bhardwaj",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Maya Gokhale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2203.11305",
    "title": "Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video",
    "abstract": "We introduce the novel problem of anticipating a time series of future hand masks from egocentric video. A key challenge is to model the stochasticity of future head motions, which globally impact the head-worn camera video analysis. To this end, we propose a novel deep generative model -- EgoGAN, which uses a 3D Fully Convolutional Network to learn a spatio-temporal video representation for pixel-wise visual anticipation, generates future head motion using Generative Adversarial Network (GAN), and then predicts the future hand masks based on the video representation and the generated future head motion. We evaluate our method on both the EPIC-Kitchens and the EGTEA Gaze+ datasets. We conduct detailed ablation studies to validate the design choices of our approach. Furthermore, we compare our method with previous state-of-the-art methods on future image segmentation and show that our method can more accurately predict future hand masks. ",
    "url": "https://arxiv.org/abs/2203.11305",
    "authors": [
      "Wenqi Jia",
      "Miao Liu",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11315",
    "title": "Landscape Analysis for Surrogate Models in the Evolutionary Black-Box  Context",
    "abstract": "Surrogate modeling has become a valuable technique for black-box optimization tasks with expensive evaluation of the objective function. In this paper, we investigate the relationship between the predictive accuracy of surrogate models and features of the black-box function landscape. We also study properties of features for landscape analysis in the context of different transformations and ways of selecting the input data. We perform the landscape analysis of a large set of data generated using runs of a surrogate-assisted version of the Covariance Matrix Adaptation Evolution Strategy on the noiseless part of the Comparing Continuous Optimisers benchmark function testbed. ",
    "url": "https://arxiv.org/abs/2203.11315",
    "authors": [
      "Zbyn\u011bk Pitra",
      "Jan Koza",
      "Ji\u0159\u00ed Tumpach",
      "Martin Hole\u0148a"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.11316",
    "title": "Random vector functional link network: recent developments,  applications, and future directions",
    "abstract": "Neural networks have been successfully employed in various domain such as classification, regression and clustering, etc. Generally, the back propagation (BP) based iterative approaches are used to train the neural networks, however, it results in the issues of local minima, sensitivity to learning rate and slow convergence. To overcome these issues, randomization based neural networks such as random vector functional link (RVFL) network have been proposed. RVFL model has several characteristics such as fast training speed, simple architecture, and universal approximation capability, that make it a viable randomized neural network. This article presents the comprehensive review of the development of RVFL model, which can serve as the extensive summary for the beginners as well as practitioners. We discuss the shallow RVFL, ensemble RVFL, deep RVFL and ensemble deep RVFL models. The variations, improvements and applications of RVFL models are discussed in detail. Moreover, we discuss the different hyperparameter optimization techniques followed in the literature to improve the generalization performance of the RVFL model. Finally, we give potential future research directions/opportunities that can inspire the researchers to improve the RVFL architecture further. ",
    "url": "https://arxiv.org/abs/2203.11316",
    "authors": [
      "A. K. Malik",
      "Ruobin Gao",
      "M.A. Ganaie",
      "M. Tanveer",
      "P.N. Suganthan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.11323",
    "title": "Training Quantised Neural Networks with STE Variants: the Additive Noise  Annealing Algorithm",
    "abstract": "Training quantised neural networks (QNNs) is a non-differentiable optimisation problem since weights and features are output by piecewise constant functions. The standard solution is to apply the straight-through estimator (STE), using different functions during the inference and gradient computation steps. Several STE variants have been proposed in the literature aiming to maximise the task accuracy of the trained network. In this paper, we analyse STE variants and study their impact on QNN training. We first observe that most such variants can be modelled as stochastic regularisations of stair functions; although this intuitive interpretation is not new, our rigorous discussion generalises to further variants. Then, we analyse QNNs mixing different regularisations, finding that some suitably synchronised smoothing of each layer map is required to guarantee pointwise compositional convergence to the target discontinuous function. Based on these theoretical insights, we propose additive noise annealing (ANA), a new algorithm to train QNNs encompassing standard STE and its variants as special cases. When testing ANA on the CIFAR-10 image classification benchmark, we find that the major impact on task accuracy is not due to the qualitative shape of the regularisations but to the proper synchronisation of the different STE variants used in a network, in accordance with the theoretical results. ",
    "url": "https://arxiv.org/abs/2203.11323",
    "authors": [
      "Matteo Spallanzani",
      "Gian Paolo Leonardi",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11331",
    "title": "On The Robustness of Offensive Language Classifiers",
    "abstract": "Social media platforms are deploying machine learning based offensive language classification systems to combat hateful, racist, and other forms of offensive speech at scale. However, despite their real-world deployment, we do not yet comprehensively understand the extent to which offensive language classifiers are robust against adversarial attacks. Prior work in this space is limited to studying robustness of offensive language classifiers against primitive attacks such as misspellings and extraneous spaces. To address this gap, we systematically analyze the robustness of state-of-the-art offensive language classifiers against more crafty adversarial attacks that leverage greedy- and attention-based word selection and context-aware embeddings for word replacement. Our results on multiple datasets show that these crafty adversarial attacks can degrade the accuracy of offensive language classifiers by more than 50% while also being able to preserve the readability and meaning of the modified text. ",
    "url": "https://arxiv.org/abs/2203.11331",
    "authors": [
      "Jonathan Rusert",
      "Zubair Shafiq",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11343",
    "title": "Using Evolutionary Coupling to Establish Relevance Links Between Tests  and Code Units. A case study on fault localization",
    "abstract": "Many software engineering techniques, such as fault localization, operate based on relevance relationships between tests and code. These relationships are often inferred through the use of dynamic test execution information (test execution traces) that approximate the link between relevant code units and asserted, by the tests, program behaviour. Unfortunately, in practice dynamic information is not always available due to the overheads introduced by the instrumentation or the nature of the production environments. To deal with this issue, we propose CEMENT, a static technique that automatically infers such test and code relationships given the projects' evolution. The key idea is that developers make relevant changes on test and code units at the same period of time, i.e., co-evolution of tests and code units reflects a probable link between them. We evaluate CEMENT on 15 open source projects and show that it indeed captures relevant links. Additionally, we perform a fault localization case study where we compare CEMENT with an existing Information Retrieval-based Fault Localization (IRFL) technique and show that it achieves comparable performance. A further analysis of our results reveals a small overlap between the faults successfully localized by the two approaches suggesting complementarity. In particular, out of the 39 successfully localized faults, two are common while CEMENT and IRFL localize 16 and 21. These results demonstrate that test and code evolutionary coupling can effectively support test and debugging activities. ",
    "url": "https://arxiv.org/abs/2203.11343",
    "authors": [
      "Jeongju Sohn",
      "Mike Papadakis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.11355",
    "title": "Origami in N dimensions: How feed-forward networks manufacture linear  separability",
    "abstract": "Neural networks can implement arbitrary functions. But, mechanistically, what are the tools at their disposal to construct the target? For classification tasks, the network must transform the data classes into a linearly separable representation in the final hidden layer. We show that a feed-forward architecture has one primary tool at hand to achieve this separability: progressive folding of the data manifold in unoccupied higher dimensions. The operation of folding provides a useful intuition in low-dimensions that generalizes to high ones. We argue that an alternative method based on shear, requiring very deep architectures, plays only a small role in real-world networks. The folding operation, however, is powerful as long as layers are wider than the data dimensionality, allowing efficient solutions by providing access to arbitrary regions in the distribution, such as data points of one class forming islands within the other classes. We argue that a link exists between the universal approximation property in ReLU networks and the fold-and-cut theorem (Demaine et al., 1998) dealing with physical paper folding. Based on the mechanistic insight, we predict that the progressive generation of separability is necessarily accompanied by neurons showing mixed selectivity and bimodal tuning curves. This is validated in a network trained on the poker hand task, showing the emergence of bimodal tuning curves during training. We hope that our intuitive picture of the data transformation in deep networks can help to provide interpretability, and discuss possible applications to the theory of convolutional networks, loss landscapes, and generalization. TL;DR: Shows that the internal processing of deep networks can be thought of as literal folding operations on the data distribution in the N-dimensional activation space. A link to a well-known theorem in origami theory is provided. ",
    "url": "https://arxiv.org/abs/2203.11355",
    "authors": [
      "Christian Keup",
      "Moritz Helias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11361",
    "title": "Complexity of limit cycles with block-sequential update schedules in  conjunctive networks",
    "abstract": "In this paper, we deal the following decision problem: given a conjunctive Boolean network defined by its interaction digraph, does it have a limit cycle of a given length k? We prove that this problem is NP-complete in general if k is a parameter of the problem and in P if the interaction digraph is strongly connected. The case where $k$ is a constant, but the interaction digraph is not strongly connected remains open. Furthermore, we study the variation of the decision problem: given a conjunctive Boolean network, does there exist a block-sequential (resp. sequential) update schedule such that there exists a limit cycle of length k? We prove that this problem is NP-complete for any constant k >= 2. ",
    "url": "https://arxiv.org/abs/2203.11361",
    "authors": [
      "Julio Aracena",
      "Florian Bridoux",
      "Luis G\u00f3mez",
      "Lilian Salinas"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2203.11372",
    "title": "Sensitivity of Single-Pulse Radar Detection to Radar State Uncertainty",
    "abstract": "Mission planners for aircraft operating under threat of detection from ground-based radar systems are often concerned with the probability of detection. Current approaches to path planning in such environments consider the radar state (i.e. radar position and parameters) to be deterministic and known. In practice, there is uncertainty in the radar state which induces uncertainty in the probability of detection. This paper presents a method to incorporate the uncertainty of the radar state in a single-pulse radar detection model. The method linearizes the radar detection model with respect to the the radar state and uses the linearized models to estimate, to the first order, the variance of the probability of detection. The results in this paper validate the linearization using Monte Carlo analysis and illustrate the sensitivity of the probability of detection to radar state uncertainty. ",
    "url": "https://arxiv.org/abs/2203.11372",
    "authors": [
      "Austin Costley",
      "Randall Christensen",
      "Robert C. Leishman",
      "Greg Droge"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11373",
    "title": "Two methods for Jamming Identification in UAVs Networks using New  Synthetic Dataset",
    "abstract": "Unmanned aerial vehicle (UAV) systems are vulnerable to jamming from self-interested users who utilize radio devices for their benefits during UAV transmissions. The vulnerability occurs due to the open nature of air-to-ground (A2G) wireless communication networks, which may enable network-wide attacks. This paper presents two strategies to identify Jammers in UAV networks. The first strategy is based on time series approaches for anomaly detection where the signal available in resource blocks are decomposed statistically to find trend, seasonality, and residues, while the second is based on newly designed deep networks. The joined technique is suitable for UAVs because the statistical model does not require heavy computation processing but is limited in generalizing possible attack's identification. On the other hand, the deep network can classify attacks accurately but requires more resources. The simulation considers the location and power of the jamming attacks and the UAV position related to the base station. The statistical method technique made it feasible to identify 84.38 % of attacks when the attacker was at 30 m from the UAV. Furthermore, the Deep network's accuracy was approximately 99.99 % for jamming powers greater than two and jammer distances less than 200 meters. ",
    "url": "https://arxiv.org/abs/2203.11373",
    "authors": [
      "Joseanne Viana",
      "Hamed Farkhari",
      "Luis Miguel Campos",
      "Pedro Sebastiao",
      "Francisco Cercas",
      "Luis Bernardo",
      "Rui Dinis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.11375",
    "title": "Robust Model Predictive Control with Polytopic Model Uncertainty through  System Level Synthesis",
    "abstract": "We propose a novel method for robust model predictive control (MPC) of uncertain systems subject to both polytopic model uncertainty and additive disturbances. In our method, we over-approximate the actual uncertainty by a surrogate additive disturbance which simplifies constraint tightening of the robust optimal control problem. Using System Level Synthesis, we can optimize over a robust linear state feedback control policy and the uncertainty over-approximation parameters jointly and in a convex manner. The proposed method is demonstrated to achieve feasible domains close to the maximal robust control invariant set for a wide range of uncertainty parameters and significant improvement in conservatism compared with tube-based MPC through numerical examples. ",
    "url": "https://arxiv.org/abs/2203.11375",
    "authors": [
      "Shaoru Chen",
      "Victor M. Preciado",
      "Manfred Morari",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.11380",
    "title": "Energy Efficient PON Backhaul Network for a VLC Based Fog Architecture",
    "abstract": "In this paper, an energy efficient passive optical network (PON) architecture is proposed for backhaul connectivity in indoor visible light communication (VLC) systems. The proposed network is used to support a fog computing architecture allowing users with processing demands to access dedicated fog nodes and idle processing resources in other user devices within a building. The fog resources within a building complement fog nodes at higher layers of the access and metro networks and the central cloud data center. A mixed integer linear programming (MILP) model is developed to minimize the total power consumption associated with serving demands over the proposed architecture. The results show that the PON backhaul network improves the energy efficiency of fog computing by 66% for networking and 12% for processing compared to an architecture based on state-of-the-art Spine-and-Leaf connectivity. ",
    "url": "https://arxiv.org/abs/2203.11380",
    "authors": [
      "Wafaa B. M. Fadlelmula",
      "Sanaa H. Mohamed",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.11387",
    "title": "Privacy Rarely Considered: Exploring Considerations in the Adoption of  Third-Party Services by Websites",
    "abstract": "Modern websites frequently use and embed third-party services to facilitate web development, connect to social media, or for monetization. This often introduces privacy issues as the inclusion of third-party services on a website can allow the third party to collect personal data about the website's visitors. While the prevalence and mechanisms of third-party web tracking have been widely studied, little is known about the decision processes that lead to websites using third-party functionality and whether efforts are being made to protect their visitors' privacy. We report results from an online survey with 395 participants involved in the creation and maintenance of websites. For ten common website functionalities we investigated if privacy has played a role in decisions about how the functionality is integrated, if specific efforts for privacy protection have been made during integration, and to what degree people are aware of data collection through third parties. We find that ease of integration drives third-party adoption but visitor privacy is considered if there are legal requirements or respective guidelines. Awareness of data collection and privacy risks is higher if the collection is directly associated with the purpose for which the third-party service is used. ",
    "url": "https://arxiv.org/abs/2203.11387",
    "authors": [
      "Christine Utz",
      "Sabrina Amft",
      "Martin Degeling",
      "Thorsten Holz",
      "Sascha Fahl",
      "Florian Schaub"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.11396",
    "title": "Towards Textual Out-of-Domain Detection without In-Domain Labels",
    "abstract": "In many real-world settings, machine learning models need to identify user inputs that are out-of-domain (OOD) so as to avoid performing wrong actions. This work focuses on a challenging case of OOD detection, where no labels for in-domain data are accessible (e.g., no intent labels for the intent classification task). To this end, we first evaluate different language model based approaches that predict likelihood for a sequence of tokens. Furthermore, we propose a novel representation learning based method by combining unsupervised clustering and contrastive learning so that better data representations for OOD detection can be learned. Through extensive experiments, we demonstrate that this method can significantly outperform likelihood-based methods and can be even competitive to the state-of-the-art supervised approaches with label information. ",
    "url": "https://arxiv.org/abs/2203.11396",
    "authors": [
      "Di Jin",
      "Shuyang Gao",
      "Seokhwan Kim",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11401",
    "title": "Suum Cuique: Studying Bias in Taboo Detection with a Community  Perspective",
    "abstract": "Prior research has discussed and illustrated the need to consider linguistic norms at the community level when studying taboo (hateful/offensive/toxic etc.) language. However, a methodology for doing so, that is firmly founded on community language norms is still largely absent. This can lead both to biases in taboo text classification and limitations in our understanding of the causes of bias. We propose a method to study bias in taboo classification and annotation where a community perspective is front and center. This is accomplished by using special classifiers tuned for each community's language. In essence, these classifiers represent community level language norms. We use these to study bias and find, for example, biases are largest against African Americans (7/10 datasets and all 3 classifiers examined). In contrast to previous papers we also study other communities and find, for example, strong biases against South Asians. In a small scale user study we illustrate our key idea which is that common utterances, i.e., those with high alignment scores with a community (community classifier confidence scores) are unlikely to be regarded taboo. Annotators who are community members contradict taboo classification decisions and annotations in a majority of instances. This paper is a significant step toward reducing false positive taboo decisions that over time harm minority communities. ",
    "url": "https://arxiv.org/abs/2203.11401",
    "authors": [
      "Osama Khalid",
      "Jonathan Rusert",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11407",
    "title": "Causal inference in time series in terms of R\u00e9nyi transfer entropy",
    "abstract": "Uncovering causal interdependencies from observational data is one of the great challenges of nonlinear time series analysis. In this paper, we discuss this topic with the help of information-theoretic concept known as R\\'enyi information measure. In particular, we tackle the directional information flow between bivariate time series in terms of R\\'enyi transfer entropy. We show that by choosing R\\'enyi $\\alpha$ parameter appropriately we can control information that is transferred only between selected parts of underlying distributions. This, in turn, provides particularly potent tool for quantifying causal interdependencies in time series, where the knowledge of \"black swan\" events such as spikes or sudden jumps are of a key importance. In this connection, we first prove that for Gaussian variables, Granger causality and R\\'enyi transfer entropy are entirely equivalent. Moreover, we also partially extend this results to heavy-tailed $\\alpha$-Gaussian variables. These results allow to establish connection between autoregressive and R\\'enyi entropy based information-theoretic approaches to data-driven causal inference. To aid our intuition we employ Leonenko et al. entropy estimator and analyze R\\'enyi information flow between bivariate time series generated from two unidirectionally coupled R\\\"ossler systems. Notably, we find that R\\'enyi transfer entropy not only allowed us to detect a threshold of synchronization but it also provided a non-trivial insight into the structure of a transient regime that exists between region of chaotic correlations and synchronization threshold. In addition, from R\\'enyi transfer entropy we could reliably infer the direction of coupling - and hence causality, only for coupling strengths smaller that the onset value of transient regime, i.e. when two R\\\"ossler systems were coupled, but have not yet entered a synchronization. ",
    "url": "https://arxiv.org/abs/2203.11407",
    "authors": [
      "Petr Jizba",
      "Hynek Lavi\u010dka",
      "Zlata Tabachov\u00e1"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2203.11409",
    "title": "A Primer on Maximum Causal Entropy Inverse Reinforcement Learning",
    "abstract": "Inverse Reinforcement Learning (IRL) algorithms infer a reward function that explains demonstrations provided by an expert acting in the environment. Maximum Causal Entropy (MCE) IRL is currently the most popular formulation of IRL, with numerous extensions. In this tutorial, we present a compressed derivation of MCE IRL and the key results from contemporary implementations of MCE IRL algorithms. We hope this will serve both as an introductory resource for those new to the field, and as a concise reference for those already familiar with these topics. ",
    "url": "https://arxiv.org/abs/2203.11409",
    "authors": [
      "Adam Gleave",
      "Sam Toyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11410",
    "title": "Dazzle: Using Optimized Generative Adversarial Networks to Address  Security Data Class Imbalance Issue",
    "abstract": "Background: Machine learning techniques have been widely used and demonstrate promising performance in many software security tasks such as software vulnerability prediction. However, the class ratio within software vulnerability datasets is often highly imbalanced (since the percentage of observed vulnerability is usually very low). Goal: To help security practitioners address software security data class imbalanced issues and further help build better prediction models with resampled datasets. Method: We introduce an approach called Dazzle which is an optimized version of conditional Wasserstein Generative Adversarial Networks with gradient penalty (cWGAN-GP). Dazzle explores the architecture hyperparameters of cWGAN-GP with a novel optimizer called Bayesian Optimization. We use Dazzle to generate minority class samples to resample the original imbalanced training dataset. Results: We evaluate Dazzle with three software security datasets, i.e., Moodle vulnerable files, Ambari bug reports, and JavaScript function code. We show that Dazzle is practical to use and demonstrates promising improvement over existing state-of-the-art oversampling techniques such as SMOTE (e.g., with an average of about 60% improvement rate over SMOTE in recall among all datasets). Conclusion: Based on this study, we would suggest the use of optimized GANs as an alternative method for security vulnerability data class imbalanced issues. ",
    "url": "https://arxiv.org/abs/2203.11410",
    "authors": [
      "Rui Shu",
      "Tianpei Xia",
      "Laurie Williams",
      "Tim Menzies"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.11412",
    "title": "Robust Pivoting: Exploiting Frictional Stability Using Bilevel  Optimization",
    "abstract": "Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interaction with uncertainty in physical properties of the object. In this paper, we study robust optimization for control of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for the inaccuracies in the estimates of the physical properties during manipulation. In particular, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a bilevel trajectory optimization algorithm to design a controller that maximizes this stability margin to provide robustness against uncertainty in physical properties of the object. We demonstrate our proposed method using a 6 DoF manipulator for manipulating several different objects. ",
    "url": "https://arxiv.org/abs/2203.11412",
    "authors": [
      "Yuki Shirai",
      "Devesh K. Jha",
      "Arvind Raghunathan",
      "Diego Romeres"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11413",
    "title": "Learning Confidence for Transformer-based Neural Machine Translation",
    "abstract": "Confidence estimation aims to quantify the confidence of the model prediction, providing an expectation of success. A well-calibrated confidence estimate enables accurate failure prediction and proper risk measurement when given noisy samples and out-of-distribution data in real-world settings. However, this task remains a severe challenge for neural machine translation (NMT), where probabilities from softmax distribution fail to describe when the model is probably mistaken. To address this problem, we propose an unsupervised confidence estimate learning jointly with the training of the NMT model. We explain confidence as how many hints the NMT model needs to make a correct prediction, and more hints indicate low confidence. Specifically, the NMT model is given the option to ask for hints to improve translation accuracy at the cost of some slight penalty. Then, we approximate their level of confidence by counting the number of hints the model uses. We demonstrate that our learned confidence estimate achieves high accuracy on extensive sentence/word-level quality estimation tasks. Analytical results verify that our confidence estimate can correctly assess underlying risk in two real-world scenarios: (1) discovering noisy samples and (2) detecting out-of-domain data. We further propose a novel confidence-based instance-specific label smoothing approach based on our learned confidence estimate, which outperforms standard label smoothing. ",
    "url": "https://arxiv.org/abs/2203.11413",
    "authors": [
      "Yu Lu",
      "Jiali Zeng",
      "Jiajun Zhang",
      "Shuangzhi Wu",
      "Mu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11432",
    "title": "Gated Domain-Invariant Feature Disentanglement for Domain Generalizable  Object Detection",
    "abstract": "For Domain Generalizable Object Detection (DGOD), Disentangled Representation Learning (DRL) helps a lot by explicitly disentangling Domain-Invariant Representations (DIR) from Domain-Specific Representations (DSR). Considering the domain category is an attribute of input data, it should be feasible for networks to fit a specific mapping which projects DSR into feature channels exclusive to domain-specific information, and thus much cleaner disentanglement of DIR from DSR can be achieved simply on channel dimension. Inspired by this idea, we propose a novel DRL method for DGOD, which is termed Gated Domain-Invariant Feature Disentanglement (GDIFD). In GDIFD, a Channel Gate Module (CGM) learns to output channel gate signals close to either 0 or 1, which can mask out the channels exclusive to domain-specific information helpful for domain recognition. With the proposed GDIFD, the backbone in our framework can fit the desired mapping easily, which enables the channel-wise disentanglement. In experiments, we demonstrate that our approach is highly effective and achieves state-of-the-art DGOD performance. ",
    "url": "https://arxiv.org/abs/2203.11432",
    "authors": [
      "Haozhuo Zhang",
      "Huimin Yu",
      "Yuming Yan",
      "Runfa Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11433",
    "title": "Making DeepFakes more spurious: evading deep face forgery detection via  trace removal attack",
    "abstract": "DeepFakes are raising significant social concerns. Although various DeepFake detectors have been developed as forensic countermeasures, these detectors are still vulnerable to attacks. Recently, a few attacks, principally adversarial attacks, have succeeded in cloaking DeepFake images to evade detection. However, these attacks have typical detector-specific designs, which require prior knowledge about the detector, leading to poor transferability. Moreover, these attacks only consider simple security scenarios. Less is known about how effective they are in high-level scenarios where either the detectors or the attacker's knowledge varies. In this paper, we solve the above challenges with presenting a novel detector-agnostic trace removal attack for DeepFake anti-forensics. Instead of investigating the detector side, our attack looks into the original DeepFake creation pipeline, attempting to remove all detectable natural DeepFake traces to render the fake images more \"authentic\". To implement this attack, first, we perform a DeepFake trace discovery, identifying three discernible traces. Then a trace removal network (TR-Net) is proposed based on an adversarial learning framework involving one generator and multiple discriminators. Each discriminator is responsible for one individual trace representation to avoid cross-trace interference. These discriminators are arranged in parallel, which prompts the generator to remove various traces simultaneously. To evaluate the attack efficacy, we crafted heterogeneous security scenarios where the detectors were embedded with different levels of defense and the attackers' background knowledge of data varies. The experimental results show that the proposed attack can significantly compromise the detection accuracy of six state-of-the-art DeepFake detectors while causing only a negligible loss in visual quality to the original DeepFake samples. ",
    "url": "https://arxiv.org/abs/2203.11433",
    "authors": [
      "Chi Liu",
      "Huajie Chen",
      "Tianqing Zhu",
      "Jun Zhang",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.11437",
    "title": "Self-Supervised Representation Learning as Multimodal Variational  Inference",
    "abstract": "This paper proposes a probabilistic extension of SimSiam, a recent self-supervised learning (SSL) method. SimSiam trains a model by maximizing the similarity between image representations of different augmented views of the same image. Although uncertainty-aware machine learning has been getting general like deep variational inference, SimSiam and other SSL are insufficiently uncertainty-aware, which could lead to limitations on its potential. The proposed extension is to make SimSiam uncertainty-aware based on variational inference. Our main contributions are twofold: Firstly, we clarify the theoretical relationship between non-contrastive SSL and multimodal variational inference. Secondly, we introduce a novel SSL called variational inference SimSiam (VI-SimSiam), which incorporates the uncertainty by involving spherical posterior distributions. Our experiment shows that VI-SimSiam outperforms SimSiam in classification tasks in ImageNette and ImageWoof by successfully estimating the representation uncertainty. ",
    "url": "https://arxiv.org/abs/2203.11437",
    "authors": [
      "Hiroki Nakamura",
      "Masashi Okada",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11441",
    "title": "Multi-Modal Learning for AU Detection Based on Multi-Head Fused  Transformers",
    "abstract": "Multi-modal learning has been intensified in recent years, especially for applications in facial analysis and action unit detection whilst there still exist two main challenges in terms of 1) relevant feature learning for representation and 2) efficient fusion for multi-modalities. Recently, there are a number of works have shown the effectiveness in utilizing the attention mechanism for AU detection, however, most of them are binding the region of interest (ROI) with features but rarely apply attention between features of each AU. On the other hand, the transformer, which utilizes a more efficient self-attention mechanism, has been widely used in natural language processing and computer vision tasks but is not fully explored in AU detection tasks. In this paper, we propose a novel end-to-end Multi-Head Fused Transformer (MFT) method for AU detection, which learns AU encoding features representation from different modalities by transformer encoder and fuses modalities by another fusion transformer module. Multi-head fusion attention is designed in the fusion transformer module for the effective fusion of multiple modalities. Our approach is evaluated on two public multi-modal AU databases, BP4D, and BP4D+, and the results are superior to the state-of-the-art algorithms and baseline models. We further analyze the performance of AU detection from different modalities. ",
    "url": "https://arxiv.org/abs/2203.11441",
    "authors": [
      "Xiang Zhang",
      "Lijun Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11444",
    "title": "Root-aligned SMILES for Molecular Retrosynthesis Prediction",
    "abstract": "Retrosynthesis prediction is a fundamental problem in organic synthesis, where the task is to discover precursor molecules that can be used to synthesize a target molecule. A popular paradigm of existing computational retrosynthesis methods formulate retrosynthesis prediction as a sequence-to-sequence translation problem, where the typical SMILES representations are adopted for both reactants and products. However, the general-purpose SMILES neglects the characteristics of retrosynthesis that 1) the search space of the reactants is quite huge, and 2) the molecular graph topology is largely unaltered from products to reactants, resulting in the suboptimal performance of SMILES if straightforwardly applied. In this article, we propose the root-aligned SMILES~(R-SMILES), which specifies a tightly aligned one-to-one mapping between the product and the reactant SMILES, to narrow the string representation discrepancy for more efficient retrosynthesis. As the minimum edit distance between the input and the output is significantly decreased with the proposed R-SMILES, the computational model is largely relieved from learning the complex syntax and dedicated to learning the chemical knowledge for retrosynthesis. We compare the proposed R-SMILES with various state-of-the-art baselines on different benchmarks and show that it significantly outperforms them all, demonstrating the superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2203.11444",
    "authors": [
      "Zipeng Zhong",
      "Jie Song",
      "Zunlei Feng",
      "Tiantao Liu",
      "Lingxiang Jia",
      "Shaolun Liu",
      "Min Wu",
      "Tingjun Hou",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2203.11458",
    "title": "Hierarchical Graph Representation Learning for the Prediction of  Drug-Target Binding Affinity",
    "abstract": "The identification of drug-target binding affinity (DTA) has attracted increasing attention in the drug discovery process due to the more specific interpretation than binary interaction prediction. Recently, numerous deep learning-based computational methods have been proposed to predict the binding affinities between drugs and targets benefiting from their satisfactory performance. However, the previous works mainly focus on encoding biological features and chemical structures of drugs and targets, with a lack of exploiting the essential topological information from the drug-target affinity network. In this paper, we propose a novel hierarchical graph representation learning model for the drug-target binding affinity prediction, namely HGRL-DTA. The main contribution of our model is to establish a hierarchical graph learning architecture to incorporate the intrinsic properties of drug/target molecules and the topological affinities of drug-target pairs. In this architecture, we adopt a message broadcasting mechanism to integrate the hierarchical representations learned from the global-level affinity graph and the local-level molecular graph. Besides, we design a similarity-based embedding map to solve the cold start problem of inferring representations for unseen drugs and targets. Comprehensive experimental results under different scenarios indicate that HGRL-DTA significantly outperforms the state-of-the-art models and shows better model generalization among all the scenarios. ",
    "url": "https://arxiv.org/abs/2203.11458",
    "authors": [
      "Zhaoyang Chu",
      "Shichao Liu",
      "Wen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2203.11474",
    "title": "Remember Intentions: Retrospective-Memory-based Trajectory Prediction",
    "abstract": "To realize trajectory prediction, most previous methods adopt the parameter-based approach, which encodes all the seen past-future instance pairs into model parameters. However, in this way, the model parameters come from all seen instances, which means a huge amount of irrelevant seen instances might also involve in predicting the current situation, disturbing the performance. To provide a more explicit link between the current situation and the seen instances, we imitate the mechanism of retrospective memory in neuropsychology and propose MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data. In MemoNet, we design a pair of memory banks to explicitly store representative instances in the training set, acting as prefrontal cortex in the neural system, and a trainable memory addresser to adaptively search a current situation with similar instances in the memory bank, acting like basal ganglia. During prediction, MemoNet recalls previous memory by using the memory addresser to index related instances in the memory bank. We further propose a two-step trajectory prediction system, where the first step is to leverage MemoNet to predict the destination and the second step is to fulfill the whole trajectory according to the predicted destinations. Experiments show that the proposed MemoNet improves the FDE by 20.3%/10.2%/28.3% from the previous best method on SDD/ETH-UCY/NBA datasets. Experiments also show that our MemoNet has the ability to trace back to specific instances during prediction, promoting more interpretability. ",
    "url": "https://arxiv.org/abs/2203.11474",
    "authors": [
      "Chenxin Xu",
      "Weibo Mao",
      "Wenjun Zhang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11481",
    "title": "Mixed Differential Privacy in Computer Vision",
    "abstract": "We introduce AdaMix, an adaptive differentially private algorithm for training deep neural network classifiers using both private and public image data. While pre-training language models on large public datasets has enabled strong differential privacy (DP) guarantees with minor loss of accuracy, a similar practice yields punishing trade-offs in vision tasks. A few-shot or even zero-shot learning baseline that ignores private data can outperform fine-tuning on a large private dataset. AdaMix incorporates few-shot training, or cross-modal zero-shot learning, on public data prior to private fine-tuning, to improve the trade-off. AdaMix reduces the error increase from the non-private upper bound from the 167-311\\% of the baseline, on average across 6 datasets, to 68-92\\% depending on the desired privacy level selected by the user. AdaMix tackles the trade-off arising in visual classification, whereby the most privacy sensitive data, corresponding to isolated points in representation space, are also critical for high classification accuracy. In addition, AdaMix comes with strong theoretical privacy guarantees and convergence analysis. ",
    "url": "https://arxiv.org/abs/2203.11481",
    "authors": [
      "Aditya Golatkar",
      "Alessandro Achille",
      "Yu-Xiang Wang",
      "Aaron Roth",
      "Michael Kearns",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.11483",
    "title": "Practical Stereo Matching via Cascaded Recurrent Network with Adaptive  Correlation",
    "abstract": "With the advent of convolutional neural networks, stereo matching algorithms have recently gained tremendous progress. However, it remains a great challenge to accurately extract disparities from real-world image pairs taken by consumer-level devices like smartphones, due to practical complicating factors such as thin structures, non-ideal rectification, camera module inconsistencies and various hard-case scenes. In this paper, we propose a set of innovative designs to tackle the problem of practical stereo matching: 1) to better recover fine depth details, we design a hierarchical network with recurrent refinement to update disparities in a coarse-to-fine manner, as well as a stacked cascaded architecture for inference; 2) we propose an adaptive group correlation layer to mitigate the impact of erroneous rectification; 3) we introduce a new synthetic dataset with special attention to difficult cases for better generalizing to real-world scenes. Our results not only rank 1st on both Middlebury and ETH3D benchmarks, outperforming existing state-of-the-art methods by a notable margin, but also exhibit high-quality details for real-life photos, which clearly demonstrates the efficacy of our contributions. ",
    "url": "https://arxiv.org/abs/2203.11483",
    "authors": [
      "Jiankun Li",
      "Peisen Wang",
      "Pengfei Xiong",
      "Tao Cai",
      "Ziwei Yan",
      "Lei Yang",
      "Jiangyu Liu",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11486",
    "title": "Approaches for Improving the Performance of Fake News Detection in  Bangla: Imbalance Handling and Model Stacking",
    "abstract": "Imbalanced datasets can lead to biasedness into the detection of fake news. In this work, we present several strategies for resolving the imbalance issue for fake news detection in Bangla with a comparative assessment of proposed methodologies. Additionally, we propose a technique for improving performance even when the dataset is imbalanced. We applied our proposed approaches to BanFakeNews, a dataset developed for the purpose of detecting fake news in Bangla comprising of 50K instances but is significantly skewed, with 97% of majority instances. We obtained a 93.1% F1-score using data manipulation manipulation techniques such as SMOTE, and a 79.1% F1-score using without data manipulation approaches such as Stacked Generalization. Without implementing these techniques, the F1-score would have been 67.6% for baseline models. We see this work as an important step towards paving the way of fake news detection in Bangla. By implementing these strategies the obstacles of imbalanced dataset can be removed and improvement in the performance can be achieved. ",
    "url": "https://arxiv.org/abs/2203.11486",
    "authors": [
      "Md Muzakker Hossain",
      "Zahin Awosaf",
      "Md. Salman Hossan Prottoy",
      "Abu Saleh Muhammod Alvy",
      "Md. Kishor Morol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11490",
    "title": "SSD-KD: A Self-supervised Diverse Knowledge Distillation Method for  Lightweight Skin Lesion Classification Using Dermoscopic Images",
    "abstract": "Skin cancer is one of the most common types of malignancy, affecting a large population and causing a heavy economic burden worldwide. Over the last few years, computer-aided diagnosis has been rapidly developed and make great progress in healthcare and medical practices due to the advances in artificial intelligence. However, most studies in skin cancer detection keep pursuing high prediction accuracies without considering the limitation of computing resources on portable devices. In this case, knowledge distillation (KD) has been proven as an efficient tool to help improve the adaptability of lightweight models under limited resources, meanwhile keeping a high-level representation capability. To bridge the gap, this study specifically proposes a novel method, termed SSD-KD, that unifies diverse knowledge into a generic KD framework for skin diseases classification. Our method models an intra-instance relational feature representation and integrates it with existing KD research. A dual relational knowledge distillation architecture is self-supervisedly trained while the weighted softened outputs are also exploited to enable the student model to capture richer knowledge from the teacher model. To demonstrate the effectiveness of our method, we conduct experiments on ISIC 2019, a large-scale open-accessed benchmark of skin diseases dermoscopic images. Experiments show that our distilled lightweight model can achieve an accuracy as high as 85% for the classification tasks of 8 different skin diseases with minimal parameters and computing requirements. Ablation studies confirm the effectiveness of our intra- and inter-instance relational knowledge integration strategy. Compared with state-of-the-art knowledge distillation techniques, the proposed method demonstrates improved performances for multi-diseases classification on the large-scale dermoscopy database. ",
    "url": "https://arxiv.org/abs/2203.11490",
    "authors": [
      "Yongwei Wang",
      "Yuheng Wang",
      "Tim K. Lee",
      "Chunyan Miao",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11492",
    "title": "Exploring High-Order Structure for Robust Graph Structure Learning",
    "abstract": "Recent studies show that Graph Neural Networks (GNNs) are vulnerable to adversarial attack, i.e., an imperceptible structure perturbation can fool GNNs to make wrong predictions. Some researches explore specific properties of clean graphs such as the feature smoothness to defense the attack, but the analysis of it has not been well-studied. In this paper, we analyze the adversarial attack on graphs from the perspective of feature smoothness which further contributes to an efficient new adversarial defensive algorithm for GNNs. We discover that the effect of the high-order graph structure is a smoother filter for processing graph structures. Intuitively, the high-order graph structure denotes the path number between nodes, where larger number indicates closer connection, so it naturally contributes to defense the adversarial perturbation. Further, we propose a novel algorithm that incorporates the high-order structural information into the graph structure learning. We perform experiments on three popular benchmark datasets, Cora, Citeseer and Polblogs. Extensive experiments demonstrate the effectiveness of our method for defending against graph adversarial attacks. ",
    "url": "https://arxiv.org/abs/2203.11492",
    "authors": [
      "Guangqian Yang",
      "Yibing Zhan",
      "Jinlong Li",
      "Baosheng Yu",
      "Liu Liu",
      "Fengxiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11496",
    "title": "TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with  Transformers",
    "abstract": "LiDAR and camera are two important sensors for 3D object detection in autonomous driving. Despite the increasing popularity of sensor fusion in this field, the robustness against inferior image conditions, e.g., bad illumination and sensor misalignment, is under-explored. Existing fusion methods are easily affected by such conditions, mainly due to a hard association of LiDAR points and image pixels, established by calibration matrices. We propose TransFusion, a robust solution to LiDAR-camera fusion with a soft-association mechanism to handle inferior image conditions. Specifically, our TransFusion consists of convolutional backbones and a detection head based on a transformer decoder. The first layer of the decoder predicts initial bounding boxes from a LiDAR point cloud using a sparse set of object queries, and its second decoder layer adaptively fuses the object queries with useful image features, leveraging both spatial and contextual relationships. The attention mechanism of the transformer enables our model to adaptively determine where and what information should be taken from the image, leading to a robust and effective fusion strategy. We additionally design an image-guided query initialization strategy to deal with objects that are difficult to detect in point clouds. TransFusion achieves state-of-the-art performance on large-scale datasets. We provide extensive experiments to demonstrate its robustness against degenerated image quality and calibration errors. We also extend the proposed method to the 3D tracking task and achieve the 1st place in the leaderboard of nuScenes tracking, showing its effectiveness and generalization capability. ",
    "url": "https://arxiv.org/abs/2203.11496",
    "authors": [
      "Xuyang Bai",
      "Zeyu Hu",
      "Xinge Zhu",
      "Qingqiu Huang",
      "Yilun Chen",
      "Hongbo Fu",
      "Chiew-Lan Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11506",
    "title": "Rebalanced Siamese Contrastive Mining for Long-Tailed Recognition",
    "abstract": "Deep neural networks perform poorly on heavily class-imbalanced datasets. Given the promising performance of contrastive learning, we propose $\\mathbf{Re}$balanced $\\mathbf{S}$iamese $\\mathbf{Co}$ntrastive $\\mathbf{m}$ining ( $\\mathbf{ResCom}$) to tackle imbalanced recognition. Based on the mathematical analysis and simulation results, we claim that supervised contrastive learning suffers a dual class-imbalance problem at both the original batch and Siamese batch levels, which is more serious than long-tailed classification learning. In this paper, at the original batch level, we introduce a class-balanced supervised contrastive loss to assign adaptive weights for different classes. At the Siamese batch level, we present a class-balanced queue, which maintains the same number of keys for all classes. Furthermore, we note that the contrastive loss gradient with respect to the contrastive logits can be decoupled into the positives and negatives, and easy positives and easy negatives will make the contrastive gradient vanish. We propose supervised hard positive and negative pairs mining to pick up informative pairs for contrastive computation and improve representation learning. Finally, to approximately maximize the mutual information between the two views, we propose Siamese Balanced Softmax and joint it with the contrastive loss for one-stage training. ResCom outperforms the previous methods by large margins on multiple long-tailed recognition benchmarks. Our code will be made publicly available at: https://github.com/dvlab-research/ResCom. ",
    "url": "https://arxiv.org/abs/2203.11506",
    "authors": [
      "Zhisheng Zhong",
      "Jiequan Cui",
      "Eric Lo",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11537",
    "title": "Convolutional Neural Network-based Efficient Dense Point Cloud  Generation using Unsigned Distance Fields",
    "abstract": "Dense point cloud generation from a sparse or incomplete point cloud is a crucial and challenging problem in 3D computer vision and computer graphics. So far, the existing methods are either computationally too expensive, suffer from limited resolution, or both. In addition, some methods are strictly limited to watertight surfaces -- another major obstacle for a number of applications. To address these issues, we propose a lightweight Convolutional Neural Network that learns and predicts the unsigned distance field for arbitrary 3D shapes for dense point cloud generation using the recently emerged concept of implicit function learning. Experiments demonstrate that the proposed architecture achieves slightly better quality results than the state of the art with 87% less model parameters and 40% less GPU memory usage. ",
    "url": "https://arxiv.org/abs/2203.11537",
    "authors": [
      "Abol Basher",
      "Jani Boutellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11542",
    "title": "Mask Usage Recognition using Vision Transformer with Transfer Learning  and Data Augmentation",
    "abstract": "The COVID-19 pandemic has disrupted various levels of society. The use of masks is essential in preventing the spread of COVID-19 by identifying an image of a person using a mask. Although only 23.1% of people use masks correctly, Artificial Neural Networks (ANN) can help classify the use of good masks to help slow the spread of the Covid-19 virus. However, it requires a large dataset to train an ANN that can classify the use of masks correctly. MaskedFace-Net is a suitable dataset consisting of 137016 digital images with 4 class labels, namely Mask, Mask Chin, Mask Mouth Chin, and Mask Nose Mouth. Mask classification training utilizes Vision Transformers (ViT) architecture with transfer learning method using pre-trained weights on ImageNet-21k, with random augmentation. In addition, the hyper-parameters of training of 20 epochs, an Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.03, a batch size of 64, a Gaussian Cumulative Distribution (GeLU) activation function, and a Cross-Entropy loss function are used to be applied on the training of three architectures of ViT, namely Base-16, Large-16, and Huge-14. Furthermore, comparisons of with and without augmentation and transfer learning are conducted. This study found that the best classification is transfer learning and augmentation using ViT Huge-14. Using this method on MaskedFace-Net dataset, the research reaches an accuracy of 0.9601 on training data, 0.9412 on validation data, and 0.9534 on test data. This research shows that training the ViT model with data augmentation and transfer learning improves classification of the mask usage, even better than convolutional-based Residual Network (ResNet). ",
    "url": "https://arxiv.org/abs/2203.11542",
    "authors": [
      "Hensel Donato Jahja",
      "Novanto Yudistira",
      "Sutrisno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11559",
    "title": "Frugal Learning of Virtual Exemplars for Label-Efficient Satellite Image  Change Detection",
    "abstract": "In this paper, we devise a novel interactive satellite image change detection algorithm based on active learning. The proposed framework is iterative and relies on a question and answer model which asks the oracle (user) questions about the most informative display (subset of critical images), and according to the user's responses, updates change detections. The contribution of our framework resides in a novel display model which selects the most representative and diverse virtual exemplars that adversely challenge the learned change detection functions, thereby leading to highly discriminating functions in the subsequent iterations of active learning. Extensive experiments, conducted on the challenging task of interactive satellite image change detection, show the superiority of the proposed virtual display model against the related work. ",
    "url": "https://arxiv.org/abs/2203.11559",
    "authors": [
      "Hichem Sahbi",
      "Sebastien Deschamps"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11564",
    "title": "Reinforcement-based frugal learning for satellite image change detection",
    "abstract": "In this paper, we introduce a novel interactive satellite image change detection algorithm based on active learning. The proposed approach is iterative and asks the user (oracle) questions about the targeted changes and according to the oracle's responses updates change detections. We consider a probabilistic framework which assigns to each unlabeled sample a relevance measure modeling how critical is that sample when training change detection functions. These relevance measures are obtained by minimizing an objective function mixing diversity, representativity and uncertainty. These criteria when combined allow exploring different data modes and also refining change detections. To further explore the potential of this objective function, we consider a reinforcement learning approach that finds the best combination of diversity, representativity and uncertainty, through active learning iterations, leading to better generalization as corroborated through experiments in interactive satellite image change detection. ",
    "url": "https://arxiv.org/abs/2203.11564",
    "authors": [
      "Sebastien Deschamps",
      "Hichem Sahbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11570",
    "title": "Conditional Generative Data Augmentation for Clinical Audio Datasets",
    "abstract": "In this work, we propose a novel data augmentation method for clinical audio datasets based on a conditional Wasserstein Generative Adversarial Network with Gradient Penalty (cWGAN-GP), operating on log-mel spectrograms. To validate our method, we created a clinical audio dataset which was recorded in a real-world operating room during Total Hip Arthroplasty (THA) procedures and contains typical sounds which resemble the different phases of the intervention. We demonstrate the capability of the proposed method to generate realistic class-conditioned samples from the dataset distribution and show that training with the generated augmented samples outperforms classical audio augmentation methods in terms of classification accuracy. The performance was evaluated using a ResNet-18 classifier which shows a mean per-class accuracy improvement of 1.51% in a 5-fold cross validation experiment using the proposed augmentation method. Because clinical data is often expensive to acquire, the development of realistic and high-quality data augmentation methods is crucial to improve the robustness and generalization capabilities of learning-based algorithms which is especially important for safety-critical medical applications. Therefore, the proposed data augmentation method is an important step towards improving the data bottleneck for clinical audio-based machine learning systems. The code and dataset will be published upon acceptance. ",
    "url": "https://arxiv.org/abs/2203.11570",
    "authors": [
      "Matthias Seibold",
      "Armando Hoch",
      "Mazda Farshad",
      "Nassir Navab",
      "Philipp F\u00fcrnstahl"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.11590",
    "title": "IDEA-Net: Dynamic 3D Point Cloud Interpolation via Deep Embedding  Alignment",
    "abstract": "This paper investigates the problem of temporally interpolating dynamic 3D point clouds with large non-rigid deformation. We formulate the problem as estimation of point-wise trajectories (i.e., smooth curves) and further reason that temporal irregularity and under-sampling are two major challenges. To tackle the challenges, we propose IDEA-Net, an end-to-end deep learning framework, which disentangles the problem under the assistance of the explicitly learned temporal consistency. Specifically, we propose a temporal consistency learning module to align two consecutive point cloud frames point-wisely, based on which we can employ linear interpolation to obtain coarse trajectories/in-between frames. To compensate the high-order nonlinear components of trajectories, we apply aligned feature embeddings that encode local geometry properties to regress point-wise increments, which are combined with the coarse estimations. We demonstrate the effectiveness of our method on various point cloud sequences and observe large improvement over state-of-the-art methods both quantitatively and visually. Our framework can bring benefits to 3D motion data acquisition. The source code is publicly available at https://github.com/ZENGYIMING-EAMON/IDEA-Net.git. ",
    "url": "https://arxiv.org/abs/2203.11590",
    "authors": [
      "Yiming Zeng",
      "Yue Qian",
      "Qijian Zhang",
      "Junhui Hou",
      "Yixuan Yuan",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11594",
    "title": "Budgeted Influence Maximization via Boost Simulated Annealing in Social  Networks",
    "abstract": "Due to much closer to real application scenarios,the budgeted influence maximization (BIM) problem has attracted great attention among researchers. As a variant of the influence maximization (IM) problem, the BIM problem aims at mining several nodes with different costs as seeds with limited budget to maximize the influence as possible. By first activating these seed nodes and spreading influence under the given propagation model, the maximized spread of influence can be reached in the network. Several approaches have been proposed for BIM. Most of them are modified versions of the greedy algorithm, which work well on the IM but seems inefficient for the BIM because huge time consuming is inevitable. Recently, some intelligence algorithms are proposed in order to reduce the running time, but analysis shows that they cannot fully utilize the relationships between nodes in networks, which will result in influence loss. Inspired by this, we propose an efficient method based on boosted simulated annealing (SA) algorithm in this paper. Three heuristic strategies are proposed to improve the performance and speed up the proposed algorithm. Experimental results on both real world and synthetic networks demonstrate that the proposed boosted SA performs much better than existed algorithms on performance with almost equal or less running time. ",
    "url": "https://arxiv.org/abs/2203.11594",
    "authors": [
      "Jianshe Wu",
      "Junjun Gao",
      "Hongde Zhu",
      "Zulei Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.11606",
    "title": "Analysis of Disfluencies for automatic detection of Mild Cognitive  Impartment: a deep learning approach",
    "abstract": "The so-called Mild Cognitive Impairment (MCI) or cognitive loss appears in a previous stage before Alzheimer's Disease (AD), but it does not seem sufficiently severe to interfere in independent abilities of daily life, so it usually does not receive an appropriate diagnosis. Its detection is a challenging issue to be addressed by medical specialists. This work presents a novel proposal based on automatic analysis of speech and disfluencies aimed at supporting MCI diagnosis. The approach includes deep learning by means of Convolutional Neural Networks (CNN) and non-linear multifeature modelling. Moreover, to select the most relevant features non-parametric Mann-Whitney U-testt and Support Vector Machine Attribute (SVM) evaluation are used. ",
    "url": "https://arxiv.org/abs/2203.11606",
    "authors": [
      "Karmele Lopez-de-Ipi\u00f1a",
      "Unai Martinez de Lizarduy",
      "Pilar Calvo",
      "Blanca Beita",
      "Joseba Garc\u00eda-Melero",
      "Miriam Ecay-Torres",
      "Ainara Estanga",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.11611",
    "title": "Dense Residual Networks for Gaze Mapping on Indian Roads",
    "abstract": "In the recent past, greater accessibility to powerful computational resources has enabled progress in the field of Deep Learning and Computer Vision to grow by leaps and bounds. This in consequence has lent progress to the domain of Autonomous Driving and Navigation Systems. Most of the present research work has been focused on driving scenarios in the European or American roads. Our paper draws special attention to the Indian driving context. To this effect, we propose a novel architecture, DR-Gaze, which is used to map the driver's gaze onto the road. We compare our results with previous works and state-of-the-art results on the DGAZE dataset. Our code will be made publicly available upon acceptance of our paper. ",
    "url": "https://arxiv.org/abs/2203.11611",
    "authors": [
      "Chaitanya Kapoor",
      "Kshitij Kumar",
      "Soumya Vishnoi",
      "Sriram Ramanathan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11612",
    "title": "Nonlinear prediction with neural nets in ADPCM",
    "abstract": "In the last years there has been a growing interest for nonlinear speech models. Several works have been published revealing the better performance of nonlinear techniques, but little attention has been dedicated to the implementation of the nonlinear model into real applications. This work is focused on the study of the behaviour of a nonlinear predictive model based on neural nets, in a speech waveform coder. Our novel scheme obtains an improvement in SEGSNR between 1 and 2 dB for an adaptive quantization ranging from 2 to 5 bits. ",
    "url": "https://arxiv.org/abs/2203.11612",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Francesc Vallverdu",
      "Enric Monte"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.11624",
    "title": "High-resolution Iterative Feedback Network for Camouflaged Object  Detection",
    "abstract": "Spotting camouflaged objects that are visually assimilated into the background is tricky for both object detection algorithms and humans who are usually confused or cheated by the perfectly intrinsic similarities between the foreground objects and the background surroundings. To tackle this challenge, we aim to extract the high-resolution texture details to avoid the detail degradation that causes blurred vision in edges and boundaries. We introduce a novel HitNet to refine the low-resolution representations by high-resolution features in an iterative feedback manner, essentially a global loop-based connection among the multi-scale resolutions. In addition, an iterative feedback loss is proposed to impose more constraints on each feedback connection. Extensive experiments on four challenging datasets demonstrate that our \\ourmodel~breaks the performance bottleneck and achieves significant improvements compared with 29 state-of-the-art methods. To address the data scarcity in camouflaged scenarios, we provide an application example by employing cross-domain learning to extract the features that can reflect the camouflaged object properties and embed the features into salient objects, thereby generating more camouflaged training samples from the diverse salient object datasets The code will be available at https://github.com/HUuxiaobin/HitNet. ",
    "url": "https://arxiv.org/abs/2203.11624",
    "authors": [
      "Xiaobin Hu",
      "Deng-Ping Fan",
      "Xuebin Qin",
      "Hang Dai",
      "Wenqi Ren",
      "Ying Tai",
      "Chengjie Wang",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11629",
    "title": "On Neural Network Equivalence Checking using SMT Solvers",
    "abstract": "Two pretrained neural networks are deemed equivalent if they yield similar outputs for the same inputs. Equivalence checking of neural networks is of great importance, due to its utility in replacing learning-enabled components with equivalent ones, when there is need to fulfill additional requirements or to address security threats, as is the case for example when using knowledge distillation, adversarial training etc. SMT solvers can potentially provide solutions to the problem of neural network equivalence checking that will be sound and complete, but as it is expected any such solution is associated with significant limitations with respect to the size of neural networks to be checked. This work presents a first SMT-based encoding of the equivalence checking problem, explores its utility and limitations and proposes avenues for future research and improvements towards more scalable and practically applicable solutions. We present experimental results that shed light to the aforementioned issues, for diverse types of neural network models (classifiers and regression networks) and equivalence criteria, towards a general and application-independent equivalence checking approach. ",
    "url": "https://arxiv.org/abs/2203.11629",
    "authors": [
      "Charis Eleftheriadis",
      "Nikolaos Kekatos",
      "Panagiotis Katsaros",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.11633",
    "title": "Semi-Targeted Model Poisoning Attack on Federated Learning via Backward  Error Analysis",
    "abstract": "Model poisoning attacks on federated learning (FL) intrude in the entire system via compromising an edge model, resulting in malfunctioning of machine learning models. Such compromised models are tampered with to perform adversary-desired behaviors. In particular, we considered a semi-targeted situation where the source class is predetermined however the target class is not. The goal is to cause the global classifier to misclassify data of the source class. Though approaches such as label flipping have been adopted to inject poisoned parameters into FL, it has been shown that their performances are usually class-sensitive varying with different target classes applied. Typically, an attack can become less effective when shifting to a different target class. To overcome this challenge, we propose the Attacking Distance-aware Attack (ADA) to enhance a poisoning attack by finding the optimized target class in the feature space. Moreover, we studied a more challenging situation where an adversary had limited prior knowledge about a client's data. To tackle this problem, ADA deduces pair-wise distances between different classes in the latent feature space from shared model parameters based on the backward error analysis. We performed extensive empirical evaluations on ADA by varying the factor of attacking frequency in three different image classification tasks. As a result, ADA succeeded in increasing the attack performance by 1.8 times in the most challenging case with an attacking frequency of 0.01. ",
    "url": "https://arxiv.org/abs/2203.11633",
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.11639",
    "title": "Learning Relation-Specific Representations for Few-shot Knowledge Graph  Completion",
    "abstract": "Recent years have witnessed increasing interest in few-shot knowledge graph completion (FKGC), which aims to infer unseen query triples for a few-shot relation using a handful of reference triples of the relation. The primary focus of existing FKGC methods lies in learning the relation representations that can reflect the common information shared by the query and reference triples. To this end, these methods learn the embeddings of entities with their direct neighbors, and use the concatenation of the entity embeddings as the relation representations. However, the entity embeddings learned only from direct neighborhoods may have low expressiveness when the entity has sparse neighbors or shares a common local neighborhood with other entities. Moreover, the embeddings of two entities are insufficient to represent the semantic information of their relationship, especially when they have multiple relations. To address these issues, we propose a Relation-Specific Context Learning (RSCL) framework, which exploits graph contexts of triples to capture the semantic information of relations and entities simultaneously. Specifically, we first extract graph contexts for each triple, which can provide long-term entity-relation dependencies. To model the graph contexts, we then develop a hierarchical relation-specific learner to learn global and local relation-specific representations for relations by capturing contextualized information of triples and incorporating local information of entities. Finally, we utilize the learned representations to predict the likelihood of the query triples. Experimental results on two public datasets demonstrate that RSCL outperforms state-of-the-art FKGC methods. ",
    "url": "https://arxiv.org/abs/2203.11639",
    "authors": [
      "Yuling Li",
      "Kui Yu",
      "Yuhong Zhang",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11648",
    "title": "Learning Operators with Mesh-Informed Neural Networks",
    "abstract": "Thanks to their universal approximation properties and new efficient training strategies, Deep Neural Networks are becoming a valuable tool for the approximation of mathematical operators. In the present work, we introduce Mesh-Informed Neural Networks (MINNs), a class of architectures specifically tailored to handle mesh based functional data, and thus of particular interest for reduced order modeling of parametrized Partial Differential Equations (PDEs). The driving idea behind MINNs is to embed hidden layers into discrete functional spaces of increasing complexity, obtained through a sequence of meshes defined over the underlying spatial domain. The approach leads to a natural pruning strategy which enables the design of sparse architectures that are able to learn general nonlinear operators. We assess this strategy through an extensive set of numerical experiments, ranging from nonlocal operators to nonlinear diffusion PDEs, where MINNs are compared to classical fully connected Deep Neural Networks. Our results show that MINNs can handle functional data defined on general domains of any shape, while ensuring reduced training times, lower computational costs, and better generalization capabilities, thus making MINNs very well-suited for demanding applications such as Reduced Order Modeling and Uncertainty Quantification for PDEs. ",
    "url": "https://arxiv.org/abs/2203.11648",
    "authors": [
      "Nicola Rares Franco",
      "Andrea Manzoni",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.11652",
    "title": "Weakly-Supervised Salient Object Detection Using Point Supervison",
    "abstract": "Current state-of-the-art saliency detection models rely heavily on large datasets of accurate pixel-wise annotations, but manually labeling pixels is time-consuming and labor-intensive. There are some weakly supervised methods developed for alleviating the problem, such as image label, bounding box label, and scribble label, while point label still has not been explored in this field. In this paper, we propose a novel weakly-supervised salient object detection method using point supervision. To infer the saliency map, we first design an adaptive masked flood filling algorithm to generate pseudo labels. Then we develop a transformer-based point-supervised saliency detection model to produce the first round of saliency maps. However, due to the sparseness of the label, the weakly supervised model tends to degenerate into a general foreground detection model. To address this issue, we propose a Non-Salient Suppression (NSS) method to optimize the erroneous saliency maps generated in the first round and leverage them for the second round of training. Moreover, we build a new point-supervised dataset (P-DUTS) by relabeling the DUTS dataset. In P-DUTS, there is only one labeled point for each salient object. Comprehensive experiments on five largest benchmark datasets demonstrate our method outperforms the previous state-of-the-art methods trained with the stronger supervision and even surpass several fully supervised state-of-the-art models. The code is available at: https://github.com/shuyonggao/PSOD. ",
    "url": "https://arxiv.org/abs/2203.11652",
    "authors": [
      "Shuyong Gao",
      "Wei Zhang",
      "Yan Wang",
      "Qianyu Guo",
      "Chenglong Zhang",
      "Yangji He",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11654",
    "title": "Fine-Grained Scene Graph Generation with Data Transfer",
    "abstract": "Scene graph generation (SGG) aims to extract (subject, predicate, object) triplets in images. Recent works have made a steady progress on SGG, and provide useful tools for high-level vision and language understanding. However, due to the data distribution problems including long-tail distribution and semantic ambiguity, the predictions of current SGG models tend to collapse to several frequent but uninformative predicates (e.g., \\textit{on}, \\textit{at}), which limits practical application of these models in downstream tasks. To deal with the problems above, we propose a novel Internal and External Data Transfer (IETrans) method, which can be applied in a play-and-plug fashion and expanded to large SGG with 1,807 predicate classes. Our IETrans tries to relieve the data distribution problem by automatically creating an enhanced dataset that provides more sufficient and coherent annotations for all predicates. By training on the transferred dataset, a Neural Motif model doubles the macro performance while maintaining competitive micro performance. The data and code for this paper are publicly available at \\url{https://github.com/waxnkw/IETrans-SGG.pytorch} ",
    "url": "https://arxiv.org/abs/2203.11654",
    "authors": [
      "Ao Zhang",
      "Yuan Yao",
      "Qianyu Chen",
      "Wei Ji",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11677",
    "title": "Robust Action Gap Increasing with Clipped Advantage Learning",
    "abstract": "Advantage Learning (AL) seeks to increase the action gap between the optimal action and its competitors, so as to improve the robustness to estimation errors. However, the method becomes problematic when the optimal action induced by the approximated value function does not agree with the true optimal action. In this paper, we present a novel method, named clipped Advantage Learning (clipped AL), to address this issue. The method is inspired by our observation that increasing the action gap blindly for all given samples while not taking their necessities into account could accumulate more errors in the performance loss bound, leading to a slow value convergence, and to avoid that, we should adjust the advantage value adaptively. We show that our simple clipped AL operator not only enjoys fast convergence guarantee but also retains proper action gaps, hence achieving a good balance between the large action gap and the fast convergence. The feasibility and effectiveness of the proposed method are verified empirically on several RL benchmarks with promising performance. ",
    "url": "https://arxiv.org/abs/2203.11677",
    "authors": [
      "Zhe Zhang",
      "Yaozhong Gan",
      "Xiaoyang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11683",
    "title": "Twin Weisfeiler-Lehman: High Expressive GNNs for Graph Classification",
    "abstract": "The expressive power of message passing GNNs is upper-bounded by Weisfeiler-Lehman (WL) test. To achieve high expressive GNNs beyond WL test, we propose a novel graph isomorphism test method, namely Twin-WL, which simultaneously passes node labels and node identities rather than only passes node label as WL. The identity-passing mechanism encodes complete structure information of rooted subgraph, and thus Twin-WL can offer extra power beyond WL at distinguishing graph structures. Based on Twin-WL, we implement two Twin-GNNs for graph classification via defining readout function over rooted subgraph: one simply readouts the size of rooted subgraph and the other readouts rich structure information of subgraph following a GNN-style. We prove that the two Twin-GNNs both have higher expressive power than traditional message passing GNNs. Experiments also demonstrate the Twin-GNNs significantly outperform state-of-the-art methods at the task of graph classification. ",
    "url": "https://arxiv.org/abs/2203.11683",
    "authors": [
      "Zhaohui Wang",
      "Qi Cao",
      "Huawei Shen",
      "Bingbing Xu",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11685",
    "title": "Piecewise Constant Parameters Identification Under Finite Excitation  Condition: Time Alertness Preservation, Exponential Convergence, Robustness  and Applications",
    "abstract": "The scope of this research is the identification of piecewise constant parameters of linear regression equations under the finite excitation condition. Such an equation is considered as a switched system, which identification usually consists of three main steps: a switching time instant detection, choice of the most appropriate model from the known set or generation of a new one, online adjustment of the chosen model parameters. Compared to the known methods, to make the computational burden lower and simplify the stability analysis, we use only one model to identify all switching states of the regression. So, the proposed identification procedure includes only two main approaches. The first one is a new estimation algorithm to detect switching time and preserve time alertness, which is based on a well-known DREM procedure and ensures adjustable detection delay. Unlike existing solutions, it does not involve an offline operation of data monitoring and stacking. The second one is the adaptive law, which provides element-wise monotonous exponential convergence of the regression parameters to their true values over the time range between two consecutive switches. Its convergence condition is that the regressor is finitely exciting somewhere inside such time interval. The robustness of the proposed identification procedure to the influence of external disturbances is analytically proved. Its effectiveness is demonstrated via numerical experiments, in which both abstract regressions and a second-order plant model are used. ",
    "url": "https://arxiv.org/abs/2203.11685",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11693",
    "title": "Optical Flow Based Motion Detection for Autonomous Driving",
    "abstract": "Motion detection is a fundamental but challenging task for autonomous driving. In particular scenes like highway, remote objects have to be paid extra attention for better controlling decision. Aiming at distant vehicles, we train a neural network model to classify the motion status using optical flow field information as the input. The experiments result in high accuracy, showing that our idea is viable and promising. The trained model also achieves an acceptable performance for nearby vehicles. Our work is implemented in PyTorch. Open tools including nuScenes, FastFlowNet and RAFT are used. Visualization videos are available at https://www.youtube.com/playlist?list=PLVVrWgq4OrlBnRebmkGZO1iDHEksMHKGk . ",
    "url": "https://arxiv.org/abs/2203.11693",
    "authors": [
      "Ka Man Lo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11700",
    "title": "Exploring Linear Feature Disentanglement For Neural Networks",
    "abstract": "Non-linear activation functions, e.g., Sigmoid, ReLU, and Tanh, have achieved great success in neural networks (NNs). Due to the complex non-linear characteristic of samples, the objective of those activation functions is to project samples from their original feature space to a linear separable feature space. This phenomenon ignites our interest in exploring whether all features need to be transformed by all non-linear functions in current typical NNs, i.e., whether there exists a part of features arriving at the linear separable feature space in the intermediate layers, that does not require further non-linear variation but an affine transformation instead. To validate the above hypothesis, we explore the problem of linear feature disentanglement for neural networks in this paper. Specifically, we devise a learnable mask module to distinguish between linear and non-linear features. Through our designed experiments we found that some features reach the linearly separable space earlier than the others and can be detached partly from the NNs. The explored method also provides a readily feasible pruning strategy which barely affects the performance of the original model. We conduct our experiments on four datasets and present promising results. ",
    "url": "https://arxiv.org/abs/2203.11700",
    "authors": [
      "Tiantian He",
      "Zhibin Li",
      "Yongshun Gong",
      "Yazhou Yao",
      "Xiushan Nie",
      "Yilong Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11720",
    "title": "Continuous Detection, Rapidly React: Unseen Rumors Detection based on  Continual Prompt-Tuning",
    "abstract": "Since open social platforms allow for a large and continuous flow of unverified information, rumors can emerge unexpectedly and spread quickly. However, existing rumor detection (RD) models often assume the same training and testing distributions and cannot cope with the continuously changing social network environment. This paper proposes a Continual Prompt-Tuning RD (CPT-RD) framework, which avoids catastrophic forgetting of upstream tasks during sequential task learning and enables knowledge transfer between domain tasks. To avoid forgetting, we optimize and store task-special soft-prompt for each domain. Furthermore, we also propose several strategies to transfer knowledge of upstream tasks to deal with emergencies and a task-conditioned prompt-wise hypernetwork (TPHNet) to consolidate past domains, enabling bidirectional knowledge transfer. Finally, CPT-RD is evaluated on English and Chinese RD datasets and is effective and efficient compared to state-of-the-art baselines, without data replay techniques and with only a few parameter tuning. ",
    "url": "https://arxiv.org/abs/2203.11720",
    "authors": [
      "Yuhui Zuo",
      "Wei Zhu",
      "Guoyong Cai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11724",
    "title": "Explainable Misinformation Detection Across Multiple Social Media  Platforms",
    "abstract": "In this work, the integration of two machine learning approaches, namely domain adaptation and explainable AI, is proposed to address these two issues of generalized detection and explainability. Firstly the Domain Adversarial Neural Network (DANN) develops a generalized misinformation detector across multiple social media platforms DANN is employed to generate the classification results for test domains with relevant but unseen data. The DANN-based model, a traditional black-box model, cannot justify its outcome, i.e., the labels for the target domain. Hence a Local Interpretable Model-Agnostic Explanations (LIME) explainable AI model is applied to explain the outcome of the DANN mode. To demonstrate these two approaches and their integration for effective explainable generalized detection, COVID-19 misinformation is considered a case study. We experimented with two datasets, namely CoAID and MiSoVac, and compared results with and without DANN implementation. DANN significantly improves the accuracy measure F1 classification score and increases the accuracy and AUC performance. The results obtained show that the proposed framework performs well in the case of domain shift and can learn domain-invariant features while explaining the target labels with LIME implementation enabling trustworthy information processing and extraction to combat misinformation effectively. ",
    "url": "https://arxiv.org/abs/2203.11724",
    "authors": [
      "Rahee Walambe",
      "Ananya Srivastava",
      "Bhargav Yagnik",
      "Mohammed Hasan",
      "Zainuddin Saiyed",
      "Gargi Joshi",
      "Ketan Kotecha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.11729",
    "title": "Machine Learning based Laser Failure Mode Detection",
    "abstract": "Laser degradation analysis is a crucial process for the enhancement of laser reliability. Here, we propose a data-driven fault detection approach based on Long Short-Term Memory (LSTM) recurrent neural networks to detect the different laser degradation modes based on synthetic historical failure data. In comparison to typical threshold-based systems, attaining 24.41% classification accuracy, the LSTM-based model achieves 95.52% accuracy, and also outperforms classical machine learning (ML) models namely Random Forest (RF), K-Nearest Neighbours (KNN) and Logistic Regression (LR). ",
    "url": "https://arxiv.org/abs/2203.11729",
    "authors": [
      "khouloud Abdelli",
      "Danish Rafique",
      "Stephan Pachnicke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11735",
    "title": "A conservative multiscale method for stochastic highly heterogeneous  flow",
    "abstract": "In this paper, we propose a local model reduction approach for subsurface flow problems in stochastic and highly heterogeneous media. To guarantee the mass conservation, we consider the mixed formulation of the flow problem and aim to solve the problem in a coarse grid to reduce the complexity of a large-scale system. We decompose the entire problem into a training and a testing stage, namely the offline coarse-grid multiscale basis generation stage and online simulation stage with different parameters. In the training stage, a parameter-independent and small-dimensional multiscale basis function space is constructed, which includes the media, source and boundary information. The key part of the basis generation stage is to solve some local problems defined specially. With the parameter-independent basis space, one can efficiently solve the concerned problems corresponding to different samples of permeability field in a coarse grid without repeatedly constructing a multiscale space for each new sample. A rigorous analysis on convergence of the proposed method is proposed. In particular, we consider a generalization error, where bases constructed with one source will be used to a different source. In the numerical experiments, we apply the proposed method for both single-phase and twophase flow problems. Simulation results for both 2D and 3D representative models demonstrate the high accuracy and impressive performance of the proposed model reduction techniques. ",
    "url": "https://arxiv.org/abs/2203.11735",
    "authors": [
      "Yiran Wang",
      "Eric Chung",
      "Shubin Fu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.11740",
    "title": "Plasticity Neural Network Based on Astrocytic Influence at Critical  Periods, Synaptic Competition and Compensation by Current and Mnemonic Brain  Plasticity and Synapse Formation",
    "abstract": "Based on the RNN frame, we accomplished the model construction, formula derivation and algorithm testing for PNN. We elucidated the mechanism of PNN based on the latest MIT research on synaptic compensation, and also grounded our study on the basis of findings of the Stanford research, which suggested that synapse formation is important for competition in dendrite morphogenesis. The influence of astrocytic impacts on brain plasticity and synapse formation is an important mechanism of our Neural Network at critical periods or the end of critical periods.In the model for critical periods, the hypothesis is that the best brain plasticity so far affects current brain plasticity and the best synapse formation so far affects current synapse formation.Furthermore, PNN takes into account the mnemonic gradient informational synapse formation, and brain plasticity and synapse formation change frame of NN is a new method of Deep Learning.The question we proposed is whether the promotion of neuroscience and brain cognition was achieved by model construction, formula derivation or algorithm testing. We resorted to the Artificial Neural Network (ANN), evolutionary computation and other numerical methods for hypotheses, possible explanations and rules, rather than only biological tests which include cutting-edge imaging and genetic tools.And it has no ethics of animal testing. ",
    "url": "https://arxiv.org/abs/2203.11740",
    "authors": [
      "Jun-Bo Tao",
      "Bai-Qing Sun",
      "Wei-Dong Zhu",
      "Shi-You Qu",
      "Ling-Kun Chen",
      "Jia-Qiang Li",
      "Chong Wu",
      "Yu Xiong",
      "Jiaxuan Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11743",
    "title": "The Stanford Drone Dataset is More Complex than We Think: An Analysis of  Key Characteristics",
    "abstract": "Several datasets exist which contain annotated information of individuals' trajectories. Such datasets are vital for many real-world applications, including trajectory prediction and autonomous navigation. One prominent dataset currently in use is the Stanford Drone Dataset (SDD). Despite its prominence, discussion surrounding the characteristics of this dataset is insufficient. We demonstrate how this insufficiency reduces the information available to users and can impact performance. Our contributions include the outlining of key characteristics in the SDD, employment of an information-theoretic measure and custom metric to clearly visualize those characteristics, the implementation of the PECNet and Y-Net trajectory prediction models to demonstrate the outlined characteristics' impact on predictive performance, and lastly we provide a comparison between the SDD and Intersection Drone (inD) Dataset. Our analysis of the SDD's key characteristics is important because without adequate information about available datasets a user's ability to select the most suitable dataset for their methods, to reproduce one another's results, and to interpret their own results are hindered. The observations we make through this analysis provide a readily accessible and interpretable source of information for those planning to use the SDD. Our intention is to increase the performance and reproducibility of methods applied to this dataset going forward, while also clearly detailing less obvious features of the dataset for new users. ",
    "url": "https://arxiv.org/abs/2203.11743",
    "authors": [
      "Joshua Andle",
      "Nicholas Soucy",
      "Simon Socolow",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11780",
    "title": "On the Modeling and Simulation of Portfolio Allocation Schemes: an  Approach based on Network Community Detection",
    "abstract": "We present a study on portfolio investments in financial applications. We describe a general modeling and simulation framework and study the impact on the use of different metrics to measure the correlation among assets. In particular, besides the traditional Pearson's correlation, we employ the Detrended Cross-Correlation Analysis (DCCA) and Detrended Partial Cross-Correlation Analysis (DPCCA). Moreover, a novel portfolio allocation scheme is introduced that treats assets as a complex network and uses modularity to detect communities of correlated assets. Weights of the allocation are then distributed among different communities for the sake of diversification. Simulations compare this novel scheme against Critical Line Algorithm (CLA), Inverse Variance Portfolio (IVP), the Hierarchical Risk Parity (HRP). Synthetic times series are generated using the Gaussian model, Geometric Brownian motion, GARCH, ARFIMA and modified ARFIMA models. Results show that the proposed scheme outperforms state of the art approaches in many scenarios. We also validate simulation results via backtesting, whose results confirm the viability of the proposal. ",
    "url": "https://arxiv.org/abs/2203.11780",
    "authors": [
      "Stefano Ferretti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Performance (cs.PF)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.11790",
    "title": "Learning Program Semantics with Code Representations: An Empirical Study",
    "abstract": "Program semantics learning is the core and fundamental for various code intelligent tasks e.g., vulnerability detection, clone detection. A considerable amount of existing works propose diverse approaches to learn the program semantics for different tasks and these works have achieved state-of-the-art performance. However, currently, a comprehensive and systematic study on evaluating different program representation techniques across diverse tasks is still missed. From this starting point, in this paper, we conduct an empirical study to evaluate different program representation techniques. Specifically, we categorize current mainstream code representation techniques into four categories i.e., Feature-based, Sequence-based, Tree-based, and Graph-based program representation technique and evaluate its performance on three diverse and popular code intelligent tasks i.e., {Code Classification}, Vulnerability Detection, and Clone Detection on the public released benchmark. We further design three {research questions (RQs)} and conduct a comprehensive analysis to investigate the performance. By the extensive experimental results, we conclude that (1) The graph-based representation is superior to the other selected techniques across these tasks. (2) Compared with the node type information used in tree-based and graph-based representations, the node textual information is more critical to learning the program semantics. (3) Different tasks require the task-specific semantics to achieve their highest performance, however combining various program semantics from different dimensions such as control dependency, data dependency can still produce promising results. ",
    "url": "https://arxiv.org/abs/2203.11790",
    "authors": [
      "Jing Kai Siow",
      "Shangqing Liu",
      "Xiaofei Xie",
      "Guozhu Meng",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2203.11793",
    "title": "A Perspective on Neural Capacity Estimation: Viability and Reliability",
    "abstract": "Recently, several methods have been proposed for estimating the mutual information from sample data using deep neural networks and without the knowledge of closed-form distribution of the data. This class of estimators is referred to as neural mutual information estimators (NMIE). In this paper, we investigate the performance of different NMIE proposed in the literature when applied to the capacity estimation problem. In particular, we study the performance of mutual information neural estimator (MINE), smoothed mutual information lower-bound estimator (SMILE), and directed information neural estimator (DINE). For the NMIE above, capacity estimation relies on two deep neural networks (DNN): (i) one DNN generates samples from a distribution that is learned, and (ii) a DNN to estimate the MI between the channel input and the channel output. We benchmark these NMIE in three scenarios: (i) AWGN channel capacity estimation and (ii) channels with unknown capacity and continuous inputs i.e., optical intensity and peak-power constrained AWGN channel (iii) channels with unknown capacity and a discrete number of mass points i.e., Poisson channel. Additionally, we also (iv) consider the extension to the MAC capacity problem by considering the AWGN and optical MAC models. ",
    "url": "https://arxiv.org/abs/2203.11793",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.11797",
    "title": "A Novel Framework for Assessment of Learning-based Detectors in  Realistic Conditions with Application to Deepfake Detection",
    "abstract": "Deep convolutional neural networks have shown remarkable results on multiple detection tasks. Despite the significant progress, the performance of such detectors are often assessed in public benchmarks under non-realistic conditions. Specifically, impact of conventional distortions and processing operations such as compression, noise, and enhancement are not sufficiently studied. This paper proposes a rigorous framework to assess performance of learning-based detectors in more realistic situations. An illustrative example is shown under deepfake detection context. Inspired by the assessment results, a data augmentation strategy based on natural image degradation process is designed, which significantly improves the generalization ability of two deepfake detectors. ",
    "url": "https://arxiv.org/abs/2203.11797",
    "authors": [
      "Yuhang Lu",
      "Ruizhi Luo",
      "Touradj Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.11799",
    "title": "AP-BSN: Self-Supervised Denoising for Real-World Images via Asymmetric  PD and Blind-Spot Network",
    "abstract": "Blind-spot network (BSN) and its variants have made significant advances in self-supervised denoising. Nevertheless, they are still bound to synthetic noisy inputs due to less practical assumptions like pixel-wise independent noise. Hence, it is challenging to deal with spatially correlated real-world noise using self-supervised BSN. Recently, pixel-shuffle downsampling (PD) has been proposed to remove the spatial correlation of real-world noise. However, it is not trivial to integrate PD and BSN directly, which prevents the fully self-supervised denoising model on real-world images. We propose an Asymmetric PD (AP) to address this issue, which introduces different PD stride factors for training and inference. We systematically demonstrate that the proposed AP can resolve inherent trade-offs caused by specific PD stride factors and make BSN applicable to practical scenarios. To this end, we develop AP-BSN, a state-of-the-art self-supervised denoising method for real-world sRGB images. We further propose random-replacing refinement, which significantly improves the performance of our AP-BSN without any additional parameters. Extensive studies demonstrate that our method outperforms the other self-supervised and even unpaired denoising methods by a large margin, without using any additional knowledge, e.g., noise level, regarding the underlying unknown noise. ",
    "url": "https://arxiv.org/abs/2203.11799",
    "authors": [
      "Wooseok Lee",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.11804",
    "title": "Information-Theoretic Approaches to Differential Privacy",
    "abstract": "This tutorial studies relationships between differential privacy and various information-theoretic measures using several selective articles. In particular, we present how these relationships can provide new interpretations for the privacy guarantee in systems that deploy differential privacy in an information-theoretic framework. To this end, this work offers an extensive summary on the existing literature that makes use of information-theoretic measures and tools such as mutual information, min entropy, Kullback-Leibler divergence and rate-distortion function for quantifying differential privacy in various settings. ",
    "url": "https://arxiv.org/abs/2203.11804",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.11805",
    "title": "On Robust Classification using Contractive Hamiltonian Neural ODEs",
    "abstract": "Deep neural networks can be fragile and sensitive to small input perturbations that might cause a significant change in the output. In this paper, we employ contraction theory to improve the robustness of neural ODEs (NODEs). A dynamical system is contractive if all solutions with different initial conditions converge to each other asymptotically. As a consequence, perturbations in initial conditions become less and less relevant over time. Since in NODEs, the input data corresponds to the initial condition of dynamical systems, we show contractivity can mitigate the effect of input perturbations. More precisely, inspired by NODEs with Hamiltonian dynamics, we propose a class of contractive Hamiltonian NODEs (CH-NODEs). By properly tuning a scalar parameter, CH-NODEs ensure contractivity by design and can be trained using standard backpropagation and gradient descent algorithms. Moreover, CH-NODEs enjoy built-in guarantees of non-exploding gradients, which ensures a well-posed training process. Finally, we demonstrate the robustness of CH-NODEs on the MNIST image classification problem with noisy test datasets. ",
    "url": "https://arxiv.org/abs/2203.11805",
    "authors": [
      "Muhammad Zakwan",
      "Liang Xu",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11807",
    "title": "A New Approach to Improve Learning-based Deepfake Detection in Realistic  Conditions",
    "abstract": "Deep convolutional neural networks have achieved exceptional results on multiple detection and recognition tasks. However, the performance of such detectors are often evaluated in public benchmarks under constrained and non-realistic situations. The impact of conventional distortions and processing operations found in imaging workflows such as compression, noise, and enhancement are not sufficiently studied. Currently, only a few researches have been done to improve the detector robustness to unseen perturbations. This paper proposes a more effective data augmentation scheme based on real-world image degradation process. This novel technique is deployed for deepfake detection tasks and has been evaluated by a more realistic assessment framework. Extensive experiments show that the proposed data augmentation scheme improves generalization ability to unpredictable data distortions and unseen datasets. ",
    "url": "https://arxiv.org/abs/2203.11807",
    "authors": [
      "Yuhang Lu",
      "Touradj Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.11812",
    "title": "Neural System Level Synthesis: Learning over All Stabilizing Policies  for Nonlinear Systems",
    "abstract": "We address the problem of designing stabilizing control policies for nonlinear systems in discrete-time, while minimizing an arbitrary cost function. When the system is linear and the cost is convex, the System Level Synthesis (SLS) approach offers an exact solution based on convex programming. Beyond this case, a globally optimal solution cannot be found in a tractable way, in general. In this paper, we develop a parametrization of all and only the control policies stabilizing a given time-varying nonlinear system in terms of the combined effect of 1) a strongly stabilizing base controller and 2) a stable SLS operator to be freely designed. Based on this result, we propose a Neural SLS (Neur-SLS) approach guaranteeing closed-loop stability during and after parameter optimization, without requiring any constraints to be satisfied. We exploit recent Deep Neural Network (DNN) models based on Recurrent Equilibrium Networks (RENs) to learn over a rich class of nonlinear stable operators, and demonstrate the effectiveness of the proposed approach in numerical examples. ",
    "url": "https://arxiv.org/abs/2203.11812",
    "authors": [
      "Luca Furieri",
      "Clara Luc\u00eda Galimberti",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11815",
    "title": "Clustering units in neural networks: upstream vs downstream information",
    "abstract": "It has been hypothesized that some form of \"modular\" structure in artificial neural networks should be useful for learning, compositionality, and generalization. However, defining and quantifying modularity remains an open problem. We cast the problem of detecting functional modules into the problem of detecting clusters of similar-functioning units. This begs the question of what makes two units functionally similar. For this, we consider two broad families of methods: those that define similarity based on how units respond to structured variations in inputs (\"upstream\"), and those based on how variations in hidden unit activations affect outputs (\"downstream\"). We conduct an empirical study quantifying modularity of hidden layer representations of simple feedforward, fully connected networks, across a range of hyperparameters. For each model, we quantify pairwise associations between hidden units in each layer using a variety of both upstream and downstream measures, then cluster them by maximizing their \"modularity score\" using established tools from network science. We find two surprising results: first, dropout dramatically increased modularity, while other forms of weight regularization had more modest effects. Second, although we observe that there is usually good agreement about clusters within both upstream methods and downstream methods, there is little agreement about the cluster assignments across these two families of methods. This has important implications for representation-learning, as it suggests that finding modular representations that reflect structure in inputs (e.g. disentanglement) may be a distinct goal from learning modular representations that reflect structure in outputs (e.g. compositionality). ",
    "url": "https://arxiv.org/abs/2203.11815",
    "authors": [
      "Richard D. Lange",
      "David S. Rolnick",
      "Konrad P. Kording"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11817",
    "title": "Modeling Tie Duration in ERGM-Based Dynamic Network Models",
    "abstract": "Krivitsky and Handcock (2014) proposed a Separable Temporal ERGM (STERGM) framework for modeling social networks, which facilitates separable modeling of the tie duration distributions and the structural dynamics of tie formation. In this note, we explore the hazard structures achievable in this framework, with first- and higher-order Markov assumptions, and propose ways to model a variety of duration distributions in this framework. ",
    "url": "https://arxiv.org/abs/2203.11817",
    "authors": [
      "Pavel N. Krivitsky"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.11828",
    "title": "Explainable Landscape Analysis in Automated Algorithm Performance  Prediction",
    "abstract": "Predicting the performance of an optimization algorithm on a new problem instance is crucial in order to select the most appropriate algorithm for solving that problem instance. For this purpose, recent studies learn a supervised machine learning (ML) model using a set of problem landscape features linked to the performance achieved by the optimization algorithm. However, these models are black-box with the only goal of achieving good predictive performance, without providing explanations which landscape features contribute the most to the prediction of the performance achieved by the optimization algorithm. In this study, we investigate the expressiveness of problem landscape features utilized by different supervised ML models in automated algorithm performance prediction. The experimental results point out that the selection of the supervised ML method is crucial, since different supervised ML regression models utilize the problem landscape features differently and there is no common pattern with regard to which landscape features are the most informative. ",
    "url": "https://arxiv.org/abs/2203.11828",
    "authors": [
      "Risto Trajanov",
      "Stefan Dimeski",
      "Martin Popovski",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.11841",
    "title": "SU-NLP at SemEval-2022 Task 11: Complex Named Entity Recognition with  Entity Linking",
    "abstract": "This paper describes the system proposed by Sabanc{\\i} University Natural Language Processing Group in the SemEval-2022 MultiCoNER task. We developed an unsupervised entity linking pipeline that detects potential entity mentions with the help of Wikipedia and also uses the corresponding Wikipedia context to help the classifier in finding the named entity type of that mention. Our results showed that our pipeline improved performance significantly, especially for complex entities in low-context settings. ",
    "url": "https://arxiv.org/abs/2203.11841",
    "authors": [
      "Buse \u00c7ar\u0131k",
      "Fatih Beyhan",
      "Reyyan Yeniterzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11849",
    "title": "A Girl Has A Name, And It's ... Adversarial Authorship Attribution for  Deobfuscation",
    "abstract": "Recent advances in natural language processing have enabled powerful privacy-invasive authorship attribution. To counter authorship attribution, researchers have proposed a variety of rule-based and learning-based text obfuscation approaches. However, existing authorship obfuscation approaches do not consider the adversarial threat model. Specifically, they are not evaluated against adversarially trained authorship attributors that are aware of potential obfuscation. To fill this gap, we investigate the problem of adversarial authorship attribution for deobfuscation. We show that adversarially trained authorship attributors are able to degrade the effectiveness of existing obfuscators from 20-30% to 5-10%. We also evaluate the effectiveness of adversarial training when the attributor makes incorrect assumptions about whether and which obfuscator was used. While there is a a clear degradation in attribution accuracy, it is noteworthy that this degradation is still at or above the attribution accuracy of the attributor that is not adversarially trained at all. Our results underline the need for stronger obfuscation approaches that are resistant to deobfuscation ",
    "url": "https://arxiv.org/abs/2203.11849",
    "authors": [
      "Wanyue Zhai",
      "Jonathan Rusert",
      "Zubair Shafiq",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11852",
    "title": "A Survey on Techniques for Identifying and Resolving Representation Bias  in Data",
    "abstract": "The grand goal of data-driven decision-making is to help humans make decisions, not only easily and at scale but also wisely, accurately, and just. However, data-driven algorithms are only as good as the data they work with, while data sets, especially social data, often miss representing minorities. Representation Bias in data can happen due to various reasons ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. One cannot expect AI-based societal solutions to have equitable outcomes without addressing the representation bias. This paper surveys the existing literature on representation bias in the data. It presents a taxonomy to categorize the studied techniques based on multiple design dimensions and provide a side-by-side comparison of their properties. There is still a long way to fully address representation bias issues in data. The authors hope that this survey motivates researchers to approach these challenges in the future by observing existing work within their respective domains. ",
    "url": "https://arxiv.org/abs/2203.11852",
    "authors": [
      "Nima Shahbazi",
      "Yin Lin",
      "Abolfazl Asudeh",
      "H. V. Jagadish"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11857",
    "title": "Optimal Slicing of Virtualised Passive Optical Networks to Support Dense  Deployment of Cloud-RAN and Multi-Access Edge Computing",
    "abstract": "The commercialization of Cloud-RAN, and Open-RAN in particular, is a key factor to enable 5G cell densification, by providing lower cost and more agile deployment of small cells. In addition, the adoption of MEC is important to support ultra-low latency and high reliability required by mission-critical applications, which constitute a milestone of the 5G and beyond vision of a fully connected society. However, connecting antenna site, C-RAN processing and MEC at low cost is challenging, as it requires high-capacity, low latency connectivity delivered through a highly inter-connected topology. While PON is being considered as a solution for providing low-cost connectivity to C-RAN, they only allow data transmission from the endpoints (for example hosting RU at the antenna site) towards a central node (e.g., the central office, hosting computing equipment), thus cannot support traffic from RU towards MEC end nodes that could host DU and possibly CU and network core. This led to research into the evolution of PON architectures with the ability to provide direct communications between endpoints, thus supporting mesh traffic patterns required by MEC installations. In this context, virtualization plays a key role in enabling efficient resource allocation (i.e. optical transmission capacity) to endpoints, according to their communication patterns. In this article, we address the challenge of dynamic allocation of virtual PON slices over mesh-PON architectures to support C-RAN and MEC nodes. We make use of a mixed analytical-iterative model to compute optimal virtual PON slice allocation, with the objective of minimizing the use of MEC node resources, while meeting a target latency threshold (100 $\\mu s$ in our scenario). Our method is particularly effective in reducing computation time, enabling virtual PON slice allocation in timescales compatible with real-time or near real-time operations. ",
    "url": "https://arxiv.org/abs/2203.11857",
    "authors": [
      "Sandip Das",
      "Frank Slyne",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.11878",
    "title": "Under the Hood of Transformer Networks for Trajectory Forecasting",
    "abstract": "Transformer Networks have established themselves as the de-facto state-of-the-art for trajectory forecasting but there is currently no systematic study on their capability to model the motion patterns of people, without interactions with other individuals nor the social context. This paper proposes the first in-depth study of Transformer Networks (TF) and Bidirectional Transformers (BERT) for the forecasting of the individual motion of people, without bells and whistles. We conduct an exhaustive evaluation of input/output representations, problem formulations and sequence modeling, including a novel analysis of their capability to predict multi-modal futures. Out of comparative evaluation on the ETH+UCY benchmark, both TF and BERT are top performers in predicting individual motions, definitely overcoming RNNs and LSTMs. Furthermore, they remain within a narrow margin wrt more complex techniques, which include both social interactions and scene contexts. Source code will be released for all conducted experiments. ",
    "url": "https://arxiv.org/abs/2203.11878",
    "authors": [
      "Luca Franco",
      "Leonardo Placidi",
      "Francesco Giuliari",
      "Irtiza Hasan",
      "Marco Cristani",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11899",
    "title": "Transformer based ensemble for emotion detection",
    "abstract": "Detecting emotions in languages is important to accomplish a complete interaction between humans and machines. This paper describes our contribution to the WASSA 2022 shared task which handles this crucial task of emotion detection. We have to identify the following emotions: sadness, surprise, neutral, anger, fear, disgust, joy based on a given essay text. We are using an ensemble of ELECTRA and BERT models to tackle this problem achieving an F1 score of 62.76%. Our codebase (https://bit.ly/WASSA_shared_task) and our WandB project (https://wandb.ai/acl_wassa_pictxmanipal/acl_wassa) is available. ",
    "url": "https://arxiv.org/abs/2203.11899",
    "authors": [
      "Aditya Kane",
      "Shantanu Patankar",
      "Sahil Khose",
      "Neeraja Kirtane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.11910",
    "title": "Improving Neural Predictivity in the Visual Cortex with Gated Recurrent  Connections",
    "abstract": "Computational models of vision have traditionally been developed in a bottom-up fashion, by hierarchically composing a series of straightforward operations - i.e. convolution and pooling - with the aim of emulating simple and complex cells in the visual cortex, resulting in the introduction of deep convolutional neural networks (CNNs). Nevertheless, data obtained with recent neuronal recording techniques support that the nature of the computations carried out in the ventral visual stream is not completely captured by current deep CNN models. To fill the gap between the ventral visual stream and deep models, several benchmarks have been designed and organized into the Brain-Score platform, granting a way to perform multi-layer (V1, V2, V4, IT) and behavioral comparisons between the two counterparts. In our work, we aim to shift the focus on architectures that take into account lateral recurrent connections, a ubiquitous feature of the ventral visual stream, to devise adaptive receptive fields. Through recurrent connections, the input s long-range spatial dependencies can be captured in a local multi-step fashion and, as introduced with Gated Recurrent CNNs (GRCNN), the unbounded expansion of the neuron s receptive fields can be modulated through the use of gates. In order to increase the robustness of our approach and the biological fidelity of the activations, we employ specific data augmentation techniques in line with several of the scoring benchmarks. Enforcing some form of invariance, through heuristics, was found to be beneficial for better neural predictivity. ",
    "url": "https://arxiv.org/abs/2203.11910",
    "authors": [
      "Simone Azeglio",
      "Simone Poetto",
      "Luca Savant Aira",
      "Marco Nurisso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2203.11926",
    "title": "Focal Modulation Networks",
    "abstract": "In this work, we propose focal modulation network (FocalNet in short), where self-attention (SA) is completely replaced by a focal modulation module that is more effective and efficient for modeling token interactions. Focal modulation comprises three components: $(i)$ hierarchical contextualization, implemented using a stack of depth-wise convolutional layers, to encode visual contexts from short to long ranges at different granularity levels, $(ii)$ gated aggregation to selectively aggregate context features for each visual token (query) based on its content, and $(iii)$ modulation or element-wise affine transformation to fuse the aggregated features into the query vector. Extensive experiments show that FocalNets outperform the state-of-the-art SA counterparts (e.g., Swin Transformers) with similar time and memory cost on the tasks of image classification, object detection, and semantic segmentation. Specifically, our FocalNets with tiny and base sizes achieve 82.3% and 83.9% top-1 accuracy on ImageNet-1K. After pretrained on ImageNet-22K, it attains 86.5% and 87.3% top-1 accuracy when finetuned with resolution 224$\\times$224 and 384$\\times$384, respectively. FocalNets exhibit remarkable superiority when transferred to downstream tasks. For object detection with Mask R-CNN, our FocalNet base trained with 1$\\times$ already surpasses Swin trained with 3$\\times$ schedule (49.0 v.s. 48.5). For semantic segmentation with UperNet, FocalNet base evaluated at single-scale outperforms Swin evaluated at multi-scale (50.5 v.s. 49.7). These results render focal modulation a favorable alternative to SA for effective and efficient visual modeling in real-world applications. Code is available at https://github.com/microsoft/FocalNet. ",
    "url": "https://arxiv.org/abs/2203.11926",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11933",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models  with Adversarial Learning",
    "abstract": "Vision-language models can encode societal biases and stereotypes, but there are challenges to measuring and mitigating these harms. Prior proposed bias measurements lack robustness and feature degradation occurs when mitigating bias without access to pretraining data. We address both of these challenges in this paper: First, we evaluate different bias measures and propose the use of retrieval metrics to image-text representations via a bias measuring framework. Second, we investigate debiasing methods and show that optimizing for adversarial loss via learnable token embeddings minimizes various bias measures without substantially degrading feature representations. ",
    "url": "https://arxiv.org/abs/2203.11933",
    "authors": [
      "Hugo Berg",
      "Siobhan Mackenzie Hall",
      "Yash Bhalgat",
      "Wonsuk Yang",
      "Hannah Rose Kirk",
      "Aleksandar Shtedritski",
      "Max Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.11937",
    "title": "4D-OR: Semantic Scene Graphs for OR Domain Modeling",
    "abstract": "Surgical procedures are conducted in highly complex operating rooms (OR), comprising different actors, devices, and interactions. To date, only medically trained human experts are capable of understanding all the links and interactions in such a demanding environment. This paper aims to bring the community one step closer to automated, holistic and semantic understanding and modeling of OR domain. Towards this goal, for the first time, we propose using semantic scene graphs (SSG) to describe and summarize the surgical scene. The nodes of the scene graphs represent different actors and objects in the room, such as medical staff, patients, and medical equipment, whereas edges are the relationships between them. To validate the possibilities of the proposed representation, we create the first publicly available 4D surgical SSG dataset, 4D-OR, containing ten simulated total knee replacement surgeries recorded with six RGB-D sensors in a realistic OR simulation center. 4D-OR includes 6734 frames and is richly annotated with SSGs, human and object poses, and clinical roles. We propose an end-to-end neural network-based SSG generation pipeline, with a rate of success of 0.75 macro F1, indeed being able to infer semantic reasoning in the OR. We further demonstrate the representation power of our scene graphs by using it for the problem of clinical role prediction, where we achieve 0.85 macro F1. The code and dataset will be made available upon acceptance. ",
    "url": "https://arxiv.org/abs/2203.11937",
    "authors": [
      "Ege \u00d6zsoy",
      "Evin P\u0131nar \u00d6rnek",
      "Ulrich Eck",
      "Tobias Czempiel",
      "Federico Tombari",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11322",
    "title": "Probabilistically robust stabilizing allocations in uncertain  cooperative games",
    "abstract": "In this paper we consider multi-agent cooperative games with uncertain value functions for which we establish distribution-free guarantees on the probability of allocation stability, i.e., agents do not have incentives to defect the grand coalition to subcoalitions for unseen realizations of the uncertain parameter. In case the set of stable allocations, the so called core of the game, is empty, we propose a randomized relaxation of the core. We then show that those allocations that belong to this relaxed set can be accompanied by stability guarantees in a probably approximately correct fashion. Finally, numerical experiments corroborate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2203.11322",
    "authors": [
      "George Pantazis",
      "Filippo Fabiani",
      "Filiberto Fele",
      "Kostas Margellos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11327",
    "title": "Online Joint Optimal Control-Estimation Architecture in Distribution  Networks",
    "abstract": "In this paper, we propose an optimal control-estimation architecture for distribution networks, which jointly solves the optimal power flow (OPF) problem and static state estimation (SE) problem through an online gradient-based feedback algorithm. The main objective is to enable a fast and timely interaction between the optimal controllers and state estimators with limited sensor measurements. First, convergence and optimality of the proposed algorithm are analytically established. Then, the proposed gradient-based algorithm is modified by introducing statistical information of the inherent estimation and linearization errors for an improved and robust performance of the online control decisions. Overall, the proposed method eliminates the traditional separation of control and operation, where control and estimation usually operate at distinct layers and different time-scales. Hence, it enables a computationally affordable, efficient and robust online operational framework for distribution networks under time-varying settings. ",
    "url": "https://arxiv.org/abs/2203.11327",
    "authors": [
      "Yi Guo",
      "Xinyang Zhou",
      "Changhong Zhao",
      "Lijun Chen",
      "Gabriela Hug",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11404",
    "title": "Enhanced Preamble Based MAC Mechanism for IIoT-oriented PLC Network",
    "abstract": "In this paper, we propose an enhanced preamble based media access control mechanism (E-PMAC), which can be applied in power line communication (PLC) network for Industrial Internet of Things (IIoT). We introduce detailed technologies used in E-PMAC, including delay calibration mechanism, preamble design, and slot allocation algorithm. With these technologies, E-PMAC is more robust than existing preamble based MAC mechanism (P-MAC). Besides, we analyze the disadvantage of P-MAC in multi-layer networking and design the networking process of E-PMAC to accelerate networking process. We analyze the complexity of networking process in P-MAC and E-PMAC and prove that E-PMAC has lower complexity than P-MAC. Finally, we simulate the single-layer networking and multi-layer networking of E-PMAC, P-MAC, and existing PLC protocol, i.e. , IEEE1901.1. The simulation results indicate that E-PMAC spends much less time in networking than IEEE1901.1 and P-MAC. Finally, with our work, a PLC network based on E-PMAC mechanism can be realized. ",
    "url": "https://arxiv.org/abs/2203.11404",
    "authors": [
      "Kai Song",
      "Biqian Feng",
      "Yongpeng Wu",
      "Wenjun Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.11438",
    "title": "An Efficient Data-Driven Multiscale Stochastic Reduced Order Modeling  Framework for Complex Systems",
    "abstract": "Suitable reduced order models (ROMs) are computationally efficient tools in characterizing key dynamical and statistical features of nature. In this paper, a systematic multiscale stochastic ROM framework is developed for complex systems with strong chaotic or turbulent behavior. The new ROMs are fundamentally different from the traditional Galerkin ROM (G-ROM) or those deterministic ROMs that aim at minimizing the path-wise errors and applying mainly to laminar systems. Here, the new ROM focuses on recovering the large-scale dynamics to the maximum extent while it also exploits cheap but effective conditional linear functions as the closure terms to capture the statistical features of the medium-scale variables and its feedback to the large scales. In addition, physics constraints are incorporated into the new ROM. One unique feature of the resulting ROM is that it facilitates an efficient and accurate scheme for nonlinear data assimilation, the solution of which is provided by closed analytic formulae. Such an analytic solvable data assimilation solution significantly accelerates the computational efficiency and allows the new ROM to avoid many potential numerical and sampling issues in recovering the unobserved states from partial observations. The overall model calibration is efficient and systematic via explicit mathematical formulae. The new ROM framework is applied to complex nonlinear systems, in which the intrinsic turbulent behavior is either triggered by external random forcing or deterministic nonlinearity. It is shown that the new ROM significantly outperforms the G-ROM in both scenarios in terms of reproducing the dynamical and statistical features as well as recovering unobserved states via the associated efficient data assimilation scheme. ",
    "url": "https://arxiv.org/abs/2203.11438",
    "authors": [
      "Changhong Mou",
      "Nan Chen",
      "Traian Iliescu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.11528",
    "title": "Out-of-distribution Generalization with Causal Invariant Transformations",
    "abstract": "In real-world applications, it is important and desirable to learn a model that performs well on out-of-distribution (OOD) data. Recently, causality has become a powerful tool to tackle the OOD generalization problem, with the idea resting on the causal mechanism that is invariant across domains of interest. To leverage the generally unknown causal mechanism, existing works assume a linear form of causal feature or require sufficiently many and diverse training domains, which are usually restrictive in practice. In this work, we obviate these assumptions and tackle the OOD problem without explicitly recovering the causal feature. Our approach is based on transformations that modify the non-causal feature but leave the causal part unchanged, which can be either obtained from prior knowledge or learned from the training data in the multi-domain scenario. Under the setting of invariant causal mechanism, we theoretically show that if all such transformations are available, then we can learn a minimax optimal model across the domains using only single domain data. Noticing that knowing a complete set of these causal invariant transformations may be impractical, we further show that it suffices to know only a subset of these transformations. Based on the theoretical findings, a regularized training procedure is proposed to improve the OOD generalization capability. Extensive experimental results on both synthetic and real datasets verify the effectiveness of the proposed algorithm, even with only a few causal invariant transformations. ",
    "url": "https://arxiv.org/abs/2203.11528",
    "authors": [
      "Ruoyu Wang",
      "Mingyang Yi",
      "Zhitang Chen",
      "Shengyu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11687",
    "title": "BEFANA: A Tool for Biodiversity-Ecosystem Functioning Assessment by  Network Analysis",
    "abstract": "BEFANA is a free and open-source software tool for ecological network analysis and visualisation. It is adapted to ecologists' needs and allows them to study the topology and dynamics of ecological networks as well as apply selected machine learning algorithms. BEFANA is implemented in Python, and structured as an ordered collection of interactive computational notebooks. It relies on widely used open-source libraries, and aims to achieve simplicity, interactivity, and extensibility. BEFANA provides methods and implementations for data loading and preprocessing, network analysis and interactive visualisation, modelling with experimental data, and predictive modelling with machine learning. We showcase BEFANA through a concrete example of a detrital soil food web of agricultural grasslands, and demonstrate all of its main components and functionalities. ",
    "url": "https://arxiv.org/abs/2203.11687",
    "authors": [
      "Martin Marzidov\u0161ek",
      "Vid Podpe\u010dan",
      "Erminia Conti",
      "Marko Debeljak",
      "Christian Mulder"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11722",
    "title": "Convolutional Neural Network to Restore Low-Dose Digital Breast  Tomosynthesis Projections in a Variance Stabilization Domain",
    "abstract": "Digital breast tomosynthesis (DBT) exams should utilize the lowest possible radiation dose while maintaining sufficiently good image quality for accurate medical diagnosis. In this work, we propose a convolution neural network (CNN) to restore low-dose (LD) DBT projections to achieve an image quality equivalent to a standard full-dose (FD) acquisition. The proposed network architecture benefits from priors in terms of layers that were inspired by traditional model-based (MB) restoration methods, considering a model-based deep learning approach, where the network is trained to operate in the variance stabilization transformation (VST) domain. To accurately control the network operation point, in terms of noise and blur of the restored image, we propose a loss function that minimizes the bias and matches residual noise between the input and the output. The training dataset was composed of clinical data acquired at the standard FD and low-dose pairs obtained by the injection of quantum noise. The network was tested using real DBT projections acquired with a physical anthropomorphic breast phantom. The proposed network achieved superior results in terms of the mean normalized squared error (MNSE), training time and noise spatial correlation compared with networks trained with traditional data-driven methods. The proposed approach can be extended for other medical imaging application that requires LD acquisitions. ",
    "url": "https://arxiv.org/abs/2203.11722",
    "authors": [
      "Rodrigo de Barros Vimieiro",
      "Chuang Niu",
      "Hongming Shan",
      "Lucas Rodrigues Borges",
      "Ge Wang",
      "Marcelo Andrade da Costa Vieira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11725",
    "title": "Unsupervised Anomaly Detection in Medical Images with a Memory-augmented  Multi-level Cross-attentional Masked Autoencoder",
    "abstract": "Unsupervised anomaly detection (UAD) aims to find anomalous images by optimising a detector using a training set that contains only normal images. UAD approaches can be based on reconstruction methods, self-supervised approaches, and Imagenet pre-trained models. Reconstruction methods, which detect anomalies from image reconstruction errors, are advantageous because they do not rely on the design of problem-specific pretext tasks needed by self-supervised approaches, and on the unreliable translation of models pre-trained from non-medical datasets. However, reconstruction methods may fail because they can have low reconstruction errors even for anomalous images. In this paper, we introduce a new reconstruction-based UAD approach that addresses this low-reconstruction error issue for anomalous images. Our UAD approach, the memory-augmented multi-level cross-attentional masked autoencoder (MemMC-MAE), is a transformer-based approach, consisting of a novel memory-augmented self-attention operator for the encoder and a new multi-level cross-attention operator for the decoder. MemMC-MAE masks large parts of the input image during its reconstruction, reducing the risk that it will produce low reconstruction errors because anomalies are likely to be masked and cannot be reconstructed. However, when the anomaly is not masked, then the normal patterns stored in the encoder's memory combined with the decoder's multi-level cross-attention will constrain the accurate reconstruction of the anomaly. We show that our method achieves SOTA anomaly detection and localisation on colonoscopy and Covid-19 Chest X-ray datasets. ",
    "url": "https://arxiv.org/abs/2203.11725",
    "authors": [
      "Yu Tian",
      "Guansong Pang",
      "Yuyuan Liu",
      "Chong Wang",
      "Yuanhong Chen",
      "Fengbei Liu",
      "Rajvinder Singh",
      "Johan W Verjans",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11727",
    "title": "Gated Recurrent Unit based Autoencoder for Optical Link Fault Diagnosis  in Passive Optical Networks",
    "abstract": "We propose a deep learning approach based on an autoencoder for identifying and localizing fiber faults in passive optical networks. The experimental results show that the proposed method detects faults with 97% accuracy, pinpoints them with an RMSE of 0.18 m and outperforms conventional techniques. ",
    "url": "https://arxiv.org/abs/2203.11727",
    "authors": [
      "Khouloud Abdelli",
      "Florian Azendorf",
      "Helmut Griesser",
      "Carsten Tropschug",
      "Stephan Pachnicke"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11784",
    "title": "Controlling the average degree in random power-law networks",
    "abstract": "We describe a procedure that allows continuously tuning the average degree $\\langle k \\rangle$ of uncorrelated networks with power-law degree distribution $p(k)$. Inn order to do this, we modify the low-$k$ region of $p(k)$, while preserving the large-$k$ tail up to a cutoff. Then, we use the modified $p(k)$ to obtain the degree sequence required to construct networks through the configuration model. We analyze the resulting nearest-neighbor degree and local clustering to verify the absence of $k$-dependencies. Finally, a further modification is introduced to eliminate the sample fluctuations in the average degree. ",
    "url": "https://arxiv.org/abs/2203.11784",
    "authors": [
      "Allan Vieira",
      "Judson Moura",
      "Celia Anteneodo"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.11837",
    "title": "Gain and phase type multipliers for structured feedback robustness",
    "abstract": "It is known that the stability of a feedback interconnection of two linear time-invariant systems implies that the graphs of the open-loop systems are quadratically separated. This separation is defined by an object known as the multiplier. The theory of integral quadratic constraints shows that the converse also holds under certain conditions. This paper establishes that if the feedback is robustly stable against certain structured uncertainty, then there always exists a multiplier that takes a corresponding form. In particular, if the feedback is robustly stable to certain gain-type uncertainty, then there exists a corresponding multiplier that is of phase-type, i.e., its diagonal blocks are zeros. These results build on the notion of phases of matrices and systems, which was recently introduced in the field of control. Similarly, if the feedback is robustly stable to certain phase-type uncertainty, then there exists a gain-type multiplier, i.e., its off-diagonal blocks are zeros. The results are meaningfully instructive in the search for a valid multiplier for establishing robust closed-loop stability, and cover the well-known small-gain and the recent small-phase theorems. ",
    "url": "https://arxiv.org/abs/2203.11837",
    "authors": [
      "Axel Ringh",
      "Xin Mao",
      "Wei Chen",
      "Li Qiu",
      "Sei Zhen Khong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.11864",
    "title": "On the (Non-)Robustness of Two-Layer Neural Networks in Different  Learning Regimes",
    "abstract": "Neural networks are known to be highly sensitive to adversarial examples. These may arise due to different factors, such as random initialization, or spurious correlations in the learning problem. To better understand these factors, we provide a precise study of robustness and generalization in different scenarios, from initialization to the end of training in different regimes, as well as intermediate scenarios, where initialization still plays a role due to \"lazy\" training. We consider over-parameterized networks in high dimensions with quadratic targets and infinite samples. Our analysis allows us to identify new trade-offs between generalization and robustness, whereby robustness can only get worse when generalization improves, and vice versa. We also show how linearized lazy training regimes can worsen robustness, due to improperly scaled random initialization. Our theoretical results are illustrated with numerical experiments. ",
    "url": "https://arxiv.org/abs/2203.11864",
    "authors": [
      "Elvis Dohmatob",
      "Alberto Bietti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.11872",
    "title": "Performance of long short-term memory artificial neural networks in  nowcasting during the COVID-19 crisis",
    "abstract": "The COVID-19 pandemic has demonstrated the increasing need of policymakers for timely estimates of macroeconomic variables. A prior UNCTAD research paper examined the suitability of long short-term memory artificial neural networks (LSTM) for performing economic nowcasting of this nature. Here, the LSTM's performance during the COVID-19 pandemic is compared and contrasted with that of the dynamic factor model (DFM), a commonly used methodology in the field. Three separate variables, global merchandise export values and volumes and global services exports, were nowcast with actual data vintages and performance evaluated for the second, third, and fourth quarters of 2020 and the first and second quarters of 2021. In terms of both mean absolute error and root mean square error, the LSTM obtained better performance in two-thirds of variable/quarter combinations, as well as displayed more gradual forecast evolutions with more consistent narratives and smaller revisions. Additionally, a methodology to introduce interpretability to LSTMs is introduced and made available in the accompanying nowcast_lstm Python library, which is now also available in R, MATLAB, and Julia. ",
    "url": "https://arxiv.org/abs/2203.11872",
    "authors": [
      "Daniel Hopp"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:1709.00944",
    "title": "Audio-Visual Speech Enhancement using Multimodal Deep Convolutional  Neural Network",
    "abstract": " Comments: This paper is the same as arXiv:1703.10893v2. Apologies for the inconvenience ",
    "url": "https://arxiv.org/abs/1709.00944",
    "authors": [
      "Jen-Cheng Hou",
      "Syu-Siang Wang",
      "Ying-Hui Lai",
      "Yu Tsao",
      "Hsiu-Wen Chang",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2004.04402",
    "title": "Reliable Time Prediction in the Markov Stochastic Block Model",
    "abstract": " Title: Reliable Time Prediction in the Markov Stochastic Block Model ",
    "url": "https://arxiv.org/abs/2004.04402",
    "authors": [
      "Quentin Duchemin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2004.05909",
    "title": "kDecay: Just adding k-decay items on Learning-Rate Schedule to improve  Neural Networks",
    "abstract": " Title: kDecay: Just adding k-decay items on Learning-Rate Schedule to improve  Neural Networks ",
    "url": "https://arxiv.org/abs/2004.05909",
    "authors": [
      "Tao Zhang",
      "Wei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.04583",
    "title": "Vertex removal in biclique graphs",
    "abstract": " Title: Vertex removal in biclique graphs ",
    "url": "https://arxiv.org/abs/2006.04583",
    "authors": [
      "Leandro Montero"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2007.04793",
    "title": "Statistical Shape Analysis of Brain Arterial Networks (BAN)",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2003.00287 ",
    "url": "https://arxiv.org/abs/2007.04793",
    "authors": [
      "Xiaoyang Guo",
      "Aditi Basu Bal",
      "Tom Needham",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2009.05208",
    "title": "Maximizing Convergence Time in Network Averaging Dynamics Subject to  Edge Removal",
    "abstract": " Title: Maximizing Convergence Time in Network Averaging Dynamics Subject to  Edge Removal ",
    "url": "https://arxiv.org/abs/2009.05208",
    "authors": [
      "S. Rasoul Etesami"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2010.10805",
    "title": "SeqTrans: Automatic Vulnerability Fix via Sequence to Sequence Learning",
    "abstract": " Comments: 22 pages, 20 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2010.10805",
    "authors": [
      "Jianlei Chi",
      "Yu Qu",
      "Ting Liu",
      "Qinghua Zheng",
      "Heng Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2012.04886",
    "title": "DS-Net: Dynamic Spatiotemporal Network for Video Salient Object  Detection",
    "abstract": " Comments: The article has made some format changes ",
    "url": "https://arxiv.org/abs/2012.04886",
    "authors": [
      "Jing Liu",
      "Jiaxiang Wang",
      "Weikang Wang",
      "Yuting Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.03824",
    "title": "Neural Termination Analysis",
    "abstract": " Title: Neural Termination Analysis ",
    "url": "https://arxiv.org/abs/2102.03824",
    "authors": [
      "Mirco Giacobbe",
      "Daniel Kroening",
      "Julian Parsert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2102.11923",
    "title": "KAM Theory Meets Statistical Learning Theory: Hamiltonian Neural  Networks with Non-Zero Training Loss",
    "abstract": " Comments: Accepted to the thirty-sixth AAAI conference on artificial intelligence (AAAI-22) as an oral presentation ",
    "url": "https://arxiv.org/abs/2102.11923",
    "authors": [
      "Yuhan Chen",
      "Takashi Matsubara",
      "Takaharu Yaguchi"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2103.10671",
    "title": "Wisecr: Secure Simultaneous Code Disseminationto Many Batteryless  Computational RFID Devices",
    "abstract": " Comments: 19 main pages, 6 Appendix. Under review at IEEE TDSC ",
    "url": "https://arxiv.org/abs/2103.10671",
    "authors": [
      "Yang Su",
      "Michael Chesser",
      "Yansong Gao",
      "Alanson P. Sample",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2103.13138",
    "title": "SCHeMa: Scheduling Scientific Containers on a Cluster of Heterogeneous  Machines",
    "abstract": " Title: SCHeMa: Scheduling Scientific Containers on a Cluster of Heterogeneous  Machines ",
    "url": "https://arxiv.org/abs/2103.13138",
    "authors": [
      "Thanasis Vergoulis",
      "Konstantinos Zagganas",
      "Loukas Kavouras",
      "Martin Reczko",
      "Stelios Sartzetakis",
      "Theodore Dalamagas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2104.06951",
    "title": "Domain Adaptation and Multi-Domain Adaptation for Neural Machine  Translation: A Survey",
    "abstract": " Comments: 43 pages + references ",
    "url": "https://arxiv.org/abs/2104.06951",
    "authors": [
      "Danielle Saunders"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2104.13450",
    "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "abstract": " Comments: Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2104.13450",
    "authors": [
      "Innfarn Yoo",
      "Huiwen Chang",
      "Xiyang Luo",
      "Ondrej Stava",
      "Ce Liu",
      "Peyman Milanfar",
      "Feng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2105.05557",
    "title": "Supporting Land Reuse of Former Open Pit Mining Sites using Text  Classification and Active Learning",
    "abstract": " Title: Supporting Land Reuse of Former Open Pit Mining Sites using Text  Classification and Active Learning ",
    "url": "https://arxiv.org/abs/2105.05557",
    "authors": [
      "Christopher Schr\u00f6der",
      "Kim B\u00fcrgl",
      "Yves Annanias",
      "Andreas Niekler",
      "Lydia M\u00fcller",
      "Daniel Wiegreffe",
      "Christian Bender",
      "Christoph Mengs",
      "Gerik Scheuermann",
      "Gerhard Heyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.11111",
    "title": "Oriented RepPoints for Aerial Object Detection",
    "abstract": " Comments: 10 pages, 4 figures, Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2105.11111",
    "authors": [
      "Wentong Li",
      "Yijie Chen",
      "Kaixuan Hu",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05113",
    "title": "More Than Meets the Eye: Self-Supervised Depth Reconstruction From Brain  Activity",
    "abstract": " Comments: Code: this https URL ",
    "url": "https://arxiv.org/abs/2106.05113",
    "authors": [
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.05470",
    "title": "Automated Self-Supervised Learning for Graphs",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2106.05470",
    "authors": [
      "Wei Jin",
      "Xiaorui Liu",
      "Xiangyu Zhao",
      "Yao Ma",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.08895",
    "title": "Masked Training of Neural Networks with Partial Gradients",
    "abstract": " Comments: Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022 ",
    "url": "https://arxiv.org/abs/2106.08895",
    "authors": [
      "Amirkeivan Mohtashami",
      "Martin Jaggi",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.16163",
    "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
    "abstract": " Comments: Accepted at ICLR'22. Checkpoints and example analyses: this http URL ",
    "url": "https://arxiv.org/abs/2106.16163",
    "authors": [
      "Thibault Sellam",
      "Steve Yadlowsky",
      "Jason Wei",
      "Naomi Saphra",
      "Alexander D'Amour",
      "Tal Linzen",
      "Jasmijn Bastings",
      "Iulia Turc",
      "Jacob Eisenstein",
      "Dipanjan Das",
      "Ian Tenney",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2107.00327",
    "title": "Orthonormal Product Quantization Network for Scalable Face Image  Retrieval",
    "abstract": " Title: Orthonormal Product Quantization Network for Scalable Face Image  Retrieval ",
    "url": "https://arxiv.org/abs/2107.00327",
    "authors": [
      "Ming Zhang",
      "Xuefei Zhe",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "abstract": " Title: DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data ",
    "url": "https://arxiv.org/abs/2107.02168",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.04631",
    "title": "Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral  Images using a Hybrid Deep Neural Network",
    "abstract": " Title: Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral  Images using a Hybrid Deep Neural Network ",
    "url": "https://arxiv.org/abs/2107.04631",
    "authors": [
      "Fangcao Xu",
      "Jian Sun",
      "Guido Cervone",
      "Mark Salvador"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.02748",
    "title": "Zero-Shot Out-of-Distribution Detection Based on the Pre-trained Model  CLIP",
    "abstract": " Title: Zero-Shot Out-of-Distribution Detection Based on the Pre-trained Model  CLIP ",
    "url": "https://arxiv.org/abs/2109.02748",
    "authors": [
      "Sepideh Esmaeilpour",
      "Bing Liu",
      "Eric Robertson",
      "Lei Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.09587",
    "title": "Recommender systems based on graph embedding techniques: A comprehensive  review",
    "abstract": " Title: Recommender systems based on graph embedding techniques: A comprehensive  review ",
    "url": "https://arxiv.org/abs/2109.09587",
    "authors": [
      "Yue Deng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.10274",
    "title": "The Trade-offs of Domain Adaptation for Neural Language Models",
    "abstract": " Comments: Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2022 ",
    "url": "https://arxiv.org/abs/2109.10274",
    "authors": [
      "David Grangier",
      "Dan Iter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.13101",
    "title": "Half a Dozen Real-World Applications of Evolutionary Multitasking, and  More",
    "abstract": " Title: Half a Dozen Real-World Applications of Evolutionary Multitasking, and  More ",
    "url": "https://arxiv.org/abs/2109.13101",
    "authors": [
      "Abhishek Gupta",
      "Lei Zhou",
      "Yew-Soon Ong",
      "Zefeng Chen",
      "Yaqing Hou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2110.00667",
    "title": "Data-Driven Detection and Identification of IoT-Enabled Load-Altering  Attacks in Power Grids",
    "abstract": " Title: Data-Driven Detection and Identification of IoT-Enabled Load-Altering  Attacks in Power Grids ",
    "url": "https://arxiv.org/abs/2110.00667",
    "authors": [
      "Subhash Lakshminarayana",
      "Saurav Sthapit",
      "Hamidreza Jahangir",
      "Carsten Maple",
      "H Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2110.07580",
    "title": "Graph Condensation for Graph Neural Networks",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.07580",
    "authors": [
      "Wei Jin",
      "Lingxiao Zhao",
      "Shichang Zhang",
      "Yozen Liu",
      "Jiliang Tang",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.03971",
    "title": "Towards noise robust trigger-word detection with contrastive learning  pre-task for fast on-boarding of new trigger-words",
    "abstract": " Comments: submitted to INTERSPEECH ",
    "url": "https://arxiv.org/abs/2111.03971",
    "authors": [
      "Sivakumar Balasubramanian",
      "Aditya Jajodia",
      "Gowtham Srinivasan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.08524",
    "title": "Non-separable Spatio-temporal Graph Kernels via SPDEs",
    "abstract": " Title: Non-separable Spatio-temporal Graph Kernels via SPDEs ",
    "url": "https://arxiv.org/abs/2111.08524",
    "authors": [
      "Alexander Nikitin",
      "ST John",
      "Arno Solin",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.08918",
    "title": "Local Texture Estimator for Implicit Representation Function",
    "abstract": " Comments: CVPR 2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2111.08918",
    "authors": [
      "Jaewon Lee",
      "Kyong Hwan Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2111.12229",
    "title": "Subspace Adversarial Training",
    "abstract": " Comments: CVPR2022 ",
    "url": "https://arxiv.org/abs/2111.12229",
    "authors": [
      "Tao Li",
      "Yingwen Wu",
      "Sizhe Chen",
      "Kun Fang",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.12531",
    "title": "Non-Intrusive Binaural Speech Intelligibility Prediction from Discrete  Latent Representations",
    "abstract": " Comments: 4 pages + 1 refs; 1 figure; accepted at IEEE SPL (to appear) ",
    "url": "https://arxiv.org/abs/2111.12531",
    "authors": [
      "Alex F. McKinney",
      "Benjamin Cauchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.14358",
    "title": "IDR: Self-Supervised Image Denoising via Iterative Data Refinement",
    "abstract": " Comments: CVPR2022; code & dataset: this https URL ",
    "url": "https://arxiv.org/abs/2111.14358",
    "authors": [
      "Yi Zhang",
      "Dasong Li",
      "Ka Lung Law",
      "Xiaogang Wang",
      "Hongwei Qin",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.04654",
    "title": "Towards Real-Time Monitoring and Control of Water Networks",
    "abstract": " Comments: Accepted for publication at the 2022 American Control Conference (ACC), Atlanta, GA, 2022 ",
    "url": "https://arxiv.org/abs/2201.04654",
    "authors": [
      "Ahmed Elkhashap",
      "Daniel R\u00fcschen",
      "Dirk Abel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.05451",
    "title": "A causal model of safety assurance for machine learning",
    "abstract": " Title: A causal model of safety assurance for machine learning ",
    "url": "https://arxiv.org/abs/2201.05451",
    "authors": [
      "Simon Burton"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.06971",
    "title": "Identification for Accountability vs Privacy",
    "abstract": " Comments: 4 pages plus appendix, 9 pages total ",
    "url": "https://arxiv.org/abs/2201.06971",
    "authors": [
      "Nick Pope",
      "Geoffrey Goodell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.12845",
    "title": "Potential destination prediction for low predictability individuals  based on knowledge graph",
    "abstract": " Title: Potential destination prediction for low predictability individuals  based on knowledge graph ",
    "url": "https://arxiv.org/abs/2201.12845",
    "authors": [
      "Guilong Li",
      "Yixian Chen",
      "Qionghua Liao",
      "Zhaocheng He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.02652",
    "title": "A Graph Neural Network Framework for Grid-Based Simulation",
    "abstract": " Comments: There are conflict of interests and I need to modify the paper before resubmitting ",
    "url": "https://arxiv.org/abs/2202.02652",
    "authors": [
      "Haoyu Tang",
      "Wennan Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2202.05928",
    "title": "Benign Overfitting without Linearity: Neural Network Classifiers Trained  by Gradient Descent for Noisy Linear Data",
    "abstract": " Comments: 35 pages; fixed typos and clarified an assumption on the activation ",
    "url": "https://arxiv.org/abs/2202.05928",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.09950",
    "title": "CampNet: Context-Aware Mask Prediction for End-to-End Text-Based Speech  Editing",
    "abstract": " Comments: under review, 14 pages, 14 figures, demo page is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.09950",
    "authors": [
      "Tao Wang",
      "Jiangyan Yi",
      "Ruibo Fu",
      "Jianhua Tao",
      "Zhengqi Wen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01057",
    "title": "Colar: Effective and Efficient Online Action Detection by Consulting  Exemplars",
    "abstract": " Comments: CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.01057",
    "authors": [
      "Le Yang",
      "Junwei Han",
      "Dingwen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01429",
    "title": "SMTNet: Hierarchical cavitation intensity recognition based on sub-main  transfer network",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2203.01118; text overlap with arXiv:2202.13226 ",
    "url": "https://arxiv.org/abs/2203.01429",
    "authors": [
      "Yu Sha",
      "Johannes Faber",
      "Shuiping Gou",
      "Bo Liu",
      "Wei Li",
      "Stefan Schramm",
      "Horst Stoecker",
      "Thomas Steckenreiter",
      "Domagoj Vnucec",
      "Nadine Wetzstein",
      "Andreas Widl",
      "Kai Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.04041",
    "title": "Shape-invariant 3D Adversarial Point Clouds",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.04041",
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Dongdong Chen",
      "Hang Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05662",
    "title": "Point Density-Aware Voxels for LiDAR 3D Object Detection",
    "abstract": " Comments: Accepted in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.05662",
    "authors": [
      "Jordan S. K. Hu",
      "Tianshu Kuai",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": " Comments: ACL2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2203.07836",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08652",
    "title": "Topology-Preserving Shape Reconstruction and Registration via Neural  Diffeomorphic Flow",
    "abstract": " Title: Topology-Preserving Shape Reconstruction and Registration via Neural  Diffeomorphic Flow ",
    "url": "https://arxiv.org/abs/2203.08652",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Deying Kong",
      "Hao Tang",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08657",
    "title": "Occlusion Fields: An Implicit Representation for Non-Line-of-Sight  Surface Reconstruction",
    "abstract": " Title: Occlusion Fields: An Implicit Representation for Non-Line-of-Sight  Surface Reconstruction ",
    "url": "https://arxiv.org/abs/2203.08657",
    "authors": [
      "Javier Grau",
      "Markus Plack",
      "Patrick Haehn",
      "Michael Weinmann",
      "Matthias Hullin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08941",
    "title": "Translating Canonical SQL to Imperative Code in Coq",
    "abstract": " Comments: Version with appendix of a paper published at OOPSLA 2022 ",
    "url": "https://arxiv.org/abs/2203.08941",
    "authors": [
      "V\u00e9ronique Benzaken",
      "\u00c9velyne Contejean",
      "Mohammed Houssem Hachmaoui",
      "Chantal Keller",
      "Louis Mandel",
      "Avraham Shinnar",
      "J\u00e9r\u00f4me Sim\u00e9on"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.09204",
    "title": "Investigation of Physics-Informed Deep Learning for the Prediction of  Parametric, Three-Dimensional Flow Based on Boundary Data",
    "abstract": " Comments: Reference to code and dataset are DOIs.The DOIs will be activated when article is reviewed. Until then please contact Philip Heger or Daniel Hilger if you wish for code and datasets ",
    "url": "https://arxiv.org/abs/2203.09204",
    "authors": [
      "Philip Heger",
      "Markus Full",
      "Daniel Hilger",
      "Norbert Hosters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.10492",
    "title": "SimAN: Exploring Self-Supervised Representation Learning of Scene Text  via Similarity-Aware Normalization",
    "abstract": " Comments: Accepted to appear in CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.10492",
    "authors": [
      "Canjie Luo",
      "Lianwen Jin",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10736",
    "title": "The activity-weight duality in feed forward neural networks: The  geometric determinants of generalization",
    "abstract": " Title: The activity-weight duality in feed forward neural networks: The  geometric determinants of generalization ",
    "url": "https://arxiv.org/abs/2203.10736",
    "authors": [
      "Yu Feng",
      "Yuhai Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.11156",
    "title": "Operator Sketching for Deep Unrolling Networks",
    "abstract": " Title: Operator Sketching for Deep Unrolling Networks ",
    "url": "https://arxiv.org/abs/2203.11156",
    "authors": [
      "Junqi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)"
    ]
  }
]