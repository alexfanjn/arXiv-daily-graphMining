[
  {
    "id": "arXiv:2203.07372",
    "title": "Enhancing crowd flow prediction in various spatial and temporal  granularities",
    "abstract": "Thanks to the diffusion of the Internet of Things, nowadays it is possible to sense human mobility almost in real time using unconventional methods (e.g., number of bikes in a bike station). Due to the diffusion of such technologies, the last years have witnessed a significant growth of human mobility studies, motivated by their importance in a wide range of applications, from traffic management to public security and computational epidemiology. A mobility task that is becoming prominent is crowd flow prediction, i.e., forecasting aggregated incoming and outgoing flows in the locations of a geographic region. Although several deep learning approaches have been proposed to solve this problem, their usage is limited to specific types of spatial tessellations and cannot provide sufficient explanations of their predictions. We propose CrowdNet, a solution to crowd flow prediction based on graph convolutional networks. Compared with state-of-the-art solutions, CrowdNet can be used with regions of irregular shapes and provide meaningful explanations of the predicted crowd flows. We conduct experiments on public data varying the spatio-temporal granularity of crowd flows to show the superiority of our model with respect to existing methods, and we investigate CrowdNet's reliability to missing or noisy input data. Our model is a step forward in the design of reliable deep learning models to predict and explain human displacements in urban environments. ",
    "url": "https://arxiv.org/abs/2203.07372",
    "authors": [
      "Marco Cardia",
      "Massimiliano Luca",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07376",
    "title": "HIE-SQL: History Information Enhanced Network for Context-Dependent  Text-to-SQL Semantic Parsing",
    "abstract": "Recently, context-dependent text-to-SQL semantic parsing which translates natural language into SQL in an interaction process has attracted a lot of attention. Previous works leverage context-dependence information either from interaction history utterances or the previous predicted SQL queries but fail in taking advantage of both since of the mismatch between natural language and logic-form SQL. In this work, we propose a History Information Enhanced text-to-SQL model (HIE-SQL) to exploit context-dependence information from both history utterances and the last predicted SQL query. In view of the mismatch, we treat natural language and SQL as two modalities and propose a bimodal pre-trained model to bridge the gap between them. Besides, we design a schema-linking graph to enhance connections from utterances and the SQL query to the database schema. We show our history information enhanced methods improve the performance of HIE-SQL by a significant margin, which achieves new state-of-the-art results on the two context-dependent text-to-SQL benchmarks, the SparC and CoSQL datasets, at the writing time. ",
    "url": "https://arxiv.org/abs/2203.07376",
    "authors": [
      "Yanzhao Zheng",
      "Haibin Wang",
      "Baohua Dong",
      "Xingjun Wang",
      "Changshan Li"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07379",
    "title": "Quantitative Gaussian Approximation of Randomly Initialized Deep Neural  Networks",
    "abstract": "Given any deep fully connected neural network, initialized with random Gaussian parameters, we bound from above the quadratic Wasserstein distance between its output distribution and a suitable Gaussian process. Our explicit inequalities indicate how the hidden and output layers sizes affect the Gaussian behaviour of the network and quantitatively recover the distributional convergence results in the wide limit, i.e., if all the hidden layers sizes become large. ",
    "url": "https://arxiv.org/abs/2203.07379",
    "authors": [
      "Andrea Basteri",
      "Dario Trevisan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.07390",
    "title": "There's no difference: Convolutional Neural Networks for transient  detection without template subtraction",
    "abstract": "We present a Convolutional Neural Network (CNN) model for the separation of astrophysical transients from image artifacts, a task known as \"real-bogus\" classification, that does not rely on Difference Image Analysis (DIA) which is a computationally expensive process involving image matching on small spatial scales in large volumes of data. We explore the use of CNNs to (1) automate the \"real-bogus\" classification, (2) reduce the computational costs of transient discovery. We compare the efficiency of two CNNs with similar architectures, one that uses \"image triplets\" (templates, search, and the corresponding difference image) and one that adopts a similar architecture but takes as input the template and search only. Without substantially changing the model architecture or retuning the hyperparameters to the new input, we observe only a small decrease in model efficiency (97% to 92% accuracy). We further investigate how the model that does not receive the difference image learns the required information from the template and search by exploring the saliency maps. Our work demonstrates that (1) CNNs are excellent models for \"real-bogus\" classification that rely exclusively on the imaging data and require no feature engineering task; (2) high-accuracy models can be built without the need to construct difference images. Since once trained, neural networks can generate predictions at minimal computational costs, we argue that future implementations of this methodology could dramatically reduce the computational costs in the detection of genuine transients in synoptic surveys like Rubin Observatory's Legacy Survey of Space and Time by bypassing the DIA step entirely. ",
    "url": "https://arxiv.org/abs/2203.07390",
    "authors": [
      "Tatiana Acero-Cuellar",
      "Federica Bianco",
      "Gregory Dobler",
      "Masao Sako",
      "Helen Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ]
  },
  {
    "id": "arXiv:2203.07401",
    "title": "Multi-Parameter Analysis of Finding Minors and Subgraphs in Edge  Periodic Temporal Graphs",
    "abstract": "We study the computational complexity of determining structural properties of edge periodic temporal graphs (EPGs). EPGs are time-varying graphs that compactly represent periodic behavior of components of a dynamic network, for example, train schedules on a rail network. In EPGs, for each edge $e$ of the graph, a binary string $s_e$ determines in which time steps the edge is present, namely $e$ is present in time step $t$ if and only if $s_e$ contains a $1$ at position $t \\mod |s_e|$. Due to this periodicity, EPGs serve as very compact representations of complex periodic systems and can even be exponentially smaller than classic temporal graphs representing one period of the same system, as the latter contain the whole sequence of graphs explicitly. In this paper, we study the computational complexity of fundamental questions of the new concept of EPGs such as what is the shortest traversal time between two vertices; is there a time step in which the graph (1) is minor-free; (2) contains a minor; (3) is subgraph-free; (4) contains a subgraph; with respect to a given minor or subgraph. We give a detailed parameterized analysis for multiple combinations of parameters for the problems stated above including several parameterized algorithms. ",
    "url": "https://arxiv.org/abs/2203.07401",
    "authors": [
      "Emmanuel Arrighi",
      "Niels Gr\u00fcttemeier",
      "Nils Morawietz",
      "Frank Sommer",
      "Petra Wolf"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2203.07402",
    "title": "Revisiting the Compositional Generalization Abilities of Neural Sequence  Models",
    "abstract": "Compositional generalization is a fundamental trait in humans, allowing us to effortlessly combine known phrases to form novel sentences. Recent works have claimed that standard seq-to-seq models severely lack the ability to compositionally generalize. In this paper, we focus on one-shot primitive generalization as introduced by the popular SCAN benchmark. We demonstrate that modifying the training distribution in simple and intuitive ways enables standard seq-to-seq models to achieve near-perfect generalization performance, thereby showing that their compositional generalization abilities were previously underestimated. We perform detailed empirical analysis of this phenomenon. Our results indicate that the generalization performance of models is highly sensitive to the characteristics of the training data which should be carefully considered while designing such benchmarks in future. ",
    "url": "https://arxiv.org/abs/2203.07402",
    "authors": [
      "Arkil Patel",
      "Satwik Bhattamishra",
      "Phil Blunsom",
      "Navin Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07404",
    "title": "Respecting causality is all you need for training physics-informed  neural networks",
    "abstract": "While the popularity of physics-informed neural networks (PINNs) is steadily rising, to this date PINNs have not been successful in simulating dynamical systems whose solution exhibits multi-scale, chaotic or turbulent behavior. In this work we attribute this shortcoming to the inability of existing PINNs formulations to respect the spatio-temporal causal structure that is inherent to the evolution of physical systems. We argue that this is a fundamental limitation and a key source of error that can ultimately steer PINN models to converge towards erroneous solutions. We address this pathology by proposing a simple re-formulation of PINNs loss functions that can explicitly account for physical causality during model training. We demonstrate that this simple modification alone is enough to introduce significant accuracy improvements, as well as a practical quantitative mechanism for assessing the convergence of a PINNs model. We provide state-of-the-art numerical results across a series of benchmarks for which existing PINNs formulations fail, including the chaotic Lorenz system, the Kuramoto-Sivashinsky equation in the chaotic regime, and the Navier-Stokes equations in the turbulent regime. To the best of our knowledge, this is the first time that PINNs have been successful in simulating such systems, introducing new opportunities for their applicability to problems of industrial complexity. ",
    "url": "https://arxiv.org/abs/2203.07404",
    "authors": [
      "Sifan Wang",
      "Shyam Sankaran",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.07411",
    "title": "On Connecting Deep Trigonometric Networks with Deep Gaussian Processes:  Covariance, Expressivity, and Neural Tangent Kernel",
    "abstract": "Deep Gaussian Process as a Bayesian learning model is promising because it is expressive and capable of uncertainty estimation. With Bochner's theorem, we can view the deep Gaussian process with squared exponential kernels as a deep trigonometric network consisting of the random feature layers, sine and cosine activation units, and random weight layers. Focusing on this particular class of models allows us to obtain analytical results. We shall show that the weight space view yields the same effective covariance functions which were obtained previously in function space. The heavy statistical tails can be studied with multivariate characteristic function. In addition, the trig networks are flexible and expressive as one can freely adopt different prior distributions over the parameters in weight and feature layers. Lastly, the deep trigonometric network representation of deep Gaussian process allows the derivation of its neural tangent kernel, which can reveal the mean of predictive distribution from the intractable inference. ",
    "url": "https://arxiv.org/abs/2203.07411",
    "authors": [
      "Chi-Ken Lu",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.07426",
    "title": "Sememe Prediction for BabelNet Synsets using Multilingual and Multimodal  Information",
    "abstract": "In linguistics, a sememe is defined as the minimum semantic unit of languages. Sememe knowledge bases (KBs), which are built by manually annotating words with sememes, have been successfully applied to various NLP tasks. However, existing sememe KBs only cover a few languages, which hinders the wide utilization of sememes. To address this issue, the task of sememe prediction for BabelNet synsets (SPBS) is presented, aiming to build a multilingual sememe KB based on BabelNet, a multilingual encyclopedia dictionary. By automatically predicting sememes for a BabelNet synset, the words in many languages in the synset would obtain sememe annotations simultaneously. However, previous SPBS methods have not taken full advantage of the abundant information in BabelNet. In this paper, we utilize the multilingual synonyms, multilingual glosses and images in BabelNet for SPBS. We design a multimodal information fusion model to encode and combine this information for sememe prediction. Experimental results show the substantial outperformance of our model over previous methods (about 10 MAP and F1 scores). All the code and data of this paper can be obtained at https://github.com/thunlp/MSGI. ",
    "url": "https://arxiv.org/abs/2203.07426",
    "authors": [
      "Fanchao Qi",
      "Chuancheng Lv",
      "Zhiyuan Liu",
      "Xiaojun Meng",
      "Maosong Sun",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07450",
    "title": "A Neural Pairwise Ranking Model for Readability Assessment",
    "abstract": "Automatic Readability Assessment (ARA), the task of assigning a reading level to a text, is traditionally treated as a classification problem in NLP research. In this paper, we propose the first neural, pairwise ranking approach to ARA and compare it with existing classification, regression, and (non-neural) ranking methods. We establish the performance of our model by conducting experiments with three English, one French and one Spanish datasets. We demonstrate that our approach performs well in monolingual single/cross corpus testing scenarios and achieves a zero-shot cross-lingual ranking accuracy of over 80% for both French and Spanish when trained on English data. Additionally, we also release a new parallel bilingual readability dataset in English and French. To our knowledge, this paper proposes the first neural pairwise ranking model for ARA, and shows the first results of cross-lingual, zero-shot evaluation of ARA with neural models. ",
    "url": "https://arxiv.org/abs/2203.07450",
    "authors": [
      "Justin Lee",
      "Sowmya Vajjala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07463",
    "title": "Simultaneous Learning of the Inputs and Parameters in Neural  Collaborative Filtering",
    "abstract": "Neural network-based collaborative filtering systems focus on designing network architectures to learn better representations while fixing the input to the user/item interaction vectors and/or ID. In this paper, we first show that the non-zero elements of the inputs are learnable parameters that determine the weights in combining the user/item embeddings, and fixing them limits the power of the models in learning the representations. Then, we propose to learn the value of the non-zero elements of the inputs jointly with the neural network parameters. We analyze the model complexity and the empirical risk of our approach and prove that learning the input leads to a better generalization bound. Our experiments on several real-world datasets show that our method outperforms the state-of-the-art methods, even using shallow network structures with a smaller number of layers and parameters. ",
    "url": "https://arxiv.org/abs/2203.07463",
    "authors": [
      "Ramin Raziperchikolaei",
      "Young-joo Chung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07471",
    "title": "Robust Dynamic Walking for a 3D Dual-SLIP Model under One-Step  Unilateral Stiffness Perturbations: Towards Bipedal Locomotion over Compliant  Terrain",
    "abstract": "Bipedal walking is one of the most important hallmarks of human that robots have been trying to mimic for many decades. Although previous control methodologies have achieved robot walking on some terrains, there is a need for a framework allowing stable and robust locomotion over a wide range of compliant surfaces. This work proposes a novel biomechanics-inspired controller that adjusts the stiffness of the legs in support for robust and dynamic bipedal locomotion over compliant terrains. First, the 3D Dual-SLIP model is extended to support for the first time locomotion over compliant surfaces with variable stiffness and damping parameters. Then, the proposed controller is compared to a Linear-Quadratic Regulator (LQR) controller, in terms of robustness on stepping on soft terrain. The LQR controller is shown to be robust only up to a moderate ground stiffness level of 174 kN/m, while it fails in lower stiffness levels. On the contrary, the proposed controller can produce stable gait in stiffness levels as low as 30 kN/m, which results in a vertical ground penetration of the leg that is deeper than 10% of its rest length. The proposed framework could advance the field of bipedal walking, by generating stable walking trajectories for a wide range of compliant terrains useful for the control of bipeds and humanoids, as well as by improving controllers for prosthetic devices with tunable stiffness. ",
    "url": "https://arxiv.org/abs/2203.07471",
    "authors": [
      "Chrysostomos Karakasis",
      "Ioannis Poulakakis",
      "Panagiotis Artemiadis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.07473",
    "title": "The Unexplored Treasure Trove of Phabricator Code Review",
    "abstract": "Phabricator is a modern code collaboration tool used by popular projects like FreeBSD and Mozilla. However, unlike the other well-known code review environments, such as Gerrit or GitHub, there is no readily accessible public code review dataset for Phabricator. This paper describes our experience mining code reviews from five different projects that use Phabricator (Blender, FreeBSD, KDE, LLVM, and Mozilla). We discuss the challenges associated with the data retrieval process and our solutions, resulting in a dataset with details regarding 317,476 Phabricator code reviews. Our dataset is available in both JSON and MySQL database dump formats. The dataset enables analyses of the history of code reviews at a more granular level than other platforms. In addition, given that the projects we mined are publicly accessible via the Conduit API, our dataset can be used as a foundation to fetch additional details and insights. ",
    "url": "https://arxiv.org/abs/2203.07473",
    "authors": [
      "Gunnar Kudrjavets",
      "Nachiappan Nagappan",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.07485",
    "title": "Simplicial Attention Networks",
    "abstract": "The aim of this work is to introduce simplicial attention networks (SANs), i.e., novel neural architectures that operate on data defined on simplicial complexes leveraging masked self-attentional layers. Hinging on formal arguments from topological signal processing, we introduce a proper self-attention mechanism able to process data components at different layers (e.g., nodes, edges, triangles, and so on), while learning how to weight both upper and lower neighborhoods of the given topological domain in a totally task-oriented fashion. The proposed SANs generalize most of the current architectures available for processing data defined on simplicial complexes. The proposed approach compares favorably with other methods when applied to different (inductive and transductive) tasks such as trajectory prediction and missing data imputations in citation complexes. ",
    "url": "https://arxiv.org/abs/2203.07485",
    "authors": [
      "L. Giusti",
      "C. Battiloro",
      "P. Di Lorenzo",
      "S. Sardellitti",
      "S. Barbarossa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.07516",
    "title": "Skydiver: A Spiking Neural Network Accelerator Exploiting  Spatio-Temporal Workload Balance",
    "abstract": "Spiking Neural Networks (SNNs) are developed as a promising alternative to Artificial Neural networks (ANNs) due to their more realistic brain-inspired computing models. SNNs have sparse neuron firing over time, i.e., spatio-temporal sparsity; thus, they are useful to enable energy-efficient hardware inference. However, exploiting spatio-temporal sparsity of SNNs in hardware leads to unpredictable and unbalanced workloads, degrading the energy efficiency. In this work, we propose an FPGA-based convolutional SNN accelerator called Skydiver that exploits spatio-temporal workload balance. We propose the Approximate Proportional Relation Construction (APRC) method that can predict the relative workload channel-wisely and a Channel-Balanced Workload Schedule (CBWS) method to increase the hardware workload balance ratio to over 90%. Skydiver was implemented on a Xilinx XC7Z045 FPGA and verified on image segmentation and MNIST classification tasks. Results show improved throughput by 1.4X and 1.2X for the two tasks. Skydiver achieved 22.6 KFPS throughput, and 42.4 uJ/Image prediction energy on the classification task with 98.5% accuracy. ",
    "url": "https://arxiv.org/abs/2203.07516",
    "authors": [
      "Qinyu Chen",
      "Chang Gao",
      "Xinyuan Fang",
      "Haitao Luan"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.07523",
    "title": "Sense Embeddings are also Biased--Evaluating Social Biases in Static and  Contextualised Sense Embeddings",
    "abstract": "Sense embedding learning methods learn different embeddings for the different senses of an ambiguous word. One sense of an ambiguous word might be socially biased while its other senses remain unbiased. In comparison to the numerous prior work evaluating the social biases in pretrained word embeddings, the biases in sense embeddings have been relatively understudied. We create a benchmark dataset for evaluating the social biases in sense embeddings and propose novel sense-specific bias evaluation measures. We conduct an extensive evaluation of multiple static and contextualised sense embeddings for various types of social biases using the proposed measures. Our experimental results show that even in cases where no biases are found at word-level, there still exist worrying levels of social biases at sense-level, which are often ignored by the word-level bias evaluation measures. ",
    "url": "https://arxiv.org/abs/2203.07523",
    "authors": [
      "Yi Zhou",
      "Masahiro Kaneko",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07524",
    "title": "Convolutional-Recurrent Neural Network Proxy for Robust Optimization and  Closed-Loop Reservoir Management",
    "abstract": "Production optimization under geological uncertainty is computationally expensive, as a large number of well control schedules must be evaluated over multiple geological realizations. In this work, a convolutional-recurrent neural network (CNN-RNN) proxy model is developed to predict well-by-well oil and water rates, for given time-varying well bottom-hole pressure (BHP) schedules, for each realization in an ensemble. This capability enables the estimation of the objective function and nonlinear constraint values required for robust optimization. The proxy model represents an extension of a recently developed long short-term memory (LSTM) RNN proxy designed to predict well rates for a single geomodel. A CNN is introduced here to processes permeability realizations, and this provides the initial states for the RNN. The CNN-RNN proxy is trained using simulation results for 300 different sets of BHP schedules and permeability realizations. We demonstrate proxy accuracy for oil-water flow through multiple realizations of 3D multi-Gaussian permeability models. The proxy is then incorporated into a closed-loop reservoir management (CLRM) workflow, where it is used with particle swarm optimization and a filter-based method for nonlinear constraint satisfaction. History matching is achieved using an adjoint-gradient-based procedure. The proxy model is shown to perform well in this setting for five different (synthetic) `true' models. Improved net present value along with constraint satisfaction and uncertainty reduction are observed with CLRM. For the robust production optimization steps, the proxy provides O(100) runtime speedup over simulation-based optimization. ",
    "url": "https://arxiv.org/abs/2203.07524",
    "authors": [
      "Yong Do Kim",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07544",
    "title": "A Unified Framework for Rank-based Evaluation Metrics for Link  Prediction in Knowledge Graphs",
    "abstract": "The link prediction task on knowledge graphs without explicit negative triples in the training data motivates the usage of rank-based metrics. Here, we review existing rank-based metrics and propose desiderata for improved metrics to address lack of interpretability and comparability of existing metrics to datasets of different sizes and properties. We introduce a simple theoretical framework for rank-based metrics upon which we investigate two avenues for improvements to existing metrics via alternative aggregation functions and concepts from probability theory. We finally propose several new rank-based metrics that are more easily interpreted and compared accompanied by a demonstration of their usage in a benchmarking of knowledge graph embedding models. ",
    "url": "https://arxiv.org/abs/2203.07544",
    "authors": [
      "Charles Tapley Hoyt",
      "Max Berrendorf",
      "Mikhail Gaklin",
      "Volker Tresp",
      "Benjamin M. Gyori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07547",
    "title": "On the Violation of Honesty in Mobile Apps: Automated Detection and  Categories",
    "abstract": "Human values such as integrity, privacy, curiosity, security, and honesty are guiding principles for what people consider important in life. Such human values may be violated by mobile software applications (apps), and the negative effects of such human value violations can be seen in various ways in society. In this work, we focus on the human value of honesty. We present a model to support the automatic identification of violations of the value of honesty from app reviews from an end-user perspective. Beyond the automatic detection of honesty violations by apps, we also aim to better understand different categories of honesty violations expressed by users in their app reviews. The result of our manual analysis of our honesty violations dataset shows that honesty violations can be characterised into ten categories: unfair cancellation and refund policies; false advertisements; delusive subscriptions; cheating systems; inaccurate information; unfair fees; no service; deletion of reviews; impersonation; and fraudulent-looking apps. Based on these results, we argue for a conscious effort in developing more honest software artefacts including mobile apps, and the promotion of honesty as a key value in software development practices. Furthermore, we discuss the role of app distribution platforms as enforcers of ethical systems supporting human values, and highlight some proposed next steps for human values in software engineering (SE) research. ",
    "url": "https://arxiv.org/abs/2203.07547",
    "authors": [
      "Humphrey O. Obie",
      "Idowu Ilekura",
      "Hung Du",
      "Mojtaba Shahin",
      "John Grundy",
      "Li Li",
      "Jon Whittle",
      "Burak Turhan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.07548",
    "title": "Physical Neural Cellular Automata for 2D Shape Classification",
    "abstract": "Materials with the ability to self-classify their own shape have the potential to advance a wide range of engineering applications and industries. Biological systems possess the ability not only to self-reconfigure but also to self-classify themselves to determine a general shape and function. Previous work into modular robotics systems have only enabled self-recognition and self-reconfiguration into a specific target shape, missing the inherent robustness present in nature to self-classify. In this paper we therefore take advantage of recent advances in deep learning and neural cellular automata, and present a simple modular 2D robotic system that can infer its own class of shape through the local communication of its components. Furthermore, we show that our system can be successfully transferred to hardware which thus opens opportunities for future self-classifying machines. ",
    "url": "https://arxiv.org/abs/2203.07548",
    "authors": [
      "Kathryn Walker",
      "Rasmus Berg Palm",
      "Rodrigo Moreno Garcia",
      "Andres Faina",
      "Kasper Stoy",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07561",
    "title": "Toward the Detection of Polyglot Files",
    "abstract": "Standardized file formats play a key role in the development and use of computer software. However, it is possible to abuse standardized file formats by creating a file that is valid in multiple file formats. The resulting polyglot (many languages) file can confound file format identification, allowing elements of the file to evade analysis.This is especially problematic for malware detection systems that rely on file format identification for feature extraction. File format identification processes that depend on file signatures can be easily evaded thanks to flexibility in the format specifications of certain file formats. Although work has been done to identify file formats using more comprehensive methods than file signatures, accurate identification of polyglot files remains an open problem. Since malware detection systems routinely perform file format-specific feature extraction, polyglot files need to be filtered out prior to ingestion by these systems. Otherwise, malicious content could pass through undetected. To address the problem of polyglot detection we assembled a data set using the mitra tool. We then evaluated the performance of the most commonly used file identification tool, file. Finally, we demonstrated the accuracy, precision, recall and F1 score of a range of machine and deep learning models. Malconv2 and Catboost demonstrated the highest recall on our data set with 95.16% and 95.34%, respectively. These models can be incorporated into a malware detector's file processing pipeline to filter out potentially malicious polyglots before file format-dependent feature extraction takes place. ",
    "url": "https://arxiv.org/abs/2203.07561",
    "authors": [
      "Luke Koch",
      "Sean Oesch",
      "Mary Adkisson",
      "Sam Erwin",
      "Brian Weber",
      "Amul Chaulagain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07596",
    "title": "Task-Agnostic Robust Representation Learning",
    "abstract": "It has been reported that deep learning models are extremely vulnerable to small but intentionally chosen perturbations of its input. In particular, a deep network, despite its near-optimal accuracy on the clean images, often mis-classifies an image with a worst-case but humanly imperceptible perturbation (so-called adversarial examples). To tackle this problem, a great amount of research has been done to study the training procedure of a network to improve its robustness. However, most of the research so far has focused on the case of supervised learning. With the increasing popularity of self-supervised learning methods, it is also important to study and improve the robustness of their resulting representation on the downstream tasks. In this paper, we study the problem of robust representation learning with unlabeled data in a task-agnostic manner. Specifically, we first derive an upper bound on the adversarial loss of a prediction model (which is based on the learned representation) on any downstream task, using its loss on the clean data and a robustness regularizer. Moreover, the regularizer is task-independent, thus we propose to minimize it directly during the representation learning phase to make the downstream prediction model more robust. Extensive experiments show that our method achieves preferable adversarial performance compared to relevant baselines. ",
    "url": "https://arxiv.org/abs/2203.07596",
    "authors": [
      "A. Tuan Nguyen",
      "Ser Nam Lim",
      "Philip Torr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07613",
    "title": "CARETS: A Consistency And Robustness Evaluative Test Suite for VQA",
    "abstract": "We introduce CARETS, a systematic test suite to measure consistency and robustness of modern VQA models through a series of six fine-grained capability tests. In contrast to existing VQA test sets, CARETS features balanced question generation to create pairs of instances to test models, with each pair focusing on a specific capability such as rephrasing, logical symmetry or image obfuscation. We evaluate six modern VQA systems on CARETS and identify several actionable weaknesses in model comprehension, especially with concepts such as negation, disjunction, or hypernym invariance. Interestingly, even the most sophisticated models are sensitive to aspects such as swapping the order of terms in a conjunction or varying the number of answer choices mentioned in the question. We release CARETS to be used as an extensible tool for evaluating multi-modal model robustness. ",
    "url": "https://arxiv.org/abs/2203.07613",
    "authors": [
      "Carlos E. Jimenez",
      "Olga Russakovsky",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07627",
    "title": "Multilingual Mix: Example Interpolation Improves Multilingual Neural  Machine Translation",
    "abstract": "Multilingual neural machine translation models are trained to maximize the likelihood of a mix of examples drawn from multiple language pairs. The dominant inductive bias applied to these models is a shared vocabulary and a shared set of parameters across languages; the inputs and labels corresponding to examples drawn from different language pairs might still reside in distinct sub-spaces. In this paper, we introduce multilingual crossover encoder-decoder (mXEncDec) to fuse language pairs at an instance level. Our approach interpolates instances from different language pairs into joint `crossover examples' in order to encourage sharing input and output spaces across languages. To ensure better fusion of examples in multilingual settings, we propose several techniques to improve example interpolation across dissimilar languages under heavy data imbalance. Experiments on a large-scale WMT multilingual dataset demonstrate that our approach significantly improves quality on English-to-Many, Many-to-English and zero-shot translation tasks (from +0.5 BLEU up to +5.5 BLEU points). Results on code-switching sets demonstrate the capability of our approach to improve model generalization to out-of-distribution multilingual examples. We also conduct qualitative and quantitative representation comparisons to analyze the advantages of our approach at the representation level. ",
    "url": "https://arxiv.org/abs/2203.07627",
    "authors": [
      "Yong Cheng",
      "Ankur Bapna",
      "Orhan Firat",
      "Yuan Cao",
      "Pidong Wang",
      "Wolfgang Macherey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07632",
    "title": "Graph Representation Learning for Popularity Prediction Problem: A  Survey",
    "abstract": "The online social platforms, like Twitter, Facebook, LinkedIn and WeChat, have grown really fast in last decade and have been one of the most effective platforms for people to communicate and share information with each other. Due to the \"word of mouth\" effects, information usually can spread rapidly on these social media platforms. Therefore, it is important to study the mechanisms driving the information diffusion and quantify the consequence of information spread. A lot of efforts have been focused on this problem to help us better understand and achieve higher performance in viral marketing and advertising. On the other hand, the development of neural networks has blossomed in the last few years, leading to a large number of graph representation learning (GRL) models. Compared to traditional models, GRL methods are often shown to be more effective. In this paper, we present a comprehensive review for existing works using GRL methods for popularity prediction problem, and categorize related literatures into two big classes, according to their mainly used model and techniques: embedding-based methods and deep learning methods. Deep learning method is further classified into six small classes: convolutional neural networks, graph convolutional networks, graph attention networks, graph neural networks, recurrent neural networks, and reinforcement learning. We compare the performance of these different models and discuss their strengths and limitations. Finally, we outline the challenges and future chances for popularity prediction problem. ",
    "url": "https://arxiv.org/abs/2203.07632",
    "authors": [
      "Tiantian Chen",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07633",
    "title": "Improving Event Representation via Simultaneous Weakly Supervised  Contrastive Learning and Clustering",
    "abstract": "Representations of events described in text are important for various tasks. In this work, we present SWCC: a Simultaneous Weakly supervised Contrastive learning and Clustering framework for event representation learning. SWCC learns event representations by making better use of co-occurrence information of events. Specifically, we introduce a weakly supervised contrastive learning method that allows us to consider multiple positives and multiple negatives, and a prototype-based clustering method that avoids semantically related events being pulled apart. For model training, SWCC learns representations by simultaneously performing weakly supervised contrastive learning and prototype-based clustering. Experimental results show that SWCC outperforms other baselines on Hard Similarity and Transitive Sentence Similarity tasks. In addition, a thorough analysis of the prototype-based clustering method demonstrates that the learned prototype vectors are able to implicitly capture various relations between events. ",
    "url": "https://arxiv.org/abs/2203.07633",
    "authors": [
      "Jun Gao",
      "Wei Wang",
      "Changlong Yu",
      "Huan Zhao",
      "Wilfred Ng",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07640",
    "title": "Unsupervised Keyphrase Extraction via Interpretable Neural Networks",
    "abstract": "Keyphrase extraction aims at automatically extracting a list of \"important\" phrases which represent the key concepts in a document. Prior approaches for unsupervised keyphrase extraction resort to heuristic notions of phrase importance via embedding similarities or graph centrality, requiring extensive domain expertise to develop them. Our work proposes an alternative operational definition: phrases that are most useful for predicting the topic of a text are important keyphrases. To this end, we propose INSPECT -- a self-explaining neural framework for identifying influential keyphrases by measuring the predictive impact of input phrases on the downstream task of topic classification. We show that this novel approach not only alleviates the need for ad-hoc heuristics but also achieves state-of-the-art results in unsupervised keyphrase extraction across four diverse datasets in two domains: scientific publications and news articles. Ultimately, our study suggests a new usage of interpretable neural networks as an intrinsic component in NLP systems, and not only as a tool for explaining model predictions to humans. ",
    "url": "https://arxiv.org/abs/2203.07640",
    "authors": [
      "Rishabh Joshi",
      "Vidhisha Balachandran",
      "Emily Saldanha",
      "Maria Glenski",
      "Svitlana Volkova",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07648",
    "title": "InfoDCL: A Distantly Supervised Contrastive Learning Framework for  Social Meaning",
    "abstract": "Existing supervised contrastive learning frameworks suffer from two major drawbacks: (i) they depend on labeled data, which is limited for the majority of tasks in real-world, and (ii) they incorporate inter-class relationships based on instance-level information, while ignoring corpus-level information, for weighting negative samples. To mitigate these challenges, we propose an effective distantly supervised contrastive learning framework (InfoDCL) that makes use of naturally occurring surrogate labels in the context of contrastive learning and employs pointwise mutual information to leverage corpus-level information. Our framework outperforms an extensive set of existing contrastive learning methods (self-supervised, supervised, and weakly supervised) on a wide range of social meaning tasks (in-domain and out-of-domain), in both the general and few-shot settings. Our method is also language-agnostic, as we demonstrate on three languages in addition to English. ",
    "url": "https://arxiv.org/abs/2203.07648",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07653",
    "title": "Generalized but not Robust? Comparing the Effects of Data Modification  Methods on Out-of-Domain Generalization and Adversarial Robustness",
    "abstract": "Data modification, either via additional training datasets, data augmentation, debiasing, and dataset filtering, has been proposed as an effective solution for generalizing to out-of-domain (OOD) inputs, in both natural language processing and computer vision literature. However, the effect of data modification on adversarial robustness remains unclear. In this work, we conduct a comprehensive study of common data modification strategies and evaluate not only their in-domain and OOD performance, but also their adversarial robustness (AR). We also present results on a two-dimensional synthetic dataset to visualize the effect of each method on the training distribution. This work serves as an empirical study towards understanding the relationship between generalizing to unseen domains and defending against adversarial perturbations. Our findings suggest that more data (either via additional datasets or data augmentation) benefits both OOD accuracy and AR. However, data filtering (previously shown to improve OOD accuracy on natural language inference) hurts OOD accuracy on other tasks such as question answering and image classification. We provide insights from our experiments to inform future work in this direction. ",
    "url": "https://arxiv.org/abs/2203.07653",
    "authors": [
      "Tejas Gokhale",
      "Swaroop Mishra",
      "Man Luo",
      "Bhavdeep Singh Sachdeva",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07656",
    "title": "Wave-SAN: Wavelet based Style Augmentation Network for Cross-Domain  Few-Shot Learning",
    "abstract": "Previous few-shot learning (FSL) works mostly are limited to natural images of general concepts and categories. These works assume very high visual similarity between the source and target classes. In contrast, the recently proposed cross-domain few-shot learning (CD-FSL) aims at transferring knowledge from general nature images of many labeled examples to novel domain-specific target categories of only a few labeled examples. The key challenge of CD-FSL lies in the huge data shift between source and target domains, which is typically in the form of totally different visual styles. This makes it very nontrivial to directly extend the classical FSL methods to address the CD-FSL task. To this end, this paper studies the problem of CD-FSL by spanning the style distributions of the source dataset. Particularly, wavelet transform is introduced to enable the decomposition of visual representations into low-frequency components such as shape and style and high-frequency components e.g., texture. To make our model robust to visual styles, the source images are augmented by swapping the styles of their low-frequency components with each other. We propose a novel Style Augmentation (StyleAug) module to implement this idea. Furthermore, we present a Self-Supervised Learning (SSL) module to ensure the predictions of style-augmented images are semantically similar to the unchanged ones. This avoids the potential semantic drift problem in exchanging the styles. Extensive experiments on two CD-FSL benchmarks show the effectiveness of our method. Our codes and models will be released. ",
    "url": "https://arxiv.org/abs/2203.07656",
    "authors": [
      "Yuqian Fu",
      "Yu Xie",
      "Yanwei Fu",
      "Jingjing Chen",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07657",
    "title": "Seamlessly Integrating Factual Information and Social Content with  Persuasive Dialogue",
    "abstract": "Effective human-chatbot conversations need to achieve both coherence and efficiency. Complex conversation settings such as persuasion involve communicating changes in attitude or behavior, so users' perspectives need to be carefully considered and addressed, even when not directly related to the topic. In this work, we contribute a novel modular dialogue system framework that seamlessly integrates factual information and social content into persuasive dialogue. Our framework is generalizable to any dialogue tasks that have mixed social and task contents. We conducted a study that compared user evaluations of our framework versus a baseline end-to-end generation model. We found our model was evaluated to be more favorable in all dimensions including competence and friendliness compared to the baseline model which does not explicitly handle social content or factual questions. ",
    "url": "https://arxiv.org/abs/2203.07657",
    "authors": [
      "Maximillian Chen",
      "Weiyan Shi",
      "Feifan Yan",
      "Ryan Hou",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.07658",
    "title": "Neural Radiance Projection",
    "abstract": "The proposed method, Neural Radiance Projection (NeRP), addresses the three most fundamental shortages of training such a convolutional neural network on X-ray image segmentation: dealing with missing/limited human-annotated datasets; ambiguity on the per-pixel label; and the imbalance across positive- and negative- classes distribution. By harnessing a generative adversarial network, we can synthesize a massive amount of physics-based X-ray images, so-called Variationally Reconstructed Radiographs (VRRs), alongside their segmentation from more accurate labeled 3D Computed Tomography data. As a result, VRRs present more faithfully than other projection methods in terms of photo-realistic metrics. Adding outputs from NeRP also surpasses the vanilla UNet models trained on the same pairs of X-ray images. ",
    "url": "https://arxiv.org/abs/2203.07658",
    "authors": [
      "Pham Ngoc Huy",
      "Tran Minh Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.07669",
    "title": "Progressive End-to-End Object Detection in Crowded Scenes",
    "abstract": "In this paper, we propose a new query-based detection framework for crowd detection. Previous query-based detectors suffer from two drawbacks: first, multiple predictions will be inferred for a single object, typically in crowded scenes; second, the performance saturates as the depth of the decoding stage increases. Benefiting from the nature of the one-to-one label assignment rule, we propose a progressive predicting method to address the above issues. Specifically, we first select accepted queries prone to generate true positive predictions, then refine the rest noisy queries according to the previously accepted predictions. Experiments show that our method can significantly boost the performance of query-based detectors in crowded scenes. Equipped with our approach, Sparse RCNN achieves 92.0\\% $\\text{AP}$, 41.4\\% $\\text{MR}^{-2}$ and 83.2\\% $\\text{JI}$ on the challenging CrowdHuman \\cite{shao2018crowdhuman} dataset, outperforming the box-based method MIP \\cite{chu2020detection} that specifies in handling crowded scenarios. Moreover, the proposed method, robust to crowdedness, can still obtain consistent improvements on moderately and slightly crowded datasets like CityPersons \\cite{zhang2017citypersons} and COCO \\cite{lin2014microsoft}. Code will be made publicly available at https://github.com/megvii-model/Iter-E2EDET. ",
    "url": "https://arxiv.org/abs/2203.07669",
    "authors": [
      "Anlin Zheng",
      "Yuang Zhang",
      "Xiangyu Zhang",
      "Xiaojuan Qi",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07670",
    "title": "Towards Adversarial Control Loops in Sensor Attacks: A Case Study to  Control the Kinematics and Actuation of Embedded Systems",
    "abstract": "Recent works investigated attacks on sensors by influencing analog sensor components with acoustic, light, and electromagnetic signals. Such attacks can have extensive security, reliability, and safety implications since many types of the targeted sensors are also widely used in critical process control, robotics, automation, and industrial control systems. While existing works advanced our understanding of the physical-level risks that are hidden from a digital-domain perspective, gaps exist in how the attack can be guided to achieve system-level control in real-time, continuous processes. This paper proposes an adversarial control loop-based approach for real-time attacks on control systems relying on sensors. We study how to utilize the system feedback extracted from physical-domain signals to guide the attacks. In the attack process, injection signals are adjusted in real time based on the extracted feedback to exert targeted influence on a victim control system that is continuously affected by the injected perturbations and applying changes to the physical environment. In our case study, we investigate how an external adversarial control system can be constructed over sensor-actuator systems and demonstrate the attacks with program-controlled processes to manipulate the victim system without accessing its internal statuses. ",
    "url": "https://arxiv.org/abs/2203.07670",
    "authors": [
      "Yazhou Tu",
      "Sara Rampazzi",
      "Xiali Hei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.07678",
    "title": "Incorporating Heterophily into Graph Neural Networks for Graph  Classification",
    "abstract": "Graph neural networks (GNNs) often assume strong homophily in graphs, seldom considering heterophily which means connected nodes tend to have different class labels and dissimilar features. In real-world scenarios, graphs may have nodes that exhibit both homophily and heterophily. Failing to generalize to this setting makes many GNNs underperform in graph classification. In this paper, we address this limitation by identifying two useful designs and develop a novel GNN architecture called IHGNN (Incorporating Heterophily into Graph Neural Networks). These designs include integration and separation of the ego- and neighbor-embeddings of nodes; and concatenation of all the node embeddings as the final graph-level readout function. In the first design, integration is combined with separation by an injective function which is the composition of the MLP and the concatenation function. The second design enables the graph-level readout function to differentiate between different node embeddings. As the functions used in both the designs are injective, IHGNN, while being simple, has an expressiveness as powerful as the 1-WL. We empirically validate IHGNN on various graph datasets and demonstrate that it achieves state-of-the-art performance on the graph classification task. ",
    "url": "https://arxiv.org/abs/2203.07678",
    "authors": [
      "Wei Ye",
      "Jiayi Yang",
      "Sourav Medya",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.07682",
    "title": "Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution",
    "abstract": "Recent vision transformers along with self-attention have achieved promising results on various computer vision tasks. In particular, a pure transformer-based image restoration architecture surpasses the existing CNN-based methods using multi-task pre-training with a large number of trainable parameters. In this paper, we introduce an effective hybrid architecture for super-resolution (SR) tasks, which leverages local features from CNNs and long-range dependencies captured by transformers to further improve the SR results. Specifically, our architecture comprises of transformer and convolution branches, and we substantially elevate the performance by mutually fusing two branches to complement each representation. Furthermore, we propose a cross-scale token attention module, which allows the transformer to efficiently exploit the informative relationships among tokens across different scales. Our proposed method achieves state-of-the-art SR results on numerous benchmark datasets. ",
    "url": "https://arxiv.org/abs/2203.07682",
    "authors": [
      "Jinsu Yoo",
      "Taehoon Kim",
      "Sihaeng Lee",
      "Seung Hwan Kim",
      "Honglak Lee",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07687",
    "title": "Compressing Sentence Representation for Semantic Retrieval via  Homomorphic Projective Distillation",
    "abstract": "How to learn highly compact yet effective sentence representation? Pre-trained language models have been effective in many NLP tasks. However, these models are often huge and produce large sentence embeddings. Moreover, there is a big performance gap between large and small models. In this paper, we propose Homomorphic Projective Distillation (HPD) to learn compressed sentence embeddings. Our method augments a small Transformer encoder model with learnable projection layers to produce compact representations while mimicking a large pre-trained language model to retain the sentence representation quality. We evaluate our method with different model sizes on both semantic textual similarity (STS) and semantic retrieval (SR) tasks. Experiments show that our method achieves 2.7-4.5 points performance gain on STS tasks compared with previous best representations of the same size. In SR tasks, our method improves retrieval speed (8.2$\\times$) and memory usage (8.0$\\times$) compared with state-of-the-art large models. ",
    "url": "https://arxiv.org/abs/2203.07687",
    "authors": [
      "Xuandong Zhao",
      "Zhiguo Yu",
      "Ming Wu",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.07688",
    "title": "InsCon:Instance Consistency Feature Representation via Self-Supervised  Learning",
    "abstract": "Feature representation via self-supervised learning has reached remarkable success in image-level contrastive learning, which brings impressive performances on image classification tasks. While image-level feature representation mainly focuses on contrastive learning in single instance, it ignores the objective differences between pretext and downstream prediction tasks such as object detection and instance segmentation. In order to fully unleash the power of feature representation on downstream prediction tasks, we propose a new end-to-end self-supervised framework called InsCon, which is devoted to capturing multi-instance information and extracting cell-instance features for object recognition and localization. On the one hand, InsCon builds a targeted learning paradigm that applies multi-instance images as input, aligning the learned feature between corresponding instance views, which makes it more appropriate for multi-instance recognition tasks. On the other hand, InsCon introduces the pull and push of cell-instance, which utilizes cell consistency to enhance fine-grained feature representation for precise boundary localization. As a result, InsCon learns multi-instance consistency on semantic feature representation and cell-instance consistency on spatial feature representation. Experiments demonstrate the method we proposed surpasses MoCo v2 by 1.1% AP^{bb} on COCO object detection and 1.0% AP^{mk} on COCO instance segmentation using Mask R-CNN R50-FPN network structure with 90k iterations, 2.1% APbb on PASCAL VOC objection detection using Faster R-CNN R50-C4 network structure with 24k iterations. ",
    "url": "https://arxiv.org/abs/2203.07688",
    "authors": [
      "Junwei Yang",
      "Ke Zhang",
      "Zhaolin Cui",
      "Jinming Su",
      "Junfeng Luo",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07691",
    "title": "Supervised Contrastive Learning with Structure Inference for Graph  Classification",
    "abstract": "Advanced graph neural networks have shown great potentials in graph classification tasks recently. Different from node classification where node embeddings aggregated from local neighbors can be directly used to learn node labels, graph classification requires a hierarchical accumulation of different levels of topological information to generate discriminative graph embeddings. Still, how to fully explore graph structures and formulate an effective graph classification pipeline remains rudimentary. In this paper, we propose a novel graph neural network based on supervised contrastive learning with structure inference for graph classification. First, we propose a data-driven graph augmentation strategy that can discover additional connections to enhance the existing edge set. Concretely, we resort to a structure inference stage based on diffusion cascades to recover possible connections with high node similarities. Second, to improve the contrastive power of graph neural networks, we propose to use a supervised contrastive loss for graph classification. With the integration of label information, the one-vs-many contrastive learning can be extended to a many-vs-many setting, so that the graph-level embeddings with higher topological similarities will be pulled closer. The supervised contrastive loss and structure inference can be naturally incorporated within the hierarchical graph neural networks where the topological patterns can be fully explored to produce discriminative graph embeddings. Experiment results show the effectiveness of the proposed method compared with recent state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.07691",
    "authors": [
      "Hao Jia",
      "Junzhong Ji",
      "Minglong Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07694",
    "title": "Implicit field supervision for robust non-rigid shape matching",
    "abstract": "Establishing a correspondence between two non-rigidly deforming shapes is one of the most fundamental problems in visual computing. Existing methods often show weak resilience when presented with challenges innate to real-world data such as noise, outliers, self-occlusion etc. On the other hand, auto-decoders have demonstrated strong expressive power in learning geometrically meaningful latent embeddings. However, their use in \\emph{shape analysis} and especially in non-rigid shape correspondence has been limited. In this paper, we introduce an approach based on auto-decoder framework, that learns a continuous shape-wise deformation field over a fixed template. By supervising the deformation field for points on-surface and regularising for points off-surface through a novel \\emph{Signed Distance Regularisation} (SDR), we learn an alignment between the template and shape \\emph{volumes}. Unlike classical correspondence techniques, our method is remarkably robust in the presence of strong artefacts and can be generalised to arbitrary shape categories. Trained on clean water-tight meshes, \\emph{without} any data-augmentation, we demonstrate compelling performance on compromised data and real-world scans. ",
    "url": "https://arxiv.org/abs/2203.07694",
    "authors": [
      "Ramana Sundararaman",
      "Gautam Pai",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07705",
    "title": "APRNet: Attention-based Pixel-wise Rendering Network for Photo-Realistic  Text Image Generation",
    "abstract": "Style-guided text image generation tries to synthesize text image by imitating reference image's appearance while keeping text content unaltered. The text image appearance includes many aspects. In this paper, we focus on transferring style image's background and foreground color patterns to the content image to generate photo-realistic text image. To achieve this goal, we propose 1) a content-style cross attention based pixel sampling approach to roughly mimicking the style text image's background; 2) a pixel-wise style modulation technique to transfer varying color patterns of the style image to the content image spatial-adaptively; 3) a cross attention based multi-scale style fusion approach to solving text foreground misalignment issue between style and content images; 4) an image patch shuffling strategy to create style, content and ground truth image tuples for training. Experimental results on Chinese handwriting text image synthesis with SCUT-HCCDoc and CASIA-OLHWDB datasets demonstrate that the proposed method can improve the quality of synthetic text images and make them more photo-realistic. ",
    "url": "https://arxiv.org/abs/2203.07705",
    "authors": [
      "Yangming Shi",
      "Haisong Ding",
      "Kai Chen",
      "Qiang Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07709",
    "title": "Adaptive Environment Modeling Based Reinforcement Learning for Collision  Avoidance in Complex Scenes",
    "abstract": "The major challenges of collision avoidance for robot navigation in crowded scenes lie in accurate environment modeling, fast perceptions, and trustworthy motion planning policies. This paper presents a novel adaptive environment model based collision avoidance reinforcement learning (i.e., AEMCARL) framework for an unmanned robot to achieve collision-free motions in challenging navigation scenarios. The novelty of this work is threefold: (1) developing a hierarchical network of gated-recurrent-unit (GRU) for environment modeling; (2) developing an adaptive perception mechanism with an attention module; (3) developing an adaptive reward function for the reinforcement learning (RL) framework to jointly train the environment model, perception function and motion planning policy. The proposed method is tested with the Gym-Gazebo simulator and a group of robots (Husky and Turtlebot) under various crowded scenes. Both simulation and experimental results have demonstrated the superior performance of the proposed method over baseline methods. ",
    "url": "https://arxiv.org/abs/2203.07709",
    "authors": [
      "Shuaijun Wang",
      "Rui Gao",
      "Ruihua Han",
      "Shengduo Chen",
      "Chengyang Li",
      "Qi Hao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.07713",
    "title": "LDP: Learnable Dynamic Precision for Efficient Deep Neural Network  Training and Inference",
    "abstract": "Low precision deep neural network (DNN) training is one of the most effective techniques for boosting DNNs' training efficiency, as it trims down the training cost from the finest bit level. While existing works mostly fix the model precision during the whole training process, a few pioneering works have shown that dynamic precision schedules help DNNs converge to a better accuracy while leading to a lower training cost than their static precision training counterparts. However, existing dynamic low precision training methods rely on manually designed precision schedules to achieve advantageous efficiency and accuracy trade-offs, limiting their more comprehensive practical applications and achievable performance. To this end, we propose LDP, a Learnable Dynamic Precision DNN training framework that can automatically learn a temporally and spatially dynamic precision schedule during training towards optimal accuracy and efficiency trade-offs. It is worth noting that LDP-trained DNNs are by nature efficient during inference. Furthermore, we visualize the resulting temporal and spatial precision schedule and distribution of LDP trained DNNs on different tasks to better understand the corresponding DNNs' characteristics at different training stages and DNN layers both during and after training, drawing insights for promoting further innovations. Extensive experiments and ablation studies (seven networks, five datasets, and three tasks) show that the proposed LDP consistently outperforms state-of-the-art (SOTA) low precision DNN training techniques in terms of training efficiency and achieved accuracy trade-offs. For example, in addition to having the advantage of being automated, our LDP achieves a 0.31\\% higher accuracy with a 39.1\\% lower computational cost when training ResNet-20 on CIFAR-10 as compared with the best SOTA method. ",
    "url": "https://arxiv.org/abs/2203.07713",
    "authors": [
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Shang Wu",
      "Mengquan Li",
      "Haoran You",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07722",
    "title": "ReACC: A Retrieval-Augmented Code Completion Framework",
    "abstract": "Code completion, which aims to predict the following code token(s) according to the code context, can improve the productivity of software development. Recent work has proved that statistical language modeling with transformers can greatly improve the performance in the code completion task via learning from large-scale source code datasets. However, current approaches focus only on code context within the file or project, i.e. internal context. Our distinction is utilizing \"external\" context, inspired by human behaviors of copying from the related code snippets when writing code. Specifically, we propose a retrieval-augmented code completion framework, leveraging both lexical copying and referring to code with similar semantics by retrieval. We adopt a stage-wise training approach that combines a source code retriever and an auto-regressive language model for programming language. We evaluate our approach in the code completion task in Python and Java programming languages, achieving a state-of-the-art performance on CodeXGLUE benchmark. ",
    "url": "https://arxiv.org/abs/2203.07722",
    "authors": [
      "Shuai Lu",
      "Nan Duan",
      "Hojae Han",
      "Daya Guo",
      "Seung-won Hwang",
      "Alexey Svyatkovskiy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07724",
    "title": "CODA: A Real-World Road Corner Case Dataset for Object Detection in  Autonomous Driving",
    "abstract": "Contemporary deep-learning object detection methods for autonomous driving usually assume prefixed categories of common traffic participants, such as pedestrians and cars. Most existing detectors are unable to detect uncommon objects and corner cases (e.g., a dog crossing a street), which may lead to severe accidents in some situations, making the timeline for the real-world application of reliable autonomous driving uncertain. One main reason that impedes the development of truly reliably self-driving systems is the lack of public datasets for evaluating the performance of object detectors on corner cases. Hence, we introduce a challenging dataset named CODA that exposes this critical problem of vision-based detectors. The dataset consists of 1500 carefully selected real-world driving scenes, each containing four object-level corner cases (on average), spanning 30+ object categories. On CODA, the performance of standard object detectors trained on large-scale autonomous driving datasets significantly drops to no more than 12.8% in mAR. Moreover, we experiment with the state-of-the-art open-world object detector and find that it also fails to reliably identify the novel objects in CODA, suggesting that a robust perception system for autonomous driving is probably still far from reach. We expect our CODA dataset to facilitate further research in reliable detection for real-world autonomous driving. Our dataset will be released at https://coda-dataset.github.io. ",
    "url": "https://arxiv.org/abs/2203.07724",
    "authors": [
      "Kaican Li",
      "Kai Chen",
      "Haoyu Wang",
      "Lanqing Hong",
      "Chaoqiang Ye",
      "Jianhua Han",
      "Yukuai Chen",
      "Wei Zhang",
      "Chunjing Xu",
      "Dit-Yan Yeung",
      "Xiaodan Liang",
      "Zhenguo Li",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.07732",
    "title": "S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular  Image",
    "abstract": "We present a novel face reconstruction method capable of reconstructing detailed face geometry, spatially varying face reflectance from a single monocular image. We build our work upon the recent advances of DNN-based auto-encoders with differentiable ray tracing image formation, trained in self-supervised manner. While providing the advantage of learning-based approaches and real-time reconstruction, the latter methods lacked fidelity. In this work, we achieve, for the first time, high fidelity face reconstruction using self-supervised learning only. Our novel coarse-to-fine deep architecture allows us to solve the challenging problem of decoupling face reflectance from geometry using a single image, at high computational speed. Compared to state-of-the-art methods, our method achieves more visually appealing reconstruction. ",
    "url": "https://arxiv.org/abs/2203.07732",
    "authors": [
      "Abdallah Dib",
      "Junghyun Ahn",
      "Cedric Thebault",
      "Philippe-Henri Gosselin",
      "Louis Chevallier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07736",
    "title": "CSRS: Code Search with Relevance Matching and Semantic Matching",
    "abstract": "Developers often search and reuse existing code snippets in the process of software development. Code search aims to retrieve relevant code snippets from a codebase according to natural language queries entered by the developer. Up to now, researchers have already proposed information retrieval (IR) based methods and deep learning (DL) based methods. The IR-based methods focus on keyword matching, that is to rank codes by relevance between queries and code snippets, while DL-based methods focus on capturing the semantic correlations. However, the existing methods rarely consider capturing two matching signals simultaneously. Therefore, in this paper, we propose CSRS, a code search model with relevance matching and semantic matching. CSRS comprises (1) an embedding module containing convolution kernels of different sizes which can extract n-gram embeddings of queries and codes, (2) a relevance matching module that measures lexical matching signals, and (3) a co-attention based semantic matching module to capture the semantic correlation. We train and evaluate CSRS on a dataset with 18.22M and 10k code snippets. The experimental results demonstrate that CSRS achieves an MRR of 0.614, which outperforms two state-of-the-art models DeepCS and CARLCS-CNN by 33.77% and 18.53% respectively. In addition, we also conducted several experiments to prove the effectiveness of each component of CSRS. ",
    "url": "https://arxiv.org/abs/2203.07736",
    "authors": [
      "Yi Cheng",
      "Li Kuang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.07737",
    "title": "An Annotation-free Restoration Network for Cataractous Fundus Images",
    "abstract": "Cataracts are the leading cause of vision loss worldwide. Restoration algorithms are developed to improve the readability of cataract fundus images in order to increase the certainty in diagnosis and treatment for cataract patients. Unfortunately, the requirement of annotation limits the application of these algorithms in clinics. This paper proposes a network to annotation-freely restore cataractous fundus images (ArcNet) so as to boost the clinical practicability of restoration. Annotations are unnecessary in ArcNet, where the high-frequency component is extracted from fundus images to replace segmentation in the preservation of retinal structures. The restoration model is learned from the synthesized images and adapted to real cataract images. Extensive experiments are implemented to verify the performance and effectiveness of ArcNet. Favorable performance is achieved using ArcNet against state-of-the-art algorithms, and the diagnosis of ocular fundus diseases in cataract patients is promoted by ArcNet. The capability of properly restoring cataractous images in the absence of annotated data promises the proposed algorithm outstanding clinical practicability. ",
    "url": "https://arxiv.org/abs/2203.07737",
    "authors": [
      "Heng Li",
      "Haofeng Liu",
      "Yan Hu",
      "Huazhu Fu",
      "Yitian Zhao",
      "Hanpei Miao",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07738",
    "title": "CSN: Component-Supervised Network for Few-Shot Classification",
    "abstract": "The few-shot classification (FSC) task has been a hot research topic in recent years. It aims to address the classification problem with insufficient labeled data on a cross-category basis. Typically, researchers pre-train a feature extractor with base data, then use it to extract the features of novel data and recognize them. Notably, the novel set only has a few annotated samples and has entirely different categories from the base set, which leads to that the pre-trained feature extractor can not adapt to the novel data flawlessly. We dub this problem as Feature-Extractor-Maladaptive (FEM) problem. Starting from the root cause of this problem, this paper presents a new scheme, Component-Supervised Network (CSN), to improve the performance of FSC. We believe that although the categories of base and novel sets are different, the composition of the sample's components is similar. For example, both cat and dog contain leg and head components. Actually, such entity components are intra-class stable. They have fine cross-category versatility and new category generalization. Therefore, we refer to WordNet, a dictionary commonly used in natural language processing, to collect component information of samples and construct a component-based auxiliary task to improve the adaptability of the feature extractor. We conduct experiments on two benchmark datasets (mini-ImageNet and tiered-ImageNet), the improvements of $0.9\\%$-$5.8\\%$ compared with state-of-the-arts have evaluated the efficiency of our CSN. ",
    "url": "https://arxiv.org/abs/2203.07738",
    "authors": [
      "Shuai Shao",
      "Baodi Liu",
      "Lei Xing",
      "Lifei Zhao",
      "Yanjiang Wang",
      "Weifeng Liu",
      "Yicong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07777",
    "title": "Social Choice Around the Block: On the Computational Social Choice of  Blockchain",
    "abstract": "One of the most innovative aspects of blockchain technology consists in the introduction of an incentive layer to regulate the behavior of distributed protocols. The designer of a blockchain system faces therefore issues that are akin to those relevant for the design of economic mechanisms, and faces them in a computational setting. From this perspective the present paper argues for the importance of computational social choice in blockchain research. It identifies a few challenges at the interface of the two fields that illustrate the strong potential for cross-fertilization between them. ",
    "url": "https://arxiv.org/abs/2203.07777",
    "authors": [
      "Davide Grossi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07782",
    "title": "Complex Evolutional Pattern Learning for Temporal Knowledge Graph  Reasoning",
    "abstract": "A Temporal Knowledge Graph (TKG) is a sequence of KGs corresponding to different timestamps. TKG reasoning aims to predict potential facts in the future given the historical KG sequences. One key of this task is to mine and understand evolutional patterns of facts from these sequences. The evolutional patterns are complex in two aspects, length-diversity and time-variability. Existing models for TKG reasoning focus on modeling fact sequences of a fixed length, which cannot discover complex evolutional patterns that vary in length. Furthermore, these models are all trained offline, which cannot well adapt to the changes of evolutional patterns from then on. Thus, we propose a new model, called Complex Evolutional Network (CEN), which uses a length-aware Convolutional Neural Network (CNN) to handle evolutional patterns of different lengths via an easy-to-difficult curriculum learning strategy. Besides, we propose to learn the model under the online setting so that it can adapt to the changes of evolutional patterns over time. Extensive experiments demonstrate that CEN obtains substantial performance improvement under both the traditional offline and the proposed online settings. ",
    "url": "https://arxiv.org/abs/2203.07782",
    "authors": [
      "Zixuan Li",
      "Saiping Guan",
      "Xiaolong Jin",
      "Weihua Peng",
      "Yajuan Lyu",
      "Yong Zhu",
      "Long Bai",
      "Wei Li",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07788",
    "title": "Scalable Penalized Regression for Noise Detection in Learning with Noisy  Labels",
    "abstract": "Noisy training set usually leads to the degradation of generalization and robustness of neural networks. In this paper, we propose using a theoretically guaranteed noisy label detection framework to detect and remove noisy data for Learning with Noisy Labels (LNL). Specifically, we design a penalized regression to model the linear relation between network features and one-hot labels, where the noisy data are identified by the non-zero mean shift parameters solved in the regression model. To make the framework scalable to datasets that contain a large number of categories and training data, we propose a split algorithm to divide the whole training set into small pieces that can be solved by the penalized regression in parallel, leading to the Scalable Penalized Regression (SPR) framework. We provide the non-asymptotic probabilistic condition for SPR to correctly identify the noisy data. While SPR can be regarded as a sample selection module for standard supervised training pipeline, we further combine it with semi-supervised algorithm to further exploit the support of noisy data as unlabeled data. Experimental results on several benchmark datasets and real-world noisy datasets show the effectiveness of our framework. Our code and pretrained models are released at https://github.com/Yikai-Wang/SPR-LNL. ",
    "url": "https://arxiv.org/abs/2203.07788",
    "authors": [
      "Yikai Wang",
      "Xinwei Sun",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07802",
    "title": "A Framework for Verifiable and Auditable Federated Anomaly Detection",
    "abstract": "Federated Leaning is an emerging approach to manage cooperation between a group of agents for the solution of Machine Learning tasks, with the goal of improving each agent's performance without disclosing any data. In this paper we present a novel algorithmic architecture that tackle this problem in the particular case of Anomaly Detection (or classification or rare events), a setting where typical applications often comprise data with sensible information, but where the scarcity of anomalous examples encourages collaboration. We show how Random Forests can be used as a tool for the development of accurate classifiers with an effective insight-sharing mechanism that does not break the data integrity. Moreover, we explain how the new architecture can be readily integrated in a blockchain infrastructure to ensure the verifiable and auditable execution of the algorithm. Furthermore, we discuss how this work may set the basis for a more general approach for the design of federated ensemble-learning methods beyond the specific task and architecture discussed in this paper. ",
    "url": "https://arxiv.org/abs/2203.07802",
    "authors": [
      "Gabriele Santin",
      "Inna Skarbovsky",
      "Fabiana Fournier",
      "Bruno Lepri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.07814",
    "title": "Competition-Level Code Generation with AlphaCode",
    "abstract": "Programming is a powerful and ubiquitous problem-solving tool. Developing systems that can assist programmers or even generate programs independently could make programming more productive and accessible, yet so far incorporating innovations in AI has proven challenging. Recent large-scale language models have demonstrated an impressive ability to generate code, and are now able to complete simple programming tasks. However, these models still perform poorly when evaluated on more complex, unseen problems that require problem-solving skills beyond simply translating instructions into code. For example, competitive programming problems which require an understanding of algorithms and complex natural language remain extremely challenging. To address this gap, we introduce AlphaCode, a system for code generation that can create novel solutions to these problems that require deeper reasoning. In simulated evaluations on recent programming competitions on the Codeforces platform, AlphaCode achieved on average a ranking of top 54.3% in competitions with more than 5,000 participants. We found that three key components were critical to achieve good and reliable performance: (1) an extensive and clean competitive programming dataset for training and evaluation, (2) large and efficient-to-sample transformer-based architectures, and (3) large-scale model sampling to explore the search space, followed by filtering based on program behavior to a small set of submissions. ",
    "url": "https://arxiv.org/abs/2203.07814",
    "authors": [
      "Yujia Li",
      "David Choi",
      "Junyoung Chung",
      "Nate Kushman",
      "Julian Schrittwieser",
      "R\u00e9mi Leblond",
      "Tom Eccles",
      "James Keeling",
      "Felix Gimeno",
      "Agustin Dal Lago",
      "Thomas Hubert",
      "Peter Choy",
      "Cyprien de Masson d'Autume",
      "Igor Babuschkin",
      "Xinyun Chen",
      "Po-Sen Huang",
      "Johannes Welbl",
      "Sven Gowal",
      "Alexey Cherepanov",
      "James Molloy",
      "Daniel J. Mankowitz",
      "Esme Sutherland Robson",
      "Pushmeet Kohli",
      "Nando de Freitas",
      "Koray Kavukcuoglu",
      "Oriol Vinyals"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07815",
    "title": "Adversarial Counterfactual Augmentation: Application in Alzheimer's  Disease Classification",
    "abstract": "Data augmentation has been widely used in deep learning to reduce over-fitting and improve the robustness of models. However, traditional data augmentation techniques, e.g., rotation, cropping, flipping, etc., do not consider \\textit{semantic} transformations, e.g., changing the age of a brain image. Previous works tried to achieve semantic augmentation by generating \\textit{counterfactuals}, but they focused on how to train deep generative models and randomly created counterfactuals with the generative models without considering which counterfactuals are most \\textit{effective} for improving downstream training. Different from these approaches, in this work, we propose a novel adversarial counterfactual augmentation scheme that aims to find the most \\textit{effective} counterfactuals to improve downstream tasks with a pre-trained generative model. Specifically, we construct an adversarial game where we update the input \\textit{conditional factor} of the generator and the downstream \\textit{classifier} with gradient backpropagation alternatively and iteratively. The key idea is to find conditional factors that can result in \\textit{hard} counterfactuals for the classifier. This can be viewed as finding the `\\textit{weakness}' of the classifier and purposely forcing it to \\textit{overcome} its weakness via the generative model. To demonstrate the effectiveness of the proposed approach, we validate the method with the classification of Alzheimer's Disease (AD) as the downstream task based on a pre-trained brain ageing synthesis model. We show the proposed approach improves test accuracy and can alleviate spurious correlations. Code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2203.07815",
    "authors": [
      "Tian Xia",
      "Pedro Sanchez",
      "Chen Qin",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07824",
    "title": "SISL:Self-Supervised Image Signature Learning for Splicing Detection and  Localization",
    "abstract": "Recent algorithms for image manipulation detection almost exclusively use deep network models. These approaches require either dense pixelwise groundtruth masks, camera ids, or image metadata to train the networks. On one hand, constructing a training set to represent the countless tampering possibilities is impractical. On the other hand, social media platforms or commercial applications are often constrained to remove camera ids as well as metadata from images. A self-supervised algorithm for training manipulation detection models without dense groundtruth or camera/image metadata would be extremely useful for many forensics applications. In this paper, we propose self-supervised approach for training splicing detection/localization models from frequency transforms of images. To identify the spliced regions, our deep network learns a representation to capture an image specific signature by enforcing (image) self consistency . We experimentally demonstrate that our proposed model can yield similar or better performances of multiple existing methods on standard datasets without relying on labels or metadata. ",
    "url": "https://arxiv.org/abs/2203.07824",
    "authors": [
      "Susmit Agrawal",
      "Prabhat Kumar",
      "Siddharth Seth",
      "Toufiq Parag",
      "Maneesh Singh",
      "Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": "Abstract meaning representation (AMR) highlights the core semantic information of text in a graph structure. Recently, pre-trained language models (PLMs) have advanced tasks of AMR parsing and AMR-to-text generation, respectively. However, PLMs are typically pre-trained on textual data, thus are sub-optimal for modeling structural knowledge. To this end, we investigate graph self-supervised training to improve the structure awareness of PLMs over AMR graphs. In particular, we introduce two graph auto-encoding strategies for graph-to-graph pre-training and four tasks to integrate text and graph information during pre-training. We further design a unified framework to bridge the gap between pre-training and fine-tuning tasks. Experiments on both AMR parsing and AMR-to-text generation show the superiority of our model. To our knowledge, we are the first to consider pre-training on semantic graphs. ",
    "url": "https://arxiv.org/abs/2203.07836",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07843",
    "title": "Locally refined quad meshing for linear elasticity problems based on  convolutional neural networks",
    "abstract": "In this paper we propose a method to generate suitably refined finite element meshes using neural networks. As a model problem we consider a linear elasticity problem on a planar domain (possibly with holes) having a polygonal boundary. We impose boundary conditions by fixing the position of a part of the boundary and applying a force on another part of the boundary. The resulting displacement and distribution of stresses depend on the geometry of the domain and on the boundary conditions. When applying a standard Galerkin discretization using quadrilateral finite elements, one usually has to perform adaptive refinement to properly resolve maxima of the stress distribution. Such an adaptive scheme requires a local error estimator and a corresponding local refinement strategy. The overall costs of such a strategy are high. We propose to reduce the costs of obtaining a suitable discretization by training a neural network whose evaluation replaces this adaptive refinement procedure. We set up a single network for a large class of possible domains and boundary conditions and not on a single domain of interest. The computational domain and boundary conditions are interpreted as images, which are suitable inputs for convolution neural networks. We use the U-net architecture and we devise training strategies by dividing the possible inputs into different categories based on their overall geometric complexity. Thus, we compare different training strategies based on varying geometric complexity. One of the advantages of the proposed approach is the interpretation of input and output as images, which do not depend on the underlying discretization scheme. Another is the generalizability and geometric flexibility. The network can be applied to previously unseen geometries, even with different topology and level of detail. Thus, training can easily be extended to other classes of geometries. ",
    "url": "https://arxiv.org/abs/2203.07843",
    "authors": [
      "Chiu Ling Chan",
      "Felix Scholz",
      "Thomas Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.07860",
    "title": "Imputing Out-of-Vocabulary Embeddings with LOVE Makes Language Models  Robust with Little Cost",
    "abstract": "State-of-the-art NLP systems represent inputs with word embeddings, but these are brittle when faced with Out-of-Vocabulary (OOV) words. To address this issue, we follow the principle of mimick-like models to generate vectors for unseen words, by learning the behavior of pre-trained embeddings using only the surface form of words. We present a simple contrastive learning framework, LOVE, which extends the word representation of an existing pre-trained language model (such as BERT), and makes it robust to OOV with few additional parameters. Extensive evaluations demonstrate that our lightweight model achieves similar or even better performances than prior competitors, both on original datasets and on corrupted variants. Moreover, it can be used in a plug-and-play fashion with FastText and BERT, where it significantly improves their robustness. ",
    "url": "https://arxiv.org/abs/2203.07860",
    "authors": [
      "Lihu Chen",
      "Ga\u00ebl Varoquaux",
      "Fabian M. Suchanek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.07895",
    "title": "Simulating Liquids with Graph Networks",
    "abstract": "Simulating complex dynamics like fluids with traditional simulators is computationally challenging. Deep learning models have been proposed as an efficient alternative, extending or replacing parts of traditional simulators. We investigate graph neural networks (GNNs) for learning fluid dynamics and find that their generalization capability is more limited than previous works would suggest. We also challenge the current practice of adding random noise to the network inputs in order to improve its generalization capability and simulation stability. We find that inserting the real data distribution, e.g. by unrolling multiple simulation steps, improves accuracy and that hiding all domain-specific features from the learning model improves generalization. Our results indicate that learning models, such as GNNs, fail to learn the exact underlying dynamics unless the training set is devoid of any other problem-specific correlations that could be used as shortcuts. ",
    "url": "https://arxiv.org/abs/2203.07895",
    "authors": [
      "Jonathan Klimesch",
      "Philipp Holl",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2203.07897",
    "title": "Magnetic Field Prediction Using Generative Adversarial Networks",
    "abstract": "Plenty of scientific and real-world applications are built on magnetic fields and their characteristics. To retrieve the valuable magnetic field information in high resolution, extensive field measurements are required, which are either time-consuming to conduct or even not feasible due to physical constraints. To alleviate this problem, we predict magnetic field values at a random point in space from a few point measurements by using a generative adversarial network (GAN) structure. The deep learning (DL) architecture consists of two neural networks: a generator, which predicts missing field values of a given magnetic field, and a critic, which is trained to calculate the statistical distance between real and generated magnetic field distributions. By minimizing this statistical distance, a reconstruction loss as well as physical losses, our trained generator has learned to predict the missing field values with a median reconstruction test error of 5.14%, when a single coherent region of field points is missing, and 5.86%, when only a few point measurements in space are available and the field measurements around are predicted. We verify the results on an experimentally validated field. ",
    "url": "https://arxiv.org/abs/2203.07897",
    "authors": [
      "Stefan Pollok",
      "Nataniel Olden-J\u00f8rgensen",
      "Peter Stanley J\u00f8rgensen",
      "Rasmus Bj\u00f8rk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.07910",
    "title": "Deep Transfer Learning with Graph Neural Network for Sensor-Based Human  Activity Recognition",
    "abstract": "The sensor-based human activity recognition (HAR) in mobile application scenarios is often confronted with sensor modalities variation and annotated data deficiency. Given this observation, we devised a graph-inspired deep learning approach toward the sensor-based HAR tasks, which was further used to build a deep transfer learning model toward giving a tentative solution for these two challenging problems. Specifically, we present a multi-layer residual structure involved graph convolutional neural network (ResGCNN) toward the sensor-based HAR tasks, namely the HAR-ResGCNN approach. Experimental results on the PAMAP2 and mHealth data sets demonstrate that our ResGCNN is effective at capturing the characteristics of actions with comparable results compared to other sensor-based HAR models (with an average accuracy of 98.18% and 99.07%, respectively). More importantly, the deep transfer learning experiments using the ResGCNN model show excellent transferability and few-shot learning performance. The graph-based framework shows good meta-learning ability and is supposed to be a promising solution in sensor-based HAR tasks. ",
    "url": "https://arxiv.org/abs/2203.07910",
    "authors": [
      "Yan Yan",
      "Tianzheng Liao",
      "Jinjin Zhao",
      "Jiahong Wang",
      "Liang Ma",
      "Wei Lv",
      "Jing Xiong",
      "Lei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07933",
    "title": "Threat Detection for General Social Engineering Attack Using Machine  Learning Techniques",
    "abstract": "This paper explores the threat detection for general social engineering (SE) attack using machine learning (ML) techniques, rather than focusing on or limited to a specific SE attack type, e.g. email phishing. Firstly, this paper processes and obtains more SE threat data from the previous knowledge graph, and then extracts different threat features and generates new datasets corresponding with three different feature combinations. Finally, 9 types of ML models are created and trained using the three datasets, respectively, and their performance are compared and analyzed with 27 threat detectors/classifiers and 270 experiments. The experimental results and analysis show that: 1) the ML techniques is feasible in detecting general SE attack threat and some ML models are quite effective; ML-based SE threat detection is complementary with knowledge graph-based approaches; 2) the generated datasets are usable; the SE domain ontology proposed in previous work can dissect SE attacks and deliver the SE threat features, allowing it to be used as a data model for future research. Besides, many conclusions and analyses about the characteristics of different ML models and the datasets are discussed. ",
    "url": "https://arxiv.org/abs/2203.07933",
    "authors": [
      "Zuoguang Wang",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07941",
    "title": "Reachability In Simple Neural Networks",
    "abstract": "We investigate the complexity of the reachability problem for (deep) neural networks: does it compute valid output given some valid input? It was recently claimed that the problem is NP-complete for general neural networks and specifications over the input/output dimension given by conjunctions of linear inequalities. We recapitulate the proof and repair some flaws in the original upper and lower bound proofs. Motivated by the general result, we show that NP-hardness already holds for restricted classes of simple specifications and neural networks. Allowing for a single hidden layer and an output dimension of one as well as neural networks with just one negative, zero and one positive weight or bias is sufficient to ensure NP-hardness. Additionally, we give a thorough discussion and outlook of possible extensions for this direction of research on neural network verification. ",
    "url": "https://arxiv.org/abs/2203.07941",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07947",
    "title": "NINNs: Nudging Induced Neural Networks",
    "abstract": "New algorithms called nudging induced neural networks (NINNs), to control and improve the accuracy of deep neural networks (DNNs), are introduced. The NINNs framework can be applied to almost all pre-existing DNNs, with forward propagation, with costs comparable to existing DNNs. NINNs work by adding a feedback control term to the forward propagation of the network. The feedback term nudges the neural network towards a desired quantity of interest. NINNs offer multiple advantages, for instance, they lead to higher accuracy when compared with existing data assimilation algorithms such as nudging. Rigorous convergence analysis is established for NINNs. The algorithmic and theoretical findings are illustrated on examples from data assimilation and chemically reacting flows. ",
    "url": "https://arxiv.org/abs/2203.07947",
    "authors": [
      "Harbir Antil",
      "Rainald L\u00f6hner",
      "Randy Price"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.07967",
    "title": "Intrinsic Neural Fields: Learning Functions on Manifolds",
    "abstract": "Neural fields have gained significant attention in the computer vision community due to their excellent performance in novel view synthesis, geometry reconstruction, and generative modeling. Some of their advantages are a sound theoretic foundation and an easy implementation in current deep learning frameworks. While neural fields have been applied to signals on manifolds, e.g., for texture reconstruction, their representation has been limited to extrinsically embedding the shape into Euclidean space. The extrinsic embedding ignores known intrinsic manifold properties and is inflexible wrt. transfer of the learned function. To overcome these limitations, this work introduces intrinsic neural fields, a novel and versatile representation for neural fields on manifolds. Intrinsic neural fields combine the advantages of neural fields with the spectral properties of the Laplace-Beltrami operator. We show theoretically that intrinsic neural fields inherit many desirable properties of the extrinsic neural field framework but exhibit additional intrinsic qualities, like isometry invariance. In experiments, we show intrinsic neural fields can reconstruct high-fidelity textures from images with state-of-the-art quality and are robust to the discretization of the underlying manifold. We demonstrate the versatility of intrinsic neural fields by tackling various applications: texture transfer between deformed shapes & different shapes, texture reconstruction from real-world images with view dependence, and discretization-agnostic learning on meshes and point clouds. ",
    "url": "https://arxiv.org/abs/2203.07967",
    "authors": [
      "Lukas Koestler",
      "Daniel Grittner",
      "Michael Moeller",
      "Daniel Cremers",
      "Zorah L\u00e4hner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07969",
    "title": "PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network  Resolutions for Graph Learning",
    "abstract": "In order to advance the state of the art in graph learning algorithms, it is necessary to construct large real-world datasets. While there are many benchmark datasets for homogeneous graphs, only a few of them are available for heterogeneous graphs. Furthermore, the latter graphs are small in size rendering them insufficient to understand how graph learning algorithms perform in terms of classification metrics and computational resource utilization. We introduce, PDNS-Net, the largest public heterogeneous graph dataset containing 447K nodes and 897K edges for the malicious domain classification task. Compared to the popular heterogeneous datasets IMDB and DBLP, PDNS-Net is 38 and 17 times bigger respectively. We provide a detailed analysis of PDNS-Net including the data collection methodology, heterogeneous graph construction, descriptive statistics and preliminary graph classification performance. The dataset is publicly available at https://github.com/qcri/PDNS-Net. Our preliminary evaluation of both popular homogeneous and heterogeneous graph neural networks on PDNS-Net reveals that further research is required to improve the performance of these models on large heterogeneous graphs. ",
    "url": "https://arxiv.org/abs/2203.07969",
    "authors": [
      "Udesh Kumarasinghe",
      "Fatih Deniz",
      "Mohamed Nabeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.07975",
    "title": "Categorical Representation Learning and RG flow operators for  algorithmic classifiers",
    "abstract": "Following the earlier formalism of the categorical representation learning (arXiv:2103.14770) by the first two authors, we discuss the construction of the \"RG-flow based categorifier\". Borrowing ideas from theory of renormalization group flows (RG) in quantum field theory, holographic duality, and hyperbolic geometry, and mixing them with neural ODE's, we construct a new algorithmic natural language processing (NLP) architecture, called the RG-flow categorifier or for short the RG categorifier, which is capable of data classification and generation in all layers. We apply our algorithmic platform to biomedical data sets and show its performance in the field of sequence-to-function mapping. In particular we apply the RG categorifier to particular genomic sequences of flu viruses and show how our technology is capable of extracting the information from given genomic sequences, find their hidden symmetries and dominant features, classify them and use the trained data to make stochastic prediction of new plausible generated sequences associated with new set of viruses which could avoid the human immune system. The content of the current article is part of the recent US patent application submitted by first two authors (U.S. Patent Application No.: 63/313.504). ",
    "url": "https://arxiv.org/abs/2203.07975",
    "authors": [
      "Artan Sheshmani",
      "Yizhuang You",
      "Wenbo Fu",
      "Ahmadreza Azizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Geometry (math.AG)",
      "Category Theory (math.CT)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2203.07980",
    "title": "Object Detection as Probabilistic Set Prediction",
    "abstract": "Accurate uncertainty estimates are essential for deploying deep object detectors in safety-critical systems. The development and evaluation of probabilistic object detectors have been hindered by shortcomings in existing performance measures, which tend to involve arbitrary thresholds or limit the detector's choice of distributions. In this work, we propose to view object detection as a set prediction task where detectors predict the distribution over the set of objects. Using the negative log-likelihood for random finite sets, we present a proper scoring rule for evaluating and training probabilistic object detectors. The proposed method can be applied to existing probabilistic detectors, is free from thresholds, and enables fair comparison between architectures. Three different types of detectors are evaluated on the COCO dataset. Our results indicate that the training of existing detectors is optimized toward non-probabilistic metrics. We hope to encourage the development of new object detectors that can accurately estimate their own uncertainty. Code will be released. ",
    "url": "https://arxiv.org/abs/2203.07980",
    "authors": [
      "Georg Hess",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07983",
    "title": "Adversarial Robustness of Neural-Statistical Features in Detection of  Generative Transformers",
    "abstract": "The detection of computer-generated text is an area of rapidly increasing significance as nascent generative models allow for efficient creation of compelling human-like text, which may be abused for the purposes of spam, disinformation, phishing, or online influence campaigns. Past work has studied detection of current state-of-the-art models, but despite a developing threat landscape, there has been minimal analysis of the robustness of detection methods to adversarial attacks. To this end, we evaluate neural and non-neural approaches on their ability to detect computer-generated text, their robustness against text adversarial attacks, and the impact that successful adversarial attacks have on human judgement of text quality. We find that while statistical features underperform neural features, statistical features provide additional adversarial robustness that can be leveraged in ensemble detection models. In the process, we find that previously effective complex phrasal features for detection of computer-generated text hold little predictive power against contemporary generative models, and identify promising statistical features to use instead. Finally, we pioneer the usage of $\\Delta$MAUVE as a proxy measure for human judgement of adversarial text quality. ",
    "url": "https://arxiv.org/abs/2203.07983",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor",
      "Paula Branco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07986",
    "title": "Distributed Pinning Set Stabilization of Large-Scale Boolean Networks",
    "abstract": "In this article, we design the distributed pinning controllers to globally stabilize a Boolean network (BN), specially a sparsely connected large-scale one, towards a preassigned subset of state space through the node-to-node message exchange. Given an appointed state set, system nodes are partitioned into two disjoint parts, which respectively gather the nodes whose states are fixed or arbitrary with respect to the given state set. With such node division, three parts of pinned nodes are selected and the state feedback controllers are accordingly designed such that the resulting BN satisfies three conditions: the states of the other nodes cannot affect the nodal dynamics of fixed-state nodes, the subgraph of network structure induced by the fixed-state nodes is acyclic, and the steady state of the subnetwork induced by the fixed-state nodes lies in the state set given beforehand. If the BN after control is acyclic, the stabilizing time is revealed to be no more than the length of the longest path in the current network structure plus one. This enables us to further design the pinning controllers with the constraint of stabilizing time. Noting that the overall procedure runs in an exponentially increasing time with respect to the largest number of functional variables in the dynamics of pinned nodes, the sparsely-connected large-scale BNs can be well addressed in a reasonable amount of time. Finally, we demonstrate the applications of our theoretical results in a T-LGL survival signal network with $29$ nodes and T-cell receptor signaling network with $90$ nodes. ",
    "url": "https://arxiv.org/abs/2203.07986",
    "authors": [
      "Shiyong Zhu",
      "Jianquan Lu",
      "Liangjie Sun",
      "Jinde Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.07993",
    "title": "RotateQVS: Representing Temporal Information as Rotations in Quaternion  Vector Space for Temporal Knowledge Graph Completion",
    "abstract": "Temporal factors are tied to the growth of facts in realistic applications, such as the progress of diseases and the development of political situation, therefore, research on Temporal Knowledge Graph (TKG) attracks much attention. In TKG, relation patterns inherent with temporality are required to be studied for representation learning and reasoning across temporal facts. However, existing methods can hardly model temporal relation patterns, nor can capture the intrinsic connections between relations when evolving over time, lacking of interpretability. In this paper, we propose a novel temporal modeling method which represents temporal entities as Rotations in Quaternion Vector Space (RotateQVS) and relations as complex vectors in Hamilton's quaternion space. We demonstrate our method can model key patterns of relations in TKG, such as symmetry, asymmetry, inverse, and can further capture time-evolved relations by theory. Empirically, we show that our method can boost the performance of link prediction tasks over four temporal knowledge graph benchmarks. ",
    "url": "https://arxiv.org/abs/2203.07993",
    "authors": [
      "Kai Chen",
      "Ye Wang",
      "Yitong Li",
      "Aiping Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.07996",
    "title": "Leveraging Uni-Modal Self-Supervised Learning for Multimodal  Audio-Visual Speech Recognition",
    "abstract": "Training Transformer-based models demands a large amount of data, while obtaining parallel aligned and labelled data in multimodality is rather cost-demanding, especially for audio-visual speech recognition (AVSR). Thus it makes a lot of sense to make use of unlabelled uni-modal data. On the other side, although the effectiveness of large-scale self-supervised learning is well established in both audio and visual modalities, how to integrate those pre-trained models into a multimodal scenario remains underexplored. In this work, we successfully leverage uni-modal self-supervised learning to promote the multimodal AVSR. In particular, we first train audio and visual encoders on a large-scale uni-modal dataset, then we integrate components of both encoders into a larger multimodal framework which learns to recognize paired audio-visual data into characters through a combination of CTC and seq2seq decoding. We show that both components inherited from uni-modal self-supervised learning cooperate well, resulting in that the multimodal framework yields competitive results through fine-tuning. Our model is experimentally validated on both word-level and sentence-level AVSR tasks. Especially, even without an external language model, our proposed model raises the state-of-the-art performances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a large margin, with a relative improvement of 30%. ",
    "url": "https://arxiv.org/abs/2203.07996",
    "authors": [
      "Xichen Pan",
      "Peiyu Chen",
      "Yichen Gong",
      "Helong Zhou",
      "Xinbing Wang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.07999",
    "title": "MSCET: A Multi-Scenario Offloading Schedule for Biomedical Data  Processing and Analysis in Cloud-Edge-Terminal Collaborative Vehicular  Networks",
    "abstract": "With the rapid development of Artificial Intelligence (AI) and Internet of Things (IoTs), an increasing number of computation intensive or delay sensitive biomedical data processing and analysis tasks are produced in vehicles, bringing more and more challenges to the biometric monitoring of drivers. Edge computing is a new paradigm to solve these challenges by offloading tasks from the resource-limited vehicles to Edge Servers (ESs) in Road Side Units (RSUs). However, most of the traditional offloading schedules for vehicular networks concentrate on the edge, while some tasks may be too complex for ESs to process. To this end, we consider a collaborative vehicular network in which the cloud, edge and terminal can cooperate with each other to accomplish the tasks. The vehicles can offload the computation intensive tasks to the cloud to save the resource of edge. We further construct the virtual resource pool which can integrate the resource of multiple ESs since some regions may be covered by multiple RSUs. In this paper, we propose a Multi-Scenario offloading schedule for biomedical data processing and analysis in Cloud-Edge-Terminal collaborative vehicular networks called MSCET. The parameters of the proposed MSCET are optimized to maximize the system utility. We also conduct extensive simulations to evaluate the proposed MSCET and the results illustrate that MSCET outperforms other existing schedules. ",
    "url": "https://arxiv.org/abs/2203.07999",
    "authors": [
      "Zhichen Ni",
      "Honglong Chen",
      "Zhe Li",
      "Xiaomeng Wang",
      "Na Yan",
      "Weifeng Liu",
      "Feng Xia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08031",
    "title": "Data-Efficient Graph Grammar Learning for Molecular Generation",
    "abstract": "The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. This presents a considerable challenge for the deep learning generative models to comprehensively describe the molecular design space. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated in the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only ${\\sim}20$ samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with only $117$ training samples and is competitive against existing methods using $81$k data points. Code is available at https://github.com/gmh14/data_efficient_grammar. ",
    "url": "https://arxiv.org/abs/2203.08031",
    "authors": [
      "Minghao Guo",
      "Veronika Thost",
      "Beichen Li",
      "Payel Das",
      "Jie Chen",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2203.08049",
    "title": "On Hyperbolic Embeddings in 2D Object Detection",
    "abstract": "Object detection, for the most part, has been formulated in the euclidean space, where euclidean or spherical geodesic distances measure the similarity of an image region to an object class prototype. In this work, we study whether a hyperbolic geometry better matches the underlying structure of the object classification space. We incorporate a hyperbolic classifier in two-stage, keypoint-based, and transformer-based object detection architectures and evaluate them on large-scale, long-tailed, and zero-shot object detection benchmarks. In our extensive experimental evaluations, we observe categorical class hierarchies emerging in the structure of the classification space, resulting in lower classification errors and boosting the overall object detection performance. ",
    "url": "https://arxiv.org/abs/2203.08049",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08073",
    "title": "Can A Neural Network Hear the Shape of A Drum?",
    "abstract": "We have developed a deep neural network that reconstructs the shape of a polygonal domain given the first hundred of its Laplacian (or Schrodinger) eigenvalues. Having an encoder-decoder structure, the network maps input spectra to a latent space and then predicts the discretized image of the domain on a square grid. We tested this network on randomly generated pentagons. The prediction accuracy is high and the predictions obey the Laplacian scaling rule. The network recovers the continuous rotational degree of freedom beyond the symmetry of the grid. The variation of the latent variables under the scaling transformation shows they are strongly correlated with Weyl' s parameters (area, perimeter, and a certain function of the angles) of the test polygons. ",
    "url": "https://arxiv.org/abs/2203.08073",
    "authors": [
      "Yueqi Zhao",
      "Michael M. Fogler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2203.08085",
    "title": "Measuring the Impact of (Psycho-)Linguistic and Readability Features and  Their Spill Over Effects on the Prediction of Eye Movement Patterns",
    "abstract": "There is a growing interest in the combined use of NLP and machine learning methods to predict gaze patterns during naturalistic reading. While promising results have been obtained through the use of transformer-based language models, little work has been undertaken to relate the performance of such models to general text characteristics. In this paper we report on experiments with two eye-tracking corpora of naturalistic reading and two language models (BERT and GPT-2). In all experiments, we test effects of a broad spectrum of features for predicting human reading behavior that fall into five categories (syntactic complexity, lexical richness, register-based multiword combinations, readability and psycholinguistic word properties). Our experiments show that both the features included and the architecture of the transformer-based language models play a role in predicting multiple eye-tracking measures during naturalistic reading. We also report the results of experiments aimed at determining the relative importance of features from different groups using SP-LIME. ",
    "url": "https://arxiv.org/abs/2203.08085",
    "authors": [
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz",
      "Justus Mattern"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08118",
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "abstract": "State-of-the-art keyphrase generation methods generally depend on large annotated datasets, limiting their performance in domains with constrained resources. To overcome this challenge, we investigate strategies to learn an intermediate representation suitable for the keyphrase generation task. We introduce salient span recovery and salient span prediction as guided denoising language modeling objectives that condense the domain-specific knowledge essential for keyphrase generation. Through experiments on multiple scientific keyphrase generation benchmarks, we show the effectiveness of the proposed approach for facilitating low-resource and zero-shot keyphrase generation. Furthermore, we observe that our method especially benefits the generation of absent keyphrases, approaching the performance of SOTA methods trained with large training sets. ",
    "url": "https://arxiv.org/abs/2203.08118",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08122",
    "title": "From 2D to 3D: Re-thinking Benchmarking of Monocular Depth Prediction",
    "abstract": "There have been numerous recently proposed methods for monocular depth prediction (MDP) coupled with the equally rapid evolution of benchmarking tools. However, we argue that MDP is currently witnessing benchmark over-fitting and relying on metrics that are only partially helpful to gauge the usefulness of the predictions for 3D applications. This limits the design and development of novel methods that are truly aware of - and improving towards estimating - the 3D structure of the scene rather than optimizing 2D-based distances. In this work, we aim to bring structural awareness to MDP, an inherently 3D task, by exhibiting the limits of evaluation metrics towards assessing the quality of the 3D geometry. We propose a set of metrics well suited to evaluate the 3D geometry of MDP approaches and a novel indoor benchmark, RIO-D3D, crucial for the proposed evaluation methodology. Our benchmark is based on a real-world dataset featuring high-quality rendered depth maps obtained from RGB-D reconstructions. We further demonstrate this to help benchmark the closely-tied task of 3D scene completion. ",
    "url": "https://arxiv.org/abs/2203.08122",
    "authors": [
      "Evin P\u0131nar \u00d6rnek",
      "Shristi Mudgal",
      "Johanna Wald",
      "Yida Wang",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08124",
    "title": "Can Neural Nets Learn the Same Model Twice? Investigating  Reproducibility and Double Descent from the Decision Boundary Perspective",
    "abstract": "We discuss methods for visualizing neural network decision boundaries and decision regions. We use these visualizations to investigate issues related to reproducibility and generalization in neural network training. We observe that changes in model architecture (and its associate inductive bias) cause visible changes in decision boundaries, while multiple runs with the same architecture yield results with strong similarities, especially in the case of wide architectures. We also use decision boundary methods to visualize double descent phenomena. We see that decision boundary reproducibility depends strongly on model width. Near the threshold of interpolation, neural network decision boundaries become fragmented into many small decision regions, and these regions are non-reproducible. Meanwhile, very narrows and very wide networks have high levels of reproducibility in their decision boundaries with relatively few decision regions. We discuss how our observations relate to the theory of double descent phenomena in convex models. Code is available at https://github.com/somepago/dbViz ",
    "url": "https://arxiv.org/abs/2203.08124",
    "authors": [
      "Gowthami Somepalli",
      "Liam Fowl",
      "Arpit Bansal",
      "Ping Yeh-Chiang",
      "Yehuda Dar",
      "Richard Baraniuk",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08130",
    "title": "One Network Doesn't Rule Them All: Moving Beyond Handcrafted  Architectures in Self-Supervised Learning",
    "abstract": "The current literature on self-supervised learning (SSL) focuses on developing learning objectives to train neural networks more effectively on unlabeled data. The typical development process involves taking well-established architectures, e.g., ResNet demonstrated on ImageNet, and using them to evaluate newly developed objectives on downstream scenarios. While convenient, this does not take into account the role of architectures which has been shown to be crucial in the supervised learning literature. In this work, we establish extensive empirical evidence showing that a network architecture plays a significant role in SSL. We conduct a large-scale study with over 100 variants of ResNet and MobileNet architectures and evaluate them across 11 downstream scenarios in the SSL setting. We show that there is no one network that performs consistently well across the scenarios. Based on this, we propose to learn not only network weights but also architecture topologies in the SSL regime. We show that \"self-supervised architectures\" outperform popular handcrafted architectures (ResNet18 and MobileNetV2) while performing competitively with the larger and computationally heavy ResNet50 on major image classification benchmarks (ImageNet-1K, iNat2021, and more). Our results suggest that it is time to consider moving beyond handcrafted architectures in SSL and start thinking about incorporating architecture search into self-supervised learning objectives. ",
    "url": "https://arxiv.org/abs/2203.08130",
    "authors": [
      "Sharath Girish",
      "Debadeepta Dey",
      "Neel Joshi",
      "Vibhav Vineet",
      "Shital Shah",
      "Caio Cesar Teodoro Mendes",
      "Abhinav Shrivastava",
      "Yale Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08133",
    "title": "Animatable Neural Implicit Surfaces for Creating Avatars from Videos",
    "abstract": "This paper aims to reconstruct an animatable human model from a video of very sparse camera views. Some recent works represent human geometry and appearance with neural radiance fields and utilize parametric human models to produce deformation fields for animation, which enables them to recover detailed 3D human models from videos. However, their reconstruction results tend to be noisy due to the lack of surface constraints on radiance fields. Moreover, as they generate the human appearance in 3D space, their rendering quality heavily depends on the accuracy of deformation fields. To solve these problems, we propose Animatable Neural Implicit Surface (AniSDF), which models the human geometry with a signed distance field and defers the appearance generation to the 2D image space with a 2D neural renderer. The signed distance field naturally regularizes the learned geometry, enabling the high-quality reconstruction of human bodies, which can be further used to improve the rendering speed. Moreover, the 2D neural renderer can be learned to compensate for geometric errors, making the rendering more robust to inaccurate deformations. Experiments on several datasets show that the proposed approach outperforms recent human reconstruction and synthesis methods by a large margin. ",
    "url": "https://arxiv.org/abs/2203.08133",
    "authors": [
      "Sida Peng",
      "Shangzhan Zhang",
      "Zhen Xu",
      "Chen Geng",
      "Boyi Jiang",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06725",
    "title": "Network Bandwidth Allocation Problem For Cloud Computing",
    "abstract": "Cloud computing enables ubiquitous, convenient, and on-demand network access to a shared pool of computing resources. Cloud computing technologies create tremendous commercial values in various areas, while many scientific challenges have arisen accordingly. The process of transmitting data through networks is characterized by some distinctive characteristics such as nonlinear, nonconvex and even noncontinuous cost functions generated by pricing schemes, periodically updated network topology, as well as replicable data within network nodes. Because of these characteristics, data transfer scheduling is a very challenging problem both engineeringly and scientifically. On the other hand, the cost for bandwidth is a major component of the operating cost for cloud providers, and thus how to save bandwidth cost is extremely important for them to supply service with minimized cost. We propose the Network Bandwidth Allocation (NBA) problem for cloud computing and formulate it as an integer programming model on a high level, with which more comprehensive and rigorous scientific studies become possible. We also show that the NBA problem captures some of the major cloud computing scenarios including the content delivery network (CDN), the live video delivery network (LVDN), the real-time communication network (RTCN), and the cloud wide area network (Cloud-WAN). ",
    "url": "https://arxiv.org/abs/2203.06725",
    "authors": [
      "Changpeng Yang",
      "Jintao You",
      "Xiaoming Yuan",
      "Pengxiang Zhao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.07373",
    "title": "SATr: Slice Attention with Transformer for Universal Lesion Detection",
    "abstract": "Universal Lesion Detection (ULD) in computed tomography plays an essential role in computer-aided diagnosis. Promising ULD results have been reported by multi-slice-input detection approaches which model 3D context from multiple adjacent CT slices, but such methods still experience difficulty in obtaining a global representation among different slices and within each individual slice since they only use convolution-based fusion operations. In this paper, we propose a novel Slice Attention Transformer (SATr) block which can be easily plugged into convolution-based ULD backbones to form hybrid network structures. Such newly formed hybrid backbones can better model long-distance feature dependency via the cascaded self-attention modules in the Transformer block while still holding a strong power of modeling local features with the convolutional operations in the original backbone. Experiments with five state-of-the-art methods show that the proposed SATr block can provide an almost free boost to lesion detection accuracy without extra hyperparameters or special network designs. ",
    "url": "https://arxiv.org/abs/2203.07373",
    "authors": [
      "Han Li",
      "Long Chen",
      "Hu Han",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07537",
    "title": "Denoising and feature extraction in photoemission spectra with  variational auto-encoder neural networks",
    "abstract": "In recent years, distinct machine learning (ML) models have been separately used for feature extraction and noise reduction from energy-momentum dispersion intensity maps obtained from raw angle-resolved photoemission spectroscopy (ARPES) data. In this work, we employ a shallow variational auto-encoder (VAE) neural network to demonstrate the prospect of using ML for both denoising of as well as feature extraction from ARPES dispersion maps. ",
    "url": "https://arxiv.org/abs/2203.07537",
    "authors": [
      "Francisco Restrepo",
      "Junjing Zhao",
      "Utpal Chatterjee"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07542",
    "title": "Neural Network Solver for Coherent Synchrotron Radiation Wakefield  Calculations in Accelerator-based Charged Particle Beams",
    "abstract": "Particle accelerators support a wide array of scientific, industrial, and medical applications. To meet the needs of these applications, accelerator physicists rely heavily on detailed simulations of the complicated particle beam dynamics through the accelerator. One of the most computationally expensive and difficult-to-model effects is the impact of Coherent Synchrotron Radiation (CSR). As a beam travels through a curved trajectory (e.g. due to a bending magnet), it emits radiation that in turn interacts with the rest of the beam. At each step through the trajectory, the electromagnetic field introduced by CSR (called the CSR wakefield) needs to computed and used when calculating the updates to the positions and momenta of every particle in the beam. CSR is one of the major drivers of growth in the beam emittance, which is a key metric of beam quality that is critical in many applications. The CSR wakefield is very computationally intensive to compute with traditional electromagnetic solvers, and this is a major limitation in accurately simulating accelerators. Here, we demonstrate a new approach for the CSR wakefield computation using a neural network solver structured in a way that is readily generalizable to new setups. We validate its performance by adding it to a standard beam tracking test problem and show a ten-fold speedup along with high accuracy. ",
    "url": "https://arxiv.org/abs/2203.07542",
    "authors": [
      "Auralee Edelen",
      "Christopher Mayes"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.07546",
    "title": "Permutation Invariant Representations with Applications to Graph Deep  Learning",
    "abstract": "This paper presents primarily two Euclidean embeddings of the quotient space generated by matrices that are identified modulo arbitrary row permutations. The original application is in deep learning on graphs where the learning task is invariant to node relabeling. Two embedding schemes are introduced, one based on sorting and the other based on algebras of multivariate polynomials. While both embeddings exhibit a computational complexity exponential in problem size, the sorting based embedding is globally bi-Lipschitz and admits a low dimensional target space. Additionally, an almost everywhere injective scheme can be implemented with minimal redundancy and low computational cost. In turn, this proves that almost any classifier can be implemented with an arbitrary small loss of performance. Numerical experiments are carried out on two data sets, a chemical compound data set (QM9) and a proteins data set (PROTEINS). ",
    "url": "https://arxiv.org/abs/2203.07546",
    "authors": [
      "Radu Balan",
      "Naveed Haghani",
      "Maneesh Singh"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07555",
    "title": "Resilience of Input Metering in Dynamic Flow Networks",
    "abstract": "In this paper, we study robustness of input metering policies in dynamic flow networks in the presence of transient disturbances and attacks. We consider a compartmental model for dynamic flow networks with a First-In-First-Out (FIFO) routing rule as found in, e.g., transportation networks. We model the effect of the transient disturbance as an abrupt change to the state of the network and use the notion of the region of attraction to measure the resilience of the network to these changes. For constant and periodic input metering, we introduce the notion of monotone-invariant points to establish inner-estimates for the regions of attraction of free-flow equilibrium points and free-flow periodic orbits using monotone systems theory. These results are applicable to, e.g., networks with cycles, which have not been considered in prior literature on dynamic flow networks with FIFO routing. Finally, we propose two approaches for finding suitable monotone-invariant points in the flow networks with FIFO rules. ",
    "url": "https://arxiv.org/abs/2203.07555",
    "authors": [
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.07659",
    "title": "Breast Cancer Molecular Subtypes Prediction on Pathological Images with  Discriminative Patch Selecting and Multi-Instance Learning",
    "abstract": "Molecular subtypes of breast cancer are important references to personalized clinical treatment. For cost and labor savings, only one of the patient's paraffin blocks is usually selected for subsequent immunohistochemistry (IHC) to obtain molecular subtypes. Inevitable sampling error is risky due to tumor heterogeneity and could result in a delay in treatment. Molecular subtype prediction from conventional H&E pathological whole slide images (WSI) using AI method is useful and critical to assist pathologists pre-screen proper paraffin block for IHC. It's a challenging task since only WSI level labels of molecular subtypes can be obtained from IHC. Gigapixel WSIs are divided into a huge number of patches to be computationally feasible for deep learning. While with coarse slide-level labels, patch-based methods may suffer from abundant noise patches, such as folds, overstained regions, or non-tumor tissues. A weakly supervised learning framework based on discriminative patch selecting and multi-instance learning was proposed for breast cancer molecular subtype prediction from H&E WSIs. Firstly, co-teaching strategy was adopted to learn molecular subtype representations and filter out noise patches. Then, a balanced sampling strategy was used to handle the imbalance in subtypes in the dataset. In addition, a noise patch filtering algorithm that used local outlier factor based on cluster centers was proposed to further select discriminative patches. Finally, a loss function integrating patch with slide constraint information was used to finetune MIL framework on obtained discriminative patches and further improve the performance of molecular subtyping. The experimental results confirmed the effectiveness of the proposed method and our models outperformed even senior pathologists, with potential to assist pathologists to pre-screen paraffin blocks for IHC in clinic. ",
    "url": "https://arxiv.org/abs/2203.07659",
    "authors": [
      "Hong Liu",
      "Wen-Dong Xu",
      "Zi-Hao Shang",
      "Xiang-Dong Wang",
      "Hai-Yan Zhou",
      "Ke-Wen Ma",
      "Huan Zhou",
      "Jia-Lin Qi",
      "Jia-Rui Jiang",
      "Li-Lan Tan",
      "Hui-Min Zeng",
      "Hui-Juan Cai",
      "Kuan-Song Wang",
      "Yue-Liang Qian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07707",
    "title": "Magnification Prior: A Self-Supervised Method for Learning  Representations on Breast Cancer Histopathological Images",
    "abstract": "This work presents a novel self-supervised pre-training method to learn efficient representations without labels on histopathology medical images utilizing magnification factors. Other state-of-theart works mainly focus on fully supervised learning approaches that rely heavily on human annotations. However, the scarcity of labeled and unlabeled data is a long-standing challenge in histopathology. Currently, representation learning without labels remains unexplored for the histopathology domain. The proposed method, Magnification Prior Contrastive Similarity (MPCS), enables self-supervised learning of representations without labels on small-scale breast cancer dataset BreakHis by exploiting magnification factor, inductive transfer, and reducing human prior. The proposed method matches fully supervised learning state-of-the-art performance in malignancy classification when only 20% of labels are used in fine-tuning and outperform previous works in fully supervised learning settings. It formulates a hypothesis and provides empirical evidence to support that reducing human-prior leads to efficient representation learning in self-supervision. The implementation of this work is available online on GitHub - https://github.com/prakashchhipa/Magnification-Prior-Self-Supervised-Method ",
    "url": "https://arxiv.org/abs/2203.07707",
    "authors": [
      "Prakash Chandra Chhipa",
      "Richa Upadhyay",
      "Gustav Grund Pihlgren",
      "Rajkumar Saini",
      "Seiichi Uchida",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07772",
    "title": "Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy",
    "abstract": "The numerical wavefront backpropagation principle of digital holography confers unique extended focus capabilities, without mechanical displacements along z-axis. However, the determination of the correct focusing distance is a non-trivial and time consuming issue. A deep learning (DL) solution is proposed to cast the autofocusing as a regression problem and tested over both experimental and simulated holograms. Single wavelength digital holograms were recorded by a Digital Holographic Microscope (DHM) with a 10$\\mathrm{x}$ microscope objective from a patterned target moving in 3D over an axial range of 92 $\\mu$m. Tiny DL models are proposed and compared such as a tiny Vision Transformer (TViT), tiny VGG16 (TVGG) and a tiny Swin-Transfomer (TSwinT). The experiments show that the predicted focusing distance $Z_R^{\\mathrm{Pred}}$ is accurately inferred with an accuracy of 1.2 $\\mu$m in average in comparison with the DHM depth of field of 15 $\\mu$m. Numerical simulations show that all tiny models give the $Z_R^{\\mathrm{Pred}}$ with an error below 0.3 $\\mu$m. Such a prospect would significantly improve the current capabilities of computer vision position sensing in applications such as 3D microscopy for life sciences or micro-robotics. Moreover, all models reach state of the art inference time on CPU, less than 25 ms per inference. ",
    "url": "https://arxiv.org/abs/2203.07772",
    "authors": [
      "St\u00e9phane Cuenat",
      "Louis Andr\u00e9oli",
      "Antoine N. Andr\u00e9",
      "Patrick Sandoz",
      "Guillaume J. Laurent",
      "Rapha\u00ebl Couturier",
      "Maxime Jacquot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2203.07798",
    "title": "Igeood: An Information Geometry Approach to Out-of-Distribution  Detection",
    "abstract": "Reliable out-of-distribution (OOD) detection is fundamental to implementing safer modern machine learning (ML) systems. In this paper, we introduce Igeood, an effective method for detecting OOD samples. Igeood applies to any pre-trained neural network, works under various degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD samples. By building on the geodesic (Fisher-Rao) distance between the underlying data distributions, our discriminator can combine confidence scores from the logits outputs and the learned features of a deep neural network. Empirically, we show that Igeood outperforms competing state-of-the-art methods on a variety of network architectures and datasets. ",
    "url": "https://arxiv.org/abs/2203.07798",
    "authors": [
      "Eduardo Dadalto Camara Gomes",
      "Florence Alberge",
      "Pierre Duhamel",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07831",
    "title": "Graph Neural Network Sensitivity Under Probabilistic Error Model",
    "abstract": "Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy. ",
    "url": "https://arxiv.org/abs/2203.07831",
    "authors": [
      "Xinjue Wang",
      "Esa Ollila",
      "Sergiy A. Vorobyov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07912",
    "title": "Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count  Data",
    "abstract": "Classically, statistical datasets have a larger number of data points than features ($n > p$). The standard model of classical statistics caters for the case where data points are considered conditionally independent given the parameters. However, for $n\\approx p$ or $p > n$ such models are poorly determined. Kalaitzis et al. (2013) introduced the Bigraphical Lasso, an estimator for sparse precision matrices based on the Cartesian product of graphs. Unfortunately, the original Bigraphical Lasso algorithm is not applicable in case of large p and n due to memory requirements. We exploit eigenvalue decomposition of the Cartesian product graph to present a more efficient version of the algorithm which reduces memory requirements from $O(n^2p^2)$ to $O(n^2 + p^2)$. Many datasets in different application fields, such as biology, medicine and social science, come with count data, for which Gaussian based models are not applicable. Our multi-way network inference approach can be used for discrete data. Our methodology accounts for the dependencies across both instances and features, reduces the computational complexity for high dimensional data and enables to deal with both discrete and continuous data. Numerical studies on both synthetic and real datasets are presented to showcase the performance of our method. ",
    "url": "https://arxiv.org/abs/2203.07912",
    "authors": [
      "Sijia Li",
      "Mart\u00edn L\u00f3pez-Garc\u00eda",
      "Neil D. Lawrence",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2203.07966",
    "title": "Learning Expanding Graphs for Signal Interpolation",
    "abstract": "Performing signal processing over graphs requires knowledge of the underlying fixed topology. However, graphs often grow in size with new nodes appearing over time, whose connectivity is typically unknown; hence, making more challenging the downstream tasks in applications like cold start recommendation. We address such a challenge for signal interpolation at the incoming nodes blind to the topological connectivity of the specific node. Specifically, we propose a stochastic attachment model for incoming nodes parameterized by the attachment probabilities and edge weights. We estimate these parameters in a data-driven fashion by relying only on the attachment behaviour of earlier incoming nodes with the goal of interpolating the signal value. We study the non-convexity of the problem at hand, derive conditions when it can be marginally convexified, and propose an alternating projected descent approach between estimating the attachment probabilities and the edge weights. Numerical experiments with synthetic and real data dealing in cold start collaborative filtering corroborate our findings. ",
    "url": "https://arxiv.org/abs/2203.07966",
    "authors": [
      "Bishwadeep Das",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08058",
    "title": "Graph filtering over expanding graphs",
    "abstract": "Our capacity to learn representations from data is related to our ability to design filters that can leverage their coupling with the underlying domain. Graph filters are one such tool for network data and have been used in a myriad of applications. But graph filters work only with a fixed number of nodes despite the expanding nature of practical networks. Learning filters in this setting is challenging not only because of the increased dimensions but also because the connectivity is known only up to an attachment model. We propose a filter learning scheme for data over expanding graphs by relying only on such a model. By characterizing the filter stochastically, we develop an empirical risk minimization framework inspired by multi-kernel learning to balance the information inflow and outflow at the incoming nodes. We particularize the approach for denoising and semi-supervised learning (SSL) over expanding graphs and show near-optimal performance compared with baselines relying on the exact topology. For SSL, the proposed scheme uses the incoming node information to improve the task on the existing ones. These findings lay the foundation for learning representations over expanding graphs by relying only on the stochastic connectivity model. ",
    "url": "https://arxiv.org/abs/2203.08058",
    "authors": [
      "Bishwadeep Das",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.08072",
    "title": "Neural Solvers for Fast and Accurate Numerical Optimal Control",
    "abstract": "Synthesizing optimal controllers for dynamical systems often involves solving optimization problems with hard real-time constraints. These constraints determine the class of numerical methods that can be applied: computationally expensive but accurate numerical routines are replaced by fast and inaccurate methods, trading inference time for solution accuracy. This paper provides techniques to improve the quality of optimized control policies given a fixed computational budget. We achieve the above via a hypersolvers approach, which hybridizes a differential equation solver and a neural network. The performance is evaluated in direct and receding-horizon optimal control tasks in both low and high dimensions, where the proposed approach shows consistent Pareto improvements in solution accuracy and control performance. ",
    "url": "https://arxiv.org/abs/2203.08072",
    "authors": [
      "Federico Berto",
      "Stefano Massaroli",
      "Michael Poli",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1903.02240",
    "title": "Efficient Deep Neural Network for Photo-realistic Image Super-Resolution",
    "abstract": " Comments: Pattern Recognition ",
    "url": "https://arxiv.org/abs/1903.02240",
    "authors": [
      "Namhyuk Ahn",
      "Byungkon Kang",
      "Kyung-Ah Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2007.08386",
    "title": "MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks",
    "abstract": " Title: MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks ",
    "url": "https://arxiv.org/abs/2007.08386",
    "authors": [
      "Xinghao Chen",
      "Yiman Zhang",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2007.12350",
    "title": "Improving the dilation of a metric graph by adding edges",
    "abstract": " Comments: Journal version, TALG 2022 ",
    "url": "https://arxiv.org/abs/2007.12350",
    "authors": [
      "Joachim Gudmundsson",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2009.07398",
    "title": "A Sensitivity-based Data Augmentation Framework for Model Predictive  Control Policy Approximation",
    "abstract": " Comments: Accepted for publication at IEEE Transactions on Automatic Control ",
    "url": "https://arxiv.org/abs/2009.07398",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2009.09778",
    "title": "Computation of Parameter Dependent Robust Invariant Sets for LPV Models  with Guaranteed Performance",
    "abstract": " Comments: 17 pages, 6 figures, preprint submitted to Automatica ",
    "url": "https://arxiv.org/abs/2009.09778",
    "authors": [
      "Ankit Gupta",
      "Manas Mejari",
      "Paolo Falcone",
      "Dario Piga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2010.06975",
    "title": "Medical Code Assignment with Gated Convolution and Note-Code Interaction",
    "abstract": " Comments: Findings of ACL-IJCNLP 2021 ",
    "url": "https://arxiv.org/abs/2010.06975",
    "authors": [
      "Shaoxiong Ji",
      "Shirui Pan",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2102.10303",
    "title": "Towards Building A Group-based Unsupervised Representation  Disentanglement Framework",
    "abstract": " Comments: Accepted by ICLR 2022 ",
    "url": "https://arxiv.org/abs/2102.10303",
    "authors": [
      "Tao Yang",
      "Xuanchi Ren",
      "Yuwang Wang",
      "Wenjun Zeng",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.04532",
    "title": "Neural RGB-D Surface Reconstruction",
    "abstract": " Comments: CVPR'22; Project page: this https URL Video: this https URL ",
    "url": "https://arxiv.org/abs/2104.04532",
    "authors": [
      "Dejan Azinovi\u0107",
      "Ricardo Martin-Brualla",
      "Dan B Goldman",
      "Matthias Nie\u00dfner",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.08678",
    "title": "Improving Question Answering Model Robustness with Synthetic Adversarial  Data Generation",
    "abstract": " Comments: EMNLP 2021 ",
    "url": "https://arxiv.org/abs/2104.08678",
    "authors": [
      "Max Bartolo",
      "Tristan Thrush",
      "Robin Jia",
      "Sebastian Riedel",
      "Pontus Stenetorp",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.13450",
    "title": "Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings",
    "abstract": " Title: Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and  Extracting Them from 2D Renderings ",
    "url": "https://arxiv.org/abs/2104.13450",
    "authors": [
      "Innfarn Yoo",
      "Huiwen Chang",
      "Xiyang Luo",
      "Ondrej Stava",
      "Ce Liu",
      "Peyman Milanfar",
      "Feng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2105.07654",
    "title": "Dependency Parsing as MRC-based Span-Span Prediction",
    "abstract": " Comments: Accepted by ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2105.07654",
    "authors": [
      "Leilei Gan",
      "Yuxian Meng",
      "Kun Kuang",
      "Xiaofei Sun",
      "Chun Fan",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2105.09871",
    "title": "Tuza's Conjecture for Threshold Graphs",
    "abstract": " Comments: 12 pages, 11 figures, Accepted to European Conference on Combinatorics, Graph Theory and Applications (EUROCOMB) 2021 ",
    "url": "https://arxiv.org/abs/2105.09871",
    "authors": [
      "Marthe Bonamy",
      "\u0141ukasz Bo\u017cyk",
      "Andrzej Grzesik",
      "Meike Hatzel",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Jana Novotn\u00e1",
      "Karolina Okrasa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2106.02736",
    "title": "Exposing the Implicit Energy Networks behind Masked Language Models via  Metropolis--Hastings",
    "abstract": " Comments: ICLR 2022 - camera ready ",
    "url": "https://arxiv.org/abs/2106.02736",
    "authors": [
      "Kartik Goyal",
      "Chris Dyer",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2106.05258",
    "title": "Generative Models as a Data Source for Multiview Representation Learning",
    "abstract": " Title: Generative Models as a Data Source for Multiview Representation Learning ",
    "url": "https://arxiv.org/abs/2106.05258",
    "authors": [
      "Ali Jahanian",
      "Xavier Puig",
      "Yonglong Tian",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.06235",
    "title": "Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial  Attacks",
    "abstract": " Comments: International Conference on Machine Learning 2021, 37 pages, 8 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2106.06235",
    "authors": [
      "Nezihe Merve G\u00fcrel",
      "Xiangyu Qi",
      "Luka Rimanic",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.07967",
    "title": "Incorporating Word Sense Disambiguation in Neural Language Models",
    "abstract": " Title: Incorporating Word Sense Disambiguation in Neural Language Models ",
    "url": "https://arxiv.org/abs/2106.07967",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.07971",
    "title": "Simple GNN Regularisation for 3D Molecular Property Prediction & Beyond",
    "abstract": " Comments: ICLR 2022 Camera Ready ",
    "url": "https://arxiv.org/abs/2106.07971",
    "authors": [
      "Jonathan Godwin",
      "Michael Schaarschmidt",
      "Alexander Gaunt",
      "Alvaro Sanchez-Gonzalez",
      "Yulia Rubanova",
      "Petar Veli\u010dkovi\u0107",
      "James Kirkpatrick",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.08290",
    "title": "PolyDot Coded Privacy Preserving Multi-Party Computation at the Edge",
    "abstract": " Comments: 23 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2106.08290",
    "authors": [
      "Elahe Vedadi",
      "Yasaman Keshtkarjahromi",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2107.08712",
    "title": "Exploring Set Similarity for Dense Self-supervised Representation  Learning",
    "abstract": " Comments: 10 pages, 4 figures, Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2107.08712",
    "authors": [
      "Zhaoqing Wang",
      "Qiang Li",
      "Guoxin Zhang",
      "Pengfei Wan",
      "Wen Zheng",
      "Nannan Wang",
      "Mingming Gong",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.11214",
    "title": "Human Pose Estimation from Sparse Inertial Measurements through  Recurrent Graph Convolution",
    "abstract": " Comments: Preprint, in submission ",
    "url": "https://arxiv.org/abs/2107.11214",
    "authors": [
      "Patrik Puchert",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.13862",
    "title": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "abstract": " Title: Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications ",
    "url": "https://arxiv.org/abs/2107.13862",
    "authors": [
      "David Meg\u00edas",
      "Daniel Lerch-Hostalot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.05018",
    "title": "Are Neural Ranking Models Robust?",
    "abstract": " Title: Are Neural Ranking Models Robust? ",
    "url": "https://arxiv.org/abs/2108.05018",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2108.06332",
    "title": "FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning",
    "abstract": " Title: FlipDA: Effective and Robust Data Augmentation for Few-Shot Learning ",
    "url": "https://arxiv.org/abs/2108.06332",
    "authors": [
      "Jing Zhou",
      "Yanan Zheng",
      "Jie Tang",
      "Jian Li",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2108.11269",
    "title": "Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis  DOmain Generalization Challenge",
    "abstract": " Comments: This is the long version of the original pre-print. Due to a bug in our automatic threshold computation the detection threshold of our model changed from 0.62 to 0.64. This value was not optimized on any other images but the validation split of the MIDOG training set. 9 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2108.11269",
    "authors": [
      "Frauke Wilm",
      "Christian Marzahl",
      "Katharina Breininger",
      "Marc Aubreville"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13458",
    "title": "The Application of Convolutional Neural Networks for Tomographic  Reconstruction of Hyperspectral Images",
    "abstract": " Comments: 31 pages, 18 figures and 4 tables. v2: clarifications and references added, analyses and network diagrams updated ",
    "url": "https://arxiv.org/abs/2108.13458",
    "authors": [
      "Wei-Chih Huang",
      "Mads Svanborg Peters",
      "Mads Juul Ahlebaek",
      "Mads Toudal Frandsen",
      "Ren\u00e9 Lynge Eriksen",
      "Bjarke J\u00f8rgensen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05948",
    "title": "A deep learning guided memetic framework for graph coloring problems",
    "abstract": " Title: A deep learning guided memetic framework for graph coloring problems ",
    "url": "https://arxiv.org/abs/2109.05948",
    "authors": [
      "Olivier Goudet",
      "Cyril Grelier",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.09033",
    "title": "Joint Distribution Alignment via Adversarial Learning for Domain  Adaptive Object Detection",
    "abstract": " Comments: Accepted by IEEE T-MM, 2021, the code is available at this https URL ",
    "url": "https://arxiv.org/abs/2109.09033",
    "authors": [
      "Bo Zhang",
      "Tao Chen",
      "Bin Wang",
      "Ruoyao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.12544",
    "title": "DAMix: A Density-Aware Mixup Augmentation for Single Image Dehazing  under Domain Shift",
    "abstract": " Title: DAMix: A Density-Aware Mixup Augmentation for Single Image Dehazing  under Domain Shift ",
    "url": "https://arxiv.org/abs/2109.12544",
    "authors": [
      "Chia-Ming Chang",
      "Tsung-Nan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.04124",
    "title": "Ensemble Neural Representation Networks",
    "abstract": " Comments: IEEE Signal Processing Letters submitted, 5 pages, 6 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2110.04124",
    "authors": [
      "Milad Soltany Kadarvish",
      "Hesam Mojtahedi",
      "Hossein Entezari Zarch",
      "Amirhossein Kazerouni",
      "Alireza Morsali",
      "Azra Abtahi",
      "Farokh Marvasti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.06850",
    "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
    "abstract": " Comments: Accepted for ICLR 2022; 21 pages ",
    "url": "https://arxiv.org/abs/2110.06850",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.07165",
    "title": "Semantically Distributed Robust Optimization for Vision-and-Language  Inference",
    "abstract": " Comments: Findings of ACL 2022; code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.07165",
    "authors": [
      "Tejas Gokhale",
      "Abhishek Chaudhary",
      "Pratyay Banerjee",
      "Chitta Baral",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.08243",
    "title": "Neural Dubber: Dubbing for Videos According to Scripts",
    "abstract": " Comments: Accepted by NeurIPS 2021; Project page at this https URL ",
    "url": "https://arxiv.org/abs/2110.08243",
    "authors": [
      "Chenxu Hu",
      "Qiao Tian",
      "Tingle Li",
      "Yuping Wang",
      "Yuxuan Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2110.09437",
    "title": "Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021",
    "abstract": " Title: Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021 ",
    "url": "https://arxiv.org/abs/2110.09437",
    "authors": [
      "Angelica Goetzen",
      "Samuel Dooley",
      "Elissa M. Redmiles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2110.09759",
    "title": "A Regularization Method to Improve Adversarial Robustness of Neural  Networks for ECG Signal Classification",
    "abstract": " Comments: This paper has been published by Computers in Biology and Medicine ",
    "url": "https://arxiv.org/abs/2110.09759",
    "authors": [
      "Linhai Ma",
      "Liang Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2110.12914",
    "title": "SILT: Self-supervised Lighting Transfer Using Implicit Image  Decomposition",
    "abstract": " Comments: Accepted to BMVC 2021. The code and pre-trained models can be found at this https URL ",
    "url": "https://arxiv.org/abs/2110.12914",
    "authors": [
      "Nikolina Kubiak",
      "Armin Mustafa",
      "Graeme Phillipson",
      "Stephen Jolly",
      "Simon Hadfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2110.13409",
    "title": "Task-Aware Meta Learning-based Siamese Neural Network for Classifying  Obfuscated Malware",
    "abstract": " Title: Task-Aware Meta Learning-based Siamese Neural Network for Classifying  Obfuscated Malware ",
    "url": "https://arxiv.org/abs/2110.13409",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Paul A. Watters",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.05806",
    "title": "On the efficiency of a general attack against the MOBS cryptosystem",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2111.05806",
    "authors": [
      "Christopher Battarbee",
      "Delaram Kahrobaei",
      "Dylan Tailor",
      "Siamak F. Shahandashti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2111.09515",
    "title": "RAANet: Range-Aware Attention Network for LiDAR-based 3D Object  Detection with Auxiliary Density Level Estimation",
    "abstract": " Title: RAANet: Range-Aware Attention Network for LiDAR-based 3D Object  Detection with Auxiliary Density Level Estimation ",
    "url": "https://arxiv.org/abs/2111.09515",
    "authors": [
      "Yantao Lu",
      "Xuetao Hao",
      "Shiqi Sun",
      "Weiheng Chai",
      "Yu Ding",
      "Muchenxuan Tong",
      "Senem Velipasalar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.10958",
    "title": "MUM : Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object  Detection",
    "abstract": " Comments: Accept to CVPR2022 ",
    "url": "https://arxiv.org/abs/2111.10958",
    "authors": [
      "JongMok Kim",
      "Jooyoung Jang",
      "Seunghyeon Seo",
      "Jisoo Jeong",
      "Jongkeun Na",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.13420",
    "title": "Confounder Identification-free Causal Visual Feature Learning",
    "abstract": " Comments: 25 pages ",
    "url": "https://arxiv.org/abs/2111.13420",
    "authors": [
      "Xin Li",
      "Zhizheng Zhang",
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14173",
    "title": "CDGNet: Class Distribution Guided Network for Human Parsing",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2111.14173",
    "authors": [
      "Kunliang Liu",
      "Ouk Choi",
      "Jianming Wang",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14549",
    "title": "MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field  Networks",
    "abstract": " Title: MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field  Networks ",
    "url": "https://arxiv.org/abs/2111.14549",
    "authors": [
      "Benoit Guillard",
      "Federico Stella",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02268",
    "title": "Bridging Pre-trained Models and Downstream Tasks for Source Code  Understanding",
    "abstract": " Comments: Accepted to the 44th International Conference on Software Engineering (ICSE 2022) ",
    "url": "https://arxiv.org/abs/2112.02268",
    "authors": [
      "Deze Wang",
      "Zhouyang Jia",
      "Shanshan Li",
      "Yue Yu",
      "Yun Xiong",
      "Wei Dong",
      "Xiangke Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.04011",
    "title": "Auxiliary Learning for Self-Supervised Video Representation via  Similarity-based Knowledge Distillation",
    "abstract": " Title: Auxiliary Learning for Self-Supervised Video Representation via  Similarity-based Knowledge Distillation ",
    "url": "https://arxiv.org/abs/2112.04011",
    "authors": [
      "Amirhossein Dadashzadeh",
      "Alan Whone",
      "Majid Mirmehdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.04035",
    "title": "Relating transformers to models and neural representations of the  hippocampal formation",
    "abstract": " Title: Relating transformers to models and neural representations of the  hippocampal formation ",
    "url": "https://arxiv.org/abs/2112.04035",
    "authors": [
      "James C.R. Whittington",
      "Joseph Warren",
      "Timothy E.J. Behrens"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with  Background Knowledge",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2112.08544",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chinthakindi",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn S. Conger",
      "Ahmed S. Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.09266",
    "title": "Incomplete Knowledge Graph Alignment",
    "abstract": " Title: Incomplete Knowledge Graph Alignment ",
    "url": "https://arxiv.org/abs/2112.09266",
    "authors": [
      "Vinh Van Tong",
      "Thanh Trung Huynh",
      "Thanh Tam Nguyen",
      "Hongzhi Yin",
      "Quoc Viet Hung Nguyen",
      "Quyet Thang Huynh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05869",
    "title": "Prototype Guided Network for Anomaly Segmentation",
    "abstract": " Comments: Need for edit,and improve the method for better performance ",
    "url": "https://arxiv.org/abs/2201.05869",
    "authors": [
      "Yiqing Hao",
      "Yi Jin",
      "Gaoyun An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10248",
    "title": "HoneyTop90: A 90-line MATLAB code for topology optimization using  honeycomb tessellation",
    "abstract": " Comments: In press ",
    "url": "https://arxiv.org/abs/2201.10248",
    "authors": [
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2201.10471",
    "title": "GIU-GANs: Global Information Utilization for Generative Adversarial  Networks",
    "abstract": " Title: GIU-GANs: Global Information Utilization for Generative Adversarial  Networks ",
    "url": "https://arxiv.org/abs/2201.10471",
    "authors": [
      "Yongqi Tian",
      "Xueyuan Gong",
      "Jialin Tang",
      "Binghua Su",
      "Xiaoxiang Liu",
      "Xinyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02521",
    "title": "Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques",
    "abstract": " Comments: 2021 International Conference on Industrial Automation, Robotics and Control Engineering (IARCE 2021) ",
    "url": "https://arxiv.org/abs/2202.02521",
    "authors": [
      "Sreenivasa Hikkal Venugopala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.05735",
    "title": "SleepPPG-Net: a deep learning algorithm for robust sleep staging from  continuous photoplethysmography",
    "abstract": " Comments: 23 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2202.05735",
    "authors": [
      "Kevin Kotzen",
      "Peter H. Charlton",
      "Sharon Salabi",
      "Lea Amar",
      "Amir Landesberg",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2202.07506",
    "title": "Confidence Threshold Neural Diving",
    "abstract": " Comments: Published on the NeurIPS 2021 ML4CO Competition Proceedings section, see this https URL ",
    "url": "https://arxiv.org/abs/2202.07506",
    "authors": [
      "Taehyun Yoon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.00120",
    "title": "Neural Ordinary Differential Equations for Nonlinear System  Identification",
    "abstract": " Title: Neural Ordinary Differential Equations for Nonlinear System  Identification ",
    "url": "https://arxiv.org/abs/2203.00120",
    "authors": [
      "Aowabin Rahman",
      "J\u00e1n Drgo\u0148a",
      "Aaron Tuor",
      "Jan Strube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.03079",
    "title": "GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for  Multi-category Attributes Prediction",
    "abstract": " Comments: CVPR 2022, 16 pages (including supplementary), CAR Dataset, VAW Dataset, this http URL ",
    "url": "https://arxiv.org/abs/2203.03079",
    "authors": [
      "Kareem Metwaly",
      "Aerin Kim",
      "Elliot Branson",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03099",
    "title": "Singular Value Perturbation and Deep Network Optimization",
    "abstract": " Title: Singular Value Perturbation and Deep Network Optimization ",
    "url": "https://arxiv.org/abs/2203.03099",
    "authors": [
      "Rudolf H. Riedi",
      "Randall Balestriero",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2203.03949",
    "title": "RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering",
    "abstract": " Comments: 17 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2203.03949",
    "authors": [
      "Di Chang",
      "Alja\u017e Bo\u017ei\u010d",
      "Tong Zhang",
      "Qingsong Yan",
      "Yingcong Chen",
      "Sabine S\u00fcsstrunk",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04771",
    "title": "Multiscale Convolutional Transformer with Center Mask Pretraining for  Hyperspectral Image Classificationtion",
    "abstract": " Comments: 8 pages, 26 figures, conference paper ",
    "url": "https://arxiv.org/abs/2203.04771",
    "authors": [
      "Yifan Wang",
      "Sen Jia",
      "Zhongfan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05151",
    "title": "Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity",
    "abstract": " Comments: 10 pages, 7 figure, CVPR 2022 conference ",
    "url": "https://arxiv.org/abs/2203.05151",
    "authors": [
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Bizhu Wu",
      "Jinheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05238",
    "title": "Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided  Label Enhancement",
    "abstract": " Comments: Accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.05238",
    "authors": [
      "Xiuwei Xu",
      "Yifan Wang",
      "Yu Zheng",
      "Yongming Rao",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05903",
    "title": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models",
    "abstract": " Title: Formal Control Synthesis for Stochastic Neural Network Dynamic Models ",
    "url": "https://arxiv.org/abs/2203.05903",
    "authors": [
      "Steven Adams",
      "Morteza Lahijanian",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.06319",
    "title": "PillarGrid: Deep Learning-based Cooperative Perception for 3D Object  Detection from Onboard-Roadside LiDAR",
    "abstract": " Comments: Submitted to The 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022) ",
    "url": "https://arxiv.org/abs/2203.06319",
    "authors": [
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Yongkang Liu",
      "Emrah Akin Sisbot",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.06587",
    "title": "Policy Learning for Robust Markov Decision Process with a Mismatched  Generative Model",
    "abstract": " Comments: AAAI 2022 ",
    "url": "https://arxiv.org/abs/2203.06587",
    "authors": [
      "Jialian Li",
      "Tongzheng Ren",
      "Dong Yan",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.06605",
    "title": "Depth-Aware Generative Adversarial Network for Talking Head Video  Generation",
    "abstract": " Comments: 15 Pages; Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.06605",
    "authors": [
      "Fa-Ting Hong",
      "Longhao Zhang",
      "Li Shen",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.06631",
    "title": "A ROS Architecture for Personalised HRI with a Bartender Social Robot",
    "abstract": " Comments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022) ",
    "url": "https://arxiv.org/abs/2203.06631",
    "authors": [
      "Alessandra Rossi",
      "Maria Di Maro",
      "Antonio Origlia",
      "Agostino Palmiero",
      "Silvia Rossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.06947",
    "title": "XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich  Document Understanding",
    "abstract": " Comments: Accepted by CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.06947",
    "authors": [
      "Zhangxuan Gu",
      "Changhua Meng",
      "Ke Wang",
      "Jun Lan",
      "Weiqiang Wang",
      "Ming Gu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.06967",
    "title": "Blind2Unblind: Self-Supervised Image Denoising with Visible Blind Spots",
    "abstract": " Comments: Accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.06967",
    "authors": [
      "Zejin Wang",
      "Jiazheng Liu",
      "Guoqing Li",
      "Hua Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07138",
    "title": "Adversarial amplitude swap towards robust image classifiers",
    "abstract": " Comments: 13+6 pages (main+supplement), 3 figures ",
    "url": "https://arxiv.org/abs/2203.07138",
    "authors": [
      "Tan Chun Yang",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.07260",
    "title": "Graph-Survival: A Survival Analysis Framework for Machine Learning on  Temporal Networks",
    "abstract": " Title: Graph-Survival: A Survival Analysis Framework for Machine Learning on  Temporal Networks ",
    "url": "https://arxiv.org/abs/2203.07260",
    "authors": [
      "Rapha\u00ebl Romero",
      "Bo Kang",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07363",
    "title": "Implicit Motion Handling for Video Camouflaged Object Detection",
    "abstract": " Comments: Accepted to CVPR 2022; Xuelian Cheng and Huan Xiong made equal contributions; Corresponding author: Deng-Ping Fan (dengpfan@gmail.com). Dataset: this https URL ",
    "url": "https://arxiv.org/abs/2203.07363",
    "authors": [
      "Xuelian Cheng",
      "Huan Xiong",
      "Deng-Ping Fan",
      "Yiran Zhong",
      "Mehrtash Harandi",
      "Tom Drummond",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]