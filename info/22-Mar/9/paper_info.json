[
  {
    "id": "arXiv:2203.03620",
    "title": "Prediction of terrorism pattern accompanied by cyber-terrorism and the  development direction of corresponding legal systems",
    "abstract": "As the information and communication system has become an essential element for national operation and people's lives, and the dependence on information and communication systems such as national infrastructure systems and facilities increases, cyber terrorism is rapidly emerging as a serious threat to national security in peacetime. As terrorist groups' access to cyber-attack assets improves, the traditional form of terrorism is also expected to change to a form combined with cyber-terrorism. Nevertheless, from a national security point of view, Korea lacks a legal system to prepare for and respond to cyber terrorism. In this paper, based on the development process of the modern military operation concept, we predict the changes in the form of terrorism, analyze the restrictions on the national response to cyber-terrorism based on the current legal system, and propose the development directions. ",
    "url": "https://arxiv.org/abs/2203.03620",
    "authors": [
      "Daegeon Kim"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.03663",
    "title": "Towards Sub-Quadratic Diameter Computation in Geometric Intersection  Graphs",
    "abstract": "We initiate the study of diameter computation in geometric intersection graphs from the fine-grained complexity perspective. A geometric intersection graph is a graph whose vertices correspond to some shapes in $d$-dimensional Euclidean space, such as balls, segments, or hypercubes, and whose edges correspond to pairs of intersecting shapes. The diameter of a graph is the largest distance realized by a pair of vertices in the graph. Computing the diameter in near-quadratic time is possible in several classes of intersection graphs [Chan and Skrepetos 2019], but it is not at all clear if these algorithms are optimal, especially since in the related class of planar graphs the diameter can be computed in $\\widetilde{\\mathcal{O}}(n^{5/3})$ time [Cabello 2019, Gawrychowski et al. 2021]. In this work we (conditionally) rule out sub-quadratic algorithms in several classes of intersection graphs, i.e., algorithms of running time $\\mathcal{O}(n^{2-\\delta})$ for some $\\delta>0$. In particular, there are no sub-quadratic algorithms already for fat objects in small dimensions: unit balls in $\\mathbb{R}^3$ or congruent equilateral triangles in $\\mathbb{R}^2$. For unit segments and congruent equilateral triangles, we can even rule out strong sub-quadratic approximations already in $\\mathbb{R}^2$. It seems that the hardness of approximation may also depend on dimensionality: for axis-parallel unit hypercubes in~$\\mathbb{R}^{12}$, distinguishing between diameter 2 and 3 needs quadratic time (ruling out $(3/2-\\varepsilon)$- approximations), whereas for axis-parallel unit squares, we give an algorithm that distinguishes between diameter $2$ and $3$ in near-linear time. Note that many of our lower bounds match the best known algorithms up to sub-polynomial factors. ",
    "url": "https://arxiv.org/abs/2203.03663",
    "authors": [
      "Karl Bringmann",
      "S\u00e1ndor Kisfaludi-Bak",
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser",
      "Zahra Parsaeian"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": "This paper addresses video anomaly detection problem for videosurveillance. Due to the inherent rarity and heterogeneity of abnormal events, the problem is viewed as a normality modeling strategy, in which our model learns object-centric normal patterns without seeing anomalous samples during training. The main contributions consist in coupling pretrained object-level action features prototypes with a cosine distance-based anomaly estimation function, therefore extending previous methods by introducing additional constraints to the mainstream reconstruction-based strategy. Our framework leverages both appearance and motion information to learn object-level behavior and captures prototypical patterns within a memory module. Experiments on several well-known datasets demonstrate the effectiveness of our method as it outperforms current state-of-the-art on most relevant spatio-temporal evaluation metrics. ",
    "url": "https://arxiv.org/abs/2203.03677",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03682",
    "title": "Monocular Robot Navigation with Self-Supervised Pretrained Vision  Transformers",
    "abstract": "In this work, we consider the problem of learning a perception model for monocular robot navigation using few annotated images. Using a Vision Transformer (ViT) pretrained with a label-free self-supervised method, we successfully train a coarse image segmentation model for the Duckietown environment using 70 training images. Our model performs coarse image segmentation at the 8x8 patch level, and the inference resolution can be adjusted to balance prediction granularity and real-time perception constraints. We study how best to adapt a ViT to our task and environment, and find that some lightweight architectures can yield good single-image segmentations at a usable frame rate, even on CPU. The resulting perception model is used as the backbone for a simple yet robust visual servoing agent, which we deploy on a differential drive mobile robot to perform two tasks: lane following and obstacle avoidance. ",
    "url": "https://arxiv.org/abs/2203.03682",
    "authors": [
      "Miguel Saavedra-Ruiz",
      "Sacha Morin",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03692",
    "title": "Low-Loss Subspace Compression for Clean Gains against Multi-Agent  Backdoor Attacks",
    "abstract": "Recent exploration of the multi-agent backdoor attack demonstrated the backfiring effect, a natural defense against backdoor attacks where backdoored inputs are randomly classified. This yields a side-effect of low accuracy w.r.t. clean labels, which motivates this paper's work on the construction of multi-agent backdoor defenses that maximize accuracy w.r.t. clean labels and minimize that of poison labels. Founded upon agent dynamics and low-loss subspace construction, we contribute three defenses that yield improved multi-agent backdoor robustness. ",
    "url": "https://arxiv.org/abs/2203.03692",
    "authors": [
      "Siddhartha Datta",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.03706",
    "title": "Detection of AI Synthesized Hindi Speech",
    "abstract": "The recent advancements in generative artificial speech models have made possible the generation of highly realistic speech signals. At first, it seems exciting to obtain these artificially synthesized signals such as speech clones or deep fakes but if left unchecked, it may lead us to digital dystopia. One of the primary focus in audio forensics is validating the authenticity of a speech. Though some solutions are proposed for English speeches but the detection of synthetic Hindi speeches have not gained much attention. Here, we propose an approach for discrimination of AI synthesized Hindi speech from an actual human speech. We have exploited the Bicoherence Phase, Bicoherence Magnitude, Mel Frequency Cepstral Coefficient (MFCC), Delta Cepstral, and Delta Square Cepstral as the discriminating features for machine learning models. Also, we extend the study to using deep neural networks for extensive experiments, specifically VGG16 and homemade CNN as the architecture models. We obtained an accuracy of 99.83% with VGG16 and 99.99% with homemade CNN models. ",
    "url": "https://arxiv.org/abs/2203.03706",
    "authors": [
      "Karan Bhatia",
      "Ansh Agrawal",
      "Priyanka Singh",
      "Arun Kumar Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.03708",
    "title": "Biological, Family and Cultural Predictors of Personality Structure  analysis based on personality prediction models constructed by open data  source",
    "abstract": "Objective: This study takes further step on understanding personality structure in order to cope with the mental health during the COVID-19 global pandemic situation. Methods: Categorized the independent variables into biological, family and cultural predictors according to the datasets of the Big-5 personality survey online. And established multiple regression prediction models and exhaustive CHAID decision tree model of each personality trait. Results: Females are different from males in personality. The personality changes when growing. One-handed dominants are less agreeable and open than those who use both hands. Different sexual orientation does have variety personality. Native language used and education attainment is significantly related to personality accordingly. Marriage did help shaping personality to be more extroverted, less neurotic or agreeable and more conscientious and open. People raised in urban are more agreeable and open. Neurotic and open people often come from small families. person participated in voting are more extroverted, conscientious and open but less neurotic and agreeable. Different religions and races have different characteristics in each dimension of personality and there is no clear pattern have been found. Conclusion: Personality traits are indeed affected by multiple confounding factors. but the exploration on multiple cultures predictors still needed more details ",
    "url": "https://arxiv.org/abs/2203.03708",
    "authors": [
      "Cheng Hua",
      "Wang Dandan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.03729",
    "title": "Robustness and Usefulness in AI Explanation Methods",
    "abstract": "Explainability in machine learning has become incredibly important as machine learning-powered systems become ubiquitous and both regulation and public sentiment begin to demand an understanding of how these systems make decisions. As a result, a number of explanation methods have begun to receive widespread adoption. This work summarizes, compares, and contrasts three popular explanation methods: LIME, SmoothGrad, and SHAP. We evaluate these methods with respect to: robustness, in the sense of sample complexity and stability; understandability, in the sense that provided explanations are consistent with user expectations; and usability, in the sense that the explanations allow for the model to be modified based on the output. This work concludes that current explanation methods are insufficient; that putting faith in and adopting these methods may actually be worse than simply not using them. ",
    "url": "https://arxiv.org/abs/2203.03729",
    "authors": [
      "Erick Galinkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03762",
    "title": "Defending Graph Convolutional Networks against Dynamic Graph  Perturbations via Bayesian Self-supervision",
    "abstract": "In recent years, plentiful evidence illustrates that Graph Convolutional Networks (GCNs) achieve extraordinary accomplishments on the node classification task. However, GCNs may be vulnerable to adversarial attacks on label-scarce dynamic graphs. Many existing works aim to strengthen the robustness of GCNs; for instance, adversarial training is used to shield GCNs against malicious perturbations. However, these works fail on dynamic graphs for which label scarcity is a pressing issue. To overcome label scarcity, self-training attempts to iteratively assign pseudo-labels to highly confident unlabeled nodes but such attempts may suffer serious degradation under dynamic graph perturbations. In this paper, we generalize noisy supervision as a kind of self-supervised learning method and then propose a novel Bayesian self-supervision model, namely GraphSS, to address the issue. Extensive experiments demonstrate that GraphSS can not only affirmatively alert the perturbations on dynamic graphs but also effectively recover the prediction of a node classifier when the graph is under such perturbations. These two advantages prove to be generalized over three classic GCNs across five public graph datasets. ",
    "url": "https://arxiv.org/abs/2203.03762",
    "authors": [
      "Jun Zhuang",
      "Mohammad Al Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03764",
    "title": "Towards Flexible Anonymous Networks",
    "abstract": "Anonymous Communication designs such as Tor build their security upon distributing the trust in many volunteers running relays in many locations globally. These volunteers run the Tor code upon various operating systems, each potentially having different software packaging policies. In practice, it leads to a heterogeneous network in which many versions of the same Tor software exist, with a different set of protocol features. Because of the heterogeneous aspect of the network, the maintainers had to come up with forward-compatible protocol design strategies. Their role is to guarantee that different versions of the Tor software interact without unrecoverable errors. In this work, we cast the protocol tolerance enabled with forward-compatible protocol considerations as a double-edged sword. Despite being beneficial for the developers, we argue that protocol tolerance is the systemic cause behind many strong attacks against Tor in the past fifteen years. To address this issue, we propose FAN for Flexible Anonymous Network, a new software architecture for volunteer-based distributed networks that shifts the dependence away from protocol tolerance without losing the ability for the developers to ensure the continuous evolution of their software. We realize an implementation, evaluate the overheads and, experiment with several of FAN's benefits to defend against a severe attack still applicable to Tor today. ",
    "url": "https://arxiv.org/abs/2203.03764",
    "authors": [
      "Florentin Rochet",
      "Tariq Elahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.03771",
    "title": "Static Prediction of Runtime Errors by Learning to Execute Programs with  External Resource Descriptions",
    "abstract": "The execution behavior of a program often depends on external resources, such as program inputs or file contents, and so cannot be run in isolation. Nevertheless, software developers benefit from fast iteration loops where automated tools identify errors as early as possible, even before programs can be compiled and run. This presents an interesting machine learning challenge: can we predict runtime errors in a \"static\" setting, where program execution is not possible? Here, we introduce a real-world dataset and task for predicting runtime errors, which we show is difficult for generic models like Transformers. We approach this task by developing an interpreter-inspired architecture with an inductive bias towards mimicking program executions, which models exception handling and \"learns to execute\" descriptions of the contents of external resources. Surprisingly, we show that the model can also predict the location of the error, despite being trained only on labels indicating the presence/absence and kind of error. In total, we present a practical and difficult-yet-approachable challenge problem related to learning program execution and we demonstrate promising new capabilities of interpreter-inspired machine learning models for code. ",
    "url": "https://arxiv.org/abs/2203.03771",
    "authors": [
      "David Bieber",
      "Rishab Goel",
      "Daniel Zheng",
      "Hugo Larochelle",
      "Daniel Tarlow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03774",
    "title": "Exploring Physical-Based Constraints in Short-Term Load Forecasting: A  Defense Mechanism Against Cyberattack",
    "abstract": "Short-term load forecasting is an essential task that supports utilities to schedule generating sufficient power for balancing supply and demand, and can become an attractive target for cyber attacks. It has been shown that the power system state estimation is vulnerable to false data injection attacks. Similarly, false data injection on input variables can result in large forecast errors. The load forecasting system should have a protective mechanism to mitigate such attacks. One approach is to model physical system constraints that would identify anomalies. This study investigates possible constraints associated with a load forecasting application. Looking at regional forecasted loads, we analyze the relation between each zone through similarity measures used in time series in order to identify constraints. Comprehensive results for historical ERCOT load data indicate variation in the measures recognizing the existence of malicious action. Still, these static measures can not be considered an efficient index across different scenarios. ",
    "url": "https://arxiv.org/abs/2203.03774",
    "authors": [
      "Mojtaba Dezvarei",
      "Kevin Tomsovic",
      "Jinyuan Stella Sun",
      "Seddik M. Djouadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.03794",
    "title": "YONO: Modeling Multiple Heterogeneous Neural Networks on  Microcontrollers",
    "abstract": "With the advancement of Deep Neural Networks (DNN) and large amounts of sensor data from Internet of Things (IoT) systems, the research community has worked to reduce the computational and resource demands of DNN to compute on low-resourced microcontrollers (MCUs). However, most of the current work in embedded deep learning focuses on solving a single task efficiently, while the multi-tasking nature and applications of IoT devices demand systems that can handle a diverse range of tasks (activity, voice, and context recognition) with input from a variety of sensors, simultaneously. In this paper, we propose YONO, a product quantization (PQ) based approach that compresses multiple heterogeneous models and enables in-memory model execution and switching for dissimilar multi-task learning on MCUs. We first adopt PQ to learn codebooks that store weights of different models. Also, we propose a novel network optimization and heuristics to maximize the compression rate and minimize the accuracy loss. Then, we develop an online component of YONO for efficient model execution and switching between multiple tasks on an MCU at run time without relying on an external storage device. YONO shows remarkable performance as it can compress multiple heterogeneous models with negligible or no loss of accuracy up to 12.37$\\times$. Besides, YONO's online component enables an efficient execution (latency of 16-159 ms per operation) and reduces model loading/switching latency and energy consumption by 93.3-94.5% and 93.9-95.0%, respectively, compared to external storage access. Interestingly, YONO can compress various architectures trained with datasets that were not shown during YONO's offline codebook learning phase showing the generalizability of our method. To summarize, YONO shows great potential and opens further doors to enable multi-task learning systems on extremely resource-constrained devices. ",
    "url": "https://arxiv.org/abs/2203.03794",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03798",
    "title": "New Insights on Reducing Abrupt Representation Change in Online  Continual Learning",
    "abstract": "In the online continual learning paradigm, agents must learn from a changing distribution while respecting memory and compute constraints. Experience Replay (ER), where a small subset of past data is stored and replayed alongside new data, has emerged as a simple and effective learning strategy. In this work, we focus on the change in representations of observed data that arises when previously unobserved classes appear in the incoming data stream, and new classes must be distinguished from previous ones. We shed new light on this question by showing that applying ER causes the newly added classes' representations to overlap significantly with the previous classes, leading to highly disruptive parameter updates. Based on this empirical analysis, we propose a new method which mitigates this issue by shielding the learned representations from drastic adaptation to accommodate new classes. We show that using an asymmetric update rule pushes new classes to adapt to the older ones (rather than the reverse), which is more effective especially at task boundaries, where much of the forgetting typically occurs. Empirical results show significant gains over strong baselines on standard continual learning benchmarks ",
    "url": "https://arxiv.org/abs/2203.03798",
    "authors": [
      "Lucas Caccia",
      "Rahaf Aljundi",
      "Nader Asadi",
      "Tinne Tuytelaars",
      "Joelle Pineau",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03805",
    "title": "Discrete Robust Control of Robot Manipulators using an Uncertainty and  Disturbance Estimator",
    "abstract": "This article presents the design of a robust observer based on the discrete-time formulation of Uncertainty and Disturbance Estimator (UDE), a well-known robust control technique, for the purpose of controlling robot manipulators. The design results in a complete closed-loop, robust, controller--observer structure. The observer incorporates the estimate of the overall uncertainty associated with the plant, in order to mimic its dynamics, and the control law is generated using an auxiliary error instead of state tracking error. A detailed qualitative and quantitative stability analysis is provided, and simulations are performed on the two-link robot manipulator system. Further, a comparative study with well-known control strategies for robot manipulators is presented. The results demonstrate the efficacy of the proposed technique, with better tracking performance and lower control energy compared to other strategies. ",
    "url": "https://arxiv.org/abs/2203.03805",
    "authors": [
      "Ram Padmanabhan",
      "Maithili Shetty",
      "T. S. Chandar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.03810",
    "title": "Towards Efficient Data-Centric Robust Machine Learning with Noise-based  Augmentation",
    "abstract": "The data-centric machine learning aims to find effective ways to build appropriate datasets which can improve the performance of AI models. In this paper, we mainly focus on designing an efficient data-centric scheme to improve robustness for models towards unforeseen malicious inputs in the black-box test settings. Specifically, we introduce a noised-based data augmentation method which is composed of Gaussian Noise, Salt-and-Pepper noise, and the PGD adversarial perturbations. The proposed method is built on lightweight algorithms and proved highly effective based on comprehensive evaluations, showing good efficiency on computation cost and robustness enhancement. In addition, we share our insights about the data-centric robust machine learning gained from our experiments. ",
    "url": "https://arxiv.org/abs/2203.03810",
    "authors": [
      "Xiaogeng Liu",
      "Haoyu Wang",
      "Yechao Zhang",
      "Fangzhou Wu",
      "Shengshan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.03818",
    "title": "Shadows can be Dangerous: Stealthy and Effective Physical-world  Adversarial Attack by Natural Phenomenon",
    "abstract": "Estimating the risk level of adversarial examples is essential for safely deploying machine learning models in the real world. One popular approach for physical-world attacks is to adopt the \"sticker-pasting\" strategy, which however suffers from some limitations, including difficulties in access to the target or printing by valid colors. A new type of non-invasive attacks emerged recently, which attempt to cast perturbation onto the target by optics based tools, such as laser beam and projector. However, the added optical patterns are artificial but not natural. Thus, they are still conspicuous and attention-grabbed, and can be easily noticed by humans. In this paper, we study a new type of optical adversarial examples, in which the perturbations are generated by a very common natural phenomenon, shadow, to achieve naturalistic and stealthy physical-world adversarial attack under the black-box setting. We extensively evaluate the effectiveness of this new attack on both simulated and real-world environments. Experimental results on traffic sign recognition demonstrate that our algorithm can generate adversarial examples effectively, reaching 98.23% and 90.47% success rates on LISA and GTSRB test sets respectively, while continuously misleading a moving camera over 95% of the time in real-world scenarios. We also offer discussions about the limitations and the defense mechanism of this attack. ",
    "url": "https://arxiv.org/abs/2203.03818",
    "authors": [
      "Yiqi Zhong",
      "Xianming Liu",
      "Deming Zhai",
      "Junjun Jiang",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03820",
    "title": "A Variational Hierarchical Model for Neural Cross-Lingual Summarization",
    "abstract": "The goal of the cross-lingual summarization (CLS) is to convert a document in one language (e.g., English) to a summary in another one (e.g., Chinese). Essentially, the CLS task is the combination of machine translation (MT) and monolingual summarization (MS), and thus there exists the hierarchical relationship between MT\\&MS and CLS. Existing studies on CLS mainly focus on utilizing pipeline methods or jointly training an end-to-end model through an auxiliary MT or MS objective. However, it is very challenging for the model to directly conduct CLS as it requires both the abilities to translate and summarize. To address this issue, we propose a hierarchical model for the CLS task, based on the conditional variational auto-encoder. The hierarchical model contains two kinds of latent variables at the local and global levels, respectively. At the local level, there are two latent variables, one for translation and the other for summarization. As for the global level, there is another latent variable for cross-lingual summarization conditioned on the two local-level variables. Experiments on two language directions (English-Chinese) verify the effectiveness and superiority of the proposed approach. In addition, we show that our model is able to generate better cross-lingual summaries than comparison models in the few-shot setting. ",
    "url": "https://arxiv.org/abs/2203.03820",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Chulun Zhou",
      "Jinan Xu",
      "Yufeng Chen",
      "Jinsong Su",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.03827",
    "title": "GANSpiration: Balancing Targeted and Serendipitous Inspiration in User  Interface Design with Style-Based Generative Adversarial Network",
    "abstract": "Inspiration from design examples plays a crucial role in the creative process of user interface design. However, current tools and techniques that support inspiration usually only focus on example browsing with limited user control or similarity-based example retrieval, leading to undesirable design outcomes such as focus drift and design fixation. To address these issues, we propose the GANSpiration approach that suggests design examples for both targeted and serendipitous inspiration, leveraging a style-based Generative Adversarial Network. A quantitative evaluation revealed that the outputs of GANSpiration-based example suggestion approaches are relevant to the input design, and at the same time include diverse instances. A user study with professional UI/UX practitioners showed that the examples suggested by our approach serve as viable sources of inspiration for overall design concepts and specific design elements. Overall, our work paves the road of using advanced generative machine learning techniques in supporting the creative design practice. ",
    "url": "https://arxiv.org/abs/2203.03827",
    "authors": [
      "Mohammad Amin Mozaffari",
      "Xinyuan Zhang",
      "Jinghui Cheng",
      "Jin L.C. Guo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.03838",
    "title": "Multi-Scale Self-Contrastive Learning with Hard Negative Mining for  Weakly-Supervised Query-based Video Grounding",
    "abstract": "Query-based video grounding is an important yet challenging task in video understanding, which aims to localize the target segment in an untrimmed video according to a sentence query. Most previous works achieve significant progress by addressing this task in a fully-supervised manner with segment-level labels, which require high labeling cost. Although some recent efforts develop weakly-supervised methods that only need the video-level knowledge, they generally match multiple pre-defined segment proposals with query and select the best one, which lacks fine-grained frame-level details for distinguishing frames with high repeatability and similarity within the entire video. To alleviate the above limitations, we propose a self-contrastive learning framework to address the query-based video grounding task under a weakly-supervised setting. Firstly, instead of utilizing redundant segment proposals, we propose a new grounding scheme that learns frame-wise matching scores referring to the query semantic to predict the possible foreground frames by only using the video-level annotations. Secondly, since some predicted frames (i.e., boundary frames) are relatively coarse and exhibit similar appearance to their adjacent frames, we propose a coarse-to-fine contrastive learning paradigm to learn more discriminative frame-wise representations for distinguishing the false positive frames. In particular, we iteratively explore multi-scale hard negative samples that are close to positive samples in the representation space for distinguishing fine-grained frame-wise details, thus enforcing more accurate segment grounding. Extensive experiments on two challenging benchmarks demonstrate the superiority of our proposed method compared with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.03838",
    "authors": [
      "Shentong Mo",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.03843",
    "title": "Self-supervised Social Relation Representation for Human Group Detection",
    "abstract": "Human group detection, which splits crowd of people into groups, is an important step for video-based human social activity analysis. The core of human group detection is the human social relation representation and division.In this paper, we propose a new two-stage multi-head framework for human group detection. In the first stage, we propose a human behavior simulator head to learn the social relation feature embedding, which is self-supervisely trained by leveraging the socially grounded multi-person behavior relationship. In the second stage, based on the social relation embedding, we develop a self-attention inspired network for human group detection. Remarkable performance on two state-of-the-art large-scale benchmarks, i.e., PANDA and JRDB-Group, verifies the effectiveness of the proposed framework. Benefiting from the self-supervised social relation embedding, our method can provide promising results with very few (labeled) training data. We will release the source code to the public. ",
    "url": "https://arxiv.org/abs/2203.03843",
    "authors": [
      "Jiacheng Li",
      "Ruize Han",
      "Haomin Yan",
      "Zekun Qian",
      "Wei Feng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03850",
    "title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation",
    "abstract": "Pre-trained models for programming languages have recently demonstrated great success on code intelligence. To support both code-related understanding and generation tasks, recent works attempt to pre-train unified encoder-decoder models. However, such encoder-decoder framework is sub-optimal for auto-regressive tasks, especially code completion that requires a decoder-only manner for efficient inference. In this paper, we present UniXcoder, a unified cross-modal pre-trained model for programming language. The model utilizes mask attention matrices with prefix adapters to control the behavior of the model and leverages cross-modal contents like AST and code comment to enhance code representation. To encode AST that is represented as a tree in parallel, we propose a one-to-one mapping method to transform AST in a sequence structure that retains all structural information from the tree. Furthermore, we propose to utilize multi-modal contents to learn representation of code fragment with contrastive learning, and then align representations among programming languages using a cross-modal generation task. We evaluate UniXcoder on five code-related tasks over nine datasets. To further evaluate the performance of code fragment representation, we also construct a dataset for a new task, called zero-shot code-to-code search. Results show that our model achieves state-of-the-art performance on most tasks and analysis reveals that comment and AST can both enhance UniXcoder. ",
    "url": "https://arxiv.org/abs/2203.03850",
    "authors": [
      "Daya Guo",
      "Shuai Lu",
      "Nan Duan",
      "Yanlin Wang",
      "Ming Zhou",
      "Jian Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.03854",
    "title": "Metaverse: Security and Privacy Concerns",
    "abstract": "The term \"metaverse\", a three-dimensional virtual universe similar to the real realm, has always been full of imagination since it was put forward in the 1990s. Recently, it is possible to realize the metaverse with the continuous emergence and progress of various technologies, and thus it has attracted extensive attention again. It may bring a lot of benefits to human society such as reducing discrimination, eliminating individual differences, and socializing. However, everything has security and privacy concerns, which is no exception for the metaverse. In this article, we firstly analyze the concept of the metaverse and propose that it is a super virtual-reality (VR) ecosystem compared with other VR technologies. Then, we carefully analyze and elaborate on possible security and privacy concerns from four perspectives: user information, communication, scenario, and goods, and immediately, the potential solutions are correspondingly put forward. Meanwhile, we propose the need to take advantage of the new buckets effect to comprehensively address security and privacy concerns from a philosophical perspective, which hopefully will bring some progress to the metaverse community. ",
    "url": "https://arxiv.org/abs/2203.03854",
    "authors": [
      "Ruoyu Zhao",
      "Yushu Zhang",
      "Youwen Zhu",
      "Rushi Lan",
      "Zhongyun Hua"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.03856",
    "title": "DARER: Dual-task Temporal Relational Recurrent Reasoning Network for  Joint Dialog Sentiment Classification and Act Recognition",
    "abstract": "The task of joint dialog sentiment classification (DSC) and act recognition (DAR) aims to simultaneously predict the sentiment label and act label for each utterance in a dialog. In this paper, we put forward a new framework which models the explicit dependencies via integrating \\textit{prediction-level interactions} other than semantics-level interactions, more consistent with human intuition. Besides, we propose a speaker-aware temporal graph (SATG) and a dual-task relational temporal graph (DRTG) to introduce \\textit{temporal relations} into dialog understanding and dual-task reasoning. To implement our framework, we propose a novel model dubbed DARER, which first generates the context-, speaker- and temporal-sensitive utterance representations via modeling SATG, then conducts recurrent dual-task relational reasoning on DRTG, in which process the estimated label distributions act as key clues in prediction-level interactions. Experiment results show that DARER outperforms existing models by large margins while requiring much less computation resource and costing less training time. Remarkably, on DSC task in Mastodon, DARER gains a relative improvement of about 25% over previous best model in terms of F1, with less than 50% parameters and about only 60% required GPU memory. ",
    "url": "https://arxiv.org/abs/2203.03856",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.03870",
    "title": "Morphological Anti-Aliasing Method for Boundary Slope Prediction",
    "abstract": "Image pixel aliasing caused by insufficient sampling is a long-standing problem in the field of computer graphics. It has always been the goal of researchers to seek anti-aliasing algorithms with high speed and good effect. Due to the deficiencies in local detection and reconstruction of sloping line boundaries, a morphological anti-aliasing method for boundary slope prediction is proposed. This method uses the information of the local line boundary slope to predict and test the end positions of the line boundary in the global scope, thereby reconstructing The boundary information more consistent with the actual boundary is obtained, and a more accurate linear boundary shape is obtained with only a small increase in the amount of calculation. Compared with the previous morphological anti-aliasing algorithm, the proposed method is based on the global morphological boundary. , can reconstruct the straight line boundary more accurately, and apply it to the anti-aliasing calculation, which can further improve the color transition of the straight line boundary, make the inclined straight line boundary have higher continuity, and obtain a better anti-aliasing effect. ",
    "url": "https://arxiv.org/abs/2203.03870",
    "authors": [
      "Yuchen Zhong",
      "Yuchi Huo",
      "Rui Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2203.03872",
    "title": "Visual anomaly detection in video by variational autoencoder",
    "abstract": "Video anomalies detection is the intersection of anomaly detection and visual intelligence. It has commercial applications in surveillance, security, self-driving cars and crop monitoring. Videos can capture a variety of anomalies. Due to efforts needed to label training data, unsupervised approaches to train anomaly detection models for videos is more practical An autoencoder is a neural network that is trained to recreate its input using latent representation of input also called a bottleneck layer. Variational autoencoder uses distribution (mean and variance) as compared to latent vector as bottleneck layer and can have better regularization effect. In this paper we have demonstrated comparison between performance of convolutional LSTM versus a variation convolutional LSTM autoencoder ",
    "url": "https://arxiv.org/abs/2203.03872",
    "authors": [
      "Faraz Waseem",
      "Rafael Perez Martinez",
      "Chris Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03876",
    "title": "High-order Order Proximity-Incorporated, Symmetry and Graph-Regularized  Nonnegative Matrix Factorization for Community Detection",
    "abstract": "Community describes the functional mechanism of a network, making community detection serve as a fundamental graph tool for various real applications like discovery of social circle. To date, a Symmetric and Non-negative Matrix Factorization (SNMF) model has been frequently adopted to address this issue owing to its high interpretability and scalability. However, most existing SNMF-based community detection methods neglect the high-order connection patterns in a network. Motivated by this discovery, in this paper, we propose a High-Order Proximity (HOP)-incorporated, Symmetry and Graph-regularized NMF (HSGN) model that adopts the following three-fold ideas: a) adopting a weighted pointwise mutual information (PMI)-based approach to measure the HOP indices among nodes in a network; b) leveraging an iterative reconstruction scheme to encode the captured HOP into the network; and c) introducing a symmetry and graph-regularized NMF algorithm to detect communities accurately. Extensive empirical studies on eight real-world networks demonstrate that an HSGN-based community detector significantly outperforms both benchmark and state-of-the-art community detectors in providing highly-accurate community detection results. ",
    "url": "https://arxiv.org/abs/2203.03876",
    "authors": [
      "Zhigang Liu",
      "Xin Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03888",
    "title": "ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via  Adversarial Rotation",
    "abstract": "Point cloud classifiers with rotation robustness have been widely discussed in the 3D deep learning community. Most proposed methods either use rotation invariant descriptors as inputs or try to design rotation equivariant networks. However, robust models generated by these methods have limited performance under clean aligned datasets due to modifications on the original classifiers or input space. In this study, for the first time, we show that the rotation robustness of point cloud classifiers can also be acquired via adversarial training with better performance on both rotated and clean datasets. Specifically, our proposed framework named ART-Point regards the rotation of the point cloud as an attack and improves rotation robustness by training the classifier on inputs with Adversarial RoTations. We contribute an axis-wise rotation attack that uses back-propagated gradients of the pre-trained model to effectively find the adversarial rotations. To avoid model over-fitting on adversarial inputs, we construct rotation pools that leverage the transferability of adversarial rotations among samples to increase the diversity of training data. Moreover, we propose a fast one-step optimization to efficiently reach the final robust model. Experiments show that our proposed rotation attack achieves a high success rate and ART-Point can be used on most existing classifiers to improve the rotation robustness while showing better performance on clean datasets than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.03888",
    "authors": [
      "Robin Wang",
      "Yibo Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03897",
    "title": "Multi-Modal Mixup for Robust Fine-tuning",
    "abstract": "Pre-trained large-scale models provide a transferable embedding, and they show comparable performance on the diverse downstream task. However, the transferability of multi-modal learning is restricted, and the analysis of learned embedding has not been explored well. This paper provides a perspective to understand the multi-modal embedding in terms of uniformity and alignment. We newly find that the representation learned by multi-modal learning models such as CLIP has a two separated representation space for each heterogeneous dataset with less alignment. Besides, there are unexplored large intermediate areas between two modalities with less uniformity. Less robust embedding might restrict the transferability of the representation for the downstream task. This paper provides a new end-to-end fine-tuning method for robust representation that encourages better uniformity and alignment score. First, we propose a multi-modal Mixup, $m^{2}$-Mix that mixes the representation of image and text to generate the hard negative samples. Second, we fine-tune the multi-modal model on a hard negative sample as well as normal negative and positive samples with contrastive learning. Our multi-modal Mixup provides a robust representation, and we validate our methods on classification, retrieval, and structure-awareness task. ",
    "url": "https://arxiv.org/abs/2203.03897",
    "authors": [
      "Junhyuk So",
      "Changdae Oh",
      "Minchul Shin",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03905",
    "title": "End-to-end system for object detection from sub-sampled radar data",
    "abstract": "Robust and accurate sensing is of critical importance for advancing autonomous automotive systems. The need to acquire situational awareness in complex urban conditions using sensors such as radar has motivated research on power and latency-efficient signal acquisition methods. In this paper, we present an end-to-end signal processing pipeline, capable of operating in extreme weather conditions, that relies on sub-sampled radar data to perform object detection in vehicular settings. The results of the object detection are further utilized to sub-sample forthcoming radar data, which stands in contrast to prior work where the sub-sampling relies on image information. We show robust detection based on radar data reconstructed using 20% of samples under extreme weather conditions such as snow or fog, and on low-illuminated nights. Additionally, we generate 20% sampled radar data in a fine-tuning set and show 1.1% gain in AP50 across scenes and 3% AP50 gain in motorway condition. ",
    "url": "https://arxiv.org/abs/2203.03905",
    "authors": [
      "Madhumitha Sakthi",
      "Ahmed Tewfik",
      "Marius Arvinte",
      "Haris Vikalo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03906",
    "title": "Graph Reinforcement Learning for Predictive Power Allocation to Mobile  Users",
    "abstract": "Allocating resources with future channels can save resource to ensure quality-of-service of video streaming. In this paper, we optimize predictive power allocation to minimize the energy consumed at distributed units (DUs) by using deep deterministic policy gradient (DDPG) to find optimal policy and predict average channel gains. To improve training efficiency, we resort to graph DDPG for exploiting two kinds of relational priors: (a) permutation equivariant (PE) and permutation invariant (PI) properties of policy function and action-value function, (b) topology relation among users and DUs. To design graph DDPG framework more systematically in harnessing the priors, we first demonstrate how to transform matrix-based DDPG into graph-based DDPG. Then, we respectively design the actor and critic networks to satisfy the permutation properties when graph neural networks are used in embedding and end to-end manners. To avoid destroying the PE/PI properties of the actor and critic networks, we conceive a batch normalization method. Finally, we show the impact of leveraging each prior. Simulation results show that the learned predictive policy performs close to the optimal solution with perfect future information, and the graph DDPG algorithms converge much faster than existing DDPG algorithms. ",
    "url": "https://arxiv.org/abs/2203.03906",
    "authors": [
      "Jianyu Zhao",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.03910",
    "title": "Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced  Training for Neural Machine Translation",
    "abstract": "Neural networks tend to gradually forget the previously learned knowledge when learning multiple tasks sequentially from dynamic data distributions. This problem is called \\textit{catastrophic forgetting}, which is a fundamental challenge in the continual learning of neural networks. In this work, we observe that catastrophic forgetting not only occurs in continual learning but also affects the traditional static training. Neural networks, especially neural machine translation models, suffer from catastrophic forgetting even if they learn from a static training set. To be specific, the final model pays imbalanced attention to training samples, where recently exposed samples attract more attention than earlier samples. The underlying cause is that training samples do not get balanced training in each model update, so we name this problem \\textit{imbalanced training}. To alleviate this problem, we propose Complementary Online Knowledge Distillation (COKD), which uses dynamically updated teacher models trained on specific data orders to iteratively provide complementary knowledge to the student model. Experimental results on multiple machine translation tasks show that our method successfully alleviates the problem of imbalanced training and achieves substantial improvements over strong baseline systems. ",
    "url": "https://arxiv.org/abs/2203.03910",
    "authors": [
      "Chenze Shao",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03911",
    "title": "Language Matters: A Weakly Supervised Pre-training Approach for Scene  Text Detection and Spotting",
    "abstract": "Recently, Vision-Language Pre-training (VLP) techniques have greatly benefited various vision-language tasks by jointly learning visual and textual representations, which intuitively helps in Optical Character Recognition (OCR) tasks due to the rich visual and textual information in scene text images. However, these methods cannot well cope with OCR tasks because of the difficulty in both instance-level text encoding and image-text pair acquisition (i.e. images and captured texts in them). This paper presents a weakly supervised pre-training method that can acquire effective scene text representations by jointly learning and aligning visual and textual information. Our network consists of an image encoder and a character-aware text encoder that extract visual and textual features, respectively, as well as a visual-textual decoder that models the interaction among textual and visual features for learning effective scene text representations. With the learning of textual features, the pre-trained model can attend texts in images well with character awareness. Besides, these designs enable the learning from weakly annotated texts (i.e. partial texts in images without text bounding boxes) which mitigates the data annotation constraint greatly. Experiments over the weakly annotated images in ICDAR2019-LSVT show that our pre-trained model improves F-score by +2.5% and +4.8% while transferring its weights to other text detection and spotting networks, respectively. In addition, the proposed method outperforms existing pre-training techniques consistently across multiple public datasets (e.g., +3.2% and +1.3% for Total-Text and CTW1500). ",
    "url": "https://arxiv.org/abs/2203.03911",
    "authors": [
      "Chuhui Xue",
      "Yu Hao",
      "Shijian Lu",
      "Philip Torr",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03923",
    "title": "ROLL: Long-Term Robust LiDAR-based Localization With Temporary Mapping  in Changing Environments",
    "abstract": "Long-term scene changes present challenges to localization systems using a pre-built map. This paper presents a LiDAR-based system that can provide robust localization against those challenges. Our method starts with activation of a mapping process temporarily when global matching towards the pre-built map is unreliable. The temporary map will be merged onto the pre-built map for later localization runs once reliable matching is obtained again. We further integrate a LiDAR inertial odometry (LIO) to provide motion-compensated LiDAR scans and a reliable initial pose guess for the global matching module. To generate a smooth real-time trajectory for navigation purposes, we fuse poses from odometry and global matching by solving a pose graph optimization problem. We evaluate our localization system with extensive experiments on the NCLT dataset including a variety of changing indoor and outdoor environments, and the results demonstrate a robust and accurate localization performance for over a year. The implementations are open sourced on GitHub. ",
    "url": "https://arxiv.org/abs/2203.03923",
    "authors": [
      "Bin Peng",
      "Hongle Xie",
      "Weidong Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.03929",
    "title": "Quantifying Privacy Risks of Masked Language Models Using Membership  Inference Attacks",
    "abstract": "The wide adoption and application of Masked language models~(MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities -- to what extent do MLMs leak information about their training data? Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying the potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are extremely susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level, with a significant improvement in the low-error region: at 1% false positive rate, our attack is 51X more powerful than prior work. ",
    "url": "https://arxiv.org/abs/2203.03929",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Kartik Goyal",
      "Archit Uniyal",
      "Taylor Berg-Kirkpatrick",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.03931",
    "title": "Part-Aware Self-Supervised Pre-Training for Person Re-Identification",
    "abstract": "In person re-identification (ReID), very recent researches have validated pre-training the models on unlabelled person images is much better than on ImageNet. However, these researches directly apply the existing self-supervised learning (SSL) methods designed for image classification to ReID without any adaption in the framework. These SSL methods match the outputs of local views (e.g., red T-shirt, blue shorts) to those of the global views at the same time, losing lots of details. In this paper, we propose a ReID-specific pre-training method, Part-Aware Self-Supervised pre-training (PASS), which can generate part-level features to offer fine-grained information and is more suitable for ReID. PASS divides the images into several local areas, and the local views randomly cropped from each area are assigned with a specific learnable [PART] token. On the other hand, the [PART]s of all local areas are also appended to the global views. PASS learns to match the output of the local views and global views on the same [PART]. That is, the learned [PART] of the local views from a local area is only matched with the corresponding [PART] learned from the global views. As a result, each [PART] can focus on a specific local area of the image and extracts fine-grained information of this area. Experiments show PASS sets the new state-of-the-art performances on Market1501 and MSMT17 on various ReID tasks, e.g., vanilla ViT-S/16 pre-trained by PASS achieves 92.2\\%/90.2\\%/88.5\\% mAP accuracy on Market1501 for supervised/UDA/USL ReID. Our codes are available at https://github.com/CASIA-IVA-Lab/PASS-reID. ",
    "url": "https://arxiv.org/abs/2203.03931",
    "authors": [
      "Kuan Zhu",
      "Haiyun Guo",
      "Tianyi Yan",
      "Yousong Zhu",
      "Jinqiao Wang",
      "Ming Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03949",
    "title": "RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering",
    "abstract": "Finding accurate correspondences among different views is the Achilles' heel of unsupervised Multi-View Stereo (MVS). Existing methods are built upon the assumption that corresponding pixels share similar photometric features. However, multi-view images in real scenarios observe non-Lambertian surfaces and experience occlusions. In this work, we propose a novel approach with neural rendering (RC-MVSNet) to solve such ambiguity issues of correspondences among views. Specifically, we impose a depth rendering consistency loss to constrain the geometry features close to the object surface to alleviate occlusions. Concurrently, we introduce a reference view synthesis loss to generate consistent supervision, even for non-Lambertian surfaces. Extensive experiments on DTU and Tanks\\&Temples benchmarks demonstrate that our RC-MVSNet approach achieves state-of-the-art performance over unsupervised MVS frameworks and competitive performance to many supervised methods.The trained models and code will be released at https://github.com/Boese0601/RC-MVSNet. ",
    "url": "https://arxiv.org/abs/2203.03949",
    "authors": [
      "Di Chang",
      "Alja\u017e Bo\u017ei\u010d",
      "Tong Zhang",
      "Qingsong Yan",
      "Yingcong Chen",
      "Sabine S\u00fcsstrunk",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03958",
    "title": "Betweenness Approximation for Hypernetwork Dismantling with Hypergraph  Neural Network",
    "abstract": "The purpose of Network Dismantling (ND) is to find an optimal set of nodes and removing these nodes can greatly decrease the network connectivity. However, current dismantling methods are mainly focus on traditional simple network which only consider the pairwise interaction between two nodes, while the hypernetwork, which can model higher order groupwise relation among arbitrary nodes, is more suitable for modeling real world. Due to the structural difference between simple network and hypernetwork, current dismantling methods cannot be directly applied to hypernetwork dismantling. Although some centrality measures in hypernetwork can be used for hypernetwork dismantling, they face the problem of banlancing effect and efficiency. Therefore, in this paper, we propose a novel HyperNetwork Dismantling methods based on hypergraph neural network, called HND. Specifically, our method first generates plenty of node ranking samples with the help of synthetic hypernetwork generator. Then, a node betweenness approximation model in hypernetwork is built based on hypergraph neural network. And this model is trained on those ranking samples generated in previous step until convergence. Finally, the well-trained model is utilized to approximate the nodes' betweenness in real world hypernetworks and further used for dismantling. To confirm the effectiveness of our method, we conduct extensive experiments on five real world hypernetworks. The experimental results demostrate that the HND outperforms various baselines. ",
    "url": "https://arxiv.org/abs/2203.03958",
    "authors": [
      "Dengcheng Yan",
      "Wenxin Xie",
      "Yiwen Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.03959",
    "title": "Enhancing Door Detection for Autonomous Mobile Robots with  Environment-Specific Data Collection",
    "abstract": "Door detection represents a fundamental capability for autonomous mobile robots employed in tasks involving indoor navigation. Recognizing the presence of a door and its status (open or closed) can induce a remarkable impact on the navigation performance, especially for dynamic settings where doors can enable or disable passages, hence changing the actual topology of the map. In this work, we address the problem of building a door detector module for an autonomous mobile robot deployed in a long-term scenario, namely operating in the same environment for a long time, thus observing the same set of doors from different points of view. First, we show how the mainstream approach for door detection, based on object recognition, falls short in considering the constrained perception setup typical of a mobile robot. Hence, we devise a method to build a dataset of images taken from a robot's perspective and we exploit it to obtain a door detector based on an established deep-learning object-recognition method. We then exploit the long-term assumption of our scenario to qualify the model on the robot working environment via fine-tuning with additional images acquired in the deployment environment. Our experimental analysis shows how this method can achieve good performance and highlights a trade-off between costs and benefits of the fine-tuning approach. ",
    "url": "https://arxiv.org/abs/2203.03959",
    "authors": [
      "Michele Antonazzi",
      "Matteo Luperto",
      "Nicola Basilico",
      "N. Alberto Borghese"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.03962",
    "title": "Generative Cooperative Learning for Unsupervised Video Anomaly Detection",
    "abstract": "Video anomaly detection is well investigated in weakly-supervised and one-class classification (OCC) settings. However, unsupervised video anomaly detection methods are quite sparse, likely because anomalies are less frequent in occurrence and usually not well-defined, which when coupled with the absence of ground truth supervision, could adversely affect the performance of the learning algorithms. This problem is challenging yet rewarding as it can completely eradicate the costs of obtaining laborious annotations and enable such systems to be deployed without human intervention. To this end, we propose a novel unsupervised Generative Cooperative Learning (GCL) approach for video anomaly detection that exploits the low frequency of anomalies towards building a cross-supervision between a generator and a discriminator. In essence, both networks get trained in a cooperative fashion, thereby allowing unsupervised learning. We conduct extensive experiments on two large-scale video anomaly detection datasets, UCF crime, and ShanghaiTech. Consistent improvement over the existing state-of-the-art unsupervised and OCC methods corroborate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2203.03962",
    "authors": [
      "Muhammad Zaigham Zaheer",
      "Arif Mahmood",
      "Muhammad Haris Khan",
      "Mattia Segu",
      "Fisher Yu",
      "Seung-Ik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03963",
    "title": "Reaching Efficient Byzantine Agreements in Bipartite Networks",
    "abstract": "For reaching efficient deterministic synchronous Byzantine agreement upon partially connected networks, the traditional broadcast primitive is extended and integrated with a general framework. With this, the Byzantine agreement is extended to fully connected bipartite networks and some bipartite bounded-degree networks. The complexity of the Byzantine agreement is lowered and optimized with the so-called Byzantine-levers under a general system structure. Some bipartite simulation of the butterfly networks and some finer properties of bipartite bounded-degree networks are also provided for building efficient incomplete Byzantine agreement under the same system structure. It shows that efficient real-world Byzantine agreement systems can be built with the provided algorithms with sufficiently high system assumption coverage. Meanwhile, the proposed bipartite solutions can improve the dependability of the systems in some open, heterogeneous, and even antagonistic environments. ",
    "url": "https://arxiv.org/abs/2203.03963",
    "authors": [
      "Shaolin Yu",
      "Jihong Zhu",
      "Jiali Yang",
      "Wei Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.03965",
    "title": "Few-Shot Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases",
    "abstract": "Accurate short-term traffic prediction plays a pivotal role in various smart mobility operation and management systems. Currently, most of the state-of-the-art prediction models are based on graph neural networks (GNNs), and the required training samples are proportional to the size of the traffic network. In many cities, the available amount of traffic data is substantially below the minimum requirement due to the data collection expense. It is still an open question to develop traffic prediction models with a small size of training data on large-scale networks. We notice that the traffic states of a node for the near future only depend on the traffic states of its localized neighborhoods, which can be represented using the graph relational inductive biases. In view of this, this paper develops a graph network (GN)-based deep learning model LocaleGn that depicts the traffic dynamics using localized data aggregating and updating functions, as well as the node-wise recurrent neural networks. LocaleGn is a light-weighted model designed for training on few samples without over-fitting, and hence it can solve the problem of few-shot traffic prediction. The proposed model is examined on predicting both traffic speed and flow with six datasets, and the experimental results demonstrate that LocaleGn outperforms existing state-of-the-art baseline models. It is also demonstrated that the learned knowledge from LocaleGn can be transferred across cities. The research outcomes can help to develop light-weighted traffic prediction systems, especially for cities lacking in historically archived traffic data. ",
    "url": "https://arxiv.org/abs/2203.03965",
    "authors": [
      "Mingxi Li",
      "Yihong Tang",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2203.03978",
    "title": "Contrastive Conditional Neural Processes",
    "abstract": "Conditional Neural Processes~(CNPs) bridge neural networks with probabilistic inference to approximate functions of Stochastic Processes under meta-learning settings. Given a batch of non-{\\it i.i.d} function instantiations, CNPs are jointly optimized for in-instantiation observation prediction and cross-instantiation meta-representation adaptation within a generative reconstruction pipeline. There can be a challenge in tying together such two targets when the distribution of function observations scales to high-dimensional and noisy spaces. Instead, noise contrastive estimation might be able to provide more robust representations by learning distributional matching objectives to combat such inherent limitation of generative models. In light of this, we propose to equip CNPs by 1) aligning prediction with encoded ground-truth observation, and 2) decoupling meta-representation adaptation from generative reconstruction. Specifically, two auxiliary contrastive branches are set up hierarchically, namely in-instantiation temporal contrastive learning~({\\tt TCL}) and cross-instantiation function contrastive learning~({\\tt FCL}), to facilitate local predictive alignment and global function consistency, respectively. We empirically show that {\\tt TCL} captures high-level abstraction of observations, whereas {\\tt FCL} helps identify underlying functions, which in turn provides more efficient representations. Our model outperforms other CNPs variants when evaluating function distribution reconstruction and parameter identification across 1D, 2D and high-dimensional time-series. ",
    "url": "https://arxiv.org/abs/2203.03978",
    "authors": [
      "Zesheng Ye",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03991",
    "title": "Sparsification and Filtering for Spatial-temporal GNN in Multivariate  Time-series",
    "abstract": "We propose an end-to-end architecture for multivariate time-series prediction that integrates a spatial-temporal graph neural network with a matrix filtering module. This module generates filtered (inverse) correlation graphs from multivariate time series before inputting them into a GNN. In contrast with existing sparsification methods adopted in graph neural network, our model explicitly leverage time-series filtering to overcome the low signal-to-noise ratio typical of complex systems data. We present a set of experiments, where we predict future sales from a synthetic time-series sales dataset. The proposed spatial-temporal graph neural network displays superior performances with respect to baseline approaches, with no graphical information, and with fully connected, disconnected graphs and unfiltered graphs. ",
    "url": "https://arxiv.org/abs/2203.03991",
    "authors": [
      "Yuanrong Wang",
      "Tomaso Aste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2203.03992",
    "title": "Semi-Integrated-Sensing-and-Communication (Semi-ISaC) Networks Assisted  by NOMA",
    "abstract": "This paper investigates non-orthogonal multiple access (NOMA) assisted integrated sensing and communication (ISaC) networks. Compared to the conventional ISaC networks, where the total bandwidth is used for both the radar detection and wireless communications, the proposed Semi-ISaC networks allow that a portion of bandwidth is used for ISaC and the rest of the bandwidth is only utilized for wireless communications. We first derive the analytical expressions of the outage probability for the communication signals, including the signals for the radar target and the communication transmitter. Additionally, we derive the analytical expressions of the ergodic radar estimation information rate (REIR) for the radar echoes. The simulation results show that 1) NOMA ISaC has better spectrum efficiency than the conventional ISaC; and 2) The REIR is enhanced when we enlarge the density of pulses. ",
    "url": "https://arxiv.org/abs/2203.03992",
    "authors": [
      "Chao Zhang",
      "Wenqiang Yi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.04007",
    "title": "DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set  Feature Extraction",
    "abstract": "Existing permutation-invariant methods can be divided into two categories according to the aggregation scope, i.e. global aggregation and local one. Although the global aggregation methods, e. g., PointNet and Deep Sets, get involved in simpler structures, their performance is poorer than the local aggregation ones like PointNet++ and Point Transformer. It remains an open problem whether there exists a global aggregation method with a simple structure, competitive performance, and even much fewer parameters. In this paper, we propose a novel global aggregation permutation-invariant network based on dual MLP dot-product, called DuMLP-Pin, which is capable of being employed to extract features for set inputs, including unordered or unstructured pixel, attribute, and point cloud data sets. We strictly prove that any permutation-invariant function implemented by DuMLP-Pin can be decomposed into two or more permutation-equivariant ones in a dot-product way as the cardinality of the given input set is greater than a threshold. We also show that the DuMLP-Pin can be viewed as Deep Sets with strong constraints under certain conditions. The performance of DuMLP-Pin is evaluated on several different tasks with diverse data sets. The experimental results demonstrate that our DuMLP-Pin achieves the best results on the two classification problems for pixel sets and attribute sets. On both the point cloud classification and the part segmentation, the accuracy of DuMLP-Pin is very close to the so-far best-performing local aggregation method with only a 1-2% difference, while the number of required parameters is significantly reduced by more than 85% in classification and 69% in segmentation, respectively. The code is publicly available on https://github.com/JaronTHU/DuMLP-Pin. ",
    "url": "https://arxiv.org/abs/2203.04007",
    "authors": [
      "Jiajun Fei",
      "Ziyu Zhu",
      "Wenlei Liu",
      "Zhidong Deng",
      "Mingyang Li",
      "Huanjun Deng",
      "Shuo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04011",
    "title": "Evolutionary Neural Cascade Search across Supernetworks",
    "abstract": "To achieve excellent performance with modern neural networks, having the right network architecture is important. Neural Architecture Search (NAS) concerns the automatic discovery of task-specific network architectures. Modern NAS approaches leverage supernetworks whose subnetworks encode candidate neural network architectures. These subnetworks can be trained simultaneously, removing the need to train each network from scratch, thereby increasing the efficiency of NAS. A recent method called Neural Architecture Transfer (NAT) further improves the efficiency of NAS for computer vision tasks by using a multi-objective evolutionary algorithm to find high-quality subnetworks of a supernetwork pretrained on ImageNet. Building upon NAT, we introduce ENCAS - Evolutionary Neural Cascade Search. ENCAS can be used to search over multiple pretrained supernetworks to achieve a trade-off front of cascades of different neural network architectures, maximizing accuracy while minimizing FLOPS count. We test ENCAS on common computer vision benchmarks (CIFAR-10, CIFAR-100, ImageNet) and achieve Pareto dominance over previous state-of-the-art NAS models up to 1.5 GFLOPS. Additionally, applying ENCAS to a pool of 518 publicly available ImageNet classifiers leads to Pareto dominance in all computation regimes and to increasing the maximum accuracy from 88.6% to 89.0%, accompanied by an 18\\% decrease in computation effort from 362 to 296 GFLOPS. Our code is available at https://github.com/AwesomeLemon/ENCAS ",
    "url": "https://arxiv.org/abs/2203.04011",
    "authors": [
      "Alexander Chebykin",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.04027",
    "title": "Data augmentation with mixtures of max-entropy transformations for  filling-level classification",
    "abstract": "We address the problem of distribution shifts in test-time data with a principled data augmentation scheme for the task of content-level classification. In such a task, properties such as shape or transparency of test-time containers (cup or drinking glass) may differ from those represented in the training data. Dealing with such distribution shifts using standard augmentation schemes is challenging and transforming the training images to cover the properties of the test-time instances requires sophisticated image manipulations. We therefore generate diverse augmentations using a family of max-entropy transformations that create samples with new shapes, colors and spectral characteristics. We show that such a principled augmentation scheme, alone, can replace current approaches that use transfer learning or can be used in combination with transfer learning to improve its performance. ",
    "url": "https://arxiv.org/abs/2203.04027",
    "authors": [
      "Apostolos Modas",
      "Andrea Cavallaro",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.04031",
    "title": "Stage-Aware Feature Alignment Network for Real-Time Semantic  Segmentation of Street Scenes",
    "abstract": "Over the past few years, deep convolutional neural network-based methods have made great progress in semantic segmentation of street scenes. Some recent methods align feature maps to alleviate the semantic gap between them and achieve high segmentation accuracy. However, they usually adopt the feature alignment modules with the same network configuration in the decoder and thus ignore the different roles of stages of the decoder during feature aggregation, leading to a complex decoder structure. Such a manner greatly affects the inference speed. In this paper, we present a novel Stage-aware Feature Alignment Network (SFANet) based on the encoder-decoder structure for real-time semantic segmentation of street scenes. Specifically, a Stage-aware Feature Alignment module (SFA) is proposed to align and aggregate two adjacent levels of feature maps effectively. In the SFA, by taking into account the unique role of each stage in the decoder, a novel stage-aware Feature Enhancement Block (FEB) is designed to enhance spatial details and contextual information of feature maps from the encoder. In this way, we are able to address the misalignment problem with a very simple and efficient multi-branch decoder structure. Moreover, an auxiliary training strategy is developed to explicitly alleviate the multi-scale object problem without bringing additional computational costs during the inference phase. Experimental results show that the proposed SFANet exhibits a good balance between accuracy and speed for real-time semantic segmentation of street scenes. In particular, based on ResNet-18, SFANet respectively obtains 78.1% and 74.7% mean of class-wise Intersection-over-Union (mIoU) at inference speeds of 37 FPS and 96 FPS on the challenging Cityscapes and CamVid test datasets by using only a single GTX 1080Ti GPU. ",
    "url": "https://arxiv.org/abs/2203.04031",
    "authors": [
      "Xi Weng",
      "Yan Yan",
      "Si Chen",
      "Jing-Hao Xue",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04032",
    "title": "Bayesian Optimisation-Assisted Neural Network Training Technique for  Radio Localisation",
    "abstract": "Radio signal-based (indoor) localisation technique is important for IoT applications such as smart factory and warehouse. Through machine learning, especially neural networks methods, more accurate mapping from signal features to target positions can be achieved. However, different radio protocols, such as WiFi, Bluetooth, etc., have different features in the transmitted signals that can be exploited for localisation purposes. Also, neural networks methods often rely on carefully configured models and extensive training processes to obtain satisfactory performance in individual localisation scenarios. The above poses a major challenge in the process of determining neural network model structure, or hyperparameters, as well as the selection of training features from the available data. This paper proposes a neural network model hyperparameter tuning and training method based on Bayesian optimisation. Adaptive selection of model hyperparameters and training features can be realised with minimal need for manual model training design. With the proposed technique, the training process is optimised in a more automatic and efficient way, enhancing the applicability of neural networks in localisation. ",
    "url": "https://arxiv.org/abs/2203.04032",
    "authors": [
      "Xingchi Liu",
      "Peizheng Li",
      "Ziming Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.04037",
    "title": "Deep Multi-Branch Aggregation Network for Real-Time Semantic  Segmentation in Street Scenes",
    "abstract": "Real-time semantic segmentation, which aims to achieve high segmentation accuracy at real-time inference speed, has received substantial attention over the past few years. However, many state-of-the-art real-time semantic segmentation methods tend to sacrifice some spatial details or contextual information for fast inference, thus leading to degradation in segmentation quality. In this paper, we propose a novel Deep Multi-branch Aggregation Network (called DMA-Net) based on the encoder-decoder structure to perform real-time semantic segmentation in street scenes. Specifically, we first adopt ResNet-18 as the encoder to efficiently generate various levels of feature maps from different stages of convolutions. Then, we develop a Multi-branch Aggregation Network (MAN) as the decoder to effectively aggregate different levels of feature maps and capture the multi-scale information. In MAN, a lattice enhanced residual block is designed to enhance feature representations of the network by taking advantage of the lattice structure. Meanwhile, a feature transformation block is introduced to explicitly transform the feature map from the neighboring branch before feature aggregation. Moreover, a global context block is used to exploit the global contextual information. These key components are tightly combined and jointly optimized in a unified network. Extensive experimental results on the challenging Cityscapes and CamVid datasets demonstrate that our proposed DMA-Net respectively obtains 77.0% and 73.6% mean Intersection over Union (mIoU) at the inference speed of 46.7 FPS and 119.8 FPS by only using a single NVIDIA GTX 1080Ti GPU. This shows that DMA-Net provides a good tradeoff between segmentation quality and speed for semantic segmentation in street scenes. ",
    "url": "https://arxiv.org/abs/2203.04037",
    "authors": [
      "Xi Weng",
      "Yan Yan",
      "Genshun Dong",
      "Chang Shu",
      "Biao Wang",
      "Hanzi Wang",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04041",
    "title": "Shape-invariant 3D Adversarial Point Clouds",
    "abstract": "Adversary and invisibility are two fundamental but conflict characters of adversarial perturbations. Previous adversarial attacks on 3D point cloud recognition have often been criticized for their noticeable point outliers, since they just involve an \"implicit constrain\" like global distance loss in the time-consuming optimization to limit the generated noise. While point cloud is a highly structured data format, it is hard to metric and constrain its perturbation with a simple loss properly. In this paper, we propose a novel Point-Cloud Sensitivity Map to boost both the efficiency and imperceptibility of point perturbations. This map reveals the vulnerability of point cloud recognition models when encountering shape-invariant adversarial noises. These noises are designed along the shape surface with an \"explicit constrain\" instead of extra distance loss. Specifically, we first apply a reversible coordinate transformation on each point of the point cloud input, to reduce one degree of point freedom and limit its movement on the tangent plane. Then we calculate the best attacking direction with the gradients of the transformed point cloud obtained on the white-box model. Finally we assign each point with a non-negative score to construct the sensitivity map, which benefits both white-box adversarial invisibility and black-box query-efficiency extended in our work. Extensive evaluations prove that our method can achieve the superior performance on various point cloud recognition models, with its satisfying adversarial imperceptibility and strong resistance to different point cloud defense settings. Our code is available at: https://github.com/shikiw/SI-Adv. ",
    "url": "https://arxiv.org/abs/2203.04041",
    "authors": [
      "Qidong Huang",
      "Xiaoyi Dong",
      "Dongdong Chen",
      "Hang Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04049",
    "title": "Graph Attention Transformer Network for Multi-Label Image Classification",
    "abstract": "Multi-label classification aims to recognize multiple objects or attributes from images. However, it is challenging to learn from proper label graphs to effectively characterize such inter-label correlations or dependencies. Current methods often use the co-occurrence probability of labels based on the training set as the adjacency matrix to model this correlation, which is greatly limited by the dataset and affects the model's generalization ability. In this paper, we propose a Graph Attention Transformer Network (GATN), a general framework for multi-label image classification that can effectively mine complex inter-label relationships. First, we use the cosine similarity based on the label word embedding as the initial correlation matrix, which can represent rich semantic information. Subsequently, we design the graph attention transformer layer to transfer this adjacency matrix to adapt to the current domain. Our extensive experiments have demonstrated that our proposed methods can achieve state-of-the-art performance on three datasets. ",
    "url": "https://arxiv.org/abs/2203.04049",
    "authors": [
      "Jin Yuan",
      "Shikai Chen",
      "Yao Zhang",
      "Zhongchao Shi",
      "Xin Geng",
      "Jianping Fan",
      "Yong Rui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04064",
    "title": "Analyzing General-Purpose Deep-Learning Detection and Segmentation  Models with Images from a Lidar as a Camera Sensor",
    "abstract": "Over the last decade, robotic perception algorithms have significantly benefited from the rapid advances in deep learning (DL). Indeed, a significant amount of the autonomy stack of different commercial and research platforms relies on DL for situational awareness, especially vision sensors. This work explores the potential of general-purpose DL perception algorithms, specifically detection and segmentation neural networks, for processing image-like outputs of advanced lidar sensors. Rather than processing the three-dimensional point cloud data, this is, to the best of our knowledge, the first work to focus on low-resolution images with 360\\textdegree field of view obtained with lidar sensors by encoding either depth, reflectivity, or near-infrared light in the image pixels. We show that with adequate preprocessing, general-purpose DL models can process these images, opening the door to their usage in environmental conditions where vision sensors present inherent limitations. We provide both a qualitative and quantitative analysis of the performance of a variety of neural network architectures. We believe that using DL models built for visual cameras offers significant advantages due to the much wider availability and maturity compared to point cloud-based perception. ",
    "url": "https://arxiv.org/abs/2203.04064",
    "authors": [
      "Yu Xianjia",
      "Sahar Salimpour",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04067",
    "title": "Lane Detection with Versatile AtrousFormer and Local Semantic Guidance",
    "abstract": "Lane detection is one of the core functions in autonomous driving and has aroused widespread attention recently. The networks to segment lane instances, especially with bad appearance, must be able to explore lane distribution properties. Most existing methods tend to resort to CNN-based techniques. A few have a try on incorporating the recent adorable, the seq2seq Transformer \\cite{transformer}. However, their innate drawbacks of weak global information collection ability and exorbitant computation overhead prohibit a wide range of the further applications. In this work, we propose Atrous Transformer (AtrousFormer) to solve the problem. Its variant local AtrousFormer is interleaved into feature extractor to enhance extraction. Their collecting information first by rows and then by columns in a dedicated manner finally equips our network with stronger information gleaning ability and better computation efficiency. To further improve the performance, we also propose a local semantic guided decoder to delineate the identities and shapes of lanes more accurately, in which the predicted Gaussian map of the starting point of each lane serves to guide the process. Extensive results on three challenging benchmarks (CULane, TuSimple, and BDD100K) show that our network performs favorably against the state of the arts. ",
    "url": "https://arxiv.org/abs/2203.04067",
    "authors": [
      "Jiaxing Yang",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04076",
    "title": "Semantic Distillation Guided Salient Object Detection",
    "abstract": "Most existing CNN-based salient object detection methods can identify local segmentation details like hair and animal fur, but often misinterpret the real saliency due to the lack of global contextual information caused by the subjectiveness of the SOD task and the locality of convolution layers. Moreover, due to the unrealistically expensive labeling costs, the current existing SOD datasets are insufficient to cover the real data distribution. The limitation and bias of the training data add additional difficulty to fully exploring the semantic association between object-to-object and object-to-environment in a given image. In this paper, we propose a semantic distillation guided SOD (SDG-SOD) method that produces accurate results by fusing semantically distilled knowledge from generated image captioning into the Vision-Transformer-based SOD framework. SDG-SOD can better uncover inter-objects and object-to-environment saliency and cover the gap between the subjective nature of SOD and its expensive labeling. Comprehensive experiments on five benchmark datasets demonstrate that the SDG-SOD outperforms the state-of-the-art approaches on four evaluation metrics, and largely improves the model performance on DUTS, ECSSD, DUT, HKU-IS, and PASCAL-S datasets. ",
    "url": "https://arxiv.org/abs/2203.04076",
    "authors": [
      "Bo Xu",
      "Guanze Liu",
      "Han Huang",
      "Cheng Lu",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.04085",
    "title": "Urban Vehicle Mobility Characteristic Mining and Trip Generation Based  on Knowledge Graph",
    "abstract": "The operation of urban transportation produces massive traffic data, which contains abundant information and is of great significance for the study of intelligent transportation systems. In particular, with the improvement of perception technology, it has become possible to obtain trip data in individual-level of vehicles. It has finer granularity and greater research potential, but at the same time requires higher requirements in terms of data organization and analysis. More importantly it cannot be made public due to privacy issues. To handle individual-level urban vehicle trip big data better, we introduce the knowledge graph for the study. For organization of individual level trip data, we designed and constructed an individual-level trip knowledge graph which greatly improves the efficiency of obtaining data. Then we used the trip knowledge graph as the data engine and designed logical rules to mine the trip characteristics of vehicles by combining the transportation domain knowledge. Finally, we further propose an individual-level trip synthesis method based on knowledge graph generation to address the privacy issue of individual-level traffic data. The experiment shows that the final generated trip data are similar to the historical one in mobility patterns and vehicle associations, and have high spatial continuity. ",
    "url": "https://arxiv.org/abs/2203.04085",
    "authors": [
      "Guilong Li",
      "Yixian Chen",
      "Jun Xie",
      "Qinghai Lin",
      "Zhaocheng He"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.04088",
    "title": "The role of alcohol outlet visits derived from mobile phone location  data in enhancing domestic violence prediction at the neighborhood level",
    "abstract": "Domestic violence (DV) is a serious public health issue, with 1 in 3 women and 1 in 4 men experiencing some form of partner-related violence every year. Existing research has shown a strong association between alcohol use and DV at the individual level. Accordingly, alcohol use could also be a predictor for DV at the neighborhood level, helping identify the neighborhoods where DV is more likely to happen. However, it is difficult and costly to collect data that can represent neighborhood-level alcohol use especially for a large geographic area. In this study, we propose to derive information about the alcohol outlet visits of the residents of different neighborhoods from anonymized mobile phone location data, and investigate whether the derived visits can help better predict DV at the neighborhood level. We use mobile phone data from the company SafeGraph, which is freely available to researchers and which contains information about how people visit various points-of-interest including alcohol outlets. In such data, a visit to an alcohol outlet is identified based on the GPS point location of the mobile phone and the building footprint (a polygon) of the alcohol outlet. We present our method for deriving neighborhood-level alcohol outlet visits, and experiment with four different statistical and machine learning models to investigate the role of the derived visits in enhancing DV prediction based on an empirical dataset about DV in Chicago. Our results reveal the effectiveness of the derived alcohol outlets visits in helping identify neighborhoods that are more likely to suffer from DV, and can inform policies related to DV intervention and alcohol outlet licensing. ",
    "url": "https://arxiv.org/abs/2203.04088",
    "authors": [
      "Ting Chang",
      "Yingjie Hu",
      "Dane Taylor",
      "Brian M. Quigley"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04089",
    "title": "Associating eHealth Policies and National Data Privacy Regulations",
    "abstract": "As electronic data becomes the lifeline of modern society, privacy concerns increase. These concerns are reflected by the European Union's enactment of the General Data Protection Regulation (GDPR), one of the most comprehensive and robust privacy regulations globally. This project aims to evaluate and highlight associations between eHealth systems' policies and personal data privacy regulations. Using bias-corrected Cramer's V and Thiel's U tests, we found weak and zero associations between e-health systems' rules and protections for data privacy. A simple decision tree model is trained, which validates the association scores obtained ",
    "url": "https://arxiv.org/abs/2203.04089",
    "authors": [
      "Saurav K. Aryal",
      "Peter A. Keiller"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.04111",
    "title": "Plumeria at SemEval-2022 Task 6: Robust Approaches for Sarcasm Detection  for English and Arabic Using Transformers and Data Augmentation",
    "abstract": "This paper describes our submission to SemEval-2022 Task 6 on sarcasm detection and its five subtasks for English and Arabic. Sarcasm conveys a meaning which contradicts the literal meaning, and it is mainly found on social networks. It has a significant role in understanding the intention of the user. For detecting sarcasm, we used deep learning techniques based on transformers due to its success in the field of Natural Language Processing (NLP) without the need for feature engineering. The datasets were taken from tweets. We created new datasets by augmenting with external data or by using word embeddings and repetition of instances. Experiments were done on the datasets with different types of preprocessing because it is crucial in this task. The rank of our team was consistent across four subtasks (fourth rank in three subtasks and sixth rank in one subtask); whereas other teams might be in the top ranks for some subtasks but rank drastically less in other subtasks. This implies the robustness and stability of the models and the techniques we used. ",
    "url": "https://arxiv.org/abs/2203.04111",
    "authors": [
      "Shubham Kumar Nigam",
      "Mosab Shaheen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04114",
    "title": "A study on joint modeling and data augmentation of multi-modalities for  audio-visual scene classification",
    "abstract": "In this paper, we propose two techniques, namely joint modeling and data augmentation, to improve system performances for audio-visual scene classification (AVSC). We employ pre-trained networks trained only on image data sets to extract video embedding; whereas for audio embedding models, we decide to train them from scratch. We explore different neural network architectures for joint modeling to effectively combine the video and audio modalities. Moreover, data augmentation strategies are investigated to increase audio-visual training set size. For the video modality the effectiveness of several operations in RandAugment is verified. An audio-video joint mixup scheme is proposed to further improve AVSC performances. Evaluated on the development set of TAU Urban Audio Visual Scenes 2021, our final system can achieve the best accuracy of 94.2% among all single AVSC systems submitted to DCASE 2021 Task 1b. ",
    "url": "https://arxiv.org/abs/2203.04114",
    "authors": [
      "Qing Wang",
      "Jun Du",
      "Siyuan Zheng",
      "Yunqing Li",
      "Yajian Wang",
      "Yuzhong Wu",
      "Hu Hu",
      "Chao-Han Huck Yang",
      "Sabato Marco Siniscalchi",
      "Yannan Wang",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.04129",
    "title": "YouTube-GDD: A challenging gun detection dataset with rich contextual  information",
    "abstract": "An automatic gun detection system can detect potential gun-related violence at an early stage that is of paramount importance for citizens security. In the whole system, object detection algorithm is the key to perceive the environment so that the system can detect dangerous objects such as pistols and rifles. However, mainstream deep learning-based object detection algorithms depend heavily on large-scale high-quality annotated samples, and the existing gun datasets are characterized by low resolution, little contextual information and little data volume. To promote the development of security, this work presents a new challenging dataset called YouTube Gun Detection Dataset (YouTube-GDD). Our dataset is collected from 343 high-definition YouTube videos and contains 5000 well-chosen images, in which 16064 instances of gun and 9046 instances of person are annotated. Compared to other datasets, YouTube-GDD is \"dynamic\", containing rich contextual information and recording shape changes of the gun during shooting. To build a baseline for gun detection, we evaluate YOLOv5 on YouTube-GDD and analyze the influence of additional related annotated information on gun detection. YouTube-GDD and subsequent updates will be released at https://github.com/UCAS-GYX/YouTube-GDD. ",
    "url": "https://arxiv.org/abs/2203.04129",
    "authors": [
      "Yongxiang Gu",
      "Xingbin Liao",
      "Xiaolin Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04130",
    "title": "NeReF: Neural Refractive Field for Fluid Surface Reconstruction and  Implicit Representation",
    "abstract": "Existing neural reconstruction schemes such as Neural Radiance Field (NeRF) are largely focused on modeling opaque objects. We present a novel neural refractive field(NeReF) to recover wavefront of transparent fluids by simultaneously estimating the surface position and normal of the fluid front. Unlike prior arts that treat the reconstruction target as a single layer of the surface, NeReF is specifically formulated to recover a volumetric normal field with its corresponding density field. A query ray will be refracted by NeReF according to its accumulated refractive point and normal, and we employ the correspondences and uniqueness of refracted ray for NeReF optimization. We show NeReF, as a global optimization scheme, can more robustly tackle refraction distortions detrimental to traditional methods for correspondence matching. Furthermore, the continuous NeReF representation of wavefront enables view synthesis as well as normal integration. We validate our approach on both synthetic and real data and show it is particularly suitable for sparse multi-view acquisition. We hence build a small light field array and experiment on various surface shapes to demonstrate high fidelity NeReF reconstruction. ",
    "url": "https://arxiv.org/abs/2203.04130",
    "authors": [
      "Ziyu Wang",
      "Wei Yang",
      "Junming Cao",
      "Lan Xu",
      "Junqing Yu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04147",
    "title": "Mu-synthesis PID Control of Full-Car with Parallel Active Link  Suspension Under Variable Payload",
    "abstract": "This paper presents a combined mu-synthesis PID control scheme, employing a frequency separation paradigm, for a recently proposed novel active suspension, the Parallel Active Link Suspension (PALS). The developed mu-synthesis control scheme is superior to the conventional H-infinity control, previously designed for the PALS, in terms of ride comfort and road holding (higher frequency dynamics), with important realistic uncertainties, such as in vehicle payload, taken into account. The developed PID control method is applied to guarantee good chassis attitude control capabilities and minimization of pitch and roll motions (low frequency dynamics). A multi-objective control method, which merges the aforementioned PID and mu-synthesis-based controls is further introduced to achieve simultaneously the low frequency mitigation of attitude motions and the high frequency vibration suppression of the vehicle. A seven-degree-of-freedom Sport Utility Vehicle (SUV) full car model with PALS, is employed in this work to test the synthesized controller by nonlinear simulations with different ISO-defined road events and variable vehicle payload. The results demonstrate the control scheme's significant robustness and performance, as compared to the conventional passive suspension as well as the actively controlled PALS by conventional H-infinity control, achieved for a wide range of vehicle payload considered in the investigation. ",
    "url": "https://arxiv.org/abs/2203.04147",
    "authors": [
      "Zilin Feng",
      "Min Yu",
      "Simos A. Evangelou",
      "Imad M Jaimoukha",
      "Daniele Dini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.04156",
    "title": "Robust Local Preserving and Global Aligning Network for Adversarial  Domain Adaptation",
    "abstract": "Unsupervised domain adaptation (UDA) requires source domain samples with clean ground truth labels during training. Accurately labeling a large number of source domain samples is time-consuming and laborious. An alternative is to utilize samples with noisy labels for training. However, training with noisy labels can greatly reduce the performance of UDA. In this paper, we address the problem that learning UDA models only with access to noisy labels and propose a novel method called robust local preserving and global aligning network (RLPGA). RLPGA improves the robustness of the label noise from two aspects. One is learning a classifier by a robust informative-theoretic-based loss function. The other is constructing two adjacency weight matrices and two negative weight matrices by the proposed local preserving module to preserve the local topology structures of input data. We conduct theoretical analysis on the robustness of the proposed RLPGA and prove that the robust informative-theoretic-based loss and the local preserving module are beneficial to reduce the empirical risk of the target domain. A series of empirical studies show the effectiveness of our proposed RLPGA. ",
    "url": "https://arxiv.org/abs/2203.04156",
    "authors": [
      "Wenwen Qiang",
      "Jiangmeng Li",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04160",
    "title": "Robustly-reliable learners under poisoning attacks",
    "abstract": "Data poisoning attacks, in which an adversary corrupts a training set with the goal of inducing specific desired mistakes, have raised substantial concern: even just the possibility of such an attack can make a user no longer trust the results of a learning system. In this work, we show how to achieve strong robustness guarantees in the face of such attacks across multiple axes. We provide robustly-reliable predictions, in which the predicted label is guaranteed to be correct so long as the adversary has not exceeded a given corruption budget, even in the presence of instance targeted attacks, where the adversary knows the test example in advance and aims to cause a specific failure on that example. Our guarantees are substantially stronger than those in prior approaches, which were only able to provide certificates that the prediction of the learning algorithm does not change, as opposed to certifying that the prediction is correct, as we are able to achieve in our work. Remarkably, we provide a complete characterization of learnability in this setting, in particular, nearly-tight matching upper and lower bounds on the region that can be certified, as well as efficient algorithms for computing this region given an ERM oracle. Moreover, for the case of linear separators over logconcave distributions, we provide efficient truly polynomial time algorithms (i.e., non-oracle algorithms) for such robustly-reliable predictions. We also extend these results to the active setting where the algorithm adaptively asks for labels of specific informative examples, and the difficulty is that the adversary might even be adaptive to this interaction, as well as to the agnostic learning setting where there is no perfect classifier even over the uncorrupted data. ",
    "url": "https://arxiv.org/abs/2203.04160",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Steve Hanneke",
      "Dravyansh Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.04162",
    "title": "Feedforward PID Control of Full-Car with Parallel Active Link Suspension  for Improved Chassis Attitude Stabilization",
    "abstract": "PID control is commonly utilized in an active suspension system to achieve desirable chassis attitude, where, due to delays, feedback information has much difficulty regulating the roll and pitch behavior, and stabilizing the chassis attitude, which may result in roll over when the vehicle steers at a large longitudinal velocity. To address the problem of the feedback delays in chassis attitude stabilization, in this paper, a feedforward control strategy is proposed to combine with a previously developed PID control scheme in the recently introduced Parallel Active Link Suspension (PALS). Numerical simulations with a nonlinear multi-body vehicle model are performed, where a set of ISO driving maneuvers are tested. Results demonstrate the feedforward-based control scheme has improved suspension performance as compared to the conventional PID control, with faster speed of convergence in brake in a turn and step steer maneuvers, and surviving the fishhook maneuver (although displaying two-wheel lift-off) with 50 mph maneuver entrance speed at which conventional PID control rolls over. ",
    "url": "https://arxiv.org/abs/2203.04162",
    "authors": [
      "Zilin Feng",
      "Min Yu",
      "Simos A. Evangelou",
      "Imad M Jaimoukha",
      "Daniele Dini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.04177",
    "title": "Occupancy Map Prediction for Improved Indoor Robot Navigation",
    "abstract": "In the typical path planning pipeline for a ground robot, we build a map (e.g., an occupancy grid) of the environment as the robot moves around. While navigating indoors, a ground robot's knowledge about the environment may be limited by the occlusions in its surroundings. Therefore, the map will have many as-yet-unknown regions that may need to be avoided by a conservative planner. Instead, if a robot is able to correctly infer what its surroundings and occluded regions look like, the navigation can be further optimized. In this work, we propose an approach using pix2pix and UNet to infer the occupancy grid in unseen areas near the robot as an image-to-image translation task. Our approach simplifies the task of occupancy map prediction for the deep learning network and reduces the amount of data required compared to similar existing methods. We show that the predicted map improves the navigation time in simulations over the existing approaches. ",
    "url": "https://arxiv.org/abs/2203.04177",
    "authors": [
      "Vishnu Dutt Sharma",
      "Jingxi Chen",
      "Abhinav Shrivastava",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.04192",
    "title": "Neural Contextual Bandits via Reward-Biased Maximum Likelihood  Estimation",
    "abstract": "Reward-biased maximum likelihood estimation (RBMLE) is a classic principle in the adaptive control literature for tackling explore-exploit trade-offs. This paper studies the stochastic contextual bandit problem with general bounded reward functions and proposes NeuralRBMLE, which adapts the RBMLE principle by adding a bias term to the log-likelihood to enforce exploration. NeuralRBMLE leverages the representation power of neural networks and directly encodes exploratory behavior in the parameter space, without constructing confidence intervals of the estimated rewards. We propose two variants of NeuralRBMLE algorithms: The first variant directly obtains the RBMLE estimator by gradient ascent, and the second variant simplifies RBMLE to a simple index policy through an approximation. We show that both algorithms achieve $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret. Through extensive experiments, we demonstrate that the NeuralRBMLE algorithms achieve comparable or better empirical regrets than the state-of-the-art methods on real-world datasets with non-linear reward functions. ",
    "url": "https://arxiv.org/abs/2203.04192",
    "authors": [
      "Yu-Heng Hung",
      "Ping-Chun Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.04227",
    "title": "Learning based Age of Information Minimization in UAV-relayed IoT  Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are used as aerial base-stations to relay time-sensitive packets from IoT devices to the nearby terrestrial base-station (TBS). Scheduling of packets in such UAV-relayed IoT-networks to ensure fresh (or up-to-date) IoT devices' packets at the TBS is a challenging problem as it involves two simultaneous steps of (i) sampling of packets generated at IoT devices by the UAVs [hop-1] and (ii) updating of sampled packets from UAVs to the TBS [hop-2]. To address this, we propose Age-of-Information (AoI) scheduling algorithms for two-hop UAV-relayed IoT-networks. First, we propose a low-complexity AoI scheduler, termed, MAF-MAD that employs Maximum AoI First (MAF) policy for sampling of IoT devices at UAV (hop-1) and Maximum AoI Difference (MAD) policy for updating sampled packets from UAV to the TBS (hop-2). We prove that MAF-MAD is the optimal AoI scheduler under ideal conditions (lossless wireless channels and generate-at-will traffic-generation at IoT devices). On the contrary, for general conditions (lossy channel conditions and varying periodic traffic-generation at IoT devices), a deep reinforcement learning algorithm, namely, Proximal Policy Optimization (PPO)-based scheduler is proposed. Simulation results show that the proposed PPO-based scheduler outperforms other schedulers like MAF-MAD, MAF, and round-robin in all considered general scenarios. ",
    "url": "https://arxiv.org/abs/2203.04227",
    "authors": [
      "Biplav Choudhury",
      "Prasenjit Karmakar",
      "Vijay K. Shah",
      "Jeffrey H. Reed"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04229",
    "title": "Neural Face Identification in a 2D Wireframe Projection of a Manifold  Object",
    "abstract": "In computer-aided design (CAD) systems, 2D line drawings are commonly used to illustrate 3D object designs. To reconstruct the 3D models depicted by a single 2D line drawing, an important key is finding the edge loops in the line drawing which correspond to the actual faces of the 3D object. In this paper, we approach the classical problem of face identification from a novel data-driven point of view. We cast it as a sequence generation problem: starting from an arbitrary edge, we adopt a variant of the popular Transformer model to predict the edges associated with the same face in a natural order. This allows us to avoid searching the space of all possible edge loops with various hand-crafted rules and heuristics as most existing methods do, deal with challenging cases such as curved surfaces and nested edge loops, and leverage additional cues such as face types. We further discuss how possibly imperfect predictions can be used for 3D object reconstruction. ",
    "url": "https://arxiv.org/abs/2203.04229",
    "authors": [
      "Kehan Wang",
      "Jia Zheng",
      "Zihan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04234",
    "title": "Adaptative Perturbation Patterns: Realistic Adversarial Learning for  Robust NIDS",
    "abstract": "Adversarial attacks pose a major threat to machine learning and to the systems that rely on it. Nonetheless, adversarial examples cannot be freely generated for domains with tabular data, such as cybersecurity. This work establishes the fundamental constraint levels required to achieve realism and introduces the Adaptative Perturbation Pattern Method (A2PM) to fulfill these constraints in a gray-box setting. A2PM relies on pattern sequences that are independently adapted to the characteristics of each class to create valid and coherent data perturbations. The developed method was evaluated in a cybersecurity case study with two scenarios: Enterprise and Internet of Things (IoT) networks. Multilayer Perceptron (MLP) and Random Forest (RF) classifiers were created with regular and adversarial training, using the CIC-IDS2017 and IoT-23 datasets. In each scenario, targeted and untargeted attacks were performed against the classifiers, and the generated examples were compared with the original network traffic flows to assess their realism. The obtained results demonstrate that A2PM provides a time efficient generation of realistic adversarial examples, which can be advantageous for both adversarial training and attacks. ",
    "url": "https://arxiv.org/abs/2203.04234",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Nuno Oliveira",
      "Isabel Pra\u00e7a"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.04250",
    "title": "Edge Intersection Graphs of Paths on a Triangular Grid",
    "abstract": "We introduce a new class of intersection graphs, the edge intersection graphs of paths on a triangular grid, called EPGt graphs. We show similarities and differences from this new class to the well-known class of EPG graphs. A turn of a path at a grid point is called a bend. An EPGt representation in which every path has at most $k$ bends is called a B$_k$-EPGt representation and the corresponding graphs are called B$_k$-EPGt graphs. We provide examples of B$_{2}$-EPG graphs that are B$_{1}$-EPGt. We characterize the representation of cliques with three vertices and chordless 4-cycles in B$_{1}$-EPGt representations. We also prove that B$_{1}$-EPGt graphs have Strong Helly number $3$. Furthermore, we prove that B$_{1}$-EPGt graphs are $7$-clique colorable. ",
    "url": "https://arxiv.org/abs/2203.04250",
    "authors": [
      "Vitor T. F. de Luca",
      "Mar\u00eda P\u00eda Mazzoleni",
      "Fabiano S. Oliveira",
      "Tanilson D. Santos",
      "Jayme L. Szwarcfiter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2203.04251",
    "title": "End-to-End Semi-Supervised Learning for Video Action Detection",
    "abstract": "In this work, we focus on semi-supervised learning for video action detection which utilizes both labeled as well as unlabeled data. We propose a simple end-to-end consistency based approach which effectively utilizes the unlabeled data. Video action detection requires both, action class prediction as well as a spatio-temporal localization of actions. Therefore, we investigate two types of constraints, classification consistency, and spatio-temporal consistency. The presence of predominant background and static regions in a video makes it challenging to utilize spatio-temporal consistency for action detection. To address this, we propose two novel regularization constraints for spatio-temporal consistency; 1) temporal coherency, and 2) gradient smoothness. Both these aspects exploit the temporal continuity of action in videos and are found to be effective for utilizing unlabeled videos for action detection. We demonstrate the effectiveness of the proposed approach on two different action detection benchmark datasets, UCF101-24 and JHMDB-21. In addition, we also show the effectiveness of the proposed approach for video object segmentation on the Youtube-VOS dataset which demonstrates its generalization capability to other tasks. The proposed approach achieves competitive performance by using merely 20% of annotations on UCF101-24 when compared with recent fully supervised methods. On UCF101-24, it improves the score by +8.9% and +11% at 0.5 f-mAP and v-mAP respectively, compared to supervised approach. ",
    "url": "https://arxiv.org/abs/2203.04251",
    "authors": [
      "Akash Kumar",
      "Yogesh Singh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.04264",
    "title": "A Survey on Privacy for B5G/6G: New Privacy Goals, Challenges, and  Research Directions",
    "abstract": "Massive progress of mobile wireless telecommunication networks was achieved in the previous decades, with privacy enhancement in each. At present, mobile users are getting familiar with the latest 5G networks, and the discussion for the next generation of Beyond 5G (B5G)/6G networks has already been initiated. It is expected that B5G/6G will push the existing network capabilities to the next level, with higher speeds, enhanced reliability, and seamless connectivity. To make these expectations a reality, research is progressing on new technologies, architectures, and intelligence-based decision-making processes related to B5G/6G. Privacy considerations are a crucial aspect that needs further attention in such developments, as billions of people and devices will be transmitting their data through the upcoming network. This paper provides a comprehensive survey on privacy-related aspects for B5G/6G networks. First, it discusses a taxonomy of different privacy perspectives. Based on the taxonomy, the paper then conceptualizes a set of privacy goals for the B5G/6G and the challenges that appear as barriers to reaching these goals. Next, this work provides a set of solutions applicable to the proposed architecture of B5G/6G networks to mitigate the challenges. Additionally, this paper discusses the emerging field of non-personal data privacy. It also provides an overview of standardization initiatives for privacy preservation. Finally, it concludes with a roadmap of future directions and upcoming trends containing privacy-related topics, which will be an arena for new research towards privacy-enhanced B5G/6G networks. This work provides a basis for privacy aspects that will significantly impact peoples' daily lives with future networks. ",
    "url": "https://arxiv.org/abs/2203.04264",
    "authors": [
      "Chamara Sandeepa",
      "Bartlomiej Siniarski",
      "Nicolas Kourtellis",
      "Shen Wang",
      "Madhusanka Liyanage"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.04275",
    "title": "Robust Multi-Task Learning and Online Refinement for Spacecraft Pose  Estimation across Domain Gap",
    "abstract": "This work presents Spacecraft Pose Network v2 (SPNv2), a Convolutional Neural Network (CNN) for pose estimation of noncooperative spacecraft across domain gap. SPNv2 is a multi-scale, multi-task CNN which consists of a shared multi-scale feature encoder and multiple prediction heads that perform different tasks on a shared feature output. These tasks are all related to detection and pose estimation of a target spacecraft from an image, such as prediction of pre-defined satellite keypoints, direct pose regression, and binary segmentation of the satellite foreground. It is shown that by jointly training on different yet related tasks with extensive data augmentations on synthetic images only, the shared encoder learns features that are common across image domains that have fundamentally different visual characteristics compared to synthetic images. This work also introduces Online Domain Refinement (ODR) which refines the parameters of the normalization layers of SPNv2 on the target domain images online at deployment. Specifically, ODR performs self-supervised entropy minimization of the predicted satellite foreground, thereby improving the CNN's performance on the target domain images without their pose labels and with minimal computational efforts. The GitHub repository for SPNv2 will be made available in the near future. ",
    "url": "https://arxiv.org/abs/2203.04275",
    "authors": [
      "Tae Ha Park",
      "Simone D'Amico"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04286",
    "title": "Proximal PanNet: A Model-Based Deep Network for Pansharpening",
    "abstract": "Recently, deep learning techniques have been extensively studied for pansharpening, which aims to generate a high resolution multispectral (HRMS) image by fusing a low resolution multispectral (LRMS) image with a high resolution panchromatic (PAN) image. However, existing deep learning-based pansharpening methods directly learn the mapping from LRMS and PAN to HRMS. These network architectures always lack sufficient interpretability, which limits further performance improvements. To alleviate this issue, we propose a novel deep network for pansharpening by combining the model-based methodology with the deep learning method. Firstly, we build an observation model for pansharpening using the convolutional sparse coding (CSC) technique and design a proximal gradient algorithm to solve this model. Secondly, we unfold the iterative algorithm into a deep network, dubbed as Proximal PanNet, by learning the proximal operators using convolutional neural networks. Finally, all the learnable modules can be automatically learned in an end-to-end manner. Experimental results on some benchmark datasets show that our network performs better than other advanced methods both quantitatively and qualitatively. ",
    "url": "https://arxiv.org/abs/2203.04286",
    "authors": [
      "Xiangyong Cao",
      "Yang Chen",
      "Wenfei Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.02090",
    "title": "Bayesian community detection for networks with covariates",
    "abstract": "The increasing prevalence of network data in a vast variety of fields and the need to extract useful information out of them have spurred fast developments in related models and algorithms. Among the various learning tasks with network data, community detection, the discovery of node clusters or \"communities,\" has arguably received the most attention in the scientific community. In many real-world applications, the network data often come with additional information in the form of node or edge covariates that should ideally be leveraged for inference. In this paper, we add to a limited literature on community detection for networks with covariates by proposing a Bayesian stochastic block model with a covariate-dependent random partition prior. Under our prior, the covariates are explicitly expressed in specifying the prior distribution on the cluster membership. Our model has the flexibility of modeling uncertainties of all the parameter estimates including the community membership. Importantly, and unlike the majority of existing methods, our model has the ability to learn the number of the communities via posterior inference without having to assume it to be known. Our model can be applied to community detection in both dense and sparse networks, with both categorical and continuous covariates, and our MCMC algorithm is very efficient with good mixing properties. We demonstrate the superior performance of our model over existing models in a comprehensive simulation study and an application to two real datasets. ",
    "url": "https://arxiv.org/abs/2203.02090",
    "authors": [
      "Luyi Shen",
      "Arash Amini",
      "Nathaniel Josephs",
      "Lizhen Lin"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03624",
    "title": "Fusion-Correction Network for Single-Exposure Correction and  Multi-Exposure Fusion",
    "abstract": "The photographs captured by digital cameras usually suffer from over-exposure or under-exposure problems. The Single-Exposure Correction (SEC) and Multi-Exposure Fusion (MEF) are two widely studied image processing tasks for image exposure enhancement. However, current SEC and MEF methods ignore the internal correlation between SEC and MEF, and are proposed under distinct frameworks. What's more, most MEF methods usually fail at processing a sequence containing only under-exposed or over-exposed images. To alleviate these problems, in this paper, we develop an integrated framework to simultaneously tackle the SEC and MEF tasks. Built upon the Laplacian Pyramid (LP) decomposition, we propose a novel Fusion-Correction Network (FCNet) to fuse and correct an image sequence sequentially in a multi-level scheme. In each LP level, the image sequence is feed into a Fusion block and a Correction block for consecutive image fusion and exposure correction. The corrected image is upsampled and re-composed with the high-frequency detail components in next-level, producing the base sequence for the next-level blocks. Experiments on the benchmark dataset demonstrate that our FCNet is effective on both the SEC and MEF tasks. ",
    "url": "https://arxiv.org/abs/2203.03624",
    "authors": [
      "Jin Liang",
      "Anran Zhang",
      "Jun Xu",
      "Hui Li",
      "Xiantong Zhen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03627",
    "title": "Multi-channel deep convolutional neural networks for multi-classifying  thyroid disease",
    "abstract": "Thyroid disease instances have been continuously increasing since the 1990s, and thyroid cancer has become the most rapidly rising disease among all the malignancies in recent years. Most existing studies focused on applying deep convolutional neural networks for detecting thyroid cancer. Despite their satisfactory performance on binary classification tasks, limited studies have explored multi-class classification of thyroid disease types; much less is known of the diagnosis of co-existence situation for different types of thyroid diseases. Therefore, this study proposed a novel multi-channel convolutional neural network (CNN) architecture to address the multi-class classification task of thyroid disease. The multi-channel CNN merits from computed tomography to drive a comprehensive diagnostic decision for the overall thyroid gland, emphasizing the disease co-existence circumstance. Moreover, this study also examined alternative strategies to enhance the diagnostic accuracy of CNN models through concatenation of different scales of feature maps. Benchmarking experiments demonstrate the improved performance of the proposed multi-channel CNN architecture compared with the standard single-channel CNN architecture. More specifically, the multi-channel CNN achieved an accuracy of 0.909, precision of 0.944, recall of 0.896, specificity of 0.994, and F1 of 0.917, in contrast to the single-channel CNN, which obtained 0.902, 0.892, 0.909, 0.993, 0.898, respectively. In addition, the proposed model was evaluated in different gender groups; it reached a diagnostic accuracy of 0.908 for the female group and 0.901 for the male group. Collectively, the results highlight that the proposed multi-channel CNN has excellent generalization and has the potential to be deployed to provide computational decision support in clinical settings. ",
    "url": "https://arxiv.org/abs/2203.03627",
    "authors": [
      "Xinyu Zhang",
      "Vincent CS. Lee",
      "Jia Rong",
      "James C. Lee",
      "Jiangning Song",
      "Feng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03634",
    "title": "InsightNet: non-contact blood pressure measuring network based on face  video",
    "abstract": "Blood pressure indicates cardiac function and peripheral vascular resistance and is critical for disease diagnosis. Traditionally, blood pressure data are mainly acquired through contact sensors, which require high maintenance and may be inconvenient and unfriendly to some people (e.g., burn patients). In this paper, an efficient non-contact blood pressure measurement network based on face videos is proposed for the first time. An innovative oversampling training strategy is proposed to handle the unbalanced data distribution. The input video sequences are first normalized and converted to our proposed YUVT color space. Then, the Spatio-temporal slicer encodes it into a multi-domain Spatio-temporal mapping. Finally, the neural network computation module, used for high-dimensional feature extraction of the multi-domain spatial feature mapping, after which the extracted high-dimensional features are used to enhance the time-domain feature association using LSTM, is computed by the blood pressure classifier to obtain the blood pressure measurement intervals. Combining the output of feature extraction and the result after classification, the blood pressure calculator, calculates the blood pressure measurement values. The solution uses a blood pressure classifier to calculate blood pressure intervals, which can help the neural network distinguish between the high-dimensional features of different blood pressure intervals and alleviate the overfitting phenomenon. It can also locate the blood pressure intervals, correct the final blood pressure values and improve the network performance. Experimental results on two datasets show that the network outperforms existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.03634",
    "authors": [
      "Jialiang Zhuang",
      "Bin Li",
      "Yun Zhang",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.03640",
    "title": "Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch  Decoder Network",
    "abstract": "Fully convolutional neural networks have made promising progress in joint liver and liver tumor segmentation. Instead of following the debates over 2D versus 3D networks (for example, pursuing the balance between large-scale 2D pretraining and 3D context), in this paper, we novelly identify the wide variation in the ratio between intra- and inter-slice resolutions as a crucial obstacle to the performance. To tackle the mismatch between the intra- and inter-slice information, we propose a slice-aware 2.5D network that emphasizes extracting discriminative features utilizing not only in-plane semantics but also out-of-plane coherence for each separate slice. Specifically, we present a slice-wise multi-input multi-output architecture to instantiate such a design paradigm, which contains a Multi-Branch Decoder (MD) with a Slice-centric Attention Block (SAB) for learning slice-specific features and a Densely Connected Dice (DCD) loss to regularize the inter-slice predictions to be coherent and continuous. Based on the aforementioned innovations, we achieve state-of-the-art results on the MICCAI 2017 Liver Tumor Segmentation (LiTS) dataset. Besides, we also test our model on the ISBI 2019 Segmentation of THoracic Organs at Risk (SegTHOR) dataset, and the result proves the robustness and generalizability of the proposed method in other segmentation tasks. ",
    "url": "https://arxiv.org/abs/2203.03640",
    "authors": [
      "Shuxin Wang",
      "Shilei Cao",
      "Zhizhong Chai",
      "Dong Wei",
      "Kai Ma",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": "We propose and analyse a novel statistical procedure, coined AgraSSt, to assess the quality of graph generators that may not be available in explicit form. In particular, AgraSSt can be used to determine whether a learnt graph generating process is capable of generating graphs that resemble a given input graph. Inspired by Stein operators for random graphs, the key idea of AgraSSt is the construction of a kernel discrepancy based on an operator obtained from the graph generator. AgraSSt can provide interpretable criticisms for a graph generator training procedure and help identify reliable sample batches for downstream tasks. Using Stein`s method we give theoretical guarantees for a broad class of random graph models. We provide empirical results on both synthetic input graphs with known graph generation procedures, and real-world input graphs that the state-of-the-art (deep) generative models for graphs are trained on. ",
    "url": "https://arxiv.org/abs/2203.03673",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03690",
    "title": "Robust Design of Rate-Splitting Multiple Access With Imperfect CSI for  Cell-Free MIMO Systems",
    "abstract": "Rate-Splitting Multiple Access (RSMA) for multi-user downlink operates by splitting the message for each user equipment (UE) into a private message and a set of common messages, which are simultaneously transmitted by means of superposition coding. The RSMA scheme can enhance throughput and connectivity as compared to conventional multiple access techniques by optimizing the rate-splitting ratios along with the corresponding downlink beamforming vectors. This work examines the impact of erroneous channel state information (CSI) on the performance of RSMA in cell-free multiple-input multiple-output (MIMO) systems. An efficient robust optimization algorithm is proposed by using closed-form lower bound expressions on the expected data rates. Extensive numerical results show the importance of robust design in the presence of CSI errors and how the performance gain of RSMA over conventional schemes is affected by CSI imperfection. ",
    "url": "https://arxiv.org/abs/2203.03690",
    "authors": [
      "Daesung Yu",
      "Seok-Hwan Park",
      "Osvaldo Simeone",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2203.03844",
    "title": "Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution  Networks",
    "abstract": "Light-weight super-resolution (SR) models have received considerable attention for their serviceability in mobile devices. Many efforts employ network quantization to compress SR models. However, these methods suffer from severe performance degradation when quantizing the SR models to ultra-low precision (e.g., 2-bit and 3-bit) with the low-cost layer-wise quantizer. In this paper, we identify that the performance drop comes from the contradiction between the layer-wise symmetric quantizer and the highly asymmetric activation distribution in SR models. This discrepancy leads to either a waste on the quantization levels or detail loss in reconstructed images. Therefore, we propose a novel activation quantizer, referred to as Dynamic Dual Trainable Bounds (DDTB), to accommodate the asymmetry of the activations. Specifically, DDTB innovates in: 1) A layer-wise quantizer with trainable upper and lower bounds to tackle the highly asymmetric activations. 2) A dynamic gate controller to adaptively adjust the upper and lower bounds at runtime to overcome the drastically varying activation ranges over different samples.To reduce the extra overhead, the dynamic gate controller is quantized to 2-bit and applied to only part of the SR networks according to the introduced dynamic intensity. Extensive experiments demonstrate that our DDTB exhibits significant performance improvements in ultra-low precision. For example, our DDTB achieves a 0.70dB PSNR increase on Urban100 benchmark when quantizing EDSR to 2-bit and scaling up output images to x4. Code is at \\url{https://github.com/zysxmu/DDTB}. ",
    "url": "https://arxiv.org/abs/2203.03844",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Xunchao Li",
      "Ke Li",
      "Yunhang Shen",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03916",
    "title": "Estimating the average causal effect of intervention in continuous  variables using machine learning",
    "abstract": "The most widely discussed methods for estimating the Average Causal Effect / Average Treatment Effect are those for intervention in discrete binary variables whose value represents the intervention / non-intervention groups. On the other hand, methods for intervening in continuous variables independent of the data generating model has not been developed. In this study, we give a method for estimating the average causal effect for intervention in continuous variables that can be applied to data of any generating model as long as the causal effect is identifiable. The proposing method is independent of machine learning algorithms and preserves the identifiability of the data. ",
    "url": "https://arxiv.org/abs/2203.03916",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04093",
    "title": "Exploration of Various Deep Learning Models for Increased Accuracy in  Automatic Polyp Detection",
    "abstract": "This paper is created to explore deep learning models and algorithms that results in highest accuracy in detecting polyp on colonoscopy images. Previous studies implemented deep learning using convolution neural network (CNN) algorithm in detecting polyp and non-polyp. Other studies used dropout, and data augmentation algorithm but mostly not checking the overfitting, thus, include more than four-layer modelss. Rulei Yu et.al from the Institute of Software, Chinese Academy of Sciences said that transfer learning is better talking about performance or improving the previous used algorithm. Most especially in applying the transfer learning in feature extraction. Series of experiments were conducted with only a minimum of 4 CNN layers applying previous used models and identified the model that produce the highest percentage accuracy of 98% among the other models that apply transfer learning. Further studies could use different optimizer to a different CNN modelsto increase accuracy. ",
    "url": "https://arxiv.org/abs/2203.04093",
    "authors": [
      "Ariel E. Isidro",
      "Arnel C. Fajardo",
      "Alexander A. Hernandez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.04118",
    "title": "An Efficient Polyp Segmentation Network",
    "abstract": "Cancer is a disease that occurs as a result of uncontrolled division and proliferation of cells. The number of cancer cases has been on the rise over the recent years.. Colon cancer is one of the most common types of cancer in the world. Polyps that can be seen in the large intestine can cause cancer if not removed with early intervention. Deep learning and image segmentation techniques are used to minimize the number of polyps that goes unnoticed by the experts during the diagnosis. Although these techniques give good results, they require too many parameters. We propose a new model to solve this problem. Our proposed model includes less parameters as well as outperforming the success of the state of the art models. In the proposed model, a partial decoder is used to reduce the number of parameters while maintaning success. EfficientNetB0, which gives successfull results as well as requiring few parameters, is used in the encoder part. Since polyps have variable aspect and aspect ratios, an asymetric convolution block was used instead of using classic convolution block. Kvasir and CVC-ClinicDB datasets were seperated as training, validation and testing, and CVC-ColonDB, ETIS and Endoscene datasets were used for testing. According to the dice metric, our model had the best results with %71.8 in the ColonDB test dataset, %89.3 in the EndoScene test dataset and %74.8 in the ETIS test dataset. Our model requires a total of 2.626.337 parameters. When we compare it in the literature, according to similar studies, the model that requires the least parameters is U-Net++ with 9.042.177 parameters. ",
    "url": "https://arxiv.org/abs/2203.04118",
    "authors": [
      "Tugberk Erol",
      "Duygu Sarikaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2007.01852",
    "title": "Language-agnostic BERT Sentence Embedding",
    "abstract": " Comments: To be presented at ACL 2022 ",
    "url": "https://arxiv.org/abs/2007.01852",
    "authors": [
      "Fangxiaoyu Feng",
      "Yinfei Yang",
      "Daniel Cer",
      "Naveen Arivazhagan",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2009.12517",
    "title": "QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings",
    "abstract": " Comments: Accepted to The ACM Web Conference 2022 (WWW '22) (Poster and Demo Track) ",
    "url": "https://arxiv.org/abs/2009.12517",
    "authors": [
      "Dai Quoc Nguyen",
      "Thanh Vu",
      "Tu Dinh Nguyen",
      "Dinh Phung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.07393",
    "title": "FAR: A General Framework for Attributional Robustness",
    "abstract": " Title: FAR: A General Framework for Attributional Robustness ",
    "url": "https://arxiv.org/abs/2010.07393",
    "authors": [
      "Adam Ivankay",
      "Ivan Girardi",
      "Chiara Marchiori",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.04543",
    "title": "Efficient model selection in switching linear dynamic systems by graph  clustering",
    "abstract": " Title: Efficient model selection in switching linear dynamic systems by graph  clustering ",
    "url": "https://arxiv.org/abs/2012.04543",
    "authors": [
      "Parisa Karimi",
      "Mark Butala",
      "Zhizhen Zhao",
      "Farzad Kamalabadi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.06109",
    "title": "Session-based Social and Dependency-aware Software Recommendation",
    "abstract": " Title: Session-based Social and Dependency-aware Software Recommendation ",
    "url": "https://arxiv.org/abs/2103.06109",
    "authors": [
      "Dengcheng Yan",
      "Tianyi Tang",
      "Wenxin Xie",
      "Yiwen Zhang",
      "Qiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2103.06560",
    "title": "Heterogeneous Information Network-based Interest Composition with Graph  Neural Network for Recommendation",
    "abstract": " Title: Heterogeneous Information Network-based Interest Composition with Graph  Neural Network for Recommendation ",
    "url": "https://arxiv.org/abs/2103.06560",
    "authors": [
      "Dengcheng Yan",
      "Wenxin Xie",
      "Yiwen Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2106.03915",
    "title": "A Graphical Representation of Membrane Filtration",
    "abstract": " Title: A Graphical Representation of Membrane Filtration ",
    "url": "https://arxiv.org/abs/2106.03915",
    "authors": [
      "Binan Gu",
      "Lou Kondic",
      "Linda J. Cummings"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.04590",
    "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial  Reconstruction Learning",
    "abstract": " Comments: 22 pages, 10 figures, accepted to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2106.04590",
    "authors": [
      "Seng Pei Liew",
      "Tsubasa Takahashi",
      "Michihiko Ueno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2106.08217",
    "title": "RFpredInterval: An R Package for Prediction Intervals with Random  Forests and Boosted Forests",
    "abstract": " Comments: 36 pages, 14 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2106.08217",
    "authors": [
      "Cansu Alakus",
      "Denis Larocque",
      "Aurelie Labbe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.13264",
    "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural  Networks",
    "abstract": " Comments: ICLR 2022 ",
    "url": "https://arxiv.org/abs/2106.13264",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Jianhao Peng",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.00363",
    "title": "Valid prediction intervals for regression problems",
    "abstract": " Comments: submitted to AI Review ",
    "url": "https://arxiv.org/abs/2107.00363",
    "authors": [
      "Nicolas Dewolf",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.10648",
    "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2107.10648",
    "authors": [
      "Mohit Mayank",
      "Shakshi Sharma",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.12790",
    "title": "RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place  Recognition Network",
    "abstract": " Title: RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place  Recognition Network ",
    "url": "https://arxiv.org/abs/2108.12790",
    "authors": [
      "Zhaoxin Fan",
      "Zhenbo Song",
      "Wenping Zhang",
      "Hongyan Liu",
      "Jun He",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05021",
    "title": "A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images",
    "abstract": " Title: A Deep Learning-Based Unified Framework for Red Lesions Detection on  Retinal Fundus Images ",
    "url": "https://arxiv.org/abs/2109.05021",
    "authors": [
      "Norah Asiri",
      "Muhammad Hussain",
      "Fadwa Al Adel",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.05205",
    "title": "Contrastive Quantization with Code Memory for Unsupervised Image  Retrieval",
    "abstract": " Comments: Accepted for AAAI'22 (Oral). 9 pages, 4 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2109.05205",
    "authors": [
      "Jinpeng Wang",
      "Ziyun Zeng",
      "Bin Chen",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2110.10380",
    "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for  Traffic Forecasting",
    "abstract": " Comments: 15 pages, Accepted as poster to ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.10380",
    "authors": [
      "Hyunwook Lee",
      "Seungmin Jin",
      "Hyeshin Chu",
      "Hongkyu Lim",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.02280",
    "title": "A reduced order Schwarz method for nonlinear multiscale elliptic  equations based on two-layer neural networks",
    "abstract": " Title: A reduced order Schwarz method for nonlinear multiscale elliptic  equations based on two-layer neural networks ",
    "url": "https://arxiv.org/abs/2111.02280",
    "authors": [
      "Shi Chen",
      "Zhiyan Ding",
      "Qin Li",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.02630",
    "title": "Network Structure and Feature Learning from Noisy Data",
    "abstract": " Title: Network Structure and Feature Learning from Noisy Data ",
    "url": "https://arxiv.org/abs/2111.02630",
    "authors": [
      "Junyao Kuang",
      "Caterina Scoglio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.09136",
    "title": "IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for  Zero-Shot Network Quantization",
    "abstract": " Comments: CVPR2022 ",
    "url": "https://arxiv.org/abs/2111.09136",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Gongrui Nan",
      "Jianzhuang Liu",
      "Baochang Zhang",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.09452",
    "title": "Open Vocabulary Object Detection with Pseudo Bounding-Box Labels",
    "abstract": " Title: Open Vocabulary Object Detection with Pseudo Bounding-Box Labels ",
    "url": "https://arxiv.org/abs/2111.09452",
    "authors": [
      "Mingfei Gao",
      "Chen Xing",
      "Juan Carlos Niebles",
      "Junnan Li",
      "Ran Xu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.10144",
    "title": "Positional Encoder Graph Neural Networks for Geographic Data",
    "abstract": " Title: Positional Encoder Graph Neural Networks for Geographic Data ",
    "url": "https://arxiv.org/abs/2111.10144",
    "authors": [
      "Konstantin Klemmer",
      "Nathan Safir",
      "Daniel B Neill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.14833",
    "title": "Adversarial Attacks in Cooperative AI",
    "abstract": " Title: Adversarial Attacks in Cooperative AI ",
    "url": "https://arxiv.org/abs/2111.14833",
    "authors": [
      "Ted Fujimoto",
      "Arthur Paul Pedersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.01740",
    "title": "AirDet: Few-Shot Detection without Fine-tuning for Autonomous  Exploration",
    "abstract": " Comments: 23 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2112.01740",
    "authors": [
      "Bowen Li",
      "Chen Wang",
      "Pranay Reddy",
      "Seungchan Kim",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02891",
    "title": "Seeing BDD100K in dark: Single-Stage Night-time Object Detection via  Continual Fourier Contrastive Learning",
    "abstract": " Title: Seeing BDD100K in dark: Single-Stage Night-time Object Detection via  Continual Fourier Contrastive Learning ",
    "url": "https://arxiv.org/abs/2112.02891",
    "authors": [
      "Ujjal Kr Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04585",
    "title": "MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification",
    "abstract": " Title: MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification ",
    "url": "https://arxiv.org/abs/2112.04585",
    "authors": [
      "Rex Liu",
      "Huanle Zhang",
      "Hamed Pirsiavash",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04906",
    "title": "Enhancing Column Generation by a Machine-Learning-Based Pricing  Heuristic for Graph Coloring",
    "abstract": " Comments: Machine learning for column generation and branch-and-price; accepted to AAAI 2022 ",
    "url": "https://arxiv.org/abs/2112.04906",
    "authors": [
      "Yunzhuang Shen",
      "Yuan Sun",
      "Xiaodong Li",
      "Andrew Eberhard",
      "Andreas Ernst"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.13257",
    "title": "A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs",
    "abstract": " Title: A Fast Row-Stochastic Decentralized Optimization Method Over Directed  Graphs ",
    "url": "https://arxiv.org/abs/2112.13257",
    "authors": [
      "Diyako Ghaderyan",
      "Necdet Serhat Aybat",
      "A. Pedro Aguiar",
      "Fernando Lobo Pereira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.15272",
    "title": "ViNMT: Neural Machine Translation Toolkit",
    "abstract": " Title: ViNMT: Neural Machine Translation Toolkit ",
    "url": "https://arxiv.org/abs/2112.15272",
    "authors": [
      "Nguyen Hoang Quan",
      "Nguyen Thanh Dat",
      "Nguyen Hoang Minh Cong",
      "Nguyen Van Vinh",
      "Ngo Thi Vinh",
      "Nguyen Phuong Thai",
      "Tran Hong Viet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.03331",
    "title": "Fiuncho: a program for any-order epistasis detection in CPU clusters",
    "abstract": " Comments: Submitted to The Journal of Supercomputing. Source code available at this https URL ",
    "url": "https://arxiv.org/abs/2201.03331",
    "authors": [
      "Christian Ponte-Fern\u00e1ndez",
      "Jorge Gonz\u00e1lez-Dom\u00ednguez",
      "Mar\u00eda J. Mart\u00edn"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2201.04756",
    "title": "Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction",
    "abstract": " Title: Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity  Background Subtraction ",
    "url": "https://arxiv.org/abs/2201.04756",
    "authors": [
      "Tianya Zhang",
      "Peter J. Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2201.06126",
    "title": "Solving Inventory Management Problems with Inventory-dynamics-informed  Neural Networks",
    "abstract": " Comments: 35 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2201.06126",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Thomas Asikis",
      "Ioannis Fragkos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.08845",
    "title": "Point-NeRF: Point-based Neural Radiance Fields",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2201.08845",
    "authors": [
      "Qiangeng Xu",
      "Zexiang Xu",
      "Julien Philip",
      "Sai Bi",
      "Zhixin Shu",
      "Kalyan Sunkavalli",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.10460",
    "title": "Conditional entropy minimization principle for learning domain invariant  representation features",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2201.10460",
    "authors": [
      "Thuan Nguyen",
      "Boyang Lyu",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.01332",
    "title": "Training a Bidirectional GAN-based One-Class Classifier for Network  Intrusion Detection",
    "abstract": " Comments: 16 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2202.01332",
    "authors": [
      "Wen Xu",
      "Julian Jang-Jaccard",
      "Tong Liu",
      "Fariza Sabrina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01426",
    "title": "Interleaving Monte Carlo Tree Search and Self-Supervised Learning for  Object Retrieval in Clutter",
    "abstract": " Comments: Accepted for ICRA 2022 ",
    "url": "https://arxiv.org/abs/2202.01426",
    "authors": [
      "Baichuan Huang",
      "Teng Guo",
      "Abdeslam Boularias",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.09741",
    "title": "Visual Attention Network",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2202.09741",
    "authors": [
      "Meng-Hao Guo",
      "Cheng-Ze Lu",
      "Zheng-Ning Liu",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11684",
    "title": "MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation  Social Network Dataset",
    "abstract": " Comments: 9+3 pages ",
    "url": "https://arxiv.org/abs/2202.11684",
    "authors": [
      "Dan Saattrup Nielsen",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2202.12154",
    "title": "Towards Effective and Robust Neural Trojan Defenses via Input Filtering",
    "abstract": " Title: Towards Effective and Robust Neural Trojan Defenses via Input Filtering ",
    "url": "https://arxiv.org/abs/2202.12154",
    "authors": [
      "Kien Do",
      "Haripriya Harikumar",
      "Hung Le",
      "Dung Nguyen",
      "Truyen Tran",
      "Santu Rana",
      "Dang Nguyen",
      "Willy Susilo",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12498",
    "title": "Diffeomorphic Image Registration with Neural Velocity Field",
    "abstract": " Title: Diffeomorphic Image Registration with Neural Velocity Field ",
    "url": "https://arxiv.org/abs/2202.12498",
    "authors": [
      "Kun Han",
      "Shanlin Sun",
      "Hao Tang",
      "Deying Kong",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13785",
    "title": "CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge  Graph Completion",
    "abstract": " Comments: The full version of a long paper accepted to ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2202.13785",
    "authors": [
      "Guanglin Niu",
      "Bo Li",
      "Yongfei Zhang",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.01426",
    "title": "SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks",
    "abstract": " Title: SPICEprop: Backpropagating Errors Through Memristive Spiking Neural  Networks ",
    "url": "https://arxiv.org/abs/2203.01426",
    "authors": [
      "Peng Zhou",
      "Jason K. Eshraghian",
      "Dong-Uk Choi",
      "Sung-Mo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2203.01786",
    "title": "Generative Modeling for Low Dimensional Speech Attributes with Neural  Spline Flows",
    "abstract": " Comments: 22 pages, 11 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2203.01786",
    "authors": [
      "Kevin J. Shih",
      "Rafael Valle",
      "Rohan Badlani",
      "Jo\u00e3o Felipe Santos",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.01870",
    "title": "KamNet: An Integrated Spatiotemporal Deep Neural Network for Rare Event  Search in KamLAND-Zen",
    "abstract": " Comments: 12 pages, dual submission with upcoming KamLAND-Zen 800 main result ",
    "url": "https://arxiv.org/abs/2203.01870",
    "authors": [
      "A. Li",
      "Z. Fu",
      "L. Winslow",
      "C. Grant",
      "H. Song",
      "H. Ozaki",
      "I. Shimizu",
      "A. Takeuchi"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.02471",
    "title": "Graph clustering with Boltzmann machines",
    "abstract": " Title: Graph clustering with Boltzmann machines ",
    "url": "https://arxiv.org/abs/2203.02471",
    "authors": [
      "Pierre Miasnikof",
      "Mohammad Bagherbeik",
      "Ali Sheikholeslami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03373",
    "title": "Adversarial Texture for Fooling Person Detectors in the Physical World",
    "abstract": " Comments: Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.03373",
    "authors": [
      "Zhanhao Hu",
      "Siyuan Huang",
      "Xiaopei Zhu",
      "Xiaolin Hu",
      "Fuchun Sun",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03457",
    "title": "Graph Neural Networks for Image Classification and Reinforcement  Learning using Graph representations",
    "abstract": " Comments: The work was done as a project for Neural Networks and Deep Learning course, Fall 2021 offering by Prof. Richard Zemel at Columbia University ",
    "url": "https://arxiv.org/abs/2203.03457",
    "authors": [
      "Naman Goyal",
      "David Steiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03564",
    "title": "TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs",
    "abstract": " Comments: To be published in AAAI-2022, additionally contains technical appendices/supplementary material ",
    "url": "https://arxiv.org/abs/2203.03564",
    "authors": [
      "Shubham Gupta",
      "Sahil Manchanda",
      "Srikanta Bedathur",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  }
]