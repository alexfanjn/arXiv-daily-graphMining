[
  {
    "id": "arXiv:2203.00001",
    "title": "AI-based approach for improving the detection of blood doping in sports",
    "abstract": "Sports officials around the world are facing incredible challenges due to the unfair means of practices performed by the athletes to improve their performance in the game. It includes the intake of hormonal based drugs or transfusion of blood to increase their strength and the result of their training. However, the current direct test of detection of these cases includes the laboratory-based method, which is limited because of the cost factors, availability of medical experts, etc. This leads us to seek for indirect tests. With the growing interest of Artificial Intelligence in healthcare, it is important to propose an algorithm based on blood parameters to improve decision making. In this paper, we proposed a statistical and machine learning-based approach to identify the presence of doping substance rhEPO in blood samples. ",
    "url": "https://arxiv.org/abs/2203.00001",
    "authors": [
      "Maxx Richard Rahman",
      "Jacob Bejder",
      "Thomas Christian Bonne",
      "Andreas Breenfeldt Andersen",
      "Jes\u00fas Rodr\u00edguez Huertas",
      "Reid Aikin",
      "Nikolai Baastrup Nordsborg",
      "Wolfgang Maa\u00df"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00002",
    "title": "SUTD-PRCM Dataset and Neural Architecture Search Approach for Complex  Metasurface Design",
    "abstract": "Metasurfaces have received a lot of attentions recently due to their versatile capability in manipulating electromagnetic wave. Advanced designs to satisfy multiple objectives with non-linear constraints have motivated researchers in using machine learning (ML) techniques like deep learning (DL) for accelerated design of metasurfaces. For metasurfaces, it is difficult to make quantitative comparisons between different ML models without having a common and yet complex dataset used in many disciplines like image classification. Many studies were directed to a relatively constrained datasets that are limited to specified patterns or shapes in metasurfaces. In this paper, we present our SUTD polarized reflection of complex metasurfaces (SUTD-PRCM) dataset, which contains approximately 260,000 samples of complex metasurfaces created from electromagnetic simulation, and it has been used to benchmark our DL models. The metasurface patterns are divided into different classes to facilitate different degree of complexity, which involves identifying and exploiting the relationship between the patterns and the electromagnetic responses that can be compared in using different DL models. With the release of this SUTD-PRCM dataset, we hope that it will be useful for benchmarking existing or future DL models developed in the ML community. We also propose a classification problem that is less encountered and apply neural architecture search to have a preliminary understanding of potential modification to the neural architecture that will improve the prediction by DL models. Our finding shows that convolution stacking is not the dominant element of the neural architecture anymore, which implies that low-level features are preferred over the traditional deep hierarchical high-level features thus explains why deep convolutional neural network based models are not performing well in our dataset. ",
    "url": "https://arxiv.org/abs/2203.00002",
    "authors": [
      "Tianning Zhang",
      "Yee Sin Ang",
      "Erping Li",
      "Chun Yun Kee",
      "L. K. Ang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2203.00003",
    "title": "Interfacing Finite Elements with Deep Neural Operators for Fast  Multiscale Modeling of Mechanics Problems",
    "abstract": "Multiscale modeling is an effective approach for investigating multiphysics systems with largely disparate size features, where models with different resolutions or heterogeneous descriptions are coupled together for predicting the system's response. The solver with lower fidelity (coarse) is responsible for simulating domains with homogeneous features, whereas the expensive high-fidelity (fine) model describes microscopic features with refined discretization, often making the overall cost prohibitively high, especially for time-dependent problems. In this work, we explore the idea of multiscale modeling with machine learning and employ DeepONet, a neural operator, as an efficient surrogate of the expensive solver. DeepONet is trained offline using data acquired from the fine solver for learning the underlying and possibly unknown fine-scale dynamics. It is then coupled with standard PDE solvers for predicting the multiscale systems with new boundary/initial conditions in the coupling stage. The proposed framework significantly reduces the computational cost of multiscale simulations since the DeepONet inference cost is negligible, facilitating readily the incorporation of a plurality of interface conditions and coupling schemes. We present various benchmarks to assess accuracy and speedup, and in particular we develop a coupling algorithm for a time-dependent problem, and we also demonstrate coupling of a continuum model (finite element methods, FEM) with a neural operator representation of a particle system (Smoothed Particle Hydrodynamics, SPH) for a uniaxial tension problem with hyperelastic material. What makes this approach unique is that a well-trained over-parametrized DeepONet can generalize well and make predictions at a negligible cost. ",
    "url": "https://arxiv.org/abs/2203.00003",
    "authors": [
      "Minglang Yin",
      "Enrui Zhang",
      "Yue Yu",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00004",
    "title": "A Dynamic Mode Decomposition Approach for Decentralized Spectral  Clustering of Graphs",
    "abstract": "We propose a novel robust decentralized graph clustering algorithm that is provably equivalent to the popular spectral clustering approach. Our proposed method uses the existing wave equation clustering algorithm that is based on propagating waves through the graph. However, instead of using a fast Fourier transform (FFT) computation at every node, our proposed approach exploits the Koopman operator framework. Specifically, we show that propagating waves in the graph followed by a local dynamic mode decomposition (DMD) computation at every node is capable of retrieving the eigenvalues and the local eigenvector components of the graph Laplacian, thereby providing local cluster assignments for all nodes. We demonstrate that the DMD computation is more robust than the existing FFT based approach and requires 20 times fewer steps of the wave equation to accurately recover the clustering information and reduces the relative error by orders of magnitude. We demonstrate the decentralized approach on a range of graph clustering problems. ",
    "url": "https://arxiv.org/abs/2203.00004",
    "authors": [
      "Hongyu Zhu",
      "Stefan Klus",
      "Tuhin Sahai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.00007",
    "title": "GCN-Transformer for short-term passenger flow prediction on holidays in  urban rail transit systems",
    "abstract": "The short-term passenger flow prediction of the urban rail transit system is of great significance for traffic operation and management. The emerging deep learning-based models provide effective methods to improve prediction accuracy. However, most of the existing models mainly predict the passenger flow on general weekdays, while few studies focus on predicting the holiday passenger flow, which can provide more significant information for operators because congestions or accidents generally occur on holidays. To this end, we propose a deep learning-based model named GCN-Transformer comprising graph conventional neural network (GCN) and Transformer for short-term passenger flow prediction on holidays. The GCN is applied to extract the spatial features of passenger flows and the Transformer is applied to extract the temporal features of passenger flows. Moreover, in addition to the historical passenger flow data, social media data are also incorporated into the prediction model, which has been proven to have a potential correlation with the fluctuation of passenger flow. The GCN-Transformer is tested on two large-scale real-world datasets from Nanning, China during the New Year holiday and is compared with several conventional prediction models. Results demonstrate its better robustness and advantages among baseline methods, which provides overwhelming support for practical applications of short-term passenger flow prediction on holidays ",
    "url": "https://arxiv.org/abs/2203.00007",
    "authors": [
      "Shuxin Zhang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00048",
    "title": "Multi-modal Alignment using Representation Codebook",
    "abstract": "Aligning signals from different modalities is an important step in vision-language representation learning as it affects the performance of later stages such as cross-modality fusion. Since image and text typically reside in different regions of the feature space, directly aligning them at instance level is challenging especially when features are still evolving during training. In this paper, we propose to align at a higher and more stable level using cluster representation. Specifically, we treat image and text as two \"views\" of the same entity, and encode them into a joint vision-language coding space spanned by a dictionary of cluster centers (codebook). We contrast positive and negative samples via their cluster assignments while simultaneously optimizing the cluster centers. To further smooth out the learning process, we adopt a teacher-student distillation paradigm, where the momentum teacher of one view guides the student learning of the other. We evaluated our approach on common vision language benchmarks and obtain new SoTA on zero-shot cross modality retrieval while being competitive on various other transfer tasks. ",
    "url": "https://arxiv.org/abs/2203.00048",
    "authors": [
      "Jiali Duan",
      "Liqun Chen",
      "Son Tran",
      "Jinyu Yang",
      "Yi Xu",
      "Belinda Zeng",
      "Chenyang Tao",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00049",
    "title": "Towards Targeted Change Detection with Heterogeneous Remote Sensing  Images for Forest Mortality Mapping",
    "abstract": "In this paper we develop a method for mapping forest mortality in the forest-tundra ecotone using satellite data from heterogeneous sensors. We use medium resolution imagery in order to provide the complex pattern of forest mortality in this sparsely forested area, which has been induced by an outbreak of geometrid moths. Specifically, Landsat-5 Thematic Mapper images from before the event are used, with RADARSAT-2 providing the post-event images. We obtain the difference images for both multispectral optical and synthetic aperture radar (SAR) by using a recently developed deep learning method for translating between the two domains. These differences are stacked with the original pre- and post-event images in order to let our algorithm also learn how the areas appear before and after the change event. By doing this, and focusing on learning only the changes of interest with one-class classification (OCC), we obtain good results with very little training data. ",
    "url": "https://arxiv.org/abs/2203.00049",
    "authors": [
      "J\u00f8rgen A. Agersborg",
      "Luigi T. Luppino",
      "Stian Normann Anfinsen",
      "Jane Uhd Jepsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00069",
    "title": "Optimal Transport-based Graph Matching for 3D retinal OCT image  registration",
    "abstract": "Registration of longitudinal optical coherence tomography (OCT) images assists disease monitoring and is essential in image fusion applications. Mouse retinal OCT images are often collected for longitudinal study of eye disease models such as uveitis, but their quality is often poor compared with human imaging. This paper presents a novel but efficient framework involving an optimal transport based graph matching (OT-GM) method for 3D mouse OCT image registration. We first perform registration of fundus-like images obtained by projecting all b-scans of a volume on a plane orthogonal to them, hereafter referred to as the x-y plane. We introduce Adaptive Weighted Vessel Graph Descriptors (AWVGD) and 3D Cube Descriptors (CD) to identify the correspondence between nodes of graphs extracted from segmented vessels within the OCT projection images. The AWVGD comprises scaling, translation and rotation, which are computationally efficient, whereas CD exploits 3D spatial and frequency domain information. The OT-GM method subsequently performs the correct alignment in the x-y plane. Finally, registration along the direction orthogonal to the x-y plane (the z-direction) is guided by the segmentation of two important anatomical features peculiar to mouse b-scans, the Internal Limiting Membrane (ILM) and the hyaloid remnant (HR). Both subjective and objective evaluation results demonstrate that our framework outperforms other well-established methods on mouse OCT images within a reasonable execution time. ",
    "url": "https://arxiv.org/abs/2203.00069",
    "authors": [
      "Xin Tian",
      "Nantheera Anantrasirichai",
      "Lindsay Nicholson",
      "Alin Achim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.00076",
    "title": "Robust Multi-Agent Bandits Over Undirected Graphs",
    "abstract": "We consider a multi-agent multi-armed bandit setting in which $n$ honest agents collaborate over a network to minimize regret but $m$ malicious agents can disrupt learning arbitrarily. Assuming the network is the complete graph, existing algorithms incur $O( (m + K/n) \\log (T) / \\Delta )$ regret in this setting, where $K$ is the number of arms and $\\Delta$ is the arm gap. For $m \\ll K$, this improves over the single-agent baseline regret of $O(K\\log(T)/\\Delta)$. In this work, we show the situation is murkier beyond the case of a complete graph. In particular, we prove that if the state-of-the-art algorithm is used on the undirected line graph, honest agents can suffer (nearly) linear regret until time is doubly exponential in $K$ and $n$. In light of this negative result, we propose a new algorithm for which the $i$-th agent has regret $O( ( d_{\\text{mal}}(i) + K/n) \\log(T)/\\Delta)$ on any connected and undirected graph, where $d_{\\text{mal}}(i)$ is the number of $i$'s neighbors who are malicious. Thus, we generalize existing regret bounds beyond the complete graph (where $d_{\\text{mal}}(i) = m$), and show the effect of malicious agents is entirely local (in the sense that only the $d_{\\text{mal}}(i)$ malicious agents directly connected to $i$ affect its long-term regret). ",
    "url": "https://arxiv.org/abs/2203.00076",
    "authors": [
      "Daniel Vial",
      "Sanjay Shakkottai",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.00083",
    "title": "Sampling-Based Winner Prediction in District-Based Elections",
    "abstract": "In a district-based election, we apply a voting rule $r$ to decide the winners in each district, and a candidate who wins in a maximum number of districts is the winner of the election. We present efficient sampling-based algorithms to predict the winner of such district-based election systems in this paper. When $r$ is plurality and the margin of victory is known to be at least $\\varepsilon$ fraction of the total population, we present an algorithm to predict the winner. The sample complexity of our algorithm is $\\mathcal{O}\\left(\\frac{1}{\\varepsilon^4}\\log \\frac{1}{\\varepsilon}\\log\\frac{1}{\\delta}\\right)$. We complement this result by proving that any algorithm, from a natural class of algorithms, for predicting the winner in a district-based election when $r$ is plurality, must sample at least $\\Omega\\left(\\frac{1}{\\varepsilon^4}\\log\\frac{1}{\\delta}\\right)$ votes. We then extend this result to any voting rule $r$. Loosely speaking, we show that we can predict the winner of a district-based election with an extra overhead of $\\mathcal{O}\\left(\\frac{1}{\\varepsilon^2}\\log\\frac{1}{\\delta}\\right)$ over the sample complexity of predicting the single-district winner under $r$. We further extend our algorithm for the case when the margin of victory is unknown, but we have only two candidates. We then consider the median voting rule when the set of preferences in each district is single-peaked. We show that the winner of a district-based election can be predicted with $\\mathcal{O}\\left(\\frac{1}{\\varepsilon^4}\\log\\frac{1}{\\varepsilon}\\log\\frac{1}{\\delta}\\right)$ samples even when the harmonious order in different districts can be different and even unknown. Finally, we also show some results for estimating the margin of victory of a district-based election within both additive and multiplicative error bounds. ",
    "url": "https://arxiv.org/abs/2203.00083",
    "authors": [
      "Palash Dey",
      "Debajyoti Kar",
      "Swagato Sanyal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00088",
    "title": "Virtual Reference Feedback Tuning for linear discrete-time systems with  robust stability guarantees",
    "abstract": "This paper proposes a data-driven method based on Virtual Reference Feedback Tuning with robust closed-loop stability guarantees in a linear setting. An uncertainty set for the system is obtained through a Set Membership identification. Based on this set, robust stability conditions are enforced as Linear Matrix Inequality constraints within an optimization problem whose cost function relies on the Virtual Reference Feedback Tuning framework. The effectiveness of the developed algorithm is demonstrated with reference to two simulation examples. ",
    "url": "https://arxiv.org/abs/2203.00088",
    "authors": [
      "William D'Amico",
      "Marcello Farina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.00095",
    "title": "Distributed randomized Kaczmarz for the adversarial workers",
    "abstract": "Developing large-scale distributed methods that are robust to the presence of adversarial or corrupted workers is an important part of making such methods practical for real-world problems. Here, we propose an iterative approach that is adversary-tolerant for least-squares problems. The algorithm utilizes simple statistics to guarantee convergence and is capable of learning the adversarial distributions. Additionally, the efficiency of the proposed method is shown in simulations in the presence of adversaries. The results demonstrate the great capability of such methods to tolerate different levels of adversary rates and to identify the erroneous workers with high accuracy. ",
    "url": "https://arxiv.org/abs/2203.00095",
    "authors": [
      "Xia Li",
      "Longxiu Huang",
      "Deanna Needell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.00101",
    "title": "ApacheJIT: A Large Dataset for Just-In-Time Defect Prediction",
    "abstract": "In this paper, we present ApacheJIT, a large dataset for Just-In-Time defect prediction. ApacheJIT consists of clean and bug-inducing software changes in popular Apache projects. ApacheJIT has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). Having a large number of commits makes ApacheJIT a suitable dataset for machine learning models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data. In addition to the original dataset, we also present carefully selected training and test sets that we recommend to be used in training and evaluating machine learning models. ",
    "url": "https://arxiv.org/abs/2203.00101",
    "authors": [
      "Hossein Keshavarz",
      "Meiyappan Nagappan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2203.00112",
    "title": "GraphWorld: Fake Graphs Bring Real Insights for GNNs",
    "abstract": "Despite advances in the field of Graph Neural Networks (GNNs), only a small number (~5) of datasets are currently used to evaluate new models. This continued reliance on a handful of datasets provides minimal insight into the performance differences between models, and is especially challenging for industrial practitioners who are likely to have datasets which look very different from those used as academic benchmarks. In the course of our work on GNN infrastructure and open-source software at Google, we have sought to develop improved benchmarks that are robust, tunable, scalable,and generalizable. In this work we introduce GraphWorld, a novel methodology and system for benchmarking GNN models on an arbitrarily-large population of synthetic graphs for any conceivable GNN task. GraphWorld allows a user to efficiently generate a world with millions of statistically diverse datasets. It is accessible, scalable, and easy to use. GraphWorld can be run on a single machine without specialized hardware, or it can be easily scaled up to run on arbitrary clusters or cloud frameworks. Using GraphWorld, a user has fine-grained control over graph generator parameters, and can benchmark arbitrary GNN models with built-in hyperparameter tuning. We present insights from GraphWorld experiments regarding the performance characteristics of tens of thousands of GNN models over millions of benchmark datasets. We further show that GraphWorld efficiently explores regions of benchmark dataset space uncovered by standard benchmarks, revealing comparisons between models that have not been historically obtainable. Using GraphWorld, we also are able to study in-detail the relationship between graph properties and task performance metrics, which is nearly impossible with the classic collection of real-world benchmarks. ",
    "url": "https://arxiv.org/abs/2203.00112",
    "authors": [
      "John Palowitch",
      "Anton Tsitsulin",
      "Brandon Mayer",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.00119",
    "title": "Efficient Task Allocation in Smart Warehouses with Multi-delivery  Stations and Heterogeneous Robots",
    "abstract": "The task allocation problem in multi-robot systems (MRTA) is an NP-hard problem whose viable solutions are usually found by heuristic algorithms. Considering the increasing need of improvement on logistics, the use of robots for increasing the efficiency of logistics warehouses is becoming a requirement. In a smart warehouse the main tasks consist of employing a fleet of automated picking and mobile robots that coordinate by picking up items from a set of orders from the shelves and dropping them at the delivery stations. Two aspects generally justify multi-robot task allocation complexity: (i) environmental aspects, such as multi-delivery stations and dispersed robots (since they remain in constant motion) and (ii) fleet heterogeneity, where robots' traffic speed and capacity loads are different from each other. Despite these properties have been widely researched in the literature, they usually are investigated separately. This work proposes a scalable and efficient task allocation algorithm for smart warehouses with multi-delivery stations and heterogeneous fleets. Our strategy employs a novel cost estimator, which computes costs as a function of the robots' variable characteristics and capacity while they receive new tasks. For validating the strategy a series of experiments is performed simulating the operation of smart warehouses with multiple delivery stations and heteregenous fleets. The results show that our strategy generates routes costing up to $33$\\% less than the routes generated by a state-of-the-art task allocation algorithm and $96$\\% faster in test instances representing our target scenario. Considering single-delivery stations and non-dispersed robots, we reduced the number of robots by up to $18$\\%, allocating tasks $92$\\% faster, and generating routes whose costs are statistically similar to the routes generated by the state-of-the-art algorithm. ",
    "url": "https://arxiv.org/abs/2203.00119",
    "authors": [
      "George S. Oliveira",
      "Juha R\u00f6ning",
      "Patricia D. M. Plentz",
      "J\u00f4nata T. Carvalho"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.00120",
    "title": "Neural Ordinary Differential Equations for Nonlinear System  Identification",
    "abstract": "Neural ordinary differential equations (NODE) have been recently proposed as a promising approach for nonlinear system identification tasks. In this work, we systematically compare their predictive performance with current state-of-the-art nonlinear and classical linear methods. In particular, we present a quantitative study comparing NODE's performance against neural state-space models and classical linear system identification methods. We evaluate the inference speed and prediction performance of each method on open-loop errors across eight different dynamical systems. The experiments show that NODEs can consistently improve the prediction accuracy by an order of magnitude compared to benchmark methods. Besides improved accuracy, we also observed that NODEs are less sensitive to hyperparameters compared to neural state-space models. On the other hand, these performance gains come with a slight increase of computation at the inference time. ",
    "url": "https://arxiv.org/abs/2203.00120",
    "authors": [
      "Aowabin Rahman",
      "J\u00e1n Drgo\u0148a",
      "Aaron Tuor",
      "Jan Strube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.00128",
    "title": "Learning Neural Hamiltonian Dynamics: A Methodological Overview",
    "abstract": "The past few years have witnessed an increased interest in learning Hamiltonian dynamics in deep learning frameworks. As an inductive bias based on physical laws, Hamiltonian dynamics endow neural networks with accurate long-term prediction, interpretability, and data-efficient learning. However, Hamiltonian dynamics also bring energy conservation or dissipation assumptions on the input data and additional computational overhead. In this paper, we systematically survey recently proposed Hamiltonian neural network models, with a special emphasis on methodologies. In general, we discuss the major contributions of these models, and compare them in four overlapping directions: 1) generalized Hamiltonian system; 2) symplectic integration, 3) generalized input form, and 4) extended problem settings. We also provide an outlook of the fundamental challenges and emerging opportunities in this area. ",
    "url": "https://arxiv.org/abs/2203.00128",
    "authors": [
      "Zhijie Chen",
      "Mingquan Feng",
      "Junchi Yan",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00138",
    "title": "Spatiotemporal Transformer Attention Network for 3D Voxel Level Joint  Segmentation and Motion Prediction in Point Cloud",
    "abstract": "Environment perception including detection, classification, tracking, and motion prediction are key enablers for automated driving systems and intelligent transportation applications. Fueled by the advances in sensing technologies and machine learning techniques, LiDAR-based sensing systems have become a promising solution. The current challenges of this solution are how to effectively combine different perception tasks into a single backbone and how to efficiently learn the spatiotemporal features directly from point cloud sequences. In this research, we propose a novel spatiotemporal attention network based on a transformer self-attention mechanism for joint semantic segmentation and motion prediction within a point cloud at the voxel level. The network is trained to simultaneously outputs the voxel level class and predicted motion by learning directly from a sequence of point cloud datasets. The proposed backbone includes both a temporal attention module (TAM) and a spatial attention module (SAM) to learn and extract the complex spatiotemporal features. This approach has been evaluated with the nuScenes dataset, and promising performance has been achieved. ",
    "url": "https://arxiv.org/abs/2203.00138",
    "authors": [
      "Zhensong Wei",
      "Xuewei Qi",
      "Zhengwei Bai",
      "Guoyuan Wu",
      "Saswat Nayak",
      "Peng Hao",
      "Matthew Barth",
      "Yongkang Liu",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00144",
    "title": "The Concordance Index decomposition -- A measure for a deeper  understanding of survival prediction models",
    "abstract": "The Concordance Index (C-index) is a commonly used metric in Survival Analysis to evaluate how good a prediction model is. This paper proposes a decomposition of the C-Index into a weighted harmonic mean of two quantities: one for ranking observed events versus other observed events, and the other for ranking observed events versus censored cases. This decomposition allows a more fine-grained analysis of the pros and cons of survival prediction methods. The utility of the decomposition is demonstrated using three benchmark survival analysis models (Cox Proportional Hazard, Random Survival Forest, and Deep Adversarial Time-to-Event Network) together with a new variational generative neural-network-based method (SurVED), which is also proposed in this paper. The demonstration is done on four publicly available datasets with varying censoring levels. The analysis with the C-index decomposition shows that all methods essentially perform equally well when the censoring level is high because of the dominance of the term measuring the ranking of events versus censored cases. In contrast, some methods deteriorate when the censoring level decreases because they do not rank the events versus other events well. ",
    "url": "https://arxiv.org/abs/2203.00144",
    "authors": [
      "Abdallah Alabdallah",
      "Mattias Ohlsson",
      "Sepideh Pashami",
      "Thorsteinn R\u00f6gnvaldsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.00146",
    "title": "VaultDB: A Real-World Pilot of Secure Multi-Party Computation within a  Clinical Research Network",
    "abstract": "Electronic health records represent a rich and growing source of clinical data for research. Privacy, regulatory, and institutional concerns limit the speed and ease of data sharing in this context. We introduce VaultDB, a framework for securely computing SQL queries over the union of private data from two or more sources. VaultDB evaluates queries using secure multiparty computation: cryptographic protocols that securely evaluate a function such that the only information revealed from running them is the query answer. We describe the development of a HIPAA-compliant version of this framework using the Chicago Area Patient Centered Outcomes Research Network (CAPriCORN), a multi-institutional clinical research network that spans the electronic health records of nearly 13M patients over hundreds of clinics and hospitals in the Chicago metropolitan area. Our results from deploying this technology at three health systems within this network demonstrate its efficiency and scalability to conduct multiparty clinical research analyses without moving patient records from their site of origin. ",
    "url": "https://arxiv.org/abs/2203.00146",
    "authors": [
      "Jennie Rogers",
      "Elizabeth Adetoro",
      "Johes Bater",
      "Talia Canter",
      "Dong Fu",
      "Andrew Hamilton",
      "Amro Hassan",
      "Ashley Martinez",
      "Erick Michalski",
      "Vesna Mitrovic",
      "Fred Rachman",
      "Raj Shah",
      "Matt Sterling",
      "Kyra VanDoren",
      "Theresa L. Walunas",
      "Xiao Wang",
      "Abel Kho"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00147",
    "title": "Arbitrarily high order implicit ODE integration by correcting a neural  network approximation with Newton's method",
    "abstract": "As a method of universal approximation deep neural networks (DNNs) are capable of finding approximate solutions to problems posed with little more constraints than a suitably-posed mathematical system and an objective function. Consequently, DNNs have considerably more flexibility in applications than classical numerical methods. On the other hand they offer an uncontrolled approximation to the sought-after mathematical solution. This suggests that hybridization of classical numerical methods with DNN-based approximations may be a desirable approach. In this work a DNN-based approximator inspired by the physics-informed neural networks (PINNs) methodology is used to provide an initial guess to a Newton's method iteration of a very-high order implicit Runge-Kutta (IRK) integration of a nonlinear system of ODEs, namely the Lorenz system. In the usual approach many explicit timesteps are needed to provide a guess to the implicit system's nonlinear solver, requiring enough work to make the IRK method infeasible. The DNN-based approach described in this work enables large implicit time-steps to be taken to any desired degree of accuracy for as much effort as it takes to converge the DNN solution to within a few percent accuracy. This work also develops a general formula for the matrix elements of the IRK method for an arbitrary quadrature order. ",
    "url": "https://arxiv.org/abs/2203.00147",
    "authors": [
      "D.W. Crews"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.00150",
    "title": "Explaining RADAR features for detecting spoofing attacks in Connected  Autonomous Vehicles",
    "abstract": "Connected autonomous vehicles (CAVs) are anticipated to have built-in AI systems for defending against cyberattacks. Machine learning (ML) models form the basis of many such AI systems. These models are notorious for acting like black boxes, transforming inputs into solutions with great accuracy, but no explanations support their decisions. Explanations are needed to communicate model performance, make decisions transparent, and establish trust in the models with stakeholders. Explanations can also indicate when humans must take control, for instance, when the ML model makes low confidence decisions or offers multiple or ambiguous alternatives. Explanations also provide evidence for post-incident forensic analysis. Research on explainable ML to security problems is limited, and more so concerning CAVs. This paper surfaces a critical yet under-researched sensor data \\textit{uncertainty} problem for training ML attack detection models, especially in highly mobile and risk-averse platforms such as autonomous vehicles. We present a model that explains \\textit{certainty} and \\textit{uncertainty} in sensor input -- a missing characteristic in data collection. We hypothesize that model explanation is inaccurate for a given system without explainable input data quality. We estimate \\textit{uncertainty} and mass functions for features in radar sensor data and incorporate them into the training model through experimental evaluation. The mass function allows the classifier to categorize all spoofed inputs accurately with an incorrect class label. ",
    "url": "https://arxiv.org/abs/2203.00150",
    "authors": [
      "Nidhi Rastogi",
      "Sara Rampazzi",
      "Michael Clifford",
      "Miriam Heller",
      "Matthew Bishop",
      "Karl Levitt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00158",
    "title": "GROW: A Row-Stationary Sparse-Dense GEMM Accelerator for  Memory-Efficient Graph Convolutional Neural Networks",
    "abstract": "Graph convolutional neural networks (GCNs) have emerged as a key technology in various application domains where the input data is relational. A unique property of GCNs is that its two primary execution stages, aggregation and combination, exhibit drastically different dataflows. Consequently, prior GCN accelerators tackle this research space by casting the aggregation and combination stages as a series of sparse-dense matrix multiplication. However, prior work frequently suffers from inefficient data movements, leaving significant performance left on the table. We present GROW, a GCN accelerator based on Gustavson's algorithm to architect a row-wise product based sparse-dense GEMM accelerator. GROW co-designs the software/hardware that strikes a balance in locality and parallelism for GCNs, achieving significant energy-efficiency improvements vs. state-of-the-art GCN accelerators. ",
    "url": "https://arxiv.org/abs/2203.00158",
    "authors": [
      "Minhoo Kang",
      "Ranggi Hwang",
      "Jiwon Lee",
      "Dongyun Kam",
      "Youngjoo Lee",
      "Minsoo Rhu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00186",
    "title": "ACTIVE:Augmentation-Free Graph Contrastive Learning for Partial  Multi-View Clustering",
    "abstract": "In this paper, we propose an augmentation-free graph contrastive learning framework, namely ACTIVE, to solve the problem of partial multi-view clustering. Notably, we suppose that the representations of similar samples (i.e., belonging to the same cluster) and their multiply views features should be similar. This is distinct from the general unsupervised contrastive learning that assumes an image and its augmentations share a similar representation. Specifically, relation graphs are constructed using the nearest neighbours to identify existing similar samples, then the constructed inter-instance relation graphs are transferred to the missing views to build graphs on the corresponding missing data. Subsequently, two main components, within-view graph contrastive learning (WGC) and cross-view graph consistency learning (CGC), are devised to maximize the mutual information of different views within a cluster. The proposed approach elevates instance-level contrastive learning and missing data inference to the cluster-level, effectively mitigating the impact of individual missing data on clustering. Experiments on several challenging datasets demonstrate the superiority of our proposed methods. ",
    "url": "https://arxiv.org/abs/2203.00186",
    "authors": [
      "Yiming Wang",
      "Dongxia Chang",
      "Zhiqiang Fu",
      "Jie Wen",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00187",
    "title": "Robots Autonomously Detecting People: A Multimodal Deep Contrastive  Learning Method Robust to Intraclass Variations",
    "abstract": "Robotic detection of people in crowded and/or cluttered human-centered environments including hospitals, long-term care, stores and airports is challenging as people can become occluded by other people or objects, and deform due to variations in clothing or pose. There can also be loss of discriminative visual features due to poor lighting. In this paper, we present a novel multimodal person detection architecture to address the mobile robot problem of person detection under intraclass variations. We present a two-stage training approach using 1) a unique pretraining method we define as Temporal Invariant Multimodal Contrastive Learning (TimCLR), and 2) a Multimodal Faster R-CNN (MFRCNN) detector. TimCLR learns person representations that are invariant under intraclass variations through unsupervised learning. Our approach is unique in that it generates image pairs from natural variations within multimodal image sequences, in addition to synthetic data augmentation, and contrasts crossmodal features to transfer invariances between different modalities. These pretrained features are used by the MFRCNN detector for finetuning and person detection from RGB-D images. Extensive experiments validate the performance of our DL architecture in both human-centered crowded and cluttered environments. Results show that our method outperforms existing unimodal and multimodal person detection approaches in terms of detection accuracy in detecting people with body occlusions and pose deformations in different lighting conditions. ",
    "url": "https://arxiv.org/abs/2203.00187",
    "authors": [
      "Angus Fung",
      "Beno Benhabib",
      "Goldie Nejat"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00191",
    "title": "NeuRecover: Regression-Controlled Repair of Deep Neural Networks with  Training History",
    "abstract": "Systematic techniques to improve quality of deep neural networks (DNNs) are critical given the increasing demand for practical applications including safety-critical ones. The key challenge comes from the little controllability in updating DNNs. Retraining to fix some behavior often has a destructive impact on other behavior, causing regressions, i.e., the updated DNN fails with inputs correctly handled by the original one. This problem is crucial when engineers are required to investigate failures in intensive assurance activities for safety or trust. Search-based repair techniques for DNNs have potentials to tackle this challenge by enabling localized updates only on \"responsible parameters\" inside the DNN. However, the potentials have not been explored to realize sufficient controllability to suppress regressions in DNN repair tasks. In this paper, we propose a novel DNN repair method that makes use of the training history for judging which DNN parameters should be changed or not to suppress regressions. We implemented the method into a tool called NeuRecover and evaluated it with three datasets. Our method outperformed the existing method by achieving often less than a quarter, even a tenth in some cases, number of regressions. Our method is especially effective when the repair requirements are tight to fix specific failure types. In such cases, our method showed stably low rates (<2%) of regressions, which were in many cases a tenth of regressions caused by retraining. ",
    "url": "https://arxiv.org/abs/2203.00191",
    "authors": [
      "Shogo Tokui",
      "Susumu Tokumoto",
      "Akihito Yoshii",
      "Fuyuki Ishikawa",
      "Takao Nakagawa",
      "Kazuki Munakata",
      "Shinji Kikuchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2203.00192",
    "title": "Layer Adaptive Deep Neural Networks for Out-of-distribution Detection",
    "abstract": "During the forward pass of Deep Neural Networks (DNNs), inputs gradually transformed from low-level features to high-level conceptual labels. While features at different layers could summarize the important factors of the inputs at varying levels, modern out-of-distribution (OOD) detection methods mostly focus on utilizing their ending layer features. In this paper, we proposed a novel layer-adaptive OOD detection framework (LA-OOD) for DNNs that can fully utilize the intermediate layers' outputs. Specifically, instead of training a unified OOD detector at a fixed ending layer, we train multiple One-Class SVM OOD detectors simultaneously at the intermediate layers to exploit the full spectrum characteristics encoded at varying depths of DNNs. We develop a simple yet effective layer-adaptive policy to identify the best layer for detecting each potential OOD example. LA-OOD can be applied to any existing DNNs and does not require access to OOD samples during the training. Using three DNNs of varying depth and architectures, our experiments demonstrate that LA-OOD is robust against OODs of varying complexity and can outperform state-of-the-art competitors by a large margin on some real-world datasets. ",
    "url": "https://arxiv.org/abs/2203.00192",
    "authors": [
      "Haoliang Wang",
      "Chen Zhao",
      "Xujiang Zhao",
      "Feng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00199",
    "title": "Equivariant and Stable Positional Encoding for More Powerful Graph  Neural Networks",
    "abstract": "Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task-based on sets of nodes such as link/motif prediction and so on. Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction, or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability. ",
    "url": "https://arxiv.org/abs/2203.00199",
    "authors": [
      "Haorui Wang",
      "Haoteng Yin",
      "Muhan Zhang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.00211",
    "title": "Investigating Selective Prediction Approaches Across Several Tasks in  IID, OOD, and Adversarial Settings",
    "abstract": "In order to equip NLP systems with selective prediction capability, several task-specific approaches have been proposed. However, which approaches work best across tasks or even if they consistently outperform the simplest baseline 'MaxProb' remains to be explored. To this end, we systematically study 'selective prediction' in a large-scale setup of 17 datasets across several NLP tasks. Through comprehensive experiments under in-domain (IID), out-of-domain (OOD), and adversarial (ADV) settings, we show that despite leveraging additional resources (held-out data/computation), none of the existing approaches consistently and considerably outperforms MaxProb in all three settings. Furthermore, their performance does not translate well across tasks. For instance, Monte-Carlo Dropout outperforms all other approaches on Duplicate Detection datasets but does not fare well on NLI datasets, especially in the OOD setting. Thus, we recommend that future selective prediction approaches should be evaluated across tasks and settings for reliable estimation of their capabilities. ",
    "url": "https://arxiv.org/abs/2203.00211",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00213",
    "title": "Optimal Routing for Multi-user Multi-hop Relay Networks via Dynamic  Programming",
    "abstract": "In this paper, we study the relay selection problem in multi-user, multi-hop relay networks with the objective of minimizing the maximum outage probability across all users. When only one user is present, it is well known that the optimal relay selection problem can be solved efficiently via dynamic programming. This solution breaks down in the multi-user scenario due to dependence between users. We resolve this challenge using a novel relay aggregation approach. On the expanded trellis, dynamic programming can be used to solve the optimal relay selection problem with computational complexity linear in the number of hops. Numerical examples illustrate the efficient use of this algorithm for relay networks. ",
    "url": "https://arxiv.org/abs/2203.00213",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.00232",
    "title": "Extended Graph Temporal Classification for Multi-Speaker End-to-End ASR",
    "abstract": "Graph-based temporal classification (GTC), a generalized form of the connectionist temporal classification loss, was recently proposed to improve automatic speech recognition (ASR) systems using graph-based supervision. For example, GTC was first used to encode an N-best list of pseudo-label sequences into a graph for semi-supervised learning. In this paper, we propose an extension of GTC to model the posteriors of both labels and label transitions by a neural network, which can be applied to a wider range of tasks. As an example application, we use the extended GTC (GTC-e) for the multi-speaker speech recognition task. The transcriptions and speaker information of multi-speaker speech are represented by a graph, where the speaker information is associated with the transitions and ASR outputs with the nodes. Using GTC-e, multi-speaker ASR modelling becomes very similar to single-speaker ASR modeling, in that tokens by multiple speakers are recognized as a single merged sequence in chronological order. For evaluation, we perform experiments on a simulated multi-speaker speech dataset derived from LibriSpeech, obtaining promising results with performance close to classical benchmarks for the task. ",
    "url": "https://arxiv.org/abs/2203.00232",
    "authors": [
      "Xuankai Chang",
      "Niko Moritz",
      "Takaaki Hori",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.00237",
    "title": "Mental Health Pandemic during the COVID-19 Outbreak: Calls for Help on  Social Media",
    "abstract": "Heightened social isolation during the COVID-19 outbreak puts individuals at greater risks of loneliness (Bu et al., 2020) where elevated levels of loneliness are closely associated with depression (Killgore et al., 2020; Palgi et al., 2020; Weeks et al., 1980). Prior research has suggested that lonely individuals are more likely to seek mental health help from an online social platform (e.g., Reddit), a perceived comfortable environment for lonely people to seek mental health support through anonymous communication with a broad social network (Andy, 2021; Bonetti et al., 2010; Morahan-Martin et al., 2003). Therefore, this study aims to identify and analyze depression-related dialogues on loneliness subreddits during the COVID-19 outbreak, with the impact on depression-related infoveillance during the pandemic. With the collected data using Reddit API, our study utilized logistic regression and topic modeling to classify and examine depression related discussions on loneliness subreddits during the outbreak. Our results reveal that lonely individuals engaging in depression-related discussions are likely to be experiencing elevated risks of mental health problems and domestic issues, higher level of relationship seeking, and heightened need of social support. Furthermore, the results suggest an increase in dog adoption as a coping behavior and challenges in the online learning environment. Finally, returning users disclose and seek information on triggering factors of mental health problems, indicating the significance of peer-to-peer mental health support on loneliness subreddits. Our future work will clinically validate the current approach, which has implications on designing surveillance system during the crisis. ",
    "url": "https://arxiv.org/abs/2203.00237",
    "authors": [
      "M. Bak",
      "J. Chin",
      "C. Chiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.00255",
    "title": "Improving Time Sensitivity for Question Answering over Temporal  Knowledge Graphs",
    "abstract": "Question answering over temporal knowledge graphs (KGs) efficiently uses facts contained in a temporal KG, which records entity relations and when they occur in time, to answer natural language questions (e.g., \"Who was the president of the US before Obama?\"). These questions often involve three time-related challenges that previous work fail to adequately address: 1) questions often do not specify exact timestamps of interest (e.g., \"Obama\" instead of 2000); 2) subtle lexical differences in time relations (e.g., \"before\" vs \"after\"); 3) off-the-shelf temporal KG embeddings that previous work builds on ignore the temporal order of timestamps, which is crucial for answering temporal-order related questions. In this paper, we propose a time-sensitive question answering (TSQA) framework to tackle these problems. TSQA features a timestamp estimation module to infer the unwritten timestamp from the question. We also employ a time-sensitive KG encoder to inject ordering information into the temporal KG embeddings that TSQA is based on. With the help of techniques to reduce the search space for potential answers, TSQA significantly outperforms the previous state of the art on a new benchmark for question answering over temporal KGs, especially achieving a 32% (absolute) error reduction on complex questions that require multiple steps of reasoning over facts in the temporal KG. ",
    "url": "https://arxiv.org/abs/2203.00255",
    "authors": [
      "Chao Shang",
      "Guangtao Wang",
      "Peng Qi",
      "Jing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00259",
    "title": "Omni-frequency Channel-selection Representations for Unsupervised  Anomaly Detection",
    "abstract": "Density-based and classification-based methods have ruled unsupervised anomaly detection in recent years, while reconstruction-based methods are rarely mentioned for the poor reconstruction ability and low performance. However, the latter requires no costly extra training samples for the unsupervised training that is more practical, so this paper focuses on improving this kind of method and proposes a novel Omni-frequency Channel-selection Reconstruction (OCR-GAN) network to handle anomaly detection task in a perspective of frequency. Concretely, we propose a Frequency Decoupling (FD) module to decouple the input image into different frequency components and model the reconstruction process as a combination of parallel omni-frequency image restorations, as we observe a significant difference in the frequency distribution of normal and abnormal images. Given the correlation among multiple frequencies, we further propose a Channel Selection (CS) module that performs frequency interaction among different encoders by adaptively selecting different channels. Abundant experiments demonstrate the effectiveness and superiority of our approach over different kinds of methods, e.g., achieving a new state-of-the-art 98.3 detection AUC on the MVTec AD dataset without extra training data that markedly surpasses the reconstruction-based baseline by +38.1 and the current SOTA method by +0.3. Source code will be available at https://github.com/zhangzjn/OCR-GAN. ",
    "url": "https://arxiv.org/abs/2203.00259",
    "authors": [
      "Yufei Liang",
      "Jiangning Zhang",
      "Shiwei Zhao",
      "Runze Wu",
      "Yong Liu",
      "Shuwen Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00274",
    "title": "TableFormer: Robust Transformer Modeling for Table-Text Encoding",
    "abstract": "Understanding tables is an important aspect of natural language understanding. Existing models for table understanding require linearization of the table structure, where row or column order is encoded as an unwanted bias. Such spurious biases make the model vulnerable to row and column order perturbations. Additionally, prior work has not thoroughly modeled the table structures or table-text alignments, hindering the table-text understanding ability. In this work, we propose a robust and structurally aware table-text encoding architecture TableFormer, where tabular structural biases are incorporated completely through learnable attention biases. TableFormer is (1) strictly invariant to row and column orders, and, (2) could understand tables better due to its tabular inductive biases. Our evaluations showed that TableFormer outperforms strong baselines in all settings on SQA, WTQ and TabFact table reasoning datasets, and achieves state-of-the-art performance on SQA, especially when facing answer-invariant row and column order perturbations (6% improvement over the best baseline), because previous SOTA models' performance drops by 4% - 6% when facing such perturbations while TableFormer is not affected. ",
    "url": "https://arxiv.org/abs/2203.00274",
    "authors": [
      "Jingfeng Yang",
      "Aditya Gupta",
      "Shyam Upadhyay",
      "Luheng He",
      "Rahul Goel",
      "Shachi Paul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.00278",
    "title": "Slice-Aware Resource Calendaring in Cloud-based Radio Access Networks",
    "abstract": "Network slicing has been introduced in 5G/6G networks to address the challenge of providing new services with different and sometimes conflicting requirements. With SDN and NFV technologies being used in the design of 5G and 6G wireless network slicing, as well as the centralization of control over these technologies, new services such as resource calendaring can also be used in wireless networks. In bandwidth calendaring, traffic with a low latency sensitivity and a high volume is shifted to later time slots so that applications with a high latency sensitivity can be served instead. We discuss how to calendar radio resources in the C-RAN architecture, which also makes use of network slicing. This is referred to as Slice-Aware Radio Resource Calendaring. A model of the problem is developed as an ILP problem and two heuristic algorithms are proposed for solving it due to complexity of optimal solution. Observations have shown that when resources are shared between tenants, the number of accepted requests increases. ",
    "url": "https://arxiv.org/abs/2203.00278",
    "authors": [
      "Zeinab Sasan",
      "Siavash Khorsandi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.00281",
    "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for  Grammar Induction and Text Representation",
    "abstract": "Recently CKY-based models show great potential in unsupervised grammar induction thanks to their human-like encoding paradigm, which runs recursively and hierarchically, but requires $O(n^3)$ time-complexity. Recursive Transformer based on Differentiable Trees (R2D2) makes it possible to scale to large language model pre-training even with complex tree encoder by introducing a heuristic pruning method. However, the rule-based pruning approach suffers from local optimum and slow inference issues. In this paper, we fix those issues in a unified method. We propose to use a top-down parser as a model-based pruning method, which also enables parallel encoding during inference. Typically, our parser casts parsing as a split point scoring task, which first scores all split points for a given sentence, and then recursively splits a span into two by picking a split point with the highest score in the current span. The reverse order of the splits is considered as the order of pruning in R2D2 encoder. Beside the bi-directional language model loss, we also optimize the parser by minimizing the KL distance between tree probabilities from parser and R2D2. Our experiments show that our Fast-R2D2 improves performance significantly in grammar induction and achieves competitive results in downstream classification tasks. ",
    "url": "https://arxiv.org/abs/2203.00281",
    "authors": [
      "Xiang Hu",
      "Haitao Mi",
      "Liang Li",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.00295",
    "title": "A Domain-Theoretic Framework for Robustness Analysis of Neural Networks",
    "abstract": "We present a domain-theoretic framework for validated robustness analysis of neural networks. We first analyze the global robustness of a general class of networks. Then, using the fact that, over finite-dimensional Banach spaces, the domain-theoretic L-derivative coincides with Clarke's generalized gradient, we extend our framework for attack-agnostic local robustness analysis. Our framework is ideal for designing algorithms which are correct by construction. We exemplify this claim by developing a validated algorithm for estimation of Lipschitz constant of feedforward regressors. We prove the completeness of the algorithm over differentiable networks, and also over general position ReLU networks. Within our domain model, differentiable and non-differentiable networks can be analyzed uniformly. We implement our algorithm using arbitrary-precision interval arithmetic, and present the results of some experiments. Our implementation is truly validated, as it handles floating-point errors as well. ",
    "url": "https://arxiv.org/abs/2203.00295",
    "authors": [
      "Can Zhou",
      "Razin A. Shaikh",
      "Yiran Li",
      "Amin Farjudian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00297",
    "title": "Comparison to control oscillations in high-order Finite Volume schemes  via physical constraint limiters, neural networks and polynomial annihilation",
    "abstract": "The construction of high-order structure-preserving numerical schemes to solve hyperbolic conservation laws has attracted a lot of attention in the last decades and various different ansatzes exist. In this paper, we compare three completely different approaches, i.e. physical constraint limiting, deep neural networks and the application of polynomial annihilation to construct high-order oscillation free Finite Volume (FV) blending schemes. We further analyze their analytical and numerical properties. We demonstrate that all techniques can be used and yield highly efficient FV methods but also come with some additional drawbacks which we point out. Our investigation of the different blending strategies should lead to a better understanding of those techniques and can be transferred to other numerical methods as well which use similar ideas. ",
    "url": "https://arxiv.org/abs/2203.00297",
    "authors": [
      "Dorian Hillebrand",
      "Simon-Christian Klein",
      "Philipp \u00d6ffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2203.00300",
    "title": "Towards Decentralized Identity Management in Multi-stakeholder 6G  Networks",
    "abstract": "Trust-building mechanisms among network entities of different administrative domains will gain significant importance in 6G because a future mobile network will be operated cooperatively by a variety of different stakeholders rather than by a single mobile network operator. The use of trusted third party issued certificates for initial trust establishment in multi-stakeholder 6G networks is only advisable to a limited extent, as trusted third parties not only represent single point of failures or attacks, but they also cannot guarantee global independence due to national legislation and regulatory or political influence. This article proposes to decentralize identity management in 6G networks in order to enable secure mutual authentication between network entities of different trust domains without relying on a trusted third party and to empower network entities with the ability to shape and strengthen cross-domain trust relationships by the exchange of verifiable credentials. A reference model for decentralized identity management in 6G is given as an initial guide for the fundamental design of a common identity management system whose operation and governance is distributed equally across multiple trust domains of interconnected and multi-stakeholder 6G ecosystems. ",
    "url": "https://arxiv.org/abs/2203.00300",
    "authors": [
      "Sandro Rodriguez Garzon",
      "Hakan Yildiz",
      "Axel K\u00fcpper"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00302",
    "title": "Adversarial samples for deep monocular 6D object pose estimation",
    "abstract": "Estimating object 6D pose from an RGB image is important for many real-world applications such as autonomous driving and robotic grasping, where robustness of the estimation is crucial. In this work, for the first time, we study adversarial samples that can fool state-of-the-art (SOTA) deep learning based 6D pose estimation models. In particular, we propose a Unified 6D pose estimation Attack, namely U6DA, which can successfully attack all the three main categories of models for 6D pose estimation. The key idea of our U6DA is to fool the models to predict wrong results for object shapes that are essential for correct 6D pose estimation. Specifically, we explore a transfer-based black-box attack to 6D pose estimation. By shifting the segmentation attention map away from its original position, adversarial samples are crafted. We show that such adversarial samples are not only effective for the direct 6D pose estimation models, but also able to attack the two-stage based models regardless of their robust RANSAC modules. Extensive experiments were conducted to demonstrate the effectiveness of our U6DA with large-scale public benchmarks. We also introduce a new U6DA-Linemod dataset for robustness study of the 6D pose estimation task. Our codes and dataset will be available at \\url{https://github.com/cuge1995/U6DA}. ",
    "url": "https://arxiv.org/abs/2203.00302",
    "authors": [
      "Jinlai Zhang",
      "Weiming Li",
      "Shuang Liang",
      "Hao Wang",
      "Jihong Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00304",
    "title": "Automatic Depression Detection via Learning and Fusing Features from  Visual Cues",
    "abstract": "Depression is one of the most prevalent mental disorders, which seriously affects one's life. Traditional depression diagnostics commonly depends on rating with scales, which can be labor-intensive and subjective. In this context, Automatic Depression Detection (ADD) has been attracting more attention for its low cost and objectivity. ADD systems are able to detect depression automatically from some medical records, like video sequences. However, it remains challenging to effectively extract depression-specific information from long sequences, thereby hindering a satisfying accuracy. In this paper, we propose a novel ADD method via learning and fusing features from visual cues. Specifically, we firstly construct Temporal Dilated Convolutional Network (TDCN), in which multiple Dilated Convolution Blocks (DCB) are designed and stacked, to learn the long-range temporal information from sequences. Then, the Feature-Wise Attention (FWA) module is adopted to fuse different features extracted from TDCNs. The module learns to assign weights for the feature channels, aiming to better incorporate different kinds of visual features and further enhance the detection accuracy. Our method achieves the state-of-the-art performance on the DAIC_WOZ dataset compared to other visual-feature-based methods, showing its effectiveness. ",
    "url": "https://arxiv.org/abs/2203.00304",
    "authors": [
      "Yanrong Guo",
      "Chenyang Zhu",
      "Shijie Hao",
      "Richang Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2203.00306",
    "title": "Comprehensive Analysis of the Object Detection Pipeline on UAVs",
    "abstract": "An object detection pipeline comprises a camera that captures the scene and an object detector that processes these images. The quality of the images directly affects the performance of the object detector. Many works nowadays focus either on improving the image quality or improving the object detection models independently, but neglect the importance of joint optimization of the two subsystems. In this paper, we first empirically analyze the influence of seven parameters (quantization, compression, resolution, color model, image distortion, gamma correction, additional channels) in remote sensing applications. For our experiments, we utilize three UAV data sets from different domains and a mixture of large and small state-of-the-art object detector models to provide an extensive evaluation of the influence of the pipeline parameters. Additionally, we realize an object detection pipeline prototype on an embedded platform for an UAV and give a best practice recommendation for building object detection pipelines based on our findings. We show that not all parameters have an equal impact on detection accuracy and data throughput, and that by using a suitable compromise between parameters we are able to improve detection accuracy for lightweight object detection models, while keeping the same data throughput. ",
    "url": "https://arxiv.org/abs/2203.00306",
    "authors": [
      "Leon Amadeus Varga",
      "Sebastian Koch",
      "Andreas Zell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00307",
    "title": "Temporal Perceiver: A General Architecture for Arbitrary Boundary  Detection",
    "abstract": "Generic Boundary Detection (GBD) aims at locating general boundaries that divide videos into semantically coherent and taxonomy-free units, and could server as an important pre-processing step for long-form video understanding. Previous research separately handle these different-level generic boundaries with specific designs of complicated deep networks from simple CNN to LSTM. Instead, in this paper, our objective is to develop a general yet simple architecture for arbitrary boundary detection in videos. To this end, we present Temporal Perceiver, a general architecture with Transformers, offering a unified solution to the detection of arbitrary generic boundaries. The core design is to introduce a small set of latent feature queries as anchors to compress the redundant input into fixed dimension via cross-attention blocks. Thanks to this fixed number of latent units, it reduces the quadratic complexity of attention operation to a linear form of input frames. Specifically, to leverage the coherence structure of videos, we construct two types of latent feature queries: boundary queries and context queries, which handle the semantic incoherence and coherence regions accordingly. Moreover, to guide the learning of latent feature queries, we propose an alignment loss on cross-attention to explicitly encourage the boundary queries to attend on the top possible boundaries. Finally, we present a sparse detection head on the compressed representations and directly output the final boundary detection results without any post-processing module. We test our Temporal Perceiver on a variety of detection benchmarks, ranging from shot-level, event-level, to scene-level GBD. Our method surpasses the previous state-of-the-art methods on all benchmarks, demonstrating the generalization ability of our temporal perceiver. ",
    "url": "https://arxiv.org/abs/2203.00307",
    "authors": [
      "Jing Tan",
      "Yuhong Wang",
      "Gangshan Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00308",
    "title": "Collaborative Robot Mapping using Spectral Graph Analysis",
    "abstract": "In this paper, we deal with the problem of creating globally consistent pose graphs in a centralized multi-robot SLAM framework. For each robot to act autonomously, individual onboard pose estimates and maps are maintained, which are then communicated to a central server to build an optimized global map. However, inconsistencies between onboard and server estimates can occur due to onboard odometry drift or failure. Furthermore, robots do not benefit from the collaborative map if the server provides no feedback in a computationally tractable and bandwidth-efficient manner. Motivated by this challenge, this paper proposes a novel collaborative mapping framework to enable accurate global mapping among robots and server. In particular, structural differences between robot and server graphs are exploited at different spatial scales using graph spectral analysis to generate necessary constraints for the individual robot pose graphs. The proposed approach is thoroughly analyzed and validated using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90%. ",
    "url": "https://arxiv.org/abs/2203.00308",
    "authors": [
      "Lukas Bernreiter",
      "Shehryar Khattak",
      "Lionel Ott",
      "Roland Siegwart",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.00324",
    "title": "Differentially private training of residual networks with scale  normalisation",
    "abstract": "We investigate the optimal choice of replacement layer for Batch Normalisation (BN) in residual networks (ResNets) for training with Differentially Private Stochastic Gradient Descent (DP-SGD) and study the phenomenon of scale mixing in residual blocks, whereby the activations on the two branches are scaled differently. Our experimental evaluation indicates that a hyperparameter search over 1-64 Group Normalisation (GN) groups improves the accuracy of ResNet-9 and ResNet-50 considerably in both benchmark (CIFAR-10) and large-image (ImageNette) tasks. Moreover, Scale Normalisation, a simple modification to the model architecture by which an additional normalisation layer is introduced after the residual block's addition operation further improves the utility of ResNets allowing us to achieve state-of-the-art results on CIFAR-10. ",
    "url": "https://arxiv.org/abs/2203.00324",
    "authors": [
      "Helena Klause",
      "Alexander Ziller",
      "Daniel Rueckert",
      "Kerstin Hammernik",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00332",
    "title": "Towards IID representation learning and its application on biomedical  data",
    "abstract": "Due to the heterogeneity of real-world data, the widely accepted independent and identically distributed (IID) assumption has been criticized in recent studies on causality. In this paper, we argue that instead of being a questionable assumption, IID is a fundamental task-relevant property that needs to be learned. Consider $k$ independent random vectors $\\mathsf{X}^{i = 1, \\ldots, k}$, we elaborate on how a variety of different causal questions can be reformulated to learning a task-relevant function $\\phi$ that induces IID among $\\mathsf{Z}^i := \\phi \\circ \\mathsf{X}^i$, which we term IID representation learning. For proof of concept, we examine the IID representation learning on Out-of-Distribution (OOD) generalization tasks. Concretely, by utilizing the representation obtained via the learned function that induces IID, we conduct prediction of molecular characteristics (molecular prediction) on two biomedical datasets with real-world distribution shifts introduced by a) preanalytical variation and b) sampling protocol. To enable reproducibility and for comparison to the state-of-the-art (SOTA) methods, this is done by following the OOD benchmarking guidelines recommended from WILDS. Compared to the SOTA baselines supported in WILDS, the results confirm the superior performance of IID representation learning on OOD tasks. The code is publicly accessible via https://github.com/CTPLab/IID_representation_learning. ",
    "url": "https://arxiv.org/abs/2203.00332",
    "authors": [
      "Jiqing Wu",
      "Inti Zlobec",
      "Maxime Lafarge",
      "Yukun He",
      "Viktor H. Koelzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00360",
    "title": "Non-linear manifold ROM with Convolutional Autoencoders and Reduced  Over-Collocation method",
    "abstract": "Non-affine parametric dependencies, nonlinearities and advection-dominated regimes of the model of interest can result in a slow Kolmogorov n-width decay, which precludes the realization of efficient reduced-order models based on linear subspace approximations. Among the possible solutions, there are purely data-driven methods that leverage autoencoders and their variants to learn a latent representation of the dynamical system, and then evolve it in time with another architecture. Despite their success in many applications where standard linear techniques fail, more has to be done to increase the interpretability of the results, especially outside the training range and not in regimes characterized by an abundance of data. Not to mention that none of the knowledge on the physics of the model is exploited during the predictive phase. In order to overcome these weaknesses, we implement the non-linear manifold method introduced by Carlberg et al [37] with hyper-reduction achieved through reduced over-collocation and teacher-student training of a reduced decoder. We test the methodology on a 2d non-linear conservation law and a 2d shallow water models, and compare the results obtained with a purely data-driven method for which the dynamics is evolved in time with a long-short term memory network. ",
    "url": "https://arxiv.org/abs/2203.00360",
    "authors": [
      "Francesco Romor",
      "Giovanni Stabile",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00371",
    "title": "Population games on dynamic community networks",
    "abstract": "In this letter, we deal with evolutionary game theoretic learning processes for population games on networks with dynamically evolving communities. Specifically, we propose a novel mathematical framework in which a deterministic, continuous-time replicator equation on a community network is coupled with a closed dynamic flow process between communities that is governed by an environmental feedback mechanism, resulting in co-evolutionary dynamics. Through a rigorous analysis of the system of differential equations obtained, we characterize the equilibria of the coupled dynamical system. Moreover, for a class of population games with two actions and symmetric rewards a Lyapunov argument is employed to establish an evolutionary folk theorem that guarantees convergence to the evolutionary stable states of the game. Numerical simulations are provided to illustrate and corroborate our findings. ",
    "url": "https://arxiv.org/abs/2203.00371",
    "authors": [
      "Alain Govaert",
      "Lorenzo Zino",
      "Emma Tegling"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Dynamical Systems (math.DS)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2203.00382",
    "title": "Addressing Randomness in Evaluation Protocols for Out-of-Distribution  Detection",
    "abstract": "Deep Neural Networks for classification behave unpredictably when confronted with inputs not stemming from the training distribution. This motivates out-of-distribution detection (OOD) mechanisms. The usual lack of prior information on out-of-distribution data renders the performance estimation of detection approaches on unseen data difficult. Several contemporary evaluation protocols are based on open set simulations, which average the performance over up to five synthetic random splits of a dataset into in- and out-of-distribution samples. However, the number of possible splits may be much larger, and the performance of Deep Neural Networks is known to fluctuate significantly depending on different sources of random variation. We empirically demonstrate that current protocols may fail to provide reliable estimates of the expected performance of OOD methods. By casting this evaluation as a random process, we generalize the concept of open set simulations and propose to estimate the performance of OOD methods using a Monte Carlo approach that addresses the randomness. ",
    "url": "https://arxiv.org/abs/2203.00382",
    "authors": [
      "Konstantin Kirchheim",
      "Tim Gonschorek",
      "Frank Ortmeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00387",
    "title": "Motion-aware Dynamic Graph Neural Network for Video Compressive Sensing",
    "abstract": "Video snapshot compressive imaging (SCI) utilizes a 2D detector to capture sequential video frames and compresses them into a single measurement. Various reconstruction methods have been developed to recover the high-speed video frames from the snapshot measurement. However, most existing reconstruction methods are incapable of capturing long-range spatial and temporal dependencies, which are critical for video processing. In this paper, we propose a flexible and robust approach based on graph neural network (GNN) to efficiently model non-local interactions between pixels in space as well as time regardless of the distance. Specifically, we develop a motion-aware dynamic GNN for better video representation, i.e., represent each pixel as the aggregation of relative nodes under the guidance of frame-by-frame motions, which consists of motion-aware dynamic sampling, cross-scale node sampling and graph aggregation. Extensive results on both simulation and real data demonstrate both the effectiveness and efficiency of the proposed approach, and the visualization clearly illustrates the intrinsic dynamic sampling operations of our proposed model for boosting the video SCI reconstruction results. The code and models will be released to the public. ",
    "url": "https://arxiv.org/abs/2203.00387",
    "authors": [
      "Ruiying Lu",
      "Ziheng Cheng",
      "Bo Chen",
      "Xin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00407",
    "title": "A Dynamical Estimation and Prediction for Covid19 on Romania using  ensemble neural networks",
    "abstract": "In this paper, we propose an analysis of Covid19 evolution and prediction on Romania combined with the mathematical model of SIRD, an extension of the classical model SIR, which includes the deceased as a separate category. The reason is that, because we can not fully trust the reported numbers of infected or recovered people, we base our analysis on the more reliable number of deceased people. In addition, one of the parameters of our model includes the proportion of infected and tested versus infected. Since there are many factors which have an impact on the evolution of the pandemic, we decide to treat the estimation and the prediction based on the previous 7 days of data, particularly important here being the number of deceased. We perform the estimation and prediction using neural networks in two steps. Firstly, by simulating data with our model, we train several neural networks which learn the parameters of the model. Secondly, we use an ensemble of ten of these neural networks to forecast the parameters from the real data of Covid19 in Romania. Many of these results are backed up by a theorem which guarantees that we can recover the parameters from the reported data. ",
    "url": "https://arxiv.org/abs/2203.00407",
    "authors": [
      "Marian Petrica",
      "Ionel Popescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2203.00411",
    "title": "Disentangled Spatiotemporal Graph Generative Models",
    "abstract": "Spatiotemporal graph represents a crucial data structure where the nodes and edges are embedded in a geometric space and can evolve dynamically over time. Nowadays, spatiotemporal graph data is becoming increasingly popular and important, ranging from microscale (e.g. protein folding), to middle-scale (e.g. dynamic functional connectivity), to macro-scale (e.g. human mobility network). Although disentangling and understanding the correlations among spatial, temporal, and graph aspects have been a long-standing key topic in network science, they typically rely on network processing hypothesized by human knowledge. This usually fit well towards the graph properties which can be predefined, but cannot do well for the most cases, especially for many key domains where the human has yet very limited knowledge such as protein folding and biological neuronal networks. In this paper, we aim at pushing forward the modeling and understanding of spatiotemporal graphs via new disentangled deep generative models. Specifically, a new Bayesian model is proposed that factorizes spatiotemporal graphs into spatial, temporal, and graph factors as well as the factors that explain the interplay among them. A variational objective function and new mutual information thresholding algorithms driven by information bottleneck theory have been proposed to maximize the disentanglement among the factors with theoretical guarantees. Qualitative and quantitative experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed model over the state-of-the-arts by up to 69.2% for graph generation and 41.5% for interpretability. ",
    "url": "https://arxiv.org/abs/2203.00411",
    "authors": [
      "Yuanqi Du",
      "Xiaojie Guo",
      "Hengning Cao",
      "Yanfang Ye",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00412",
    "title": "Interpretable Molecular Graph Generation via Monotonic Constraints",
    "abstract": "Designing molecules with specific properties is a long-lasting research problem and is central to advancing crucial domains such as drug discovery and material science. Recent advances in deep graph generative models treat molecule design as graph generation problems which provide new opportunities toward the breakthrough of this long-lasting problem. Existing models, however, have many shortcomings, including poor interpretability and controllability toward desired molecular properties. This paper focuses on new methodologies for molecule generation with interpretable and controllable deep generative models, by proposing new monotonically-regularized graph variational autoencoders. The proposed models learn to represent the molecules with latent variables and then learn the correspondence between them and molecule properties parameterized by polynomial functions. To further improve the intepretability and controllability of molecule generation towards desired properties, we derive new objectives which further enforce monotonicity of the relation between some latent variables and target molecule properties such as toxicity and clogP. Extensive experimental evaluation demonstrates the superiority of the proposed framework on accuracy, novelty, disentanglement, and control towards desired molecular properties. The code is open-source at https://anonymous.4open.science/r/MDVAE-FD2C. ",
    "url": "https://arxiv.org/abs/2203.00412",
    "authors": [
      "Yuanqi Du",
      "Xiaojie Guo",
      "Amarda Shehu",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00422",
    "title": "Short-term passenger flow prediction for multi-traffic modes: A residual  network and Transformer based multi-task learning method",
    "abstract": "With the prevailing of mobility as a service (MaaS), it becomes increasingly important to manage multi-traffic modes simultaneously and cooperatively. As an important component of MaaS, short-term passenger flow prediction for multi-traffic modes has thus been brought into focus. It is a challenging problem because the spatiotemporal features of multi-traffic modes are critically complex. To solve the problem, this paper proposes a multi-task learning-based model, called Res-Transformer, for short-term passenger flow prediction of multi-traffic modes (subway, taxi, and bus). Each traffic mode is treated as a single task in the model. The Res-Transformer consists of three parts: (1) several modified transformer layers comprising 2D convolutional neural networks (CNN) and multi-head attention mechanism, which helps to extract the spatial and temporal features of multi-traffic modes, (2) a residual network architecture used to extract the inner pattern of different traffic modes and enhance the passenger flow features of multi-traffic modes. The Res-Transformer model is evaluated on two large-scale real-world datasets from Beijing, China. One is the region of a traffic hub and the other is the region of a residential area. Experiments are conducted to compare the performance of the proposed model with several state-of-the-art models to prove the effectiveness and robustness of the proposed method. This paper can give critical insights into the short-tern passenger flow prediction for multi-traffic modes. ",
    "url": "https://arxiv.org/abs/2203.00422",
    "authors": [
      "Yongjie Yang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00436",
    "title": "Boundary Corrected Multi-scale Fusion Network for Real-time Semantic  Segmentation",
    "abstract": "Image semantic segmentation aims at the pixel-level classification of images, which has requirements for both accuracy and speed in practical application. Existing semantic segmentation methods mainly rely on the high-resolution input to achieve high accuracy and do not meet the requirements of inference time. Although some methods focus on high-speed scene parsing with lightweight architectures, they can not fully mine semantic features under low computation with relatively low performance. To realize the real-time and high-precision segmentation, we propose a new method named Boundary Corrected Multi-scale Fusion Network, which uses the designed Low-resolution Multi-scale Fusion Module to extract semantic information. Moreover, to deal with boundary errors caused by low-resolution feature map fusion, we further design an additional Boundary Corrected Loss to constrain overly smooth features. Extensive experiments show that our method achieves a state-of-the-art balance of accuracy and speed for the real-time semantic segmentation. ",
    "url": "https://arxiv.org/abs/2203.00436",
    "authors": [
      "Tianjiao Jiang",
      "Yi Jin",
      "Tengfei Liang",
      "Xu Wang",
      "Yidong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00438",
    "title": "An Analytical Approach to Compute the Exact Preimage of Feed-Forward  Neural Networks",
    "abstract": "Neural networks are a convenient way to automatically fit functions that are too complex to be described by hand. The downside of this approach is that it leads to build a black-box without understanding what happened inside. Finding the preimage would help to better understand how and why such neural networks had given such outputs. Because most of the neural networks are noninjective function, it is often impossible to compute it entirely only by a numerical way. The point of this study is to give a method to compute the exact preimage of any Feed-Forward Neural Network with linear or piecewise linear activation functions for hidden layers. In contrast to other methods, this one is not returning a unique solution for a unique output but returns analytically the entire and exact preimage. ",
    "url": "https://arxiv.org/abs/2203.00438",
    "authors": [
      "Th\u00e9o Nancy",
      "Vassili Maillet",
      "Johann Barbier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00448",
    "title": "Memory Planning for Deep Neural Networks",
    "abstract": "We study memory allocation patterns in DNNs during inference, in the context of large-scale systems. We observe that such memory allocation patterns, in the context of multi-threading, are subject to high latencies, due to \\texttt{mutex} contention in the system memory allocator. Latencies incurred due to such \\texttt{mutex} contention produce undesirable bottlenecks in user-facing services. Thus, we propose a \"memorization\" based technique, \\texttt{MemoMalloc}, for optimizing overall latency, with only moderate increases in peak memory usage. Specifically, our technique consists of a runtime component, which captures all allocations and uniquely associates them with their high-level source operation, and a static analysis component, which constructs an efficient allocation \"plan\". We present an implementation of \\texttt{MemoMalloc} in the PyTorch deep learning framework and evaluate memory consumption and execution performance on a wide range of DNN architectures. We find that \\texttt{MemoMalloc} outperforms state-of-the-art general purpose memory allocators, with respect to DNN inference latency, by as much as 40\\%. ",
    "url": "https://arxiv.org/abs/2203.00448",
    "authors": [
      "Maksim Levental"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2203.00451",
    "title": "Physics-Informed Neural Networks for Quantum Eigenvalue Problems",
    "abstract": "Eigenvalue problems are critical to several fields of science and engineering. We expand on the method of using unsupervised neural networks for discovering eigenfunctions and eigenvalues for differential eigenvalue problems. The obtained solutions are given in an analytical and differentiable form that identically satisfies the desired boundary conditions. The network optimization is data-free and depends solely on the predictions of the neural network. We introduce two physics-informed loss functions. The first, called ortho-loss, motivates the network to discover pair-wise orthogonal eigenfunctions. The second loss term, called norm-loss, requests the discovery of normalized eigenfunctions and is used to avoid trivial solutions. We find that embedding even or odd symmetries to the neural network architecture further improves the convergence for relevant problems. Lastly, a patience condition can be used to automatically recognize eigenfunction solutions. This proposed unsupervised learning method is used to solve the finite well, multiple finite wells, and hydrogen atom eigenvalue quantum problems. ",
    "url": "https://arxiv.org/abs/2203.00451",
    "authors": [
      "Henry Jin",
      "Marios Mattheakis",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2203.00453",
    "title": "A genetic algorithm for straight-line embedding of a cycle onto a given  set of points inside the general simple polygons",
    "abstract": "In this paper, we have examined the problem of embedding a cycle of n vertices onto a given set of n points inside a simple polygon. The goal of the problem is that the cycle must be embedded without bends and does not intersect itself and the polygon. This problem is a special case of the problem of finding a (s, X, t) - path inside a simple polygon with the minimum number of bends and intersections. The complexity of the problem is examined in this paper is open, but it has been proved that similar problems are NP-complete. We have presented a metaheuristic algorithm based on a genetic algorithm for straight-line embedding of a cycle with the minimum numbers of intersections, onto a given set of points inside the general simple polygons. The efficiency of the proposed genetic algorithm is due to the definition of the mutation operation, which removes it if there is an intersection between the embedded edges of the cycle. The experimental results show that the results of the version of the algorithm that uses this mutation operation are much more efficient than the version that uses only the usual two-points mutation operation. ",
    "url": "https://arxiv.org/abs/2203.00453",
    "authors": [
      "Maryam Fadavian",
      "Heidar Fadavian"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2203.00458",
    "title": "A hybrid model-based evolutionary optimization with passive boundaries  for physical human-robot interaction",
    "abstract": "The field of physical human-robot interaction has dramatically evolved in the last decades. As a result, the robotic system's requirements have become more challenging, including personalized behavior for different tasks and users. Various machine learning techniques have been proposed to give the robot such adaptability features. This paper proposes a model-based evolutionary optimization algorithm to tune the apparent impedance of a wrist rehabilitation device. We used passivity to define boundaries for the possible controller outcomes, limiting the shared autonomy of the robot and ensuring the coupled system stability. The experiment consists of a hardware-in-the-loop optimization and a one-degree-of-freedom robot used for wrist rehabilitation. Experimental results showed that the proposed technique could generate customized passive impedance controllers for three subjects. Furthermore, when compared with a constant impedance controller, the method suggested decreased in 20\\% the root mean square of interaction torques while maintaining stability during optimization. ",
    "url": "https://arxiv.org/abs/2203.00458",
    "authors": [
      "Gustavo J. G. Lahr",
      "Henrique B. Garcia",
      "Arash Ajoudani",
      "Thiago Boaventura",
      "Glauco A. P. Caurin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.00467",
    "title": "Belief propagation for supply networks: Efficient clustering of their  factor graphs",
    "abstract": "We consider belief propagation (BP) as an efficient and scalable tool for state estimation and optimization problems in supply networks, in particular in power grids and natural gas pipeline networks. BP algorithms make use of factor graph representations, whose assignment to the problem of interest is not unique. It depends on the state variables and their mutual interdependencies. Many short loops in factor graphs may impede the accuracy of BP. We propose a systematic way to cluster loops of factor graphs such that the resulting transformed factor graphs have no additional loops as compared to the original network. They guarantee an accurate performance of BP with only slightly increased computational effort. The method outperforms existing alternatives to handle the loops. We point to other applications to supply networks such as water networks that share the structure of constraints in the form of analogues of Kirchhoff's laws. Whenever small and abundant loops in factor graphs are systematically generated by constraints between variables in the original network, our factor-graph assignment in BP complements other approaches. It provides a fast and reliable algorithm to perform marginalization in state determination, estimation, or optimization issues in supply networks. ",
    "url": "https://arxiv.org/abs/2203.00467",
    "authors": [
      "Tim Ritmeester",
      "Hildegard Meyer-Ortmanns"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00481",
    "title": "Beyond Gradients: Exploiting Adversarial Priors in Model Inversion  Attacks",
    "abstract": "Collaborative machine learning settings like federated learning can be susceptible to adversarial interference and attacks. One class of such attacks is termed model inversion attacks, characterised by the adversary reverse-engineering the model to extract representations and thus disclose the training data. Prior implementations of this attack typically only rely on the captured data (i.e. the shared gradients) and do not exploit the data the adversary themselves control as part of the training consortium. In this work, we propose a novel model inversion framework that builds on the foundations of gradient-based model inversion attacks, but additionally relies on matching the features and the style of the reconstructed image to data that is controlled by an adversary. Our technique outperforms existing gradient-based approaches both qualitatively and quantitatively, while still maintaining the same honest-but-curious threat model, allowing the adversary to obtain enhanced reconstructions while remaining concealed. ",
    "url": "https://arxiv.org/abs/2203.00481",
    "authors": [
      "Dmitrii Usynin",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00489",
    "title": "Attention-based Contextual Multi-View Graph Convolutional Networks for  Short-term Population Prediction",
    "abstract": "Short-term future population prediction is a crucial problem in urban computing. Accurate future population prediction can provide rich insights for urban planners or developers. However, predicting the future population is a challenging task due to its complex spatiotemporal dependencies. Many existing works have attempted to capture spatial correlations by partitioning a city into grids and using Convolutional Neural Networks (CNN). However, CNN merely captures spatial correlations by using a rectangle filter; it ignores urban environmental information such as distribution of railroads and location of POI. Moreover, the importance of those kinds of information for population prediction differs in each region and is affected by contextual situations such as weather conditions and day of the week. To tackle this problem, we propose a novel deep learning model called Attention-based Contextual Multi-View Graph Convolutional Networks (ACMV-GCNs). We first construct multiple graphs based on urban environmental information, and then ACMV-GCNs captures spatial correlations from various views with graph convolutional networks. Further, we add an attention module to consider the contextual situations when leveraging urban environmental information for future population prediction. Using statistics population count data collected through mobile phones, we demonstrate that our proposed model outperforms baseline methods. In addition, by visualizing weights calculated by an attention module, we show that our model learns an efficient way to utilize urban environment information without any prior knowledge. ",
    "url": "https://arxiv.org/abs/2203.00489",
    "authors": [
      "Yuki Kubota",
      "Yuki Ohira",
      "Tetsuo Shimizu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.00497",
    "title": "A predictive analytics approach for stroke prediction using machine  learning and neural networks",
    "abstract": "The negative impact of stroke in society has led to concerted efforts to improve the management and diagnosis of stroke. With an increased synergy between technology and medical diagnosis, caregivers create opportunities for better patient management by systematically mining and archiving the patients' medical records. Therefore, it is vital to study the interdependency of these risk factors in patients' health records and understand their relative contribution to stroke prediction. This paper systematically analyzes the various factors in electronic health records for effective stroke prediction. Using various statistical techniques and principal component analysis, we identify the most important factors for stroke prediction. We conclude that age, heart disease, average glucose level, and hypertension are the most important factors for detecting stroke in patients. Furthermore, a perceptron neural network using these four attributes provides the highest accuracy rate and lowest miss rate compared to using all available input features and other benchmarking algorithms. As the dataset is highly imbalanced concerning the occurrence of stroke, we report our results on a balanced dataset created via sub-sampling techniques. ",
    "url": "https://arxiv.org/abs/2203.00497",
    "authors": [
      "Soumyabrata Dev",
      "Hewei Wang",
      "Chidozie Shamrock Nwosu",
      "Nishtha Jain",
      "Bharadwaj Veeravalli",
      "Deepu John"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00508",
    "title": "Reconfigurable Intelligent Surface-Aided Spectrum Sharing Coexisting  with Multiple Primary Networks",
    "abstract": "In the spectrum sharing system (SSS) coexisting with multiple primary networks, a well-designed reconfigurable intelligent surface (RIS) is employed to control the radio environments of wireless channels and relieve the scarcity of the spectrum resource in this work, which can realize high spectral efficiency (SE) and energy efficiency (EE). Specifically, the SE enhancement in the considered SSS is decomposed into two subproblems which are a second-order programming (SOP) and a fractional programming of the convex quadratic form (CQFP), respectively, to optimize alternatively the beamforming vector at the secondary access point and the reflecting coefficients at the RIS. The CQFP subproblem about optimizing the reflecting coefficients can be solved by the domain and envelope shrinking algorithm (DES), providing the best SE performance. Besides, a low-complexity method of gradient-based linearization with domain (GLD) is proposed for obtaining a sub-optimal reflecting coefficients for fast deployment. Considering the power consumption in the practical application of RIS-aided SSS, the EE performance of our proposed GLD method has significant gain over that of the SSS without RIS. The simulation results indicate the effectiveness of the DES algorithm and show that the GLD method improves the SE and EE performance in RIS-aided SSS with multiple primary networks. ",
    "url": "https://arxiv.org/abs/2203.00508",
    "authors": [
      "Zhong Tian",
      "Zhengchuan Chen",
      "Min Wang",
      "Yunjian Jia",
      "Shi Jin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.00515",
    "title": "Social Network Extraction Unsupervised",
    "abstract": "In the era of information technology, the two developing sides are data science and artificial intelligence. In terms of scientific data, one of the tasks is the extraction of social networks from information sources that have the nature of big data. Meanwhile, in terms of artificial intelligence, the presence of contradictory methods has an impact on knowledge. This article describes an unsupervised as a stream of methods for extracting social networks from information sources. There are a variety of possible approaches and strategies to superficial methods as a starting concept. Each method has its advantages, but in general, it contributes to the integration of each other, namely simplifying, enriching, and emphasizing the results. ",
    "url": "https://arxiv.org/abs/2203.00515",
    "authors": [
      "Mahyuddin K. M. Nasution",
      "Rahmad Syah"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.00548",
    "title": "An Adaptable and Agnostic Flow Scheduling Approach for Data Center  Networks",
    "abstract": "Cloud applications have reshaped the model of services and infrastructure of the Internet. Search engines, social networks, content delivery and retail and e-commerce sites belong to this group of applications. An important element in the architecture of data centers where these applications run is the communication infrastructure, commonly known as data center networks (DCNs). A critical challenge DCNs have to address is the processing of the traffic of cloud applications, which due to its properties is essentially different to the traffic of other Internet applications. In order to improve the responsiveness and throughput of applications, DCNs should be able to prioritize short flows (a few KB) over long flows (several MB). However, given the time and space variations the traffic presents, the information about flow sizes is not available in advance in order to plan the flow scheduling. In this paper, we present an adaptable mechanism called Adaptable Workload-Agnostic Flow Scheduling (AWAFS). It is an adaptable approach that can adjust in an agnostic way the scheduling configuration of DCN forwarding devices. This agnostic adjustment contributes to reduce the Flow Completion Time (FCT) of those short flows, representing around 85% of the traffic handled by cloud applications. Our evaluation results based on simulation show that AWAFS can reduce the average FCT of short flows between 16.9% and 45.2% when compared to the best existing agnostic non-adaptable solution, without inducing starvation on long flows. Indeed, it can provide improvements as high as 39% for long flows. Additionally, AWAFS can improve the FCT for short flows in scenarios with high heterogeneity in the traffic present in the network, with a reduction up to 5% for the average FCT and 15% for the tail FCT. ",
    "url": "https://arxiv.org/abs/2203.00548",
    "authors": [
      "Sergio Armando Guti\u00e9rrez",
      "Juan Felipe Botero",
      "John Willian Branch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.00551",
    "title": "Bayesian Optimisation for Robust Model Predictive Control under Model  Parameter Uncertainty",
    "abstract": "We propose an adaptive optimisation approach for tuning stochastic model predictive control (MPC) hyper-parameters while jointly estimating probability distributions of the transition model parameters based on performance rewards. In particular, we develop a Bayesian optimisation (BO) algorithm with a heteroscedastic noise model to deal with varying noise across the MPC hyper-parameter and dynamics model parameter spaces. Typical homoscedastic noise models are unrealistic for tuning MPC since stochastic controllers are inherently noisy, and the level of noise is affected by their hyper-parameter settings. We evaluate the proposed optimisation algorithm in simulated control and robotics tasks where we jointly infer control and dynamics parameters. Experimental results demonstrate that our approach leads to higher cumulative rewards and more stable controllers. ",
    "url": "https://arxiv.org/abs/2203.00551",
    "authors": [
      "Rel Guzman",
      "Rafael Oliveira",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.00553",
    "title": "Global-Local Regularization Via Distributional Robustness",
    "abstract": "Despite superior performance in many situations, deep neural networks are often vulnerable to adversarial examples and distribution shifts, limiting model generalization ability in real-world applications. To alleviate these problems, recent approaches leverage distributional robustness optimization (DRO) to find the most challenging distribution, and then minimize loss function over this most challenging distribution. Regardless of achieving some improvements, these DRO approaches have some obvious limitations. First, they purely focus on local regularization to strengthen model robustness, missing a global regularization effect which is useful in many real-world applications (e.g., domain adaptation, domain generalization, and adversarial machine learning). Second, the loss functions in the existing DRO approaches operate in only the most challenging distribution, hence decouple with the original distribution, leading to a restrictive modeling capability. In this paper, we propose a novel regularization technique, following the veins of Wasserstein-based DRO framework. Specifically, we define a particular joint distribution and Wasserstein-based uncertainty, allowing us to couple the original and most challenging distributions for enhancing modeling capability and applying both local and global regularizations. Empirical studies on different learning problems demonstrate that our proposed approach significantly outperforms the existing regularization approaches in various domains: semi-supervised learning, domain adaptation, domain generalization, and adversarial machine learning. ",
    "url": "https://arxiv.org/abs/2203.00553",
    "authors": [
      "Hoang Phan",
      "Trung Le",
      "Trung Phung",
      "Tuan Anh Bui",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00579",
    "title": "Multi-Channel Man-in-the-Middle Attacks Against Protected Wi-Fi  Networks: A State of the Art Review",
    "abstract": "Multi-Channel Man-in-the-Middle (MitM) attacks are special MitM attacks capable of manipulating encrypted Wi-Fi wireless frames between two legitimate endpoints. Since its inception in 2014, attackers have been targeting WPA Wi-Fi networks to perform different attacks, such as cipher downgrades, denial of service, key reinstallation Man-in-the-Middle (MitM) attacks (KRACK) in 2017, and recently FragAttacks in 2021, which widely impacted millions of Wi-Fi Multi-Channel MitM (MC-MitM) devices, especially IoT devices. To the best of our knowledge, there are no studies in the literature that KRACK holistically review the different types of Multi-Channel MitM enabled attacks and analyze their potential Internet of Things (IoT) impact. To this end, we evaluate the capabilities of Multi-Channel MitM and review every reported attack in Encryption the state of the art. We examine practical issues that hamper the total adoption of protection mechanisms, i.e., Security security patches and Protected Management Frames (PMF), and review available defense mechanisms in FragAttacks confronting the Multi-Channel MitM enabled attacks in the IoT context. Finally, we highlight the potential research problems and identify future research lines in this field. ",
    "url": "https://arxiv.org/abs/2203.00579",
    "authors": [
      "Manesh Thankappan",
      "Helena Rif\u00e0-Pous",
      "Carles Garrigues"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00585",
    "title": "Self-Supervised Vision Transformers Learn Visual Concepts in  Histopathology",
    "abstract": "Tissue phenotyping is a fundamental task in learning objective characterizations of histopathologic biomarkers within the tumor-immune microenvironment in cancer pathology. However, whole-slide imaging (WSI) is a complex computer vision in which: 1) WSIs have enormous image resolutions with precludes large-scale pixel-level efforts in data curation, and 2) diversity of morphological phenotypes results in inter- and intra-observer variability in tissue labeling. To address these limitations, current efforts have proposed using pretrained image encoders (transfer learning from ImageNet, self-supervised pretraining) in extracting morphological features from pathology, but have not been extensively validated. In this work, we conduct a search for good representations in pathology by training a variety of self-supervised models with validation on a variety of weakly-supervised and patch-level tasks. Our key finding is in discovering that Vision Transformers using DINO-based knowledge distillation are able to learn data-efficient and interpretable features in histology images wherein the different attention heads learn distinct morphological phenotypes. We make evaluation code and pretrained weights publicly-available at: https://github.com/Richarizardd/Self-Supervised-ViT-Path. ",
    "url": "https://arxiv.org/abs/2203.00585",
    "authors": [
      "Richard J. Chen",
      "Rahul G. Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2203.00608",
    "title": "A Method Based on Deep Learning for the Detection and Characterization  of Cybersecurity Incidents in Internet of Things Devices",
    "abstract": "Given the increased growing of Internet of Things networks and their presence in critical aspects of human activities, the security of devices connected to these networks becomes critical. Machine Learning approaches are becoming prominent as enablers for security solutions in computer networks due to its capacity to process traffic information in order to detect abnormal patterns which might represent attacks targeting infrastructures. In this paper, we propose to leverage Convolutional and Recurrent Neural Networks, two artifacts that have been successfully used in contexts such as image processing for pattern recognition, for the development of a security solution to be used in the context of Internet of Things. Our results show that this approach, when evaluated with a state-of-the-art data set, achieves around 99% of accuracy in the binary classification of attacks (i.e. normal traffic vs attack traffic) and 96% for multiclass classification (recognition of different types of attacks) accuracy. These results outperform proposals available in literature, showing a promising landscape for developing security solutions for IoT infrastructures. ",
    "url": "https://arxiv.org/abs/2203.00608",
    "authors": [
      "Jhon Alex\u00e1nder Parra",
      "Sergio Armando Guti\u00e9rrez",
      "John Willian Branch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.00611",
    "title": "Learning Intermediate Representations using Graph Neural Networks for  NUMA and Prefetchers Optimization",
    "abstract": "There is a large space of NUMA and hardware prefetcher configurations that can significantly impact the performance of an application. Previous studies have demonstrated how a model can automatically select configurations based on the dynamic properties of the code to achieve speedups. This paper demonstrates how the static Intermediate Representation (IR) of the code can guide NUMA/prefetcher optimizations without the prohibitive cost of performance profiling. We propose a method to create a comprehensive dataset that includes a diverse set of intermediate representations along with optimum configurations. We then apply a graph neural network model in order to validate this dataset. We show that our static intermediate representation based model achieves 80% of the performance gains provided by expensive dynamic performance profiling based strategies. We further develop a hybrid model that uses both static and dynamic information. Our hybrid model achieves the same gains as the dynamic models but at a reduced cost by only profiling 30% of the programs. ",
    "url": "https://arxiv.org/abs/2203.00611",
    "authors": [
      "Ali TehraniJamsaz",
      "Mihail Popov",
      "Akash Dutta",
      "Emmanuelle Saillard",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00637",
    "title": "Signature Correction Attack on Dilithium Signature Scheme",
    "abstract": "Motivated by the rise of quantum computers, existing public-key cryptosystems are expected to be replaced by post-quantum schemes in the next decade in billions of devices. To facilitate the transition, NIST is running a standardization process which is currently in its final Round. Only three digital signature schemes are left in the competition, among which Dilithium and Falcon are the ones based on lattices. Classical fault attacks on signature schemes make use of pairs of faulty and correct signatures to recover the secret key which only works on deterministic schemes. To counter such attacks, Dilithium offers a randomized version which makes each signature unique, even when signing identical messages. In this work, we introduce a novel Signature Correction Attack which not only applies to the deterministic version but also to the randomized version of Dilithium and is effective even on constant-time implementations using AVX2 instructions. The Signature Correction Attack exploits the mathematical structure of Dilithium to recover the secret key bits by using faulty signatures and the public-key. It can work for any fault mechanism which can induce single bit-flips. For demonstration, we are using Rowhammer induced faults. Thus, our attack does not require any physical access or special privileges, and hence could be also implemented on shared cloud servers. We perform a thorough classical and quantum security analysis of Dilithium and successfully recover 1,851 bits out of 3,072 bits of secret key $s_1$ for security level 2. The lattice strength against quantum attackers is reduced from $2^{128}$ to $2^{81}$ while the strength against classical attackers is reduced from $2^{141}$ to $2^{89}$. Hence, the Signature Correction Attack may be employed to achieve a practical attack on Dilithium (security level 2) as proposed in Round 3 of the NIST post-quantum standardization process. ",
    "url": "https://arxiv.org/abs/2203.00637",
    "authors": [
      "Saad Islam",
      "Koksal Mus",
      "Richa Singh",
      "Patrick Schaumont",
      "Berk Sunar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00638",
    "title": "PaSca: a Graph Neural Architecture Search System under the Scalable  Paradigm",
    "abstract": "Graph neural networks (GNNs) have achieved state-of-the-art performance in various graph-based tasks. However, as mainstream GNNs are designed based on the neural message passing mechanism, they do not scale well to data size and message passing steps. Although there has been an emerging interest in the design of scalable GNNs, current researches focus on specific GNN design, rather than the general design space, limiting the discovery of potential scalable GNN models. This paper proposes PasCa, a new paradigm and system that offers a principled approach to systemically construct and explore the design space for scalable GNNs, rather than studying individual designs. Through deconstructing the message passing mechanism, PasCa presents a novel Scalable Graph Neural Architecture Paradigm (SGAP), together with a general architecture design space consisting of 150k different designs. Following the paradigm, we implement an auto-search engine that can automatically search well-performing and scalable GNN architectures to balance the trade-off between multiple criteria (e.g., accuracy and efficiency) via multi-objective optimization. Empirical studies on ten benchmark datasets demonstrate that the representative instances (i.e., PasCa-V1, V2, and V3) discovered by our system achieve consistent performance among competitive baselines. Concretely, PasCa-V3 outperforms the state-of-the-art GNN method JK-Net by 0.4\\% in terms of predictive accuracy on our large industry dataset while achieving up to $28.3\\times$ training speedups. ",
    "url": "https://arxiv.org/abs/2203.00638",
    "authors": [
      "Wentao Zhang",
      "Yu Shen",
      "Zheyu Lin",
      "Yang Li",
      "Xiaosen Li",
      "Wen Ouyang",
      "Yangyu Tao",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.00648",
    "title": "Measuring the Impact of Individual Domain Factors in Self-Supervised  Pre-Training",
    "abstract": "Human speech data comprises a rich set of domain factors such as accent, syntactic and semantic variety, or acoustic environment. Previous work explores the effect of domain mismatch in automatic speech recognition between pre-training and fine-tuning as a whole but does not dissect the contribution of individual factors. In this paper, we present a controlled study to better understand the effect of such factors on the performance of pre-trained representations. To do so, we pre-train models either on modified natural speech or synthesized audio, with a single domain factor modified, and then measure performance on automatic speech recognition after fine tuning. Results show that phonetic domain factors play an important role during pre-training while grammatical and syntactic factors are far less important. To our knowledge, this is the first study to better understand the domain characteristics in self-supervised pre-training for speech. ",
    "url": "https://arxiv.org/abs/2203.00648",
    "authors": [
      "Ramon Sanabria",
      "Wei-Ning Hsu",
      "Alexei Baevski",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.00653",
    "title": "ONBRA: Rigorous Estimation of the Temporal Betweenness Centrality in  Temporal Networks",
    "abstract": "In network analysis, the betweenness centrality of a node informally captures the fraction of shortest paths visiting that node. The computation of the betweenness centrality measure is a fundamental task in the analysis of modern networks, enabling the identification of the most central nodes in such networks. Additionally to being massive, modern networks also contain information about the time at which their events occur. Such networks are often called temporal networks. The temporal information makes the study of the betweenness centrality in temporal networks (i.e., temporal betweenness centrality) much more challenging than in static networks (i.e., networks without temporal information). Moreover, the exact computation of the temporal betweenness centrality is often impractical on even moderately-sized networks, given its extremely high computational cost. A natural approach to reduce such computational cost is to obtain high-quality estimates of the exact values of the temporal betweenness centrality. In this work we present ONBRA, the first sampling-based approximation algorithm for estimating the temporal betweenness centrality values of the nodes in a temporal network, providing rigorous probabilistic guarantees on the quality of its output. ONBRA is able to compute the estimates of the temporal betweenness centrality values under two different optimality criteria for the shortest paths of the temporal network. In addition, ONBRA outputs high-quality estimates with sharp theoretical guarantees leveraging on the \\emph{empirical Bernstein bound}, an advanced concentration inequality. Finally, our experimental evaluation shows that ONBRA significantly reduces the computational resources required by the exact computation of the temporal betweenness centrality on several real world networks, while reporting high-quality estimates with rigorous guarantees. ",
    "url": "https://arxiv.org/abs/2203.00653",
    "authors": [
      "Diego Santoro",
      "Ilie Sarpe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00667",
    "title": "Generative Adversarial Networks",
    "abstract": "Generative Adversarial Networks (GANs) are very popular frameworks for generating high-quality data, and are immensely used in both the academia and industry in many domains. Arguably, their most substantial impact has been in the area of computer vision, where they achieve state-of-the-art image generation. This chapter gives an introduction to GANs, by discussing their principle mechanism and presenting some of their inherent problems during training and evaluation. We focus on these three issues: (1) mode collapse, (2) vanishing gradients, and (3) generation of low-quality images. We then list some architecture-variant and loss-variant GANs that remedy the above challenges. Lastly, we present two utilization examples of GANs for real-world applications: Data augmentation and face images generation. ",
    "url": "https://arxiv.org/abs/2203.00667",
    "authors": [
      "Gilad Cohen",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00672",
    "title": "Generalizable Person Re-Identification via Self-Supervised Batch Norm  Test-Time Adaption",
    "abstract": "In this paper, we investigate the generalization problem of person re-identification (re-id), whose major challenge is the distribution shift on an unseen domain. As an important tool of regularizing the distribution, batch normalization (BN) has been widely used in existing methods. However, they neglect that BN is severely biased to the training domain and inevitably suffers the performance drop if directly generalized without being updated. To tackle this issue, we propose Batch Norm Test-time Adaption (BNTA), a novel re-id framework that applies the self-supervised strategy to update BN parameters adaptively. Specifically, BNTA quickly explores the domain-aware information within unlabeled target data before inference, and accordingly modulates the feature distribution normalized by BN to adapt to the target domain. This is accomplished by two designed self-supervised auxiliary tasks, namely part positioning and part nearest neighbor matching, which help the model mine the domain-aware information with respect to the structure and identity of body parts, respectively. To demonstrate the effectiveness of our method, we conduct extensive experiments on three re-id datasets and confirm the superior performance to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2203.00672",
    "authors": [
      "Ke Han",
      "Chenyang Si",
      "Yan Huang",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00680",
    "title": "CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D  Point Cloud Understanding",
    "abstract": "Manual annotation of large-scale point cloud dataset for varying tasks such as 3D object classification, segmentation and detection is often laborious owing to the irregular structure of point clouds. Self-supervised learning, which operates without any human labeling, is a promising approach to address this issue. We observe in the real world that humans are capable of mapping the visual concepts learnt from 2D images to understand the 3D world. Encouraged by this insight, we propose CrossPoint, a simple cross-modal contrastive learning approach to learn transferable 3D point cloud representations. It enables a 3D-2D correspondence of objects by maximizing agreement between point clouds and the corresponding rendered 2D image in the invariant space, while encouraging invariance to transformations in the point cloud modality. Our joint training objective combines the feature correspondences within and across modalities, thus ensembles a rich learning signal from both 3D point cloud and 2D image modalities in a self-supervised fashion. Experimental results show that our approach outperforms the previous unsupervised learning methods on a diverse range of downstream tasks including 3D object classification and segmentation. Further, the ablation studies validate the potency of our approach for a better point cloud understanding. Code and pretrained models are available at this http URL ",
    "url": "https://arxiv.org/abs/2203.00680",
    "authors": [
      "Mohamed Afham",
      "Isuru Dissanayake",
      "Dinithi Dissanayake",
      "Amaya Dharmasiri",
      "Kanchana Thilakarathna",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00055",
    "title": "Risk-averse controller design against data injection attacks on  actuators for uncertain control systems",
    "abstract": "In this paper, we consider the optimal controller design problem against data injection attacks on actuators for an uncertain control system. We consider attacks that aim at maximizing the attack impact while remaining stealthy in the finite horizon. To this end, we use the Conditional Value-at-Risk to characterize the risk associated with the impact of attacks. The worst-case attack impact is characterized using the recently proposed output-to-output $\\ell_2$-gain (OOG). We formulate the design problem and observe that it is non-convex and hard to solve. Using the framework of scenario-based optimization and a convex proxy for the OOG, we propose a convex optimization problem that approximately solves the design problem with probabilistic certificates. Finally, we illustrate the results through a numerical example. ",
    "url": "https://arxiv.org/abs/2203.00055",
    "authors": [
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.00097",
    "title": "Estimating causal effects with optimization-based methods: A review and  empirical comparison",
    "abstract": "In the absence of randomized controlled and natural experiments, it is necessary to balance the distributions of (observable) covariates of the treated and control groups in order to obtain an unbiased estimate of a causal effect of interest; otherwise, a different effect size may be estimated, and incorrect recommendations may be given. To achieve this balance, there exist a wide variety of methods. In particular, several methods based on optimization models have been recently proposed in the causal inference literature. While these optimization-based methods empirically showed an improvement over a limited number of other causal inference methods in their relative ability to balance the distributions of covariates and to estimate causal effects, they have not been thoroughly compared to each other and to other noteworthy causal inference methods. In addition, we believe that there exist several unaddressed opportunities that operational researchers could contribute with their advanced knowledge of optimization, for the benefits of the applied researchers that use causal inference tools. In this review paper, we present an overview of the causal inference literature and describe in more detail the optimization-based causal inference methods, provide a comparative analysis of the prevailing optimization-based methods, and discuss opportunities for new methods. ",
    "url": "https://arxiv.org/abs/2203.00097",
    "authors": [
      "Martin Cousineau",
      "Vedat Verter",
      "Susan A. Murphy",
      "Joelle Pineau"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.00129",
    "title": "BlazeNeo: Blazing fast polyp segmentation and neoplasm detection",
    "abstract": "In recent years, computer-aided automatic polyp segmentation and neoplasm detection have been an emerging topic in medical image analysis, providing valuable support to colonoscopy procedures. Attentions have been paid to improving the accuracy of polyp detection and segmentation. However, not much focus has been given to latency and throughput for performing these tasks on dedicated devices, which can be crucial for practical applications. This paper introduces a novel deep neural network architecture called BlazeNeo, for the task of polyp segmentation and neoplasm detection with an emphasis on compactness and speed while maintaining high accuracy. The model leverages the highly efficient HarDNet backbone alongside lightweight Receptive Field Blocks for computational efficiency, and an auxiliary training mechanism to take full advantage of the training data for the segmentation quality. Our experiments on a challenging dataset show that BlazeNeo achieves improvements in latency and model size while maintaining comparable accuracy against state-of-the-art methods. When deploying on the Jetson AGX Xavier edge device in INT8 precision, our BlazeNeo achieves over 155 fps while yielding the best accuracy among all compared methods. ",
    "url": "https://arxiv.org/abs/2203.00129",
    "authors": [
      "Nguyen Sy An",
      "Phan Ngoc Lan",
      "Dao Viet Hang",
      "Dao Van Long",
      "Tran Quang Trung",
      "Nguyen Thi Thuy",
      "Dinh Viet Sang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00137",
    "title": "Learning Cross-Video Neural Representations for High-Quality Frame  Interpolation",
    "abstract": "This paper considers the problem of temporal video interpolation, where the goal is to synthesize a new video frame given its two neighbors. We propose Cross-Video Neural Representation (CURE) as the first video interpolation method based on neural fields (NF). NF refers to the recent class of methods for the neural representation of complex 3D scenes that has seen widespread success and application across computer vision. CURE represents the video as a continuous function parameterized by a coordinate-based neural network, whose inputs are the spatiotemporal coordinates and outputs are the corresponding RGB values. CURE introduces a new architecture that conditions the neural network on the input frames for imposing space-time consistency in the synthesized video. This not only improves the final interpolation quality, but also enables CURE to learn a prior across multiple videos. Experimental evaluations show that CURE achieves the state-of-the-art performance on video interpolation on several benchmark datasets. ",
    "url": "https://arxiv.org/abs/2203.00137",
    "authors": [
      "Wentao Shangguan",
      "Yu Sun",
      "Weijie Gan",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00296",
    "title": "Earthquake Control: An Emerging Application for Robust Control. Theory  and Experimental Tests",
    "abstract": "This paper addresses the possibility of using robust control theory for preventing earthquakes through fluid injections in the earth's crust. The designed robust controllers drive aseismically a fault system to a new equilibrium point of lower energy by tracking a slow reference signal. The control design is based on a reduced-order nonlinear model able to reproduce earthquake-like instabilities. Uncertainties related to the frictional and mechanical properties of the underlying physical process and external perturbations are considered. Two kinds of controllers are derived. The first one is based on sliding-mode theory and leads to local finite-time convergence of the tracking error and rejection of Lipschitz w.r.t. time perturbations. The second controller is based on LQR control and presents global exponential stability of the tracking error and rejection of Lipschitz w.r.t. states perturbations. Both controllers generate a continuous control signal, attenuating the chattering effect in the case of the sliding-mode algorithms. The developed controllers are tested extensively and compared on the basis of numerical simulations and experiments in the laboratory. The present work opens new perspectives for the application of robust nonlinear control theory to complex geosystems, earthquakes and sustainable energy production. ",
    "url": "https://arxiv.org/abs/2203.00296",
    "authors": [
      "Diego Guti\u00e9rrez-Oribio",
      "Georgios Tzortzopoulos",
      "Ioannis Stefanou",
      "Franck Plestan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.00320",
    "title": "Graph Normalized-LMP Algorithm for Signal Estimation Under Impulsive  Noise",
    "abstract": "In this paper, we introduce an adaptive graph normalized least mean pth power (GNLMP) algorithm for graph signal processing (GSP) that utilizes GSP techniques, including bandlimited filtering and node sampling, to estimate sampled graph signals under impulsive noise. Different from least-squares-based algorithms, such as the adaptive GSP Least Mean Squares (GLMS) algorithm and the normalized GLMS (GNLMS) algorithm, the GNLMP algorithm has the ability to reconstruct a graph signal that is corrupted by non-Gaussian noise with heavy-tailed characteristics. Compared to the recently introduced adaptive GSP least mean pth power (GLMP) algorithm, the GNLMP algorithm reduces the number of iterations to converge to a steady graph signal. The convergence condition of the GNLMP algorithm is derived, and the ability of the GNLMP algorithm to process multidimensional time-varying graph signals with multiple features is demonstrated as well. Simulations show the performance of the GNLMP algorithm in estimating steady-state and time-varying graph signals is faster than GLMP and more robust in comparison to GLMS and GNLMS. ",
    "url": "https://arxiv.org/abs/2203.00320",
    "authors": [
      "Yi Yan",
      "Radwa Adel",
      "Ercan Engin Kuruoglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00355",
    "title": "Tempera: Spatial Transformer Feature Pyramid Network for Cardiac MRI  Segmentation",
    "abstract": "Assessing the structure and function of the right ventricle (RV) is important in the diagnosis of several cardiac pathologies. However, it remains more challenging to segment the RV than the left ventricle (LV). In this paper, we focus on segmenting the RV in both short (SA) and long-axis (LA) cardiac MR images simultaneously. For this task, we propose a new multi-input/output architecture, hybrid 2D/3D geometric spatial TransformEr Multi-Pass fEature pyRAmid (Tempera). Our feature pyramid extends current designs by allowing not only a multi-scale feature output but multi-scale SA and LA input images as well. Tempera transfers learned features between SA and LA images via layer weight sharing and incorporates a geometric target transformer to map the predicted SA segmentation to LA space. Our model achieves an average Dice score of 0.836 and 0.798 for the SA and LA, respectively, and 26.31 mm and 31.19 mm Hausdorff distances. This opens up the potential for the incorporation of RV segmentation models into clinical workflows. ",
    "url": "https://arxiv.org/abs/2203.00355",
    "authors": [
      "Christoforos Galazis",
      "Huiyi Wu",
      "Zhuoyu Li",
      "Camille Petri",
      "Anil A. Bharath",
      "Marta Varela"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00373",
    "title": "On a faithful representation of Sturmian morphisms",
    "abstract": "The set of morphisms mapping any Sturmian sequence to a Sturmian sequence forms together with composition the so-called monoid of Sturm. For this monoid, we defne a faithful representation by $(3\\times 3)$-matrices with integer entries. We find three convex cones in $\\mathbb{R}^3$ and show that a matrix $R \\in Sl(\\mathbb{Z},3)$ is a matrix representing a Sturmian morphism if the three cones are invariant under multiplication by $R$ or $R^{-1}$. This property offers a new tool to study Sturmian sequences. We provide alternative proofs of four known results on Sturmian sequences fixed by a primitive morphism and a new result concerning the square root of a Sturmian sequence. ",
    "url": "https://arxiv.org/abs/2203.00373",
    "authors": [
      "Jana Lep\u0161ov\u00e1",
      "Edita Pelantov\u00e1",
      "\u0160t\u011bp\u00e1n Starosta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2203.00418",
    "title": "Recovery of Missing Sensor Data by Reconstructing Time-varying Graph  Signals",
    "abstract": "Wireless sensor networks are among the most promising technologies of the current era because of their small size, lower cost, and ease of deployment. With the increasing number of wireless sensors, the probability of generating missing data also rises. This incomplete data could lead to disastrous consequences if used for decision-making. There is rich literature dealing with this problem. However, most approaches show performance degradation when a sizable amount of data is lost. Inspired by the emerging field of graph signal processing, this paper performs a new study of a Sobolev reconstruction algorithm in wireless sensor networks. Experimental comparisons on several publicly available datasets demonstrate that the algorithm surpasses multiple state-of-the-art techniques by a maximum margin of 54%. We further show that this algorithm consistently retrieves the missing data even during massive data loss situations. ",
    "url": "https://arxiv.org/abs/2203.00418",
    "authors": [
      "Anindya Mondal",
      "Mayukhmali Das",
      "Aditi Chatterjee",
      "Palaniandavar Venkateswaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2203.00449",
    "title": "Deep Learning based Prediction of MSI in Colorectal Cancer via  Prediction of the Status of MMR Markers",
    "abstract": "An accurate diagnosis and profiling of tumour are critical to the best treatment choices for cancer patients. In addition to the cancer type and its aggressiveness, molecular heterogeneity also plays a vital role in treatment selection. MSI or MMR deficiency is one of the well-studied aberrations in terms of molecular changes. Colorectal cancer patients with MMR deficiency respond well to immunotherapy, hence assessment of the relevant molecular markers can assist clinicians in making optimal treatment selections for patients. Immunohistochemistry is one of the ways for identifying these molecular changes which requires additional sections of tumour tissue. Introduction of automated methods that can predict MSI or MMR status from a target image without the need for additional sections can substantially reduce the cost associated with it. In this work, we present our work on predicting MSI status in a two-stage process using a single target slide either stained with CK818 or H\\&E. First, we train a multi-headed convolutional neural network model where each head is responsible for predicting one of the MMR protein expressions. To this end, we perform registration of MMR slides to the target slide as a pre-processing step. In the second stage, statistical features computed from the MMR prediction maps are used for the final MSI prediction. Our results demonstrate that MSI classification can be improved on incorporating fine-grained MMR labels in comparison to the previous approaches in which coarse labels (MSI/MSS) are utilised. ",
    "url": "https://arxiv.org/abs/2203.00449",
    "authors": [
      "Ruqayya Awan",
      "Mohammed Nimir",
      "Shan E Ahmed Raza",
      "Johannes Lotz",
      "David Snead",
      "Andrew Robison",
      "Nasir M. Rajpoot"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.00461",
    "title": "JOINED : Prior Guided Multi-task Learning for Joint Optic Disc/Cup  Segmentation and Fovea Detection",
    "abstract": "Fundus photography has been routinely used to document the presence and severity of various retinal degenerative diseases such as age-related macula degeneration, glaucoma, and diabetic retinopathy, for which the fovea, optic disc (OD), and optic cup (OC) are important anatomical landmarks. Identification of those anatomical landmarks is of great clinical importance. However, the presence of lesions, drusen, and other abnormalities during retinal degeneration severely complicates automatic landmark detection and segmentation. Most existing works treat the identification of each landmark as a single task and typically do not make use of any clinical prior information. In this paper, we present a novel method, named JOINED, for prior guided multi-task learning for joint OD/OC segmentation and fovea detection. An auxiliary branch for distance prediction, in addition to a segmentation branch and a detection branch, is constructed to effectively utilize the distance information from each image pixel to landmarks of interest. Our proposed JOINED pipeline consists of a coarse stage and a fine stage. At the coarse stage, we obtain the OD/OC coarse segmentation and the heatmap localization of fovea through a joint segmentation and detection module. Afterwards, we crop the regions of interest for subsequent fine processing and use predictions obtained at the coarse stage as additional information for better performance and faster convergence. Experimental results reveal that our proposed JOINED outperforms existing state-of-the-art approaches on the publicly-available GAMMA, PALM, and REFUGE datasets of fundus images. Furthermore, JOINED ranked the 5th on the OD/OC segmentation and fovea detection tasks in the GAMMA challenge hosted by the MICCAI2021 workshop OMIA8. ",
    "url": "https://arxiv.org/abs/2203.00461",
    "authors": [
      "Huaqing He",
      "Li Lin",
      "Zhiyuan Cai",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00503",
    "title": "Gait Events Prediction using Hybrid CNN-RNN-based Deep Learning models  through a Single Waist-worn Wearable Sensor",
    "abstract": "Elderly gait is a source of rich information about their physical and mental health condition. As an alternative to the multiple sensors on the lower body parts, a single sensor on the pelvis has a positional advantage and an abundance of information acquirable. This study aimed to explore a way of improving the accuracy of gait event detection in the elderly using a single sensor on the waist and deep learning models. Data was gathered from elderly subjects equipped with three IMU sensors while they walked. The input was taken only from the waist sensor was used to train 16 deep-learning models including CNN, RNN, and CNN-RNN hybrid with or without the Bidirectional and Attention mechanism. The groundtruth was extracted from foot IMU sensors. Fairly high accuracy of 99.73% and 93.89% was achieved by the CNN-BiGRU-Att model at the tolerance window of $\\pm$6TS ($\\pm$6ms) and $\\pm$1TS ($\\pm$1ms) respectively. Advancing from the previous studies exploring gait event detection, the model showed a great improvement in terms of its prediction error having an MAE of 6.239ms and 5.24ms for HS and TO events respectively at the tolerance window of $\\pm$1TS. The results showed that the use of CNN-RNN hybrid models with Attention and Bidirectional mechanisms is promising for accurate gait event detection using a single waist sensor. The study can contribute to reducing the burden of gait detection and increase its applicability in future wearable devices that can be used for remote health monitoring (RHM) or diagnosis based thereon. ",
    "url": "https://arxiv.org/abs/2203.00503",
    "authors": [
      "Muhammad Zeeshan Arshad",
      "Ankhzaya Jamsrandorj",
      "Jinwook Kim",
      "Kyung-Ryoul Mun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00512",
    "title": "A Deep Bayesian Neural Network for Cardiac Arrhythmia Classification  with Rejection from ECG Recordings",
    "abstract": "With the development of deep learning-based methods, automated classification of electrocardiograms (ECGs) has recently gained much attention. Although the effectiveness of deep neural networks has been encouraging, the lack of information given by the outputs restricts clinicians' reexamination. If the uncertainty estimation comes along with the classification results, cardiologists can pay more attention to \"uncertain\" cases. Our study aims to classify ECGs with rejection based on data uncertainty and model uncertainty. We perform experiments on a real-world 12-lead ECG dataset. First, we estimate uncertainties using the Monte Carlo dropout for each classification prediction, based on our Bayesian neural network. Then, we accept predictions with uncertainty under a given threshold and provide \"uncertain\" cases for clinicians. Furthermore, we perform a simulation experiment using varying thresholds. Finally, with the help of a clinician, we conduct case studies to explain the results of large uncertainties and incorrect predictions with small uncertainties. The results show that correct predictions are more likely to have smaller uncertainties, and the performance on accepted predictions improves as the accepting ratio decreases (i.e. more rejections). Case studies also help explain why rejection can improve the performance. Our study helps neural networks produce more accurate results and provide information on uncertainties to better assist clinicians in the diagnosis process. It can also enable deep-learning-based ECG interpretation in clinical implementation. ",
    "url": "https://arxiv.org/abs/2203.00512",
    "authors": [
      "Wenrui Zhang",
      "Xinxin Di",
      "Guodong Wei",
      "Shijia Geng",
      "Zhaoji Fu",
      "Shenda Hong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00521",
    "title": "Causal Structure Learning with Greedy Unconditional Equivalence Search",
    "abstract": "We consider the problem of characterizing directed acyclic graph (DAG) models up to unconditional equivalence, i.e., when two DAGs have the same set of unconditional d-separation statements. Each unconditional equivalence class (UEC) can be uniquely represented with an undirected graph whose clique structure encodes the members of the class. Via this structure, we provide a transformational characterization of unconditional equivalence. Combining these results, we introduce a hybrid algorithm for learning DAG models from observational data, called Greedy Unconditional Equivalence Search (GUES), which first estimates the UEC of the data using independence tests and then greedily searches the UEC for the optimal DAG. Applying GUES on synthetic data, we show that it achieves comparable accuracy to existing methods. However, in contrast to existing methods, since the average UEC is observed to contain few DAGs, the search space for GUES is drastically reduced. ",
    "url": "https://arxiv.org/abs/2203.00521",
    "authors": [
      "Alex Markham",
      "Danai Deligeorgaki",
      "Pratik Misra",
      "Liam Solus"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2203.00531",
    "title": "Towards deep learning-powered IVF: A large public benchmark for  morphokinetic parameter prediction",
    "abstract": "An important limitation to the development of Artificial Intelligence (AI)-based solutions for In Vitro Fertilization (IVF) is the absence of a public reference benchmark to train and evaluate deep learning (DL) models. In this work, we describe a fully annotated dataset of 756 videos of developing embryos, for a total of 337k images. We applied ResNet, LSTM, and ResNet-3D architectures to our dataset and demonstrate that they overperform algorithmic approaches to automatically annotate stage development phases. Altogether, we propose the first public benchmark that will allow the community to evaluate morphokinetic models. This is the first step towards deep learning-powered IVF. Of note, we propose highly detailed annotations with 16 different development phases, including early cell division phases, but also late cell divisions, phases after morulation, and very early phases, which have never been used before. We postulate that this original approach will help improve the overall performance of deep learning approaches on time-lapse videos of embryo development, ultimately benefiting infertile patients with improved clinical success rates (Code and data are available at https://gitlab.univ-nantes.fr/E144069X/bench_mk_pred.git). ",
    "url": "https://arxiv.org/abs/2203.00531",
    "authors": [
      "Tristan Gomez",
      "Magalie Feyeux",
      "Nicolas Normand",
      "Laurent David",
      "Perrine Paul-Gilloteaux",
      "Thomas Fr\u00e9our",
      "Harold Mouch\u00e8re"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00550",
    "title": "Multivariate permutation entropy, a Cartesian graph product approach",
    "abstract": "Entropy metrics are nonlinear measures to quantify the complexity of time series. Among them, permutation entropy is a common metric due to its robustness and fast computation. Multivariate entropy metrics techniques are needed to analyse data consisting of more than one time series. To this end, we present a multivariate permutation entropy, $MPE_G$, using a graph-based approach. Given a multivariate signal, the algorithm $MPE_G$ involves two main steps: 1) we construct an underlying graph G as the Cartesian product of two graphs G1 and G2, where G1 preserves temporal information of each times series together with G2 that models the relations between different channels, and 2) we consider the multivariate signal as samples defined on the regular graph G and apply the recently introduced permutation entropy for graphs. Our graph-based approach gives the flexibility to consider diverse types of cross channel relationships and signals, and it overcomes with the limitations of current multivariate permutation entropy. ",
    "url": "https://arxiv.org/abs/2203.00550",
    "authors": [
      "John Stewart Fabila-Carrasco",
      "Chao Tan",
      "Javier Escudero"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.00554",
    "title": "Neural Score Matching for High-Dimensional Causal Inference",
    "abstract": "Traditional methods for matching in causal inference are impractical for high-dimensional datasets. They suffer from the curse of dimensionality: exact matching and coarsened exact matching find exponentially fewer matches as the input dimension grows, and propensity score matching may match highly unrelated units together. To overcome this problem, we develop theoretical results which motivate the use of neural networks to obtain non-trivial, multivariate balancing scores of a chosen level of coarseness, in contrast to the classical, scalar propensity score. We leverage these balancing scores to perform matching for high-dimensional causal inference and call this procedure neural score matching. We show that our method is competitive against other matching approaches on semi-synthetic high-dimensional datasets, both in terms of treatment effect estimation and reducing imbalance. ",
    "url": "https://arxiv.org/abs/2203.00554",
    "authors": [
      "Oscar Clivio",
      "Fabian Falck",
      "Brieuc Lehmann",
      "George Deligiannidis",
      "Chris Holmes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00595",
    "title": "Parameter estimation for WMTI-Watson model of white matter using  encoder-decoder recurrent neural network",
    "abstract": "Biophysical modelling of the diffusion MRI signal provides estimates of specific microstructural tissue properties.Although nonlinear optimization such as non-linear least squares (NLLS) is the most widespread method for model estimation, it suffers from local minima and high computational cost. Deep Learning approaches are steadily replacing NL fitting, but come with the limitation that the model needs to be retrained for each acquisition protocol and noise level. The White Matter Tract Integrity (WMTI)-Watson model was proposed as an implementation of the Standard Model of diffusion in white matter that estimates model parameters from the diffusion and kurtosis tensors (DKI). Here we proposed a deep learning approach based on the encoder-decoder recurrent neural network (RNN) to increase the robustness and accelerate the parameter estimation of WMTI-Watson. We use an embedding approach to render the model insensitive to potential differences in distributions between training data and experimental data. This RNN-based solver thus has the advantage of being highly efficient in computation and more readily translatable to other datasets, irrespective of acquisition protocol and underlying parameter distributions as long as DKI was pre-computed from the data. In this study, we evaluated the performance of NLLS, the RNN-based method and a multilayer perceptron (MLP) on synthetic and in vivo datasets of rat and human brain. We showed that the proposed RNN-based fitting approach had the advantage of highly reduced computation time over NLLS (from hours to seconds), with similar accuracy and precision but improved robustness, and superior translatability to new datasets over MLP. ",
    "url": "https://arxiv.org/abs/2203.00595",
    "authors": [
      "Yujian Diao",
      "Ileana Ozana Jelescu"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2203.00597",
    "title": "Path sampling of recurrent neural networks by incorporating known  physics",
    "abstract": "Recurrent neural networks have seen widespread use in modeling dynamical systems in varied domains such as weather prediction, text prediction and several others. Often one wishes to supplement the experimentally observed dynamics with prior knowledge or intuition about the system. While the recurrent nature of these networks allows them to model arbitrarily long memories in the time series used in training, it makes it harder to impose prior knowledge or intuition through generic constraints. In this work, we present a path sampling approach based on principle of Maximum Caliber that allows us to include generic thermodynamic or kinetic constraints into recurrent neural networks. We show the method here for a widely used type of recurrent neural network known as long short-term memory network in the context of supplementing time series collecting from all-atom molecular dynamics. We demonstrate the power of the formalism for different applications. Our method can be easily generalized to other generative artificial intelligence models and to generic time series in different areas of physical and social sciences, where one wishes to supplement limited data with intuition or theory based corrections. ",
    "url": "https://arxiv.org/abs/2203.00597",
    "authors": [
      "Sun-Ting Tsai",
      "Eric Fields",
      "Pratyush Tiwary"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2203.00628",
    "title": "A Neural Ordinary Differential Equation Model for Visualizing Deep  Neural Network Behaviors in Multi-Parametric MRI based Glioma Segmentation",
    "abstract": "Purpose: To develop a neural ordinary differential equation (ODE) model for visualizing deep neural network (DNN) behavior during multi-parametric MRI (mp-MRI) based glioma segmentation as a method to enhance deep learning explainability. Methods: By hypothesizing that deep feature extraction can be modeled as a spatiotemporally continuous process, we designed a novel deep learning model, neural ODE, in which deep feature extraction was governed by an ODE without explicit expression. The dynamics of 1) MR images after interactions with DNN and 2) segmentation formation can be visualized after solving ODE. An accumulative contribution curve (ACC) was designed to quantitatively evaluate the utilization of each MRI by DNN towards the final segmentation results. The proposed neural ODE model was demonstrated using 369 glioma patients with a 4-modality mp-MRI protocol: T1, contrast-enhanced T1 (T1-Ce), T2, and FLAIR. Three neural ODE models were trained to segment enhancing tumor (ET), tumor core (TC), and whole tumor (WT). The key MR modalities with significant utilization by DNN were identified based on ACC analysis. Segmentation results by DNN using only the key MR modalities were compared to the ones using all 4 MR modalities. Results: All neural ODE models successfully illustrated image dynamics as expected. ACC analysis identified T1-Ce as the only key modality in ET and TC segmentations, while both FLAIR and T2 were key modalities in WT segmentation. Compared to the U-Net results using all 4 MR modalities, Dice coefficient of ET (0.784->0.775), TC (0.760->0.758), and WT (0.841->0.837) using the key modalities only had minimal differences without significance. Conclusion: The neural ODE model offers a new tool for optimizing the deep learning model inputs with enhanced explainability. The presented methodology can be generalized to other medical image-related deep learning applications. ",
    "url": "https://arxiv.org/abs/2203.00628",
    "authors": [
      "Zhenyu Yang",
      "Zongsheng Hu",
      "Hangjie Ji",
      "Kyle Lafata",
      "Scott Floyd",
      "Fang-Fang Yin",
      "Chunhao Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2203.00641",
    "title": "Multi-Task Multi-Scale Learning For Outcome Prediction in 3D PET Images",
    "abstract": "Background and Objectives: Predicting patient response to treatment and survival in oncology is a prominent way towards precision medicine. To that end, radiomics was proposed as a field of study where images are used instead of invasive methods. The first step in radiomic analysis is the segmentation of the lesion. However, this task is time consuming and can be physician subjective. Automated tools based on supervised deep learning have made great progress to assist physicians. However, they are data hungry, and annotated data remains a major issue in the medical field where only a small subset of annotated images is available. Methods: In this work, we propose a multi-task learning framework to predict patient's survival and response. We show that the encoder can leverage multiple tasks to extract meaningful and powerful features that improve radiomics performance. We show also that subsidiary tasks serve as an inductive bias so that the model can better generalize. Results: Our model was tested and validated for treatment response and survival in lung and esophageal cancers, with an area under the ROC curve of 77% and 71% respectively, outperforming single task learning methods. Conclusions: We show that, by using a multi-task learning approach, we can boost the performance of radiomic analysis by extracting rich information of intratumoral and peritumoral regions. ",
    "url": "https://arxiv.org/abs/2203.00641",
    "authors": [
      "Amine Amyar",
      "Romain Modzelewski",
      "Pierre Vera",
      "Vincent Morard",
      "Su Ruan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1404.1646",
    "title": "Proximal Navigation Graphs and t-spanners",
    "abstract": " Comments: There is an error in the main claim ",
    "url": "https://arxiv.org/abs/1404.1646",
    "authors": [
      "Guillermo Ruiz",
      "Edgar Ch\u00e1vez"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2006.04735",
    "title": "Minibatch vs Local SGD for Heterogeneous Distributed Learning",
    "abstract": " Comments: 34 pages ",
    "url": "https://arxiv.org/abs/2006.04735",
    "authors": [
      "Blake Woodworth",
      "Kumar Kshitij Patel",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.14058",
    "title": "Anycast Agility: Network Playbooks to Fight DDoS",
    "abstract": " Comments: 21 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2006.14058",
    "authors": [
      "A S M Rizvi",
      "Leandro Bertholdo",
      "Joao Ceron",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2007.01634",
    "title": "Social distancing with the Optimal Steps Model",
    "abstract": " Comments: 9 pages, 8 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2007.01634",
    "authors": [
      "Christina Maria Mayr",
      "Gerta K\u00f6ster"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2009.02383",
    "title": "Don't miss the Mismatch: Investigating the Objective Function Mismatch  for Unsupervised Representation Learning",
    "abstract": " Comments: 13 pages, 6 figures, Published in Neural Computing and Applications ",
    "url": "https://arxiv.org/abs/2009.02383",
    "authors": [
      "Bonifaz Stuhr",
      "J\u00fcrgen Brauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.04293",
    "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions",
    "abstract": " Comments: Accepted to Findings of ACL 2022 ",
    "url": "https://arxiv.org/abs/2012.04293",
    "authors": [
      "Tayfun Ates",
      "M. Samil Atesoglu",
      "Cagatay Yigit",
      "Ilker Kesen",
      "Mert Kobas",
      "Erkut Erdem",
      "Aykut Erdem",
      "Tilbe Goksun",
      "Deniz Yuret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.11701",
    "title": "Learning from What We Know: How to Perform Vulnerability Prediction  using Noisy Historical Data",
    "abstract": " Title: Learning from What We Know: How to Perform Vulnerability Prediction  using Noisy Historical Data ",
    "url": "https://arxiv.org/abs/2012.11701",
    "authors": [
      "Aayush Garg",
      "Renzo Degiovanni",
      "Matthieu Jimenez",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2012.15764",
    "title": "Divergence Regulated Encoder Network for Joint Dimensionality Reduction  and Classification",
    "abstract": " Comments: 8 pages (5 main pages and 3 supplemental pages), 2 figures, accepted to IEEE Geoscience and Remote Sensing Letters ",
    "url": "https://arxiv.org/abs/2012.15764",
    "authors": [
      "Joshua Peeples",
      "Sarah Walker",
      "Connor McCurley",
      "Alina Zare",
      "James Keller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2101.08386",
    "title": "Invariance, encodings, and generalization: learning identity effects  with neural networks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2005.04330 ",
    "url": "https://arxiv.org/abs/2101.08386",
    "authors": [
      "S. Brugiapaglia",
      "M. Liu",
      "P. Tupper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2104.04798",
    "title": "Op2Vec: An Opcode Embedding Technique and Dataset Design for End-to-End  Detection of Android Malware",
    "abstract": " Title: Op2Vec: An Opcode Embedding Technique and Dataset Design for End-to-End  Detection of Android Malware ",
    "url": "https://arxiv.org/abs/2104.04798",
    "authors": [
      "Kaleem Nawaz Khan",
      "Najeeb Ullah",
      "Sikandar Ali",
      "Muhammad Salman Khan",
      "Mohammad Nauman",
      "Anwar Ghani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2104.05262",
    "title": "The Theory of Universal Graphs for Infinite Duration Games",
    "abstract": " Comments: 43 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2104.05262",
    "authors": [
      "Thomas Colcombet",
      "Nathana\u00ebl Fijalkow",
      "Pawe\u0142 Gawrychowski",
      "Pierre Ohlmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2104.08273",
    "title": "Membership Inference Attacks on Knowledge Graphs",
    "abstract": " Comments: Under submission ",
    "url": "https://arxiv.org/abs/2104.08273",
    "authors": [
      "Yu Wang",
      "Lifu Huang",
      "Philip S. Yu",
      "Lichao Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2105.12419",
    "title": "Adversarial Attack Framework on Graph Embedding Models with Limited  Knowledge",
    "abstract": " Comments: Journal extension of GF-Attack, accepted by TKDE ",
    "url": "https://arxiv.org/abs/2105.12419",
    "authors": [
      "Heng Chang",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang",
      "Honglei Zhang",
      "Peng Cui",
      "Xin Wang",
      "Wenwu Zhu",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.09637",
    "title": "AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition",
    "abstract": " Comments: Submitted to IROS 2022. Copyright may be transferred without notice, after which this version may no longer be accessible. Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version ",
    "url": "https://arxiv.org/abs/2106.09637",
    "authors": [
      "Tiago Barros",
      "Lu\u00eds Garrote",
      "Ricardo Pereira",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.11171",
    "title": "UniTTS: Residual Learning of Unified Embedding Space for Speech Style  Control",
    "abstract": " Comments: 20 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2106.11171",
    "authors": [
      "Minsu Kang",
      "Sungjae Kim",
      "Injung Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2107.01559",
    "title": "Smoothed Differential Privacy",
    "abstract": " Comments: 10 Page main text + Appendix ",
    "url": "https://arxiv.org/abs/2107.01559",
    "authors": [
      "Ao Liu",
      "Yu-Xiang Wang",
      "Lirong Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.00083",
    "title": "Majorization Minimization Methods for Distributed Pose Graph  Optimization",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/2108.00083",
    "authors": [
      "Taosha Fan",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2108.02352",
    "title": "Understand me, if you refer to Aspect Knowledge: Knowledge-aware Gated  Recurrent Memory Network",
    "abstract": " Comments: Accepted by IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI) 2022 ",
    "url": "https://arxiv.org/abs/2108.02352",
    "authors": [
      "Bowen Xing",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.06889",
    "title": "Causal Incremental Graph Convolution for Recommender System Retraining",
    "abstract": " Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2108.06889",
    "authors": [
      "Sihao Ding",
      "Fuli Feng",
      "Xiangnan He",
      "Yong Liao",
      "Jun Shi",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.02753",
    "title": "Semi-relaxed Gromov-Wasserstein divergence with applications on graphs",
    "abstract": " Comments: Published as a conference paper at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.02753",
    "authors": [
      "C\u00e9dric Vincent-Cuaz",
      "R\u00e9mi Flamary",
      "Marco Corneli",
      "Titouan Vayer",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03177",
    "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
    "abstract": " Comments: Published on ICLR 2022 ",
    "url": "https://arxiv.org/abs/2110.03177",
    "authors": [
      "Yikun Ban",
      "Yuchen Yan",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.07336",
    "title": "RPT: Toward Transferable Model on Heterogeneous Researcher Data via  Pre-Training",
    "abstract": " Comments: Accepted as regular paper by IEEE Transactions on Big Data ",
    "url": "https://arxiv.org/abs/2110.07336",
    "authors": [
      "Ziyue Qiao",
      "Yanjie Fu",
      "Pengyang Wang",
      "Meng Xiao",
      "Zhiyuan Ning",
      "Denghui Zhang",
      "Yi Du",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.15250",
    "title": "End-to-end Learning the Partial Permutation Matrix for Robust 3D Point  Cloud Registration",
    "abstract": " Comments: Accepted by AAAI 2022 ",
    "url": "https://arxiv.org/abs/2110.15250",
    "authors": [
      "Zhiyuan Zhang",
      "Jiadai Sun",
      "Yuchao Dai",
      "Dingfu Zhou",
      "Xibin Song",
      "Mingyi He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.00379",
    "title": "EfficientWord-Net: An Open Source Hotword Detection Engine based on  One-shot Learning",
    "abstract": " Comments: 9 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2111.00379",
    "authors": [
      "Chidhambararajan R",
      "Aman Rangapur",
      "Sibi Chakkaravarthy Sethuraman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.13566",
    "title": "StarNet: Joint Action-Space Prediction with Star Graphs and Implicit  Global Frame Self-Attention",
    "abstract": " Title: StarNet: Joint Action-Space Prediction with Star Graphs and Implicit  Global Frame Self-Attention ",
    "url": "https://arxiv.org/abs/2111.13566",
    "authors": [
      "Faris Janjo\u0161",
      "Maxim Dolgov",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2201.05409",
    "title": "Progressively Optimized Bi-Granular Document Representation for Scalable  Embedding Based Retrieval",
    "abstract": " Comments: Accepted as a full paper in WWW 2022 ",
    "url": "https://arxiv.org/abs/2201.05409",
    "authors": [
      "Shitao Xiao",
      "Zheng Liu",
      "Weihao Han",
      "Jianjin Zhang",
      "Yingxia Shao",
      "Defu Lian",
      "Chaozhuo Li",
      "Hao Sun",
      "Denvy Deng",
      "Liangjie Zhang",
      "Qi Zhang",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.06858",
    "title": "Self-Modifying Code in Open-Ended Evolutionary Systems",
    "abstract": " Comments: 27 pages, presented at The Fourth Workshop on Open-Ended Evolution (OEE4), extended version ",
    "url": "https://arxiv.org/abs/2201.06858",
    "authors": [
      "Patrik Christen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.12498",
    "title": "Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise",
    "abstract": " Title: Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise ",
    "url": "https://arxiv.org/abs/2201.12498",
    "authors": [
      "Yihao Xue",
      "Kyle Whitecross",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.05713",
    "title": "Cross Domain Few-Shot Learning via Meta Adversarial Training",
    "abstract": " Comments: 6 pages including references, submitted to ACL2021 ",
    "url": "https://arxiv.org/abs/2202.05713",
    "authors": [
      "Jirui Qi",
      "Richong Zhang",
      "Chune Li",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.06163",
    "title": "Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost",
    "abstract": " Title: Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost ",
    "url": "https://arxiv.org/abs/2202.06163",
    "authors": [
      "A. M. Khalili",
      "Abdelhamid Bouchachia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09027",
    "title": "Trusted AI in Multi-agent Systems: An Overview of Privacy and Security  for Distributed Learning",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1907.09470, arXiv:2003.02133, arXiv:1606.05053, arXiv:1812.06415 by other authors ",
    "url": "https://arxiv.org/abs/2202.09027",
    "authors": [
      "Chuan Ma",
      "Jun Li",
      "Kang Wei",
      "Bo Liu",
      "Ming Ding",
      "Long Yuan",
      "Zhu Han",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.10418",
    "title": "Composite Anomaly Detection via Hierarchical Dynamic Search",
    "abstract": " Title: Composite Anomaly Detection via Hierarchical Dynamic Search ",
    "url": "https://arxiv.org/abs/2202.10418",
    "authors": [
      "Benjamin Wolff",
      "Tomer Gafni",
      "Guy Revach",
      "Nir Shlezinger",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.10832",
    "title": "Multi-service Threats: Attacking and Protecting Network Printers and  VoIP Phones alike",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2111.10645, arXiv:2111.15468 ",
    "url": "https://arxiv.org/abs/2202.10832",
    "authors": [
      "Giampaolo Bella",
      "Pietro Biondi",
      "Stefano Bognanni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.11006",
    "title": "Robust and Online LiDAR-inertial Initialization",
    "abstract": " Comments: 8 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2202.11006",
    "authors": [
      "Fangcheng Zhu",
      "Yunfan Ren",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.12154",
    "title": "Towards Effective and Robust Neural Trojan Defenses via Input Filtering",
    "abstract": " Title: Towards Effective and Robust Neural Trojan Defenses via Input Filtering ",
    "url": "https://arxiv.org/abs/2202.12154",
    "authors": [
      "Kien Do",
      "Haripriya Harikumar",
      "Hung Le",
      "Dung Nguyen",
      "Truyen Tran",
      "Santu Rana",
      "Dang Nguyen",
      "Willy Susilo",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12450",
    "title": "MetaVA: Curriculum Meta-learning and Pre-fine-tuning of Deep Neural  Networks for Detecting Ventricular Arrhythmias based on ECGs",
    "abstract": " Title: MetaVA: Curriculum Meta-learning and Pre-fine-tuning of Deep Neural  Networks for Detecting Ventricular Arrhythmias based on ECGs ",
    "url": "https://arxiv.org/abs/2202.12450",
    "authors": [
      "Wenrui Zhang",
      "Shijia Geng",
      "Zhaoji Fu",
      "Linlin Zheng",
      "Chenyang Jiang",
      "Shenda Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.12478",
    "title": "GAME-ON: Graph Attention Network based Multimodal Fusion for Fake News  Detection",
    "abstract": " Comments: 8 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2202.12478",
    "authors": [
      "Mudit Dhawan",
      "Shakshi Sharma",
      "Aditya Kadam",
      "Rajesh Sharma",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12785",
    "title": "Confidence Calibration for Object Detection and Segmentation",
    "abstract": " Comments: Book chapter in: Tim Fingerscheidt, Hanno Gottschalk, Sebastian Houben (eds.): \"Deep Neural Networks and Data for Automated Driving\", pp. 255--282, Springer Nature Switzerland, 2022 ",
    "url": "https://arxiv.org/abs/2202.12785",
    "authors": [
      "Fabian K\u00fcppers",
      "Anselm Haselhoff",
      "Jan Kronenberger",
      "Jonas Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.13093",
    "title": "Exploring the Impact of Negative Samples of Contrastive Learning: A Case  Study of Sentence Embedding",
    "abstract": " Comments: 16 pages, 13 figures, accepted to appear in the Findings of ACL 2022 ",
    "url": "https://arxiv.org/abs/2202.13093",
    "authors": [
      "Rui Cao",
      "Yihao Wang",
      "Yuxin Liang",
      "Ling Gao",
      "Jie Zheng",
      "Jie Ren",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.13226",
    "title": "An acoustic signal cavitation detection framework based on XGBoost with  adaptive selection feature engineering",
    "abstract": " Title: An acoustic signal cavitation detection framework based on XGBoost with  adaptive selection feature engineering ",
    "url": "https://arxiv.org/abs/2202.13226",
    "authors": [
      "Yu Sha",
      "Johannes Faber",
      "Shuiping Gou",
      "Bo Liu",
      "Wei Li",
      "Stefan Schramm",
      "Horst Stoecker",
      "Thomas Steckenreiter",
      "Domagoj Vnucec",
      "Nadine Wetzstein",
      "Andreas Widl",
      "Kai Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.13313",
    "title": "An Efficient End-to-End 3D Model Reconstruction based on Neural  Architecture Search",
    "abstract": " Title: An Efficient End-to-End 3D Model Reconstruction based on Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2202.13313",
    "authors": [
      "Yongdong Huang",
      "Yuanzhan Li",
      "Xulong Cao",
      "Siyu Zhang",
      "Shen Cai",
      "Ting Lu",
      "Yuqi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13424",
    "title": "The Art of Manipulation: Threat of Multi-Step Manipulative Attacks in  Security Games",
    "abstract": " Title: The Art of Manipulation: Threat of Multi-Step Manipulative Attacks in  Security Games ",
    "url": "https://arxiv.org/abs/2202.13424",
    "authors": [
      "Thanh H. Nguyen",
      "Arunesh Sinha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2202.13755",
    "title": "Towards Robust Stacked Capsule Autoencoder with Hybrid Adversarial  Training",
    "abstract": " Title: Towards Robust Stacked Capsule Autoencoder with Hybrid Adversarial  Training ",
    "url": "https://arxiv.org/abs/2202.13755",
    "authors": [
      "Jiazhu Dai",
      "Siwei Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.13941",
    "title": "Background Mixup Data Augmentation for Hand and Object-in-Contact  Detection",
    "abstract": " Comments: 5 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2202.13941",
    "authors": [
      "Koya Tango",
      "Takehiko Ohkawa",
      "Ryosuke Furuta",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]