[
  {
    "id": "arXiv:2203.09550",
    "title": "Multi-similarity based Hyperrelation Network for few-shot segmentation",
    "abstract": "Few-shot semantic segmentation aims at recognizing the object regions of unseen categories with only a few annotated examples as supervision. The key to few-shot segmentation is to establish a robust semantic relationship between the support and query images and to prevent overfitting. In this paper, we propose an effective Multi-similarity Hyperrelation Network (MSHNet) to tackle the few-shot semantic segmentation problem. In MSHNet, we propose a new Generative Prototype Similarity (GPS), which together with cosine similarity can establish a strong semantic relation between the support and query images. The locally generated prototype similarity based on global feature is logically complementary to the global cosine similarity based on local feature, and the relationship between the query image and the supported image can be expressed more comprehensively by using the two similarities simultaneously. In addition, we propose a Symmetric Merging Block (SMB) in MSHNet to efficiently merge multi-layer, multi-shot and multi-similarity hyperrelational features. MSHNet is built on the basis of similarity rather than specific category features, which can achieve more general unity and effectively reduce overfitting. On two benchmark semantic segmentation datasets Pascal-5i and COCO-20i, MSHNet achieves new state-of-the-art performances on 1-shot and 5-shot semantic segmentation tasks. ",
    "url": "https://arxiv.org/abs/2203.09550",
    "authors": [
      "Xiangwen Shi",
      "Shaobing Zhang",
      "Miao Cheng",
      "Lian He",
      "Zhe Cui",
      "Xianghong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09553",
    "title": "Efficient Federated Learning on Knowledge Graphs via Privacy-preserving  Relation Embedding Aggregation",
    "abstract": "Federated Learning (FL) on knowledge graphs (KGs) has yet to be as well studied as other domains, such as computer vision and natural language processing. A recent study FedE first proposes an FL framework that shares entity embeddings of KGs across all clients. However, compared with model sharing in vanilla FL, entity embedding sharing from FedE would incur severe privacy leakage. Specifically, the known entity embedding can be used to infer whether a specific relation between two entities exists in a private client. In this paper, we first develop a novel attack that aims to recover the original data based on embedding information, which is further used to evaluate the vulnerabilities of FedE. Furthermore, we propose a Federated learning paradigm with privacy-preserving Relation embedding aggregation (FedR) to tackle the privacy issue in FedE. Compared to entity embedding sharing, relation embedding sharing policy can significantly reduce the communication cost due to its smaller size of queries. We conduct extensive experiments to evaluate FedR with five different embedding learning models and three benchmark KG datasets. Compared to FedE, FedR achieves similar utility and significant (nearly 2X) improvements in both privacy and efficiency on link prediction task. ",
    "url": "https://arxiv.org/abs/2203.09553",
    "authors": [
      "Kai Zhang",
      "Yu Wang",
      "Hongyi Wang",
      "Lifu Huang",
      "Carl Yang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09555",
    "title": "On the expressive power of message-passing neural networks as global  feature map transformers",
    "abstract": "We investigate the power of message-passing neural networks (MPNNs) in their capacity to transform the numerical features stored in the nodes of their input graphs. Our focus is on global expressive power, uniformly over all input graphs, or over graphs of bounded degree with features from a bounded domain. Accordingly, we introduce the notion of a global feature map transformer (GFMT). As a yardstick for expressiveness, we use a basic language for GFMTs, which we call MPLang. Every MPNN can be expressed in MPLang, and our results clarify to which extent the converse inclusion holds. We consider exact versus approximate expressiveness; the use of arbitrary activation functions; and the case where only the ReLU activation function is allowed. ",
    "url": "https://arxiv.org/abs/2203.09555",
    "authors": [
      "Floris Geerts",
      "Jasper Steegmans",
      "Jan Van den Bussche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09566",
    "title": "Leveraging Adversarial Examples to Quantify Membership Information  Leakage",
    "abstract": "The use of personal data for training machine learning systems comes with a privacy threat and measuring the level of privacy of a model is one of the major challenges in machine learning today. Identifying training data based on a trained model is a standard way of measuring the privacy risks induced by the model. We develop a novel approach to address the problem of membership inference in pattern recognition models, relying on information provided by adversarial examples. The strategy we propose consists of measuring the magnitude of a perturbation necessary to build an adversarial example. Indeed, we argue that this quantity reflects the likelihood of belonging to the training data. Extensive numerical experiments on multivariate data and an array of state-of-the-art target models show that our method performs comparable or even outperforms state-of-the-art strategies, but without requiring any additional training samples. ",
    "url": "https://arxiv.org/abs/2203.09566",
    "authors": [
      "Ganesh Del Grosso",
      "Hamid Jalalzai",
      "Georg Pichler",
      "Catuscia Palamidessi",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09572",
    "title": "Triangle and Four Cycle Counting with Predictions in Graph Streams",
    "abstract": "We propose data-driven one-pass streaming algorithms for estimating the number of triangles and four cycles, two fundamental problems in graph analytics that are widely studied in the graph data stream literature. Recently, (Hsu 2018) and (Jiang 2020) applied machine learning techniques in other data stream problems, using a trained oracle that can predict certain properties of the stream elements to improve on prior \"classical\" algorithms that did not use oracles. In this paper, we explore the power of a \"heavy edge\" oracle in multiple graph edge streaming models. In the adjacency list model, we present a one-pass triangle counting algorithm improving upon the previous space upper bounds without such an oracle. In the arbitrary order model, we present algorithms for both triangle and four cycle estimation with fewer passes and the same space complexity as in previous algorithms, and we show several of these bounds are optimal. We analyze our algorithms under several noise models, showing that the algorithms perform well even when the oracle errs. Our methodology expands upon prior work on \"classical\" streaming algorithms, as previous multi-pass and random order streaming algorithms can be seen as special cases of our algorithms, where the first pass or random order was used to implement the heavy edge oracle. Lastly, our experiments demonstrate advantages of the proposed method compared to state-of-the-art streaming algorithms. ",
    "url": "https://arxiv.org/abs/2203.09572",
    "authors": [
      "Justin Y. Chen",
      "Talya Eden",
      "Piotr Indyk",
      "Honghao Lin",
      "Shyam Narayanan",
      "Ronitt Rubinfeld",
      "Sandeep Silwal",
      "Tal Wagner",
      "David P. Woodruff",
      "Michael Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09578",
    "title": "GAC: A Deep Reinforcement Learning Model Toward User Incentivization in  Unknown Social Networks",
    "abstract": "In recent years, providing incentives to human users for attracting their attention and engagement has been widely adopted in many applications. To effectively incentivize users, most incentive mechanisms determine incentive values based on users' individual attributes, such as preferences. These approaches could be ineffective when such information is unavailable. Meanwhile, due to the budget limitation, the number of users who can be incentivized is also restricted. In this light, we intend to utilize social influence among users to maximize the incentivization. By directly incentivizing influential users in the social network, their followers and friends could be indirectly incentivized with fewer incentives or no incentive. However, it is difficult to identify influential users beforehand in the social network, as the influence strength between each pair of users is typically unknown. In this work, we propose an end-to-end reinforcement learning-based framework, named Geometric Actor-Critic (GAC), to discover effective incentive allocation policies under limited budgets. More specifically, the proposed approach can extract information from a high-level network representation for learning effective incentive allocation policies. The proposed GAC only requires the topology of the social network and does not rely on any prior information about users' attributes. We use three real-world social network datasets to evaluate the performance of the proposed GAC. The experimental results demonstrate the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2203.09578",
    "authors": [
      "Shiqing Wu",
      "Weihua Li",
      "Quan Bai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09580",
    "title": "Surface Defect Detection and Evaluation for Marine Vessels using  Multi-Stage Deep Learning",
    "abstract": "Detecting and evaluating surface coating defects is important for marine vessel maintenance. Currently, the assessment is carried out manually by qualified inspectors using international standards and their own experience. Automating the processes is highly challenging because of the high level of variation in vessel type, paint surface, coatings, lighting condition, weather condition, paint colors, areas of the vessel, and time in service. We present a novel deep learning-based pipeline to detect and evaluate the percentage of corrosion, fouling, and delamination on the vessel surface from normal photographs. We propose a multi-stage image processing framework, including ship section segmentation, defect segmentation, and defect classification, to automatically recognize different types of defects and measure the coverage percentage on the ship surface. Experimental results demonstrate that our proposed pipeline can objectively perform a similar assessment as a qualified inspector. ",
    "url": "https://arxiv.org/abs/2203.09580",
    "authors": [
      "Li Yu",
      "Kareem Metwaly",
      "James Z. Wang",
      "Vishal Monga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09604",
    "title": "Overview of Test Coverage Criteria for Test Case Generation from Finite  State Machines Modelled as Directed Graphs",
    "abstract": "Test Coverage criteria are an essential concept for test engineers when generating the test cases from a System Under Test model. They are routinely used in test case generation for user interfaces, middleware, and back-end system parts for software, electronics, or Internet of Things (IoT) systems. Test Coverage criteria define the number of actions or combinations by which a system is tested, informally determining a potential \"strength\" of a test set. As no previous study summarized all commonly used test coverage criteria for Finite State Machines and comprehensively discussed them regarding their subsumption, equivalence, or non-comparability, this paper provides this overview. In this study, 14 most common test coverage criteria and seven of their synonyms for Finite State Machines defined via a directed graph are summarized and compared. The results give researchers and industry testing engineers a helpful overview when setting a software-based or IoT system test strategy. ",
    "url": "https://arxiv.org/abs/2203.09604",
    "authors": [
      "Vaclav Rechtberger",
      "Miroslav Bures",
      "Bestoun S. Ahmed"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2203.09607",
    "title": "Learning Distributionally Robust Models at Scale via Composite  Optimization",
    "abstract": "To train machine learning models that are robust to distribution shifts in the data, distributionally robust optimization (DRO) has been proven very effective. However, the existing approaches to learning a distributionally robust model either require solving complex optimization problems such as semidefinite programming or a first-order method whose convergence scales linearly with the number of data samples -- which hinders their scalability to large datasets. In this paper, we show how different variants of DRO are simply instances of a finite-sum composite optimization for which we provide scalable methods. We also provide empirical results that demonstrate the effectiveness of our proposed algorithm with respect to the prior art in order to learn robust models from very large datasets. ",
    "url": "https://arxiv.org/abs/2203.09607",
    "authors": [
      "Farzin Haddadpour",
      "Mohammad Mahdi Kamani",
      "Mehrdad Mahdavi",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.09619",
    "title": "The Analysis of Online Event Streams: Predicting the Next Activity for  Anomaly Detection",
    "abstract": "Anomaly detection in process mining focuses on identifying anomalous cases or events in process executions. The resulting diagnostics are used to provide measures to prevent fraudulent behavior, as well as to derive recommendations for improving process compliance and security. Most existing techniques focus on detecting anomalous cases in an offline setting. However, to identify potential anomalies in a timely manner and take immediate countermeasures, it is necessary to detect event-level anomalies online, in real-time. In this paper, we propose to tackle the online event anomaly detection problem using next-activity prediction methods. More specifically, we investigate the use of both ML models (such as RF and XGBoost) and deep models (such as LSTM) to predict the probabilities of next-activities and consider the events predicted unlikely as anomalies. We compare these predictive anomaly detection methods to four classical unsupervised anomaly detection approaches (such as Isolation forest and LOF) in the online setting. Our evaluation shows that the proposed method using ML models tends to outperform the one using a deep model, while both methods outperform the classical unsupervised approaches in detecting anomalous events. ",
    "url": "https://arxiv.org/abs/2203.09619",
    "authors": [
      "Suhwan Lee",
      "Xixi Lu",
      "Hajo A. Reijers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.09620",
    "title": "Message recovery attack to NTRU using a lattice independent from the  public key",
    "abstract": "In the present paper we introduce a new attack on NTRU-HPS cryptosystem using lattice theory and Babai's Nearest Plane Algorithm. This attack has many similarities with the classic CVP attack on NTRU, but in our case we use a different lattice, instead of the classic lattice which is constructed with the public key. Finally, the attack is illustrated by many examples. ",
    "url": "https://arxiv.org/abs/2203.09620",
    "authors": [
      "Marios Adamoudis",
      "K. A. Draziotis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.09630",
    "title": "Monotonic Differentiable Sorting Networks",
    "abstract": "Differentiable sorting algorithms allow training with sorting and ranking supervision, where only the ordering or ranking of samples is known. Various methods have been proposed to address this challenge, ranging from optimal transport-based differentiable Sinkhorn sorting algorithms to making classic sorting networks differentiable. One problem of current differentiable sorting methods is that they are non-monotonic. To address this issue, we propose a novel relaxation of conditional swap operations that guarantees monotonicity in differentiable sorting networks. We introduce a family of sigmoid functions and prove that they produce differentiable sorting networks that are monotonic. Monotonicity ensures that the gradients always have the correct sign, which is an advantage in gradient-based optimization. We demonstrate that monotonic differentiable sorting networks improve upon previous differentiable sorting methods. ",
    "url": "https://arxiv.org/abs/2203.09630",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.09637",
    "title": "Investigating Compounding Prediction Errors in Learned Dynamics Models",
    "abstract": "Accurately predicting the consequences of agents' actions is a key prerequisite for planning in robotic control. Model-based reinforcement learning (MBRL) is one paradigm which relies on the iterative learning and prediction of state-action transitions to solve a task. Deep MBRL has become a popular candidate, using a neural network to learn a dynamics model that predicts with each pass from high-dimensional states to actions. These \"one-step\" predictions are known to become inaccurate over longer horizons of composed prediction - called the compounding error problem. Given the prevalence of the compounding error problem in MBRL and related fields of data-driven control, we set out to understand the properties of and conditions causing these long-horizon errors. In this paper, we explore the effects of subcomponents of a control problem on long term prediction error: including choosing a system, collecting data, and training a model. These detailed quantitative studies on simulated and real-world data show that the underlying dynamics of a system are the strongest factor determining the shape and magnitude of prediction error. Given a clearer understanding of compounding prediction error, researchers can implement new types of models beyond \"one-step\" that are more useful for control. ",
    "url": "https://arxiv.org/abs/2203.09637",
    "authors": [
      "Nathan Lambert",
      "Kristofer Pister",
      "Roberto Calandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09638",
    "title": "Unified Line and Paragraph Detection by Graph Convolutional Networks",
    "abstract": "We formulate the task of detecting lines and paragraphs in a document into a unified two-level clustering problem. Given a set of text detection boxes that roughly correspond to words, a text line is a cluster of boxes and a paragraph is a cluster of lines. These clusters form a two-level tree that represents a major part of the layout of a document. We use a graph convolutional network to predict the relations between text detection boxes and then build both levels of clusters from these predictions. Experimentally, we demonstrate that the unified approach can be highly efficient while still achieving state-of-the-art quality for detecting paragraphs in public benchmarks and real-world images. ",
    "url": "https://arxiv.org/abs/2203.09638",
    "authors": [
      "Shuang Liu",
      "Renshen Wang",
      "Michalis Raptis",
      "Yasuhisa Fujii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09639",
    "title": "Generating unrepresented proportions of geological facies using  Generative Adversarial Networks",
    "abstract": "In this work, we investigate the capacity of Generative Adversarial Networks (GANs) in interpolating and extrapolating facies proportions in a geological dataset. The new generated realizations with unrepresented (aka. missing) proportions are assumed to belong to the same original data distribution. Specifically, we design a conditional GANs model that can drive the generated facies toward new proportions not found in the training set. The presented study includes an investigation of various training settings and model architectures. In addition, we devised new conditioning routines for an improved generation of the missing samples. The presented numerical experiments on images of binary and multiple facies showed good geological consistency as well as strong correlation with the target conditions. ",
    "url": "https://arxiv.org/abs/2203.09639",
    "authors": [
      "Alhasan Abdellatif",
      "Ahmed H. Elsheikh",
      "Gavin Graham",
      "Daniel Busby",
      "Philippe Berthet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09663",
    "title": "An Improved Subject-Independent Stress Detection Model Applied to  Consumer-grade Wearable Devices",
    "abstract": "Stress is a complex issue with wide-ranging physical and psychological impacts on human daily performance. Specifically, acute stress detection is becoming a valuable application in contextual human understanding. Two common approaches to training a stress detection model are subject-dependent and subject-independent training methods. Although subject-dependent training methods have proven to be the most accurate approach to build stress detection models, subject-independent models are a more practical and cost-efficient method, as they allow for the deployment of stress level detection and management systems in consumer-grade wearable devices without requiring training data for the end-user. To improve the performance of subject-independent stress detection models, in this paper, we introduce a stress-related bio-signal processing pipeline with a simple neural network architecture using statistical features extracted from multimodal contextual sensing sources including Electrodermal Activity (EDA), Blood Volume Pulse (BVP), and Skin Temperature (ST) captured from a consumer-grade wearable device. Using our proposed model architecture, we compare the accuracy between stress detection models that use measures from each individual signal source, and one model employing the fusion of multiple sensor sources. Extensive experiments on the publicly available WESAD dataset demonstrate that our proposed model outperforms conventional methods as well as providing 1.63% higher mean accuracy score compared to the state-of-the-art model while maintaining a low standard deviation. Our experiments also show that combining features from multiple sources produce more accurate predictions than using only one sensor source individually. ",
    "url": "https://arxiv.org/abs/2203.09663",
    "authors": [
      "Van-Tu Ninh",
      "Manh-Duy Nguyen",
      "Sin\u00e9ad Smyth",
      "Minh-Triet Tran",
      "Graham Healy",
      "Binh T. Nguyen",
      "Cathal Gurrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09669",
    "title": "Analysing the Performance of Stress Detection Models on Consumer-Grade  Wearable Devices",
    "abstract": "Identifying stress levels can provide valuable data for mental health analytics as well as labels for annotation systems. Although much research has been conducted into stress detection models using heart rate variability at a higher cost of data collection, there is a lack of research on the potential of using low-resolution Electrodermal Activity (EDA) signals from consumer-grade wearable devices to identify stress patterns. In this paper, we concentrate on performing statistical analyses on the stress detection capability of two popular approaches of training stress detection models with stress-related biometric signals: user-dependent and user-independent models. Our research manages to show that user-dependent models are statistically more accurate for stress detection. In terms of effectiveness assessment, the balanced accuracy (BA) metric is employed to evaluate the capability of distinguishing stress and non-stress conditions of the models trained on either low-resolution or high-resolution Electrodermal Activity (EDA) signals. The results from the experiment show that training the model with (comparatively low-cost) low-resolution EDA signal does not affect the stress detection accuracy of the model significantly compared to using a high-resolution EDA signal. Our research results demonstrate the potential of attaching the user-dependent stress detection model trained on personal low-resolution EDA signal recorded to collect data in daily life to provide users with personal stress level insight and analysis. ",
    "url": "https://arxiv.org/abs/2203.09669",
    "authors": [
      "Van-Tu Ninh",
      "Sin\u00e9ad Smyth",
      "Minh-Triet Tran",
      "Cathal Gurrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09672",
    "title": "Multi-Modal Causal Inference with Deep Structural Equation Models",
    "abstract": "Accounting for the effects of confounders is one of the central challenges in causal inference. Unstructured multi-modal data (images, time series, text) contains valuable information about diverse types of confounders, yet it is typically left unused by most existing methods. This paper seeks to develop techniques that leverage this unstructured data within causal inference to correct for additional confounders that may otherwise not be accounted for. We formalize this task and we propose algorithms based on deep structural equations that treat multi-modal unstructured data as proxy variables. We empirically demonstrate on tasks in genomics and healthcare that unstructured data can be used to correct for diverse sources of confounding, potentially enabling the use of large amounts of data that were previously not used in causal inference. ",
    "url": "https://arxiv.org/abs/2203.09672",
    "authors": [
      "Shachi Deshpande",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09678",
    "title": "Self-Ensemble Adversarial Training for Improved Robustness",
    "abstract": "Due to numerous breakthroughs in real-world applications brought by machine intelligence, deep neural networks (DNNs) are widely employed in critical applications. However, predictions of DNNs are easily manipulated with imperceptible adversarial perturbations, which impedes the further deployment of DNNs and may result in profound security and privacy implications. By incorporating adversarial samples into the training data pool, adversarial training is the strongest principled strategy against various adversarial attacks among all sorts of defense methods. Recent works mainly focus on developing new loss functions or regularizers, attempting to find the unique optimal point in the weight space. But none of them taps the potentials of classifiers obtained from standard adversarial training, especially states on the searching trajectory of training. In this work, we are dedicated to the weight states of models through the training process and devise a simple but powerful \\emph{Self-Ensemble Adversarial Training} (SEAT) method for yielding a robust classifier by averaging weights of history models. This considerably improves the robustness of the target model against several well known adversarial attacks, even merely utilizing the naive cross-entropy loss to supervise. We also discuss the relationship between the ensemble of predictions from different adversarially trained models and the prediction of weight-ensembled models, as well as provide theoretical and empirical evidence that the proposed self-ensemble method provides a smoother loss landscape and better robustness than both individual models and the ensemble of predictions from different classifiers. We further analyze a subtle but fatal issue in the general settings for the self-ensemble model, which causes the deterioration of the weight-ensembled method in the late phases. ",
    "url": "https://arxiv.org/abs/2203.09678",
    "authors": [
      "Hongjun Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.09692",
    "title": "Facial Geometric Detail Recovery via Implicit Representation",
    "abstract": "Learning a dense 3D model with fine-scale details from a single facial image is highly challenging and ill-posed. To address this problem, many approaches fit smooth geometries through facial prior while learning details as additional displacement maps or personalized basis. However, these techniques typically require vast datasets of paired multi-view data or 3D scans, whereas such datasets are scarce and expensive. To alleviate heavy data dependency, we present a robust texture-guided geometric detail recovery approach using only a single in-the-wild facial image. More specifically, our method combines high-quality texture completion with the powerful expressiveness of implicit surfaces. Initially, we inpaint occluded facial parts, generate complete textures, and build an accurate multi-view dataset of the same subject. In order to estimate the detailed geometry, we define an implicit signed distance function and employ a physically-based implicit renderer to reconstruct fine geometric details from the generated multi-view images. Our method not only recovers accurate facial details but also decomposes normals, albedos, and shading parts in a self-supervised way. Finally, we register the implicit shape details to a 3D Morphable Model template, which can be used in traditional modeling and rendering pipelines. Extensive experiments demonstrate that the proposed approach can reconstruct impressive facial details from a single image, especially when compared with state-of-the-art methods trained on large datasets. ",
    "url": "https://arxiv.org/abs/2203.09692",
    "authors": [
      "Xingyu Ren",
      "Alexandros Lattas",
      "Baris Gecer",
      "Jiankang Deng",
      "Chao Ma",
      "Xiaokang Yang",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09697",
    "title": "Towards Training Billion Parameter Graph Neural Networks for Atomic  Simulations",
    "abstract": "Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the number of parameters of the recently proposed DimeNet++ and GemNet models by over an order of magnitude. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric for the S2EF task and 2) 21% on the AFbT metric for the IS2RS task, establishing new state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2203.09697",
    "authors": [
      "Anuroop Sriram",
      "Abhishek Das",
      "Brandon M. Wood",
      "Siddharth Goyal",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.09702",
    "title": "Federated Learning for Privacy Preservation in Smart Healthcare Systems:  A Comprehensive Survey",
    "abstract": "Recent advances in electronic devices and communication infrastructure have revolutionized the traditional healthcare system into a smart healthcare system by using IoMT devices. However, due to the centralized training approach of artificial intelligence (AI), the use of mobile and wearable IoMT devices raises privacy concerns with respect to the information that has been communicated between hospitals and end users. The information conveyed by the IoMT devices is highly confidential and can be exposed to adversaries. In this regard, federated learning (FL), a distributive AI paradigm has opened up new opportunities for privacy-preservation in IoMT without accessing the confidential data of the participants. Further, FL provides privacy to end users as only gradients are shared during training. For these specific properties of FL, in this paper we present privacy related issues in IoMT. Afterwards, we present the role of FL in IoMT networks for privacy preservation and introduce some advanced FL architectures incorporating deep reinforcement learning (DRL), digital twin, and generative adversarial networks (GANs) for detecting privacy threats. Subsequently, we present some practical opportunities of FL in smart healthcare systems. At the end, we conclude this survey by providing open research challenges for FL that can be used in future smart healthcare systems ",
    "url": "https://arxiv.org/abs/2203.09702",
    "authors": [
      "Mansoor Ali",
      "Faisal Naeem",
      "Muhammad Tariq",
      "Geroges Kaddoum"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09704",
    "title": "VISTA: Boosting 3D Object Detection via Dual Cross-VIew SpaTial  Attention",
    "abstract": "Detecting objects from LiDAR point clouds is of tremendous significance in autonomous driving. In spite of good progress, accurate and reliable 3D detection is yet to be achieved due to the sparsity and irregularity of LiDAR point clouds. Among existing strategies, multi-view methods have shown great promise by leveraging the more comprehensive information from both bird's eye view (BEV) and range view (RV). These multi-view methods either refine the proposals predicted from single view via fused features, or fuse the features without considering the global spatial context; their performance is limited consequently. In this paper, we propose to adaptively fuse multi-view features in a global spatial context via Dual Cross-VIew SpaTial Attention (VISTA). The proposed VISTA is a novel plug-and-play fusion module, wherein the multi-layer perceptron widely adopted in standard attention modules is replaced with a convolutional one. Thanks to the learned attention mechanism, VISTA can produce fused features of high quality for prediction of proposals. We decouple the classification and regression tasks in VISTA, and an additional constraint of attention variance is applied that enables the attention module to focus on specific targets instead of generic points. We conduct thorough experiments on the benchmarks of nuScenes and Waymo; results confirm the efficacy of our designs. At the time of submission, our method achieves 63.0% in overall mAP and 69.8% in NDS on the nuScenes benchmark, outperforming all published methods by up to 24% in safety-crucial categories such as cyclist. The source code in PyTorch is available at https://github.com/Gorilla-Lab-SCUT/VISTA ",
    "url": "https://arxiv.org/abs/2203.09704",
    "authors": [
      "Shengheng Deng",
      "Zhihao Liang",
      "Lin Sun",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09707",
    "title": "M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source  Code Summarization",
    "abstract": "Source code summarization aims to generate natural language descriptions of code snippets. Many existing studies learn the syntactic and semantic knowledge of code snippets from their token sequences and Abstract Syntax Trees (ASTs). They use the learned code representations as input to code summarization models, which can accordingly generate summaries describing source code. Traditional models traverse ASTs as sequences or split ASTs into paths as input. However, the former loses the structural properties of ASTs, and the latter destroys the overall structure of ASTs. Therefore, comprehensively capturing the structural features of ASTs in learning code representations for source code summarization remains a challenging problem to be solved. In this paper, we propose M2TS, a Multi-scale Multi-modal approach based on Transformer for source code Summarization. M2TS uses a multi-scale AST feature extraction method, which can extract the structures of ASTs more completely and accurately at multiple local and global levels. To complement missing semantic information in ASTs, we also obtain code token features, and further combine them with the extracted AST features using a cross modality fusion method that not only fuses the syntactic and contextual semantic information of source code, but also highlights the key features of each modality. We conduct experiments on two Java and one Python datasets, and the experimental results demonstrate that M2TS outperforms current state-of-the-art methods. We release our code at https://github.com/TranSMS/M2TS. ",
    "url": "https://arxiv.org/abs/2203.09707",
    "authors": [
      "Yuexiu Gao",
      "Chen Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09717",
    "title": "Towards an AI-Driven Universal Anti-Jamming Solution with Convolutional  Interference Cancellation Network",
    "abstract": "Wireless links are increasingly used to deliver critical services, while intentional interference (jamming) remains a very serious threat to such services. In this paper, we are concerned with the design and evaluation of a universal anti-jamming building block, that is agnostic to the specifics of the communication link and can therefore be combined with existing technologies. We believe that such a block should not require explicit probes, sounding, training sequences, channel estimation, or even the cooperation of the transmitter. To meet these requirements, we propose an approach that relies on advances in Machine Learning, and the promises of neural accelerators and software defined radios. We identify and address multiple challenges, resulting in a convolutional neural network architecture and models for a multi-antenna system to infer the existence of interference, the number of interfering emissions and their respective phases. This information is continuously fed into an algorithm that cancels the interfering signal. We develop a two-antenna prototype system and evaluate our jamming cancellation approach in various environment settings and modulation schemes using Software Defined Radio platforms. We demonstrate that the receiving node equipped with our approach can detect a jammer with over 99% of accuracy and achieve a Bit Error Rate (BER) as low as $10^{-6}$ even when the jammer power is nearly two orders of magnitude (18 dB) higher than the legitimate signal, and without requiring modifications to the link modulation. In non-adversarial settings, our approach can have other advantages such as detecting and mitigating collisions. ",
    "url": "https://arxiv.org/abs/2203.09717",
    "authors": [
      "Hai N. Nguyen",
      "Guevara Noubir"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09722",
    "title": "DGC-vector: A new speaker embedding for zero-shot voice conversion",
    "abstract": "Recently, more and more zero-shot voice conversion algorithms have been proposed. As a fundamental part of zero-shot voice conversion, speaker embeddings are the key to improving the converted speech's speaker similarity. In this paper, we study the impact of speaker embeddings on zero-shot voice conversion performance. To better represent the characteristics of the target speaker and improve the speaker similarity in zero-shot voice conversion, we propose a novel speaker representation method in this paper. Our method combines the advantages of D-vector, global style token (GST) based speaker representation and auxiliary supervision. Objective and subjective evaluations show that the proposed method achieves a decent performance on zero-shot voice conversion and significantly improves speaker similarity over D-vector and GST-based speaker embedding. ",
    "url": "https://arxiv.org/abs/2203.09722",
    "authors": [
      "Ruitong Xiao",
      "Haitong Zhang",
      "Yue Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.09730",
    "title": "A Dual Weighting Label Assignment Scheme for Object Detection",
    "abstract": "Label assignment (LA), which aims to assign each training sample a positive (pos) and a negative (neg) loss weight, plays an important role in object detection. Existing LA methods mostly focus on the design of pos weighting function, while the neg weight is directly derived from the pos weight. Such a mechanism limits the learning capacity of detectors. In this paper, we explore a new weighting paradigm, termed dual weighting (DW), to specify pos and neg weights separately. We first identify the key influential factors of pos/neg weights by analyzing the evaluation metrics in object detection, and then design the pos and neg weighting functions based on them. Specifically, the pos weight of a sample is determined by the consistency degree between its classification and localization scores, while the neg weight is decomposed into two terms: the probability that it is a neg sample and its importance conditioned on being a neg sample. Such a weighting strategy offers greater flexibility to distinguish between important and less important samples, resulting in a more effective object detector. Equipped with the proposed DW method, a single FCOS-ResNet-50 detector can reach 41.5% mAP on COCO under 1x schedule, outperforming other existing LA methods. It consistently improves the baselines on COCO by a large margin under various backbones without bells and whistles. Code is available at https://github.com/strongwolf/DW. ",
    "url": "https://arxiv.org/abs/2203.09730",
    "authors": [
      "Shuai Li",
      "Chenhang He",
      "Ruihuang Li",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09736",
    "title": "Series Photo Selection via Multi-view Graph Learning",
    "abstract": "Series photo selection (SPS) is an important branch of the image aesthetics quality assessment, which focuses on finding the best one from a series of nearly identical photos. While a great progress has been observed, most of the existing SPS approaches concentrate solely on extracting features from the original image, neglecting that multiple views, e.g, saturation level, color histogram and depth of field of the image, will be of benefit to successfully reflecting the subtle aesthetic changes. Taken multi-view into consideration, we leverage a graph neural network to construct the relationships between multi-view features. Besides, multiple views are aggregated with an adaptive-weight self-attention module to verify the significance of each view. Finally, a siamese network is proposed to select the best one from a series of nearly identical photos. Experimental results demonstrate that our model accomplish the highest success rates compared with competitive methods. ",
    "url": "https://arxiv.org/abs/2203.09736",
    "authors": [
      "Jin Huang",
      "Lu Zhang",
      "Yongshun Gong",
      "Jian Zhang",
      "Xiushan Nie",
      "Yilong Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09739",
    "title": "Do Deep Networks Transfer Invariances Across Classes?",
    "abstract": "To generalize well, classifiers must learn to be invariant to nuisance transformations that do not alter an input's class. Many problems have \"class-agnostic\" nuisance transformations that apply similarly to all classes, such as lighting and background changes for image classification. Neural networks can learn these invariances given sufficient data, but many real-world datasets are heavily class imbalanced and contain only a few examples for most of the classes. We therefore pose the question: how well do neural networks transfer class-agnostic invariances learned from the large classes to the small ones? Through careful experimentation, we observe that invariance to class-agnostic transformations is still heavily dependent on class size, with the networks being much less invariant on smaller classes. This result holds even when using data balancing techniques, and suggests poor invariance transfer across classes. Our results provide one explanation for why classifiers generalize poorly on unbalanced and long-tailed distributions. Based on this analysis, we show how a generative approach for learning the nuisance transformations can help transfer invariances across classes and improve performance on a set of imbalanced image classification benchmarks. Source code for our experiments is available at https://github.com/AllanYangZhou/generative-invariance-transfer. ",
    "url": "https://arxiv.org/abs/2203.09739",
    "authors": [
      "Allan Zhou",
      "Fahim Tajwar",
      "Alexander Robey",
      "Tom Knowles",
      "George J. Pappas",
      "Hamed Hassani",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09756",
    "title": "AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack",
    "abstract": "Deep neural networks (DNNs) have been proven to be vulnerable to adversarial examples. A special branch of adversarial examples, namely sparse adversarial examples, can fool the target DNNs by perturbing only a few pixels. However, many existing sparse adversarial attacks use heuristic methods to select the pixels to be perturbed, and regard the pixel selection and the adversarial attack as two separate steps. From the perspective of neural network pruning, we propose a novel end-to-end sparse adversarial attack method, namely AutoAdversary, which can find the most important pixels automatically by integrating the pixel selection into the adversarial attack. Specifically, our method utilizes a trainable neural network to generate a binary mask for the pixel selection. After jointly optimizing the adversarial perturbation and the neural network, only the pixels corresponding to the value 1 in the mask are perturbed. Experiments demonstrate the superiority of our proposed method over several state-of-the-art methods. Furthermore, since AutoAdversary does not require a heuristic pixel selection process, it does not slow down excessively as other methods when the image size increases. ",
    "url": "https://arxiv.org/abs/2203.09756",
    "authors": [
      "Jinqiao Li",
      "Xiaotao Liu",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09767",
    "title": "Speaker Embedding-aware Neural Diarization: a Novel Framework for  Overlapped Speech Diarization in the Meeting Scenario",
    "abstract": "In this paper, we reformulate overlapped speech diarization as a single-label prediction problem, which is always treated as a multi-label classification task in previous studies. Specifically, the multiple labels of each frame are encoded into a single label with the power set, which represents the possible combinations of different speakers. Through this formulation, we propose the speaker embedding-aware neural diarization (SEND) system. In SEND, the speech encoder, speaker encoder, similarity scores, and post-processing network are optimized to predict the power set encoded labels according to the similarities between speech features and speaker embeddings. Experimental results show that our method significantly outperforms the variational Bayesian hidden Markov model-based clustering algorithm (VBx). Besides, the proposed method has two benefits compared with the target-speaker voice activity detection (TSVAD). First, SEND can achieve lower diarization error rates in the real meeting scenario. Second, when the training data has a high overlap ratio, the learning process of SEND is more stable than TSVAD. ",
    "url": "https://arxiv.org/abs/2203.09767",
    "authors": [
      "Zhihao Du",
      "Shiliang Zhang",
      "Siqi Zheng",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.09780",
    "title": "Sparse Fuse Dense: Towards High Quality 3D Detection with Depth  Completion",
    "abstract": "Current LiDAR-only 3D detection methods inevitably suffer from the sparsity of point clouds. Many multi-modal methods are proposed to alleviate this issue, while different representations of images and point clouds make it difficult to fuse them, resulting in suboptimal performance. In this paper, we present a novel multi-modal framework SFD (Sparse Fuse Dense), which utilizes pseudo point clouds generated from depth completion to tackle the issues mentioned above. Different from prior works, we propose a new RoI fusion strategy 3D-GAF (3D Grid-wise Attentive Fusion) to make fuller use of information from different types of point clouds. Specifically, 3D-GAF fuses 3D RoI features from the couple of point clouds in a grid-wise attentive way, which is more fine-grained and more precise. In addition, we propose a SynAugment (Synchronized Augmentation) to enable our multi-modal framework to utilize all data augmentation approaches tailored to LiDAR-only methods. Lastly, we customize an effective and efficient feature extractor CPConv (Color Point Convolution) for pseudo point clouds. It can explore 2D image features and 3D geometric features of pseudo point clouds simultaneously. Our method holds the highest entry on the KITTI car 3D object detection leaderboard, demonstrating the effectiveness of our SFD. Code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2203.09780",
    "authors": [
      "Xiaopei Wu",
      "Liang Peng",
      "Honghui Yang",
      "Liang Xie",
      "Chenxi Huang",
      "Chengqi Deng",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09790",
    "title": "Towards Robust 2D Convolution for Reliable Visual Recognition",
    "abstract": "2D convolution (Conv2d), which is responsible for extracting features from the input image, is one of the key modules of a convolutional neural network (CNN). However, Conv2d is vulnerable to image corruptions and adversarial samples. It is an important yet rarely investigated problem that whether we can design a more robust alternative of Conv2d for more reliable feature extraction. In this paper, inspired by the recently developed learnable sparse transform that learns to convert the CNN features into a compact and sparse latent space, we design a novel building block, denoted by RConv-MK, to strengthen the robustness of extracted convolutional features. Our method leverages a set of learnable kernels of different sizes to extract features at different frequencies and employs a normalized soft thresholding operator to adaptively remove noises and trivial features at different corruption levels. Extensive experiments on clean images, corrupted images as well as adversarial samples validate the effectiveness of the proposed robust module for reliable visual recognition. The source codes are enclosed in the submission. ",
    "url": "https://arxiv.org/abs/2203.09790",
    "authors": [
      "Lida Li",
      "Shuai Li",
      "Kun Wang",
      "Xiangchu Feng",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09792",
    "title": "AdIoTack: Quantifying and Refining Resilience of Decision Tree Ensemble  Inference Models against Adversarial Volumetric Attacks on IoT Networks",
    "abstract": "Machine Learning-based techniques have shown success in cyber intelligence. However, they are increasingly becoming targets of sophisticated data-driven adversarial attacks resulting in misprediction, eroding their ability to detect threats on network devices. In this paper, we present AdIoTack, a system that highlights vulnerabilities of decision trees against adversarial attacks, helping cybersecurity teams quantify and refine the resilience of their trained models for monitoring IoT networks. To assess the model for the worst-case scenario, AdIoTack performs white-box adversarial learning to launch successful volumetric attacks that decision tree ensemble models cannot flag. Our first contribution is to develop a white-box algorithm that takes a trained decision tree ensemble model and the profile of an intended network-based attack on a victim class as inputs. It then automatically generates recipes that specify certain packets on top of the indented attack packets (less than 15% overhead) that together can bypass the inference model unnoticed. We ensure that the generated attack instances are feasible for launching on IP networks and effective in their volumetric impact. Our second contribution develops a method to monitor the network behavior of connected devices actively, inject adversarial traffic (when feasible) on behalf of a victim IoT device, and successfully launch the intended attack. Our third contribution prototypes AdIoTack and validates its efficacy on a testbed consisting of a handful of real IoT devices monitored by a trained inference model. We demonstrate how the model detects all non-adversarial volumetric attacks on IoT devices while missing many adversarial ones. The fourth contribution develops systematic methods for applying patches to trained decision tree ensemble models, improving their resilience against adversarial volumetric attacks. ",
    "url": "https://arxiv.org/abs/2203.09792",
    "authors": [
      "Arman Pashamokhtari",
      "Gustavo Batista",
      "Hassan Habibi Gharakheili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.09811",
    "title": "Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased  Scene Graph Generation",
    "abstract": "Scene Graph Generation, which generally follows a regular encoder-decoder pipeline, aims to first encode the visual contents within the given image and then parse them into a compact summary graph. Existing SGG approaches generally not only neglect the insufficient modality fusion between vision and language, but also fail to provide informative predicates due to the biased relationship predictions, leading SGG far from practical. Towards this end, in this paper, we first present a novel Stacked Hybrid-Attention network, which facilitates the intra-modal refinement as well as the inter-modal interaction, to serve as the encoder. We then devise an innovative Group Collaborative Learning strategy to optimize the decoder. Particularly, based upon the observation that the recognition capability of one classifier is limited towards an extremely unbalanced dataset, we first deploy a group of classifiers that are expert in distinguishing different subsets of classes, and then cooperatively optimize them from two aspects to promote the unbiased SGG. Experiments conducted on VG and GQA datasets demonstrate that, we not only establish a new state-of-the-art in the unbiased metric, but also nearly double the performance compared with two baselines. ",
    "url": "https://arxiv.org/abs/2203.09811",
    "authors": [
      "Xingning Dong",
      "Tian Gan",
      "Xuemeng Song",
      "Jianlong Wu",
      "Yuan Cheng",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09813",
    "title": "Are You Robert or RoBERTa? Deceiving Online Authorship Attribution  Models Using Neural Text Generators",
    "abstract": "Recently, there has been a rise in the development of powerful pre-trained natural language models, including GPT-2, Grover, and XLM. These models have shown state-of-the-art capabilities towards a variety of different NLP tasks, including question answering, content summarisation, and text generation. Alongside this, there have been many studies focused on online authorship attribution (AA). That is, the use of models to identify the authors of online texts. Given the power of natural language models in generating convincing texts, this paper examines the degree to which these language models can generate texts capable of deceiving online AA models. Experimenting with both blog and Twitter data, we utilise GPT-2 language models to generate texts using the existing posts of online users. We then examine whether these AI-based text generators are capable of mimicking authorial style to such a degree that they can deceive typical AA models. From this, we find that current AI-based text generators are able to successfully mimic authorship, showing capabilities towards this on both datasets. Our findings, in turn, highlight the current capacity of powerful natural language models to generate original online posts capable of mimicking authorial style sufficiently to deceive popular AA methods; a key finding given the proposed role of AA in real world applications such as spam-detection and forensic investigation. ",
    "url": "https://arxiv.org/abs/2203.09813",
    "authors": [
      "Keenan Jones",
      "Jason R. C. Nurse",
      "Shujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09829",
    "title": "Towards Representative Subset Selection for Self-Supervised Speech  Recognition",
    "abstract": "Self-supervised speech recognition models require considerable labeled training data for learning high-fidelity representations for Automatic Speech Recognition (ASR), which hinders their application to low-resource languages. We consider the task of identifying an optimal subset of training data to fine-tune self-supervised speech models for ASR. We make a surprising observation that active learning strategies for sampling harder-to-learn examples do not perform better than random subset selection for fine-tuning self-supervised ASR. We then present the COWERAGE algorithm for better subset selection in self-supervised ASR which is based on our finding that ensuring the coverage of examples based on training WER in the early training epochs leads to better generalization performance. Extensive experiments on the wav2vec 2.0 model and TIMIT dataset show the effectiveness of COWERAGE, with up to 27% absolute WER improvement over active learning methods. We also report the connection between training WER and the phonemic cover and demonstrate that our algorithm ensures inclusion of phonemically diverse examples. ",
    "url": "https://arxiv.org/abs/2203.09829",
    "authors": [
      "Abdul Hameed Azeemi",
      "Ihsan Ayyub Qazi",
      "Agha Ali Raza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.09830",
    "title": "Laneformer: Object-aware Row-Column Transformers for Lane Detection",
    "abstract": "We present Laneformer, a conceptually simple yet powerful transformer-based architecture tailored for lane detection that is a long-standing research topic for visual perception in autonomous driving. The dominant paradigms rely on purely CNN-based architectures which often fail in incorporating relations of long-range lane points and global contexts induced by surrounding objects (e.g., pedestrians, vehicles). Inspired by recent advances of the transformer encoder-decoder architecture in various vision tasks, we move forwards to design a new end-to-end Laneformer architecture that revolutionizes the conventional transformers into better capturing the shape and semantic characteristics of lanes, with minimal overhead in latency. First, coupling with deformable pixel-wise self-attention in the encoder, Laneformer presents two new row and column self-attention operations to efficiently mine point context along with the lane shapes. Second, motivated by the appearing objects would affect the decision of predicting lane segments, Laneformer further includes the detected object instances as extra inputs of multi-head attention blocks in the encoder and decoder to facilitate the lane point detection by sensing semantic contexts. Specifically, the bounding box locations of objects are added into Key module to provide interaction with each pixel and query while the ROI-aligned features are inserted into Value module. Extensive experiments demonstrate our Laneformer achieves state-of-the-art performances on CULane benchmark, in terms of 77.1% F1 score. We hope our simple and effective Laneformer will serve as a strong baseline for future research in self-attention models for lane detection. ",
    "url": "https://arxiv.org/abs/2203.09830",
    "authors": [
      "Jianhua Han",
      "Xiajun Deng",
      "Xinyue Cai",
      "Zhen Yang",
      "Hang Xu",
      "Chunjing Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09831",
    "title": "DTA: Physical Camouflage Attacks using Differentiable Transformation  Network",
    "abstract": "To perform adversarial attacks in the physical world, many studies have proposed adversarial camouflage, a method to hide a target object by applying camouflage patterns on 3D object surfaces. For obtaining optimal physical adversarial camouflage, previous studies have utilized the so-called neural renderer, as it supports differentiability. However, existing neural renderers cannot fully represent various real-world transformations due to a lack of control of scene parameters compared to the legacy photo-realistic renderers. In this paper, we propose the Differentiable Transformation Attack (DTA), a framework for generating a robust physical adversarial pattern on a target object to camouflage it against object detection models with a wide range of transformations. It utilizes our novel Differentiable Transformation Network (DTN), which learns the expected transformation of a rendered object when the texture is changed while preserving the original properties of the target object. Using our attack framework, an adversary can gain both the advantages of the legacy photo-realistic renderers including various physical-world transformations and the benefit of white-box access by offering differentiability. Our experiments show that our camouflaged 3D vehicles can successfully evade state-of-the-art object detection models in the photo-realistic environment (i.e., CARLA on Unreal Engine). Furthermore, our demonstration on a scaled Tesla Model 3 proves the applicability and transferability of our method to the real world. ",
    "url": "https://arxiv.org/abs/2203.09831",
    "authors": [
      "Naufal Suryanto",
      "Yongsu Kim",
      "Hyoeun Kang",
      "Harashta Tatimma Larasati",
      "Youngyeo Yun",
      "Thi-Thu-Huong Le",
      "Hunmin Yang",
      "Se-Yoon Oh",
      "Howon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09845",
    "title": "Location-Free Camouflage Generation Network",
    "abstract": "Camouflage is a common visual phenomenon, which refers to hiding the foreground objects into the background images, making them briefly invisible to the human eye. Previous work has typically been implemented by an iterative optimization process. However, these methods struggle in 1) efficiently generating camouflage images using foreground and background with arbitrary structure; 2) camouflaging foreground objects to regions with multiple appearances (e.g. the junction of the vegetation and the mountains), which limit their practical application. To address these problems, this paper proposes a novel Location-free Camouflage Generation Network (LCG-Net) that fuse high-level features of foreground and background image, and generate result by one inference. Specifically, a Position-aligned Structure Fusion (PSF) module is devised to guide structure feature fusion based on the point-to-point structure similarity of foreground and background, and introduce local appearance features point-by-point. To retain the necessary identifiable features, a new immerse loss is adopted under our pipeline, while a background patch appearance loss is utilized to ensure that the hidden objects look continuous and natural at regions with multiple appearances. Experiments show that our method has results as satisfactory as state-of-the-art in the single-appearance regions and are less likely to be completely invisible, but far exceed the quality of the state-of-the-art in the multi-appearance regions. Moreover, our method is hundreds of times faster than previous methods. Benefitting from the unique advantages of our method, we provide some downstream applications for camouflage generation, which show its potential. The related code and dataset will be released at https://github.com/Tale17/LCG-Net. ",
    "url": "https://arxiv.org/abs/2203.09845",
    "authors": [
      "Yangyang Li",
      "Wei Zhai",
      "Yang Cao",
      "Zheng-jun Zha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09849",
    "title": "Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition",
    "abstract": "Recent works have revealed the vulnerability of automatic speech recognition (ASR) models to adversarial examples (AEs), i.e., small perturbations that cause an error in the transcription of the audio signal. Studying audio adversarial attacks is therefore the first step towards robust ASR. Despite the significant progress made in attacking audio examples, the black-box attack remains challenging because only the hard-label information of transcriptions is provided. Due to this limited information, existing black-box methods often require an excessive number of queries to attack a single audio example. In this paper, we introduce NP-Attack, a neural predictor-based method, which progressively evolves the search towards a small adversarial perturbation. Given a perturbation direction, our neural predictor directly estimates the smallest perturbation that causes a mistranscription. In particular, it enables NP-Attack to accurately learn promising perturbation directions via gradient-based optimization. Experimental results show that NP-Attack achieves competitive results with other state-of-the-art black-box adversarial attacks while requiring a significantly smaller number of queries. The code of NP-Attack is available online. ",
    "url": "https://arxiv.org/abs/2203.09849",
    "authors": [
      "Marie Biolkov\u00e1",
      "Bac Nguyen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.09888",
    "title": "Hypergraph Modeling via Spectral Embedding Connection: Hypergraph Cut,  Weighted Kernel $k$-means, and Heat Kernel",
    "abstract": "We propose a theoretical framework of multi-way similarity to model real-valued data into hypergraphs for clustering via spectral embedding. For graph cut based spectral clustering, it is common to model real-valued data into graph by modeling pairwise similarities using kernel function. This is because the kernel function has a theoretical connection to the graph cut. For problems where using multi-way similarities are more suitable than pairwise ones, it is natural to model as a hypergraph, which is generalization of a graph. However, although the hypergraph cut is well-studied, there is not yet established a hypergraph cut based framework to model multi-way similarity. In this paper, we formulate multi-way similarities by exploiting the theoretical foundation of kernel function. We show a theoretical connection between our formulation and hypergraph cut in two ways, generalizing both weighted kernel $k$-means and the heat kernel, by which we justify our formulation. We also provide a fast algorithm for spectral clustering. Our algorithm empirically shows better performance than existing graph and other heuristic modeling methods. ",
    "url": "https://arxiv.org/abs/2203.09888",
    "authors": [
      "Shota Saito"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.09910",
    "title": "Fourier Document Restoration for Robust Document Dewarping and  Recognition",
    "abstract": "State-of-the-art document dewarping techniques learn to predict 3-dimensional information of documents which are prone to errors while dealing with documents with irregular distortions or large variations in depth. This paper presents FDRNet, a Fourier Document Restoration Network that can restore documents with different distortions and improve document recognition in a reliable and simpler manner. FDRNet focuses on high-frequency components in the Fourier space that capture most structural information but are largely free of degradation in appearance. It dewarps documents by a flexible Thin-Plate Spline transformation which can handle various deformations effectively without requiring deformation annotations in training. These features allow FDRNet to learn from a small amount of simply labeled training images, and the learned model can dewarp documents with complex geometric distortion and recognize the restored texts accurately. To facilitate document restoration research, we create a benchmark dataset consisting of over one thousand camera documents with different types of geometric and photometric distortion. Extensive experiments show that FDRNet outperforms the state-of-the-art by large margins on both dewarping and text recognition tasks. In addition, FDRNet requires a small amount of simply labeled training data and is easy to deploy. ",
    "url": "https://arxiv.org/abs/2203.09910",
    "authors": [
      "Chuhui Xue",
      "Zichen Tian",
      "Fangneng Zhan",
      "Shijian Lu",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09913",
    "title": "Convolutional Simultaneous Sparse Approximation with Applications to  RGB-NIR Image Fusion",
    "abstract": "Simultaneous sparse approximation (SSA) seeks to represent a set of dependent signals using sparse vectors with identical supports. The SSA model has been used in various signal and image processing applications involving multiple correlated input signals. In this paper, we propose algorithms for convolutional SSA (CSSA) based on the alternating direction method of multipliers. Specifically, we address the CSSA problem with different sparsity structures and the convolutional feature learning problem in multimodal data/signals based on the SSA model. We evaluate the proposed algorithms by applying them to multimodal and multifocus image fusion problems. ",
    "url": "https://arxiv.org/abs/2203.09913",
    "authors": [
      "Farshad G. Veshki",
      "Sergiy A. Vorobyov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09936",
    "title": "Fake News Detection Using Majority Voting Technique",
    "abstract": "Due to the evolution of the Web and social network platforms it becomes very easy to disseminate the information. Peoples are creating and sharing more information than ever before, which may be misleading, misinformation or fake information. Fake news detection is a crucial and challenging task due to the unstructured nature of the available information. In the recent years, researchers have provided significant solutions to tackle with the problem of fake news detection, but due to its nature there are still many open issues. In this paper, we have proposed majority voting approach to detect fake news articles. We have used different textual properties of fake and real news. We have used publicly available fake news dataset, comprising of 20,800 news articles among which 10,387 are real and 10,413 are fake news labeled as binary 0 and 1. For the evaluation of our approach, we have used commonly used machine learning classifiers like, Decision Tree, Logistic Regression, XGBoost, Random Forest, Extra Trees, AdaBoost, SVM, SGD and Naive Bayes. Using the aforementioned classifiers, we built a multi-model fake news detection system using Majority Voting technique to achieve the more accurate results. The experimental results show that, our proposed approach achieved accuracy of 96.38%, precision of 96%, recall of 96% and F1-measure of 96%. The evaluation confirms that, Majority Voting technique achieved more acceptable results as compare to individual learning technique. ",
    "url": "https://arxiv.org/abs/2203.09936",
    "authors": [
      "Dharmaraj R. Patil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.09937",
    "title": "On the sensitivity of pose estimation neural networks: rotation  parameterizations, Lipschitz constants, and provable bounds",
    "abstract": "In this paper, we approach the task of determining sensitivity bounds for pose estimation neural networks. This task is particularly challenging as it requires characterizing the sensitivity of 3D rotations. We develop a sensitivity measure that describes the maximum rotational change in a network's output with respect to a Euclidean change in its input. We show that this measure is a type of Lipschitz constant, and that it is bounded by the product of a network's Euclidean Lipschitz constant and an intrinsic property of a rotation parameterization which we call the \"distance ratio constant\". We derive the distance ratio constant for several rotation parameterizations, and then discuss why the structure of most of these parameterizations makes it difficult to construct a pose estimation network with provable sensitivity bounds. However, we show that sensitivity bounds can be computed for networks which parameterize rotation using unconstrained exponential coordinates. We then construct and train such a network and compute sensitivity bounds for it. ",
    "url": "https://arxiv.org/abs/2203.09937",
    "authors": [
      "Trevor Avant",
      "Kristi A. Morgansen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09938",
    "title": "A Comparison of Static, Dynamic, and Hybrid Analysis for Malware  Detection",
    "abstract": "In this research, we compare malware detection techniques based on static, dynamic, and hybrid analysis. Specifically, we train Hidden Markov Models (HMMs ) on both static and dynamic feature sets and compare the resulting detection rates over a substantial number of malware families. We also consider hybrid cases, where dynamic analysis is used in the training phase, with static techniques used in the detection phase, and vice versa. In our experiments, a fully dynamic approach generally yields the best detection rates. We discuss the implications of this research for malware detection based on hybrid techniques. ",
    "url": "https://arxiv.org/abs/2203.09938",
    "authors": [
      "Anusha Damodaran",
      "Fabio Di Troia",
      "Visaggio Aaron Corrado",
      "Thomas H. Austin",
      "Mark Stamp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09940",
    "title": "Defending Variational Autoencoders from Adversarial Attacks with MCMC",
    "abstract": "Variational autoencoders (VAEs) are deep generative models used in various domains. VAEs can generate complex objects and provide meaningful latent representations, which can be further used in downstream tasks such as classification. As previous work has shown, one can easily fool VAEs to produce unexpected latent representations and reconstructions for a visually slightly modified input. Here, we examine several objective functions for adversarial attacks construction, suggest metrics assess the model robustness, and propose a solution to alleviate the effect of an attack. Our method utilizes the Markov Chain Monte Carlo (MCMC) technique in the inference step and is motivated by our theoretical analysis. Thus, we do not incorporate any additional costs during training or we do not decrease the performance on non-attacked inputs. We validate our approach on a variety of datasets (MNIST, Fashion MNIST, Color MNIST, CelebA) and VAE configurations ($\\beta$-VAE, NVAE, TC-VAE) and show that it consistently improves the model robustness to adversarial attacks. ",
    "url": "https://arxiv.org/abs/2203.09940",
    "authors": [
      "Anna Kuzina",
      "Max Welling",
      "Jakub M. Tomczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09948",
    "title": "Neural Enhanced Belief Propagation for Data Assocation in Multiobject  Tracking",
    "abstract": "Situation-aware technologies enabled by multiobject tracking (MOT) methods will create new services and applications in fields such as autonomous navigation and applied ocean sciences. Belief propagation (BP) is a state-of-the-art method for Bayesian MOT but fully relies on a statistical model and preprocessed sensor measurements. In this paper, we establish a hybrid method for model-based and data-driven MOT. The proposed neural enhanced belief propagation (NEBP) approach complements BP by information learned from raw sensor data with the goal to improve data association and to reject false alarm measurements. We evaluate the performance of our NEBP approach for MOT on the nuScenes autonomous driving dataset and demonstrate that it can outperform state-of-the-art reference methods. ",
    "url": "https://arxiv.org/abs/2203.09948",
    "authors": [
      "Mingchao Liang",
      "Florian Meyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.09952",
    "title": "Conquering Ghosts: Relation Learning for Information Reliability  Representation and End-to-End Robust Navigation",
    "abstract": "Environmental disturbances, such as sensor data noises, various lighting conditions, challenging weathers and external adversarial perturbations, are inevitable in real self-driving applications. Existing researches and testings have shown that they can severely influence the vehicles perception ability and performance, one of the main issue is the false positive detection, i.e., the ghost object which is not real existed or occurs in the wrong position (such as a non-existent vehicle). Traditional navigation methods tend to avoid every detected objects for safety, however, avoiding a ghost object may lead the vehicle into a even more dangerous situation, such as a sudden break on the highway. Considering the various disturbance types, it is difficult to address this issue at the perceptual aspect. A potential solution is to detect the ghost through relation learning among the whole scenario and develop an integrated end-to-end navigation system. Our underlying logic is that the behavior of all vehicles in the scene is influenced by their neighbors, and normal vehicles behave in a logical way, while ghost vehicles do not. By learning the spatio-temporal relation among surrounding vehicles, an information reliability representation is learned for each detected vehicle and then a robot navigation network is developed. In contrast to existing works, we encourage the network to learn how to represent the reliability and how to aggregate all the information with uncertainties by itself, thus increasing the efficiency and generalizability. To the best of the authors knowledge, this paper provides the first work on using graph relation learning to achieve end-to-end robust navigation in the presence of ghost vehicles. Simulation results in the CARLA platform demonstrate the feasibility and effectiveness of the proposed method in various scenarios. ",
    "url": "https://arxiv.org/abs/2203.09952",
    "authors": [
      "Kefan Jin",
      "Xingyao Han"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09960",
    "title": "Improving Semantic Consistency of Variable Names with Use-Flow Graph  Analysis",
    "abstract": "Consistency is one of the keys to maintainable source code and hence a successful software project. We propose a novel method of extracting the intent of programmers from source code of a large project (~300kLOC) and checking the semantic consistency of its variable names. Our system learns a project-specific naming convention for variables based on its role solely from source code, and suggest alternatives when it violates its internal consistency. The system can also show the reasoning why a certain variable should be named in a specific way. The system does not rely on any external knowledge. We applied our method to 12 open-source projects and evaluated its results with human reviewers. Our system proposed alternative variable names for 416 out of 1080 (39%) instances that are considered better than ones originally used by the developers. Based on the results, we created patches to correct the inconsistent names and sent them to its developers. Three open-source projects adopted it. ",
    "url": "https://arxiv.org/abs/2203.09960",
    "authors": [
      "Yusuke Shinyama",
      "Yoshitaka Arahori",
      "Katsuhiko Gondow"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2203.09961",
    "title": "Personalized filled-pause generation with group-wise prediction models",
    "abstract": "In this paper, we propose a method to generate personalized filled pauses (FPs) with group-wise prediction models. Compared with fluent text generation, disfluent text generation has not been widely explored. To generate more human-like texts, we addressed disfluent text generation. The usage of disfluency, such as FPs, rephrases, and word fragments, differs from speaker to speaker, and thus, the generation of personalized FPs is required. However, it is difficult to predict them because of the sparsity of position and the frequency difference between more and less frequently used FPs. Moreover, it is sometimes difficult to adapt FP prediction models to each speaker because of the large variation of the tendency within each speaker. To address these issues, we propose a method to build group-dependent prediction models by grouping speakers on the basis of their tendency to use FPs. This method does not require a large amount of data and time to train each speaker model. We further introduce a loss function and a word embedding model suitable for FP prediction. Our experimental results demonstrate that group-dependent models can predict FPs with higher scores than a non-personalized one and the introduced loss function and word embedding model improve the prediction performance. ",
    "url": "https://arxiv.org/abs/2203.09961",
    "authors": [
      "Yuta Matsunaga",
      "Takaaki Saeki",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2203.09962",
    "title": "SS-SAM : Stochastic Scheduled Sharpness-Aware Minimization for  Efficiently Training Deep Neural Networks",
    "abstract": "By driving optimizers to converge to flat minima, sharpness-aware minimization (SAM) has shown the power to improve the model generalization. However, SAM requires to perform two forward-backward propagations for one parameter update, which largely burdens the practical computation. In this paper, we propose a novel and efficient training scheme, called Stochastic Scheduled SAM (SS-SAM). Specifically, in SS-SAM, the optimizer is arranged by a predefined scheduling function to perform a random trial at each update step, which would randomly select to perform the SGD optimization or the SAM optimization. In this way, the overall count of propagation pair could be largely reduced. Then, we empirically investigate four typical types of scheduling functions, and demonstrates the computational efficiency and their impact on model performance respectively. We show that with proper scheduling functions, models could be trained to achieve comparable or even better performance with much lower computation cost compared to models trained with only SAM training scheme. ",
    "url": "https://arxiv.org/abs/2203.09962",
    "authors": [
      "Yang Zhao",
      "Hao Zhang",
      "Xiuyuan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09969",
    "title": "Intro-Stabilizing Byzantine Clock Synchronization in Heterogeneous IoT  Networks",
    "abstract": "For reaching dependable high-precision clock synchronization (CS) upon IoT networks, the distributed CS paradigm adopted in ultra-high reliable systems and the master-slave CS paradigm adopted in high-performance but unreliable systems are integrated. Meanwhile, traditional internal clock synchronization is also integrated with external time references to achieve efficient stabilization. Low network connectivity, low complexity, high precision, and high reliability are all considered. To tolerate permanent failures, the Byzantine CS is integrated with the common CS protocols. To tolerate transient failures, the self-stabilizing Byzantine CS is also extended upon open-world IoT networks. With these, the proposed intro-stabilizing Byzantine CS solution can establish and maintain synchronization with arbitrary initial states in the presence of permanent Byzantine faults. With the formal analysis and numerical simulations, it is shown that the best of the CS solutions provided for the ultra-high reliable systems and the high-performance unreliable systems can be well integrated upon IoT networks to derive dependable high-precision CS even across the traditional closed safety-boundary. ",
    "url": "https://arxiv.org/abs/2203.09969",
    "authors": [
      "Shaolin Yu",
      "Jihong Zhu",
      "Jiali Yang",
      "Wei Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2203.09975",
    "title": "BIOS: An Algorithmically Generated Biomedical Knowledge Graph",
    "abstract": "Biomedical knowledge graphs (BioMedKGs) are essential infrastructures for biomedical and healthcare big data and artificial intelligence (AI), facilitating natural language processing, model development, and data exchange. For many decades, these knowledge graphs have been built via expert curation, which can no longer catch up with the speed of today's AI development, and a transition to algorithmically generated BioMedKGs is necessary. In this work, we introduce the Biomedical Informatics Ontology System (BIOS), the first large scale publicly available BioMedKG that is fully generated by machine learning algorithms. BIOS currently contains 4.1 million concepts, 7.4 million terms in two languages, and 7.3 million relation triplets. We introduce the methodology for developing BIOS, which covers curation of raw biomedical terms, computationally identifying synonymous terms and aggregating them to create concept nodes, semantic type classification of the concepts, relation identification, and biomedical machine translation. We provide statistics about the current content of BIOS and perform preliminary assessment for term quality, synonym grouping, and relation extraction. Results suggest that machine learning-based BioMedKG development is a totally viable solution for replacing traditional expert curation. ",
    "url": "https://arxiv.org/abs/2203.09975",
    "authors": [
      "Sheng Yu",
      "Zheng Yuan",
      "Jun Xia",
      "Shengxuan Luo",
      "Huaiyuan Ying",
      "Sihang Zeng",
      "Jingyi Ren",
      "Hongyi Yuan",
      "Zhengyun Zhao",
      "Yucong Lin",
      "Keming Lu",
      "Jing Wang",
      "Yutao Xie",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.09994",
    "title": "Graph-Text Multi-Modal Pre-training for Medical Representation Learning",
    "abstract": "As the volume of Electronic Health Records (EHR) sharply grows, there has been emerging interest in learning the representation of EHR for healthcare applications. Representation learning of EHR requires appropriate modeling of the two dominant modalities in EHR: structured data and unstructured text. In this paper, we present MedGTX, a pre-trained model for multi-modal representation learning of the structured and textual EHR data. MedGTX uses a novel graph encoder to exploit the graphical nature of structured EHR data, and a text encoder to handle unstructured text, and a cross-modal encoder to learn a joint representation space. We pre-train our model through four proxy tasks on MIMIC-III, an open-source EHR data, and evaluate our model on two clinical benchmarks and three novel downstream tasks which tackle real-world problems in EHR data. The results consistently show the effectiveness of pre-training the model for joint representation of both structured and unstructured information from EHR. Given the promising performance of MedGTX, we believe this work opens a new door to jointly understanding the two fundamental modalities of EHR data. ",
    "url": "https://arxiv.org/abs/2203.09994",
    "authors": [
      "Sungjin Park",
      "Seongsu Bae",
      "Jiho Kim",
      "Tackeun Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10006",
    "title": "Ultra-low Latency Spiking Neural Networks with Spatio-Temporal  Compression and Synaptic Convolutional Block",
    "abstract": "Spiking neural networks (SNNs), as one of the brain-inspired models, has spatio-temporal information processing capability, low power feature, and high biological plausibility. The effective spatio-temporal feature makes it suitable for event streams classification. However, neuromorphic datasets, such as N-MNIST, CIFAR10-DVS, DVS128-gesture, need to aggregate individual events into frames with a new higher temporal resolution for event stream classification, which causes high training and inference latency. In this work, we proposed a spatio-temporal compression method to aggregate individual events into a few time steps of synaptic current to reduce the training and inference latency. To keep the accuracy of SNNs under high compression ratios, we also proposed a synaptic convolutional block to balance the dramatic change between adjacent time steps. And multi-threshold Leaky Integrate-and-Fire (LIF) with learnable membrane time constant is introduced to increase its information processing capability. We evaluate the proposed method for event streams classification tasks on neuromorphic N-MNIST, CIFAR10-DVS, DVS128 gesture datasets. The experiment results show that our proposed method outperforms the state-of-the-art accuracy on nearly all datasets, using fewer time steps. ",
    "url": "https://arxiv.org/abs/2203.10006",
    "authors": [
      "Changqing Xu",
      "Yi Liu",
      "Yintang Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10024",
    "title": "Offensive Language Detection in Under-resourced Algerian Dialectal  Arabic Language",
    "abstract": "This paper addresses the problem of detecting the offensive and abusive content in Facebook comments, where we focus on the Algerian dialectal Arabic which is one of under-resourced languages. The latter has a variety of dialects mixed with different languages (i.e. Berber, French and English). In addition, we deal with texts written in both Arabic and Roman scripts (i.e. Arabizi). Due to the scarcity of works on the same language, we have built a new corpus regrouping more than 8.7k texts manually annotated as normal, abusive and offensive. We have conducted a series of experiments using the state-of-the-art classifiers of text categorisation, namely: BiLSTM, CNN, FastText, SVM and NB. The results showed acceptable performances, but the problem requires further investigation on linguistic features to increase the identification accuracy. ",
    "url": "https://arxiv.org/abs/2203.10024",
    "authors": [
      "Oussama Boucherit",
      "Kheireddine Abainia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2203.10030",
    "title": "Nonnegative-Constrained Joint Collaborative Representation with Union  Dictionary for Hyperspectral Anomaly Detection",
    "abstract": "Recently, many collaborative representation-based (CR) algorithms have been proposed for hyperspectral anomaly detection. CR-based detectors approximate the image by a linear combination of background dictionaries and the coefficient matrix, and derive the detection map by utilizing recovery residuals. However, these CR-based detectors are often established on the premise of precise background features and strong image representation, which are very difficult to obtain. In addition, pursuing the coefficient matrix reinforced by the general $l_2$-min is very time consuming. To address these issues, a nonnegative-constrained joint collaborative representation model is proposed in this paper for the hyperspectral anomaly detection task. To extract reliable samples, a union dictionary consisting of background and anomaly sub-dictionaries is designed, where the background sub-dictionary is obtained at the superpixel level and the anomaly sub-dictionary is extracted by the pre-detection process. And the coefficient matrix is jointly optimized by the Frobenius norm regularization with a nonnegative constraint and a sum-to-one constraint. After the optimization process, the abnormal information is finally derived by calculating the residuals that exclude the assumed background information. To conduct comparable experiments, the proposed nonnegative-constrained joint collaborative representation (NJCR) model and its kernel version (KNJCR) are tested in four HSI data sets and achieve superior results compared with other state-of-the-art detectors. ",
    "url": "https://arxiv.org/abs/2203.10030",
    "authors": [
      "Shizhen Chang",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10050",
    "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for  Feedback-efficient Preference-based Reinforcement Learning",
    "abstract": "Preference-based reinforcement learning (RL) has shown potential for teaching agents to perform the target tasks without a costly, pre-defined reward function by learning the reward with a supervisor's preference between the two agent behaviors. However, preference-based learning often requires a large amount of human feedback, making it difficult to apply this approach to various applications. This data-efficiency problem, on the other hand, has been typically addressed by using unlabeled samples or data augmentation techniques in the context of supervised learning. Motivated by the recent success of these approaches, we present SURF, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation. In order to leverage unlabeled samples for reward learning, we infer pseudo-labels of the unlabeled samples based on the confidence of the preference predictor. To further improve the label-efficiency of reward learning, we introduce a new data augmentation that temporally crops consecutive subsequences from the original behaviors. Our experiments demonstrate that our approach significantly improves the feedback-efficiency of the state-of-the-art preference-based method on a variety of locomotion and robotic manipulation tasks. ",
    "url": "https://arxiv.org/abs/2203.10050",
    "authors": [
      "Jongjin Park",
      "Younggyo Seo",
      "Jinwoo Shin",
      "Honglak Lee",
      "Pieter Abbeel",
      "Kimin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.09518",
    "title": "Privacy-Preserving Speech Representation Learning using Vector  Quantization",
    "abstract": "With the popularity of virtual assistants (e.g., Siri, Alexa), the use of speech recognition is now becoming more and more widespread.However, speech signals contain a lot of sensitive information, such as the speaker's identity, which raises privacy concerns.The presented experiments show that the representations extracted by the deep layers of speech recognition networks contain speaker information.This paper aims to produce an anonymous representation while preserving speech recognition performance.To this end, we propose to use vector quantization to constrain the representation space and induce the network to suppress the speaker identity.The choice of the quantization dictionary size allows to configure the trade-off between utility (speech recognition) and privacy (speaker identity concealment). ",
    "url": "https://arxiv.org/abs/2203.09518",
    "authors": [
      "Pierre Champion",
      "Denis Jouvet",
      "Anthony Larcher"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2203.09546",
    "title": "Parity-time symmetric optical neural networks",
    "abstract": "Optical neural networks (ONNs), implemented on an array of cascaded Mach-Zehnder interferometers (MZIs), have recently been proposed as a possible replacement for conventional deep learning hardware. They potentially offer higher energy efficiency and computational speed when compared to their electronic counterparts. By utilizing tunable phase shifters, one can adjust the output of each of MZIs in order to enable emulation of arbitrary matrix-vector multiplication. These phase shifters are central to the programmability of ONNs, but they require large footprint and are relatively slow. Here we propose an ONN architecture that utilizes parity-time (PT) symmetric couplers as its building blocks. Instead of modulating phase, gain/loss contrasts across the array are adjusted as a means to train the network. We demonstrate that PT symmetric optical neural networks (PT-ONN) are adequately expressive by performing the digit-recognition task on the modified national institute of standard and technology (MNIST) dataset. Compared to conventional ONNs, the PT-ONN achieves a comparable accuracy (67% vs. 71%) while circumventing the problems associated with changing phase. Our approach may lead to new and alternative avenues for fast training in chip-scale optical neural networks. ",
    "url": "https://arxiv.org/abs/2203.09546",
    "authors": [
      "Haoqin Deng",
      "Mercedeh Khajavikhan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2203.09724",
    "title": "Rethinking the optimization process for self-supervised model-driven MRI  reconstruction",
    "abstract": "Recovering high-quality images from undersampled measurements is critical for accelerated MRI reconstruction. Recently, various supervised deep learning-based MRI reconstruction methods have been developed. Despite the achieved promising performances, these methods require fully sampled reference data, the acquisition of which is resource-intensive and time-consuming. Self-supervised learning has emerged as a promising solution to alleviate the reliance on fully sampled datasets. However, existing self-supervised methods suffer from reconstruction errors due to the insufficient constraint enforced on the non-sampled data points and the error accumulation happened alongside the iterative image reconstruction process for model-driven deep learning reconstrutions. To address these challenges, we propose K2Calibrate, a K-space adaptation strategy for self-supervised model-driven MR reconstruction optimization. By iteratively calibrating the learned measurements, K2Calibrate can reduce the network's reconstruction deterioration caused by statistically dependent noise. Extensive experiments have been conducted on the open-source dataset FastMRI, and K2Calibrate achieves better results than five state-of-the-art methods. The proposed K2Calibrate is plug-and-play and can be easily integrated with different model-driven deep learning reconstruction methods. ",
    "url": "https://arxiv.org/abs/2203.09724",
    "authors": [
      "Weijian Huang",
      "Cheng Li",
      "Wenxin Fan",
      "Yongjin Zhou",
      "Qiegen Liu",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2007.12133",
    "title": "Provably Robust Adversarial Examples",
    "abstract": " Title: Provably Robust Adversarial Examples ",
    "url": "https://arxiv.org/abs/2007.12133",
    "authors": [
      "Dimitar I. Dimitrov",
      "Gagandeep Singh",
      "Timon Gehr",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.03717",
    "title": "Hierarchical Message-Passing Graph Neural Networks",
    "abstract": " Title: Hierarchical Message-Passing Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2009.03717",
    "authors": [
      "Zhiqiang Zhong",
      "Cheng-Te Li",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.00238",
    "title": "Multi-grained Semantics-aware Graph Neural Networks",
    "abstract": " Title: Multi-grained Semantics-aware Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2010.00238",
    "authors": [
      "Zhiqiang Zhong",
      "Cheng-Te Li",
      "Jun Pang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.03924",
    "title": "Domain Adversarial Neural Networks for Domain Generalization: When It  Works and How to Improve",
    "abstract": " Title: Domain Adversarial Neural Networks for Domain Generalization: When It  Works and How to Improve ",
    "url": "https://arxiv.org/abs/2102.03924",
    "authors": [
      "Anthony Sicilia",
      "Xingchen Zhao",
      "Seong Jae Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.10411",
    "title": "Group interactions modulate critical mass dynamics in social convention",
    "abstract": " Comments: 10 pages, 5 figures, Supplementary Material (13 pages, 12 figures) ",
    "url": "https://arxiv.org/abs/2103.10411",
    "authors": [
      "Iacopo Iacopini",
      "Giovanni Petri",
      "Andrea Baronchelli",
      "Alain Barrat"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2104.13754",
    "title": "Can crowdsourcing rescue the social marketplace of ideas?",
    "abstract": " Comments: Under Review - revision 3 ",
    "url": "https://arxiv.org/abs/2104.13754",
    "authors": [
      "Taha Yasseri",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2105.04349",
    "title": "Generative Adversarial Registration for Improved Conditional Deformable  Templates",
    "abstract": " Comments: ICCV 2021 camera-ready. 24 pages, 15 figures. Project page: this https URL Code: this https URL ",
    "url": "https://arxiv.org/abs/2105.04349",
    "authors": [
      "Neel Dey",
      "Mengwei Ren",
      "Adrian V. Dalca",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2105.10377",
    "title": "Adaptive Filters in Graph Convolutional Neural Networks",
    "abstract": " Title: Adaptive Filters in Graph Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2105.10377",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgr\u00f2",
      "Andrea Pollastro",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.01098",
    "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and  Practical Solutions",
    "abstract": " Comments: Accepted as a Spotlight presentation at ICLR 2022 ",
    "url": "https://arxiv.org/abs/2106.01098",
    "authors": [
      "Leslie O'Bray",
      "Max Horn",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.10918",
    "title": "A Mocktail of Source Code Representations",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2106.10918",
    "authors": [
      "Karthik Chandra Swarna",
      "Noble Saji Mathews",
      "Dheeraj Vagavolu",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2107.10224",
    "title": "CycleMLP: A MLP-like Architecture for Dense Prediction",
    "abstract": " Comments: ICLR 2022 (Oral). Camera-ready Code: this https URL ",
    "url": "https://arxiv.org/abs/2107.10224",
    "authors": [
      "Shoufa Chen",
      "Enze Xie",
      "Chongjian Ge",
      "Runjian Chen",
      "Ding Liang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.03625",
    "title": "Unifying Heterogeneous Electronic Health Records Systems via Text-Based  Code Embedding",
    "abstract": " Comments: Accepted at CHIL 2022. Main paper + supplementary material (21 pages, 8 figures, 12 tables) ",
    "url": "https://arxiv.org/abs/2108.03625",
    "authors": [
      "Kyunghoon Hur",
      "Jiyoung Lee",
      "Jungwoo Oh",
      "Wesley Price",
      "Young-Hak Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2108.05081",
    "title": "Cervical Optical Coherence Tomography Image Classification Based on  Contrastive Self-Supervised Texture Learning",
    "abstract": " Comments: 22 pages, 7 figures, and 7 tables ",
    "url": "https://arxiv.org/abs/2108.05081",
    "authors": [
      "Kaiyi Chen",
      "Qingbin Wang",
      "Yutao Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.08579",
    "title": "Checking Security Compliance between Models and Code",
    "abstract": " Title: Checking Security Compliance between Models and Code ",
    "url": "https://arxiv.org/abs/2108.08579",
    "authors": [
      "Katja Tuma",
      "Sven Peldszus",
      "Daniel Str\u00fcber",
      "Riccardo Scandariato",
      "Jan J\u00fcrjens"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2108.11439",
    "title": "PGTRNet: Two-phase Weakly Supervised Object Detection with Pseudo Ground  Truth Refinement",
    "abstract": " Comments: This paper was accepted by ICASSP2022. arXiv admin note: substantial text overlap with arXiv:2104.00231 ",
    "url": "https://arxiv.org/abs/2108.11439",
    "authors": [
      "Jun Wang",
      "Hefeng Zhou",
      "Xiaohan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.13655",
    "title": "MELM: Data Augmentation with Masked Entity Language Modeling for  Low-Resource NER",
    "abstract": " Comments: Accepted at ACL 2022 ",
    "url": "https://arxiv.org/abs/2108.13655",
    "authors": [
      "Ran Zhou",
      "Xin Li",
      "Ruidan He",
      "Lidong Bing",
      "Erik Cambria",
      "Luo Si",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2108.13993",
    "title": "Designing Rotationally Invariant Neural Networks from PDEs and  Variational Methods",
    "abstract": " Title: Designing Rotationally Invariant Neural Networks from PDEs and  Variational Methods ",
    "url": "https://arxiv.org/abs/2108.13993",
    "authors": [
      "Tobias Alt",
      "Karl Schrader",
      "Joachim Weickert",
      "Pascal Peter",
      "Matthias Augustin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.03926",
    "title": "Transformers in the loop: Polarity in neural models of language",
    "abstract": " Comments: Accepted to ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2109.03926",
    "authors": [
      "Lisa Bylinina",
      "Alexey Tikhonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.03774",
    "title": "Data-driven Tissue Mechanics with Polyconvex Neural Ordinary  Differential Equations",
    "abstract": " Comments: 17 pages (including references and appendix), 8 figures. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.03774",
    "authors": [
      "Vahidullah Tac",
      "Francisco S. Costabal",
      "Adrian Buganza Tepole"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.06468",
    "title": "Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based  Vertical Federated Learning",
    "abstract": " Title: Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based  Vertical Federated Learning ",
    "url": "https://arxiv.org/abs/2110.06468",
    "authors": [
      "Jinyin Chen",
      "Guohan Huang",
      "Haibin Zheng",
      "Shanqing Yu",
      "Wenrong Jiang",
      "Chen Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.07159",
    "title": "Interpreting the Robustness of Neural NLP Models to Textual  Perturbations",
    "abstract": " Comments: Accepted to Findings of ACL 2022 ",
    "url": "https://arxiv.org/abs/2110.07159",
    "authors": [
      "Yunxiang Zhang",
      "Liangming Pan",
      "Samson Tan",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.09320",
    "title": "Deploying Near-Optimal Delay-Constrained Paths with Segment Routing in  Massive-Scale Networks",
    "abstract": " Title: Deploying Near-Optimal Delay-Constrained Paths with Segment Routing in  Massive-Scale Networks ",
    "url": "https://arxiv.org/abs/2110.09320",
    "authors": [
      "Jean-Romain Luttringer",
      "Thomas Alfroy",
      "Pascal M\u00e9rindol",
      "Quentin Bramas",
      "Fran\u00e7ois Clad",
      "Cristel Pelsser"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.05237",
    "title": "Psycho-linguistic differences among competing vaccination communities on  social media",
    "abstract": " Title: Psycho-linguistic differences among competing vaccination communities on  social media ",
    "url": "https://arxiv.org/abs/2111.05237",
    "authors": [
      "Jialiang Shi",
      "Piyush Ghasiya",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2112.00476",
    "title": "Null Model-Based Data Augmentation for Graph Classification",
    "abstract": " Title: Null Model-Based Data Augmentation for Graph Classification ",
    "url": "https://arxiv.org/abs/2112.00476",
    "authors": [
      "Qi Xuan",
      "Zeyu Wang",
      "Jinhuan Wang",
      "Yalu Shan",
      "Xiaoke Xu",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.01653",
    "title": "Learning Curves for Continual Learning in Neural Networks:  Self-Knowledge Transfer and Forgetting",
    "abstract": " Comments: 27 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2112.01653",
    "authors": [
      "Ryo Karakida",
      "Shotaro Akaho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02612",
    "title": "Training Structured Neural Networks Through Manifold Identification and  Variance Reduction",
    "abstract": " Title: Training Structured Neural Networks Through Manifold Identification and  Variance Reduction ",
    "url": "https://arxiv.org/abs/2112.02612",
    "authors": [
      "Zih-Syuan Huang",
      "Ching-pei Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.06567",
    "title": "Implications of Topological Imbalance for Representation Learning on  Biomedical Knowledge Graphs",
    "abstract": " Title: Implications of Topological Imbalance for Representation Learning on  Biomedical Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2112.06567",
    "authors": [
      "Stephen Bonner",
      "Ufuk Kirik",
      "Ola Engkvist",
      "Jian Tang",
      "Ian P Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2112.09219",
    "title": "All You Need is RAW: Defending Against Adversarial Attacks with Camera  Image Pipelines",
    "abstract": " Title: All You Need is RAW: Defending Against Adversarial Attacks with Camera  Image Pipelines ",
    "url": "https://arxiv.org/abs/2112.09219",
    "authors": [
      "Yuxuan Zhang",
      "Bo Dong",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2201.08413",
    "title": "Unicorn: Reasoning about Configurable System Performance through the  lens of Causality",
    "abstract": " Comments: EuroSys 2022 (camera-ready) ",
    "url": "https://arxiv.org/abs/2201.08413",
    "authors": [
      "Md Shahriar Iqbal",
      "Rahul Krishna",
      "Mohammad Ali Javidian",
      "Baishakhi Ray",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2201.10285",
    "title": "Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition",
    "abstract": " Title: Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition ",
    "url": "https://arxiv.org/abs/2201.10285",
    "authors": [
      "Abdoulaye Koroko",
      "Ani Anciaux-Sedrakian",
      "Ibtihel Gharbia",
      "Val\u00e9rie Gar\u00e8s",
      "Mounir Haddou",
      "Quang Huy Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.02833",
    "title": "CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in  Medical Imaging AI",
    "abstract": " Comments: Added code url ",
    "url": "https://arxiv.org/abs/2202.02833",
    "authors": [
      "Arjun Soin",
      "Jameson Merkow",
      "Jin Long",
      "Joseph Paul Cohen",
      "Smitha Saligrama",
      "Stephen Kaiser",
      "Steven Borg",
      "Ivan Tarapov",
      "Matthew P Lungren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04239",
    "title": "A multiscale spatiotemporal approach for smallholder irrigation  detection",
    "abstract": " Title: A multiscale spatiotemporal approach for smallholder irrigation  detection ",
    "url": "https://arxiv.org/abs/2202.04239",
    "authors": [
      "Terence Conlon",
      "Christopher Small",
      "Vijay Modi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10326",
    "title": "A Deep Learning Approach for Repairing Missing Activity Labels in Event  Logs for Process Mining",
    "abstract": " Title: A Deep Learning Approach for Repairing Missing Activity Labels in Event  Logs for Process Mining ",
    "url": "https://arxiv.org/abs/2202.10326",
    "authors": [
      "Yang Lu",
      "Qifan Chen",
      "Simon K. Poon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2202.12634",
    "title": "Deep Dirichlet uncertainty for unsupervised out-of-distribution  detection of eye fundus photographs in glaucoma screening",
    "abstract": " Comments: Submitted to ISBI 2022 ",
    "url": "https://arxiv.org/abs/2202.12634",
    "authors": [
      "Teresa Ara\u00fajo",
      "Guilherme Aresta",
      "Hrvoje Bogunovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01583",
    "title": "Towards Universal Backward-Compatible Representation Learning",
    "abstract": " Title: Towards Universal Backward-Compatible Representation Learning ",
    "url": "https://arxiv.org/abs/2203.01583",
    "authors": [
      "Binjie Zhang",
      "Yixiao Ge",
      "Yantao Shen",
      "Shupeng Su",
      "Fanzi Wu",
      "Chun Yuan",
      "Xuyuan Xu",
      "Yexin Wang",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03373",
    "title": "Adversarial Texture for Fooling Person Detectors in the Physical World",
    "abstract": " Comments: Accepted by CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.03373",
    "authors": [
      "Zhanhao Hu",
      "Siyuan Huang",
      "Xiaopei Zhu",
      "Xiaolin Hu",
      "Fuchun Sun",
      "Bo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.03910",
    "title": "Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced  Training for Neural Machine Translation",
    "abstract": " Comments: ACL 2022 main conference ",
    "url": "https://arxiv.org/abs/2203.03910",
    "authors": [
      "Chenze Shao",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03916",
    "title": "Estimating the average causal effect of intervention in continuous  variables using machine learning",
    "abstract": " Title: Estimating the average causal effect of intervention in continuous  variables using machine learning ",
    "url": "https://arxiv.org/abs/2203.03916",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06889",
    "title": "Lead-agnostic Self-supervised Learning for Local and Global  Representations of Electrocardiogram",
    "abstract": " Comments: Accepted at CHIL 2022 (16 pages, 3 figures, 4 tables) ",
    "url": "https://arxiv.org/abs/2203.06889",
    "authors": [
      "Jungwoo Oh",
      "Hyunseung Chung",
      "Joon-myoung Kwon",
      "Dong-gyun Hong",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.07182",
    "title": "NeILF: Neural Incident Light Field for Physically-based Material  Estimation",
    "abstract": " Title: NeILF: Neural Incident Light Field for Physically-based Material  Estimation ",
    "url": "https://arxiv.org/abs/2203.07182",
    "authors": [
      "Yao Yao",
      "Jingyang Zhang",
      "Jingbo Liu",
      "Yihang Qu",
      "Tian Fang",
      "David McKinnon",
      "Yanghai Tsin",
      "Long Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08049",
    "title": "On Hyperbolic Embeddings in 2D Object Detection",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2203.08049",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.08606",
    "title": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "abstract": " Title: A Reachability Index for Recursive Label-Concatenated Graph Queries ",
    "url": "https://arxiv.org/abs/2203.08606",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "Hugo Kapp",
      "Vlad Ioan Haprian",
      "Jean-Pierre Lozi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2203.08898",
    "title": "Neural network processing of holographic images",
    "abstract": " Comments: 38 pages, 15 figures. Submitted to Atmospheric Measurement Techniques ",
    "url": "https://arxiv.org/abs/2203.08898",
    "authors": [
      "John S. Schreck",
      "Gabrielle Gantos",
      "Matthew Hayman",
      "Aaron Bansemer",
      "David John Gagne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2203.09208",
    "title": "Neural Compression-Based Feature Learning for Video Restoration",
    "abstract": " Comments: Accepted to CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.09208",
    "authors": [
      "Cong Huang",
      "Jiahao Li",
      "Bin Li",
      "Dong Liu",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09360",
    "title": "Behavior-aware Account De-anonymization on Ethereum Interaction Graph",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2203.09360",
    "authors": [
      "Jiajun Zhou",
      "Chenkai Hu",
      "Jianlei Chi",
      "Jiajing Wu",
      "Meng Shen",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.09364",
    "title": "Interacting Attention Graph for Single Image Two-Hand Reconstruction",
    "abstract": " Comments: To appear in CVPR 2022. Project page: this http URL ",
    "url": "https://arxiv.org/abs/2203.09364",
    "authors": [
      "Mengcheng Li",
      "Liang An",
      "Hongwen Zhang",
      "Lianpeng Wu",
      "Feng Chen",
      "Tao Yu",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09388",
    "title": "A Text Attention Network for Spatial Deformation Robust Scene Text Image  Super-resolution",
    "abstract": " Comments: Accepted to CVPR2022 ",
    "url": "https://arxiv.org/abs/2203.09388",
    "authors": [
      "Jianqi Ma",
      "Zhetong Liang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09446",
    "title": "Vox2Cortex: Fast Explicit Reconstruction of Cortical Surfaces from 3D  MRI Scans with Geometric Deep Neural Networks",
    "abstract": " Comments: Accepted at CVPR 2022 ",
    "url": "https://arxiv.org/abs/2203.09446",
    "authors": [
      "Fabian Bongratz",
      "Anne-Marie Rickmann",
      "Sebastian P\u00f6lsterl",
      "Christian Wachinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.09452",
    "title": "Automated Transpilation of Imperative to Functional Code using  Neural-Guided Program Synthesis (Extended Version)",
    "abstract": " Comments: Fixed some incorrectly rendered citations ",
    "url": "https://arxiv.org/abs/2203.09452",
    "authors": [
      "Benjamin Mariano",
      "Yanju Chen",
      "Yu Feng",
      "Greg Durrett",
      "Isil Dillig"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2203.09494",
    "title": "Transframer: Arbitrary Frame Prediction with Generative Models",
    "abstract": " Title: Transframer: Arbitrary Frame Prediction with Generative Models ",
    "url": "https://arxiv.org/abs/2203.09494",
    "authors": [
      "Charlie Nash",
      "Jo\u00e3o Carreira",
      "Jacob Walker",
      "Iain Barr",
      "Andrew Jaegle",
      "Mateusz Malinowski",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]