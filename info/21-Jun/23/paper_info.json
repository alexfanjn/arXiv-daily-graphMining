[
  {
    "id": "arXiv:2106.11360",
    "title": "Hi-BEHRT: Hierarchical Transformer-based model for accurate prediction  of clinical events using multimodal longitudinal electronic health records",
    "abstract": "Electronic health records represent a holistic overview of patients' trajectories. Their increasing availability has fueled new hopes to leverage them and develop accurate risk prediction models for a wide range of diseases. Given the complex interrelationships of medical records and patient outcomes, deep learning models have shown clear merits in achieving this goal. However, a key limitation of these models remains their capacity in processing long sequences. Capturing the whole history of medical encounters is expected to lead to more accurate predictions, but the inclusion of records collected for decades and from multiple resources can inevitably exceed the receptive field of the existing deep learning architectures. This can result in missing crucial, long-term dependencies. To address this gap, we present Hi-BEHRT, a hierarchical Transformer-based model that can significantly expand the receptive field of Transformers and extract associations from much longer sequences. Using a multimodal large-scale linked longitudinal electronic health records, the Hi-BEHRT exceeds the state-of-the-art BEHRT 1% to 5% for area under the receiver operating characteristic (AUROC) curve and 3% to 6% for area under the precision recall (AUPRC) curve on average, and 3% to 6% (AUROC) and 3% to 11% (AUPRC) for patients with long medical history for 5-year heart failure, diabetes, chronic kidney disease, and stroke risk prediction. Additionally, because pretraining for hierarchical Transformer is not well-established, we provide an effective end-to-end contrastive pre-training strategy for Hi-BEHRT using EHR, improving its transferability on predicting clinical events with relatively small training dataset. ",
    "url": "https://arxiv.org/abs/2106.11360",
    "authors": [
      "Yikuan Li",
      "Mohammad Mamouei",
      "Gholamreza Salimi-Khorshidi",
      "Shishir Rao",
      "Abdelaali Hassaine",
      "Dexter Canoy",
      "Thomas Lukasiewicz",
      "Kazem Rahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11411",
    "title": "Attention-based cross-modal fusion for audio-visual voice activity  detection in musical video streams",
    "abstract": "Many previous audio-visual voice-related works focus on speech, ignoring the singing voice in the growing number of musical video streams on the Internet. For processing diverse musical video data, voice activity detection is a necessary step. This paper attempts to detect the speech and singing voices of target performers in musical video streams using audiovisual information. To integrate information of audio and visual modalities, a multi-branch network is proposed to learn audio and image representations, and the representations are fused by attention based on semantic similarity to shape the acoustic representations through the probability of anchor vocalization. Experiments show the proposed audio-visual multi-branch network far outperforms the audio-only model in challenging acoustic environments, indicating the cross-modal information fusion based on semantic correlation is sensible and successful. ",
    "url": "https://arxiv.org/abs/2106.11411",
    "authors": [
      "Yuanbo Hou",
      "Zhesong Yu",
      "Xia Liang",
      "Xingjian Du",
      "Bilei Zhu",
      "Zejun Ma",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2106.11696",
    "title": "Diversity-aware $k$-median : Clustering with fair center representation",
    "abstract": "We introduce a novel problem for diversity-aware clustering. We assume that the potential cluster centers belong to a set of groups defined by protected attributes, such as ethnicity, gender, etc. We then ask to find a minimum-cost clustering of the data into $k$ clusters so that a specified minimum number of cluster centers are chosen from each group. We thus require that all groups are represented in the clustering solution as cluster centers, according to specified requirements. More precisely, we are given a set of clients $C$, a set of facilities $\\pazocal{F}$, a collection $\\mathcal{F}=\\{F_1,\\dots,F_t\\}$ of facility groups $F_i \\subseteq \\pazocal{F}$, budget $k$, and a set of lower-bound thresholds $R=\\{r_1,\\dots,r_t\\}$, one for each group in $\\mathcal{F}$. The \\emph{diversity-aware $k$-median problem} asks to find a set $S$ of $k$ facilities in $\\pazocal{F}$ such that $|S \\cap F_i| \\geq r_i$, that is, at least $r_i$ centers in $S$ are from group $F_i$, and the $k$-median cost $\\sum_{c \\in C} \\min_{s \\in S} d(c,s)$ is minimized. We show that in the general case where the facility groups may overlap, the diversity-aware $k$-median problem is \\np-hard, fixed-parameter intractable, and inapproximable to any multiplicative factor. On the other hand, when the facility groups are disjoint, approximation algorithms can be obtained by reduction to the \\emph{matroid median} and \\emph{red-blue median} problems. Experimentally, we evaluate our approximation methods for the tractable cases, and present a relaxation-based heuristic for the theoretically intractable case, which can provide high-quality and efficient solutions for real-world datasets. ",
    "url": "https://arxiv.org/abs/2106.11696",
    "authors": [
      "Suhas Thejaswi",
      "Bruno Ordozgoiti",
      "Aristides Gionis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.11747",
    "title": "Single-chip photonic deep neural network for instantaneous image  classification",
    "abstract": "Deep neural networks with applications from computer vision and image processing to medical diagnosis are commonly implemented using clock-based processors, where computation speed is limited by the clock frequency and the memory access time. Advances in photonic integrated circuits have enabled research in photonic computation, where, despite excellent features such as fast linear computation, no integrated photonic deep network has been demonstrated to date due to the lack of scalable nonlinear functionality and the loss of photonic devices, making scalability to a large number of layers challenging. Here we report the first integrated end-to-end photonic deep neural network (PDNN) that performs instantaneous image classification through direct processing of optical waves. Images are formed on the input pixels and optical waves are coupled into nanophotonic waveguides and processed as the light propagates through layers of neurons on-chip. Each neuron generates an optical output from input optical signals, where linear computation is performed optically and the nonlinear activation function is realised opto-electronically. The output of a laser coupled into the chip is uniformly distributed among all neurons within the network providing the same per-neuron supply light. Thus, all neurons have the same optical output range enabling scalability to deep networks with large number of layers. The PDNN chip is used for 2- and 4-class classification of handwritten letters achieving accuracies of higher than 93.7% and 90.3%, respectively, with a computation time less than one clock cycle of state-of-the-art digital computation platforms. Direct clock-less processing of optical data eliminates photo-detection, A/D conversion, and the requirement for a large memory module, enabling significantly faster and more energy-efficient neural networks for the next generations of deep learning systems. ",
    "url": "https://arxiv.org/abs/2106.11747",
    "authors": [
      "Farshid Ashtiani",
      "Alexander J. Geers",
      "Firooz Aflatouni"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2106.11756",
    "title": "Trinity: A No-Code AI platform for complex spatial datasets",
    "abstract": "We present a no-code Artificial Intelligence (AI) platform called Trinity with the main design goal of enabling both machine learning researchers and non-technical geospatial domain experts to experiment with domain-specific signals and datasets for solving a variety of complex problems on their own. This versatility to solve diverse problems is achieved by transforming complex Spatio-temporal datasets to make them consumable by standard deep learning models, in this case, Convolutional Neural Networks (CNNs), and giving the ability to formulate disparate problems in a standard way, eg. semantic segmentation. With an intuitive user interface, a feature store that hosts derivatives of complex feature engineering, a deep learning kernel, and a scalable data processing mechanism, Trinity provides a powerful platform for domain experts to share the stage with scientists and engineers in solving business-critical problems. It enables quick prototyping, rapid experimentation and reduces the time to production by standardizing model building and deployment. In this paper, we present our motivation behind Trinity and its design along with showcasing sample applications to motivate the idea of lowering the bar to using AI. ",
    "url": "https://arxiv.org/abs/2106.11756",
    "authors": [
      "C.V.Krishnakumar Iyer",
      "Feili Hou",
      "Henry Wang",
      "Yonghong Wang",
      "Kay Oh",
      "Swetava Ganguli",
      "Vipul Pandey"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.11451",
    "title": "Physics-constrained deep neural network method for estimating parameters  in a redox flow battery",
    "abstract": "In this paper, we present a physics-constrained deep neural network (PCDNN) method for parameter estimation in the zero-dimensional (0D) model of the vanadium redox flow battery (VRFB). In this approach, we use deep neural networks (DNNs) to approximate the model parameters as functions of the operating conditions. This method allows the integration of the VRFB computational models as the physical constraints in the parameter learning process, leading to enhanced accuracy of parameter estimation and cell voltage prediction. Using an experimental dataset, we demonstrate that the PCDNN method can estimate model parameters for a range of operating conditions and improve the 0D model prediction of voltage compared to the 0D model prediction with constant operation-condition-independent parameters estimated with traditional inverse methods. We also demonstrate that the PCDNN approach has an improved generalization ability for estimating parameter values for operating conditions not used in the DNN training. ",
    "url": "https://arxiv.org/abs/2106.11451",
    "authors": [
      "QiZhi He",
      "Panos Stinis",
      "Alexandre Tartakovsky"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11794",
    "title": "Deep neural network Based Low-latency Speech Separation with Asymmetric  analysis-Synthesis Window Pair",
    "abstract": "Time-frequency masking or spectrum prediction computed via short symmetric windows are commonly used in low-latency deep neural network (DNN) based source separation. In this paper, we propose the usage of an asymmetric analysis-synthesis window pair which allows for training with targets with better frequency resolution, while retaining the low-latency during inference suitable for real-time speech enhancement or assisted hearing applications. In order to assess our approach across various model types and datasets, we evaluate it with both speaker-independent deep clustering (DC) model and a speaker-dependent mask inference (MI) model. We report an improvement in separation performance of up to 1.5 dB in terms of source-to-distortion ratio (SDR) while maintaining an algorithmic latency of 8 ms. ",
    "url": "https://arxiv.org/abs/2106.11794",
    "authors": [
      "Shanshan Wang",
      "Gaurav Naithani",
      "Archontis Politis",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2005.08140",
    "title": "Global inducing point variational posteriors for Bayesian neural  networks and deep Gaussian processes",
    "abstract": " Comments: Accepted for publication at the 38th International Conference on Machine Learning (ICML 2021, PMLR 139), 33 pages ",
    "url": "https://arxiv.org/abs/2005.08140",
    "authors": [
      "Sebastian W. Ober",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.12067",
    "title": "Orbit Structure of Grassmannian $G_{2, m}$ and a decoder for Grassmann  code $C(2, m)$",
    "abstract": " Title: Orbit Structure of Grassmannian $G_{2, m}$ and a decoder for Grassmann  code $C(2, m)$ ",
    "url": "https://arxiv.org/abs/2008.12067",
    "authors": [
      "Fernando Pi\u00f1ero",
      "Prasant Singh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2103.07609",
    "title": "Untrained networks for compressive lensless photography",
    "abstract": " Comments: 17 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2103.07609",
    "authors": [
      "Kristina Monakhova",
      "Vi Tran",
      "Grace Kuo",
      "Laura Waller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2103.10201",
    "title": "The impact of using biased performance metrics on software defect  prediction research",
    "abstract": " Comments: Accepted by the journal Information & Software Technology. It is a greatly extended version of \"Assessing Software Defection Prediction Performance: Why Using the Matthews Correlation Coefficient Matters\" presented at EASE 2020 ",
    "url": "https://arxiv.org/abs/2103.10201",
    "authors": [
      "Jingxiu Yao",
      "Martin Shepperd"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05009",
    "title": "Network insensitivity to parameter noise via adversarial regularization",
    "abstract": " Title: Network insensitivity to parameter noise via adversarial regularization ",
    "url": "https://arxiv.org/abs/2106.05009",
    "authors": [
      "Julian B\u00fcchel",
      "Fynn Faber",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.10476",
    "title": "Neural network interpretability for forecasting of aggregated renewable  generation",
    "abstract": " Title: Neural network interpretability for forecasting of aggregated renewable  generation ",
    "url": "https://arxiv.org/abs/2106.10476",
    "authors": [
      "Yucun Lu",
      "Ilgiz Murzakhanov",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]