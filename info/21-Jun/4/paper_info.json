[
  {
    "id": "arXiv:2106.01367",
    "title": "On using distributed representations of source code for the detection of  C security vulnerabilities",
    "abstract": "This paper presents an evaluation of the code representation model Code2vec when trained on the task of detecting security vulnerabilities in C source code. We leverage the open-source library astminer to extract path-contexts from the abstract syntax trees of a corpus of labeled C functions. Code2vec is trained on the resulting path-contexts with the task of classifying a function as vulnerable or non-vulnerable. Using the CodeXGLUE benchmark, we show that the accuracy of Code2vec for this task is comparable to simple transformer-based methods such as pre-trained RoBERTa, and outperforms more naive NLP-based methods. We achieved an accuracy of 61.43% while maintaining low computational requirements relative to larger models. ",
    "url": "https://arxiv.org/abs/2106.01367",
    "authors": [
      "David Coimbra",
      "Sofia Reis",
      "Rui Abreu",
      "Corina P\u0103s\u0103reanu",
      "Hakan Erdogmus"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2106.01604",
    "title": "Noisy student-teacher training for robust keyword spotting",
    "abstract": "We propose self-training with noisy student-teacher approach for streaming keyword spotting, that can utilize large-scale unlabeled data and aggressive data augmentation. The proposed method applies aggressive data augmentation (spectral augmentation) on the input of both student and teacher and utilize unlabeled data at scale, which significantly boosts the accuracy of student against challenging conditions. Such aggressive augmentation usually degrades model performance when used with supervised training with hard-labeled data. Experiments show that aggressive spec augmentation on baseline supervised training method degrades accuracy, while the proposed self-training with noisy student-teacher training improves accuracy of some difficult-conditioned test sets by as much as 60%. ",
    "url": "https://arxiv.org/abs/2106.01604",
    "authors": [
      "Hyun-Jin Park",
      "Pai Zhu",
      "Ignacio Lopez Moreno",
      "Niranjan Subrahmanya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.01635",
    "title": "Can vectors read minds better than experts? Comparing data augmentation  strategies for the automated scoring of children's mindreading ability",
    "abstract": "In this paper we implement and compare 7 different data augmentation strategies for the task of automatic scoring of children's ability to understand others' thoughts, feelings, and desires (or \"mindreading\"). We recruit in-domain experts to re-annotate augmented samples and determine to what extent each strategy preserves the original rating. We also carry out multiple experiments to measure how much each augmentation strategy improves the performance of automatic scoring systems. To determine the capabilities of automatic systems to generalize to unseen data, we create UK-MIND-20 - a new corpus of children's performance on tests of mindreading, consisting of 10,320 question-answer pairs. We obtain a new state-of-the-art performance on the MIND-CA corpus, improving macro-F1-score by 6 points. Results indicate that both the number of training examples and the quality of the augmentation strategies affect the performance of the systems. The task-specific augmentations generally outperform task-agnostic augmentations. Automatic augmentations based on vectors (GloVe, FastText) perform the worst. We find that systems trained on MIND-CA generalize well to UK-MIND-20. We demonstrate that data augmentation strategies also improve the performance on unseen data. ",
    "url": "https://arxiv.org/abs/2106.01635",
    "authors": [
      "Venelin Kovatchev",
      "Phillip Smith",
      "Mark Lee",
      "Rory Devine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01644",
    "title": "Corporate core values and social responsibility: What really matters to  whom",
    "abstract": "This study uses an innovative measure, the Semantic Brand Score, to assess the interest of stakeholders in different company core values. Among others, we focus on corporate social responsibility (CSR) core value statements, and on the attention they receive from five categories of stakeholders (customers, company communication teams, employees, associations and media). Combining big data methods and tools of Social Network Analysis and Text Mining, we analyzed about 58,000 Italian tweets and found that different stakeholders have different prevailing interests. CSR gets much less attention than expected. Core values related to customers and employees are in the foreground. ",
    "url": "https://arxiv.org/abs/2106.01644",
    "authors": [
      "M. A. Barchiesi",
      "A. Fronzetti Colladon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2106.01695",
    "title": "From indexation policies through citation networks to normalized  citation impacts: Web of Science, Scopus, and Dimensions as varying resonance  chambers",
    "abstract": "Dimensions was introduced as an alternative bibliometric database to the well-established Web of Science (WoS) and Scopus, however all three databases have fundamental differences in coverage and content, resultant from their owners' indexation philosophies. In light of these differences, we explore here, using a citation network analysis and assessment of normalised citation impact of \"duplicate\" publications, whether the three databases offer structurally different perspectives of the bibliometric landscape or if they are essentially homogenous substitutes. Our citation network analysis of core and exclusive 2016-2018 publications revealed a large set of core publications indexed in all three databases that are highly self-referential. In comparison, each database selected a set of exclusive publications that appeared to hold similarly low levels of relevance to the core set and to one another, with slightly more internal communication between exclusive publications in Scopus and Dimensions than WoS. Our comparison of normalised citations for 41,848 publications indexed in all three databases found that German sectors were valuated as more impactful in Scopus and Dimensions compared to WoS, particularly for sectors with an applied research focus. We conclude that the databases do present structurally different perspectives, although Scopus and Dimensions with their additional circle of applied research vary more from the more base research-focused WoS than they do from one another. ",
    "url": "https://arxiv.org/abs/2106.01695",
    "authors": [
      "Stephan Stahlschmidt",
      "Dimity Stephen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2106.01706",
    "title": "EmoDNN: Understanding emotions from short texts through a deep neural  network ensemble",
    "abstract": "The latent knowledge in the emotions and the opinions of the individuals that are manifested via social networks are crucial to numerous applications including social management, dynamical processes, and public security. Affective computing, as an interdisciplinary research field, linking artificial intelligence to cognitive inference, is capable to exploit emotion-oriented knowledge from brief contents. The textual contents convey hidden information such as personality and cognition about corresponding authors that can determine both correlations and variations between users. Emotion recognition from brief contents should embrace the contrast between authors where the differences in personality and cognition can be traced within emotional expressions. To tackle this challenge, we devise a framework that, on the one hand, infers latent individual aspects, from brief contents and, on the other hand, presents a novel ensemble classifier equipped with dynamic dropout convnets to extract emotions from textual context. To categorize short text contents, our proposed method conjointly leverages cognitive factors and exploits hidden information. We utilize the outcome vectors in a novel embedding model to foster emotion-pertinent features that are collectively assembled by lexicon inductions. Experimental results show that compared to other competitors, our proposed model can achieve a higher performance in recognizing emotion from noisy contents. ",
    "url": "https://arxiv.org/abs/2106.01706",
    "authors": [
      "Sara Kamran",
      "Raziyeh Zall",
      "Mohammad Reza Kangavari",
      "Saeid Hosseini",
      "Sana Rahmani",
      "Wen Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.01782",
    "title": "Machine learning models for DOTA 2 outcomes prediction",
    "abstract": "Prediction of the real-time multiplayer online battle arena (MOBA) games' match outcome is one of the most important and exciting tasks in Esports analytical research. This research paper predominantly focuses on building predictive machine and deep learning models to identify the outcome of the Dota 2 MOBA game using the new method of multi-forward steps predictions. Three models were investigated and compared: Linear Regression (LR), Neural Networks (NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In order to achieve the goals, we developed a data collecting python server using Game State Integration (GSI) to track the real-time data of the players. Once the exploratory feature analysis and tuning hyper-parameters were done, our models' experiments took place on different players with dissimilar backgrounds of playing experiences. The achieved accuracy scores depend on the multi-forward prediction parameters, which for the worse case in linear regression 69\\% but on average 82\\%, while in the deep learning models hit the utmost accuracy of prediction on average 88\\% for NN, and 93\\% for LSTM models. ",
    "url": "https://arxiv.org/abs/2106.01782",
    "authors": [
      "Kodirjon Akhmedov",
      "Anh Huy Phan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01813",
    "title": "Identification of physical networks through structured polynomial models",
    "abstract": "Physical dynamic networks most commonly consist of interconnections of physical components that can be described by diffusive couplings. These diffusive couplings imply that the cause-effect relationships in the interconnections are symmetric and therefore physical dynamic networks can be represented by undirected graphs. This paper shows how (prediction error) identification methods developed for polynomial linear time-invariant systems can be configured to consistently identify the parameters and the interconnection structure of (undirected) physical networks. Further, a multi-step least squares (convex) optimization algorithm is developed to solve the nonconvex optimization problem that results from the identification method. ",
    "url": "https://arxiv.org/abs/2106.01813",
    "authors": [
      "E.M.M.",
      "Kivits",
      "Paul M.J. Van den Hof"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.01683",
    "title": "Rich dynamics caused by known biological brain network features  resulting in stateful networks",
    "abstract": "The mammalian brain could contain dense and sparse network connectivity structures, including both excitatory and inhibitory neurons, but is without any clearly defined output layer. The neurons have time constants, which mean that the integrated network structure has state memory. The network structure contains complex mutual interactions between the neurons under different conditions, which depend on the internal state of the network. The internal state can be defined as the distribution of activity across all individual neurons across the network. Therefore, the state of a neuron/network becomes a defining factor for how information is represented within the network. Towards this study, we constructed a fully connected (with dense/sparse coding strategies) recurrent network comprising of both excitatory and inhibitory neurons, driven by pseudo-random inputs of varying frequencies. In this study we assessed the impact of varying specific intrinsic parameters of the neurons that enriched network state dynamics, such as initial neuron activity, amount of inhibition in combination with thresholded neurons and conduction delays. The impact was assessed by quantifying the changes in mutual interactions between the neurons within the network for each given input. We found such effects were more profound in sparsely connected networks than in densely connected networks. However, also densely connected networks could make use of such dynamic changes in the mutual interactions between neurons, as a given input could induce multiple different network states. ",
    "url": "https://arxiv.org/abs/2106.01683",
    "authors": [
      "Udaya B. Rongala",
      "Henrik J\u00f6rntell"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2106.01789",
    "title": "Speaker verification-derived loss and data augmentation for DNN-based  multispeaker speech synthesis",
    "abstract": "Building multispeaker neural network-based text-to-speech synthesis systems commonly relies on the availability of large amounts of high quality recordings from each speaker and conditioning the training process on the speaker's identity or on a learned representation of it. However, when little data is available from each speaker, or the number of speakers is limited, the multispeaker TTS can be hard to train and will result in poor speaker similarity and naturalness. In order to address this issue, we explore two directions: forcing the network to learn a better speaker identity representation by appending an additional loss term; and augmenting the input data pertaining to each speaker using waveform manipulation methods. We show that both methods are efficient when evaluated with both objective and subjective measures. The additional loss term aids the speaker similarity, while the data augmentation improves the intelligibility of the multispeaker TTS system. ",
    "url": "https://arxiv.org/abs/2106.01789",
    "authors": [
      "Beata Lorincz",
      "Adriana Stan",
      "Mircea Giurgiu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.01812",
    "title": "An objective evaluation of the effects of recording conditions and  speaker characteristics in multi-speaker deep neural speech synthesis",
    "abstract": "Multi-speaker spoken datasets enable the creation of text-to-speech synthesis (TTS) systems which can output several voice identities. The multi-speaker (MSPK) scenario also enables the use of fewer training samples per speaker. However, in the resulting acoustic model, not all speakers exhibit the same synthetic quality, and some of the voice identities cannot be used at all. In this paper we evaluate the influence of the recording conditions, speaker gender, and speaker particularities over the quality of the synthesised output of a deep neural TTS architecture, namely Tacotron2. The evaluation is possible due to the use of a large Romanian parallel spoken corpus containing over 81 hours of data. Within this setup, we also evaluate the influence of different types of text representations: orthographic, phonetic, and phonetic extended with syllable boundaries and lexical stress markings. We evaluate the results of the MSPK system using the objective measures of equal error rate (EER) and word error rate (WER), and also look into the distances between natural and synthesised t-SNE projections of the embeddings computed by an accurate speaker verification network. The results show that there is indeed a large correlation between the recording conditions and the speaker's synthetic voice quality. The speaker gender does not influence the output, and that extending the input text representation with syllable boundaries and lexical stress information does not equally enhance the generated audio across all speaker identities. The visualisation of the t-SNE projections of the natural and synthesised speaker embeddings show that the acoustic model shifts some of the speakers' neural representation, but not all of them. As a result, these speakers have lower performances of the output speech. ",
    "url": "https://arxiv.org/abs/2106.01812",
    "authors": [
      "Beata Lorincz",
      "Adriana Stan",
      "Mircea Giurgiu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.01836",
    "title": "DNA-GCN: Graph convolutional networks for predicting DNA-protein binding",
    "abstract": "Predicting DNA-protein binding is an important and classic problem in bioinformatics. Convolutional neural networks have outperformed conventional methods in modeling the sequence specificity of DNA-protein binding. However, none of the studies has utilized graph convolutional networks for motif inference. In this work, we propose to use graph convolutional networks for motif inference. We build a sequence k-mer graph for the whole dataset based on k-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph Convolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is initialized with a one-hot representation for all nodes, and it then jointly learns the embeddings for both k-mers and sequences, as supervised by the known labels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN shows its competitive performance compared with the baseline model. Besides, we analyze our model and design several different architectures to help fit different datasets. ",
    "url": "https://arxiv.org/abs/2106.01836",
    "authors": [
      "Yuhang Guo",
      "Xiao Luo",
      "Liang Chen",
      "Minghua Deng"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2003.04696",
    "title": "TorchIO: a Python library for efficient loading, preprocessing,  augmentation and patch-based sampling of medical images in deep learning",
    "abstract": " Comments: Submitted to Computer Methods and Programs in Biomedicine. 27 pages, 7 figures. Documentation for TorchIO can be found at this http URL ",
    "url": "https://arxiv.org/abs/2003.04696",
    "authors": [
      "Fernando P\u00e9rez-Garc\u00eda",
      "Rachel Sparks",
      "S\u00e9bastien Ourselin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2005.14356",
    "title": "Adjustable reach in a network centrality based on current flows",
    "abstract": " Title: Adjustable reach in a network centrality based on current flows ",
    "url": "https://arxiv.org/abs/2005.14356",
    "authors": [
      "Aleks J. Gurfinkel",
      "Per Arne Rikvold"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2009.07625",
    "title": "Distributed formation maneuver control by manipulating the complex  Laplacian",
    "abstract": " Comments: Automatica, 8 pages ",
    "url": "https://arxiv.org/abs/2009.07625",
    "authors": [
      "Hector Garcia de Marina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2104.02095",
    "title": "Deep neural network approximation of analytic functions",
    "abstract": " Title: Deep neural network approximation of analytic functions ",
    "url": "https://arxiv.org/abs/2104.02095",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.13010",
    "title": "An error analysis of generative adversarial networks for learning  distributions",
    "abstract": " Title: An error analysis of generative adversarial networks for learning  distributions ",
    "url": "https://arxiv.org/abs/2105.13010",
    "authors": [
      "Jian Huang",
      "Yuling Jiao",
      "Zhen Li",
      "Shiao Liu",
      "Yang Wang",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.00647",
    "title": "Mapping the NFT revolution: market trends, trade networks and visual  features",
    "abstract": " Comments: Working paper, comments welcome ",
    "url": "https://arxiv.org/abs/2106.00647",
    "authors": [
      "Matthieu Nadini",
      "Laura Alessandretti",
      "Flavio Di Giacinto",
      "Mauro Martino",
      "Luca Maria Aiello",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  }
]