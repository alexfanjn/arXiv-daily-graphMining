[
  {
    "id": "arXiv:2106.05316",
    "title": "Raman spectral analysis of mixtures with one-dimensional convolutional  neural network",
    "abstract": "Recently, the combination of robust one-dimensional convolutional neural networks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid identification of unknown substances with good accuracy. Using this technique, researchers can recognize a pure compound and distinguish it from unknown substances in a mixture. The novelty of this approach is that the trained neural network operates automatically without any pre- or post-processing of data. Some studies have attempted to extend this technique to the classification of pure compounds in an unknown mixture. However, the application of 1-D CNNs has typically been restricted to binary classifications of pure compounds. Here we will highlight a new approach in spectral recognition and quantification of chemical components in a multicomponent mixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this purpose. The former is for rapid classification of components in a mixture while the latter is for quantitative determination of those constituents. In the proposed method, there is no limit to the number of compounds in a mixture. A data augmentation method is also introduced by adding random baselines to the Raman spectra. The experimental results revealed that the classification accuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at the same time, the RaMixNet II model may achieve a regression accuracy of 88% for the quantification of each component. ",
    "url": "https://arxiv.org/abs/2106.05316",
    "authors": [
      "M. Hamed Mozaffari",
      "Li-Lin Tay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2106.05434",
    "title": "FedDICE: A ransomware spread detection in a distributed integrated  clinical environment using federated learning and SDN based mitigation",
    "abstract": "An integrated clinical environment (ICE) enables the connection and coordination of the internet of medical things around the care of patients in hospitals. However, ransomware attacks and their spread on hospital infrastructures, including ICE, are rising. Often the adversaries are targeting multiple hospitals with the same ransomware attacks. These attacks are detected by using machine learning algorithms. But the challenge is devising the anti-ransomware learning mechanisms and services under the following conditions: (1) provide immunity to other hospitals if one of them got the attack, (2) hospitals are usually distributed over geographical locations, and (3) direct data sharing is avoided due to privacy concerns. In this regard, this paper presents a federated distributed integrated clinical environment, aka. FedDICE. FedDICE integrates federated learning (FL), which is privacy-preserving learning, to SDN-oriented security architecture to enable collaborative learning, detection, and mitigation of ransomware attacks. We demonstrate the importance of FedDICE in a collaborative environment with up to four hospitals and four popular ransomware families, namely WannaCry, Petya, BadRabbit, and PowerGhost. Our results find that in both IID and non-IID data setups, FedDICE achieves the centralized baseline performance that needs direct data sharing for detection. However, as a trade-off to data privacy, FedDICE observes overhead in the anti-ransomware model training, e.g., 28x for the logistic regression model. Besides, FedDICE utilizes SDN's dynamic network programmability feature to remove the infected devices in ICE. ",
    "url": "https://arxiv.org/abs/2106.05434",
    "authors": [
      "Chandra Thapa",
      "Kallol Krishna Karmakar",
      "Alberto Huertas Celdran",
      "Seyit Camtepe",
      "Vijay Varadharajan",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.05437",
    "title": "Data augmentation to improve robustness of image captioning solutions",
    "abstract": "In this paper, we study the impact of motion blur, a common quality flaw in real world images, on a state-of-the-art two-stage image captioning solution, and notice a degradation in solution performance as blur intensity increases. We investigate techniques to improve the robustness of the solution to motion blur using training data augmentation at each or both stages of the solution, i.e., object detection and captioning, and observe improved results. In particular, augmenting both the stages reduces the CIDEr-D degradation for high motion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to 6.8 on Vizwiz dataset. ",
    "url": "https://arxiv.org/abs/2106.05437",
    "authors": [
      "Shashank Bujimalla",
      "Mahesh Subedar",
      "Omesh Tickoo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05452",
    "title": "Nonlinear mixed-dimension model for embedded tubular networks with  application to root water uptake",
    "abstract": "We present a numerical scheme for the solution of nonlinear mixed-dimensional PDEs describing coupled processes in embedded tubular network system in exchange with a bulk domain. Such problems arise in various biological and technical applications such as in the modeling of root-water uptake, heat exchangers, or geothermal wells. The nonlinearity appears in form of solution-dependent parameters such as pressure-dependent permeability or temperature-dependent thermal conductivity. We derive and analyse a numerical scheme based on distributing the bulk-network coupling source term by a smoothing kernel with local support. By the use of local analytical solutions, interface unknowns and fluxes at the bulk-network interface can be accurately reconstructed from coarsely resolved numerical solutions in the bulk domain. Numerical examples give confidence in the robustness of the method and show the results in comparison to previously published methods. The new method outperforms these existing methods in accuracy and efficiency. In a root water uptake scenario, we accurately estimate the transpiration rate using only a few thousand 3D mesh cells and a structured cube grid whereas other state-of-the-art numerical schemes require millions of cells and local grid refinement to reach comparable accuracy. ",
    "url": "https://arxiv.org/abs/2106.05452",
    "authors": [
      "Timo Koch",
      "Hanchuan Wu",
      "Martin Schneider"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2106.05459",
    "title": "Mode recovery in neural autoregressive sequence modeling",
    "abstract": "Despite its wide use, recent studies have revealed unexpected and undesirable properties of neural autoregressive sequence models trained with maximum likelihood, such as an unreasonably high affinity to short sequences after training and to infinitely long sequences at decoding time. We propose to study these phenomena by investigating how the modes, or local maxima, of a distribution are maintained throughout the full learning chain of the ground-truth, empirical, learned and decoding-induced distributions, via the newly proposed mode recovery cost. We design a tractable testbed where we build three types of ground-truth distributions: (1) an LSTM based structured distribution, (2) an unstructured distribution where probability of a sequence does not depend on its content, and (3) a product of these two which we call a semi-structured distribution. Our study reveals both expected and unexpected findings. First, starting with data collection, mode recovery cost strongly relies on the ground-truth distribution and is most costly with the semi-structured distribution. Second, after learning, mode recovery cost from the ground-truth distribution may increase or decrease compared to data collection, with the largest cost degradation occurring with the semi-structured ground-truth distribution. Finally, the ability of the decoding-induced distribution to recover modes from the learned distribution is highly impacted by the choices made earlier in the learning chain. We conclude that future research must consider the entire learning chain in order to fully understand the potentials and perils and to further improve neural autoregressive sequence models. ",
    "url": "https://arxiv.org/abs/2106.05459",
    "authors": [
      "Ilia Kulikov",
      "Sean Welleck",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.05657",
    "title": "Deep neural network loses attention to adversarial images",
    "abstract": "Adversarial algorithms have shown to be effective against neural networks for a variety of tasks. Some adversarial algorithms perturb all the pixels in the image minimally for the image classification task in image classification. In contrast, some algorithms perturb few pixels strongly. However, very little information is available regarding why these adversarial samples so diverse from each other exist. Recently, Vargas et al. showed that the existence of these adversarial samples might be due to conflicting saliency within the neural network. We test this hypothesis of conflicting saliency by analysing the Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM) of original and few different types of adversarial samples. We also analyse how different adversarial samples distort the attention of the neural network compared to original samples. We show that in the case of Pixel Attack, perturbed pixels either calls the network attention to themselves or divert the attention from them. Simultaneously, the Projected Gradient Descent Attack perturbs pixels so that intermediate layers inside the neural network lose attention for the correct class. We also show that both attacks affect the saliency map and activation maps differently. Thus, shedding light on why some defences successful against some attacks remain vulnerable against other attacks. We hope that this analysis will improve understanding of the existence and the effect of adversarial samples and enable the community to develop more robust neural networks. ",
    "url": "https://arxiv.org/abs/2106.05657",
    "authors": [
      "Shashank Kotyan",
      "Danilo Vasconcellos Vargas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05728",
    "title": "Face mask detection using convolution neural network",
    "abstract": "In the recent times, the Coronaviruses that are a big family of different viruses have become very common, contagious and dangerous to the whole human kind. It spreads human to human by exhaling the infection breath, which leaves droplets of the virus on different surface which is then inhaled by other person and catches the infection too. So it has become very important to protect ourselves and the people around us from this situation. We can take precautions such as social distancing, washing hands every two hours, using sanitizer, maintaining social distance and the most important wearing a mask. Public use of wearing a masks has become very common everywhere in the whole world now. From that the most affected and devastating condition is of India due to its extreme population in small area. This paper proposes a method to detect the face mask is put on or not for offices, or any other work place with a lot of people coming to work. We have used convolutional neural network for the same. The model is trained on a real world dataset and tested with live video streaming with a good accuracy. Further the accuracy of the model with different hyper parameters and multiple people at different distance and location of the frame is done. ",
    "url": "https://arxiv.org/abs/2106.05728",
    "authors": [
      "Riya Shah Rutva Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2106.05741",
    "title": "End-to-end lung nodule detection framework with model-based feature  projection block",
    "abstract": "This paper proposes novel end-to-end framework for detecting suspicious pulmonary nodules in chest CT scans. The method core idea is a new nodule segmentation architecture with a model-based feature projection block on three-dimensional convolutions. This block acts as a preliminary feature extractor for a two-dimensional U-Net-like convolutional network. Using the proposed approach along with an axial, coronal, and sagittal projection analysis makes it possible to abandon the widely used false positives reduction step. The proposed method achieves SOTA on LUNA2016 with 0.959 average sensitivity, and 0.936 sensitivity if the false-positive level per scan is 0.25. The paper describes the proposed approach and represents the experimental results on LUNA2016 as well as ablation studies. ",
    "url": "https://arxiv.org/abs/2106.05741",
    "authors": [
      "Ivan Drokin",
      "Elena Ericheva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05795",
    "title": "Transformed CNNs: recasting pre-trained convolutional layers with  self-attention",
    "abstract": "Vision Transformers (ViT) have recently emerged as a powerful alternative to convolutional networks (CNNs). Although hybrid models attempt to bridge the gap between these two architectures, the self-attention layers they rely on induce a strong computational bottleneck, especially at large spatial resolutions. In this work, we explore the idea of reducing the time spent training these layers by initializing them as convolutional layers. This enables us to transition smoothly from any pre-trained CNN to its functionally identical hybrid model, called Transformed CNN (T-CNN). With only 50 epochs of fine-tuning, the resulting T-CNNs demonstrate significant performance gains over the CNN (+2.2% top-1 on ImageNet-1k for a ResNet50-RS) as well as substantially improved robustness (+11% top-1 on ImageNet-C). We analyze the representations learnt by the T-CNN, providing deeper insights into the fruitful interplay between convolutions and self-attention. Finally, we experiment initializing the T-CNN from a partially trained CNN, and find that it reaches better performance than the corresponding hybrid model trained from scratch, while reducing training time. ",
    "url": "https://arxiv.org/abs/2106.05795",
    "authors": [
      "St\u00e9phane d'Ascoli",
      "Levent Sagun",
      "Giulio Biroli",
      "Ari Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05815",
    "title": "Italian Twitter semantic network during the Covid-19 epidemic",
    "abstract": "The Covid-19 pandemic has had a deep impact on the lives of the entire world population, inducing a participated societal debate. As in other contexts, the debate has been the subject of several d/misinformation campaigns; in a quite unprecedented fashion, however, the presence of false information has seriously put at risk the public health. In this sense, detecting the presence of malicious narratives and identifying the kinds of users that are more prone to spread them represent the first step to limit the persistence of the former ones. In the present paper we analyse the semantic network observed on Twitter during the first Italian lockdown (induced by the hashtags contained in approximately 1.5 millions tweets published between the 23rd of March 2020 and the 23rd of April 2020) and study the extent to which various discursive communities are exposed to d/misinformation arguments. As observed in other studies, the recovered discursive communities largely overlap with traditional political parties, even if the debated topics concern different facets of the management of the pandemic. Although the themes directly related to d/misinformation are a minority of those discussed within our semantic networks, their popularity is unevenly distributed among the various discursive communities. ",
    "url": "https://arxiv.org/abs/2106.05815",
    "authors": [
      "Mattia Mattei",
      "Guido Caldarelli",
      "Tiziano Squartini",
      "Fabio Saracco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2106.05824",
    "title": "Rare event estimation using stochastic spectral embedding",
    "abstract": "Estimating the probability of rare failure events is an essential step in the reliability assessment of engineering systems. Computing this failure probability for complex non-linear systems is challenging, and has recently spurred the development of active-learning reliability methods. These methods approximate the limit-state function (LSF) using surrogate models trained with a sequentially enriched set of model evaluations. A recently proposed method called stochastic spectral embedding (SSE) aims to improve the local approximation accuracy of global, spectral surrogate modelling techniques by sequentially embedding local residual expansions in subdomains of the input space. In this work we apply SSE to the LSF, giving rise to a stochastic spectral embedding-based reliability (SSER) method. The resulting partition of the input space decomposes the failure probability into a set of easy-to-compute domain-wise failure probabilities. We propose a set of modifications that tailor the algorithm to efficiently solve rare event estimation problems. These modifications include specialized refinement domain selection, partitioning and enrichment strategies. We showcase the algorithm performance on four benchmark problems of various dimensionality and complexity in the LSF. ",
    "url": "https://arxiv.org/abs/2106.05824",
    "authors": [
      "P.-R. Wagner",
      "S. Marelli",
      "I. Papaioannou",
      "D. Straub",
      "B. Sudret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.05836",
    "title": "EventDrop: data augmentation for event-based learning",
    "abstract": "The advantages of event-sensing over conventional sensors (e.g., higher dynamic range, lower time latency, and lower power consumption) have spurred research into machine learning for event data. Unsurprisingly, deep learning has emerged as a competitive methodology for learning with event sensors; in typical setups, discrete and asynchronous events are first converted into frame-like tensors on which standard deep networks can be applied. However, over-fitting remains a challenge, particularly since event datasets remain small relative to conventional datasets (e.g., ImageNet). In this paper, we introduce EventDrop, a new method for augmenting asynchronous event data to improve the generalization of deep models. By dropping events selected with various strategies, we are able to increase the diversity of training data (e.g., to simulate various levels of occlusion). From a practical perspective, EventDrop is simple to implement and computationally low-cost. Experiments on two event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can significantly improve the generalization performance across a variety of deep networks. ",
    "url": "https://arxiv.org/abs/2106.05836",
    "authors": [
      "Fuqiang Gu",
      "Weicong Sng",
      "Xuke Hu",
      "Fangwen Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.05932",
    "title": "Early-stopped neural networks are consistent",
    "abstract": "This work studies the behavior of neural networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms of calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. Lastly, while it is not shown that early stopping is necessary, it is shown that any univariate classifier satisfying a local interpolation property is necessarily inconsistent. ",
    "url": "https://arxiv.org/abs/2106.05932",
    "authors": [
      "Ziwei Ji",
      "Justin D. Li",
      "Matus Telgarsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.05408",
    "title": "Audiovisual transfer learning for audio tagging and sound event  detection",
    "abstract": "We study the merit of transfer learning for two sound recognition problems, i.e., audio tagging and sound event detection. Employing feature fusion, we adapt a baseline system utilizing only spectral acoustic inputs to also make use of pretrained auditory and visual features, extracted from networks built for different tasks and trained with external data. We perform experiments with these modified models on an audiovisual multi-label data set, of which the training partition contains a large number of unlabeled samples and a smaller amount of clips with weak annotations, indicating the clip-level presence of 10 sound categories without specifying the temporal boundaries of the active auditory events. For clip-based audio tagging, this transfer learning method grants marked improvements. Addition of the visual modality on top of audio also proves to be advantageous in this context. When it comes to generating transcriptions of audio recordings, the benefit of pretrained features depends on the requested temporal resolution: for coarse-grained sound event detection, their utility remains notable. But when more fine-grained predictions are required, performance gains are strongly reduced due to a mismatch between the problem at hand and the goals of the models from which the pretrained vectors were obtained. ",
    "url": "https://arxiv.org/abs/2106.05408",
    "authors": [
      "Wim Boes",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2106.05586",
    "title": "Data augmentation in Bayesian neural networks and the cold posterior  effect",
    "abstract": "Data augmentation is a highly effective approach for improving performance in deep neural networks. The standard view is that it creates an enlarged dataset by adding synthetic data, which raises a problem when combining it with Bayesian inference: how much data are we really conditioning on? This question is particularly relevant to recent observations linking data augmentation to the cold posterior effect. We investigate various principled ways of finding a log-likelihood for augmented datasets. Our approach prescribes augmenting the same underlying image multiple times, both at test and train-time, and averaging either the logits or the predictive probabilities. Empirically, we observe the best performance with averaging probabilities. While there are interactions with the cold posterior effect, neither averaging logits or averaging probabilities eliminates it. ",
    "url": "https://arxiv.org/abs/2106.05586",
    "authors": [
      "Seth Nabarro",
      "Stoil Ganev",
      "Adri\u00e0 Garriga-Alonso",
      "Vincent Fortuin",
      "Mark van der Wilk",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.05900",
    "title": "Classical algorithms and quantum limitations for maximum cut on  high-girth graphs",
    "abstract": "We study the performance of local quantum algorithms such as the Quantum Approximate Optimization Algorithm (QAOA) for the maximum cut problem, and their relationship to that of classical algorithms. (1) We prove that every (quantum or classical) one-local algorithm achieves on $D$-regular graphs of girth $> 5$ a maximum cut of at most $1/2 + C/\\sqrt{D}$ for $C=1/\\sqrt{2} \\approx 0.7071$. This is the first such result showing that one-local algorithms achieve a value bounded away from the true optimum for random graphs, which is $1/2 + P_*/\\sqrt{D} + o(1/\\sqrt{D})$ for $P_* \\approx 0.7632$. (2) We show that there is a classical $k$-local algorithm that achieves a value of $1/2 + C/\\sqrt{D} - O(1/\\sqrt{k})$ for $D$-regular graphs of girth $> 2k+1$, where $C = 2/\\pi \\approx 0.6366$. This is an algorithmic version of the existential bound of Lyons and is related to the algorithm of Aizenman, Lebowitz, and Ruelle (ALR) for the Sherrington-Kirkpatrick model. This bound is better than that achieved by the one-local and two-local versions of QAOA on high-girth graphs. (3) Through computational experiments, we give evidence that the ALR algorithm achieves better performance than constant-locality QAOA for random $D$-regular graphs, as well as other natural instances, including graphs that do have short cycles. Our experimental work suggests that it could be possible to extend beyond our theoretical constraints. This points at the tantalizing possibility that $O(1)$-local quantum maximum-cut algorithms might be *pointwise dominated* by polynomial-time classical algorithms, in the sense that there is a classical algorithm outputting cuts of equal or better quality *on every possible instance*. This is in contrast to the evidence that polynomial-time algorithms cannot simulate the probability distributions induced by local quantum algorithms. ",
    "url": "https://arxiv.org/abs/2106.05900",
    "authors": [
      "Boaz Barak",
      "Kunal Marwaha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2003.13827",
    "title": "Co-occurrence of deep convolutional features for image search",
    "abstract": " Title: Co-occurrence of deep convolutional features for image search ",
    "url": "https://arxiv.org/abs/2003.13827",
    "authors": [
      "J.I.Forcen",
      "Miguel Pagola",
      "Edurne Barrenechea",
      "Humberto Bustince"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2011.04611",
    "title": "On the hardness of code equivalence problems in rank metric",
    "abstract": " Title: On the hardness of code equivalence problems in rank metric ",
    "url": "https://arxiv.org/abs/2011.04611",
    "authors": [
      "Alain Couvreur",
      "Thomas Debris-Alazard",
      "Philippe Gaborit"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Geometry (cs.CG)",
      "Rings and Algebras (math.RA)"
    ]
  },
  {
    "id": "arXiv:2102.11636",
    "title": "Using a deep neural network to predict the motion of under-resolved  triangular rigid bodies in an incompressible flow",
    "abstract": " Title: Using a deep neural network to predict the motion of under-resolved  triangular rigid bodies in an incompressible flow ",
    "url": "https://arxiv.org/abs/2102.11636",
    "authors": [
      "Henry von Wahl",
      "Thomas Richter"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2102.11742",
    "title": "Classifying high-dimensional Gaussian mixtures: Where kernel methods  fail and neural networks succeed",
    "abstract": " Comments: The accompanying code for this paper is available at this https URL ",
    "url": "https://arxiv.org/abs/2102.11742",
    "authors": [
      "Maria Refinetti",
      "Sebastian Goldt",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.03404",
    "title": "ResMLP: Feedforward networks for image classification with  data-efficient training",
    "abstract": " Title: ResMLP: Feedforward networks for image classification with  data-efficient training ",
    "url": "https://arxiv.org/abs/2105.03404",
    "authors": [
      "Hugo Touvron",
      "Piotr Bojanowski",
      "Mathilde Caron",
      "Matthieu Cord",
      "Alaaeldin El-Nouby",
      "Edouard Grave",
      "Gautier Izacard",
      "Armand Joulin",
      "Gabriel Synnaeve",
      "Jakob Verbeek",
      "Herv\u00e9 J\u00e9gou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]