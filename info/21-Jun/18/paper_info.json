[
  {
    "id": "arXiv:2106.09021",
    "title": "On the training of sparse and dense deep neural networks: less  parameters, same performance",
    "abstract": "Deep neural networks can be trained in reciprocal space, by acting on the eigenvalues and eigenvectors of suitable transfer operators in direct space. Adjusting the eigenvalues, while freezing the eigenvectors, yields a substantial compression of the parameter space. This latter scales by definition with the number of computing neurons. The classification scores, as measured by the displayed accuracy, are however inferior to those attained when the learning is carried in direct space, for an identical architecture and by employing the full set of trainable parameters (with a quadratic dependence on the size of neighbor layers). In this Letter, we propose a variant of the spectral learning method as appeared in Giambagli et al {Nat. Comm.} 2021, which leverages on two sets of eigenvalues, for each mapping between adjacent layers. The eigenvalues act as veritable knobs which can be freely tuned so as to (i) enhance, or alternatively silence, the contribution of the input nodes, (ii) modulate the excitability of the receiving nodes with a mechanism which we interpret as the artificial analogue of the homeostatic plasticity. The number of trainable parameters is still a linear function of the network size, but the performances of the trained device gets much closer to those obtained via conventional algorithms, these latter requiring however a considerably heavier computational cost. The residual gap between conventional and spectral trainings can be eventually filled by employing a suitable decomposition for the non trivial block of the eigenvectors matrix. Each spectral parameter reflects back on the whole set of inter-nodes weights, an attribute which we shall effectively exploit to yield sparse networks with stunning classification abilities, as compared to their homologues trained with conventional means. ",
    "url": "https://arxiv.org/abs/2106.09021",
    "authors": [
      "Lorenzo Chicchi",
      "Lorenzo Giambagli",
      "Lorenzo Buffoni",
      "Timoteo Carletti",
      "Marco Ciavarella",
      "Duccio Fanelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2106.09260",
    "title": "Joining datasets via data augmentation in the label space for neural  networks",
    "abstract": "Most, if not all, modern deep learning systems restrict themselves to a single dataset for neural network training and inference. In this article, we are interested in systematic ways to join datasets that are made of similar purposes. Unlike previous published works that ubiquitously conduct the dataset joining in the uninterpretable latent vectorial space, the core to our method is an augmentation procedure in the label space. The primary challenge to address the label space for dataset joining is the discrepancy between labels: non-overlapping label annotation sets, different labeling granularity or hierarchy and etc. Notably we propose a new technique leveraging artificially created knowledge graph, recurrent neural networks and policy gradient that successfully achieve the dataset joining in the label space. Empirical results on both image and text classification justify the validity of our approach. ",
    "url": "https://arxiv.org/abs/2106.09260",
    "authors": [
      "Jake Zhao",
      "Mingfeng Ou",
      "Linji Xue",
      "Yunkai Cui",
      "Sai Wu",
      "Gang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.09289",
    "title": "MHNF: Multi-hop Heterogeneous Neighborhood information Fusion graph  representation learning",
    "abstract": "Attention mechanism enables the Graph Neural Networks(GNNs) to learn the attention weights between the target node and its one-hop neighbors, the performance is further improved. However, the most existing GNNs are oriented to homogeneous graphs and each layer can only aggregate the information of one-hop neighbors. Stacking multi-layer networks will introduce a lot of noise and easily lead to over smoothing. We propose a Multi-hop Heterogeneous Neighborhood information Fusion graph representation learning method (MHNF). Specifically, we first propose a hybrid metapath autonomous extraction model to efficiently extract multi-hop hybrid neighbors. Then, we propose a hop-level heterogeneous Information aggregation model, which selectively aggregates different-hop neighborhood information within the same hybrid metapath. Finally, a hierarchical semantic attention fusion model (HSAF) is proposed, which can efficiently integrate different-hop and different-path neighborhood information respectively. This paper can solve the problem of aggregating the multi-hop neighborhood information and can learn hybrid metapaths for target task, reducing the limitation of manually specifying metapaths. In addition, HSAF can extract the internal node information of the metapaths and better integrate the semantic information of different levels. Experimental results on real datasets show that MHNF is superior to state-of-the-art methods in node classification and clustering tasks (10.94% - 69.09% and 11.58% - 394.93% relative improvement on average, respectively). ",
    "url": "https://arxiv.org/abs/2106.09289",
    "authors": [
      "Dongjie Zhu",
      "Yundong Sun",
      "Haiwen Du",
      "Zhaoshuo Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.09326",
    "title": "Towards bio-inspired unsupervised representation learning for indoor  aerial navigation",
    "abstract": "Aerial navigation in GPS-denied, indoor environments, is still an open challenge. Drones can perceive the environment from a richer set of viewpoints, while having more stringent compute and energy constraints than other autonomous platforms. To tackle that problem, this research displays a biologically inspired deep-learning algorithm for simultaneous localization and mapping (SLAM) and its application in a drone navigation system. We propose an unsupervised representation learning method that yields low-dimensional latent state descriptors, that mitigates the sensitivity to perceptual aliasing, and works on power-efficient, embedded hardware. The designed algorithm is evaluated on a dataset collected in an indoor warehouse environment, and initial results show the feasibility for robust indoor aerial navigation. ",
    "url": "https://arxiv.org/abs/2106.09326",
    "authors": [
      "Ni Wang",
      "Ozan Catal",
      "Tim Verbelen",
      "Matthias Hartmann",
      "Bart Dhoedt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.09350",
    "title": "Identifiability of AMP chain graph models",
    "abstract": "We study identifiability of Andersson-Madigan-Perlman (AMP) chain graph models, which are a common generalization of linear structural equation models and Gaussian graphical models. AMP models are described by DAGs on chain components which themselves are undirected graphs. For a known chain component decomposition, we show that the DAG on the chain components is identifiable if the determinants of the residual covariance matrices of the chain components are monotone non-decreasing in topological order. This condition extends the equal variance identifiability criterion for Bayes nets, and it can be generalized from determinants to any super-additive function on positive semidefinite matrices. When the component decomposition is unknown, we describe conditions that allow recovery of the full structure using a polynomial time algorithm based on submodular function minimization. We also conduct experiments comparing our algorithm's performance against existing baselines. ",
    "url": "https://arxiv.org/abs/2106.09350",
    "authors": [
      "Yuhao Wang",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.09408",
    "title": "Predicting cognitive scores with graph neural networks through sample  selection learning",
    "abstract": "Analyzing the relation between intelligence and neural activity is of the utmost importance in understanding the working principles of the human brain in health and disease. In existing literature, functional brain connectomes have been used successfully to predict cognitive measures such as intelligence quotient (IQ) scores in both healthy and disordered cohorts using machine learning models. However, existing methods resort to flattening the brain connectome (i.e., graph) through vectorization which overlooks its topological properties. To address this limitation and inspired from the emerging graph neural networks (GNNs), we design a novel regression GNN model (namely RegGNN) for predicting IQ scores from brain connectivity. On top of that, we introduce a novel, fully modular sample selection method to select the best samples to learn from for our target prediction task. However, since such deep learning architectures are computationally expensive to train, we further propose a \\emph{learning-based sample selection} method that learns how to choose the training samples with the highest expected predictive power on unseen samples. For this, we capitalize on the fact that connectomes (i.e., their adjacency matrices) lie in the symmetric positive definite (SPD) matrix cone. Our results on full-scale and verbal IQ prediction outperforms comparison methods in autism spectrum disorder cohorts and achieves a competitive performance for neurotypical subjects using 3-fold cross-validation. Furthermore, we show that our sample selection approach generalizes to other learning-based methods, which shows its usefulness beyond our GNN architecture. ",
    "url": "https://arxiv.org/abs/2106.09408",
    "authors": [
      "Martin Hanik",
      "Mehmet Arif Demirta\u015f",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2106.09445",
    "title": "A structure-preserving surrogate model for the closure of the moment  system of the Boltzmann equation using convex deep neural networks",
    "abstract": "Direct simulation of physical processes on a kinetic level is prohibitively expensive in aerospace applications due to the extremely high dimension of the solution spaces. In this paper, we consider the moment system of the Boltzmann equation, which projects the kinetic physics onto the hydrodynamic scale. The unclosed moment system can be solved in conjunction with the entropy closure strategy. Using an entropy closure provides structural benefits to the physical system of partial differential equations. Usually computing such closure of the system spends the majority of the total computational cost, since one needs to solve an ill-conditioned constrained optimization problem. Therefore, we build a neural network surrogate model to close the moment system, which preserves the structural properties of the system by design, but reduces the computational cost significantly. Numerical experiments are conducted to illustrate the performance of the current method in comparison to the traditional closure. ",
    "url": "https://arxiv.org/abs/2106.09445",
    "authors": [
      "Steffen Schotth\u00f6fer",
      "Tianbai Xiao",
      "Martin Frank",
      "Cory D. Hauck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2106.09564",
    "title": "Knowledge distillation from multi-modal to mono-modal segmentation  networks",
    "abstract": "The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher's inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy. ",
    "url": "https://arxiv.org/abs/2106.09564",
    "authors": [
      "Minhao Hu",
      "Matthis Maillard",
      "Ya Zhang",
      "Tommaso Ciceri",
      "Giammarco La Barbera",
      "Isabelle Bloch",
      "Pietro Gori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.09589",
    "title": "Classifying vaccine sentiment tweets by modelling domain-specific  representation and commonsense knowledge into context-aware attentive GRU",
    "abstract": "Vaccines are an important public health measure, but vaccine hesitancy and refusal can create clusters of low vaccine coverage and reduce the effectiveness of vaccination programs. Social media provides an opportunity to estimate emerging risks to vaccine acceptance by including geographical location and detailing vaccine-related concerns. Methods for classifying social media posts, such as vaccine-related tweets, use language models (LMs) trained on general domain text. However, challenges to measuring vaccine sentiment at scale arise from the absence of tonal stress and gestural cues and may not always have additional information about the user, e.g., past tweets or social connections. Another challenge in LMs is the lack of commonsense knowledge that are apparent in users metadata, i.e., emoticons, positive and negative words etc. In this study, to classify vaccine sentiment tweets with limited information, we present a novel end-to-end framework consisting of interconnected components that use domain-specific LM trained on vaccine-related tweets and models commonsense knowledge into a bidirectional gated recurrent network (CK-BiGRU) with context-aware attention. We further leverage syntactical, user metadata and sentiment information to capture the sentiment of a tweet. We experimented using two popular vaccine-related Twitter datasets and demonstrate that our proposed approach outperforms state-of-the-art models in identifying pro-vaccine, anti-vaccine and neutral tweets. ",
    "url": "https://arxiv.org/abs/2106.09589",
    "authors": [
      "Usman Naseem",
      "Matloob Khushi",
      "Jinman Kim",
      "Adam G. Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2106.09693",
    "title": "Orthogonal-Pad\u00e9 Activation Functions: Trainable Activation functions  for smooth and faster convergence in deep networks",
    "abstract": "We have proposed orthogonal-Pad\\'e activation functions, which are trainable activation functions and show that they have faster learning capability and improves the accuracy in standard deep learning datasets and models. Based on our experiments, we have found two best candidates out of six orthogonal-Pad\\'e activations, which we call safe Hermite-Pade (HP) activation functions, namely HP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1 accuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75% respectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset top-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by 2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in Efficientnet B0. ",
    "url": "https://arxiv.org/abs/2106.09693",
    "authors": [
      "Koushik Biswas",
      "Shilpak Banerjee",
      "Ashish Kumar Pandey"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.09068",
    "title": "Extracting real social interactions from social media: a debate of  COVID-19 policies in Mexico",
    "abstract": "A study of the dynamical formation of networks of friends and enemies in social media, in this case Twitter, is presented. We characterise the single node properties of such networks, as the clustering coefficient and the degree, to investigate the structure of links. The results indicate that the network is made from three kinds of nodes: one with high clustering coefficient but very small degree, a second group has zero clustering coefficient with variable degree, and finally, a third group in which the clustering coefficient as a function of the degree decays as a power law. This third group represents $\\sim2\\%$ of the nodes and is characteristic of dynamical networks with feedback. This part of the lattice seemingly represents strongly interacting friends in a real social network. ",
    "url": "https://arxiv.org/abs/2106.09068",
    "authors": [
      "Alberto Garc\u00eda-Rodr\u00edguez",
      "Tzipe Govezensky",
      "Carlos Gershenson",
      "Gerardo G. Naumis",
      "Rafael A. Barrio"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.09303",
    "title": "A Multi-task convolutional neural network for blind stereoscopic image  quality assessment using naturalness analysis",
    "abstract": "This paper addresses the problem of blind stereoscopic image quality assessment (NR-SIQA) using a new multi-task deep learning based-method. In the field of stereoscopic vision, the information is fairly distributed between the left and right views as well as the binocular phenomenon. In this work, we propose to integrate these characteristics to estimate the quality of stereoscopic images without reference through a convolutional neural network. Our method is based on two main tasks: the first task predicts naturalness analysis based features adapted to stereo images, while the second task predicts the quality of such images. The former, so-called auxiliary task, aims to find more robust and relevant features to improve the quality prediction. To do this, we compute naturalness-based features using a Natural Scene Statistics (NSS) model in the complex wavelet domain. It allows to capture the statistical dependency between pairs of the stereoscopic images. Experiments are conducted on the well known LIVE PHASE I and LIVE PHASE II databases. The results obtained show the relevance of our method when comparing with those of the state-of-the-art. Our code is available online on \\url{https://github.com/Bourbia-Salima/multitask-cnn-nrsiqa_2021}. ",
    "url": "https://arxiv.org/abs/2106.09303",
    "authors": [
      "Salima Bourbia",
      "Ayoub Karine",
      "Aladine Chetouani",
      "Mohammed El Hassouni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.09702",
    "title": "Spectral goodness-of-fit tests for complete and partial network data",
    "abstract": "Networks describe the, often complex, relationships between individual actors. In this work, we address the question of how to determine whether a parametric model, such as a stochastic block model or latent space model, fits a dataset well and will extrapolate to similar data. We use recent results in random matrix theory to derive a general goodness-of-fit test for dyadic data. We show that our method, when applied to a specific model of interest, provides an straightforward, computationally fast way of selecting parameters in a number of commonly used network models. For example, we show how to select the dimension of the latent space in latent space models. Unlike other network goodness-of-fit methods, our general approach does not require simulating from a candidate parametric model, which can be cumbersome with large graphs, and eliminates the need to choose a particular set of statistics on the graph for comparison. It also allows us to perform goodness-of-fit tests on partial network data, such as Aggregated Relational Data. We show with simulations that our method performs well in many situations of interest. We analyze several empirically relevant networks and show that our method leads to improved community detection algorithms. R code to implement our method is available on Github. ",
    "url": "https://arxiv.org/abs/2106.09702",
    "authors": [
      "Shane Lubold",
      "Bolun Liu",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.10411",
    "title": "Sparse bottleneck neural networks for exploratory non-linear  visualization of Patch-seq data",
    "abstract": " Comments: 15 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2006.10411",
    "authors": [
      "Yves Bernaerts",
      "Philipp Berens",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.13051",
    "title": "Interpretable security analysis of cancellable biometrics using  constrained-optimized similarity-based attack",
    "abstract": " Title: Interpretable security analysis of cancellable biometrics using  constrained-optimized similarity-based attack ",
    "url": "https://arxiv.org/abs/2006.13051",
    "authors": [
      "Hanrui Wang",
      "Xingbo Dong",
      "Zhe Jin",
      "Andrew Beng Jin Teoh",
      "Massimo Tistarelli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2008.07838",
    "title": "Improving adversarial robustness of deep neural networks by using  semantic information",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2008.07838",
    "authors": [
      "Lina Wang",
      "Rui Tang",
      "Yawei Yue",
      "Xingshu Chen",
      "Wei Wang",
      "Yi Zhu",
      "Xuemei Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.06818",
    "title": "A new iterative method for solving a class of two-by-two block complex  linear systems",
    "abstract": " Comments: 17 Pages, Revised, Submitted ",
    "url": "https://arxiv.org/abs/2011.06818",
    "authors": [
      "Davod Khojasteh Salkuyeh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2101.05404",
    "title": "Machine-learning enhanced dark soliton detection in Bose-Einstein  condensates",
    "abstract": " Comments: 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2101.05404",
    "authors": [
      "Shangjie Guo",
      "Amilson R. Fritsch",
      "Craig Greenberg",
      "I. B. Spielman",
      "Justyna P. Zwolak"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2101.10533",
    "title": "Numerical aspects of shot noise representation of infinitely divisible  laws and related processes",
    "abstract": " Comments: 37 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2101.10533",
    "authors": [
      "Sida Yuan",
      "Reiichiro Kawai"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.02469",
    "title": "Can convolutional ResNets approximately preserve input distances? A  frequency analysis perspective",
    "abstract": " Comments: Main paper 10 pages including references, appendix 10 pages. 7 figures and 6 tables including appendix ",
    "url": "https://arxiv.org/abs/2106.02469",
    "authors": [
      "Lewis Smith",
      "Joost van Amersfoort",
      "Haiwen Huang",
      "Stephen Roberts",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]