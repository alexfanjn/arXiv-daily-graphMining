[
  {
    "id": "arXiv:2106.00742",
    "title": "A systematic review of Hate Speech automatic detection using Natural  Language Processing",
    "abstract": "With the multiplication of social media platforms, which offer anonymity, easy access and online community formation, and online debate, the issue of hate speech detection and tracking becomes a growing challenge to society, individual, policy-makers and researchers. Despite efforts for leveraging automatic techniques for automatic detection and monitoring, their performances are still far from satisfactory, which constantly calls for future research on the issue. This paper provides a systematic review of literature in this field, with a focus on natural language processing and deep learning technologies, highlighting the terminology, processing pipeline, core methods employed, with a focal point on deep learning architecture. From a methodological perspective, we adopt PRISMA guideline of systematic review of the last 10 years literature from ACM Digital Library and Google Scholar. In the sequel, existing surveys, limitations, and future research directions are extensively discussed. ",
    "url": "https://arxiv.org/abs/2106.00742",
    "authors": [
      "Md Saroar Jahan",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2106.00776",
    "title": "Risk-sensitive safety analysis via state-space augmentation",
    "abstract": "Risk-sensitive safety analysis is a safety analysis method for stochastic systems on Borel spaces that uses a risk functional from finance called Conditional Value-at-Risk (CVaR). CVaR provides a particularly expressive way to quantify the safety of a control system, as it represents the average cost in a fraction of worst cases. In prior work, the notion of a risk-sensitive safe set was defined in terms of a non-standard optimal control problem, in which a maximum cost is assessed via CVaR. Here, we provide a method to compute risk-sensitive safe sets exactly in principle by utilizing a state-space augmentation technique. In addition, we prove the existence of an optimal pre-commitment policy under a measurable selection condition. The proposed framework assumes continuous system dynamics and cost functions, but is otherwise flexible. In particular, it can accommodate probabilistic control policies, fairly general disturbance distributions, and control-dependent, non-monotonic, and non-convex stage costs. We demonstrate how risk-sensitive safety analysis is useful for a stormwater infrastructure application. Our numerical examples are inspired by current challenges that cities face in managing precipitation uncertainty. ",
    "url": "https://arxiv.org/abs/2106.00776",
    "authors": [
      "Margaret P. Chapman",
      "Michael Fauss",
      "H. Vincent Poor",
      "Kevin M. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.00799",
    "title": "Multi-task fully convolutional network for tree species mapping in dense  forests using small training hyperspectral data",
    "abstract": "This work proposes a multi-task fully convolutional architecture for tree species mapping in dense forests from sparse and scarce polygon-level annotations using hyperspectral UAV-borne data. Our model implements a partial loss function that enables dense tree semantic labeling outcomes from non-dense training samples, and a distance regression complementary task that enforces tree crown boundary constraints and substantially improves the model performance. Our multi-task architecture uses a shared backbone network that learns common representations for both tasks and two task-specific decoders, one for the semantic segmentation output and one for the distance map regression. We report that introducing the complementary task boosts the semantic segmentation performance compared to the single-task counterpart in up to 10% reaching an overall F1 score of 87.5% and an overall accuracy of 85.9%, achieving state-of-art performance for tree species classification in tropical forests. ",
    "url": "https://arxiv.org/abs/2106.00799",
    "authors": [
      "Laura Elena Cu\u00e9 La Rosa",
      "Camile Sothe",
      "Raul Queiroz Feitosa",
      "Cl\u00e1udia Maria de Almeida",
      "Marcos Benedito Schimalski",
      "Dario Augusto Borges Oliveira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.00827",
    "title": "Weighting vectors for machine learning: numerical harmonic analysis  applied to boundary detection",
    "abstract": "Metric space magnitude, an active field of research in algebraic topology, is a scalar quantity that summarizes the effective number of distinct points that live in a general metric space. The {\\em weighting vector} is a closely-related concept that captures, in a nontrivial way, much of the underlying geometry of the original metric space. Recent work has demonstrated that when the metric space is Euclidean, the weighting vector serves as an effective tool for boundary detection. We recast this result and show the weighting vector may be viewed as a solution to a kernelized SVM. As one consequence, we apply this new insight to the task of outlier detection, and we demonstrate performance that is competitive or exceeds performance of state-of-the-art techniques on benchmark data sets. Under mild assumptions, we show the weighting vector, which has computational cost of matrix inversion, can be efficiently approximated in linear time. We show how nearest neighbor methods can approximate solutions to the minimization problems defined by SVMs. ",
    "url": "https://arxiv.org/abs/2106.00827",
    "authors": [
      "Eric Bunch",
      "Jeffery Kline",
      "Daniel Dickinson",
      "Suhaas Bhat",
      "Glenn Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.01001",
    "title": "Warming-up recurrent neural networks to maximize reachable  multi-stability greatly improves learning",
    "abstract": "Training recurrent neural networks is known to be difficult when time dependencies become long. Consequently, training standard gated cells such as gated recurrent units and long-short term memory on benchmarks where long-term memory is required remains an arduous task. In this work, we propose a general way to initialize any recurrent network connectivity through a process called \"warm-up\" to improve its capability to learn arbitrarily long time dependencies. This initialization process is designed to maximize network reachable multi-stability, i.e. the number of attractors within the network that can be reached through relevant input trajectories. Warming-up is performed before training, using stochastic gradient descent on a specifically designed loss. We show that warming-up greatly improves recurrent neural network performance on long-term memory benchmarks for multiple recurrent cell types, but can sometimes impede precision. We therefore introduce a parallel recurrent network structure with partial warm-up that is shown to greatly improve learning on long time-series while maintaining high levels of precision. This approach provides a general framework for improving learning abilities of any recurrent cell type when long-term memory is required. ",
    "url": "https://arxiv.org/abs/2106.01001",
    "authors": [
      "Nicolas Vecoven",
      "Damien Ernst",
      "Guillaume Drion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01086",
    "title": "Learning to schedule job-shop problems: Representation and policy  learning using graph neural network and reinforcement learning",
    "abstract": "We propose a framework to learn to schedule a job-shop problem (JSSP) using a graph neural network (GNN) and reinforcement learning (RL). We formulate the scheduling process of JSSP as a sequential decision-making problem with graph representation of the state to consider the structure of JSSP. In solving the formulated problem, the proposed framework employs a GNN to learn that node features that embed the spatial structure of the JSSP represented as a graph (representation learning) and derive the optimum scheduling policy that maps the embedded node features to the best scheduling action (policy learning). We employ Proximal Policy Optimization (PPO) based RL strategy to train these two modules in an end-to-end fashion. We empirically demonstrate that the GNN scheduler, due to its superb generalization capability, outperforms practically favored dispatching rules and RL-based schedulers on various benchmark JSSP. We also confirmed that the proposed framework learns a transferable scheduling policy that can be employed to schedule a completely new JSSP (in terms of size and parameters) without further training. ",
    "url": "https://arxiv.org/abs/2106.01086",
    "authors": [
      "Junyoung Park",
      "Jaehyeong Chun",
      "Sang Hun Kim",
      "Youngkook Kim",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2106.01110",
    "title": "A robust controller for stable 3D pinching using tactile sensing",
    "abstract": "This paper proposes a controller for stable grasping of unknown-shaped objects by two robotic fingers with tactile fingertips. The grasp is stabilised by rolling the fingertips on the contact surface and applying a desired grasping force to reach an equilibrium state. The validation is both in simulation and on a fully-actuated robot hand (the Shadow Modular Grasper) fitted with custom-built optical tactile sensors (based on the BRL TacTip). The controller requires the orientations of the contact surfaces, which are estimated by regressing a deep convolutional neural network over the tactile images. Overall, the grasp system is demonstrated to achieve stable equilibrium poses on a range of objects varying in shape and softness, with the system being robust to perturbations and measurement errors. This approach also has promise to extend beyond grasping to stable in-hand object manipulation with multiple fingers. ",
    "url": "https://arxiv.org/abs/2106.01110",
    "authors": [
      "Efi Psomopoulou",
      "Nicholas Pestell",
      "Fotios Papadopoulos",
      "John Lloyd",
      "Zoe Doulgeri",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.01272",
    "title": "Grasp stability prediction with time series data based on STFT and LSTM",
    "abstract": "With an increasing demand for robots, robotic grasping will has a more important role in future applications. This paper takes grasp stability prediction as the key technology for grasping and tries to solve the problem with time series data inputs including the force and pressure data. Widely applied to more fields to predict unstable grasping with time series data, algorithms can significantly promote the application of artificial intelligence in traditional industries. This research investigates models that combine short-time Fourier transform (STFT) and long short-term memory (LSTM) and then tested generalizability with dexterous hand and suction cup gripper. The experiments suggest good results for grasp stability prediction with the force data and the generalized results in the pressure data. Among the 4 models, (Data + STFT) & LSTM delivers the best performance. We plan to perform more work on grasp stability prediction, generalize the findings to different types of sensors, and apply the grasp stability prediction in more grasping use cases in real life. ",
    "url": "https://arxiv.org/abs/2106.01272",
    "authors": [
      "Tao Wang",
      "Frank Kirchner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.01277",
    "title": "Data augmentation and pre-trained networks for extremely low data  regimes unsupervised visual inspection",
    "abstract": "The use of deep features coming from pre-trained neural networks for unsupervised anomaly detection purposes has recently gathered momentum in the computer vision field. In particular, industrial inspection applications can take advantage of such features, as demonstrated by the multiple successes of related methods on the MVTec Anomaly Detection (MVTec AD) dataset. These methods make use of neural networks pre-trained on auxiliary classification tasks such as ImageNet. However, to our knowledge, no comparative study of robustness to the low data regimes between these approaches has been conducted yet. For quality inspection applications, the handling of limited sample sizes may be crucial as large quantities of images are not available for small series. In this work, we aim to compare three approaches based on deep pre-trained features when varying the quantity of available data in MVTec AD: KNN, Mahalanobis, and PaDiM. We show that although these methods are mostly robust to small sample sizes, they still can benefit greatly from using data augmentation in the original image space, which allows to deal with very small production runs. ",
    "url": "https://arxiv.org/abs/2106.01277",
    "authors": [
      "Pierre Gutierrez",
      "Antoine Cordier",
      "Tha\u00efs Caldeira",
      "Th\u00e9ophile Sautory"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2104.08135",
    "title": "Sharp bounds for the number of regions of maxout networks and vertices  of Minkowski sums",
    "abstract": "We present results on the number of linear regions of the functions that can be represented by artificial feedforward neural networks with maxout units. A rank-k maxout unit is a function computing the maximum of $k$ linear functions. For networks with a single layer of maxout units, the linear regions correspond to the upper vertices of a Minkowski sum of polytopes. We obtain face counting formulas in terms of the intersection posets of tropical hypersurfaces or the number of upper faces of partial Minkowski sums, along with explicit sharp upper bounds for the number of regions for any input dimension, any number of units, and any ranks, in the cases with and without biases. Based on these results we also obtain asymptotically sharp upper bounds for networks with multiple layers. ",
    "url": "https://arxiv.org/abs/2104.08135",
    "authors": [
      "Guido Mont\u00fafar",
      "Yue Ren",
      "Leon Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.00757",
    "title": "Neural message passing for joint paratope-epitope prediction",
    "abstract": "Antibodies are proteins in the immune system which bind to antigens to detect and neutralise them. The binding sites in an antibody-antigen interaction are known as the paratope and epitope, respectively, and the prediction of these regions is key to vaccine and synthetic antibody development. Contrary to prior art, we argue that paratope and epitope predictors require asymmetric treatment, and propose distinct neural message passing architectures that are geared towards the specific aspects of paratope and epitope prediction, respectively. We obtain significant improvements on both tasks, setting the new state-of-the-art and recovering favourable qualitative predictions on antigens of relevance to COVID-19. ",
    "url": "https://arxiv.org/abs/2106.00757",
    "authors": [
      "Alice Del Vecchio",
      "Andreea Deac",
      "Pietro Li\u00f2",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2106.01138",
    "title": "Learning neural network potentials from experimental data via  Differentiable Trajectory Reweighting",
    "abstract": "In molecular dynamics (MD), neural network (NN) potentials trained bottom-up on quantum mechanical data have seen tremendous success recently. Top-down approaches that learn NN potentials directly from experimental data have received less attention, typically facing numerical and computational challenges when backpropagating through MD simulations. We present the Differentiable Trajectory Reweighting (DiffTRe) method, which bypasses differentiation through the MD simulation for time-independent observables. Leveraging thermodynamic perturbation theory, we avoid exploding gradients and achieve around 2 orders of magnitude speed-up in gradient computation for top-down learning. We show effectiveness of DiffTRe in learning NN potentials for an atomistic model of diamond and a coarse-grained model of water based on diverse experimental observables including thermodynamic, structural and mechanical properties. Importantly, DiffTRe also generalizes bottom-up structural coarse-graining methods such as iterative Boltzmann inversion to arbitrary potentials. The presented method constitutes an important milestone towards enriching NN potentials with experimental data, particularly when accurate bottom-up data is unavailable. ",
    "url": "https://arxiv.org/abs/2106.01138",
    "authors": [
      "Stephan Thaler",
      "Julija Zavadlav"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2106.01202",
    "title": "Framing RNN as a kernel method: A neural ODE approach",
    "abstract": "Building on the interpretation of a recurrent neural network (RNN) as a continuous-time neural differential equation, we show, under appropriate conditions, that the solution of a RNN can be viewed as a linear function of a specific feature set of the input sequence, known as the signature. This connection allows us to frame a RNN as a kernel method in a suitable reproducing kernel Hilbert space. As a consequence, we obtain theoretical guarantees on generalization and stability for a large class of recurrent networks. Our results are illustrated on simulated datasets. ",
    "url": "https://arxiv.org/abs/2106.01202",
    "authors": [
      "Adeline Fermanian",
      "Pierre Marion",
      "Jean-Philippe Vert",
      "G\u00e9rard Biau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.01282",
    "title": "Spectral embedding for dynamic networks with stability guarantees",
    "abstract": "We consider the problem of embedding a dynamic network, to obtain time-evolving vector representations of each node, which can then be used to describe the changes in behaviour of a single node, one or more communities, or the entire graph. Given this open-ended remit, we wish to guarantee stability in the spatio-temporal positioning of the nodes: assigning the same position, up to noise, to nodes behaving similarly at a given time (cross-sectional stability) and a constant position, up to noise, to a single node behaving similarly across different times (longitudinal stability). These properties are defined formally within a generic dynamic latent position model. By showing how this model can be recast as a multilayer random dot product graph, we demonstrate that unfolded adjacency spectral embedding satisfies both stability conditions, allowing, for example, spatio-temporal clustering under the dynamic stochastic block model. We also show how alternative methods, such as omnibus, independent or time-averaged spectral embedding, lack one or the other form of stability. ",
    "url": "https://arxiv.org/abs/2106.01282",
    "authors": [
      "Ian Gallagher",
      "Andrew Jones",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.06716",
    "title": "Predicting trends in the quality of state-of-the-art neural networks  without access to training or testing data",
    "abstract": " Comments: 35 pages, 8 tables, 17 figures. To appear in Nature Communications ",
    "url": "https://arxiv.org/abs/2002.06716",
    "authors": [
      "Charles H. Martin",
      "Tongsu",
      "Peng",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.05707",
    "title": "Low-resource expressive text-to-speech using data augmentation",
    "abstract": " Title: Low-resource expressive text-to-speech using data augmentation ",
    "url": "https://arxiv.org/abs/2011.05707",
    "authors": [
      "Goeric Huybrechts",
      "Thomas Merritt",
      "Giulia Comini",
      "Bartek Perz",
      "Raahil Shah",
      "Jaime Lorenzo-Trueba"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2105.13471",
    "title": "Inspecting the concept knowledge graph encoded by modern language models",
    "abstract": " Title: Inspecting the concept knowledge graph encoded by modern language models ",
    "url": "https://arxiv.org/abs/2105.13471",
    "authors": [
      "Carlos Aspillaga",
      "Marcelo Mendoza",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  }
]