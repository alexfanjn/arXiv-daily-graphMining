[
  {
    "id": "arXiv:2212.05094",
    "title": "Age of Broadcast and Collection in Spatially Distributed Wireless  Networks",
    "abstract": "We consider a wireless network with a base station broadcasting and collecting time-sensitive data to and from spatially distributed nodes in the presence of wireless interference. The Age of Information (AoI) is the time that has elapsed since the most-recently delivered packet was generated, and captures the freshness of information. In the context of broadcast and collection, we define the Age of Broadcast (AoB) to be the amount of time elapsed until all nodes receive a fresh update, and the Age of Collection (AoC) as the amount of time that elapses until the base station receives an update from all nodes. We quantify the average broadcast and collection ages in two scenarios: 1) instance-dependent, in which the locations of all nodes and interferers are known, and 2) instance-independent, in which they are not known but are located randomly, and expected age is characterized with respect to node locations. In the instance-independent case, we show that AoB and AoC scale super-exponentially with respect to the radius of the region surrounding the base station. Simulation results highlight how expected AoB and AoC are affected by network parameters such as network density, medium access probability, and the size of the coverage region. ",
    "url": "https://arxiv.org/abs/2212.05094",
    "authors": [
      "Chirag Rao",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.05124",
    "title": "Multi-view Graph Convolutional Networks with Differentiable Node  Selection",
    "abstract": "Multi-view data containing complementary and consensus information can facilitate representation learning by exploiting the intact integration of multi-view features. Because most objects in real world often have underlying connections, organizing multi-view data as heterogeneous graphs is beneficial to extracting latent information among different objects. Due to the powerful capability to gather information of neighborhood nodes, in this paper, we apply Graph Convolutional Network (GCN) to cope with heterogeneous-graph data originating from multi-view data, which is still under-explored in the field of GCN. In order to improve the quality of network topology and alleviate the interference of noises yielded by graph fusion, some methods undertake sorting operations before the graph convolution procedure. These GCN-based methods generally sort and select the most confident neighborhood nodes for each vertex, such as picking the top-k nodes according to pre-defined confidence values. Nonetheless, this is problematic due to the non-differentiable sorting operators and inflexible graph embedding learning, which may result in blocked gradient computations and undesired performance. To cope with these issues, we propose a joint framework dubbed Multi-view Graph Convolutional Network with Differentiable Node Selection (MGCN-DNS), which is constituted of an adaptive graph fusion layer, a graph learning module and a differentiable node selection schema. MGCN-DNS accepts multi-channel graph-structural data as inputs and aims to learn more robust graph fusion through a differentiable neural network. The effectiveness of the proposed method is verified by rigorous comparisons with considerable state-of-the-art approaches in terms of multi-view semi-supervised classification tasks. ",
    "url": "https://arxiv.org/abs/2212.05124",
    "authors": [
      "Zhaoliang Chen",
      "Lele Fu",
      "Shunxin Xiao",
      "Shiping Wang",
      "Claudia Plant",
      "Wenzhong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05136",
    "title": "CLIP-TSA: CLIP-Assisted Temporal Self-Attention for Weakly-Supervised  Video Anomaly Detection",
    "abstract": "Video anomaly detection (VAD) -- commonly formulated as a multiple-instance learning problem in a weakly-supervised manner due to its labor-intensive nature -- is a challenging problem in video surveillance where the frames of anomaly need to be localized in an untrimmed video. In this paper, we first propose to utilize the ViT-encoded visual features from CLIP, in contrast with the conventional C3D or I3D features in the domain, to efficiently extract discriminative representations in the novel technique. We then model long- and short-range temporal dependencies and nominate the snippets of interest by leveraging our proposed Temporal Self-Attention (TSA). The ablation study conducted on each component confirms its effectiveness in the problem, and the extensive experiments show that our proposed CLIP-TSA outperforms the existing state-of-the-art (SOTA) methods by a large margin on two commonly-used benchmark datasets in the VAD problem (UCF-Crime and ShanghaiTech Campus). The source code will be made publicly available upon acceptance. ",
    "url": "https://arxiv.org/abs/2212.05136",
    "authors": [
      "Hyekang Kevin Joo",
      "Khoa Vo",
      "Kashu Yamazaki",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05147",
    "title": "Multi-task Learning for Personal Health Mention Detection on Social  Media",
    "abstract": "Detecting personal health mentions on social media is essential to complement existing health surveillance systems. However, annotating data for detecting health mentions at a large scale is a challenging task. This research employs a multitask learning framework to leverage available annotated data from a related task to improve the performance on the main task to detect personal health experiences mentioned in social media texts. Specifically, we focus on incorporating emotional information into our target task by using emotion detection as an auxiliary task. Our approach significantly improves a wide range of personal health mention detection tasks compared to a strong state-of-the-art baseline. ",
    "url": "https://arxiv.org/abs/2212.05147",
    "authors": [
      "Olanrewaju Tahir Aduragba",
      "Jialin Yu",
      "Alexandra I. Cristea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05171",
    "title": "ULIP: Learning Unified Representation of Language, Image and Point Cloud  for 3D Understanding",
    "abstract": "The understanding capabilities of current state-of-the-art 3D models are limited by datasets with a small number of annotated data and a pre-defined set of categories. In its 2D counterpart, recent advances have shown that similar problems can be significantly alleviated by employing knowledge from other modalities, such as language. Inspired by this, leveraging multimodal information for 3D modality could be promising to improve 3D understanding under the restricted data regime, but this line of research is not well studied. Therefore, we introduce ULIP to learn a unified representation of image, text, and 3D point cloud by pre-training with object triplets from the three modalities. To overcome the shortage of training triplets, ULIP leverages a pre-trained vision-language model that has already learned a common visual and textual space by training with massive image-text pairs. Then, ULIP learns a 3D representation space aligned with the common image-text space, using a small number of automatically synthesized triplets. ULIP is agnostic to 3D backbone networks and can easily be integrated into any 3D architecture. Experiments show that ULIP effectively improves the performance of multiple recent 3D backbones by simply pre-training them on ShapeNet55 using our framework, achieving state-of-the-art performance in both standard 3D classification and zero-shot 3D classification on ModelNet40 and ScanObjectNN. ULIP also improves the performance of PointMLP by around 3% in 3D classification on ScanObjectNN, and outperforms PointCLIP by 28.8% on top-1 accuracy for zero-shot 3D classification on ModelNet40. Our code and pre-trained models will be released. ",
    "url": "https://arxiv.org/abs/2212.05171",
    "authors": [
      "Le Xue",
      "Mingfei Gao",
      "Chen Xing",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Jiajun Wu",
      "Caiming Xiong",
      "Ran Xu",
      "Juan Carlos Niebles",
      "Silvio Savarese"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05178",
    "title": "State-Regularized Recurrent Neural Networks to Extract Automata and  Explain Predictions",
    "abstract": "Recurrent neural networks are a widely used class of neural architectures. They have, however, two shortcomings. First, they are often treated as black-box models and as such it is difficult to understand what exactly they learn as well as how they arrive at a particular prediction. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in principle. We aim to address both shortcomings with a class of recurrent networks that use a stochastic state transition mechanism between cell applications. This mechanism, which we term state-regularization, makes RNNs transition between a finite set of learnable states. We evaluate state-regularized RNNs on (1) regular languages for the purpose of automata extraction; (2) non-regular languages such as balanced parentheses and palindromes where external memory is required; and (3) real-word sequence learning tasks for sentiment analysis, visual object recognition and text categorisation. We show that state-regularization (a) simplifies the extraction of finite state automata that display an RNN's state transition dynamic; (b) forces RNNs to operate more like automata with external memory and less like finite state machines, which potentiality leads to a more structural memory; (c) leads to better interpretability and explainability of RNNs by leveraging the probabilistic finite state transition mechanism over time steps. ",
    "url": "https://arxiv.org/abs/2212.05178",
    "authors": [
      "Cheng Wang",
      "Carolin Lawrence",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05189",
    "title": "Expanding Knowledge Graphs with Humans in the Loop",
    "abstract": "Curated knowledge graphs encode domain expertise and improve the performance of recommendation, segmentation, ad targeting, and other machine learning systems in several domains. As new concepts emerge in a domain, knowledge graphs must be expanded to preserve machine learning performance. Manually expanding knowledge graphs, however, is infeasible at scale. In this work, we propose a method for knowledge graph expansion with humans-in-the-loop. Concretely, given a knowledge graph, our method predicts the \"parents\" of new concepts to be added to this graph for further verification by human experts. We show that our method is both accurate and provably \"human-friendly\". Specifically, we prove that our method predicts parents that are \"near\" concepts' true parents in the knowledge graph, even when the predictions are incorrect. We then show, with a controlled experiment, that satisfying this property increases both the speed and the accuracy of the human-algorithm collaboration. We further evaluate our method on a knowledge graph from Pinterest and show that it outperforms competing methods on both accuracy and human-friendliness. Upon deployment in production at Pinterest, our method reduced the time needed for knowledge graph expansion by ~400% (compared to manual expansion), and contributed to a subsequent increase in ad revenue of 20%. ",
    "url": "https://arxiv.org/abs/2212.05189",
    "authors": [
      "Emaad Manzoor",
      "Jordan Tong",
      "Sriniketh Vijayaraghavan",
      "Rui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05190",
    "title": "Neural Bandits for Data Mining: Searching for Dangerous Polypharmacy",
    "abstract": "Polypharmacy, most often defined as the simultaneous consumption of five or more drugs at once, is a prevalent phenomenon in the older population. Some of these polypharmacies, deemed inappropriate, may be associated with adverse health outcomes such as death or hospitalization. Considering the combinatorial nature of the problem as well as the size of claims database and the cost to compute an exact association measure for a given drug combination, it is impossible to investigate every possible combination of drugs. Therefore, we propose to optimize the search for potentially inappropriate polypharmacies (PIPs). To this end, we propose the OptimNeuralTS strategy, based on Neural Thompson Sampling and differential evolution, to efficiently mine claims datasets and build a predictive model of the association between drug combinations and health outcomes. We benchmark our method using two datasets generated by an internally developed simulator of polypharmacy data containing 500 drugs and 100 000 distinct combinations. Empirically, our method can detect up to 33\\% of PIPs while maintaining an average precision score of 99\\% using 10 000 time steps. ",
    "url": "https://arxiv.org/abs/2212.05190",
    "authors": [
      "Alexandre Larouche",
      "Audrey Durand",
      "Richard Khoury",
      "Caroline Sirois"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05194",
    "title": "Artificial Text Detection with Multiple Training Strategies",
    "abstract": "As the deep learning rapidly promote, the artificial texts created by generative models are commonly used in news and social media. However, such models can be abused to generate product reviews, fake news, and even fake political content. The paper proposes a solution for the Russian Artificial Text Detection in the Dialogue shared task 2022 (RuATD 2022) to distinguish which model within the list is used to generate this text. We introduce the DeBERTa pre-trained language model with multiple training strategies for this shared task. Extensive experiments conducted on the RuATD dataset validate the effectiveness of our proposed method. Moreover, our submission ranked second place in the evaluation phase for RuATD 2022 (Multi-Class). ",
    "url": "https://arxiv.org/abs/2212.05194",
    "authors": [
      "Bin Li",
      "Yixuan Weng",
      "Qiya Song",
      "Hanjun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05197",
    "title": "Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from  Misbehaving Peers",
    "abstract": "GossipSub is a new peer-to-peer communication protocol designed to counter attacks from misbehaving peers by carefully controlling what information is disseminated and to whom, via a score function computed by each peer that captures positive and negative behaviors of its neighbors. The score function depends on several parameters (weights, caps, thresholds, etc.) that can be configured by applications using GossipSub. The specification for GossipSub is written in English and its resilience to attacks from misbehaving peers is supported empirically by emulation testing using an implementation in Golang. In this work we take a foundational approach to understanding the resilience of GossipSub to attacks from misbehaving peers. We build the first formal model of GossipSub, using the ACL2s theorem prover. Our model is officially endorsed by GossipSub developers. It can simulate GossipSub networks of arbitrary size and topology, with arbitrarily configured peers, and can be used to prove and disprove theorems about the protocol. We formalize fundamental security properties stating that the score function is fair, penalizes bad behavior and rewards good behavior. We prove that the score function is always fair, but can be configured in ways that either penalize good behavior or ignore bad behavior. Using our model, we run GossipSub with the specific configurations for two popular real-world applications: the FileCoin and Eth2.0 blockchains. We show that all properties hold for FileCoin. However, given any Eth2.0 network (of any topology and size) with any number of potentially misbehaving peers, we can synthesize attacks where these peers are able to continuously misbehave by never forwarding topic messages, while maintaining positive scores so that they are never pruned from the network by GossipSub. ",
    "url": "https://arxiv.org/abs/2212.05197",
    "authors": [
      "Ankit Kumar",
      "Max von Hippel",
      "Pete Manolios",
      "Cristina Nita-Rotaru"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05200",
    "title": "Neural Controller Synthesis for Signal Temporal Logic Specifications  Using Encoder-Decoder Structured Networks",
    "abstract": "In this paper, we propose a control synthesis method for signal temporal logic (STL) specifications with neural networks (NNs). Most of the previous works consider training a controller for only a given STL specification. These approaches, however, require retraining the NN controller if a new specification arises and needs to be satisfied, which results in large consumption of memory and inefficient training. To tackle this problem, we propose to construct NN controllers by introducing encoder-decoder structured NNs with an attention mechanism. The encoder takes an STL formula as input and encodes it into an appropriate vector, and the decoder outputs control signals that will meet the given specification. As the encoder, we consider three NN structures: sequential, tree-structured, and graph-structured NNs. All the model parameters are trained in an end-to-end manner to maximize the expected robustness that is known to be a quantitative semantics of STL formulae. We compare the control performances attained by the above NN structures through a numerical experiment of the path planning problem, showing the efficacy of the proposed approach. ",
    "url": "https://arxiv.org/abs/2212.05200",
    "authors": [
      "Wataru Hashimoto",
      "Kazumune Hashimoto",
      "Masako Kishida",
      "Shigemasa Takai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05204",
    "title": "Parallel Exploration of Directed Acyclic Graphs using the Actor Model",
    "abstract": "In this paper we describe a generic scheme for the parallel exploration of directed acyclic graphs starting from one or more `roots' of the graph. Our scheme is designed for graphs with the following properties, (i) discovering neighbors at any node requires a non-trivial amount of computation, it is not a simple lookup; (ii) once a node is processed, all its neighbors are discovered; (iii) each node can be discovered through multiple paths, but should only be processed once. Several computational problems can be reduced to traversing such graphs, where the goal is to explore the graph and build a traversal roadmap. As a proof of concept for the effectiveness of our scheme at achieving speedup due to parallelism, we implement the scheme for the parallel exploration of assembly landscape using the EASAL methodology. ",
    "url": "https://arxiv.org/abs/2212.05204",
    "authors": [
      "Rahul Prabhu",
      "Amit Verma",
      "Meera Sitharam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.05228",
    "title": "QESK: Quantum-based Entropic Subtree Kernels for Graph Classification",
    "abstract": "In this paper, we propose a novel graph kernel, namely the Quantum-based Entropic Subtree Kernel (QESK), for Graph Classification. To this end, we commence by computing the Average Mixing Matrix (AMM) of the Continuous-time Quantum Walk (CTQW) evolved on each graph structure. Moreover, we show how this AMM matrix can be employed to compute a series of entropic subtree representations associated with the classical Weisfeiler-Lehman (WL) algorithm. For a pair of graphs, the QESK kernel is defined by computing the exponentiation of the negative Euclidean distance between their entropic subtree representations, theoretically resulting in a positive definite graph kernel. We show that the proposed QESK kernel not only encapsulates complicated intrinsic quantum-based structural characteristics of graph structures through the CTQW, but also theoretically addresses the shortcoming of ignoring the effects of unshared substructures arising in state-of-the-art R-convolution graph kernels. Moreover, unlike the classical R-convolution kernels, the proposed QESK can discriminate the distinctions of isomorphic subtrees in terms of the global graph structures, theoretically explaining the effectiveness. Experiments indicate that the proposed QESK kernel can significantly outperform state-of-the-art graph kernels and graph deep learning methods for graph classification problems. ",
    "url": "https://arxiv.org/abs/2212.05228",
    "authors": [
      "Lu Bai",
      "Lixin Cui",
      "Edwin R. Hancock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05231",
    "title": "NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view  Reconstruction",
    "abstract": "Recent methods for neural surface representation and rendering, for example NeuS, have demonstrated remarkably high-quality reconstruction of static scenes. However, the training of NeuS takes an extremely long time (8 hours), which makes it almost impossible to apply them to dynamic scenes with thousands of frames. We propose a fast neural surface reconstruction approach, called NeuS2, which achieves two orders of magnitude improvement in terms of acceleration without compromising reconstruction quality. To accelerate the training process, we integrate multi-resolution hash encodings into a neural surface representation and implement our whole algorithm in CUDA. We also present a lightweight calculation of second-order derivatives tailored to our networks (i.e., ReLU-based MLPs), which achieves a factor two speed up. To further stabilize training, a progressive learning strategy is proposed to optimize multi-resolution hash encodings from coarse to fine. In addition, we extend our method for reconstructing dynamic scenes with an incremental training strategy. Our experiments on various datasets demonstrate that NeuS2 significantly outperforms the state-of-the-arts in both surface reconstruction accuracy and training speed. The video is available at https://vcai.mpi-inf.mpg.de/projects/NeuS2/ . ",
    "url": "https://arxiv.org/abs/2212.05231",
    "authors": [
      "Yiming Wang",
      "Qin Han",
      "Marc Habermann",
      "Kostas Daniilidis",
      "Christian Theobalt",
      "Lingjie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.05238",
    "title": "Structured information extraction from complex scientific text with  fine-tuned large language models",
    "abstract": "Intelligently extracting and linking complex scientific information from unstructured text is a challenging endeavor particularly for those inexperienced with natural language processing. Here, we present a simple sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientific text. The approach leverages a pre-trained large language model (LLM), GPT-3, that is fine-tuned on approximately 500 pairs of prompts (inputs) and completions (outputs). Information is extracted either from single sentences or across sentences in abstracts/passages, and the output can be returned as simple English sentences or a more structured format, such as a list of JSON objects. We demonstrate that LLMs trained in this way are capable of accurately extracting useful records of complex scientific knowledge for three representative tasks in materials chemistry: linking dopants with their host materials, cataloging metal-organic frameworks, and general chemistry/phase/morphology/application information extraction. This approach represents a simple, accessible, and highly-flexible route to obtaining large databases of structured knowledge extracted from unstructured text. An online demo is available at this http URL ",
    "url": "https://arxiv.org/abs/2212.05238",
    "authors": [
      "Alexander Dunn",
      "John Dagdelen",
      "Nicholas Walker",
      "Sanghoon Lee",
      "Andrew S. Rosen",
      "Gerbrand Ceder",
      "Kristin Persson",
      "Anubhav Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2212.05244",
    "title": "A Quantitative Flavour of Robust Reachability",
    "abstract": "Many software analysis techniques attempt to determine whether bugs are reachable, but for security purpose this is only part of the story as it does not indicate whether the bugs found could be easily triggered by an attacker. The recently introduced notion of robust reachability aims at filling this gap by distinguishing the input controlled by the attacker from those that are not. Yet, this qualitative notion may be too strong in practice, leaving apart bugs which are mostly but not fully replicable. We aim here at proposing a quantitative version of robust reachability, more flexible and still amenable to automation. We propose quantitative robustness, a metric expressing how easily an attacker can trigger a bug while taking into account that he can only influence part of the program input, together with a dedicated quantitative symbolic execution technique (QRSE). Interestingly, QRSE relies on a variant of model counting (namely, functional E-MAJSAT) unseen so far in formal verification, but which has been studied in AI domains such as Bayesian network, knowledge representation and probabilistic planning. Yet, the existing solving methods from these fields turn out to be unsatisfactory for formal verification purpose, leading us to propose a novel parametric method. These results have been implemented and evaluated over two security-relevant case studies, allowing to demonstrate the feasibility and relevance of our ideas. ",
    "url": "https://arxiv.org/abs/2212.05244",
    "authors": [
      "S\u00e9bastien Bardin",
      "Guillaume Girol"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2212.05245",
    "title": "Joint Spatio-Temporal Modeling for Semantic Change Detection in Remote  Sensing Images",
    "abstract": "Semantic Change Detection (SCD) refers to the task of simultaneously extracting the changed areas and the semantic categories (before and after the changes) in Remote Sensing Images (RSIs). This is more meaningful than Binary Change Detection (BCD) since it enables detailed change analysis in the observed areas. Previous works established triple-branch Convolutional Neural Network (CNN) architectures as the paradigm for SCD. However, it remains challenging to exploit semantic information with a limited amount of change samples. In this work, we investigate to jointly consider the spatio-temporal dependencies to improve the accuracy of SCD. First, we propose a SCanFormer (Semantic Change Transformer) to explicitly model the 'from-to' semantic transitions between the bi-temporal RSIs. Then, we introduce a semantic learning scheme to leverage the spatio-temporal constraints, which are coherent to the SCD task, to guide the learning of semantic changes. The resulting network (ScanNet) significantly outperforms the baseline method in terms of both detection of critical semantic changes and semantic consistency in the obtained bi-temporal results. It achieves the SOTA accuracy on two benchmark datasets for the SCD. ",
    "url": "https://arxiv.org/abs/2212.05245",
    "authors": [
      "Lei Ding",
      "Jing Zhang",
      "Kai Zhang",
      "Haitao Guo",
      "Bing Liu",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05250",
    "title": "Phases, Modalities, Temporal and Spatial Locality: Domain Specific ML  Prefetcher for Accelerating Graph Analytics",
    "abstract": "Graph processing applications are severely bottlenecked by memory system performance due to low data reuse and irregular memory accesses. While state-of-the-art prefetchers using Machine Learning (ML) have made great progress, they do not perform well on graph analytics applications due to phase transitions in the execution and irregular data access that is hard to predict. We propose MPGraph: a novel ML-based Prefetcher for Graph analytics. MPGraph makes three novel optimizations based on domain knowledge of graph analytics. It detects the transition of graph processing phases during execution using a novel soft detection technique, predicts memory accesses and pages using phase-specific multi-modality predictors, and prefetches using a novel chain spatio-temporal prefetching strategy. We evaluate our approach using three widely-used graph processing frameworks and a variety of graph datasets. Our approach achieves 34.17%-82.15% higher precision in phase transition detection than the KSWIN and decision tree baselines. Our predictors achieve 6.80%-16.02% higher F1-score for access prediction and 11.68%-15.41% higher accuracy-at-10 for page prediction compared with the baselines LSTM-based and vanilla attention-based models. Simulations show that MPGraph achieves on the average 87.16% (prefetch accuracy) and 73.29% (prefetch coverage), leading to 12.52%-21.23% IPC improvement. It outperforms the widely-used non-ML prefetcher BO by 7.58%-12.03%, and outperforms state-of-the-art ML-based prefetchers Voyager by 3.27%-4.42% and TransFetch by 3.73%-4.58% with respect to IPC improvement. ",
    "url": "https://arxiv.org/abs/2212.05250",
    "authors": [
      "Pengmiao Zhang",
      "Rajgopal Kannan",
      "Viktor K. Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2212.05251",
    "title": "A Unified Knowledge Graph Service for Developing Domain Language Models  in AI Software",
    "abstract": "Natural Language Processing (NLP) is one of the core techniques in AI software. As AI is being applied to more and more domains, how to efficiently develop high-quality domain-specific language models becomes a critical question in AI software engineering. Existing domain-specific language model development processes mostly focus on learning a domain-specific pre-trained language model (PLM); when training the domain task-specific language model based on PLM, only a direct (and often unsatisfactory) fine-tuning strategy is adopted commonly. By enhancing the task-specific training procedure with domain knowledge graphs, we propose KnowledgeDA, a unified and low-code domain language model development service. Given domain-specific task texts input by a user, KnowledgeDA can automatically generate a domain-specific language model following three steps: (i) localize domain knowledge entities in texts via an embedding-similarity approach; (ii) generate augmented samples by retrieving replaceable domain entity pairs from two views of both knowledge graph and training data; (iii) select high-quality augmented samples for fine-tuning via confidence-based assessment. We implement a prototype of KnowledgeDA to learn language models for two domains, healthcare and software development. Experiments on five domain-specific NLP tasks verify the effectiveness and generalizability of KnowledgeDA. (Code is publicly available at https://github.com/RuiqingDing/KnowledgeDA.) ",
    "url": "https://arxiv.org/abs/2212.05251",
    "authors": [
      "Ruiqing Ding",
      "Xiao Han",
      "Leye Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.05253",
    "title": "Graph Analysis in Decentralized Online Social Networks with Fine-Grained  Privacy Protection",
    "abstract": "Graph analysts cannot directly obtain the global structure in decentralized social networks, and analyzing such a network requires collecting local views of the social graph from individual users. Since the edges between users may reveal sensitive social interactions in the local view, applying differential privacy in the data collection process is often desirable, which provides strong and rigorous privacy guarantees. In practical decentralized social graphs, different edges have different privacy requirements due to the distinct sensitivity levels. However, the existing differentially private analysis of social graphs provide the same protection for all edges. To address this issue, this work proposes a fine-grained privacy notion as well as novel algorithms for private graph analysis. We first design a fine-grained relationship differential privacy (FGR-DP) notion for social graph analysis, which enforces different protections for the edges with distinct privacy requirements. Then, we design algorithms for triangle counting and k-stars counting, respectively, which can accurately estimate subgraph counts given fine-grained protection for social edges. We also analyze upper bounds on the estimation error, including k-stars and triangle counts, and show their superior performance compared with the state-of-the-arts. Finally, we perform extensive experiments on two real social graph datasets and demonstrate that the proposed mechanisms satisfying FGR-DP have better utility than the state-of-the-art mechanisms due to the finer-grained protection. ",
    "url": "https://arxiv.org/abs/2212.05253",
    "authors": [
      "Lele Zheng",
      "Bowen Deng",
      "Tao Zhang",
      "Yulong Shen",
      "Yang Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05258",
    "title": "Image augmentation with conformal mappings for a convolutional neural  network",
    "abstract": "For augmentation of the square-shaped image data of a convolutional neural network (CNN), we introduce a new method, in which the original images are mapped onto a disk with a conformal mapping, rotated around the center of this disk and mapped under such a M\\\"obius transformation that preserves the disk, and then mapped back onto their original square shape. This process does not result the loss of information caused by removing areas from near the edges of the original images unlike the typical transformations used in the data augmentation for a CNN. We offer here the formulas of all the mappings needed together with detailed instructions how to write a code for transforming the images. The new method is also tested with simulated data and, according the results, using this method to augment the training data of 10 images into 40 images decreases the amount of the error in the predictions by a CNN for a test set of 160 images in a statistically significant way (p-value=0.0360). ",
    "url": "https://arxiv.org/abs/2212.05258",
    "authors": [
      "Oona Rainio",
      "Mohamed M.S. Nasser",
      "Matti Vuorinen",
      "Riku Kl\u00e9n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05262",
    "title": "Position Embedding Needs an Independent Layer Normalization",
    "abstract": "The Position Embedding (PE) is critical for Vision Transformers (VTs) due to the permutation-invariance of self-attention operation. By analyzing the input and output of each encoder layer in VTs using reparameterization and visualization, we find that the default PE joining method (simply adding the PE and patch embedding together) operates the same affine transformation to token embedding and PE, which limits the expressiveness of PE and hence constrains the performance of VTs. To overcome this limitation, we propose a simple, effective, and robust method. Specifically, we provide two independent layer normalizations for token embeddings and PE for each layer, and add them together as the input of each layer's Muti-Head Self-Attention module. Since the method allows the model to adaptively adjust the information of PE for different layers, we name it as Layer-adaptive Position Embedding, abbreviated as LaPE. Extensive experiments demonstrate that LaPE can improve various VTs with different types of PE and make VTs robust to PE types. For example, LaPE improves 0.94% accuracy for ViT-Lite on Cifar10, 0.98% for CCT on Cifar100, and 1.72% for DeiT on ImageNet-1K, which is remarkable considering the negligible extra parameters, memory and computational cost brought by LaPE. The code is publicly available at https://github.com/Ingrid725/LaPE. ",
    "url": "https://arxiv.org/abs/2212.05262",
    "authors": [
      "Runyi Yu",
      "Zhennan Wang",
      "Yinhuai Wang",
      "Kehan Li",
      "Yian Zhao",
      "Jian Zhang",
      "Guoli Song",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05265",
    "title": "Multi-Sem Fusion: Multimodal Semantic Fusion for 3D Object Detection",
    "abstract": "LiDAR-based 3D Object detectors have achieved impressive performances in many benchmarks, however, multisensors fusion-based techniques are promising to further improve the results. PointPainting, as a recently proposed framework, can add the semantic information from the 2D image into the 3D LiDAR point by the painting operation to boost the detection performance. However, due to the limited resolution of 2D feature maps, severe boundary-blurring effect happens during re-projection of 2D semantic segmentation into the 3D point clouds. To well handle this limitation, a general multimodal fusion framework MSF has been proposed to fuse the semantic information from both the 2D image and 3D points scene parsing results. Specifically, MSF includes three main modules. First, SOTA off-the-shelf 2D/3D semantic segmentation approaches are employed to generate the parsing results for 2D images and 3D point clouds. The 2D semantic information is further re-projected into the 3D point clouds with calibrated parameters. To handle the misalignment between the 2D and 3D parsing results, an AAF module is proposed to fuse them by learning an adaptive fusion score. Then the point cloud with the fused semantic label is sent to the following 3D object detectors. Furthermore, we propose a DFF module to aggregate deep features in different levels to boost the final detection performance. The effectiveness of the framework has been verified on two public large-scale 3D object detection benchmarks by comparing with different baselines. The experimental results show that the proposed fusion strategies can significantly improve the detection performance compared to the methods using only point clouds and the methods using only 2D semantic information. Most importantly, the proposed approach significantly outperforms other approaches and sets new SOTA results on the nuScenes testing benchmark. ",
    "url": "https://arxiv.org/abs/2212.05265",
    "authors": [
      "Shaoqing Xu",
      "Dingfu Zhou",
      "Jin Fang",
      "Pengcheng Wang",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05269",
    "title": "Performance Evaluation of Apache Spark MLlib Algorithms on an Intrusion  Detection Dataset",
    "abstract": "The increase in the use of the Internet and web services and the advent of the fifth generation of cellular network technology (5G) along with ever-growing Internet of Things (IoT) data traffic will grow global internet usage. To ensure the security of future networks, machine learning-based intrusion detection and prevention systems (IDPS) must be implemented to detect new attacks, and big data parallel processing tools can be used to handle a huge collection of training data in these systems. In this paper Apache Spark, a general-purpose and fast cluster computing platform is used for processing and training a large volume of network traffic feature data. In this work, the most important features of the CSE-CIC-IDS2018 dataset are used for constructing machine learning models and then the most popular machine learning approaches, namely Logistic Regression, Support Vector Machine (SVM), three different Decision Tree Classifiers, and Naive Bayes algorithm are used to train the model using up to eight number of worker nodes. Our Spark cluster contains seven machines acting as worker nodes and one machine is configured as both a master and a worker. We use the CSE-CIC-IDS2018 dataset to evaluate the overall performance of these algorithms on Botnet attacks and distributed hyperparameter tuning is used to find the best single decision tree parameters. We have achieved up to 100% accuracy using selected features by the learning method in our experiments ",
    "url": "https://arxiv.org/abs/2212.05269",
    "authors": [
      "Ramin Atefinia",
      "Mahmood Ahmadi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.05275",
    "title": "Towards Scale Balanced 6-DoF Grasp Detection in Cluttered Scenes",
    "abstract": "In this paper, we focus on the problem of feature learning in the presence of scale imbalance for 6-DoF grasp detection and propose a novel approach to especially address the difficulty in dealing with small-scale samples. A Multi-scale Cylinder Grouping (MsCG) module is presented to enhance local geometry representation by combining multi-scale cylinder features and global context. Moreover, a Scale Balanced Learning (SBL) loss and an Object Balanced Sampling (OBS) strategy are designed, where SBL enlarges the gradients of the samples whose scales are in low frequency by apriori weights while OBS captures more points on small-scale objects with the help of an auxiliary segmentation network. They alleviate the influence of the uneven distribution of grasp scales in training and inference respectively. In addition, Noisy-clean Mix (NcM) data augmentation is introduced to facilitate training, aiming to bridge the domain gap between synthetic and raw scenes in an efficient way by generating more data which mix them into single ones at instance-level. Extensive experiments are conducted on the GraspNet-1Billion benchmark and competitive results are reached with significant gains on small-scale cases. Besides, the performance of real-world grasping highlights its generalization ability. Our code is available at https://github.com/mahaoxiang822/Scale-Balanced-Grasp. ",
    "url": "https://arxiv.org/abs/2212.05275",
    "authors": [
      "Haoxiang Ma",
      "Di Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05289",
    "title": "A Hybrid Brain-Computer Interface Using Motor Imagery and SSVEP Based on  Convolutional Neural Network",
    "abstract": "The key to electroencephalography (EEG)-based brain-computer interface (BCI) lies in neural decoding, and its accuracy can be improved by using hybrid BCI paradigms, that is, fusing multiple paradigms. However, hybrid BCIs usually require separate processing processes for EEG signals in each paradigm, which greatly reduces the efficiency of EEG feature extraction and the generalizability of the model. Here, we propose a two-stream convolutional neural network (TSCNN) based hybrid brain-computer interface. It combines steady-state visual evoked potential (SSVEP) and motor imagery (MI) paradigms. TSCNN automatically learns to extract EEG features in the two paradigms in the training process, and improves the decoding accuracy by 25.4% compared with the MI mode, and 2.6% compared with SSVEP mode in the test data. Moreover, the versatility of TSCNN is verified as it provides considerable performance in both single-mode (70.2% for MI, 93.0% for SSVEP) and hybrid-mode scenarios (95.6% for MI-SSVEP hybrid). Our work will facilitate the real-world applications of EEG-based BCI systems. ",
    "url": "https://arxiv.org/abs/2212.05289",
    "authors": [
      "Wenwei Luo",
      "Wanguang Yin",
      "Quanying Liu",
      "Youzhi Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05326",
    "title": "Vertical Layering of Quantized Neural Networks for Heterogeneous  Inference",
    "abstract": "Although considerable progress has been obtained in neural network quantization for efficient inference, existing methods are not scalable to heterogeneous devices as one dedicated model needs to be trained, transmitted, and stored for one specific hardware setting, incurring considerable costs in model training and maintenance. In this paper, we study a new vertical-layered representation of neural network weights for encapsulating all quantized models into a single one. With this representation, we can theoretically achieve any precision network for on-demand service while only needing to train and maintain one model. To this end, we propose a simple once quantization-aware training (QAT) scheme for obtaining high-performance vertical-layered models. Our design incorporates a cascade downsampling mechanism which allows us to obtain multiple quantized networks from one full precision source model by progressively mapping the higher precision weights to their adjacent lower precision counterparts. Then, with networks of different bit-widths from one source model, multi-objective optimization is employed to train the shared source model weights such that they can be updated simultaneously, considering the performance of all networks. By doing this, the shared weights will be optimized to balance the performance of different quantized models, thus making the weights transferable among different bit widths. Experiments show that the proposed vertical-layered representation and developed once QAT scheme are effective in embodying multiple quantized networks into a single one and allow one-time training, and it delivers comparable performance as that of quantized models tailored to any specific bit-width. Code will be available. ",
    "url": "https://arxiv.org/abs/2212.05326",
    "authors": [
      "Hai Wu",
      "Ruifei He",
      "Haoru Tan",
      "Xiaojuan Qi",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05327",
    "title": "Identifying the Source of Vulnerability in Explanation Discrepancy: A  Case Study in Neural Text Classification",
    "abstract": "Some recent works observed the instability of post-hoc explanations when input side perturbations are applied to the model. This raises the interest and concern in the stability of post-hoc explanations. However, the remaining question is: is the instability caused by the neural network model or the post-hoc explanation method? This work explores the potential source that leads to unstable post-hoc explanations. To separate the influence from the model, we propose a simple output probability perturbation method. Compared to prior input side perturbation methods, the output probability perturbation method can circumvent the neural model's potential effect on the explanations and allow the analysis on the explanation method. We evaluate the proposed method with three widely-used post-hoc explanation methods (LIME (Ribeiro et al., 2016), Kernel Shapley (Lundberg and Lee, 2017a), and Sample Shapley (Strumbelj and Kononenko, 2010)). The results demonstrate that the post-hoc methods are stable, barely producing discrepant explanations under output probability perturbations. The observation suggests that neural network models may be the primary source of fragile explanations. ",
    "url": "https://arxiv.org/abs/2212.05327",
    "authors": [
      "Ruixuan Tang",
      "Hanjie Chen",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05330",
    "title": "Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud  Sequence Representation Learning",
    "abstract": "Recent work on 4D point cloud sequences has attracted a lot of attention. However, obtaining exhaustively labeled 4D datasets is often very expensive and laborious, so it is especially important to investigate how to utilize raw unlabeled data. However, most existing self-supervised point cloud representation learning methods only consider geometry from a static snapshot omitting the fact that sequential observations of dynamic scenes could reveal more comprehensive geometric details. And the video representation learning frameworks mostly model motion as image space flows, let alone being 3D-geometric-aware. To overcome such issues, this paper proposes a new 4D self-supervised pre-training method called Complete-to-Partial 4D Distillation. Our key idea is to formulate 4D self-supervised representation learning as a teacher-student knowledge distillation framework and let the student learn useful 4D representations with the guidance of the teacher. Experiments show that this approach significantly outperforms previous pre-training approaches on a wide range of 4D point cloud sequence understanding tasks including indoor and outdoor scenarios. ",
    "url": "https://arxiv.org/abs/2212.05330",
    "authors": [
      "Yuhao Dong",
      "Zhuoyang Zhang",
      "Yunze Liu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05332",
    "title": "An approach to robust ICP initialization",
    "abstract": "In this note, we propose an approach for initializing the Iterative Closest Point (ICP) algorithm that allows us to apply ICP to unlabelled point clouds that are related by rigid transformations. We also give bounds on the robustness of our approach to noise. Numerical experiments confirm our theoretical findings. ",
    "url": "https://arxiv.org/abs/2212.05332",
    "authors": [
      "Alexander Kolpakov",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.05337",
    "title": "Targeted Adversarial Attacks on Deep Reinforcement Learning Policies via  Model Checking",
    "abstract": "Deep Reinforcement Learning (RL) agents are susceptible to adversarial noise in their observations that can mislead their policies and decrease their performance. However, an adversary may be interested not only in decreasing the reward, but also in modifying specific temporal logic properties of the policy. This paper presents a metric that measures the exact impact of adversarial attacks against such properties. We use this metric to craft optimal adversarial attacks. Furthermore, we introduce a model checking method that allows us to verify the robustness of RL policies against adversarial attacks. Our empirical analysis confirms (1) the quality of our metric to craft adversarial attacks against temporal logic properties, and (2) that we are able to concisely assess a system's robustness against attacks. ",
    "url": "https://arxiv.org/abs/2212.05337",
    "authors": [
      "Dennis Gross",
      "Thiago D. Simao",
      "Nils Jansen",
      "Guillermo A. Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05340",
    "title": "Scaling pattern mining through non-overlapping variable partitioning",
    "abstract": "Biclustering algorithms play a central role in the biotechnological and biomedical domains. The knowledge extracted supports the extraction of putative regulatory modules, essential to understanding diseases, aiding therapy research, and advancing biological knowledge. However, given the NP-hard nature of the biclustering task, algorithms with optimality guarantees tend to scale poorly in the presence of high-dimensionality data. To this end, we propose a pipeline for clustering-based vertical partitioning that takes into consideration both parallelization and cross-partition pattern merging needs. Given a specific type of pattern coherence, these clusters are built based on the likelihood that variables form those patterns. Subsequently, the extracted patterns per cluster are then merged together into a final set of closed patterns. This approach is evaluated using five published datasets. Results show that in some of the tested data, execution times yield statistically significant improvements when variables are clustered together based on the likelihood to form specific types of patterns, as opposed to partitions based on dissimilarity or randomness. This work offers a departuring step on the efficiency impact of vertical partitioning criteria along the different stages of pattern mining and biclustering algorithms. Availability: All the code is freely available at https://github.com/JupitersMight/pattern_merge under the MIT license. ",
    "url": "https://arxiv.org/abs/2212.05340",
    "authors": [
      "Leonardo Alexandre",
      "Rafael S. Costa",
      "Rui Henriques"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2212.05358",
    "title": "Efficient and Generic Algorithms for Quantitative Attack Tree Analysis",
    "abstract": "Numerous analysis methods for quantitative attack tree analysis have been proposed. These algorithms compute relevant security metrics, i.e. performance indicators that quantify how good the security of a system is; typical metrics being the most likely attack, the cheapest, or the most damaging one. However, existing methods are only geared towards specific metrics or do not work on general attack trees. This paper classifies attack trees in two dimensions: proper trees vs. directed acyclic graphs (i.e. with shared subtrees); and static vs. dynamic gates. For three out of these four classes, we propose novel algorithms that work over a generic attribute domain, encompassing a large number of concrete security metrics defined on the attack tree semantics; dynamic attack trees with directed acyclic graph structure are left as an open problem. We also analyse the computational complexity of our methods. ",
    "url": "https://arxiv.org/abs/2212.05358",
    "authors": [
      "Milan Lopuha\u00e4-Zwakenberg",
      "Carlos E. Budde",
      "Mari\u00eblle Stoelinga"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.05380",
    "title": "Mitigating Adversarial Gray-Box Attacks Against Phishing Detectors",
    "abstract": "Although machine learning based algorithms have been extensively used for detecting phishing websites, there has been relatively little work on how adversaries may attack such \"phishing detectors\" (PDs for short). In this paper, we propose a set of Gray-Box attacks on PDs that an adversary may use which vary depending on the knowledge that he has about the PD. We show that these attacks severely degrade the effectiveness of several existing PDs. We then propose the concept of operation chains that iteratively map an original set of features to a new set of features and develop the \"Protective Operation Chain\" (POC for short) algorithm. POC leverages the combination of random feature selection and feature mappings in order to increase the attacker's uncertainty about the target PD. Using 3 existing publicly available datasets plus a fourth that we have created and will release upon the publication of this paper, we show that POC is more robust to these attacks than past competing work, while preserving predictive performance when no adversarial attacks are present. Moreover, POC is robust to attacks on 13 different classifiers, not just one. These results are shown to be statistically significant at the p < 0.001 level. ",
    "url": "https://arxiv.org/abs/2212.05380",
    "authors": [
      "Giovanni Apruzzese",
      "V.S. Subrahmanian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05386",
    "title": "A Hierarchical Approach for Investigating Social Features of a City from  Mobile Phone Call Detail Records",
    "abstract": "Cellphone service-providers continuously collect Call Detail Records (CDR) as a usage log containing spatio-temporal traces of phone users. We proposed a multi-layered hierarchical analytical model for large spatio-temporal datasets and applied that for the progressive exploration of social features of a city, e.g., social activities, relationships, and groups, from CDR. This approach utilizes CDR as the preliminary input for the initial layer, and analytical results from consecutive layers are added to the knowledge-base to be used in the subsequent layers to explore more detailed social features. Each subsequent layer uses the results from previous layers, facilitating the discovery of more in-depth social features not predictable in a single-layered approach using only raw CDR. This model starts with exploring aggregated overviews of the social features and gradually focuses on comprehensive details of social relationships and groups, which facilitates a novel approach for investigating CDR datasets for the progressive exploration of social features in a densely-populated city. ",
    "url": "https://arxiv.org/abs/2212.05386",
    "authors": [
      "Fahim Hasan Khan",
      "Mohammed Eunus Ali"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05387",
    "title": "General Adversarial Defense Against Black-box Attacks via Pixel Level  and Feature Level Distribution Alignments",
    "abstract": "Deep Neural Networks (DNNs) are vulnerable to the black-box adversarial attack that is highly transferable. This threat comes from the distribution gap between adversarial and clean samples in feature space of the target DNNs. In this paper, we use Deep Generative Networks (DGNs) with a novel training mechanism to eliminate the distribution gap. The trained DGNs align the distribution of adversarial samples with clean ones for the target DNNs by translating pixel values. Different from previous work, we propose a more effective pixel level training constraint to make this achievable, thus enhancing robustness on adversarial samples. Further, a class-aware feature-level constraint is formulated for integrated distribution alignment. Our approach is general and applicable to multiple tasks, including image classification, semantic segmentation, and object detection. We conduct extensive experiments on different datasets. Our strategy demonstrates its unique effectiveness and generality against black-box attacks. ",
    "url": "https://arxiv.org/abs/2212.05387",
    "authors": [
      "Xiaogang Xu",
      "Hengshuang Zhao",
      "Philip Torr",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05397",
    "title": "Task modules Partitioning, Scheduling and Floorplanning for Partially  Dynamically Reconfigurable Systems Based on Modern Heterogeneous FPGAs",
    "abstract": "Modern field programmable gate array(FPGA) can be partially dynamically reconfigurable with heterogeneous resources distributed on the chip. And FPGA-based partially dynamically reconfigurable system(FPGA-PDRS) can be used to accelerate computing and improve computing flexibility. However, the traditional design of FPGA-PDRS is based on manual design. Implementing the automation of FPGA-PDRS needs to solve the problems of task modules partitioning, scheduling, and floorplanning on heterogeneous resources. Existing works only partly solve problems for the automation process of FPGA-PDRS or model homogeneous resource for FPGA-PDRS. To better solve the problems in the automation process of FPGA-PDRS and narrow the gap between algorithm and application, in this paper, we propose a complete workflow including three parts, pre-processing to generate the list of task modules candidate shapes according to the resources requirements, exploration process to search the solution of task modules partitioning, scheduling, and floorplanning, and post-optimization to improve the success rate of floorplan. Experimental results show that, compared with state-of-the-art work, the proposed complete workflow can improve performance by 18.7\\%, reduce communication cost by 8.6\\%, on average, with improving the resources reuse rate of the heterogeneous resources on the chip. And based on the solution generated by the exploration process, the post-optimization can improve the success rate of the floorplan by 14\\%. ",
    "url": "https://arxiv.org/abs/2212.05397",
    "authors": [
      "Bo Ding",
      "Jinglei Huang",
      "Junpeng Wang",
      "Qi Xu",
      "Song Chen",
      "Yi Kang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05399",
    "title": "Untargeted Attack against Federated Recommendation Systems via Poisonous  Item Embeddings and the Defense",
    "abstract": "Federated recommendation (FedRec) can train personalized recommenders without collecting user data, but the decentralized nature makes it susceptible to poisoning attacks. Most previous studies focus on the targeted attack to promote certain items, while the untargeted attack that aims to degrade the overall performance of the FedRec system remains less explored. In fact, untargeted attacks can disrupt the user experience and bring severe financial loss to the service provider. However, existing untargeted attack methods are either inapplicable or ineffective against FedRec systems. In this paper, we delve into the untargeted attack and its defense for FedRec systems. (i) We propose ClusterAttack, a novel untargeted attack method. It uploads poisonous gradients that converge the item embeddings into several dense clusters, which make the recommender generate similar scores for these items in the same cluster and perturb the ranking order. (ii) We propose a uniformity-based defense mechanism (UNION) to protect FedRec systems from such attacks. We design a contrastive learning task that regularizes the item embeddings toward a uniform distribution. Then the server filters out these malicious gradients by estimating the uniformity of updated item embeddings. Experiments on two public datasets show that ClusterAttack can effectively degrade the performance of FedRec systems while circumventing many defense methods, and UNION can improve the resistance of the system against various untargeted attacks, including our ClusterAttack. ",
    "url": "https://arxiv.org/abs/2212.05399",
    "authors": [
      "Yang Yu",
      "Qi Liu",
      "Likang Wu",
      "Runlong Yu",
      "Sanshi Lei Yu",
      "Zaixi Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05400",
    "title": "How to Backdoor Diffusion Models?",
    "abstract": "Diffusion models are state-of-the-art deep learning empowered generative models that are trained based on the principle of learning forward and reverse diffusion processes via progressive noise-addition and denoising. To gain a better understanding of the limitations and potential risks, this paper presents the first study on the robustness of diffusion models against backdoor attacks. Specifically, we propose BadDiffusion, a novel attack framework that engineers compromised diffusion processes during model training for backdoor implantation. At the inference stage, the backdoored diffusion model will behave just like an untampered generator for regular data inputs, while falsely generating some targeted outcome designed by the bad actor upon receiving the implanted trigger signal. Such a critical risk can be dreadful for downstream tasks and applications built upon the problematic model. Our extensive experiments on various backdoor attack settings show that BadDiffusion can consistently lead to compromised diffusion models with high utility and target specificity. Even worse, BadDiffusion can be made cost-effective by simply finetuning a clean pre-trained diffusion model to implant backdoors. We also explore some possible countermeasures for risk mitigation. Our results call attention to potential risks and possible misuse of diffusion models. ",
    "url": "https://arxiv.org/abs/2212.05400",
    "authors": [
      "Sheng-Yen Chou",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05410",
    "title": "ABC: Aggregation before Communication, a Communication Reduction  Framework for Distributed Graph Neural Network Training and Effective  Partition",
    "abstract": "Graph Neural Networks(GNNs) are a family of neural models tailored for graph-structure data and have shown superior performance in learning representations for graph-structured data. However, training GNNs on large graphs remains challenging and a promising direction is distributed GNN training, which is to partition the input graph and distribute the workload across multiple machines. The key bottleneck of the existing distributed GNNs training framework is the across-machine communication induced by the dependency on the graph data and aggregation operator of GNNs. In this paper, we study the communication complexity during distributed GNNs training and propose a simple lossless communication reduction method, termed the Aggregation before Communication (ABC) method. ABC method exploits the permutation-invariant property of the GNNs layer and leads to a paradigm where vertex-cut is proved to admit a superior communication performance than the currently popular paradigm (edge-cut). In addition, we show that the new partition paradigm is particularly ideal in the case of dynamic graphs where it is infeasible to control the edge placement due to the unknown stochastic of the graph-changing process. ",
    "url": "https://arxiv.org/abs/2212.05410",
    "authors": [
      "Junwei Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.05433",
    "title": "Beyond circular-arc graphs -- recognizing lollipop graphs and medusa  graphs",
    "abstract": "In 1992 Bir\\'{o}, Hujter and Tuza introduced, for every fixed connected graph $H$, the class of $H$-graphs, defined as the intersection graphs of connected subgraphs of some subdivision of $H$. Recently, quite a lot of research has been devoted to understanding the tractability border for various computational problems, such as recognition or isomorphism testing, in classes of $H$-graphs for different graphs $H$. In this work we undertake this research topic, focusing on the recognition problem. Chaplick, T\\\"{o}pfer, Voborn\\'{\\i}k, and Zeman showed, for every fixed tree $T$, a polynomial-time algorithm recognizing $T$-graphs. Tucker showed a polynomial time algorithm recognizing $K_3$-graphs (circular-arc graphs). On the other hand, Chaplick at al. showed that recognition of $H$-graphs is $NP$-hard if $H$ contains two different cycles sharing an edge. The main two results of this work narrow the gap between the $NP$-hard and $P$ cases of $H$-graphs recognition. First, we show that recognition of $H$-graphs is $NP$-hard when $H$ contains two different cycles. On the other hand, we show a polynomial-time algorithm recognizing $L$-graphs, where $L$ is a graph containing a cycle and an edge attached to it ($L$-graphs are called lollipop graphs). Our work leaves open the recognition problems of $M$-graphs for every unicyclic graph $M$ different from a cycle and a lollipop. Other results of this work, which shed some light on the cases that remain open, are as follows. Firstly, the recognition of $M$-graphs, where $M$ is a fixed unicyclic graph, admits a polynomial time algorithm if we restrict the input to graphs containing particular holes (hence recognition of $M$-graphs is probably most difficult for chordal graphs). Secondly, the recognition of medusa graphs, which are defined as the union of $M$-graphs, where $M$ runs over all unicyclic graphs, is $NP$-complete. ",
    "url": "https://arxiv.org/abs/2212.05433",
    "authors": [
      "Deniz A\u011fao\u011flu \u00c7a\u011f\u0131r\u0131c\u0131",
      "Onur \u00c7a\u011f\u0131r\u0131c\u0131",
      "Jan Derbisz",
      "Tim A. Hartmann",
      "Petr Hlin\u011bn\u00fd",
      "Jan Kratochv\u00edl",
      "Tomasz Krawczyk",
      "Peter Zeman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.05463",
    "title": "Vision Transformer with Attentive Pooling for Robust Facial Expression  Recognition",
    "abstract": "Facial Expression Recognition (FER) in the wild is an extremely challenging task. Recently, some Vision Transformers (ViT) have been explored for FER, but most of them perform inferiorly compared to Convolutional Neural Networks (CNN). This is mainly because the new proposed modules are difficult to converge well from scratch due to lacking inductive bias and easy to focus on the occlusion and noisy areas. TransFER, a representative transformer-based method for FER, alleviates this with multi-branch attention dropping but brings excessive computations. On the contrary, we present two attentive pooling (AP) modules to pool noisy features directly. The AP modules include Attentive Patch Pooling (APP) and Attentive Token Pooling (ATP). They aim to guide the model to emphasize the most discriminative features while reducing the impacts of less relevant features. The proposed APP is employed to select the most informative patches on CNN features, and ATP discards unimportant tokens in ViT. Being simple to implement and without learnable parameters, the APP and ATP intuitively reduce the computational cost while boosting the performance by ONLY pursuing the most discriminative features. Qualitative results demonstrate the motivations and effectiveness of our attentive poolings. Besides, quantitative results on six in-the-wild datasets outperform other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2212.05463",
    "authors": [
      "Fanglei Xue",
      "Qiangchang Wang",
      "Zichang Tan",
      "Zhongsong Ma",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05478",
    "title": "Mul-GAD: a semi-supervised graph anomaly detection framework via  aggregating multi-view information",
    "abstract": "Anomaly detection is defined as discovering patterns that do not conform to the expected behavior. Previously, anomaly detection was mostly conducted using traditional shallow learning techniques, but with little improvement. As the emergence of graph neural networks (GNN), graph anomaly detection has been greatly developed. However, recent studies have shown that GNN-based methods encounter challenge, in that no graph anomaly detection algorithm can perform generalization on most datasets. To bridge the tap, we propose a multi-view fusion approach for graph anomaly detection (Mul-GAD). The view-level fusion captures the extent of significance between different views, while the feature-level fusion makes full use of complementary information. We theoretically and experimentally elaborate the effectiveness of the fusion strategies. For a more comprehensive conclusion, we further investigate the effect of the objective function and the number of fused views on detection performance. Exploiting these findings, our Mul-GAD is proposed equipped with fusion strategies and the well-performed objective function. Compared with other state-of-the-art detection methods, we achieve a better detection performance and generalization in most scenarios via a series of experiments conducted on Pubmed, Amazon Computer, Amazon Photo, Weibo and Books. Our code is available at https://github.com/liuyishoua/Mul-Graph-Fusion. ",
    "url": "https://arxiv.org/abs/2212.05478",
    "authors": [
      "Zhiyuan Liu",
      "Chunjie Cao",
      "Jingzhang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05500",
    "title": "Security Defense of Large Scale Networks Under False Data Injection  Attacks: An Attack Detection Scheduling Approach",
    "abstract": "In large scale networks, communication links between nodes are easily injected with false data by adversaries, so this paper proposes a novel security defense strategy to ensure the security of the network from the perspective of attack detection scheduling. Compared with existing attack detection methods, the attack detection scheduling strategy in this paper only needs to detect half of the neighbor node information to ensure the security of the node local state estimation. We first formulate the problem of selecting the sensor to be detected as a combinatorial optimization problem, which is Nondeterminism Polynomial hard (NP-hard). To solve the above problem, we convert the objective function into a submodular function. Then, we propose an attack detection scheduling algorithm based on sequential submodular maximization, which incorporates expert problem to better cope with dynamic attack strategies. The proposed algorithm can run in polynomial time with a theoretical lower bound on the optimization rate. In addition, the proposed algorithm can guarantee the security of the whole network under two kinds of insecurity conditions from the perspective of the augmented estimation error. Finally, a numerical simulation of the industrial continuous stirred tank reactor verifies the effectiveness of the developed approach. ",
    "url": "https://arxiv.org/abs/2212.05500",
    "authors": [
      "Yuhan Suo",
      "Senchun Chai",
      "Runqi Chai",
      "Zhong-Hua Pang",
      "Yuanqing Xia",
      "Guo-Ping Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05505",
    "title": "Focal-PETR: Embracing Foreground for Efficient Multi-Camera 3D Object  Detection",
    "abstract": "The dominant multi-camera 3D detection paradigm is based on explicit 3D feature construction, which requires complicated indexing of local image-view features via 3D-to-2D projection. Other methods implicitly introduce geometric positional encoding and perform global attention (e.g., PETR) to build the relationship between image tokens and 3D objects. The 3D-to-2D perspective inconsistency and global attention lead to a weak correlation between foreground tokens and queries, resulting in slow convergence. We propose Focal-PETR with instance-guided supervision and spatial alignment module to adaptively focus object queries on discriminative foreground regions. Focal-PETR additionally introduces a down-sampling strategy to reduce the consumption of global attention. Due to the highly parallelized implementation and down-sampling strategy, our model, without depth supervision, achieves leading performance on the large-scale nuScenes benchmark and a superior speed of 30 FPS on a single RTX3090 GPU. Extensive experiments show that our method outperforms PETR while consuming 3x fewer training hours. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2212.05505",
    "authors": [
      "Shihao Wang",
      "Xiaohui Jiang",
      "Ying Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05510",
    "title": "Mutimodal Ranking Optimization for Heterogeneous Face Re-identification",
    "abstract": "Heterogeneous face re-identification, namely matching heterogeneous faces across disjoint visible light (VIS) and near-infrared (NIR) cameras, has become an important problem in video surveillance application. However, the large domain discrepancy between heterogeneous NIR-VIS faces makes the performance of face re-identification degraded dramatically. To solve this problem, a multimodal fusion ranking optimization algorithm for heterogeneous face re-identification is proposed in this paper. Firstly, we design a heterogeneous face translation network to obtain multimodal face pairs, including NIR-VIS/NIR-NIR/VIS-VIS face pairs, through mutual transformation between NIR-VIS faces. Secondly, we propose linear and non-linear fusion strategies to aggregate initial ranking lists of multimodal face pairs and acquire the optimized re-ranked list based on modal complementarity. The experimental results show that the proposed multimodal fusion ranking optimization algorithm can effectively utilize the complementarity and outperforms some relative methods on the SCface dataset. ",
    "url": "https://arxiv.org/abs/2212.05510",
    "authors": [
      "Hui Hu",
      "Jiawei Zhang",
      "Zhen Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05523",
    "title": "A model-data asymptotic-preserving neural network method based on  micro-macro decomposition for gray radiative transfer equations",
    "abstract": "We propose a model-data asymptotic-preserving neural network(MD-APNN) method to solve the nonlinear gray radiative transfer equations(GRTEs). The system is challenging to be simulated with both the traditional numerical schemes and the vanilla physics-informed neural networks(PINNs) due to the multiscale characteristics. Under the framework of PINNs, we employ a micro-macro decomposition technique to construct a new asymptotic-preserving(AP) loss function, which includes the residual of the governing equations in the micro-macro coupled form, the initial and boundary conditions with additional diffusion limit information, the conservation laws, and a few labeled data. A convergence analysis is performed for the proposed method, and a number of numerical examples are presented to illustrate the efficiency of MD-APNNs, and particularly, the importance of the AP property in the neural networks for the diffusion dominating problems. The numerical results indicate that MD-APNNs lead to a better performance than APNNs or pure data-driven networks in the simulation of the nonlinear non-stationary GRTEs. ",
    "url": "https://arxiv.org/abs/2212.05523",
    "authors": [
      "Hongyan Li",
      "Song Jiang",
      "Wenjun Sun",
      "Liwei Xu",
      "Guanyu Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05532",
    "title": "Graph Learning for Anomaly Analytics: Algorithms, Applications, and  Challenges",
    "abstract": "Anomaly analytics is a popular and vital task in various research contexts, which has been studied for several decades. At the same time, deep learning has shown its capacity in solving many graph-based tasks like, node classification, link prediction, and graph classification. Recently, many studies are extending graph learning models for solving anomaly analytics problems, resulting in beneficial advances in graph-based anomaly analytics techniques. In this survey, we provide a comprehensive overview of graph learning methods for anomaly analytics tasks. We classify them into four categories based on their model architectures, namely graph convolutional network (GCN), graph attention network (GAT), graph autoencoder (GAE), and other graph learning models. The differences between these methods are also compared in a systematic manner. Furthermore, we outline several graph-based anomaly analytics applications across various domains in the real world. Finally, we discuss five potential future research directions in this rapidly growing field. ",
    "url": "https://arxiv.org/abs/2212.05532",
    "authors": [
      "Jing Ren",
      "Feng Xia",
      "Azadeh Noori Hoshyar",
      "Charu C. Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05546",
    "title": "Associations Between Natural Language Processing (NLP) Enriched Social  Determinants of Health and Suicide Death among US Veterans",
    "abstract": "Importance: Social determinants of health (SDOH) are known to be associated with increased risk of suicidal behaviors, but few studies utilized SDOH from unstructured electronic health record (EHR) notes. Objective: To investigate associations between suicide and recent SDOH, identified using structured and unstructured data. Design: Nested case-control study. Setting: EHR data from the US Veterans Health Administration (VHA). Participants: 6,122,785 Veterans who received care in the US VHA between October 1, 2010, and September 30, 2015. Exposures: Occurrence of SDOH over a maximum span of two years compared with no occurrence of SDOH. Main Outcomes and Measures: Cases of suicide deaths were matched with 4 controls on birth year, cohort entry date, sex, and duration of follow-up. We developed an NLP system to extract SDOH from unstructured notes. Structured data, NLP on unstructured data, and combining them yielded seven, eight and nine SDOH respectively. Adjusted odds ratios (aORs) and 95% confidence intervals (CIs) were estimated using conditional logistic regression. Results: In our cohort, 8,821 Veterans committed suicide during 23,725,382 person-years of follow-up (incidence rate 37.18 /100,000 person-years). Our cohort was mostly male (92.23%) and white (76.99%). Across the six common SDOH as covariates, NLP-extracted SDOH, on average, covered 84.38% of all SDOH occurrences. All SDOH, measured by structured data and NLP, were significantly associated with increased risk of suicide. The SDOH with the largest effects was legal problems (aOR=2.67, 95% CI=2.46-2.89), followed by violence (aOR=2.26, 95% CI=2.11-2.43). NLP-extracted and structured SDOH were also associated with suicide. Conclusions and Relevance: NLP-extracted SDOH were always significantly associated with increased risk of suicide among Veterans, suggesting the potential of NLP in public health studies. ",
    "url": "https://arxiv.org/abs/2212.05546",
    "authors": [
      "Avijit Mitra",
      "Richeek Pradhan",
      "Rachel D Melamed",
      "Kun Chen",
      "David C Hoaglin",
      "Katherine L Tucker",
      "Joel I Reisman",
      "Zhichao Yang",
      "Weisong Liu",
      "Jack Tsai",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.05563",
    "title": "Energy-based General Sequential Episodic Memory Networks at the  Adiabatic Limit",
    "abstract": "The General Associative Memory Model (GAMM) has a constant state-dependant energy surface that leads the output dynamics to fixed points, retrieving single memories from a collection of memories that can be asynchronously preloaded. We introduce a new class of General Sequential Episodic Memory Models (GSEMM) that, in the adiabatic limit, exhibit temporally changing energy surface, leading to a series of meta-stable states that are sequential episodic memories. The dynamic energy surface is enabled by newly introduced asymmetric synapses with signal propagation delays in the network's hidden layer. We study the theoretical and empirical properties of two memory models from the GSEMM class, differing in their activation functions. LISEM has non-linearities in the feature layer, whereas DSEM has non-linearity in the hidden layer. In principle, DSEM has a storage capacity that grows exponentially with the number of neurons in the network. We introduce a learning rule for the synapses based on the energy minimization principle and show it can learn single memories and their sequential relationships online. This rule is similar to the Hebbian learning algorithm and Spike-Timing Dependent Plasticity (STDP), which describe conditions under which synapses between neurons change strength. Thus, GSEMM combines the static and dynamic properties of episodic memory under a single theoretical framework and bridges neuroscience, machine learning, and artificial intelligence. ",
    "url": "https://arxiv.org/abs/2212.05563",
    "authors": [
      "Arjun Karuvally",
      "Terry J. Sejnowski",
      "Hava T. Siegelmann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.05581",
    "title": "Efficient Relation-aware Neighborhood Aggregation in Graph Neural  Networks via Tensor Decomposition",
    "abstract": "Numerous models have tried to effectively embed knowledge graphs in low dimensions. Among the state-of-the-art methods, Graph Neural Network (GNN) models provide structure-aware representations of knowledge graphs. However, they often utilize the information of relations and their interactions with entities inefficiently. Moreover, most state-of-the-art knowledge graph embedding models suffer from scalability issues because of assigning high-dimensional embeddings to entities and relations. To address the above limitations, we propose a scalable general knowledge graph encoder that adaptively involves a powerful tensor decomposition method in the aggregation function of RGCN, a well-known relational GNN model. Specifically, the parameters of a low-rank core projection tensor, used to transform neighborhood entities in the encoder, are shared across relations to benefit from multi-task learning and incorporate relations information effectively. Besides, we propose a low-rank estimation of the core tensor using CP decomposition to compress the model, which is also applicable, as a regularization method, to other similar linear models. We evaluated our model on knowledge graph completion as a common downstream task. We train our model for using a new loss function based on contrastive learning, which relieves the training limitation of the 1-N method on huge graphs. We improved RGCN performance on FB15-237 by 0.42% with considerably lower dimensionality of embeddings. ",
    "url": "https://arxiv.org/abs/2212.05581",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05589",
    "title": "Learning Neural Volumetric Field for Point Cloud Geometry Compression",
    "abstract": "Due to the diverse sparsity, high dimensionality, and large temporal variation of dynamic point clouds, it remains a challenge to design an efficient point cloud compression method. We propose to code the geometry of a given point cloud by learning a neural volumetric field. Instead of representing the entire point cloud using a single overfit network, we divide the entire space into small cubes and represent each non-empty cube by a neural network and an input latent code. The network is shared among all the cubes in a single frame or multiple frames, to exploit the spatial and temporal redundancy. The neural field representation of the point cloud includes the network parameters and all the latent codes, which are generated by using back-propagation over the network parameters and its input. By considering the entropy of the network parameters and the latent codes as well as the distortion between the original and reconstructed cubes in the loss function, we derive a rate-distortion (R-D) optimal representation. Experimental results show that the proposed coding scheme achieves superior R-D performances compared to the octree-based G-PCC, especially when applied to multiple frames of a point cloud video. The code is available at https://github.com/huzi96/NVFPCC/. ",
    "url": "https://arxiv.org/abs/2212.05589",
    "authors": [
      "Yueyu Hu",
      "Yao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.05598",
    "title": "Recurrent Vision Transformers for Object Detection with Event Cameras",
    "abstract": "We present Recurrent Vision Transformers (RVTs), a novel backbone for object detection with event cameras. Event cameras provide visual information with sub-millisecond latency at a high-dynamic range and with strong robustness against motion blur. These unique properties offer great potential for low-latency object detection and tracking in time-critical scenarios. Prior work in event-based vision has achieved outstanding detection performance but at the cost of substantial inference time, typically beyond 40 milliseconds. By revisiting the high-level design of recurrent vision backbones, we reduce inference time by a factor of 5 while retaining similar performance. To achieve this, we explore a multi-stage design that utilizes three key concepts in each stage: First, a convolutional prior that can be regarded as a conditional positional embedding. Second, local- and dilated global self-attention for spatial feature interaction. Third, recurrent temporal feature aggregation to minimize latency while retaining temporal information. RVTs can be trained from scratch to reach state-of-the-art performance on event-based object detection - achieving an mAP of 47.5% on the Gen1 automotive dataset. At the same time, RVTs offer fast inference (13 ms on a T4 GPU) and favorable parameter efficiency (5 times fewer than prior art). Our study brings new insights into effective design choices that could be fruitful for research beyond event-based vision. ",
    "url": "https://arxiv.org/abs/2212.05598",
    "authors": [
      "Mathias Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05610",
    "title": "Authorship Identification of Source Code Segments Written by Multiple  Authors Using Stacking Ensemble Method",
    "abstract": "Source code segment authorship identification is the task of identifying the author of a source code segment through supervised learning. It has vast importance in plagiarism detection, digital forensics, and several other law enforcement issues. However, when a source code segment is written by multiple authors, typical author identification methods no longer work. Here, an author identification technique, capable of predicting the authorship of source code segments, even in the case of multiple authors, has been proposed which uses a stacking ensemble classifier. This proposed technique is built upon several deep neural networks, random forests and support vector machine classifiers. It has been shown that for identifying the author group, a single classification technique is no longer sufficient and using a deep neural network-based stacking ensemble method can enhance the accuracy significantly. The performance of the proposed technique has been compared with some existing methods which only deal with the source code segments written precisely by a single author. Despite the harder task of authorship identification for source code segments written by multiple authors, our proposed technique has achieved promising results evidenced by the identification accuracy, compared to the related works which only deal with code segments written by a single author. ",
    "url": "https://arxiv.org/abs/2212.05610",
    "authors": [
      "Parvez Mahbub",
      "Naz Zarreen Oishie",
      "S M Rafizul Haque"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.05611",
    "title": "Accelerating Self-Supervised Learning via Efficient Training Strategies",
    "abstract": "Recently the focus of the computer vision community has shifted from expensive supervised learning towards self-supervised learning of visual representations. While the performance gap between supervised and self-supervised has been narrowing, the time for training self-supervised deep networks remains an order of magnitude larger than its supervised counterparts, which hinders progress, imposes carbon cost, and limits societal benefits to institutions with substantial resources. Motivated by these issues, this paper investigates reducing the training time of recent self-supervised methods by various model-agnostic strategies that have not been used for this problem. In particular, we study three strategies: an extendable cyclic learning rate schedule, a matching progressive augmentation magnitude and image resolutions schedule, and a hard positive mining strategy based on augmentation difficulty. We show that all three methods combined lead up to 2.7 times speed-up in the training time of several self-supervised methods while retaining comparable performance to the standard self-supervised learning setting. ",
    "url": "https://arxiv.org/abs/2212.05611",
    "authors": [
      "Mustafa Taha Ko\u00e7yi\u011fit",
      "Timothy M. Hospedales",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05613",
    "title": "A Study of Slang Representation Methods",
    "abstract": "Warning: this paper contains content that may be offensive or upsetting. Considering the large amount of content created online by the minute, slang-aware automatic tools are critically needed to promote social good, and assist policymakers and moderators in restricting the spread of offensive language, abuse, and hate speech. Despite the success of large language models and the spontaneous emergence of slang dictionaries, it is unclear how far their combination goes in terms of slang understanding for downstream social good tasks. In this paper, we provide a framework to study different combinations of representation learning models and knowledge resources for a variety of downstream tasks that rely on slang understanding. Our experiments show the superiority of models that have been pre-trained on social media data, while the impact of dictionaries is positive only for static word embeddings. Our error analysis identifies core challenges for slang representation learning, including out-of-vocabulary words, polysemy, variance, and annotation disagreements, which can be traced to characteristics of slang as a quickly evolving and highly subjective language. ",
    "url": "https://arxiv.org/abs/2212.05613",
    "authors": [
      "Aravinda Kolla",
      "Filip Ilievski",
      "H\u00f4ng-\u00c2n Sandlin",
      "Alain Mermoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05630",
    "title": "DISCO: Adversarial Defense with Local Implicit Functions",
    "abstract": "The problem of adversarial defenses for image classification, where the goal is to robustify a classifier against adversarial examples, is considered. Inspired by the hypothesis that these examples lie beyond the natural image manifold, a novel aDversarIal defenSe with local impliCit functiOns (DISCO) is proposed to remove adversarial perturbations by localized manifold projections. DISCO consumes an adversarial image and a query pixel location and outputs a clean RGB value at the location. It is implemented with an encoder and a local implicit module, where the former produces per-pixel deep features and the latter uses the features in the neighborhood of query pixel for predicting the clean RGB value. Extensive experiments demonstrate that both DISCO and its cascade version outperform prior defenses, regardless of whether the defense is known to the attacker. DISCO is also shown to be data and parameter efficient and to mount defenses that transfers across datasets, classifiers and attacks. ",
    "url": "https://arxiv.org/abs/2212.05630",
    "authors": [
      "Chih-Hui Ho",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05643",
    "title": "Detecting Code Injections in Noisy Environments Through EM Signal  Analysis and SVD Denoising",
    "abstract": "The penetration of embedded devices in networks that support critical applications has rendered them a lucrative target for attackers and evildoers. However, traditional protection mechanisms may not be supported due to the memory and computational limitations of these systems. Recently, the analysis of electromagnetic (EM) emanations has gathered the interest of the research community. Thus, analogous protection systems have emerged as a viable solution e.g., for providing external, non-intrusive control-flow attestation for resource-constrained devices. Unfortunately, the majority of current work fails to account for the implications of real-life factors, predominantly the impact of environmental noise. In this work, we introduce a framework that integrates singular value decomposition (SVD) along with outlier detection for discovering malicious modifications of embedded software even under variable conditions of noise. Our proposed framework achieves high detection accuracy i.e., above 93\\% AUC score for unknown attacks, even for extreme noise conditions i.e., -10 SNR. To the best of our knowledge, this is the first time this realistic limiting factor, i.e., environmental noise, is successfully addressed in the context of EM-based anomaly detection for embedded devices. ",
    "url": "https://arxiv.org/abs/2212.05643",
    "authors": [
      "Ekaterina Miller",
      "Georgios Michail Makrakis",
      "Kurt A. Vedros",
      "Constantinos Kolias",
      "Craig Rieger",
      "Daniel Barbara"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05648",
    "title": "DRIVE: Dockerfile Rule Mining and Violation Detection",
    "abstract": "A Dockerfile defines a set of instructions to build Docker images, which can then be instantiated to support containerized applications. Recent studies have revealed a considerable amount of quality issues with Dockerfiles. In this paper, we propose a novel approach DRIVE (Dockerfiles Rule mIning and Violation dEtection) to mine implicit rules and detect potential violations of such rules in Dockerfiles. DRIVE firstly parses Dockerfiles and transforms them to an intermediate representation. It then leverages an efficient sequential pattern mining algorithm to extract potential patterns. With heuristic-based reduction and moderate human intervention, potential rules are identified, which can then be utilized to detect potential violations of Dockerfiles. DRIVE identifies 34 semantic rules and 19 syntactic rules including 9 new semantic rules which have not been reported elsewhere. Extensive experiments on real-world Dockerfiles demonstrate the efficacy of our approach. ",
    "url": "https://arxiv.org/abs/2212.05648",
    "authors": [
      "Yu Zhou",
      "Weilin Zhan",
      "Zi Li",
      "Tingting Han",
      "Taolue Chen",
      "Harald Gall"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.05653",
    "title": "Spatial-temporal traffic modeling with a fusion graph reconstructed by  tensor decomposition",
    "abstract": "Accurate spatial-temporal traffic flow forecasting is essential for helping traffic managers to take control measures and drivers to choose the optimal travel routes. Recently, graph convolutional networks (GCNs) have been widely used in traffic flow prediction owing to their powerful ability to capture spatial-temporal dependencies. The design of the spatial-temporal graph adjacency matrix is a key to the success of GCNs, and it is still an open question. This paper proposes reconstructing the binary adjacency matrix via tensor decomposition, and a traffic flow forecasting method is proposed. First, we reformulate the spatial-temporal fusion graph adjacency matrix into a three-way adjacency tensor. Then, we reconstructed the adjacency tensor via Tucker decomposition, wherein more informative and global spatial-temporal dependencies are encoded. Finally, a Spatial-temporal Synchronous Graph Convolutional module for localized spatial-temporal correlations learning and a Dilated Convolution module for global correlations learning are assembled to aggregate and learn the comprehensive spatial-temporal dependencies of the road network. Experimental results on four open-access datasets demonstrate that the proposed model outperforms state-of-the-art approaches in terms of the prediction performance and computational cost. ",
    "url": "https://arxiv.org/abs/2212.05653",
    "authors": [
      "Qin Li",
      "Xuan Yang",
      "Yong Wang",
      "Yuankai Wu",
      "Deqiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05667",
    "title": "Fighting Malicious Media Data: A Survey on Tampering Detection and  Deepfake Detection",
    "abstract": "Online media data, in the forms of images and videos, are becoming mainstream communication channels. However, recent advances in deep learning, particularly deep generative models, open the doors for producing perceptually convincing images and videos at a low cost, which not only poses a serious threat to the trustworthiness of digital information but also has severe societal implications. This motivates a growing interest of research in media tampering detection, i.e., using deep learning techniques to examine whether media data have been maliciously manipulated. Depending on the content of the targeted images, media forgery could be divided into image tampering and Deepfake techniques. The former typically moves or erases the visual elements in ordinary images, while the latter manipulates the expressions and even the identity of human faces. Accordingly, the means of defense include image tampering detection and Deepfake detection, which share a wide variety of properties. In this paper, we provide a comprehensive review of the current media tampering detection approaches, and discuss the challenges and trends in this field for future research. ",
    "url": "https://arxiv.org/abs/2212.05667",
    "authors": [
      "Junke Wang",
      "Zhenxin Li",
      "Chao Zhang",
      "Jingjing Chen",
      "Zuxuan Wu",
      "Larry S. Davis",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05679",
    "title": "Evolutionary Multitasking with Solution Space Cutting for Point Cloud  Registration",
    "abstract": "Point cloud registration (PCR) is a popular research topic in computer vision. Recently, the registration method in an evolutionary way has received continuous attention because of its robustness to the initial pose and flexibility in objective function design. However, most evolving registration methods cannot tackle the local optimum well and they have rarely investigated the success ratio, which implies the probability of not falling into local optima and is closely related to the practicality of the algorithm. Evolutionary multi-task optimization (EMTO) is a widely used paradigm, which can boost exploration capability through knowledge transfer among related tasks. Inspired by this concept, this study proposes a novel evolving registration algorithm via EMTO, where the multi-task configuration is based on the idea of solution space cutting. Concretely, one task searching in cut space assists another task with complex function landscape in escaping from local optima and enhancing successful registration ratio. To reduce unnecessary computational cost, a sparse-to-dense strategy is proposed. In addition, a novel fitness function robust to various overlap rates as well as a problem-specific metric of computational cost is introduced. Compared with 7 evolving registration approaches and 4 traditional registration approaches on the object-scale and scene-scale registration datasets, experimental results demonstrate that the proposed method has superior performances in terms of precision and tackling local optima. ",
    "url": "https://arxiv.org/abs/2212.05679",
    "authors": [
      "Wu Yue",
      "Peiran Gong",
      "Maoguo Gong",
      "Hangqi Ding",
      "Zedong Tang",
      "Yibo Liu",
      "Wenping Ma",
      "Qiguang Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05680",
    "title": "REAP: A Large-Scale Realistic Adversarial Patch Benchmark",
    "abstract": "Machine learning models are known to be susceptible to adversarial perturbation. One famous attack is the adversarial patch, a sticker with a particularly crafted pattern that makes the model incorrectly predict the object it is placed on. This attack presents a critical threat to cyber-physical systems that rely on cameras such as autonomous cars. Despite the significance of the problem, conducting research in this setting has been difficult; evaluating attacks and defenses in the real world is exceptionally costly while synthetic data are unrealistic. In this work, we propose the REAP (REalistic Adversarial Patch) benchmark, a digital benchmark that allows the user to evaluate patch attacks on real images, and under real-world conditions. Built on top of the Mapillary Vistas dataset, our benchmark contains over 14,000 traffic signs. Each sign is augmented with a pair of geometric and lighting transformations, which can be used to apply a digitally generated patch realistically onto the sign. Using our benchmark, we perform the first large-scale assessments of adversarial patch attacks under realistic conditions. Our experiments suggest that adversarial patch attacks may present a smaller threat than previously believed and that the success rate of an attack on simpler digital simulations is not predictive of its actual effectiveness in practice. We release our benchmark publicly at https://github.com/wagner-group/reap-benchmark. ",
    "url": "https://arxiv.org/abs/2212.05680",
    "authors": [
      "Nabeel Hingun",
      "Chawin Sitawarin",
      "Jerry Li",
      "David Wagner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05691",
    "title": "CircleNet: Reciprocating Feature Adaptation for Robust Pedestrian  Detection",
    "abstract": "Pedestrian detection in the wild remains a challenging problem especially when the scene contains significant occlusion and/or low resolution of the pedestrians to be detected. Existing methods are unable to adapt to these difficult cases while maintaining acceptable performance. In this paper we propose a novel feature learning model, referred to as CircleNet, to achieve feature adaptation by mimicking the process humans looking at low resolution and occluded objects: focusing on it again, at a finer scale, if the object can not be identified clearly for the first time. CircleNet is implemented as a set of feature pyramids and uses weight sharing path augmentation for better feature fusion. It targets at reciprocating feature adaptation and iterative object detection using multiple top-down and bottom-up pathways. To take full advantage of the feature adaptation capability in CircleNet, we design an instance decomposition training strategy to focus on detecting pedestrian instances of various resolutions and different occlusion levels in each cycle. Specifically, CircleNet implements feature ensemble with the idea of hard negative boosting in an end-to-end manner. Experiments on two pedestrian detection datasets, Caltech and CityPersons, show that CircleNet improves the performance of occluded and low-resolution pedestrians with significant margins while maintaining good performance on normal instances. ",
    "url": "https://arxiv.org/abs/2212.05691",
    "authors": [
      "Tianliang Zhang",
      "Zhenjun Han",
      "Huijuan Xu",
      "Baochang Zhang",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05699",
    "title": "MMNet: Multi-modal Fusion with Mutual Learning Network for Fake News  Detection",
    "abstract": "The rapid development of social media provides a hotbed for the dissemination of fake news, which misleads readers and causes negative effects on society. News usually involves texts and images to be more vivid. Consequently, multi-modal fake news detection has received wide attention. Prior efforts primarily conduct multi-modal fusion by simple concatenation or co-attention mechanism, leading to sub-optimal performance. In this paper, we propose a novel mutual learning network based model MMNet, which enhances the multi-modal fusion for fake news detection via mutual learning between text- and vision-centered views towards the same classification objective. Specifically, we design two detection modules respectively based on text- and vision-centered multi-modal fusion features, and enable the mutual learning of the two modules to facilitate the multi-modal fusion, considering the latent consistency between the two modules towards the same training objective. Moreover, we also consider the influence of the image-text matching degree on news authenticity judgement by designing an image-text matching aware co-attention mechanism for multi-modal fusion. Extensive experiments are conducted on three benchmark datasets and the results demonstrate that our proposed MMNet achieves superior performance in fake news detection. ",
    "url": "https://arxiv.org/abs/2212.05699",
    "authors": [
      "Linmei Hu",
      "Ziwang Zhao",
      "Xinkai Ge",
      "Xuemeng Song",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2212.05705",
    "title": "An Integrated LiDAR-SLAM System for Complex Environment with Noisy Point  Clouds",
    "abstract": "The current LiDAR SLAM (Simultaneous Localization and Mapping) system suffers greatly from low accuracy and limited robustness when faced with complicated circumstances. From our experiments, we find that current LiDAR SLAM systems have limited performance when the noise level in the obtained point clouds is large. Therefore, in this work, we propose a general framework to tackle the problem of denoising and loop closure for LiDAR SLAM in complex environments with many noises and outliers caused by reflective materials. Current approaches for point clouds denoising are mainly designed for small-scale point clouds and can not be extended to large-scale point clouds scenes. In this work, we firstly proposed a lightweight network for large-scale point clouds denoising. Subsequently, we have also designed an efficient loop closure network for place recognition in global optimization to improve the localization accuracy of the whole system. Finally, we have demonstrated by extensive experiments and benchmark studies that our method can have a significant boost on the localization accuracy of the LiDAR SLAM system when faced with noisy point clouds, with a marginal increase in computational cost. ",
    "url": "https://arxiv.org/abs/2212.05705",
    "authors": [
      "Kangcheng Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.05706",
    "title": "Detection Selection Algorithm: A Likelihood based Optimization Method to  Perform Post Processing for Object Detection",
    "abstract": "In object detection, post-processing methods like Non-maximum Suppression (NMS) are widely used. NMS can substantially reduce the number of false positive detections but may still keep some detections with low objectness scores. In order to find the exact number of objects and their labels in the image, we propose a post processing method called Detection Selection Algorithm (DSA) which is used after NMS or related methods. DSA greedily selects a subset of detected bounding boxes, together with full object reconstructions that give the interpretation of the whole image with highest likelihood, taking into account object occlusions. The algorithm consists of four components. First, we add an occlusion branch to Faster R-CNN to obtain occlusion relationships between objects. Second, we develop a single reconstruction algorithm which can reconstruct the whole appearance of an object given its visible part, based on the optimization of latent variables of a trained generative network which we call the decoder. Third, we propose a whole reconstruction algorithm which generates the joint reconstruction of all objects in a hypothesized interpretation, taking into account occlusion ordering. Finally we propose a greedy algorithm that incrementally adds or removes detections from a list to maximize the likelihood of the corresponding interpretation. DSA with NMS or Soft-NMS can achieve better results than NMS or Soft-NMS themselves, as is illustrated in our experiments on synthetic images with mutiple 3d objects. ",
    "url": "https://arxiv.org/abs/2212.05706",
    "authors": [
      "Angzhi Fan",
      "Benjamin Ticknor",
      "Yali Amit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05707",
    "title": "Human Mobility Modeling During the COVID-19 Pandemic via Deep Graph  Diffusion Infomax",
    "abstract": "Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modeled human mobility via macro indicators (e.g., average daily travel distance) and then studied the effectiveness of NPIs. In this work, we focus on mobility modeling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a micro perspective prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (i.e., limited case and location information). To address these challenges, we formulate the micro perspective mobility modeling into computing the relevance score between a diffusion and a location, conditional on a geometric graph. we propose a model named Deep Graph Diffusion Infomax (DGDI), which jointly models variables including a geometric graph, a set of diffusions and a set of locations.To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods. ",
    "url": "https://arxiv.org/abs/2212.05707",
    "authors": [
      "Yang Liu",
      "Yu Rong",
      "Zhuoning Guo",
      "Nuo Chen",
      "Tingyang Xu",
      "Fugee Tsung",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05716",
    "title": "On Generalization and Regularization via Wasserstein Distributionally  Robust Optimization",
    "abstract": "Wasserstein distributionally robust optimization (DRO) has found success in operations research and machine learning applications as a powerful means to obtain solutions with favourable out-of-sample performances. Two compelling explanations for the success are the generalization bounds derived from Wasserstein DRO and the equivalency between Wasserstein DRO and the regularization scheme commonly applied in machine learning. Existing results on generalization bounds and the equivalency to regularization are largely limited to the setting where the Wasserstein ball is of a certain type and the decision criterion takes certain forms of an expected function. In this paper, we show that by focusing on Wasserstein DRO problems with affine decision rules, it is possible to obtain generalization bounds and the equivalency to regularization in a significantly broader setting where the Wasserstein ball can be of a general type and the decision criterion can be a general measure of risk, i.e., nonlinear in distributions. This allows for accommodating many important classification, regression, and risk minimization applications that have not been addressed to date using Wasserstein DRO. Our results are strong in that the generalization bounds do not suffer from the curse of dimensionality and the equivalency to regularization is exact. As a byproduct, our regularization results broaden considerably the class of Wasserstein DRO models that can be solved efficiently via regularization formulations. ",
    "url": "https://arxiv.org/abs/2212.05716",
    "authors": [
      "Qinyu Wu",
      "Jonathan Yu-Meng Li",
      "Tiantian Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.05717",
    "title": "Feature Calibration Network for Occluded Pedestrian Detection",
    "abstract": "Pedestrian detection in the wild remains a challenging problem especially for scenes containing serious occlusion. In this paper, we propose a novel feature learning method in the deep learning framework, referred to as Feature Calibration Network (FC-Net), to adaptively detect pedestrians under various occlusions. FC-Net is based on the observation that the visible parts of pedestrians are selective and decisive for detection, and is implemented as a self-paced feature learning framework with a self-activation (SA) module and a feature calibration (FC) module. In a new self-activated manner, FC-Net learns features which highlight the visible parts and suppress the occluded parts of pedestrians. The SA module estimates pedestrian activation maps by reusing classifier weights, without any additional parameter involved, therefore resulting in an extremely parsimony model to reinforce the semantics of features, while the FC module calibrates the convolutional features for adaptive pedestrian representation in both pixel-wise and region-based ways. Experiments on CityPersons and Caltech datasets demonstrate that FC-Net improves detection performance on occluded pedestrians up to 10% while maintaining excellent performance on non-occluded instances. ",
    "url": "https://arxiv.org/abs/2212.05717",
    "authors": [
      "Tianliang Zhang",
      "Qixiang Ye",
      "Baochang Zhang",
      "Jianzhuang Liu",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05720",
    "title": "Tensor-based Sequential Learning via Hankel Matrix Representation for  Next Item Recommendations",
    "abstract": "Self-attentive transformer models have recently been shown to solve the next item recommendation task very efficiently. The learned attention weights capture sequential dynamics in user behavior and generalize well. Motivated by the special structure of learned parameter space, we question if it is possible to mimic it with an alternative and more lightweight approach. We develop a new tensor factorization-based model that ingrains the structural knowledge about sequential data within the learning process. We demonstrate how certain properties of a self-attention network can be reproduced with our approach based on special Hankel matrix representation. The resulting model has a shallow linear architecture and compares competitively to its neural counterpart. ",
    "url": "https://arxiv.org/abs/2212.05720",
    "authors": [
      "Evgeny Frolov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.05722",
    "title": "HDNet: A Hierarchically Decoupled Network for Crowd Counting",
    "abstract": "Recently, density map regression-based methods have dominated in crowd counting owing to their excellent fitting ability on density distribution. However, further improvement tends to saturate mainly because of the confusing background noise and the large density variation. In this paper, we propose a Hierarchically Decoupled Network (HDNet) to solve the above two problems within a unified framework. Specifically, a background classification sub-task is decomposed from the density map prediction task, which is then assigned to a Density Decoupling Module (DDM) to exploit its highly discriminative ability. For the remaining foreground prediction sub-task, it is further hierarchically decomposed to several density-specific sub-tasks by the DDM, which are then solved by the regression-based experts in a Foreground Density Estimation Module (FDEM). Although the proposed strategy effectively reduces the hypothesis space so as to relieve the optimization for those task-specific experts, the high correlation of these sub-tasks are ignored. Therefore, we introduce three types of interaction strategies to unify the whole framework, which are Feature Interaction, Gradient Interaction, and Scale Interaction. Integrated with the above spirits, HDNet achieves state-of-the-art performance on several popular counting benchmarks. ",
    "url": "https://arxiv.org/abs/2212.05722",
    "authors": [
      "Chenliang Gu",
      "Changan Wang",
      "Bin-Bin Gao",
      "Jun Liu",
      "Tianliang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05728",
    "title": "Stimuli Dependent Synergy and Redundancy Dominated Causal Effects in  Time Series",
    "abstract": "We characterize the degree of synergy- and redundancy-dominated causal influence a time series has upon the interaction between other time series. We prove that for a class of time series, the early past of the stimuli yields a synergistic effect upon the interaction, whereas the late past has a redundancy-dominated effect. Our information theoretic quantities are easy to compute in practice, and we provide simulation studies on synthetic time series and real-world signals. As an example, we use our measures on intracranial EEG data to demonstrate that the stimuli from specific deep electrodes cause a synergistic exchange of information to take place between different brain regions during seizures. ",
    "url": "https://arxiv.org/abs/2212.05728",
    "authors": [
      "Jan \u00d8stergaard",
      "Payam Boubakani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.05729",
    "title": "ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient  Self-Supervised Monocular Depth Estimation",
    "abstract": "The exploration of mutual-benefit cross-domains has shown great potential toward accurate self-supervised depth estimation. In this work, we revisit feature fusion between depth and semantic information and propose an efficient local adaptive attention method for geometric aware representation enhancement. Instead of building global connections or deforming attention across the feature space without restraint, we bound the spatial interaction within a learnable region of interest. In particular, we leverage geometric cues from semantic information to learn local adaptive bounding boxes to guide unsupervised feature aggregation. The local areas preclude most irrelevant reference points from attention space, yielding more selective feature learning and faster convergence. We naturally extend the paradigm into a multi-head and hierarchic way to enable the information distillation in different semantic levels and improve the feature discriminative ability for fine-grained depth estimation. Extensive experiments on the KITTI dataset show that our proposed method establishes a new state-of-the-art in self-supervised monocular depth estimation task, demonstrating the effectiveness of our approach over former Transformer variants. ",
    "url": "https://arxiv.org/abs/2212.05729",
    "authors": [
      "Daitao Xing",
      "Jinglin Shen",
      "Chiuman Ho",
      "Anthony Tzes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05735",
    "title": "Adaptive Low-Precision Training for Embeddings in Click-Through Rate  Prediction",
    "abstract": "Embedding tables are usually huge in click-through rate (CTR) prediction models. To train and deploy the CTR models efficiently and economically, it is necessary to compress their embedding tables at the training stage. To this end, we formulate a novel quantization training paradigm to compress the embeddings from the training stage, termed low-precision training (LPT). Also, we provide theoretical analysis on its convergence. The results show that stochastic weight quantization has a faster convergence rate and a smaller convergence error than deterministic weight quantization in LPT. Further, to reduce the accuracy degradation, we propose adaptive low-precision training (ALPT) that learns the step size (i.e., the quantization resolution) through gradient descent. Experiments on two real-world datasets confirm our analysis and show that ALPT can significantly improve the prediction accuracy, especially at extremely low bit widths. For the first time in CTR models, we successfully train 8-bit embeddings without sacrificing prediction accuracy. The code of ALPT is publicly available. ",
    "url": "https://arxiv.org/abs/2212.05735",
    "authors": [
      "Shiwei Li",
      "Huifeng Guo",
      "Lu Hou",
      "Wei Zhang",
      "Xing Tang",
      "Ruiming Tang",
      "Rui Zhang",
      "Ruixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.05744",
    "title": "Hitting Times of Random Walks on Edge Corona Product Graphs",
    "abstract": "Graph products have been extensively applied to model complex networks with striking properties observed in real-world complex systems. In this paper, we study the hitting times for random walks on a class of graphs generated iteratively by edge corona product. We first derive recursive solutions to the eigenvalues and eigenvectors of the normalized adjacency matrix associated with the graphs. Based on these results, we further obtain interesting quantities about hitting times of random walks, providing iterative formulas for two-node hitting time, as well as closed-form expressions for the Kemeny's constant defined as a weighted average of hitting times over all node pairs, as well as the arithmetic mean of hitting times of all pairs of nodes. ",
    "url": "https://arxiv.org/abs/2212.05744",
    "authors": [
      "Mingzhe Zhu",
      "Wanyue Xu",
      "Wei Li",
      "Zhongzhi Zhang",
      "Haibin Kan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05752",
    "title": "Scale-Semantic Joint Decoupling Network for Image-text Retrieval in  Remote Sensing",
    "abstract": "Image-text retrieval in remote sensing aims to provide flexible information for data analysis and application. In recent years, state-of-the-art methods are dedicated to ``scale decoupling'' and ``semantic decoupling'' strategies to further enhance the capability of representation. However, these previous approaches focus on either the disentangling scale or semantics but ignore merging these two ideas in a union model, which extremely limits the performance of cross-modal retrieval models. To address these issues, we propose a novel Scale-Semantic Joint Decoupling Network (SSJDN) for remote sensing image-text retrieval. Specifically, we design the Bidirectional Scale Decoupling (BSD) module, which exploits Salience Feature Extraction (SFE) and Salience-Guided Suppression (SGS) units to adaptively extract potential features and suppress cumbersome features at other scales in a bidirectional pattern to yield different scale clues. Besides, we design the Label-supervised Semantic Decoupling (LSD) module by leveraging the category semantic labels as prior knowledge to supervise images and texts probing significant semantic-related information. Finally, we design a Semantic-guided Triple Loss (STL), which adaptively generates a constant to adjust the loss function to improve the probability of matching the same semantic image and text and shorten the convergence time of the retrieval model. Our proposed SSJDN outperforms state-of-the-art approaches in numerical experiments conducted on four benchmark remote sensing datasets. ",
    "url": "https://arxiv.org/abs/2212.05752",
    "authors": [
      "Chengyu Zheng",
      "Ning song",
      "Ruoyu Zhang",
      "Lei Huang",
      "Zhiqiang Wei",
      "Jie Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05759",
    "title": "Resistance Distances in Simplicial Networks",
    "abstract": "It is well known that in many real networks, such as brain networks and scientific collaboration networks, there exist higher-order nonpairwise relations among nodes, i.e., interactions between among than two nodes at a time. This simplicial structure can be described by simplicial complexes and has an important effect on topological and dynamical properties of networks involving such group interactions. In this paper, we study analytically resistance distances in iteratively growing networks with higher-order interactions characterized by the simplicial structure that is controlled by a parameter q. We derive exact formulas for interesting quantities about resistance distances, including Kirchhoff index, additive degree-Kirchhoff index, multiplicative degree-Kirchhoff index, as well as average resistance distance, which have found applications in various areas elsewhere. We show that the average resistance distance tends to a q-dependent constant, indicating the impact of simplicial organization on the structural robustness measured by average resistance distance. ",
    "url": "https://arxiv.org/abs/2212.05759",
    "authors": [
      "Mingzhe Zhu",
      "Wanyue Xu",
      "Zhongzhi Zhang",
      "Haibin Kan",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05778",
    "title": "Instrumental Variables in Causal Inference and Machine Learning: A  Survey",
    "abstract": "Causal inference is the process of using assumptions, study designs, and estimation strategies to draw conclusions about the causal relationships between variables based on data. This allows researchers to better understand the underlying mechanisms at work in complex systems and make more informed decisions. In many settings, we may not fully observe all the confounders that affect both the treatment and outcome variables, complicating the estimation of causal effects. To address this problem, a growing literature in both causal inference and machine learning proposes to use Instrumental Variables (IV). This paper serves as the first effort to systematically and comprehensively introduce and discuss the IV methods and their applications in both causal inference and machine learning. First, we provide the formal definition of IVs and discuss the identification problem of IV regression methods under different assumptions. Second, we categorize the existing work on IV methods into three streams according to the focus on the proposed methods, including two-stage least squares with IVs, control function with IVs, and evaluation of IVs. For each stream, we present both the classical causal inference methods, and recent developments in the machine learning literature. Then, we introduce a variety of applications of IV methods in real-world scenarios and provide a summary of the available datasets and algorithms. Finally, we summarize the literature, discuss the open problems and suggest promising future research directions for IV methods and their applications. We also develop a toolkit of IVs methods reviewed in this survey at https://github.com/causal-machine-learning-lab/mliv. ",
    "url": "https://arxiv.org/abs/2212.05778",
    "authors": [
      "Anpeng Wu",
      "Kun Kuang",
      "Ruoxuan Xiong",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.05781",
    "title": "Robust Recurrent Neural Network to Identify Ship Motion in Open Water  with Performance Guarantees -- Technical Report",
    "abstract": "Recurrent neural networks are capable of learning the dynamics of an unknown nonlinear system purely from input-output measurements. However, the resulting models do not provide any stability guarantees on the input-output mapping. In this work, we represent a recurrent neural network as a linear time-invariant system with nonlinear disturbances. By introducing constraints on the parameters, we can guarantee finite gain stability and incremental finite gain stability. We apply this identification method to learn the motion of a four-degrees-of-freedom ship that is moving in open water and compare it against other purely learning-based approaches with unconstrained parameters. Our analysis shows that the constrained recurrent neural network has a lower prediction accuracy on the test set, but it achieves comparable results on an out-of-distribution set and respects stability conditions. ",
    "url": "https://arxiv.org/abs/2212.05781",
    "authors": [
      "Daniel Frank",
      "Decky Aspandi Latif",
      "Michael Muehlebach",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05782",
    "title": "GT-CausIn: a novel causal-based insight for traffic prediction",
    "abstract": "Traffic forecasting is an important application of spatiotemporal series prediction. Among different methods, graph neural networks have achieved so far the most promising results, learning relations between graph nodes then becomes a crucial task. However, improvement space is very limited when these relations are learned in a node-to-node manner. The challenge stems from (1) obscure temporal dependencies between different stations, (2) difficulties in defining variables beyond the node level, and (3) no ready-made method to validate the learned relations. To confront these challenges, we define legitimate traffic causal variables to discover the causal relation inside the traffic network, which is carefully checked with statistic tools and case analysis. We then present a novel model named Graph Spatial-Temporal Network Based on Causal Insight (GT-CausIn), where prior learned causal information is integrated with graph diffusion layers and temporal convolutional network (TCN) layers. Experiments are carried out on two real-world traffic datasets: PEMS-BAY and METR-LA, which show that GT-CausIn significantly outperforms the state-of-the-art models on mid-term and long-term prediction. ",
    "url": "https://arxiv.org/abs/2212.05782",
    "authors": [
      "Ting Gao",
      "Rodrigo Kappes Marques",
      "Lei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05789",
    "title": "Collaborating Heterogeneous Natural Language Processing Tasks via  Federated Learning",
    "abstract": "The increasing privacy concerns on personal private text data promote the development of federated learning (FL) in recent years. However, the existing studies on applying FL in NLP are not suitable to coordinate participants with heterogeneous or private learning objectives. In this study, we further broaden the application scope of FL in NLP by proposing an Assign-Then-Contrast (denoted as ATC) framework, which enables clients with heterogeneous NLP tasks to construct an FL course and learn useful knowledge from each other. Specifically, the clients are suggested to first perform local training with the unified tasks assigned by the server rather than using their own learning objectives, which is called the Assign training stage. After that, in the Contrast training stage, clients train with different local learning objectives and exchange knowledge with other clients who contribute consistent and useful model updates. We conduct extensive experiments on six widely-used datasets covering both Natural Language Understanding (NLU) and Natural Language Generation (NLG) tasks, and the proposed ATC framework achieves significant improvements compared with various baseline methods. The source code is available at \\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}. ",
    "url": "https://arxiv.org/abs/2212.05789",
    "authors": [
      "Chenhe Dong",
      "Yuexiang Xie",
      "Bolin Ding",
      "Ying Shen",
      "Yaliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.05798",
    "title": "BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph",
    "abstract": "Answering complex questions over textual resources remains a challenging problem$\\unicode{x2013}$especially when interpreting the fine-grained relationships among multiple entities that occur within a natural-language question or clue. Curated knowledge bases (KBs), such as YAGO, DBpedia, Freebase and Wikidata, have been widely used in this context and gained great acceptance for question-answering (QA) applications in the past decade. While current KBs offer a concise representation of structured knowledge, they lack the variety of formulations and semantic nuances as well as the context of information provided by the natural-language sources. With BigText-QA, we aim to develop an integrated QA system which is able to answer questions based on a more redundant form of a knowledge graph (KG) that organizes both structured and unstructured (i.e., \"hybrid\") knowledge in a unified graphical representation. BigText-QA thereby is able to combine the best of both worlds$\\unicode{x2013}$a canonical set of named entities, mapped to a structured background KB (such as YAGO or Wikidata), as well as an open set of textual clauses providing highly diversified relational paraphrases with rich context information. ",
    "url": "https://arxiv.org/abs/2212.05798",
    "authors": [
      "Jingjing Xu",
      "Maria Biryukov",
      "Martin Theobald",
      "Vinu Ellampallil Venugopal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05810",
    "title": "Transfer Learning using Spectral Convolutional Autoencoders on  Semi-Regular Surface Meshes",
    "abstract": "The underlying dynamics and patterns of 3D surface meshes deforming over time can be discovered by unsupervised learning, especially autoencoders, which calculate low-dimensional embeddings of the surfaces. To study the deformation patterns of unseen shapes by transfer learning, we want to train an autoencoder that can analyze new surface meshes without training a new network. Here, most state-of-the-art autoencoders cannot handle meshes of different connectivity and therefore have limited to no generalization capacities to new meshes. Also, reconstruction errors strongly increase in comparison to the errors for the training shapes. To address this, we propose a novel spectral CoSMA (Convolutional Semi-Regular Mesh Autoencoder) network. This patch-based approach is combined with a surface-aware training. It reconstructs surfaces not presented during training and generalizes the deformation behavior of the surfaces' patches. The novel approach reconstructs unseen meshes from different datasets in superior quality compared to state-of-the-art autoencoders that have been trained on these shapes. Our transfer learning errors on unseen shapes are 40% lower than those from models learned directly on the data. Furthermore, baseline autoencoders detect deformation patterns of unseen mesh sequences only for the whole shape. In contrast, due to the employed regional patches and stable reconstruction quality, we can localize where on the surfaces these deformation patterns manifest. ",
    "url": "https://arxiv.org/abs/2212.05810",
    "authors": [
      "Sara Hahner",
      "Felix Kerkhoff",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05827",
    "title": "Carpet-bombing patch: attacking a deep network without usual  requirements",
    "abstract": "Although deep networks have shown vulnerability to evasion attacks, such attacks have usually unrealistic requirements. Recent literature discussed the possibility to remove or not some of these requirements. This paper contributes to this literature by introducing a carpet-bombing patch attack which has almost no requirement. Targeting the feature representations, this patch attack does not require knowing the network task. This attack decreases accuracy on Imagenet, mAP on Pascal Voc, and IoU on Cityscapes without being aware that the underlying tasks involved classification, detection or semantic segmentation, respectively. Beyond the potential safety issues raised by this attack, the impact of the carpet-bombing attack highlights some interesting property of deep network layer dynamic. ",
    "url": "https://arxiv.org/abs/2212.05827",
    "authors": [
      "Pol Labarbarie",
      "Adrien Chan-Hon-Tong",
      "St\u00e9phane Herbin",
      "Milad Leyli-Abadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05830",
    "title": "P-Transformer: Towards Better Document-to-Document Neural Machine  Translation",
    "abstract": "Directly training a document-to-document (Doc2Doc) neural machine translation (NMT) via Transformer from scratch, especially on small datasets usually fails to converge. Our dedicated probing tasks show that 1) both the absolute position and relative position information gets gradually weakened or even vanished once it reaches the upper encoder layers, and 2) the vanishing of absolute position information in encoder output causes the training failure of Doc2Doc NMT. To alleviate this problem, we propose a position-aware Transformer (P-Transformer) to enhance both the absolute and relative position information in both self-attention and cross-attention. Specifically, we integrate absolute positional information, i.e., position embeddings, into the query-key pairs both in self-attention and cross-attention through a simple yet effective addition operation. Moreover, we also integrate relative position encoding in self-attention. The proposed P-Transformer utilizes sinusoidal position encoding and does not require any task-specified position embedding, segment embedding, or attention mechanism. Through the above methods, we build a Doc2Doc NMT model with P-Transformer, which ingests the source document and completely generates the target document in a sequence-to-sequence (seq2seq) way. In addition, P-Transformer can be applied to seq2seq-based document-to-sentence (Doc2Sent) and sentence-to-sentence (Sent2Sent) translation. Extensive experimental results of Doc2Doc NMT show that P-Transformer significantly outperforms strong baselines on widely-used 9 document-level datasets in 7 language pairs, covering small-, middle-, and large-scales, and achieves a new state-of-the-art. Experimentation on discourse phenomena shows that our Doc2Doc NMT models improve the translation quality in both BLEU and discourse coherence. We make our code available on Github. ",
    "url": "https://arxiv.org/abs/2212.05830",
    "authors": [
      "Yachao Li",
      "Junhui Li",
      "Jing Jiang",
      "Shimin Tao",
      "Hao Yang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.05843",
    "title": "Optimizing ship detection efficiency in SAR images",
    "abstract": "The detection and prevention of illegal fishing is critical to maintaining a healthy and functional ecosystem. Recent research on ship detection in satellite imagery has focused exclusively on performance improvements, disregarding detection efficiency. However, the speed and compute cost of vessel detection are essential for a timely intervention to prevent illegal fishing. Therefore, we investigated optimization methods that lower detection time and cost with minimal performance loss. We trained an object detection model based on a convolutional neural network (CNN) using a dataset of satellite images. Then, we designed two efficiency optimizations that can be applied to the base CNN or any other base model. The optimizations consist of a fast, cheap classification model and a statistical algorithm. The integration of the optimizations with the object detection model leads to a trade-off between speed and performance. We studied the trade-off using metrics that give different weight to execution time and performance. We show that by using a classification model the average precision of the detection model can be approximated to 99.5% in 44% of the time or to 92.7% in 25% of the time. ",
    "url": "https://arxiv.org/abs/2212.05843",
    "authors": [
      "Arthur Van Meerbeeck",
      "Jordy Van Landeghem",
      "Ruben Cartuyvels",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05845",
    "title": "CbwLoss: Constrained Bidirectional Weighted Loss for Self-supervised  Learning of Depth and Pose",
    "abstract": "Photometric differences are widely used as supervision signals to train neural networks for estimating depth and camera pose from unlabeled monocular videos. However, this approach is detrimental for model optimization because occlusions and moving objects in a scene violate the underlying static scenario assumption. In addition, pixels in textureless regions or less discriminative pixels hinder model training. To solve these problems, in this paper, we deal with moving objects and occlusions utilizing the difference of the flow fields and depth structure generated by affine transformation and view synthesis, respectively. Secondly, we mitigate the effect of textureless regions on model optimization by measuring differences between features with more semantic and contextual information without adding networks. In addition, although the bidirectionality component is used in each sub-objective function, a pair of images are reasoned about only once, which helps reduce overhead. Extensive experiments and visual analysis demonstrate the effectiveness of the proposed method, which outperform existing state-of-the-art self-supervised methods under the same conditions and without introducing additional auxiliary information. ",
    "url": "https://arxiv.org/abs/2212.05845",
    "authors": [
      "Fei Wang",
      "Jun Cheng",
      "Penglei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05853",
    "title": "DeepCut: Unsupervised Segmentation using Graph Neural Networks  Clustering",
    "abstract": "Image segmentation is a fundamental task in computer vision. Data annotation for training supervised methods can be labor-intensive, motivating unsupervised methods. Some existing approaches extract deep features from pre-trained networks and build a graph to apply classical clustering methods (e.g., $k$-means and normalized-cuts) as a post-processing stage. These techniques reduce the high-dimensional information encoded in the features to pair-wise scalar affinities. In this work, we replace classical clustering algorithms with a lightweight Graph Neural Network (GNN) trained to achieve the same clustering objective function. However, in contrast to existing approaches, we feed the GNN not only the pair-wise affinities between local image features but also the raw features themselves. Maintaining this connection between the raw feature and the clustering goal allows to perform part semantic segmentation implicitly, without requiring additional post-processing steps. We demonstrate how classical clustering objectives can be formulated as self-supervised loss functions for training our image segmentation GNN. Additionally, we use the Correlation-Clustering (CC) objective to perform clustering without defining the number of clusters ($k$-less clustering). We apply the proposed method for object localization, segmentation, and semantic part segmentation tasks, surpassing state-of-the-art performance on multiple benchmarks. ",
    "url": "https://arxiv.org/abs/2212.05853",
    "authors": [
      "Amit Aflalo",
      "Shai Bagon",
      "Tamar Kashti",
      "Yonina eldar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05854",
    "title": "IRS-Assisted Millimeter-wave Massive MIMO with Transmit Antenna  Selection for IoT Networks",
    "abstract": "An intelligent reflecting surface (IRS)-assisted millimeter-wave (mmWave) massive multiple input multiple output (MIMO) system with transmit antenna selection (TAS) using orthogonal space-time block codes (OSTBC) scheme is proposed in this paper. This system combines TAS and IRS with hybrid analog-digital beamforming (HBF) for 60 GHz mmWave communications in order to exploit the benefits of TAS, OSTBC, analog beamforming (ABF), and transmit digital precoding techniques. The proposed system, however, benefits from the transmit diversity gain of OSTBC scheme as well as from the signal-to-noise ratio (SNR) gains of both the beamformer and the IRS technology. The simulation results demonstrate that TAS-OSTBC system with zero-forcing precoding technique outperforms the conventional TAS system with OSTBC scheme. Furthermore, the bit error rate (BER) performance significantly im-proves as the number of antenna array elements increases due to providing a beamforming gain. In addition, increasing the number of reflecting elements further enhances the error performance. It is also found from the simulation results that the TAS-OSTBC system with hybrid precoding has better BER performance than that of TAS-OSTBC with ABF, and IRS-assisted systems significantly outperform the conventional systems without the IRS technology. This makes the proposed IRS-assisted system an appealing solution for internet-of-things (IoT) networks. ",
    "url": "https://arxiv.org/abs/2212.05854",
    "authors": [
      "Taissir Y. Elganimi",
      "Khaled M. Rabie",
      "Galymzhan Nauryzbayev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.05861",
    "title": "CountingMOT: Joint Counting, Detection and Re-Identification for  Multiple Object Tracking",
    "abstract": "The recent trend in multiple object tracking (MOT) is jointly solving detection and tracking, where object detection and appearance feature (or motion) are learned simultaneously. Despite competitive performance, in crowded scenes, joint detection and tracking usually fail to find accurate object associations due to missed or false detections. In this paper, we jointly model counting, detection and re-identification in an end-to-end framework, named CountingMOT, tailored for crowded scenes. By imposing mutual object-count constraints between detection and counting, the CountingMOT tries to find a balance between object detection and crowd density map estimation, which can help it to recover missed detections or reject false detections. Our approach is an attempt to bridge the gap of object detection, counting, and re-Identification. This is in contrast to prior MOT methods that either ignore the crowd density and thus are prone to failure in crowded scenes, or depend on local correlations to build a graphical relationship for matching targets. The proposed MOT tracker can perform online and real-time tracking, and achieves the state-of-the-art results on public benchmarks MOT16 (MOTA of 77.6), MOT17 (MOTA of 78.0%) and MOT20 (MOTA of 70.2%). ",
    "url": "https://arxiv.org/abs/2212.05861",
    "authors": [
      "Weihong Ren",
      "Bowen Chen",
      "Yuhang Shi",
      "Weibo Jiang",
      "Honghai Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05884",
    "title": "Finger-NestNet: Interpretable Fingerphoto Verification on Smartphone  using Deep Nested Residual Network",
    "abstract": "Fingerphoto images captured using a smartphone are successfully used to verify the individuals that have enabled several applications. This work presents a novel algorithm for fingerphoto verification using a nested residual block: Finger-NestNet. The proposed Finger-NestNet architecture is designed with three consecutive convolution blocks followed by a series of nested residual blocks to achieve reliable fingerphoto verification. This paper also presents the interpretability of the proposed method using four different visualization techniques that can shed light on the critical regions in the fingerphoto biometrics that can contribute to the reliable verification performance of the proposed method. Extensive experiments are performed on the fingerphoto dataset comprised of 196 unique fingers collected from 52 unique data subjects using an iPhone6S. Experimental results indicate the improved verification of the proposed method compared to six different existing methods with EER = 1.15%. ",
    "url": "https://arxiv.org/abs/2212.05884",
    "authors": [
      "Raghavendra Ramachandra",
      "Hailin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.05895",
    "title": "Diff-Font: Diffusion Model for Robust One-Shot Font Generation",
    "abstract": "Font generation is a difficult and time-consuming task, especially in those languages using ideograms that have complicated structures with a large number of characters, such as Chinese. To solve this problem, few-shot font generation and even one-shot font generation have attracted a lot of attention. However, most existing font generation methods may still suffer from (i) large cross-font gap challenge; (ii) subtle cross-font variation problem; and (iii) incorrect generation of complicated characters. In this paper, we propose a novel one-shot font generation method based on a diffusion model, named Diff-Font, which can be stably trained on large datasets. The proposed model aims to generate the entire font library by giving only one sample as the reference. Specifically, a large stroke-wise dataset is constructed, and a stroke-wise diffusion model is proposed to preserve the structure and the completion of each generated character. To our best knowledge, the proposed Diff-Font is the first work that developed diffusion models to handle the font generation task. The well-trained Diff-Font is not only robust to font gap and font variation, but also achieved promising performance on difficult character generation. Compared to previous font generation methods, our model reaches state-of-the-art performance both qualitatively and quantitatively. ",
    "url": "https://arxiv.org/abs/2212.05895",
    "authors": [
      "Haibin He",
      "Xinyuan Chen",
      "Chaoyue Wang",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05901",
    "title": "Parameter-Efficient Finetuning of Transformers for Source Code",
    "abstract": "Pretrained Transformers achieve state-of-the-art performance in various code-processing tasks but may be too large to be deployed. As software development tools often incorporate modules for various purposes which may potentially use a single instance of the pretrained model, it appears relevant to utilize parameter-efficient fine-tuning for the pretrained models of code. In this work, we test two widely used approaches, adapters and LoRA, which were initially tested on NLP tasks, on four code-processing tasks. We find that though the efficient fine-tuning approaches may achieve comparable or higher performance than the standard, full, fine-tuning in code understanding tasks, they underperform full fine-tuning in code-generative tasks. These results underline the importance of testing efficient fine-tuning approaches on other domains than NLP and motivate future research in efficient fine-tuning for source code. ",
    "url": "https://arxiv.org/abs/2212.05901",
    "authors": [
      "Shamil Ayupov",
      "Nadezhda Chirkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.05909",
    "title": "NFResNet: Multi-scale and U-shaped Networks for Deblurring",
    "abstract": "Multi-Scale and U-shaped Networks are widely used in various image restoration problems, including deblurring. Keeping in mind the wide range of applications, we present a comparison of these architectures and their effects on image deblurring. We also introduce a new block called as NFResblock. It consists of a Fast Fourier Transformation layer and a series of modified Non-Linear Activation Free Blocks. Based on these architectures and additions, we introduce NFResnet and NFResnet+, which are modified multi-scale and U-Net architectures, respectively. We also use three different loss functions to train these architectures: Charbonnier Loss, Edge Loss, and Frequency Reconstruction Loss. Extensive experiments on the Deep Video Deblurring dataset, along with ablation studies for each component, have been presented in this paper. The proposed architectures achieve a considerable increase in Peak Signal to Noise (PSNR) ratio and Structural Similarity Index (SSIM) value. ",
    "url": "https://arxiv.org/abs/2212.05909",
    "authors": [
      "Tanish Mittal",
      "Preyansh Agrawal",
      "Esha Pahwa",
      "Aarya Makwana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.05911",
    "title": "Adaptive Self-Training for Object Detection",
    "abstract": "Deep learning has emerged as an effective solution for solving the task of object detection in images but at the cost of requiring large labeled datasets. To mitigate this cost, semi-supervised object detection methods, which consist in leveraging abundant unlabeled data, have been proposed and have already shown impressive results. However, most of these methods require linking a pseudo-label to a ground-truth object by thresholding. In previous works, this threshold value is usually determined empirically, which is time consuming, and only done for a single data distribution. When the domain, and thus the data distribution, changes, a new and costly parameter search is necessary. In this work, we introduce our method Adaptive Self-Training for Object Detection (ASTOD), which is a simple yet effective teacher-student method. ASTOD determines without cost a threshold value based directly on the ground value of the score histogram. To improve the quality of the teacher predictions, we also propose a novel pseudo-labeling procedure. We use different views of the unlabeled images during the pseudo-labeling step to reduce the number of missed predictions and thus obtain better candidate labels. Our teacher and our student are trained separately, and our method can be used in an iterative fashion by replacing the teacher by the student. On the MS-COCO dataset, our method consistently performs favorably against state-of-the-art methods that do not require a threshold parameter, and shows competitive results with methods that require a parameter sweep search. Additional experiments with respect to a supervised baseline on the DIOR dataset containing satellite images lead to similar conclusions, and prove that it is possible to adapt the score threshold automatically in self-training, regardless of the data distribution. ",
    "url": "https://arxiv.org/abs/2212.05911",
    "authors": [
      "Renaud Vandeghen",
      "Gilles Louppe",
      "Marc Van Droogenbroeck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05917",
    "title": "SRoUDA: Meta Self-training for Robust Unsupervised Domain Adaptation",
    "abstract": "As acquiring manual labels on data could be costly, unsupervised domain adaptation (UDA), which transfers knowledge learned from a rich-label dataset to the unlabeled target dataset, is gaining increasing popularity. While extensive studies have been devoted to improving the model accuracy on target domain, an important issue of model robustness is neglected. To make things worse, conventional adversarial training (AT) methods for improving model robustness are inapplicable under UDA scenario since they train models on adversarial examples that are generated by supervised loss function. In this paper, we present a new meta self-training pipeline, named SRoUDA, for improving adversarial robustness of UDA models. Based on self-training paradigm, SRoUDA starts with pre-training a source model by applying UDA baseline on source labeled data and taraget unlabeled data with a developed random masked augmentation (RMA), and then alternates between adversarial target model training on pseudo-labeled target data and finetuning source model by a meta step. While self-training allows the direct incorporation of AT in UDA, the meta step in SRoUDA further helps in mitigating error propagation from noisy pseudo labels. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SRoUDA where it achieves significant model robustness improvement without harming clean accuracy. Code is available at https://github.com/Vision. ",
    "url": "https://arxiv.org/abs/2212.05917",
    "authors": [
      "Wanqing Zhu",
      "Jia-Li Yin",
      "Bo-Hao Chen",
      "Ximeng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05936",
    "title": "Encoder-Decoder Network with Guided Transmission Map: Architecture --  Extended Abstract",
    "abstract": "An insight into the architecture of the Encoder-Decoder Network with Guided Transmission Map (EDN-GTM), a novel and effective single image dehazing scheme, is presented in this paper. The EDN-GTM takes a conventional RGB hazy image in conjunction with the corresponding transmission map estimated by the dark channel prior (DCP) approach as inputs of the network. The EDN-GTM adopts an enhanced structure of U-Net developed for dehazing tasks and the resulting EDN-GDM has shown state-of-the-art performances on benchmark dehazing datasets in terms of PSNR and SSIM metrics. In order to give an in-depth understanding of the well-designed architecture which largely contributes to the success of the EDN-GTM, extensive experiments and analysis from selecting the core structure of the scheme to investigating advanced network designs are presented in this paper. ",
    "url": "https://arxiv.org/abs/2212.05936",
    "authors": [
      "Le-Anh Tran",
      "Dong-Chul Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.05942",
    "title": "Physics-preserving IMPES based multiscale methods for immiscible  two-phase flow in highly heterogeneous porous media",
    "abstract": "In this paper, we propose a physics-preserving multiscale method to solve an immiscible two-phase flow problem, which is modeled as a coupling system consisting of Darcy's law and mass conservation equations. We use a new Physics-preserving IMplicit Pressure Explicit Saturation (P-IMPES) scheme in order to maintain the local conservation of mass for both phases. Besides, this scheme is unbiased and if the time step is smaller than a certain value, the saturation of both phases are bounds-preserving. When updating velocity, MGMsFEM serves as an efficient solver by computing the unknowns on a coarse grid. We follow the operation splitting techinque to deal with the two-phase flow. In particular, we use an upwind strategy to iterate the saturation explicitly and the MGMsFEM is utilized to compute velocity with a decoupled system on a coarse mesh. To show the efficiency and robustness of the proposed method, we design a set of interesting experiments. A rigorous analysis is also included to serve as a theoretical base of the method, which is well verified by the numerical results. Both simulations and analysis indicate that the method attains a good balance between accuracy and computation cost. ",
    "url": "https://arxiv.org/abs/2212.05942",
    "authors": [
      "Yiran Wang",
      "Eric Chung",
      "Shuyu Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.05961",
    "title": "RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning  for Language Understanding",
    "abstract": "This paper presents a new data augmentation algorithm for natural understanding tasks, called RPN:Random Position Noise algorithm.Due to the relative paucity of current text augmentation methods. Few of the extant methods apply to natural language understanding tasks for all sentence-level tasks.RPN applies the traditional augmentation on the original text to the word vector level. The RPN algorithm makes a substitution in one or several dimensions of some word vectors. As a result, the RPN can introduce a certain degree of perturbation to the sample and can adjust the range of perturbation on different tasks. The augmented samples are then used to give the model training.This makes the model more robust. In subsequent experiments, we found that adding RPN to the training or fine-tuning model resulted in a stable boost on all 8 natural language processing tasks, including TweetEval, CoLA, and SST-2 datasets, and more significant improvements than other data augmentation algorithms.The RPN algorithm applies to all sentence-level tasks for language understanding and is used in any deep learning model with a word embedding layer. ",
    "url": "https://arxiv.org/abs/2212.05961",
    "authors": [
      "Zhengqing Yuan",
      "Zhuanzhe Zhao",
      "Yongming Liu",
      "Xiaolong Zhang",
      "Xuecong Hou",
      "Yue Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05970",
    "title": "Decomposing a Recurrent Neural Network into Modules for Enabling  Reusability and Replacement",
    "abstract": "Can we take a recurrent neural network (RNN) trained to translate between languages and augment it to support a new natural language without retraining the model from scratch? Can we fix the faulty behavior of the RNN by replacing portions associated with the faulty behavior? Recent works on decomposing a fully connected neural network (FCNN) and convolutional neural network (CNN) into modules have shown the value of engineering deep models in this manner, which is standard in traditional SE but foreign for deep learning models. However, prior works focus on the image-based multiclass classification problems and cannot be applied to RNN due to (a) different layer structures, (b) loop structures, (c) different types of input-output architectures, and (d) usage of both nonlinear and logistic activation functions. In this work, we propose the first approach to decompose an RNN into modules. We study different types of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN modules can be reused and replaced in various scenarios. We evaluate our approach against 5 canonical datasets (i.e., Math QA, Brown Corpus, Wiki-toxicity, Clinc OOS, and Tatoeba) and 4 model variants for each dataset. We found that decomposing a trained model has a small cost (Accuracy: -0.6%, BLEU score: +0.10%). Also, the decomposed modules can be reused and replaced without needing to retrain. ",
    "url": "https://arxiv.org/abs/2212.05970",
    "authors": [
      "Sayem Mohammad Imtiaz",
      "Fraol Batole",
      "Astha Singh",
      "Rangeet Pan",
      "Breno Dantas Cruz",
      "Hridesh Rajan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05979",
    "title": "On the Age-Optimality of Relax-then-Truncate Approach under Partial  Battery Knowledge in Energy Harvesting IoT Networks",
    "abstract": "We consider an energy harvesting (EH) IoT network, where users make on-demand requests to a cache-enabled edge node to send status updates about various random processes, each monitored by an EH sensor. The edge node serves users' requests by either commanding the corresponding sensor to send a fresh status update or retrieving the most recently received measurement from the cache. We aim to find a control policy at the edge node that minimizes the average on-demand AoI over all sensors subject to per-slot transmission and energy constraints under partial battery knowledge at the edge node. Namely, the limited radio resources (e.g., bandwidth) causes that only a limited number of sensors can send status updates at each time slot (i.e., per-slot transmission constraint) and the scarcity of energy for the EH sensors imposes an energy constraint. Besides, the edge node is informed of the sensors' battery levels only via received status update packets, leading to uncertainty about the battery levels for the decision-making.We develop a low-complexity algorithm -- termed relax-then-truncate -- and prove that it is asymptotically optimal as the number of sensors goes to infinity. Numerical results illustrate that the proposed method achieves significant gains over a request-aware greedy policy and show that it has near-optimal performance even for moderate numbers of sensors. ",
    "url": "https://arxiv.org/abs/2212.05979",
    "authors": [
      "Mohammad Hatami",
      "Markus Leinonen",
      "Marian Codreanu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05986",
    "title": "A Cross-Layer Descent Approach for Resilient Network Operations of  Proliferated LEO Satellites",
    "abstract": "With the proliferated low-Earth-orbit (LEO) satellites in mega-constellations, the future Internet will be able to reach any place on Earth, providing high-quality services to everyone. However, high-quality operations in terms of timeliness and resilience are lacking in the current solutions. This paper proposes a multi-layer networking approach called \"Cross-Layer Descent (CLD)\". Based on the proposed system model, principles, and measures, CLD can support foundational services such as telecommand (TC) transmissions for various network operation missions for LEO satellites compliant with the Consultative Committee for Space Data Systems (CCSDS) standards. The CLD approach enhances timing and resilience requirements using advanced communication payloads. From the simulation-based analysis, the proposed scheme outperforms other classical ones in resilience and latency for typical TC missions. The future work and conclusive remarks are discussed at the end. ",
    "url": "https://arxiv.org/abs/2212.05986",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05987",
    "title": "Selective classification using a robust meta-learning approach",
    "abstract": "Selective classification involves identifying the subset of test samples that a model can classify with high accuracy, and is important for applications such as automated medical diagnosis. We argue that this capability of identifying uncertain samples is valuable for training classifiers as well, with the aim of building more accurate classifiers. We unify these dual roles by training a single auxiliary meta-network to output an importance weight as a function of the instance. This measure is used at train time to reweight training data, and at test-time to rank test instances for selective classification. A second, key component of our proposal is the meta-objective of minimizing dropout variance (the variance of classifier output when subjected to random weight dropout) for training the metanetwork. We train the classifier together with its metanetwork using a nested objective of minimizing classifier loss on training data and meta-loss on a separate meta-training dataset. We outperform current state-of-the-art on selective classification by substantial margins--for instance, upto 1.9% AUC and 2% accuracy on a real-world diabetic retinopathy dataset. Finally, our meta-learning framework extends naturally to unsupervised domain adaptation, given our unsupervised variance minimization meta-objective. We show cumulative absolute gains of 3.4% / 3.3% accuracy and AUC over the other baselines in domain shift settings on the Retinopathy dataset using unsupervised domain adaptation. ",
    "url": "https://arxiv.org/abs/2212.05987",
    "authors": [
      "Nishant Jain",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05989",
    "title": "MegaCRN: Meta-Graph Convolutional Recurrent Network for Spatio-Temporal  Modeling",
    "abstract": "Spatio-temporal modeling as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the underlying heterogeneity and non-stationarity implied in the graph streams, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (METR-LA and PEMS-BAY) and a large-scale spatio-temporal dataset that contains a variaty of non-stationary phenomena. Our model outperformed the state-of-the-arts to a large degree on all three datasets (over 27% MAE and 34% RMSE). Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle locations and time slots with different patterns and be robustly adaptive to different anomalous situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN. ",
    "url": "https://arxiv.org/abs/2212.05989",
    "authors": [
      "Renhe Jiang",
      "Zhaonan Wang",
      "Jiawei Yong",
      "Puneet Jeph",
      "Quanjun Chen",
      "Yasumasa Kobayashi",
      "Xuan Song",
      "Toyotaro Suzumura",
      "Shintaro Fukushima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.05996",
    "title": "Dirichlet-Survival Process: Scalable Inference of Topic-Dependent  Diffusion Networks",
    "abstract": "Information spread on networks can be efficiently modeled by considering three features: documents' content, time of publication relative to other publications, and position of the spreader in the network. Most previous works model up to two of those jointly, or rely on heavily parametric approaches. Building on recent Dirichlet-Point processes literature, we introduce the Houston (Hidden Online User-Topic Network) model, that jointly considers all those features in a non-parametric unsupervised framework. It infers dynamic topic-dependent underlying diffusion networks in a continuous-time setting along with said topics. It is unsupervised; it considers an unlabeled stream of triplets shaped as \\textit{(time of publication, information's content, spreading entity)} as input data. Online inference is conducted using a sequential Monte-Carlo algorithm that scales linearly with the size of the dataset. Our approach yields consequent improvements over existing baselines on both cluster recovery and subnetworks inference tasks. ",
    "url": "https://arxiv.org/abs/2212.05996",
    "authors": [
      "Ga\u00ebl Poux-M\u00e9dard",
      "Julien Velcin",
      "Sabine Loudcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.06008",
    "title": "Who Evaluates the Evaluators? On Automatic Metrics for Assessing  AI-based Offensive Code Generators",
    "abstract": "AI-based code generators are an emerging solution for automatically writing programs starting from descriptions in natural language, by using deep neural networks (Neural Machine Translation, NMT). In particular, code generators have been used for ethical hacking and offensive security testing by generating proof-of-concept attacks. Unfortunately, the evaluation of code generators still faces several issues. The current practice uses automatic metrics, which compute the textual similarity of generated code with ground-truth references. However, it is not clear what metric to use, and which metric is most suitable for specific contexts. This practical experience report analyzes a large set of output similarity metrics on offensive code generators. We apply the metrics on two state-of-the-art NMT models using two datasets containing offensive assembly and Python code with their descriptions in the English language. We compare the estimates from the automatic metrics with human evaluation and provide practical insights into their strengths and limitations. ",
    "url": "https://arxiv.org/abs/2212.06008",
    "authors": [
      "Cristina Improta",
      "Pietro Liguori",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06011",
    "title": "A Neural ODE Interpretation of Transformer Layers",
    "abstract": "Transformer layers, which use an alternating pattern of multi-head attention and multi-layer perceptron (MLP) layers, provide an effective tool for a variety of machine learning problems. As the transformer layers use residual connections to avoid the problem of vanishing gradients, they can be viewed as the numerical integration of a differential equation. In this extended abstract, we build upon this connection and propose a modification of the internal architecture of a transformer layer. The proposed model places the multi-head attention sublayer and the MLP sublayer parallel to each other. Our experiments show that this simple modification improves the performance of transformer networks in multiple tasks. Moreover, for the image classification task, we show that using neural ODE solvers with a sophisticated integration scheme further improves performance. ",
    "url": "https://arxiv.org/abs/2212.06011",
    "authors": [
      "Yaofeng Desmond Zhong",
      "Tongtao Zhang",
      "Amit Chakraborty",
      "Biswadip Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06021",
    "title": "A novel feature-scrambling approach reveals the capacity of  convolutional neural networks to learn spatial relations",
    "abstract": "Convolutional neural networks (CNNs) are one of the most successful computer vision systems to solve object recognition. Furthermore, CNNs have major applications in understanding the nature of visual representations in the human brain. Yet it remains poorly understood how CNNs actually make their decisions, what the nature of their internal representations is, and how their recognition strategies differ from humans. Specifically, there is a major debate about the question of whether CNNs primarily rely on surface regularities of objects, or whether they are capable of exploiting the spatial arrangement of features, similar to humans. Here, we develop a novel feature-scrambling approach to explicitly test whether CNNs use the spatial arrangement of features (i.e. object parts) to classify objects. We combine this approach with a systematic manipulation of effective receptive field sizes of CNNs as well as minimal recognizable configurations (MIRCs) analysis. In contrast to much previous literature, we provide evidence that CNNs are in fact capable of using relatively long-range spatial relationships for object classification. Moreover, the extent to which CNNs use spatial relationships depends heavily on the dataset, e.g. texture vs. sketch. In fact, CNNs even use different strategies for different classes within heterogeneous datasets (ImageNet), suggesting CNNs have a continuous spectrum of classification strategies. Finally, we show that CNNs learn the spatial arrangement of features only up to an intermediate level of granularity, which suggests that intermediate rather than global shape features provide the optimal trade-off between sensitivity and specificity in object classification. These results provide novel insights into the nature of CNN representations and the extent to which they rely on the spatial arrangement of features for object classification. ",
    "url": "https://arxiv.org/abs/2212.06021",
    "authors": [
      "Amr Farahat",
      "Felix Effenberger",
      "Martin Vinck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.06023",
    "title": "Reconstructing Humpty Dumpty: Multi-feature Graph Autoencoder for Open  Set Action Recognition",
    "abstract": "Most action recognition datasets and algorithms assume a closed world, where all test samples are instances of the known classes. In open set problems, test samples may be drawn from either known or unknown classes. Existing open set action recognition methods are typically based on extending closed set methods by adding post hoc analysis of classification scores or feature distances and do not capture the relations among all the video clip elements. Our approach uses the reconstruction error to determine the novelty of the video since unknown classes are harder to put back together and thus have a higher reconstruction error than videos from known classes. We refer to our solution to the open set action recognition problem as \"Humpty Dumpty\", due to its reconstruction abilities. Humpty Dumpty is a novel graph-based autoencoder that accounts for contextual and semantic relations among the clip pieces for improved reconstruction. A larger reconstruction error leads to an increased likelihood that the action can not be reconstructed, i.e., can not put Humpty Dumpty back together again, indicating that the action has never been seen before and is novel/unknown. Extensive experiments are performed on two publicly available action recognition datasets including HMDB-51 and UCF-101, showing the state-of-the-art performance for open set action recognition. ",
    "url": "https://arxiv.org/abs/2212.06023",
    "authors": [
      "Dawei Du",
      "Ameya Shringi",
      "Anthony Hoogs",
      "Christopher Funk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06026",
    "title": "Video Prediction by Efficient Transformers",
    "abstract": "Video prediction is a challenging computer vision task that has a wide range of applications. In this work, we present a new family of Transformer-based models for video prediction. Firstly, an efficient local spatial-temporal separation attention mechanism is proposed to reduce the complexity of standard Transformers. Then, a full autoregressive model, a partial autoregressive model and a non-autoregressive model are developed based on the new efficient Transformer. The partial autoregressive model has a similar performance with the full autoregressive model but a faster inference speed. The non-autoregressive model not only achieves a faster inference speed but also mitigates the quality degradation problem of the autoregressive counterparts, but it requires additional parameters and loss function for learning. Given the same attention mechanism, we conducted a comprehensive study to compare the proposed three video prediction variants. Experiments show that the proposed video prediction models are competitive with more complex state-of-the-art convolutional-LSTM based models. The source code is available at https://github.com/XiYe20/VPTR. ",
    "url": "https://arxiv.org/abs/2212.06026",
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06035",
    "title": "News Headlines Dataset For Sarcasm Detection",
    "abstract": "Past studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag-based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets, and detecting sarcasm in these requires the availability of contextual tweets. To overcome the limitations related to noise in Twitter datasets, we curate News Headlines Dataset from two news websites: TheOnion aims at producing sarcastic versions of current events, whereas HuffPost publishes real news. The dataset contains about 28K headlines out of which 13K are sarcastic. To make it more useful, we have included the source links of the news articles so that more data can be extracted as needed. In this paper, we describe various details about the dataset and potential use cases apart from Sarcasm Detection. ",
    "url": "https://arxiv.org/abs/2212.06035",
    "authors": [
      "Rishabh Misra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.06048",
    "title": "Machine Learning Approaches for Principle Prediction in Naturally  Occurring Stories",
    "abstract": "Value alignment is the task of creating autonomous systems whose values align with those of humans. Past work has shown that stories are a potentially rich source of information on human values; however, past work has been limited to considering values in a binary sense. In this work, we explore the use of machine learning models for the task of normative principle prediction on naturally occurring story data. To do this, we extend a dataset that has been previously used to train a binary normative classifier with annotations of moral principles. We then use this dataset to train a variety of machine learning models, evaluate these models and compare their results against humans who were asked to perform the same task. We show that while individual principles can be classified, the ambiguity of what \"moral principles\" represent, poses a challenge for both human participants and autonomous systems which are faced with the same task. ",
    "url": "https://arxiv.org/abs/2212.06048",
    "authors": [
      "Md Sultan Al Nahian",
      "Spencer Frazier",
      "Brent Harrison",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06068",
    "title": "Solving the Wide-band Inverse Scattering Problem via Equivariant Neural  Networks",
    "abstract": "This paper introduces a novel deep neural network architecture for solving the inverse scattering problem in frequency domain with wide-band data, by directly approximating the inverse map, thus avoiding the expensive optimization loop of classical methods. The architecture is motivated by the filtered back-projection formula in the full aperture regime and with homogeneous background, and it leverages the underlying equivariance of the problem and compressibility of the integral operator. This drastically reduces the number of training parameters, and therefore the computational and sample complexity of the method. In particular, we obtain an architecture whose number of parameters scale sub-linearly with respect to the dimension of the inputs, while its inference complexity scales super-linearly but with very small constants. We provide several numerical tests that show that the current approach results in better reconstruction than optimization-based techniques such as full-waveform inversion, but at a fraction of the cost while being competitive with state-of-the-art machine learning methods. ",
    "url": "https://arxiv.org/abs/2212.06068",
    "authors": [
      "Borong Zhang",
      "Leonardo Zepeda-N\u00fa\u00f1ez",
      "Qin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.06074",
    "title": "Regression with Label Differential Privacy",
    "abstract": "We study the task of training regression models with the guarantee of label differential privacy (DP). Based on a global prior distribution on label values, which could be obtained privately, we derive a label DP randomization mechanism that is optimal under a given regression loss function. We prove that the optimal mechanism takes the form of a ``randomized response on bins'', and propose an efficient algorithm for finding the optimal bin values. We carry out a thorough experimental evaluation on several datasets demonstrating the efficacy of our algorithm. ",
    "url": "https://arxiv.org/abs/2212.06074",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Ethan Leeman",
      "Pasin Manurangsi",
      "Avinash Varadarajan",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.06079",
    "title": "Robust Perception through Equivariance",
    "abstract": "Deep networks for computer vision are not reliable when they encounter adversarial examples. In this paper, we introduce a framework that uses the dense intrinsic constraints in natural images to robustify inference. By introducing constraints at inference time, we can shift the burden of robustness from training to the inference algorithm, thereby allowing the model to adjust dynamically to each individual image's unique and potentially novel characteristics at inference time. Among different constraints, we find that equivariance-based constraints are most effective, because they allow dense constraints in the feature space without overly constraining the representation at a fine-grained level. Our theoretical results validate the importance of having such dense constraints at inference time. Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks. Project page is available at equi4robust.cs.columbia.edu. ",
    "url": "https://arxiv.org/abs/2212.06079",
    "authors": [
      "Chengzhi Mao",
      "Lingyu Zhang",
      "Abhishek Joshi",
      "Junfeng Yang",
      "Hao Wang",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06096",
    "title": "Implicit Neural Convolutional Kernels for Steerable CNNs",
    "abstract": "Steerable convolutional neural networks (CNNs) provide a general framework for building neural networks equivariant to translations and other transformations belonging to an origin-preserving group $G$, such as reflections and rotations. They rely on standard convolutions with $G$-steerable kernels obtained by analytically solving the group-specific equivariance constraint imposed onto the kernel space. As the solution is tailored to a particular group $G$, the implementation of a kernel basis does not generalize to other symmetry transformations, which complicates the development of group equivariant models. We propose using implicit neural representation via multi-layer perceptrons (MLPs) to parameterize $G$-steerable kernels. The resulting framework offers a simple and flexible way to implement Steerable CNNs and generalizes to any group $G$ for which a $G$-equivariant MLP can be built. We apply our method to point cloud (ModelNet-40) and molecular data (QM9) and demonstrate a significant improvement in performance compared to standard Steerable CNNs. ",
    "url": "https://arxiv.org/abs/2212.06096",
    "authors": [
      "Maksim Zhdanov",
      "Nico Hoffmann",
      "Gabriele Cesa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06097",
    "title": "Resolving Semantic Confusions for Improved Zero-Shot Detection",
    "abstract": "Zero-shot detection (ZSD) is a challenging task where we aim to recognize and localize objects simultaneously, even when our model has not been trained with visual samples of a few target (\"unseen\") classes. Recently, methods employing generative models like GANs have shown some of the best results, where unseen-class samples are generated based on their semantics by a GAN trained on seen-class data, enabling vanilla object detectors to recognize unseen objects. However, the problem of semantic confusion still remains, where the model is sometimes unable to distinguish between semantically-similar classes. In this work, we propose to train a generative model incorporating a triplet loss that acknowledges the degree of dissimilarity between classes and reflects them in the generated samples. Moreover, a cyclic-consistency loss is also enforced to ensure that generated visual samples of a class highly correspond to their own semantics. Extensive experiments on two benchmark ZSD datasets - MSCOCO and PASCAL-VOC - demonstrate significant gains over the current ZSD methods, reducing semantic confusion and improving detection for the unseen classes. ",
    "url": "https://arxiv.org/abs/2212.06097",
    "authors": [
      "Sandipan Sarma",
      "Sushil Kumar",
      "Arijit Sur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06107",
    "title": "A Bargaining Game for Personalized, Energy Efficient Split Learning over  Wireless Networks",
    "abstract": "Split learning (SL) is an emergent distributed learning framework which can mitigate the computation and wireless communication overhead of federated learning. It splits a machine learning model into a device-side model and a server-side model at a cut layer. Devices only train their allocated model and transmit the activations of the cut layer to the server. However, SL can lead to data leakage as the server can reconstruct the input data using the correlation between the input and intermediate activations. Although allocating more layers to a device-side model can reduce the possibility of data leakage, this will lead to more energy consumption for resource-constrained devices and more training time for the server. Moreover, non-iid datasets across devices will reduce the convergence rate leading to increased training time. In this paper, a new personalized SL framework is proposed. For this framework, a novel approach for choosing the cut layer that can optimize the tradeoff between the energy consumption for computation and wireless transmission, training time, and data privacy is developed. In the considered framework, each device personalizes its device-side model to mitigate non-iid datasets while sharing the same server-side model for generalization. To balance the energy consumption for computation and wireless transmission, training time, and data privacy, a multiplayer bargaining problem is formulated to find the optimal cut layer between devices and the server. To solve the problem, the Kalai-Smorodinsky bargaining solution (KSBS) is obtained using the bisection method with the feasibility test. Simulation results show that the proposed personalized SL framework with the cut layer from the KSBS can achieve the optimal sum utilities by balancing the energy consumption, training time, and data privacy, and it is also robust to non-iid datasets. ",
    "url": "https://arxiv.org/abs/2212.06107",
    "authors": [
      "Minsu Kim",
      "Alexander DeRieux",
      "Walid Saad"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.06111",
    "title": "Where To Start? Transferring Simple Skills to Complex Environments",
    "abstract": "Robot learning provides a number of ways to teach robots simple skills, such as grasping. However, these skills are usually trained in open, clutter-free environments, and therefore would likely cause undesirable collisions in more complex, cluttered environments. In this work, we introduce an affordance model based on a graph representation of an environment, which is optimised during deployment to find suitable robot configurations to start a skill from, such that the skill can be executed without any collisions. We demonstrate that our method can generalise a priori acquired skills to previously unseen cluttered and constrained environments, in simulation and in the real world, for both a grasping and a placing task. ",
    "url": "https://arxiv.org/abs/2212.06111",
    "authors": [
      "Vitalis Vosylius",
      "Edward Johns"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.06121",
    "title": "In Defense of Cross-Encoders for Zero-Shot Retrieval",
    "abstract": "Bi-encoders and cross-encoders are widely used in many state-of-the-art retrieval pipelines. In this work we study the generalization ability of these two types of architectures on a wide range of parameter count on both in-domain and out-of-domain scenarios. We find that the number of parameters and early query-document interactions of cross-encoders play a significant role in the generalization ability of retrieval models. Our experiments show that increasing model size results in marginal gains on in-domain test sets, but much larger gains in new domains never seen during fine-tuning. Furthermore, we show that cross-encoders largely outperform bi-encoders of similar size in several tasks. In the BEIR benchmark, our largest cross-encoder surpasses a state-of-the-art bi-encoder by more than 4 average points. Finally, we show that using bi-encoders as first-stage retrievers provides no gains in comparison to a simpler retriever such as BM25 on out-of-domain tasks. The code is available at https://github.com/guilhermemr04/scaling-zero-shot-retrieval.git ",
    "url": "https://arxiv.org/abs/2212.06121",
    "authors": [
      "Guilherme Rosa",
      "Luiz Bonifacio",
      "Vitor Jeronymo",
      "Hugo Abonizio",
      "Marzieh Fadaee",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.06125",
    "title": "Neural Assets: Volumetric Object Capture and Rendering for Interactive  Environments",
    "abstract": "Creating realistic virtual assets is a time-consuming process: it usually involves an artist designing the object, then spending a lot of effort on tweaking its appearance. Intricate details and certain effects, such as subsurface scattering, elude representation using real-time BRDFs, making it impossible to fully capture the appearance of certain objects. Inspired by the recent progress of neural rendering, we propose an approach for capturing real-world objects in everyday environments faithfully and fast. We use a novel neural representation to reconstruct volumetric effects, such as translucent object parts, and preserve photorealistic object appearance. To support real-time rendering without compromising rendering quality, our model uses a grid of features and a small MLP decoder that is transpiled into efficient shader code with interactive framerates. This leads to a seamless integration of the proposed neural assets with existing mesh environments and objects. Thanks to the use of standard shader code rendering is portable across many existing hardware and software systems. ",
    "url": "https://arxiv.org/abs/2212.06125",
    "authors": [
      "Alja\u017e Bo\u017ei\u010d",
      "Denis Gladkov",
      "Luke Doukakis",
      "Christoph Lassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.06130",
    "title": "Siamese Neural Networks for Skin Cancer Classification and New Class  Detection using Clinical and Dermoscopic Image Datasets",
    "abstract": "Skin cancer is the most common malignancy in the world. Automated skin cancer detection would significantly improve early detection rates and prevent deaths. To help with this aim, a number of datasets have been released which can be used to train Deep Learning systems - these have produced impressive results for classification. However, this only works for the classes they are trained on whilst they are incapable of identifying skin lesions from previously unseen classes, making them unconducive for clinical use. We could look to massively increase the datasets by including all possible skin lesions, though this would always leave out some classes. Instead, we evaluate Siamese Neural Networks (SNNs), which not only allows us to classify images of skin lesions, but also allow us to identify those images which are different from the trained classes - allowing us to determine that an image is not an example of our training classes. We evaluate SNNs on both dermoscopic and clinical images of skin lesions. We obtain top-1 classification accuracy levels of 74.33% and 85.61% on clinical and dermoscopic datasets, respectively. Although this is slightly lower than the state-of-the-art results, the SNN approach has the advantage that it can detect out-of-class examples. Our results highlight the potential of an SNN approach as well as pathways towards future clinical deployment. ",
    "url": "https://arxiv.org/abs/2212.06130",
    "authors": [
      "Michael Luke Battle",
      "Amir Atapour-Abarghouei",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05217",
    "title": "Snapshot Multispectral Imaging Using a Diffractive Optical Network",
    "abstract": "Multispectral imaging has been used for numerous applications in e.g., environmental monitoring, aerospace, defense, and biomedicine. Here, we present a diffractive optical network-based multispectral imaging system trained using deep learning to create a virtual spectral filter array at the output image field-of-view. This diffractive multispectral imager performs spatially-coherent imaging over a large spectrum, and at the same time, routes a pre-determined set of spectral channels onto an array of pixels at the output plane, converting a monochrome focal plane array or image sensor into a multispectral imaging device without any spectral filters or image recovery algorithms. Furthermore, the spectral responsivity of this diffractive multispectral imager is not sensitive to input polarization states. Through numerical simulations, we present different diffractive network designs that achieve snapshot multispectral imaging with 4, 9 and 16 unique spectral bands within the visible spectrum, based on passive spatially-structured diffractive surfaces, with a compact design that axially spans ~72 times the mean wavelength of the spectral band of interest. Moreover, we experimentally demonstrate a diffractive multispectral imager based on a 3D-printed diffractive network that creates at its output image plane a spatially-repeating virtual spectral filter array with 2x2=4 unique bands at terahertz spectrum. Due to their compact form factor and computation-free, power-efficient and polarization-insensitive forward operation, diffractive multispectral imagers can be transformative for various imaging and sensing applications and be used at different parts of the electromagnetic spectrum where high-density and wide-area multispectral pixel arrays are not widely available. ",
    "url": "https://arxiv.org/abs/2212.05217",
    "authors": [
      "Deniz Mengu",
      "Anika Tabassum",
      "Mona Jarrahi",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2212.05354",
    "title": "Phenomenological modeling of diverse and heterogeneous synaptic dynamics  at natural density",
    "abstract": "This chapter sheds light on the synaptic organization of the brain from the perspective of computational neuroscience. It provides an introductory overview on how to account for empirical data in mathematical models, implement them in software, and perform simulations reflecting experiments. This path is demonstrated with respect to four key aspects of synaptic signaling: the connectivity of brain networks, synaptic transmission, synaptic plasticity, and the heterogeneity across synapses. Each step and aspect of the modeling and simulation workflow comes with its own challenges and pitfalls, which are highlighted and addressed in detail. ",
    "url": "https://arxiv.org/abs/2212.05354",
    "authors": [
      "Agnes Korcsak-Gorzo",
      "Charl Linssen",
      "Jasper Albers",
      "Stefan Dasbach",
      "Renato Duarte",
      "Susanne Kunkel",
      "Abigail Morrison",
      "Johanna Senk",
      "Jonas Stapmanns",
      "Tom Tetzlaff",
      "Markus Diesmann",
      "Sacha J. van Albada"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.05357",
    "title": "On Blockchain We Cooperate: An Evolutionary Game Perspective",
    "abstract": "Cooperation is fundamental for human prosperity. Blockchain, as a trust machine, is a cooperative institution in cyberspace that supports cooperation through distributed trust with consensus protocols. While studies in computer science focus on fault tolerance problems with consensus algorithms, economic research utilizes incentive designs to analyze agent behaviors. To achieve cooperation on blockchains, emerging interdisciplinary research introduces rationality and game-theoretical solution concepts to study the equilibrium outcomes of various consensus protocols. However, existing studies do not consider the possibility for agents to learn from historical observations. Therefore, we abstract a general consensus protocol as a dynamic game environment, apply a solution concept of bounded rationality to model agent behavior, and resolve the initial conditions for three different stable equilibria. In our game, agents imitatively learn the global history in an evolutionary process toward equilibria, for which we evaluate the outcomes from both computing and economic perspectives in terms of safety, liveness, validity, and social welfare. Our research contributes to the literature across disciplines, including distributed consensus in computer science, game theory in economics on blockchain consensus, evolutionary game theory at the intersection of biology and economics, bounded rationality at the interplay between psychology and economics, and cooperative AI with joint insights into computing and social science. Finally, we discuss that future protocol design can better achieve the most desired outcomes of our honest stable equilibria by increasing the reward-punishment ratio and lowering both the cost-punishment ratio and the pivotality rate. ",
    "url": "https://arxiv.org/abs/2212.05357",
    "authors": [
      "Luyao Zhang",
      "Xinyu Tian"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2212.05378",
    "title": "Neural Continuous-Time Markov Models",
    "abstract": "Continuous-time Markov chains are used to model stochastic systems where transitions can occur at irregular times, e.g., birth-death processes, chemical reaction networks, population dynamics, and gene regulatory networks. We develop a method to learn a continuous-time Markov chain's transition rate functions from fully observed time series. In contrast with existing methods, our method allows for transition rates to depend nonlinearly on both state variables and external covariates. The Gillespie algorithm is used to generate trajectories of stochastic systems where propensity functions (reaction rates) are known. Our method can be viewed as the inverse: given trajectories of a stochastic reaction network, we generate estimates of the propensity functions. While previous methods used linear or log-linear methods to link transition rates to covariates, we use neural networks, increasing the capacity and potential accuracy of learned models. In the chemical context, this enables the method to learn propensity functions from non-mass-action kinetics. We test our method with synthetic data generated from a variety of systems with known transition rates. We show that our method learns these transition rates with considerably more accuracy than log-linear methods, in terms of mean absolute error between ground truth and predicted transition rates. We also demonstrate an application of our methods to open-loop control of a continuous-time Markov chain. ",
    "url": "https://arxiv.org/abs/2212.05378",
    "authors": [
      "Majerle Reeves",
      "Harish S. Bhat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05497",
    "title": "Target Detection Framework for Lobster Eye X-Ray Telescopes with Machine  Learning Algorithms",
    "abstract": "Lobster eye telescopes are ideal monitors to detect X-ray transients, because they could observe celestial objects over a wide field of view in X-ray band. However, images obtained by lobster eye telescopes are modified by their unique point spread functions, making it hard to design a high efficiency target detection algorithm. In this paper, we integrate several machine learning algorithms to build a target detection framework for data obtained by lobster eye telescopes. Our framework would firstly generate two 2D images with different pixel scales according to positions of photons on the detector. Then an algorithm based on morphological operations and two neural networks would be used to detect candidates of celestial objects with different flux from these 2D images. At last, a random forest algorithm will be used to pick up final detection results from candidates obtained by previous steps. Tested with simulated data of the Wide-field X-ray Telescope onboard the Einstein Probe, our detection framework could achieve over 94% purity and over 90% completeness for targets with flux more than 3 mCrab (9.6 * 10-11 erg/cm2/s) and more than 94% purity and moderate completeness for targets with lower flux at acceptable time cost. The framework proposed in this paper could be used as references for data processing methods developed for other lobster eye X-ray telescopes. ",
    "url": "https://arxiv.org/abs/2212.05497",
    "authors": [
      "Peng Jia",
      "Wenbo Liu",
      "Yuan Liu",
      "Haiwu Pan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05632",
    "title": "Blockchain Network Analysis: A Comparative Study of Decentralized Banks",
    "abstract": "Decentralized finance (DeFi) is known for its unique mechanism design, which applies smart contracts to facilitate peer-to-peer transactions. The decentralized bank is a typical DeFi application. Ideally, a decentralized bank should be decentralized in the transaction. However, many recent studies have found that decentralized banks have not achieved a significant degree of decentralization. This research conducts a comparative study among mainstream decentralized banks. We apply core-periphery network features analysis using the transaction data from four decentralized banks, Liquity, Aave, MakerDao, and Compound. We extract six features and compare the banks' levels of decentralization cross-sectionally. According to the analysis results, we find that: 1) MakerDao and Compound are more decentralized in the transactions than Aave and Liquity. 2) Although decentralized banking transactions are supposed to be decentralized, the data show that four banks have primary external transaction core addresses such as Huobi, Coinbase, Binance, etc. We also discuss four design features that might affect network decentralization. Our research contributes to the literature at the interface of decentralized finance, financial technology (Fintech), and social network analysis and inspires future protocol designs to live up to the promise of decentralized finance for a truly peer-to-peer transaction network. ",
    "url": "https://arxiv.org/abs/2212.05632",
    "authors": [
      "Yufan Zhang",
      "Zichao Chen",
      "Yutong Sun",
      "Yulin Liu",
      "Luyao Zhang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)",
      "Trading and Market Microstructure (q-fin.TR)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2212.05794",
    "title": "CTT-Net: A Multi-view Cross-token Transformer for Cataract Postoperative  Visual Acuity Prediction",
    "abstract": "Surgery is the only viable treatment for cataract patients with visual acuity (VA) impairment. Clinically, to assess the necessity of cataract surgery, accurately predicting postoperative VA before surgery by analyzing multi-view optical coherence tomography (OCT) images is crucially needed. Unfortunately, due to complicated fundus conditions, determining postoperative VA remains difficult for medical experts. Deep learning methods for this problem were developed in recent years. Although effective, these methods still face several issues, such as not efficiently exploring potential relations between multi-view OCT images, neglecting the key role of clinical prior knowledge (e.g., preoperative VA value), and using only regression-based metrics which are lacking reference. In this paper, we propose a novel Cross-token Transformer Network (CTT-Net) for postoperative VA prediction by analyzing both the multi-view OCT images and preoperative VA. To effectively fuse multi-view features of OCT images, we develop cross-token attention that could restrict redundant/unnecessary attention flow. Further, we utilize the preoperative VA value to provide more information for postoperative VA prediction and facilitate fusion between views. Moreover, we design an auxiliary classification loss to improve model performance and assess VA recovery more sufficiently, avoiding the limitation by only using the regression metrics. To evaluate CTT-Net, we build a multi-view OCT image dataset collected from our collaborative hospital. A set of extensive experiments validate the effectiveness of our model compared to existing methods in various metrics. Code is available at: https://github.com/wjh892521292/Cataract OCT. ",
    "url": "https://arxiv.org/abs/2212.05794",
    "authors": [
      "Jinhong Wang",
      "Jingwen Wang",
      "Tingting Chen",
      "Wenhao Zheng",
      "Zhe Xu",
      "Xingdi Wu",
      "Wen Xu",
      "Haochao Ying",
      "Danny Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05808",
    "title": "Z-SSMNet: A Zonal-aware Self-Supervised Mesh Network for Prostate Cancer  Detection and Diagnosis in bpMRI",
    "abstract": "Prostate cancer (PCa) is one of the most prevalent cancers in men and many people around the world die from clinically significant PCa (csPCa). Early diagnosis of csPCa in bi-parametric MRI (bpMRI), which is non-invasive, cost-effective, and more efficient compared to multiparametric MRI (mpMRI), can contribute to precision care for PCa. The rapid rise in artificial intelligence (AI) algorithms are enabling unprecedented improvements in providing decision support systems that can aid in csPCa diagnosis and understanding. However, existing state of the art AI algorithms which are based on deep learning technology are often limited to 2D images that fails to capture inter-slice correlations in 3D volumetric images. The use of 3D convolutional neural networks (CNNs) partly overcomes this limitation, but it does not adapt to the anisotropy of images, resulting in sub-optimal semantic representation and poor generalization. Furthermore, due to the limitation of the amount of labelled data of bpMRI and the difficulty of labelling, existing CNNs are built on relatively small datasets, leading to a poor performance. To address the limitations identified above, we propose a new Zonal-aware Self-supervised Mesh Network (Z-SSMNet) that adaptatively fuses multiple 2D, 2.5D and 3D CNNs to effectively balance representation for sparse inter-slice information and dense intra-slice information in bpMRI. A self-supervised learning (SSL) technique is further introduced to pre-train our network using unlabelled data to learn the generalizable image features. Furthermore, we constrained our network to understand the zonal specific domain knowledge to improve the diagnosis precision of csPCa. Experiments on the PI-CAI Challenge dataset demonstrate our proposed method achieves better performance for csPCa detection and diagnosis in bpMRI. ",
    "url": "https://arxiv.org/abs/2212.05808",
    "authors": [
      "Yuan Yuan",
      "Euijoon Ahn",
      "Dagan Feng",
      "Mohamad Khadra",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05912",
    "title": "A machine learning approach to support decision in insider trading  detection",
    "abstract": "Identifying market abuse activity from data on investors' trading activity is very challenging both for the data volume and for the low signal to noise ratio. Here we propose two complementary unsupervised machine learning methods to support market surveillance aimed at identifying potential insider trading activities. The first one uses clustering to identify, in the vicinity of a price sensitive event such as a takeover bid, discontinuities in the trading activity of an investor with respect to his/her own past trading history and on the present trading activity of his/her peers. The second unsupervised approach aims at identifying (small) groups of investors that act coherently around price sensitive events, pointing to potential insider rings, i.e. a group of synchronised traders displaying strong directional trading in rewarding position in a period before the price sensitive event. As a case study, we apply our methods to investor resolved data of Italian stocks around takeover bids. ",
    "url": "https://arxiv.org/abs/2212.05912",
    "authors": [
      "Piero Mazzarisi",
      "Adele Ravagnani",
      "Paola Deriu",
      "Fabrizio Lillo",
      "Francesca Medda",
      "Antonio Russo"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.05916",
    "title": "NETpred: Network-based modeling and prediction of multiple connected  market indices",
    "abstract": "Market prediction plays a major role in supporting financial decisions. An emerging approach in this domain is to use graphical modeling and analysis to for prediction of next market index fluctuations. One important question in this domain is how to construct an appropriate graphical model of the data that can be effectively used by a semi-supervised GNN to predict index fluctuations. In this paper, we introduce a framework called NETpred that generates a novel heterogeneous graph representing multiple related indices and their stocks by using several stock-stock and stock-index relation measures. It then thoroughly selects a diverse set of representative nodes that cover different parts of the state space and whose price movements are accurately predictable. By assigning initial predicted labels to such a set of nodes, NETpred makes sure that the subsequent GCN model can be successfully trained using a semi-supervised learning process. The resulting model is then used to predict the stock labels which are finally aggregated to infer the labels for all the index nodes in the graph. Our comprehensive set of experiments shows that NETpred improves the performance of the state-of-the-art baselines by 3%-5% in terms of F-score measure on different well-known data sets. ",
    "url": "https://arxiv.org/abs/2212.05916",
    "authors": [
      "Alireza Jafari",
      "Saman Haratizadeh"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05925",
    "title": "CausalEGM: a general causal inference framework by encoding generative  modeling",
    "abstract": "Although understanding and characterizing causal effects have become essential in observational studies, it is challenging when the confounders are high-dimensional. In this article, we develop a general framework $\\textit{CausalEGM}$ for estimating causal effects by encoding generative modeling, which can be applied in both binary and continuous treatment settings. Under the potential outcome framework with unconfoundedness, we establish a bidirectional transformation between the high-dimensional confounders space and a low-dimensional latent space where the density is known (e.g., multivariate normal distribution). Through this, CausalEGM simultaneously decouples the dependencies of confounders on both treatment and outcome and maps the confounders to the low-dimensional latent space. By conditioning on the low-dimensional latent features, CausalEGM can estimate the causal effect for each individual or the average causal effect within a population. Our theoretical analysis shows that the excess risk for CausalEGM can be bounded through empirical process theory. Under an assumption on encoder-decoder networks, the consistency of the estimate can be guaranteed. In a series of experiments, CausalEGM demonstrates superior performance over existing methods for both binary and continuous treatments. Specifically, we find CausalEGM to be substantially more powerful than competing methods in the presence of large sample sizes and high dimensional confounders. The software of CausalEGM is freely available at https://github.com/SUwonglab/CausalEGM. ",
    "url": "https://arxiv.org/abs/2212.05925",
    "authors": [
      "Qiao Liu",
      "Zhongren Chen",
      "Wing Hung Wong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05991",
    "title": "Graph algorithms for predicting subcellular localization at the pathway  level",
    "abstract": "Protein subcellular localization is an important factor in normal cellular processes and disease. While many protein localization resources treat it as static, protein localization is dynamic and heavily influenced by biological context. Biological pathways are graphs that represent a specific biological context and can be inferred from large-scale data. We develop graph algorithms to predict the localization of all interactions in a biological pathway as an edge-labeling task. We compare a variety of models including graph neural networks, probabilistic graphical models, and discriminative classifiers for predicting localization annotations from curated pathway databases. We also perform a case study where we construct biological pathways and predict localizations of human fibroblasts undergoing viral infection. Pathway localization prediction is a promising approach for integrating publicly available localization data into the analysis of large-scale biological data. ",
    "url": "https://arxiv.org/abs/2212.05991",
    "authors": [
      "Chris S. Magnano",
      "Anthony Gitter"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1212.2950",
    "title": "Improved enumeration of simple topological graphs",
    "abstract": " Comments: 41 pages, 19 figures; removed an incorrect remark after Proposition 6 ",
    "url": "https://arxiv.org/abs/1212.2950",
    "authors": [
      "Jan Kyn\u010dl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:1708.08749",
    "title": "Blockchain: A Graph Primer",
    "abstract": " Comments: 19 pages, 5 figures ",
    "url": "https://arxiv.org/abs/1708.08749",
    "authors": [
      "Cuneyt Gurcan Akcora",
      "Yulia R. Gel",
      "Murat Kantarcioglu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:1907.04733",
    "title": "Coresets for Clustering in Graphs of Bounded Treewidth",
    "abstract": " Title: Coresets for Clustering in Graphs of Bounded Treewidth ",
    "url": "https://arxiv.org/abs/1907.04733",
    "authors": [
      "Daniel Baker",
      "Vladimir Braverman",
      "Lingxiao Huang",
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Xuan Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2001.03048",
    "title": "Resource-Efficient Neural Networks for Embedded Systems",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1812.02240 ",
    "url": "https://arxiv.org/abs/2001.03048",
    "authors": [
      "Wolfgang Roth",
      "G\u00fcnther Schindler",
      "Bernhard Klein",
      "Robert Peharz",
      "Sebastian Tschiatschek",
      "Holger Fr\u00f6ning",
      "Franz Pernkopf",
      "Zoubin Ghahramani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2004.02360",
    "title": "Moving Metric Detection and Alerting System at eBay",
    "abstract": " Comments: The work is oral presented on the AAAI-20 Workshop on Cloud Intelligence, 2020 ",
    "url": "https://arxiv.org/abs/2004.02360",
    "authors": [
      "Zezhong Zhang",
      "Keyu Nie",
      "Ted Tao Yuan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.03351",
    "title": "The universal approximation theorem for complex-valued neural networks",
    "abstract": " Title: The universal approximation theorem for complex-valued neural networks ",
    "url": "https://arxiv.org/abs/2012.03351",
    "authors": [
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2012.13033",
    "title": "An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time  Video Enhancement",
    "abstract": " Title: An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time  Video Enhancement ",
    "url": "https://arxiv.org/abs/2012.13033",
    "authors": [
      "Dario Fuoli",
      "Zhiwu Huang",
      "Danda Pani Paudel",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.09250",
    "title": "Cyber-Resilient Self-Triggered Distributed Control of Networked  Microgrids Against Multi-Layer DoS Attacks",
    "abstract": " Comments: accepted by IEEE Trans. on Smart Grid ",
    "url": "https://arxiv.org/abs/2104.09250",
    "authors": [
      "Pudong Ge",
      "Boli Chen",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2108.09976",
    "title": "Revealing the Distributional Vulnerability of Discriminators by Implicit  Generators",
    "abstract": " Title: Revealing the Distributional Vulnerability of Discriminators by Implicit  Generators ",
    "url": "https://arxiv.org/abs/2108.09976",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.06407",
    "title": "Neural Networks with Physics-Informed Architectures and Constraints for  Dynamical Systems Modeling",
    "abstract": " Comments: Published as a conference paper at L4DC 2022 ",
    "url": "https://arxiv.org/abs/2109.06407",
    "authors": [
      "Franck Djeumou",
      "Cyrus Neary",
      "Eric Goubault",
      "Sylvie Putot",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.03302",
    "title": "MPSN: Motion-aware Pseudo Siamese Network for Indoor Video Head  Detection in Buildings",
    "abstract": " Comments: Published in Building and Environment.Copyright:Elsevier. Paper link:this https URL ",
    "url": "https://arxiv.org/abs/2110.03302",
    "authors": [
      "Kailai Sun",
      "Xiaoteng Ma",
      "Peng Liu",
      "Qianchuan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11396",
    "title": "Latent Network Models to Account for Noisy, Multiply-Reported Social  Network Data",
    "abstract": " Title: Latent Network Models to Account for Noisy, Multiply-Reported Social  Network Data ",
    "url": "https://arxiv.org/abs/2112.11396",
    "authors": [
      "Caterina De Bacco",
      "Martina Contisciani",
      "Jonathan Cardoso-Silva",
      "Hadiseh Safdari",
      "Diego Baptista",
      "Gabriela L. Borges",
      "Tracy Sweet",
      "Jean-Gabriel Young",
      "Jeremy Koster",
      "Cody T. Ross",
      "Richard McElreath",
      "Daniel Redhead",
      "Eleanor A. Power"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.04604",
    "title": "Fine-grained Graph Learning for Multi-view Subspace Clustering",
    "abstract": " Title: Fine-grained Graph Learning for Multi-view Subspace Clustering ",
    "url": "https://arxiv.org/abs/2201.04604",
    "authors": [
      "Yidi Wang",
      "Xiaobing Pei",
      "Haoxi Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12006",
    "title": "Improving Expert Predictions with Prediction Sets",
    "abstract": " Title: Improving Expert Predictions with Prediction Sets ",
    "url": "https://arxiv.org/abs/2201.12006",
    "authors": [
      "Eleni Straitouri",
      "Lequn Wang",
      "Nastaran Okati",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07301",
    "title": "User-Oriented Robust Reinforcement Learning",
    "abstract": " Title: User-Oriented Robust Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2202.07301",
    "authors": [
      "Haoyi You",
      "Beichen Yu",
      "Haiming Jin",
      "Zhaoxing Yang",
      "Jiahui Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09657",
    "title": "Survey of Machine Learning Based Intrusion Detection Methods for  Internet of Medical Things",
    "abstract": " Comments: 40 pages, 3 figures, and 6 tables ",
    "url": "https://arxiv.org/abs/2202.09657",
    "authors": [
      "Ayoub Si-Ahmed",
      "Mohammed Ali Al-Garadi",
      "Narhimene Boustia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.09745",
    "title": "RDP-Net: Region Detail Preserving Network for Change Detection",
    "abstract": " Comments: 10 pages, 10 figures, 55 references ",
    "url": "https://arxiv.org/abs/2202.09745",
    "authors": [
      "Hongjia Chen",
      "Fangling Pu",
      "Rui Yang",
      "Rui Tang",
      "Xin Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.13758",
    "title": "Logical Fallacy Detection",
    "abstract": " Comments: EMNLP 2021 Findings ",
    "url": "https://arxiv.org/abs/2202.13758",
    "authors": [
      "Zhijing Jin",
      "Abhinav Lalwani",
      "Tejas Vaidhya",
      "Xiaoyu Shen",
      "Yiwen Ding",
      "Zhiheng Lyu",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2203.09672",
    "title": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With  Unstructured Proxies",
    "abstract": " Comments: NeurIPS 2022 (accepted version) ",
    "url": "https://arxiv.org/abs/2203.09672",
    "authors": [
      "Shachi Deshpande",
      "Kaiwen Wang",
      "Dhruv Sreenivas",
      "Zheng Li",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.12531",
    "title": "Multi-label Transformer for Action Unit Detection",
    "abstract": " Title: Multi-label Transformer for Action Unit Detection ",
    "url": "https://arxiv.org/abs/2203.12531",
    "authors": [
      "Gauthier Tallec",
      "Edouard Yvinec",
      "Arnaud Dapogny",
      "Kevin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.03080",
    "title": "Graph Neural Networks Designed for Different Graph Types: A Survey",
    "abstract": " Title: Graph Neural Networks Designed for Different Graph Types: A Survey ",
    "url": "https://arxiv.org/abs/2204.03080",
    "authors": [
      "Josephine M. Thomas",
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "Clara Holzh\u00fcter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10208",
    "title": "Message Flow Analysis with Complex Causal Links for Distributed ROS 2  Systems",
    "abstract": " Comments: 14 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2204.10208",
    "authors": [
      "Christophe B\u00e9dard",
      "Pierre-Yves Lajoie",
      "Giovanni Beltrame",
      "Michel Dagenais"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.11304",
    "title": "Dictionary Attacks on Speaker Verification",
    "abstract": " Comments: Accepted in IEEE Transactions on Information Forensics and Security ",
    "url": "https://arxiv.org/abs/2204.11304",
    "authors": [
      "Mirko Marras",
      "Pawel Korus",
      "Anubhav Jain",
      "Nasir Memon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.01629",
    "title": "AutoFi: Towards Automatic WiFi Human Sensing via Geometric  Self-Supervised Learning",
    "abstract": " Comments: The paper has been accepted by IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2205.01629",
    "authors": [
      "Jianfei Yang",
      "Xinyan Chen",
      "Han Zou",
      "Dazhuo Wang",
      "Lihua Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2205.06241",
    "title": "Can counterfactual explanations of AI systems' predictions skew lay  users' causal intuitions about the world? If so, can we correct for that?",
    "abstract": " Title: Can counterfactual explanations of AI systems' predictions skew lay  users' causal intuitions about the world? If so, can we correct for that? ",
    "url": "https://arxiv.org/abs/2205.06241",
    "authors": [
      "Marko Tesic",
      "Ulrike Hahn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.11338",
    "title": "Temporal Network Analysis Using Zigzag Persistence",
    "abstract": " Title: Temporal Network Analysis Using Zigzag Persistence ",
    "url": "https://arxiv.org/abs/2205.11338",
    "authors": [
      "Audun Myers",
      "David Mu\u00f1oz",
      "Firas Khasawneh",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2205.14922",
    "title": "ACIL: Analytic Class-Incremental Learning with Absolute Memorization and  Privacy Protection",
    "abstract": " Comments: published in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.14922",
    "authors": [
      "Huiping Zhuang",
      "Zhenyu Weng",
      "Hongxin Wei",
      "Renchunzi Xie",
      "Kar-Ann Toh",
      "Zhiping Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01266",
    "title": "Exponential Separations in Symmetric Neural Networks",
    "abstract": " Title: Exponential Separations in Symmetric Neural Networks ",
    "url": "https://arxiv.org/abs/2206.01266",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01927",
    "title": "Variational Monte Carlo Approach to Partial Differential Equations with  Neural Networks",
    "abstract": " Comments: 6 + 3 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2206.01927",
    "authors": [
      "Moritz Reh",
      "Martin G\u00e4rttner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2206.02777",
    "title": "Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation",
    "abstract": " Title: Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation ",
    "url": "https://arxiv.org/abs/2206.02777",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Huaizhe xu",
      "Shilong Liu",
      "Lei Zhang",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03865",
    "title": "Fault-Aware Neural Code Rankers",
    "abstract": " Comments: In the proceedings of Advances in Neural Information Processing Systems, 2022 ",
    "url": "https://arxiv.org/abs/2206.03865",
    "authors": [
      "Jeevana Priya Inala",
      "Chenglong Wang",
      "Mei Yang",
      "Andres Codas",
      "Mark Encarnaci\u00f3n",
      "Shuvendu K Lahiri",
      "Madanlal Musuvathi",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.04320",
    "title": "Negative Shannon Information Hides Networks",
    "abstract": " Comments: 6+11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2206.04320",
    "authors": [
      "Ming-Xing Luo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.04797",
    "title": "Memory-efficient model-based deep learning with convergence and  robustness guarantees",
    "abstract": " Title: Memory-efficient model-based deep learning with convergence and  robustness guarantees ",
    "url": "https://arxiv.org/abs/2206.04797",
    "authors": [
      "Aniket Pramanik",
      "Mathews Jacob"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04922",
    "title": "A Novel Chinese Dialect TTS Frontend with Non-Autoregressive Neural  Machine Translation",
    "abstract": " Comments: 4 pages,5 figures ",
    "url": "https://arxiv.org/abs/2206.04922",
    "authors": [
      "Junhui Zhang",
      "Wudi Bao",
      "Junjie Pan",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.10911",
    "title": "Influence of uncertainty estimation techniques on false-positive  reduction in liver lesion detection",
    "abstract": " Comments: Accepted for publication in the Journal of Machine Learning for Biomedical Imaging (MELBA) ",
    "url": "https://arxiv.org/abs/2206.10911",
    "authors": [
      "Ishaan Bhat",
      "Josien P.W. Pluim",
      "Max A. Viergever",
      "Hugo J. Kuijf"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.01105",
    "title": "Scalable Polar Code Construction for Successive Cancellation List  Decoding: A Graph Neural Network-Based Approach",
    "abstract": " Comments: 32 pages, 11 figures, submitted to IEEE Transactions on Communications ",
    "url": "https://arxiv.org/abs/2207.01105",
    "authors": [
      "Yun Liao",
      "Seyyed Ali Hashemi",
      "Hengjie Yang",
      "John M. Cioffi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.02242",
    "title": "State-Augmented Learnable Algorithms for Resource Management in Wireless  Networks",
    "abstract": " Comments: To appear in IEEE Transactions on Signal Processing. The implementation code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.02242",
    "authors": [
      "Navid NaderiAlizadeh",
      "Mark Eisen",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.02428",
    "title": "Modeling and Analysis of Utilizing Cryptocurrency Mining for Demand  Flexibility in Electric Energy Systems: A Synthetic Texas Grid Case Study",
    "abstract": " Comments: This paper has been accepted for publication in IEEE Transactions on Energy Markets, Policy and Regulation journal ",
    "url": "https://arxiv.org/abs/2207.02428",
    "authors": [
      "Ali Menati",
      "Kiyeob Lee",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.03933",
    "title": "A law of adversarial risk, interpolation, and label noise",
    "abstract": " Comments: 22 pages, 8 figures. In review for ICLR 2023 ",
    "url": "https://arxiv.org/abs/2207.03933",
    "authors": [
      "Daniel Paleka",
      "Amartya Sanyal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00751",
    "title": "CSDN: Cross-modal Shape-transfer Dual-refinement Network for Point Cloud  Completion",
    "abstract": " Title: CSDN: Cross-modal Shape-transfer Dual-refinement Network for Point Cloud  Completion ",
    "url": "https://arxiv.org/abs/2208.00751",
    "authors": [
      "Zhe Zhu",
      "Liangliang Nan",
      "Haoran Xie",
      "Honghua Chen",
      "Mingqiang Wei",
      "Jun Wang",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.03264",
    "title": "Towards Antisymmetric Neural Ansatz Separation",
    "abstract": " Title: Towards Antisymmetric Neural Ansatz Separation ",
    "url": "https://arxiv.org/abs/2208.03264",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06530",
    "title": "Representation learning for a generalized, quantitative comparison of  complex model outputs",
    "abstract": " Comments: 10 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2208.06530",
    "authors": [
      "Colin G. Cess",
      "Stacey D. Finley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.07498",
    "title": "Universal Solutions of Feedforward ReLU Networks for Interpolations",
    "abstract": " Comments: v2:minor revision; v3-v4:proposition 5 revised; v5:theorem 10 refined ",
    "url": "https://arxiv.org/abs/2208.07498",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.08193",
    "title": "A Survey of User Perspectives on Security and Privacy in a Home  Networking Environment",
    "abstract": " Comments: 35 pages, Published in ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2208.08193",
    "authors": [
      "Nandita Pattnaik",
      "Shujun Li",
      "Jason R.C. Nurse"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.10373",
    "title": "Reversing Skin Cancer Adversarial Examples by Multiscale Diffusive and  Denoising Aggregation Mechanism",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2208.10373",
    "authors": [
      "Yongwei Wang",
      "Yuan Li",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.12422",
    "title": "Toward Robust Graph Semi-Supervised Learning against Extreme Data  Scarcity",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2208.12422",
    "authors": [
      "Kaize Ding",
      "Elnaz Nouri",
      "Guoqing Zheng",
      "Huan Liu",
      "Ryen White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12650",
    "title": "Empowering First-Year Computer Science Ph.D. Students to Create a  Culture that Values Community and Mental Health",
    "abstract": " Comments: Accepted at SIGCSE 2023 ",
    "url": "https://arxiv.org/abs/2208.12650",
    "authors": [
      "Yaniv Yacoby",
      "John Girash",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.14385",
    "title": "Application of Convolutional Neural Networks with Quasi-Reversibility  Method Results for Option Forecasting",
    "abstract": " Comments: 10 pages, 2 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2208.14385",
    "authors": [
      "Zheng Cao",
      "Wenyu Du",
      "Kirill V. Golubnichiy"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2209.06235",
    "title": "Improving Self-Supervised Learning by Characterizing Idealized  Representations",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.06235",
    "authors": [
      "Yann Dubois",
      "Tatsunori Hashimoto",
      "Stefano Ermon",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.08579",
    "title": "Bivariate Causal Discovery for Categorical Data via Classification with  Optimal Label Permutation",
    "abstract": " Title: Bivariate Causal Discovery for Categorical Data via Classification with  Optimal Label Permutation ",
    "url": "https://arxiv.org/abs/2209.08579",
    "authors": [
      "Yang Ni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2209.08639",
    "title": "Distributionally robust trading strategies for renewable energy  producers",
    "abstract": " Title: Distributionally robust trading strategies for renewable energy  producers ",
    "url": "https://arxiv.org/abs/2209.08639",
    "authors": [
      "Pierre Pinson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.12316",
    "title": "Weather2vec: Representation Learning for Causal Inference with Non-Local  Confounding in Air Pollution and Climate Studies",
    "abstract": " Title: Weather2vec: Representation Learning for Causal Inference with Non-Local  Confounding in Air Pollution and Climate Studies ",
    "url": "https://arxiv.org/abs/2209.12316",
    "authors": [
      "Mauricio Tec",
      "James Scott",
      "Corwin Zigler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.12372",
    "title": "Scalable Quantum Convolutional Neural Networks",
    "abstract": " Title: Scalable Quantum Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2209.12372",
    "authors": [
      "Hankyul Baek",
      "Won Joon Yun",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01741",
    "title": "Neural Conservation Laws: A Divergence-Free Perspective",
    "abstract": " Title: Neural Conservation Laws: A Divergence-Free Perspective ",
    "url": "https://arxiv.org/abs/2210.01741",
    "authors": [
      "Jack Richter-Powell",
      "Yaron Lipman",
      "Ricky T. Q. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02595",
    "title": "Exploration of A Self-Supervised Speech Model: A Study on Emotional  Corpora",
    "abstract": " Comments: Accepted to SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.02595",
    "authors": [
      "Yuanchao Li",
      "Yumnah Mohamied",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.04267",
    "title": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "abstract": " Title: Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection ",
    "url": "https://arxiv.org/abs/2210.04267",
    "authors": [
      "Omkar Gokhale",
      "Aditya Kane",
      "Shantanu Patankar",
      "Tanmay Chavan",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04633",
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models  for Programming Language Attend Code Structure",
    "abstract": " Comments: Accepted by EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.04633",
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.04742",
    "title": "Over-the-Air Split Machine Learning in Wireless MIMO Networks",
    "abstract": " Comments: to be pubilshed in IEEE Journal on Selected Areas in Communications, 15 pages, 13 figures, journal paper ",
    "url": "https://arxiv.org/abs/2210.04742",
    "authors": [
      "Yuzhi Yang",
      "Zhaoyang Zhang",
      "Yuqing Tian",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Caijun Zhong",
      "Kai-Kit Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08057",
    "title": "Pishgu: Universal Path Prediction Network Architecture for Real-time  Cyber-physical Edge Systems",
    "abstract": " Title: Pishgu: Universal Path Prediction Network Architecture for Real-time  Cyber-physical Edge Systems ",
    "url": "https://arxiv.org/abs/2210.08057",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Armin Danesh Pazho",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.11152",
    "title": "Machine Learning for K-adaptability in Two-stage Robust Optimization",
    "abstract": " Title: Machine Learning for K-adaptability in Two-stage Robust Optimization ",
    "url": "https://arxiv.org/abs/2210.11152",
    "authors": [
      "Esther Julien",
      "Krzysztof Postek",
      "\u015e. \u0130lker Birbil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11582",
    "title": "Deep Learning for Diagonal Earlobe Crease Detection",
    "abstract": " Comments: Accepted at 12th International Conference on Pattern Recognition Applications (ICPRAM 2023) ",
    "url": "https://arxiv.org/abs/2210.11582",
    "authors": [
      "Sara L. Almonacid-Uribe",
      "Oliverio J. Santana",
      "Daniel Hern\u00e1ndez-Sosa",
      "David Freire-Obreg\u00f3n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.17449",
    "title": "Globally Gated Deep Linear Networks",
    "abstract": " Title: Globally Gated Deep Linear Networks ",
    "url": "https://arxiv.org/abs/2210.17449",
    "authors": [
      "Qianyi Li",
      "Haim Sompolinsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2211.01689",
    "title": "Isotropic Gaussian Processes on Finite Spaces of Graphs",
    "abstract": " Title: Isotropic Gaussian Processes on Finite Spaces of Graphs ",
    "url": "https://arxiv.org/abs/2211.01689",
    "authors": [
      "Viacheslav Borovitskiy",
      "Mohammad Reza Karimi",
      "Vignesh Ram Somnath",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01768",
    "title": "Embedding Knowledge Graph of Patent Metadata to Measure Knowledge  Proximity",
    "abstract": " Title: Embedding Knowledge Graph of Patent Metadata to Measure Knowledge  Proximity ",
    "url": "https://arxiv.org/abs/2211.01768",
    "authors": [
      "Guangtong Li",
      "L Siddharth",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.02820",
    "title": "A Robust and Low Complexity Deep Learning Model for Remote Sensing Image  Classification",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2211.02820",
    "authors": [
      "Cam Le",
      "Lam Pham",
      "Nghia NVN",
      "Truong Nguyen",
      "Le Hong Trang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.02904",
    "title": "HAQJSK: Hierarchical-Aligned Quantum Jensen-Shannon Kernels for Graph  Classification",
    "abstract": " Title: HAQJSK: Hierarchical-Aligned Quantum Jensen-Shannon Kernels for Graph  Classification ",
    "url": "https://arxiv.org/abs/2211.02904",
    "authors": [
      "Lu Bai",
      "Lixin Cui",
      "Yue Wang",
      "Ming Li",
      "Edwin R. Hancock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.03348",
    "title": "Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for  Unsupervised Sentence Embedding",
    "abstract": " Comments: Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2211.03348",
    "authors": [
      "Jiali Zeng",
      "Yongjing Yin",
      "Yufan Jiang",
      "Shuangzhi Wu",
      "Yunbo Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.04871",
    "title": "Graph classes equivalent to 12-representable graphs",
    "abstract": " Comments: 12 pages, 6 figures, Corrected typos ",
    "url": "https://arxiv.org/abs/2211.04871",
    "authors": [
      "Asahi Takaoka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.05262",
    "title": "Stabilizing Machine Learning Prediction of Dynamics: Noise and  Noise-inspired Regularization",
    "abstract": " Comments: 39 pages, 8 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2211.05262",
    "authors": [
      "Alexander Wikner",
      "Joseph Harvey",
      "Michelle Girvan",
      "Brian R. Hunt",
      "Andrew Pomerance",
      "Thomas Antonsen",
      "Edward Ott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2211.08804",
    "title": "Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Systems",
    "abstract": " Title: Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Systems ",
    "url": "https://arxiv.org/abs/2211.08804",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09299",
    "title": "FedFA: Federated Learning with Feature Anchors to Align Feature and  Classifier for Heterogeneous Data",
    "abstract": " Title: FedFA: Federated Learning with Feature Anchors to Align Feature and  Classifier for Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2211.09299",
    "authors": [
      "Tailin Zhou",
      "Jun Zhang",
      "Danny Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09717",
    "title": "UPTON: Unattributable Authorship Text via Data Poisoning",
    "abstract": " Title: UPTON: Unattributable Authorship Text via Data Poisoning ",
    "url": "https://arxiv.org/abs/2211.09717",
    "authors": [
      "Ziyao Wang",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.10738",
    "title": "Relational Symmetry based Knowledge Graph Contrastive Learning",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.10738",
    "authors": [
      "Ke Liang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Wenxuan Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11475",
    "title": "Sensing-Assisted Communication in Vehicular Networks with Intelligent  Surface",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. arXiv admin note: text overlap with arXiv:2211.04200 ",
    "url": "https://arxiv.org/abs/2211.11475",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.13424",
    "title": "Deepfake Detection via Joint Unsupervised Reconstruction and Supervised  Classification",
    "abstract": " Comments: This paper has been submitted to Pattern Recognition Letter for review ",
    "url": "https://arxiv.org/abs/2211.13424",
    "authors": [
      "Bosheng Yan",
      "Chang-Tsun Li",
      "Xuequan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13902",
    "title": "TAOTF: A Two-stage Approximately Orthogonal Training Framework in Deep  Neural Networks",
    "abstract": " Title: TAOTF: A Two-stage Approximately Orthogonal Training Framework in Deep  Neural Networks ",
    "url": "https://arxiv.org/abs/2211.13902",
    "authors": [
      "Taoyong Cui",
      "Jianze Li",
      "Yuhan Dong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00735",
    "title": "xTrimoABFold: De novo Antibody Structure Prediction without MSA",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2212.00735",
    "authors": [
      "Yining Wang",
      "Xumeng Gong",
      "Shaochuan Li",
      "Bing Yang",
      "YiWu Sun",
      "Chuan Shi",
      "Yangang Wang",
      "Cheng Yang",
      "Hui Li",
      "Le Song"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.02017",
    "title": "GNN-SL: Sequence Labeling Based on Nearest Examples via GNN",
    "abstract": " Comments: preprint ",
    "url": "https://arxiv.org/abs/2212.02017",
    "authors": [
      "Shuhe Wang",
      "Yuxian Meng",
      "Rongbin Ouyang",
      "Jiwei Li",
      "Tianwei Zhang",
      "Lingjuan Lyu",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.02295",
    "title": "Block Selection Method for Using Feature Norm in Out-of-distribution  Detection",
    "abstract": " Comments: 11 pages including reference. 5 figures and 5 tables ",
    "url": "https://arxiv.org/abs/2212.02295",
    "authors": [
      "Yeonguk Yu",
      "Sungho Shin",
      "Seongju Lee",
      "Changhyun Jun",
      "Kyoobin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.02477",
    "title": "Malaria Parasitic Detection using a New Deep Boosted and Ensemble  Learning Framework",
    "abstract": " Comments: 26 pages, 10 figures, 9 Tables ",
    "url": "https://arxiv.org/abs/2212.02477",
    "authors": [
      "Saddam Hussain Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02952",
    "title": "Simple Baseline for Weather Forecasting Using Spatiotemporal Context  Aggregation Network",
    "abstract": " Comments: 1st place solution for stage1 and Core Transfer in the Weather4Cast competition on NeurIPS 22 ",
    "url": "https://arxiv.org/abs/2212.02952",
    "authors": [
      "Minseok Seo",
      "Doyi Kim",
      "Seungheon Shin",
      "Eunbin Kim",
      "Sewoong Ahn",
      "Yeji Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.02968",
    "title": "Domain Generalization Strategy to Train Classifiers Robust to  Spatial-Temporal Shift",
    "abstract": " Comments: Core Transfer Track 1st place solution in Weather4Cast competition at NeuIPS22 ",
    "url": "https://arxiv.org/abs/2212.02968",
    "authors": [
      "Minseok Seo",
      "Doyi Kim",
      "Seungheon Shin",
      "Eunbin Kim",
      "Sewoong Ahn",
      "Yeji Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.03125",
    "title": "Self-supervised and Weakly Supervised Contrastive Learning for  Frame-wise Action Representations",
    "abstract": " Comments: 13 pages, 8 figures. arXiv admin note: substantial text overlap with arXiv:2203.14957 ",
    "url": "https://arxiv.org/abs/2212.03125",
    "authors": [
      "Minghao Chen",
      "Renbo Tu",
      "Chenxi Huang",
      "Yuqi Lin",
      "Boxi Wu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.03279",
    "title": "From Knowledge Augmentation to Multi-tasking: Towards Human-like  Dialogue Systems",
    "abstract": " Comments: PhD thesis ",
    "url": "https://arxiv.org/abs/2212.03279",
    "authors": [
      "Tom Young"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.03369",
    "title": "Exploring Randomly Wired Neural Networks for Climate Model Emulation",
    "abstract": " Title: Exploring Randomly Wired Neural Networks for Climate Model Emulation ",
    "url": "https://arxiv.org/abs/2212.03369",
    "authors": [
      "William Yik",
      "Sam J. Silva",
      "Andrew Geiss",
      "Duncan Watson-Parris"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04454",
    "title": "XRand: Differentially Private Defense against Explanation-Guided Attacks",
    "abstract": " Comments: To be published at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.04454",
    "authors": [
      "Truc Nguyen",
      "Phung Lai",
      "NhatHai Phan",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.04481",
    "title": "A Survey of Graph Neural Networks for Social Recommender Systems",
    "abstract": " Comments: GitHub repository with the curated list of papers: this https URL ",
    "url": "https://arxiv.org/abs/2212.04481",
    "authors": [
      "Kartik Sharma",
      "Yeon-Chang Lee",
      "Sivagami Nambi",
      "Aditya Salian",
      "Shlok Shah",
      "Sang-Wook Kim",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  }
]