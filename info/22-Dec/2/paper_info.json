[
  {
    "id": "arXiv:2212.00015",
    "title": "Scalable Pathogen Detection from Next Generation DNA Sequencing with  Deep Learning",
    "abstract": "Next-generation sequencing technologies have enhanced the scope of Internet-of-Things (IoT) to include genomics for personalized medicine through the increased availability of an abundance of genome data collected from heterogeneous sources at a reduced cost. Given the sheer magnitude of the collected data and the significant challenges offered by the presence of highly similar genomic structure across species, there is a need for robust, scalable analysis platforms to extract actionable knowledge such as the presence of potentially zoonotic pathogens. The emergence of zoonotic diseases from novel pathogens, such as the influenza virus in 1918 and SARS-CoV-2 in 2019 that can jump species barriers and lead to pandemic underscores the need for scalable metagenome analysis. In this work, we propose MG2Vec, a deep learning-based solution that uses the transformer network as its backbone, to learn robust features from raw metagenome sequences for downstream biomedical tasks such as targeted and generalized pathogen detection. Extensive experiments on four increasingly challenging, yet realistic diagnostic settings, show that the proposed approach can help detect pathogens from uncurated, real-world clinical samples with minimal human supervision in the form of labels. Further, we demonstrate that the learned representations can generalize to completely unrelated pathogens across diseases and species for large-scale metagenome analysis. We provide a comprehensive evaluation of a novel representation learning framework for metagenome-based disease diagnostics with deep learning and provide a way forward for extracting and using robust vector representations from low-cost next generation sequencing to develop generalizable diagnostic tools. ",
    "url": "https://arxiv.org/abs/2212.00015",
    "authors": [
      "Sai Narayanan",
      "Sathyanarayanan N. Aakur",
      "Priyadharsini Ramamurthy",
      "Arunkumar Bagavathi",
      "Vishalini Ramnath",
      "Akhilesh Ramachandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2212.00021",
    "title": "Location analysis of players in UEFA EURO 2020 and 2022 using  generalized valuation of defense by estimating probabilities",
    "abstract": "Analyzing defenses in team sports is generally challenging because of the limited event data. Researchers have previously proposed methods to evaluate football team defense by predicting the events of ball gain and being attacked using locations of all players and the ball. However, they did not consider the importance of the events, assumed the perfect observation of all 22 players, and did not fully investigated the influence of the diversity (e.g., nationality and sex). Here, we propose a generalized valuation method of defensive teams by score-scaling the predicted probabilities of the events. Using the open-source location data of all players in broadcast video frames in football games of men's Euro 2020 and women's Euro 2022, we investigated the effect of the number of players on the prediction and validated our approach by analyzing the games. Results show that for the predictions of being attacked, scoring, and conceding, all players' information was not necessary, while that of ball gain required information on three to four offensive and defensive players. With game analyses we explained the excellence in defense of finalist teams in Euro 2020. Our approach might be applicable to location data from broadcast video frames in football games. ",
    "url": "https://arxiv.org/abs/2212.00021",
    "authors": [
      "Rikuhei Umemoto",
      "Kazushi Tsutsui",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00022",
    "title": "Optical multi-task learning using multi-wavelength diffractive deep  neural networks",
    "abstract": "Photonic neural networks are brain-inspired information processing technology using photons instead of electrons to perform artificial intelligence (AI) tasks. However, existing architectures are designed for a single task but fail to multiplex different tasks in parallel within a single monolithic system due to the task competition that deteriorates the model performance. This paper proposes a novel optical multi-task learning system by designing multi-wavelength diffractive deep neural networks (D2NNs) with the joint optimization method. By encoding multi-task inputs into multi-wavelength channels, the system can increase the computing throughput and significantly alle-viate the competition to perform multiple tasks in parallel with high accuracy. We design the two-task and four-task D2NNs with two and four spectral channels, respectively, for classifying different inputs from MNIST, FMNIST, KMNIST, and EMNIST databases. The numerical evaluations demonstrate that, under the same network size, mul-ti-wavelength D2NNs achieve significantly higher classification accuracies for multi-task learning than single-wavelength D2NNs. Furthermore, by increasing the network size, the multi-wavelength D2NNs for simultaneously performing multiple tasks achieve comparable classification accuracies with respect to the individual training of multiple single-wavelength D2NNs to perform tasks separately. Our work paves the way for developing the wave-length-division multiplexing technology to achieve high-throughput neuromorphic photonic computing and more general AI systems to perform multiple tasks in parallel. ",
    "url": "https://arxiv.org/abs/2212.00022",
    "authors": [
      "Zhengyang Duan",
      "Hang Chen",
      "Xing Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2212.00024",
    "title": "Semi-Supervised Heterogeneous Graph Learning with Multi-level Data  Augmentation",
    "abstract": "In recent years, semi-supervised graph learning with data augmentation (DA) is currently the most commonly used and best-performing method to enhance model robustness in sparse scenarios with few labeled samples. Differing from homogeneous graph, DA in heterogeneous graph has greater challenges: heterogeneity of information requires DA strategies to effectively handle heterogeneous relations, which considers the information contribution of different types of neighbors and edges to the target nodes. Furthermore, over-squashing of information is caused by the negative curvature that formed by the non-uniformity distribution and strong clustering in complex graph. To address these challenges, this paper presents a novel method named Semi-Supervised Heterogeneous Graph Learning with Multi-level Data Augmentation (HG-MDA). For the problem of heterogeneity of information in DA, node and topology augmentation strategies are proposed for the characteristics of heterogeneous graph. And meta-relation-based attention is applied as one of the indexes for selecting augmented nodes and edges. For the problem of over-squashing of information, triangle based edge adding and removing are designed to alleviate the negative curvature and bring the gain of topology. Finally, the loss function consists of the cross-entropy loss for labeled data and the consistency regularization for unlabeled data. In order to effectively fuse the prediction results of various DA strategies, the sharpening is used. Existing experiments on public datasets, i.e., ACM, DBLP, OGB, and industry dataset MB show that HG-MDA outperforms current SOTA models. Additionly, HG-MDA is applied to user identification in internet finance scenarios, helping the business to add 30% key users, and increase loans and balances by 3.6%, 11.1%, and 9.8%. ",
    "url": "https://arxiv.org/abs/2212.00024",
    "authors": [
      "Ying Chen",
      "Siwei Qiang",
      "Mingming Ha",
      "Xiaolei Liu",
      "Shaoshuai Li",
      "Lingfeng Yuan",
      "Xiaobo Guo",
      "Zhenfeng Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00060",
    "title": "Capacity of generalized diamond networks",
    "abstract": "We consider the problem of error correction in a network where the errors can occur only on a proper subset of the network edges. For a generalization of the so-called Diamond Network we consider lower and upper bounds for the network's ($1$-shot) capacity. ",
    "url": "https://arxiv.org/abs/2212.00060",
    "authors": [
      "Sascha Kurz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.00122",
    "title": "Self-Supervised Feature Learning for Long-Term Metric Visual  Localization",
    "abstract": "Visual localization is the task of estimating camera pose in a known scene, which is an essential problem in robotics and computer vision. However, long-term visual localization is still a challenge due to the environmental appearance changes caused by lighting and seasons. While techniques exist to address appearance changes using neural networks, these methods typically require ground-truth pose information to generate accurate image correspondences or act as a supervisory signal during training. In this paper, we present a novel self-supervised feature learning framework for metric visual localization. We use a sequence-based image matching algorithm across different sequences of images (i.e., experiences) to generate image correspondences without ground-truth labels. We can then sample image pairs to train a deep neural network that learns sparse features with associated descriptors and scores without ground-truth pose supervision. The learned features can be used together with a classical pose estimator for visual stereo localization. We validate the learned features by integrating with an existing Visual Teach & Repeat pipeline to perform closed-loop localization experiments under different lighting conditions for a total of 22.4 km. ",
    "url": "https://arxiv.org/abs/2212.00122",
    "authors": [
      "Yuxuan Chen",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00131",
    "title": "Evidential Conditional Neural Processes",
    "abstract": "The Conditional Neural Process (CNP) family of models offer a promising direction to tackle few-shot problems by achieving better scalability and competitive predictive performance. However, the current CNP models only capture the overall uncertainty for the prediction made on a target data point. They lack a systematic fine-grained quantification on the distinct sources of uncertainty that are essential for model training and decision-making under the few-shot setting. We propose Evidential Conditional Neural Processes (ECNP), which replace the standard Gaussian distribution used by CNP with a much richer hierarchical Bayesian structure through evidential learning to achieve epistemic-aleatoric uncertainty decomposition. The evidential hierarchical structure also leads to a theoretically justified robustness over noisy training tasks. Theoretical analysis on the proposed ECNP establishes the relationship with CNP while offering deeper insights on the roles of the evidential parameters. Extensive experiments conducted on both synthetic and real-world data demonstrate the effectiveness of our proposed model in various few-shot settings. ",
    "url": "https://arxiv.org/abs/2212.00131",
    "authors": [
      "Deep Shankar Pandey",
      "Qi Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00133",
    "title": "Generative Adversarial Learning of Sinkhorn Algorithm Initializations",
    "abstract": "The Sinkhorn algorithm (arXiv:1306.0895) is the state-of-the-art to compute approximations of optimal transport distances between discrete probability distributions, making use of an entropically regularized formulation of the problem. The algorithm is guaranteed to converge, no matter its initialization. This lead to little attention being paid to initializing it, and simple starting vectors like the n-dimensional one-vector are common choices. We train a neural network to compute initializations for the algorithm, which significantly outperform standard initializations. The network predicts a potential of the optimal transport dual problem, where training is conducted in an adversarial fashion using a second, generating network. The network is universal in the sense that it is able to generalize to any pair of distributions of fixed dimension. Furthermore, we show that for certain applications the network can be used independently. ",
    "url": "https://arxiv.org/abs/2212.00133",
    "authors": [
      "Jonathan Geuter",
      "Vaios Laschos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.00149",
    "title": "Deep Learning-Based Vehicle Speed Prediction for Ecological Adaptive  Cruise Control in Urban and Highway Scenarios",
    "abstract": "In a typical car-following scenario, target vehicle speed fluctuations act as an external disturbance to the host vehicle and in turn affect its energy consumption. To control a host vehicle in an energy-efficient manner using model predictive control (MPC), and moreover, enhance the performance of an ecological adaptive cruise control (EACC) strategy, forecasting the future velocities of a target vehicle is essential. For this purpose, a deep recurrent neural network-based vehicle speed prediction using long-short term memory (LSTM) and gated recurrent units (GRU) is studied in this work. Besides these, the physics-based constant velocity (CV) and constant acceleration (CA) models are discussed. The sequential time series data for training (e.g. speed trajectories of the target and its preceding vehicles obtained through vehicle-to-vehicle (V2V) communication, road speed limits, traffic light current and future phases collected using vehicle-to-infrastructure (V2I) communication) is gathered from both urban and highway networks created in the microscopic traffic simulator SUMO. The proposed speed prediction models are evaluated for long-term predictions (up to 10 s) of target vehicle future velocities. Moreover, the results revealed that the LSTM-based speed predictor outperformed other models in terms of achieving better prediction accuracy on unseen test datasets, and thereby showcasing better generalization ability. Furthermore, the performance of EACC-equipped host car on the predicted velocities is evaluated, and its energy-saving benefits for different prediction horizons are presented. ",
    "url": "https://arxiv.org/abs/2212.00149",
    "authors": [
      "Sai Krishna Chada",
      "Daniel G\u00f6rges",
      "Achim Ebert",
      "Roman Teutsch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00173",
    "title": "SPADE: Semi-supervised Anomaly Detection under Distribution Mismatch",
    "abstract": "Semi-supervised anomaly detection is a common problem, as often the datasets containing anomalies are partially labeled. We propose a canonical framework: Semi-supervised Pseudo-labeler Anomaly Detection with Ensembling (SPADE) that isn't limited by the assumption that labeled and unlabeled data come from the same distribution. Indeed, the assumption is often violated in many applications - for example, the labeled data may contain only anomalies unlike unlabeled data, or unlabeled data may contain different types of anomalies, or labeled data may contain only 'easy-to-label' samples. SPADE utilizes an ensemble of one class classifiers as the pseudo-labeler to improve the robustness of pseudo-labeling with distribution mismatch. Partial matching is proposed to automatically select the critical hyper-parameters for pseudo-labeling without validation data, which is crucial with limited labeled data. SPADE shows state-of-the-art semi-supervised anomaly detection performance across a wide range of scenarios with distribution mismatch in both tabular and image domains. In some common real-world settings such as model facing new types of unlabeled anomalies, SPADE outperforms the state-of-the-art alternatives by 5% AUC in average. ",
    "url": "https://arxiv.org/abs/2212.00173",
    "authors": [
      "Jinsung Yoon",
      "Kihyuk Sohn",
      "Chun-Liang Li",
      "Sercan O. Arik",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00190",
    "title": "Mixed Neural Voxels for Fast Multi-view Video Synthesis",
    "abstract": "Synthesizing high-fidelity videos from real-world multi-view input is challenging because of the complexities of real-world environments and highly dynamic motions. Previous works based on neural radiance fields have demonstrated high-quality reconstructions of dynamic scenes. However, training such models on real-world scenes is time-consuming, usually taking days or weeks. In this paper, we present a novel method named MixVoxels to better represent the dynamic scenes with fast training speed and competitive rendering qualities. The proposed MixVoxels represents the 4D dynamic scenes as a mixture of static and dynamic voxels and processes them with different networks. In this way, the computation of the required modalities for static voxels can be processed by a lightweight model, which essentially reduces the amount of computation, especially for many daily dynamic scenes dominated by the static background. To separate the two kinds of voxels, we propose a novel variation field to estimate the temporal variance of each voxel. For the dynamic voxels, we design an inner-product time query method to efficiently query multiple time steps, which is essential to recover the high-dynamic motions. As a result, with 15 minutes of training for dynamic scenes with inputs of 300-frame videos, MixVoxels achieves better PSNR than previous methods. Codes and trained models are available at https://github.com/fengres/mixvoxels ",
    "url": "https://arxiv.org/abs/2212.00190",
    "authors": [
      "Feng Wang",
      "Sinan Tan",
      "Xinghang Li",
      "Zeyue Tian",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00214",
    "title": "Test-Time Mixup Augmentation for Data and Class-Specific Uncertainty  Estimation in Multi-Class Image Classification",
    "abstract": "Uncertainty estimation of the trained deep learning network provides important information for improving the learning efficiency or evaluating the reliability of the network prediction. In this paper, we propose a method for the uncertainty estimation for multi-class image classification using test-time mixup augmentation (TTMA). To improve the discrimination ability between the correct and incorrect prediction of the existing aleatoric uncertainty, we propose the data uncertainty by applying the mixup augmentation on the test data and measuring the entropy of the histogram of predicted labels. In addition to the data uncertainty, we propose a class-specific uncertainty presenting the aleatoric uncertainty associated with the specific class, which can provide information on the class confusion and class similarity of the trained network. The proposed methods are validated on two public datasets, the ISIC-18 skin lesion diagnosis dataset, and the CIFAR-100 real-world image classification dataset. The experiments demonstrate that (1) the proposed data uncertainty better separates the correct and incorrect prediction than the existing uncertainty measures thanks to the mixup perturbation, and (2) the proposed class-specific uncertainty provides information on the class confusion and class similarity of the trained network for both datasets. ",
    "url": "https://arxiv.org/abs/2212.00214",
    "authors": [
      "Hansang Lee",
      "Haeil Lee",
      "Helen Hong",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00222",
    "title": "Experimental Observations of the Topology of Convolutional Neural  Network Activations",
    "abstract": "Topological data analysis (TDA) is a branch of computational mathematics, bridging algebraic topology and data science, that provides compact, noise-robust representations of complex structures. Deep neural networks (DNNs) learn millions of parameters associated with a series of transformations defined by the model architecture, resulting in high-dimensional, difficult-to-interpret internal representations of input data. As DNNs become more ubiquitous across multiple sectors of our society, there is increasing recognition that mathematical methods are needed to aid analysts, researchers, and practitioners in understanding and interpreting how these models' internal representations relate to the final classification. In this paper, we apply cutting edge techniques from TDA with the goal of gaining insight into the interpretability of convolutional neural networks used for image classification. We use two common TDA approaches to explore several methods for modeling hidden-layer activations as high-dimensional point clouds, and provide experimental evidence that these point clouds capture valuable structural information about the model's process. First, we demonstrate that a distance metric based on persistent homology can be used to quantify meaningful differences between layers, and we discuss these distances in the broader context of existing representational similarity metrics for neural network interpretability. Second, we show that a mapper graph can provide semantic insight into how these models organize hierarchical class knowledge at each layer. These observations demonstrate that TDA is a useful tool to help deep learning practitioners unlock the hidden structures of their models. ",
    "url": "https://arxiv.org/abs/2212.00222",
    "authors": [
      "Emilie Purvine",
      "Davis Brown",
      "Brett Jefferson",
      "Cliff Joslyn",
      "Brenda Praggastis",
      "Archit Rathore",
      "Madelyn Shapiro",
      "Bei Wang",
      "Youjia Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2212.00228",
    "title": "Gated Recurrent Neural Networks with Weighted Time-Delay Feedback",
    "abstract": "We introduce a novel gated recurrent unit (GRU) with a weighted time-delay feedback mechanism in order to improve the modeling of long-term dependencies in sequential data. This model is a discretized version of a continuous-time formulation of a recurrent unit, where the dynamics are governed by delay differential equations (DDEs). By considering a suitable time-discretization scheme, we propose $\\tau$-GRU, a discrete-time gated recurrent unit with delay. We prove the existence and uniqueness of solutions for the continuous-time model, and we demonstrate that the proposed feedback mechanism can help improve the modeling of long-term dependencies. Our empirical results show that $\\tau$-GRU can converge faster and generalize better than state-of-the-art recurrent units and gated recurrent architectures on a range of tasks, including time-series classification, human activity recognition, and speech recognition. ",
    "url": "https://arxiv.org/abs/2212.00228",
    "authors": [
      "N. Benjamin Erichson",
      "Soon Hoe Lim",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.00229",
    "title": "NIR-Prompt: A Multi-task Generalized Neural Information Retrieval  Training Framework",
    "abstract": "Information retrieval aims to find information that meets users' needs from the corpus. Different needs correspond to different IR tasks such as document retrieval, open-domain question answering, retrieval-based dialogue, etc., while they share the same schema to estimate the relationship between texts. It indicates that a good IR model can generalize to different tasks and domains. However, previous studies indicate that state-of-the-art neural information retrieval (NIR) models, e.g, pre-trained language models (PLMs) are hard to generalize. Mainly because the end-to-end fine-tuning paradigm makes the model overemphasize task-specific signals and domain biases but loses the ability to capture generalized essential signals. To address this problem, we propose a novel NIR training framework named NIR-Prompt for retrieval and reranking stages based on the idea of decoupling signal capturing and combination. NIR-Prompt exploits Essential Matching Module (EMM) to capture the essential matching signals and gets the description of tasks by Matching Description Module (MDM). The description is used as task-adaptation information to combine the essential matching signals to adapt to different tasks. Experiments under in-domain multi-task, out-of-domain multi-task, and new task adaptation settings show that NIR-Prompt can improve the generalization of PLMs in NIR for both retrieval and reranking stages compared with baselines. ",
    "url": "https://arxiv.org/abs/2212.00229",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.00231",
    "title": "Modeling Complex Dialogue Mappings via Sentence Semantic Segmentation  Guided Conditional Variational Auto-Encoder",
    "abstract": "Complex dialogue mappings (CDM), including one-to-many and many-to-one mappings, tend to make dialogue models generate incoherent or dull responses, and modeling these mappings remains a huge challenge for neural dialogue systems. To alleviate these problems, methods like introducing external information, reconstructing the optimization function, and manipulating data samples are proposed, while they primarily focus on avoiding training with CDM, inevitably weakening the model's ability of understanding CDM in human conversations and limiting further improvements in model performance. This paper proposes a Sentence Semantic \\textbf{Seg}mentation guided \\textbf{C}onditional \\textbf{V}ariational \\textbf{A}uto-\\textbf{E}ncoder (SegCVAE) method which can model and take advantages of the CDM data. Specifically, to tackle the incoherent problem caused by one-to-many, SegCVAE uses response-related prominent semantics to constrained the latent variable. To mitigate the non-diverse problem brought by many-to-one, SegCVAE segments multiple prominent semantics to enrich the latent variables. Three novel components, Internal Separation, External Guidance, and Semantic Norms, are proposed to achieve SegCVAE. On dialogue generation tasks, both the automatic and human evaluation results show that SegCVAE achieves new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2212.00231",
    "authors": [
      "Bin Sun",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Weichao Wang",
      "Fei Mi",
      "Yitong Li",
      "Kan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00239",
    "title": "Noisy Label Detection for Speaker Recognition",
    "abstract": "The success of deep neural networks requires both high annotation quality and massive data. However, the size and the quality of a dataset are usually a trade-off in practice, as data collection and cleaning are expensive and time-consuming. Therefore, automatic noisy label detection (NLD) techniques are critical to real-world applications, especially those using crowdsourcing datasets. As this is an under-explored topic in automatic speaker verification (ASV), we present a simple but effective solution to the task. First, we compare the effectiveness of various commonly used metric learning loss functions under different noise settings. Then, we propose two ranking-based NLD methods, inter-class inconsistency and intra-class inconsistency ranking. They leverage the inconsistent nature of noisy labels and show high detection precision even under a high level of noise. Our solution gives rise to both efficient and effective cleaning of large-scale speaker recognition datasets. ",
    "url": "https://arxiv.org/abs/2212.00239",
    "authors": [
      "Ruibin Yuan",
      "Hanzhi Yin",
      "Yi Wang",
      "Yifan He",
      "Yushi Ye",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.00244",
    "title": "CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection",
    "abstract": "Domain adaptation for Cross-LiDAR 3D detection is challenging due to the large gap on the raw data representation with disparate point densities and point arrangements. By exploring domain-invariant 3D geometric characteristics and motion patterns, we present an unsupervised domain adaptation method that overcomes above difficulties. First, we propose the Spatial Geometry Alignment module to extract similar 3D shape geometric features of the same object class to align two domains, while eliminating the effect of distinct point distributions. Second, we present Temporal Motion Alignment module to utilize motion features in sequential frames of data to match two domains. Prototypes generated from two modules are incorporated into the pseudo-label reweighting procedure and contribute to our effective self-training framework for the target domain. Extensive experiments show that our method achieves state-of-the-art performance on cross-device datasets, especially for the datasets with large gaps captured by mechanical scanning LiDARs and solid-state LiDARs in various scenes. Project homepage is at https://github.com/4DVLab/CL3D.git ",
    "url": "https://arxiv.org/abs/2212.00244",
    "authors": [
      "Xidong Peng",
      "Xinge Zhu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00250",
    "title": "Split Learning without Local Weight Sharing to Enhance Client-side Data  Privacy",
    "abstract": "Split learning (SL) aims to protect user data privacy by splitting deep models between client-server and keeping private data locally. SL has been demonstrated to achieve similar accuracy as the centralized learning model. In SL with multiple clients, the local training weights are shared between clients for local model aggregation. This paper investigates the potential of data leakage due to local weight sharing among the clients in SL by performing model inversion attacks. To mitigate the identified leakage issue, we propose and analyze privacy-enhancement SL (P-SL), e.g., SL without local weight sharing, to boost client-side data privacy. We also propose paralleled P-SL to speed up the training process by employing multiple servers without accuracy reduction. Finally, we investigate P-SL with late participating clients and develop a server-based cache-based training to address the forgetting phenomenon in SL. Experimental results demonstrate that P-SL helps reduce up to 50% of client-side data leakage compared to SL. Moreover, P-SL and its cache-based version achieve comparable accuracy to SL under various data distributions with lower computation and communications costs. Also, caching in P-SL reduces the negative effect of forgetting, stabilizes the learning, and enables effective and low-complexity training in a dynamic environment with late-arriving clients. ",
    "url": "https://arxiv.org/abs/2212.00250",
    "authors": [
      "Ngoc Duy Pham",
      "Tran Khoa Phan",
      "Alsharif Abuadbba",
      "Doan Nguyen",
      "Naveen Chilamkurti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.00259",
    "title": "Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual  Reasoning",
    "abstract": "Visual Question Answering (VQA) models often perform poorly on out-of-distribution data and struggle on domain generalization. Due to the multi-modal nature of this task, multiple factors of variation are intertwined, making generalization difficult to analyze. This motivates us to introduce a virtual benchmark, Super-CLEVR, where different factors in VQA domain shifts can be isolated in order that their effects can be studied independently. Four factors are considered: visual complexity, question redundancy, concept distribution and concept compositionality. With controllably generated data, Super-CLEVR enables us to test VQA methods in situations where the test data differs from the training data along each of these axes. We study four existing methods, including two neural symbolic methods NSCL and NSVQA, and two non-symbolic methods FiLM and mDETR; and our proposed method, probabilistic NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA outperforms other methods on three of the four domain shift factors. Our results suggest that disentangling reasoning and perception, combined with probabilistic uncertainty, form a strong VQA model that is more robust to domain shifts. The dataset and code are released at https://github.com/Lizw14/Super-CLEVR. ",
    "url": "https://arxiv.org/abs/2212.00259",
    "authors": [
      "Zhuowan Li",
      "Xingrui Wang",
      "Elias Stengel-Eskin",
      "Adam Kortylewski",
      "Wufei Ma",
      "Benjamin Van Durme",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00261",
    "title": "Task Discovery: Finding the Tasks that Neural Networks Generalize on",
    "abstract": "When developing deep learning models, we usually decide what task we want to solve then search for a model that generalizes well on the task. An intriguing question would be: what if, instead of fixing the task and searching in the model space, we fix the model and search in the task space? Can we find tasks that the model generalizes on? How do they look, or do they indicate anything? These are the questions we address in this paper. We propose a task discovery framework that automatically finds examples of such tasks via optimizing a generalization-based quantity called agreement score. We demonstrate that one set of images can give rise to many tasks on which neural networks generalize well. These tasks are a reflection of the inductive biases of the learning framework and the statistical patterns present in the data, thus they can make a useful tool for analysing the neural networks and their biases. As an example, we show that the discovered tasks can be used to automatically create adversarial train-test splits which make a model fail at test time, without changing the pixels or labels, but by only selecting how the datapoints should be split between the train and test sets. We end with a discussion on human-interpretability of the discovered tasks. ",
    "url": "https://arxiv.org/abs/2212.00261",
    "authors": [
      "Andrei Atanov",
      "Andrei Filatov",
      "Teresa Yeo",
      "Ajay Sohmshetty",
      "Amir Zamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00262",
    "title": "Low-Rank Tensor Function Representation for Multi-Dimensional Data  Recovery",
    "abstract": "Since higher-order tensors are naturally suitable for representing multi-dimensional data in real-world, e.g., color images and videos, low-rank tensor representation has become one of the emerging areas in machine learning and computer vision. However, classical low-rank tensor representations can only represent data on finite meshgrid due to their intrinsical discrete nature, which hinders their potential applicability in many scenarios beyond meshgrid. To break this barrier, we propose a low-rank tensor function representation (LRTFR), which can continuously represent data beyond meshgrid with infinite resolution. Specifically, the suggested tensor function, which maps an arbitrary coordinate to the corresponding value, can continuously represent data in an infinite real space. Parallel to discrete tensors, we develop two fundamental concepts for tensor functions, i.e., the tensor function rank and low-rank tensor function factorization. We theoretically justify that both low-rank and smooth regularizations are harmoniously unified in the LRTFR, which leads to high effectiveness and efficiency for data continuous representation. Extensive multi-dimensional data recovery applications arising from image processing (image inpainting and denoising), machine learning (hyperparameter optimization), and computer graphics (point cloud upsampling) substantiate the superiority and versatility of our method as compared with state-of-the-art methods. Especially, the experiments beyond the original meshgrid resolution (hyperparameter optimization) or even beyond meshgrid (point cloud upsampling) validate the favorable performances of our method for continuous representation. ",
    "url": "https://arxiv.org/abs/2212.00262",
    "authors": [
      "Yisi Luo",
      "Xile Zhao",
      "Zhemin Li",
      "Michael K. Ng",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00265",
    "title": "PIZZA: A new benchmark for complex end-to-end task-oriented parsing",
    "abstract": "Much recent work in task-oriented parsing has focused on finding a middle ground between flat slots and intents, which are inexpressive but easy to annotate, and powerful representations such as the lambda calculus, which are expressive but costly to annotate. This paper continues the exploration of task-oriented parsing by introducing a new dataset for parsing pizza and drink orders, whose semantics cannot be captured by flat slots and intents. We perform an extensive evaluation of deep-learning techniques for task-oriented parsing on this dataset, including different flavors of seq2seq systems and RNNGs. The dataset comes in two main versions, one in a recently introduced utterance-level hierarchical notation that we call TOP, and one whose targets are executable representations (EXR). We demonstrate empirically that training the parser to directly generate EXR notation not only solves the problem of entity resolution in one fell swoop and overcomes a number of expressive limitations of TOP notation, but also results in significantly greater parsing accuracy. ",
    "url": "https://arxiv.org/abs/2212.00265",
    "authors": [
      "Konstantine Arkoudas",
      "Nicolas Guenon des Mesnards",
      "Melanie Rubino",
      "Sandesh Swamy",
      "Saarthak Khanna",
      "Weiqi Sun",
      "Khan Haidar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00266",
    "title": "Multi-view Tracking, Re-ID, and Social Network Analysis of a Flock of  Visually Similar Birds in an Outdoor Aviary",
    "abstract": "The ability to capture detailed interactions among individuals in a social group is foundational to our study of animal behavior and neuroscience. Recent advances in deep learning and computer vision are driving rapid progress in methods that can record the actions and interactions of multiple individuals simultaneously. Many social species, such as birds, however, live deeply embedded in a three-dimensional world. This world introduces additional perceptual challenges such as occlusions, orientation-dependent appearance, large variation in apparent size, and poor sensor coverage for 3D reconstruction, that are not encountered by applications studying animals that move and interact only on 2D planes. Here we introduce a system for studying the behavioral dynamics of a group of songbirds as they move throughout a 3D aviary. We study the complexities that arise when tracking a group of closely interacting animals in three dimensions and introduce a novel dataset for evaluating multi-view trackers. Finally, we analyze captured ethogram data and demonstrate that social context affects the distribution of sequential interactions between birds in the aviary. ",
    "url": "https://arxiv.org/abs/2212.00266",
    "authors": [
      "Shiting Xiao",
      "Yufu Wang",
      "Ammon Perkes",
      "Bernd Pfrommer",
      "Marc Schmidt",
      "Kostas Daniilidis",
      "Marc Badger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00272",
    "title": "ResNet Structure Simplification with the Convolutional Kernel Redundancy  Measure",
    "abstract": "Deep learning, especially convolutional neural networks, has triggered accelerated advancements in computer vision, bringing changes into our daily practice. Furthermore, the standardized deep learning modules (also known as backbone networks), i.e., ResNet and EfficientNet, have enabled efficient and rapid development of new computer vision solutions. Yet, deep learning methods still suffer from several drawbacks. One of the most concerning problems is the high memory and computational cost, such that dedicated computing units, typically GPUs, have to be used for training and development. Therefore, in this paper, we propose a quantifiable evaluation method, the convolutional kernel redundancy measure, which is based on perceived image differences, for guiding the network structure simplification. When applying our method to the chest X-ray image classification problem with ResNet, our method can maintain the performance of the network and reduce the number of parameters from over $23$ million to approximately $128$ thousand (reducing $99.46\\%$ of the parameters). ",
    "url": "https://arxiv.org/abs/2212.00272",
    "authors": [
      "Hongzhi Zhu",
      "Robert Rohling",
      "Septimiu Salcudean"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00278",
    "title": "Adaptive Conformal Prediction for Motion Planning among Dynamic Agents",
    "abstract": "This paper proposes an algorithm for motion planning among dynamic agents using adaptive conformal prediction. We consider a deterministic control system and use trajectory predictors to predict the dynamic agents' future motion, which is assumed to follow an unknown distribution. We then leverage ideas from adaptive conformal prediction to dynamically quantify prediction uncertainty from an online data stream. Particularly, we provide an online algorithm uses delayed agent observations to obtain uncertainty sets for multistep-ahead predictions with probabilistic coverage. These uncertainty sets are used within a model predictive controller to safely navigate among dynamic agents. While most existing data-driven prediction approached quantify prediction uncertainty heuristically, we quantify the true prediction uncertainty in a distribution-free, adaptive manner that even allows to capture changes in prediction quality and the agents' motion. We empirically evaluate of our algorithm on a simulation case studies where a drone avoids a flying frisbee. ",
    "url": "https://arxiv.org/abs/2212.00278",
    "authors": [
      "Anushri Dixit",
      "Lars Lindemann",
      "Skylar Wei",
      "Matthew Cleaveland",
      "George J. Pappas",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00281",
    "title": "Localization vs. Semantics: How Can Language Benefit Visual  Representation Learning?",
    "abstract": "Despite the superior performance brought by vision-and-language pretraining, it remains unclear whether learning with multi-modal data can help understand each individual modality. In this work, we investigate how language can help with visual representation learning from a probing perspective. Specifically, we compare vision-and-language and vision-only models by probing their visual representations on a broad range of tasks, in order to assess the quality of the learned representations in a fine-grained manner. Interestingly, our probing results suggest that vision-and-language models are better at label prediction tasks like object and attribute prediction, while vision-only models are stronger at dense prediction tasks that require more localized information. With further analysis using detailed metrics, our study suggests that language helps vision models learn better semantics, but not localization. Code is released at https://github.com/Lizw14/visual_probing. ",
    "url": "https://arxiv.org/abs/2212.00281",
    "authors": [
      "Zhuowan Li",
      "Cihang Xie",
      "Benjamin Van Durme",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00290",
    "title": "Component Segmentation of Engineering Drawings Using Graph Convolutional  Networks",
    "abstract": "We present a data-driven framework to automate the vectorization and machine interpretation of 2D engineering part drawings. In industrial settings, most manufacturing engineers still rely on manual reads to identify the topological and manufacturing requirements from drawings submitted by designers. The interpretation process is laborious and time-consuming, which severely inhibits the efficiency of part quotation and manufacturing tasks. While recent advances in image-based computer vision methods have demonstrated great potential in interpreting natural images through semantic segmentation approaches, the application of such methods in parsing engineering technical drawings into semantically accurate components remains a significant challenge. The severe pixel sparsity in engineering drawings also restricts the effective featurization of image-based data-driven methods. To overcome these challenges, we propose a deep learning based framework that predicts the semantic type of each vectorized component. Taking a raster image as input, we vectorize all components through thinning, stroke tracing, and cubic bezier fitting. Then a graph of such components is generated based on the connectivity between the components. Finally, a graph convolutional neural network is trained on this graph data to identify the semantic type of each component. We test our framework in the context of semantic segmentation of text, dimension and, contour components in engineering drawings. Results show that our method yields the best performance compared to recent image, and graph-based segmentation methods. ",
    "url": "https://arxiv.org/abs/2212.00290",
    "authors": [
      "Wentai Zhang",
      "Joe Joseph",
      "Yue Yin",
      "Liuyue Xie",
      "Tomotake Furuhata",
      "Soji Yamakawa",
      "Kenji Shimada",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00291",
    "title": "The Effect of Data Dimensionality on Neural Network Prunability",
    "abstract": "Practitioners prune neural networks for efficiency gains and generalization improvements, but few scrutinize the factors determining the prunability of a neural network the maximum fraction of weights that pruning can remove without compromising the model's test accuracy. In this work, we study the properties of input data that may contribute to the prunability of a neural network. For high dimensional input data such as images, text, and audio, the manifold hypothesis suggests that these high dimensional inputs approximately lie on or near a significantly lower dimensional manifold. Prior work demonstrates that the underlying low dimensional structure of the input data may affect the sample efficiency of learning. In this paper, we investigate whether the low dimensional structure of the input data affects the prunability of a neural network. ",
    "url": "https://arxiv.org/abs/2212.00291",
    "authors": [
      "Zachary Ankner",
      "Alex Renda",
      "Gintare Karolina Dziugaite",
      "Jonathan Frankle",
      "Tian Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00298",
    "title": "A Commonsense-Infused Language-Agnostic Learning Framework for Enhancing  Prediction of Political Polarity in Multilingual News Headlines",
    "abstract": "Predicting the political polarity of news headlines is a challenging task that becomes even more challenging in a multilingual setting with low-resource languages. To deal with this, we propose to utilise the Inferential Commonsense Knowledge via a Translate-Retrieve-Translate strategy to introduce a learning framework. To begin with, we use the method of translation and retrieval to acquire the inferential knowledge in the target language. We then employ an attention mechanism to emphasise important inferences. We finally integrate the attended inferences into a multilingual pre-trained language model for the task of bias prediction. To evaluate the effectiveness of our framework, we present a dataset of over 62.6K multilingual news headlines in five European languages annotated with their respective political polarities. We evaluate several state-of-the-art multilingual pre-trained language models since their performance tends to vary across languages (low/high resource). Evaluation results demonstrate that our proposed framework is effective regardless of the models employed. Overall, the best performing model trained with only headlines show 0.90 accuracy and F1, and 0.83 jaccard score. With attended knowledge in our framework, the same model show an increase in 2.2% accuracy and F1, and 3.6% jaccard score. Extending our experiments to individual languages reveals that the models we analyze for Slovenian perform significantly worse than other languages in our dataset. To investigate this, we assess the effect of translation quality on prediction performance. It indicates that the disparity in performance is most likely due to poor translation quality. We release our dataset and scripts at: https://github.com/Swati17293/KG-Multi-Bias for future research. Our framework has the potential to benefit journalists, social scientists, news producers, and consumers. ",
    "url": "https://arxiv.org/abs/2212.00298",
    "authors": [
      "Swati Swati",
      "Adrian Mladeni\u0107 Grobelnik",
      "Dunja Mladeni\u0107",
      "Marko Grobelnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00306",
    "title": "Decentralized Matrix Factorization with Heterogeneous Differential  Privacy",
    "abstract": "Conventional matrix factorization relies on centralized collection of users' data for recommendation, which might introduce an increased risk of privacy leakage especially when the recommender is untrusted. Existing differentially private matrix factorization methods either assume the recommender is trusted, or can only provide a uniform level of privacy protection for all users and items with untrusted recommender. In this paper, we propose a novel Heterogeneous Differentially Private Matrix Factorization algorithm (denoted as HDPMF) for untrusted recommender. To the best of our knowledge, we are the first to achieve heterogeneous differential privacy for decentralized matrix factorization in untrusted recommender scenario. Specifically, our framework uses modified stretching mechanism with an innovative rescaling scheme to achieve better trade off between privacy and accuracy. Meanwhile, by allocating privacy budget properly, we can capture homogeneous privacy preference within a user/item but heterogeneous privacy preference across different users/items. Theoretical analysis confirms that HDPMF renders rigorous privacy guarantee, and exhaustive experiments demonstrate its superiority especially in strong privacy guarantee, high dimension model and sparse dataset scenario. ",
    "url": "https://arxiv.org/abs/2212.00306",
    "authors": [
      "Wentao Hu",
      "Hui Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.00313",
    "title": "Concealed Object Detection for Passive Millimeter-Wave Security Imaging  Based on Task-Aligned Detection Transformer",
    "abstract": "Passive millimeter-wave (PMMW) is a significant potential technique for human security screening. Several popular object detection networks have been used for PMMW images. However, restricted by the low resolution and high noise of PMMW images, PMMW hidden object detection based on deep learning usually suffers from low accuracy and low classification confidence. To tackle the above problems, this paper proposes a Task-Aligned Detection Transformer network, named PMMW-DETR. In the first stage, a Denoising Coarse-to-Fine Transformer (DCFT) backbone is designed to extract long- and short-range features in the different scales. In the second stage, we propose the Query Selection module to introduce learned spatial features into the network as prior knowledge, which enhances the semantic perception capability of the network. In the third stage, aiming to improve the classification performance, we perform a Task-Aligned Dual-Head block to decouple the classification and regression tasks. Based on our self-developed PMMW security screening dataset, experimental results including comparison with State-Of-The-Art (SOTA) methods and ablation study demonstrate that the PMMW-DETR obtains higher accuracy and classification confidence than previous works, and exhibits robustness to the PMMW images of low quality. ",
    "url": "https://arxiv.org/abs/2212.00313",
    "authors": [
      "Cheng Guo",
      "Fei Hu",
      "Yan Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00322",
    "title": "Hijack Vertical Federated Learning Models with Adversarial Embedding",
    "abstract": "Vertical federated learning (VFL) is an emerging paradigm that enables collaborators to build machine learning models together in a distributed fashion. In general, these parties have a group of users in common but own different features. Existing VFL frameworks use cryptographic techniques to provide data privacy and security guarantees, leading to a line of works studying computing efficiency and fast implementation. However, the security of VFL's model remains underexplored. ",
    "url": "https://arxiv.org/abs/2212.00322",
    "authors": [
      "Pengyu Qiu",
      "Xuhong Zhang",
      "Shouling Ji",
      "Changjiang Li",
      "Yuwen Pu",
      "Xing Yang",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.00325",
    "title": "All You Need Is Hashing: Defending Against Data Reconstruction Attack in  Vertical Federated Learning",
    "abstract": "Vertical federated learning is a trending solution for multi-party collaboration in training machine learning models. Industrial frameworks adopt secure multi-party computation methods such as homomorphic encryption to guarantee data security and privacy. However, a line of work has revealed that there are still leakage risks in VFL. The leakage is caused by the correlation between the intermediate representations and the raw data. Due to the powerful approximation ability of deep neural networks, an adversary can capture the correlation precisely and reconstruct the data. To deal with the threat of the data reconstruction attack, we propose a hashing-based VFL framework, called \\textit{HashVFL}, to cut off the reversibility directly. The one-way nature of hashing allows our framework to block all attempts to recover data from hash codes. However, integrating hashing also brings some challenges, e.g., the loss of information. This paper proposes and addresses three challenges to integrating hashing: learnability, bit balance, and consistency. Experimental results demonstrate \\textit{HashVFL}'s efficiency in keeping the main task's performance and defending against data reconstruction attacks. Furthermore, we also analyze its potential value in detecting abnormal inputs. In addition, we conduct extensive experiments to prove \\textit{HashVFL}'s generalization in various settings. In summary, \\textit{HashVFL} provides a new perspective on protecting multi-party's data security and privacy in VFL. We hope our study can attract more researchers to expand the application domains of \\textit{HashVFL}. ",
    "url": "https://arxiv.org/abs/2212.00325",
    "authors": [
      "Pengyu Qiu",
      "Xuhong Zhang",
      "Shouling Ji",
      "Yuwen Pu",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00344",
    "title": "Bayesian Heuristics for Robust Spatial Perception",
    "abstract": "Spatial perception is a key task in several robotics applications. In general, it involves the nonlinear estimation of hidden variables that represent the state of the robot/environment. However, in the presence of outliers the standard nonlinear least squared formulation results in poor estimates. Several methods have been considered in the literature to improve the reliability of the estimation process. Most methods are based on heuristics since guaranteed global robust estimation is not generally practical due to high computational costs. Recently general purpose robust estimation heuristics have been proposed that leverage existing non-minimal solvers available for the outlier-free formulations without the need for an initial guess. In this work, we propose two similar heuristics backed by Bayesian theory. We evaluate these heuristics in practical scenarios to demonstrate their merits in different applications including 3D point cloud registration, mesh registration and pose graph optimization. ",
    "url": "https://arxiv.org/abs/2212.00344",
    "authors": [
      "Aamir Hussain Chughtai",
      "Muhammad Tahir",
      "Momin Uppal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.00345",
    "title": "Semiconductor Defect Pattern Classification by  Self-Proliferation-and-Attention Neural Network",
    "abstract": "Semiconductor manufacturing is on the cusp of a revolution: the Internet of Things (IoT). With IoT we can connect all the equipment and feed information back to the factory so that quality issues can be detected. In this situation, more and more edge devices are used in wafer inspection equipment. This edge device must have the ability to quickly detect defects. Therefore, how to develop a high-efficiency architecture for automatic defect classification to be suitable for edge devices is the primary task. In this paper, we present a novel architecture that can perform defect classification in a more efficient way. The first function is self-proliferation, using a series of linear transformations to generate more feature maps at a cheaper cost. The second function is self-attention, capturing the long-range dependencies of feature map by the channel-wise and spatial-wise attention mechanism. We named this method as self-proliferation-and-attention neural network. This method has been successfully applied to various defect pattern classification tasks. Compared with other latest methods, SP&A-Net has higher accuracy and lower computation cost in many defect inspection tasks. ",
    "url": "https://arxiv.org/abs/2212.00345",
    "authors": [
      "YuanFu Yang",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00352",
    "title": "A Dataset with Multibeam Forward-Looking Sonar for Underwater Object  Detection",
    "abstract": "Multibeam forward-looking sonar (MFLS) plays an important role in underwater detection. There are several challenges to the research on underwater object detection with MFLS. Firstly, the research is lack of available dataset. Secondly, the sonar image, generally processed at pixel level and transformed to sector representation for the visual habits of human beings, is disadvantageous to the research in artificial intelligence (AI) areas. Towards these challenges, we present a novel dataset, the underwater acoustic target detection (UATD) dataset, consisting of over 9000 MFLS images captured using Tritech Gemini 1200ik sonar. Our dataset provides raw data of sonar images with annotation of 10 categories of target objects (cube, cylinder, tyres, etc). The data was collected from lake and shallow water. To verify the practicality of UATD, we apply the dataset to the state-of-the-art detectors and provide corresponding benchmarks for its accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2212.00352",
    "authors": [
      "Kaibing Xie",
      "Jian Yang",
      "Kang Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00369",
    "title": "Deep neural network techniques for monaural speech enhancement: state of  the art analysis",
    "abstract": "Deep neural networks (DNN) techniques have become pervasive in domains such as natural language processing and computer vision. They have achieved great success in these domains in task such as machine translation and image generation. Due to their success, these data driven techniques have been applied in audio domain. More specifically, DNN models have been applied in speech enhancement domain to achieve denosing, dereverberation and multi-speaker separation in monaural speech enhancement. In this paper, we review some dominant DNN techniques being employed to achieve speech separation. The review looks at the whole pipeline of speech enhancement from feature extraction, how DNN based tools are modelling both global and local features of speech and model training (supervised and unsupervised). We also review the use of speech-enhancement pre-trained models to boost speech enhancement process. The review is geared towards covering the dominant trends with regards to DNN application in speech enhancement in speech obtained via a single speaker. ",
    "url": "https://arxiv.org/abs/2212.00369",
    "authors": [
      "Peter Ochieng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.00377",
    "title": "Domain Adaptive Scene Text Detection via Subcategorization",
    "abstract": "Most existing scene text detectors require large-scale training data which cannot scale well due to two major factors: 1) scene text images often have domain-specific distributions; 2) collecting large-scale annotated scene text images is laborious. We study domain adaptive scene text detection, a largely neglected yet very meaningful task that aims for optimal transfer of labelled scene text images while handling unlabelled images in various new domains. Specifically, we design SCAST, a subcategory-aware self-training technique that mitigates the network overfitting and noisy pseudo labels in domain adaptive scene text detection effectively. SCAST consists of two novel designs. For labelled source data, it introduces pseudo subcategories for both foreground texts and background stuff which helps train more generalizable source models with multi-class detection objectives. For unlabelled target data, it mitigates the network overfitting by co-regularizing the binary and subcategory classifiers trained in the source domain. Extensive experiments show that SCAST achieves superior detection performance consistently across multiple public benchmarks, and it also generalizes well to other domain adaptive detection tasks such as vehicle detection. ",
    "url": "https://arxiv.org/abs/2212.00377",
    "authors": [
      "Zichen Tian",
      "Chuhui Xue",
      "Jingyi Zhang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00414",
    "title": "A Comprehensive Study on Machine Learning Methods to Increase the  Prediction Accuracy of Classifiers and Reduce the Number of Medical Tests  Required to Diagnose Alzheimer'S Disease",
    "abstract": "Alzheimer's patients gradually lose their ability to think, behave, and interact with others. Medical history, laboratory tests, daily activities, and personality changes can all be used to diagnose the disorder. A series of time-consuming and expensive tests are used to diagnose the illness. The most effective way to identify Alzheimer's disease is using a Random-forest classifier in this study, along with various other Machine Learning techniques. The main goal of this study is to fine-tune the classifier to detect illness with fewer tests while maintaining a reasonable disease discovery accuracy. We successfully identified the condition in almost 94% of cases using four of the thirty frequently utilized indicators. ",
    "url": "https://arxiv.org/abs/2212.00414",
    "authors": [
      "Md. Sharifur Rahman",
      "Professor Girijesh Prasad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00423",
    "title": "Motion Informed Object Detection of Small Insects in Time-lapse Camera  Recordings",
    "abstract": "Insects as pollinators play a key role in ecosystem management and world food production. However, insect populations are declining, calling for a necessary global demand of insect monitoring. Existing methods analyze video or time-lapse images of insects in nature, but the analysis is challenging since insects are small objects in complex and dynamic scenes of natural vegetation. The current paper provides a dataset of primary honeybees visiting three different plant species during two months of summer-period. The dataset consists of more than 700,000 time-lapse images from multiple cameras, including more than 100,000 annotated images. The paper presents a new method pipeline for detecting insects in time-lapse RGB-images. The pipeline consists of a two-step process. Firstly, the time-lapse RGB-images are preprocessed to enhance insects in the images. We propose a new prepossessing enhancement method: Motion-Informed-enhancement. The technique uses motion and colors to enhance insects in images. The enhanced images are subsequently fed into a Convolutional Neural network (CNN) object detector. Motion-Informed-enhancement improves the deep learning object detectors You Only Look Once (YOLO) and Faster Region-based Convolutional Neural Networks (Faster R-CNN). Using Motion-Informed-enhancement the YOLO-detector improves average micro F1-score from 0.49 to 0.71, and the Faster R-CNN-detector improves average micro F1-score from 0.32 to 0.56 on the our dataset. Our datasets are published on: https://vision.eng.au.dk/mie/ ",
    "url": "https://arxiv.org/abs/2212.00423",
    "authors": [
      "Kim Bjerge",
      "Carsten Eie Frigaard",
      "Henrik Karstoft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00436",
    "title": "ViewNeRF: Unsupervised Viewpoint Estimation Using Category-Level Neural  Radiance Fields",
    "abstract": "We introduce ViewNeRF, a Neural Radiance Field-based viewpoint estimation method that learns to predict category-level viewpoints directly from images during training. While NeRF is usually trained with ground-truth camera poses, multiple extensions have been proposed to reduce the need for this expensive supervision. Nonetheless, most of these methods still struggle in complex settings with large camera movements, and are restricted to single scenes, i.e. they cannot be trained on a collection of scenes depicting the same object category. To address these issues, our method uses an analysis by synthesis approach, combining a conditional NeRF with a viewpoint predictor and a scene encoder in order to produce self-supervised reconstructions for whole object categories. Rather than focusing on high fidelity reconstruction, we target efficient and accurate viewpoint prediction in complex scenarios, e.g. 360{\\deg} rotation on real data. Our model shows competitive results on synthetic and real datasets, both for single scenes and multi-instance collections. ",
    "url": "https://arxiv.org/abs/2212.00436",
    "authors": [
      "Octave Mariotti",
      "Oisin Mac Aodha",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00442",
    "title": "MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term  Motion-Guided Temporal Attention for 3D Object Detection",
    "abstract": "Most scanning LiDAR sensors generate a sequence of point clouds in real-time. While conventional 3D object detectors use a set of unordered LiDAR points acquired over a fixed time interval, recent studies have revealed that substantial performance improvement can be achieved by exploiting the spatio-temporal context present in a sequence of LiDAR point sets. In this paper, we propose a novel 3D object detection architecture, which can encode LiDAR point cloud sequences acquired by multiple successive scans. The encoding process of the point cloud sequence is performed on two different time scales. We first design a short-term motion-aware voxel encoding that captures the short-term temporal changes of point clouds driven by the motion of objects in each voxel. We also propose long-term motion-guided bird's eye view (BEV) feature enhancement that adaptively aligns and aggregates the BEV feature maps obtained by the short-term voxel encoding by utilizing the dynamic motion context inferred from the sequence of the feature maps. The experiments conducted on the public nuScenes benchmark demonstrate that the proposed 3D object detector offers significant improvements in performance compared to the baseline methods and that it sets a state-of-the-art performance for certain 3D object detection categories. Code is available at https://github.com/HYjhkoh/MGTANet.git ",
    "url": "https://arxiv.org/abs/2212.00442",
    "authors": [
      "Junho Koh",
      "Junhyung Lee",
      "Youngwoo Lee",
      "Jaekyum Kim",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00443",
    "title": "Unbiased Heterogeneous Scene Graph Generation with Relation-aware  Message Passing Neural Network",
    "abstract": "Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the context-awareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between objects. Our extensive evaluations demonstrate that HetSGG outperforms state-of-the-art methods, especially outperforming on tail predicate classes. ",
    "url": "https://arxiv.org/abs/2212.00443",
    "authors": [
      "Kanghoon Yoon",
      "Kibum Kim",
      "Jinyoung Moon",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00449",
    "title": "GrannGAN: Graph annotation generative adversarial networks",
    "abstract": "We consider the problem of modelling high-dimensional distributions and generating new examples of data with complex relational feature structure coherent with a graph skeleton. The model we propose tackles the problem of generating the data features constrained by the specific graph structure of each data point by splitting the task into two phases. In the first it models the distribution of features associated with the nodes of the given graph, in the second it complements the edge features conditionally on the node features. We follow the strategy of implicit distribution modelling via generative adversarial network (GAN) combined with permutation equivariant message passing architecture operating over the sets of nodes and edges. This enables generating the feature vectors of all the graph objects in one go (in 2 phases) as opposed to a much slower one-by-one generations of sequential models, prevents the need for expensive graph matching procedures usually needed for likelihood-based generative models, and uses efficiently the network capacity by being insensitive to the particular node ordering in the graph representation. To the best of our knowledge, this is the first method that models the feature distribution along the graph skeleton allowing for generations of annotated graphs with user specified structures. Our experiments demonstrate the ability of our model to learn complex structured distributions through quantitative evaluation over three annotated graph datasets. ",
    "url": "https://arxiv.org/abs/2212.00449",
    "authors": [
      "Yoann Boget",
      "Magda Gregorova",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00465",
    "title": "FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning",
    "abstract": "Recently, webly supervised learning (WSL) has been studied to leverage numerous and accessible data from the Internet. Most existing methods focus on learning noise-robust models from web images while neglecting the performance drop caused by the differences between web domain and real-world domain. However, only by tackling the performance gap above can we fully exploit the practical value of web datasets. To this end, we propose a Few-shot guided Prototypical (FoPro) representation learning method, which only needs a few labeled examples from reality and can significantly improve the performance in the real-world domain. Specifically, we initialize each class center with few-shot real-world data as the ``realistic\" prototype. Then, the intra-class distance between web instances and ``realistic\" prototypes is narrowed by contrastive learning. Finally, we measure image-prototype distance with a learnable metric. Prototypes are polished by adjacent high-quality web images and involved in removing distant out-of-distribution samples. In experiments, FoPro is trained on web datasets with a few real-world examples guided and evaluated on real-world datasets. Our method achieves the state-of-the-art performance on three fine-grained datasets and two large-scale datasets. Compared with existing WSL methods under the same few-shot settings, FoPro still excels in real-world generalization. Code is available at https://github.com/yuleiqin/fopro. ",
    "url": "https://arxiv.org/abs/2212.00465",
    "authors": [
      "Yulei Qin",
      "Xingyu Chen",
      "Chao Chen",
      "Yunhang Shen",
      "Bo Ren",
      "Yun Gu",
      "Jie Yang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00475",
    "title": "Slack-based tunable damping leads to a trade-off between robustness and  efficiency in legged locomotion",
    "abstract": "Animals run robustly in diverse terrain. This locomotion robustness is puzzling because axon conduction velocity is limited to a few ten meters per second. If reflex loops deliver sensory information with significant delays, one would expect a destabilizing effect on sensorimotor control. Hence, an alternative explanation describes a hierarchical structure of low-level adaptive mechanics and high-level sensorimotor control to help mitigate the effects of transmission delays. Motivated by the concept of an adaptive mechanism triggering an immediate response, we developed a tunable physical damper system. Our mechanism combines a tendon with adjustable slackness connected to a physical damper. The slack damper allows adjustment of damping force, onset timing, effective stroke, and energy dissipation. We characterize the slack damper mechanism mounted to a legged robot controlled in open-loop mode. The robot hops vertically and planar over varying terrains and perturbations. During forward hopping, slack-based damping improves faster perturbation recovery (up to 170%) at higher energetic cost (27%). The tunable slack mechanism auto-engages the damper during perturbations, leading to a perturbation-trigger damping, improving robustness at minimum energetic cost. With the results from the slack damper mechanism, we propose a new functional interpretation of animals' redundant muscle tendons as tunable dampers. ",
    "url": "https://arxiv.org/abs/2212.00475",
    "authors": [
      "An Mo",
      "Fabio Izzi",
      "Emre Cemal G\u00f6nen",
      "Daniel Haeufle",
      "Alexander Badri-Spr\u00f6witz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.00479",
    "title": "Noisy Label Classification using Label Noise Selection with Test-Time  Augmentation Cross-Entropy and NoiseMix Learning",
    "abstract": "As the size of the dataset used in deep learning tasks increases, the noisy label problem, which is a task of making deep learning robust to the incorrectly labeled data, has become an important task. In this paper, we propose a method of learning noisy label data using the label noise selection with test-time augmentation (TTA) cross-entropy and classifier learning with the NoiseMix method. In the label noise selection, we propose TTA cross-entropy by measuring the cross-entropy to predict the test-time augmented training data. In the classifier learning, we propose the NoiseMix method based on MixUp and BalancedMix methods by mixing the samples from the noisy and the clean label data. In experiments on the ISIC-18 public skin lesion diagnosis dataset, the proposed TTA cross-entropy outperformed the conventional cross-entropy and the TTA uncertainty in detecting label noise data in the label noise selection process. Moreover, the proposed NoiseMix not only outperformed the state-of-the-art methods in the classification performance but also showed the most robustness to the label noise in the classifier learning. ",
    "url": "https://arxiv.org/abs/2212.00479",
    "authors": [
      "Hansang Lee",
      "Haeil Lee",
      "Helen Hong",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00482",
    "title": "IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn  Response Selection",
    "abstract": "The task of response selection in multi-turn dialogue is to find the best option from all candidates. In order to improve the reasoning ability of the model, previous studies pay more attention to using explicit algorithms to model the dependencies between utterances, which are deterministic, limited and inflexible. In addition, few studies consider differences between the options before and after reasoning. In this paper, we propose an Implicit Relational Reasoning Graph Network to address these issues, which consists of the Utterance Relational Reasoner (URR) and the Option Dual Comparator (ODC). URR aims to implicitly extract dependencies between utterances, as well as utterances and options, and make reasoning with relational graph convolutional networks. ODC focuses on perceiving the difference between the options through dual comparison, which can eliminate the interference of the noise options. Experimental results on two multi-turn dialogue reasoning benchmark datasets MuTual and MuTual+ show that our method significantly improves the baseline of four pretrained language models and achieves state-of-the-art performance. The model surpasses human performance for the first time on the MuTual dataset. ",
    "url": "https://arxiv.org/abs/2212.00482",
    "authors": [
      "Jingcheng Deng",
      "Hengwei Dai",
      "Xuewei Guo",
      "Yuanchen Ju",
      "Wei Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00501",
    "title": "Crowd-level Abnormal Behavior Detection via Multi-scale Motion  Consistency Learning",
    "abstract": "Detecting abnormal crowd motion emerging from complex interactions of individuals is paramount to ensure the safety of crowds. Crowd-level abnormal behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the crucial causes of many crowd disasters. In the recent decade, video anomaly detection (VAD) techniques have achieved remarkable success in detecting individual-level abnormal behaviors (e.g., sudden running, fighting and stealing), but research on VAD for CABs is rather limited. Unlike individual-level anomaly, CABs usually do not exhibit salient difference from the normal behaviors when observed locally, and the scale of CABs could vary from one scenario to another. In this paper, we present a systematic study to tackle the important problem of VAD for CABs with a novel crowd motion learning framework, multi-scale motion consistency network (MSMC-Net). MSMC-Net first captures the spatial and temporal crowd motion consistency information in a graph representation. Then, it simultaneously trains multiple feature graphs constructed at different scales to capture rich crowd patterns. An attention network is used to adaptively fuse the multi-scale features for better CAB detection. For the empirical study, we consider three large-scale crowd event datasets, UMN, Hajj and Love Parade. Experimental results show that MSMC-Net could substantially improve the state-of-the-art performance on all the datasets. ",
    "url": "https://arxiv.org/abs/2212.00501",
    "authors": [
      "Linbo Luo",
      "Yuanjing Li",
      "Haiyan Yin",
      "Shangwei Xie",
      "Ruimin Hu",
      "Wentong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00522",
    "title": "CL4CTR: A Contrastive Learning Framework for CTR Prediction",
    "abstract": "Many Click-Through Rate (CTR) prediction works focused on designing advanced architectures to model complex feature interactions but neglected the importance of feature representation learning, e.g., adopting a plain embedding layer for each feature, which results in sub-optimal feature representations and thus inferior CTR prediction performance. For instance, low frequency features, which account for the majority of features in many CTR tasks, are less considered in standard supervised learning settings, leading to sub-optimal feature representations. In this paper, we introduce self-supervised learning to produce high-quality feature representations directly and propose a model-agnostic Contrastive Learning for CTR (CL4CTR) framework consisting of three self-supervised learning signals to regularize the feature representation learning: contrastive loss, feature alignment, and field uniformity. The contrastive module first constructs positive feature pairs by data augmentation and then minimizes the distance between the representations of each positive feature pair by the contrastive loss. The feature alignment constraint forces the representations of features from the same field to be close, and the field uniformity constraint forces the representations of features from different fields to be distant. Extensive experiments verify that CL4CTR achieves the best performance on four datasets and has excellent effectiveness and compatibility with various representative baselines. ",
    "url": "https://arxiv.org/abs/2212.00522",
    "authors": [
      "Fangye Wang",
      "Yingxu Wang",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Ning Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00528",
    "title": "A Value-Centered Exploration of Data Privacy and Personalized Privacy  Assistants",
    "abstract": "In the the current post-GDPR landscape, privacy notices have become ever more prevalent on our phones and online. However, these notices are not well suited to their purpose of helping users make informed decisions. I suggest that instead of utilizing notice to eliciting informed consent, we could repurpose privacy notices to create the space for more meaningful, value-centered user decisions. Value-centered privacy decisions, or those that accurately reflect who we are and what we value, encapsulate the intuitive role of personal values in data privacy decisions. To explore how notices could be repurposed to support such decisions, I utilize Suzy Killmister's four-dimensional theory of autonomy (4DT) to operationalize value-centered privacy decisions. I then assess the degree that an existing technology, Personalized Privacy Assistants (PPAs), uses notices in a manner that allows for value-centered decision-making. Lastly, I explore the implications of the PPA assessment for designing a new assistant, called a value-centered privacy assistant (VcPA). A VcPA could ideally utilized notice to assists users in value-centered app selection and in other data privacy decisions. ",
    "url": "https://arxiv.org/abs/2212.00528",
    "authors": [
      "Sarah E. Carter"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2212.00535",
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks  with Augmented View",
    "abstract": "Graph anomaly detection (GAD) is a vital task in graph-based machine learning and has been widely applied in many real-world applications. The primary goal of GAD is to capture anomalous nodes from graph datasets, which evidently deviate from the majority of nodes. Recent methods have paid attention to various scales of contrastive strategies for GAD, i.e., node-subgraph and node-node contrasts. However, they neglect the subgraph-subgraph comparison information which the normal and abnormal subgraph pairs behave differently in terms of embeddings and structures in GAD, resulting in sub-optimal task performance. In this paper, we fulfill the above idea in the proposed multi-view multi-scale contrastive learning framework with subgraph-subgraph contrast for the first practice. To be specific, we regard the original input graph as the first view and generate the second view by graph augmentation with edge modifications. With the guidance of maximizing the similarity of the subgraph pairs, the proposed subgraph-subgraph contrast contributes to more robust subgraph embeddings despite of the structure variation. Moreover, the introduced subgraph-subgraph contrast cooperates well with the widely-adopted node-subgraph and node-node contrastive counterparts for mutual GAD performance promotions. Besides, we also conduct sufficient experiments to investigate the impact of different graph augmentation approaches on detection performance. The comprehensive experimental results well demonstrate the superiority of our method compared with the state-of-the-art approaches and the effectiveness of the multi-view subgraph pair contrastive strategy for the GAD task. ",
    "url": "https://arxiv.org/abs/2212.00535",
    "authors": [
      "Jingcan Duan",
      "Siwei Wang",
      "Pei Zhang",
      "En Zhu",
      "Jingtao Hu",
      "Hu Jin",
      "Yue Liu",
      "Zhibin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00539",
    "title": "Audio-Visual Activity Guided Cross-Modal Identity Association for Active  Speaker Detection",
    "abstract": "Active speaker detection in videos addresses associating a source face, visible in the video frames, with the underlying speech in the audio modality. The two primary sources of information to derive such a speech-face relationship are i) visual activity and its interaction with the speech signal and ii) co-occurrences of speakers' identities across modalities in the form of face and speech. The two approaches have their limitations: the audio-visual activity models get confused with other frequently occurring vocal activities, such as laughing and chewing, while the speakers' identity-based methods are limited to videos having enough disambiguating information to establish a speech-face association. Since the two approaches are independent, we investigate their complementary nature in this work. We propose a novel unsupervised framework to guide the speakers' cross-modal identity association with the audio-visual activity for active speaker detection. Through experiments on entertainment media videos from two benchmark datasets, the AVA active speaker (movies) and Visual Person Clustering Dataset (TV shows), we show that a simple late fusion of the two approaches enhances the active speaker detection performance. ",
    "url": "https://arxiv.org/abs/2212.00539",
    "authors": [
      "Rahul Sharma",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00543",
    "title": "Fine-Grained Selective Similarity Integration for Drug-Target  Interaction Prediction",
    "abstract": "The discovery of drug-target interactions (DTIs) is a pivotal process in pharmaceutical development. Computational approaches are a promising and efficient alternative to tedious and costly wet-lab experiments for predicting novel DTIs from numerous candidates. Recently, with the availability of abundant heterogeneous biological information from diverse data sources, computational methods have been able to leverage multiple drug and target similarities to boost the performance of DTI prediction. Similarity integration is an effective and flexible strategy to extract crucial information across complementary similarity views, providing a compressed input for any similarity-based DTI prediction model. However, existing similarity integration methods filter and fuse similarities from a global perspective, neglecting the utility of similarity views for each drug and target. In this study, we propose a Fine-Grained Selective similarity integration approach, called FGS, which employs a local interaction consistency-based weight matrix to capture and exploit the importance of similarities at a finer granularity in both similarity selection and combination steps. We evaluate FGS on five DTI prediction datasets under various prediction settings. Experimental results show that our method not only outperforms similarity integration competitors with comparable computational costs, but also achieves better prediction performance than state-of-the-art DTI prediction approaches by collaborating with conventional base models. Furthermore, case studies on the analysis of similarity weights and on the verification of novel predictions confirm the practical ability of FGS. ",
    "url": "https://arxiv.org/abs/2212.00543",
    "authors": [
      "Bin Liu",
      "Jin Wang",
      "Kaiwei Sun",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00554",
    "title": "Early prediction of the risk of ICU mortality with Deep Federated  Learning",
    "abstract": "Intensive Care Units usually carry patients with a serious risk of mortality. Recent research has shown the ability of Machine Learning to indicate the patients' mortality risk and point physicians toward individuals with a heightened need for care. Nevertheless, healthcare data is often subject to privacy regulations and can therefore not be easily shared in order to build Centralized Machine Learning models that use the combined data of multiple hospitals. Federated Learning is a Machine Learning framework designed for data privacy that can be used to circumvent this problem. In this study, we evaluate the ability of deep Federated Learning to predict the risk of Intensive Care Unit mortality at an early stage. We compare the predictive performance of Federated, Centralized, and Local Machine Learning in terms of AUPRC, F1-score, and AUROC. Our results show that Federated Learning performs equally well as the centralized approach and is substantially better than the local approach, thus providing a viable solution for early Intensive Care Unit mortality prediction. In addition, we show that the prediction performance is higher when the patient history window is closer to discharge or death. Finally, we show that using the F1-score as an early stopping metric can stabilize and increase the performance of our approach for the task at hand. ",
    "url": "https://arxiv.org/abs/2212.00554",
    "authors": [
      "Korbinian Rand",
      "N\u00faria Llad\u00f3s Armengol",
      "Lena Mondrejevski",
      "Ioanna Miliou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00557",
    "title": "Deep Kernel Learning for Mortality Prediction in the Face of Temporal  Shift",
    "abstract": "Neural models, with their ability to provide novel representations, have shown promising results in prediction tasks in healthcare. However, patient demographics, medical technology, and quality of care change over time. This often leads to drop in the performance of neural models for prospective patients, especially in terms of their calibration. The deep kernel learning (DKL) framework may be robust to such changes as it combines neural models with Gaussian processes, which are aware of prediction uncertainty. Our hypothesis is that out-of-distribution test points will result in probabilities closer to the global mean and hence prevent overconfident predictions. This in turn, we hypothesise, will result in better calibration on prospective data. This paper investigates DKL's behaviour when facing a temporal shift, which was naturally introduced when an information system that feeds a cohort database was changed. We compare DKL's performance to that of a neural baseline based on recurrent neural networks. We show that DKL indeed produced superior calibrated predictions. We also confirm that the DKL's predictions were indeed less sharp. In addition, DKL's discrimination ability was even improved: its AUC was 0.746 (+- 0.014 std), compared to 0.739 (+- 0.028 std) for the baseline. The paper demonstrated the importance of including uncertainty in neural computing, especially for their prospective use. ",
    "url": "https://arxiv.org/abs/2212.00557",
    "authors": [
      "Miguel Rios",
      "Ameen Abu-Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00567",
    "title": "P2Net: A Post-Processing Network for Refining Semantic Segmentation of  LiDAR Point Cloud based on Consistency of Consecutive Frames",
    "abstract": "We present a lightweight post-processing method to refine the semantic segmentation results of point cloud sequences. Most existing methods usually segment frame by frame and encounter the inherent ambiguity of the problem: based on a measurement in a single frame, labels are sometimes difficult to predict even for humans. To remedy this problem, we propose to explicitly train a network to refine these results predicted by an existing segmentation method. The network, which we call the P2Net, learns the consistency constraints between coincident points from consecutive frames after registration. We evaluate the proposed post-processing method both qualitatively and quantitatively on the SemanticKITTI dataset that consists of real outdoor scenes. The effectiveness of the proposed method is validated by comparing the results predicted by two representative networks with and without the refinement by the post-processing network. Specifically, qualitative visualization validates the key idea that labels of the points that are difficult to predict can be corrected with P2Net. Quantitatively, overall mIoU is improved from 10.5% to 11.7% for PointNet [1] and from 10.8% to 15.9% for PointNet++ [2]. ",
    "url": "https://arxiv.org/abs/2212.00567",
    "authors": [
      "Yutaka Momma",
      "Weimin Wang",
      "Edgar Simo-Serra",
      "Satoshi Iizuka",
      "Ryosuke Nakamura",
      "Hiroshi Ishikawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.00585",
    "title": "Soft Labels for Rapid Satellite Object Detection",
    "abstract": "Soft labels in image classification are vector representations of an image's true classification. In this paper, we investigate soft labels in the context of satellite object detection. We propose using detections as the basis for a new dataset of soft labels. Much of the effort in creating a high-quality model is gathering and annotating the training data. If we could use a model to generate a dataset for us, we could not only rapidly create datasets, but also supplement existing open-source datasets. Using a subset of the xView dataset, we train a YOLOv5 model to detect cars, planes, and ships. We then use that model to generate soft labels for the second training set which we then train and compare to the original model. We show that soft labels can be used to train a model that is almost as accurate as a model trained on the original data. ",
    "url": "https://arxiv.org/abs/2212.00585",
    "authors": [
      "Matthew Ciolino",
      "Grant Rosario",
      "David Noever"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00587",
    "title": "Embedding generation for text classification of Brazilian Portuguese  user reviews: from bag-of-words to transformers",
    "abstract": "Text classification is a natural language processing (NLP) task relevant to many commercial applications, like e-commerce and customer service. Naturally, classifying such excerpts accurately often represents a challenge, due to intrinsic language aspects, like irony and nuance. To accomplish this task, one must provide a robust numerical representation for documents, a process known as embedding. Embedding represents a key NLP field nowadays, having faced a significant advance in the last decade, especially after the introduction of the word-to-vector concept and the popularization of Deep Learning models for solving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite the impressive achievements in this field, the literature coverage regarding generating embeddings for Brazilian Portuguese texts is scarce, especially when considering commercial user reviews. Therefore, this work aims to provide a comprehensive experimental study of embedding approaches targeting a binary sentiment classification of user reviews in Brazilian Portuguese. This study includes from classical (Bag-of-Words) to state-of-the-art (Transformer-based) NLP models. The methods are evaluated with five open-source databases with pre-defined data partitions made available in an open digital repository to encourage reproducibility. The Fine-tuned TLMs achieved the best results for all cases, being followed by the Feature-based TLM, LSTM, and CNN, with alternate ranks, depending on the database under analysis. ",
    "url": "https://arxiv.org/abs/2212.00587",
    "authors": [
      "Frederico Dias Souza",
      "Jo\u00e3o Baptista de Oliveira e Souza Filho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00593",
    "title": "Plug-and-Play Secondary Control for Safety of LTI Systems under Attacks",
    "abstract": "We consider the problem of controller design for linear time-invariant cyber-physical systems (CPSs) controlled via networks. Specifically, we adopt the set-up that a controller has already been designed to stabilize the plant. However, the closed loop system may be subject to actuator and sensor attacks. We first perform a reachability analysis to see the effect of potential attacks. To further ensure the safety of the states of the system, we choose a subset of sensors that can be locally secured and made free of attacks. Using these limited resources, an extra controller is designed to enhance the safety of the new closed loop. The safety of the system will be characterized by the notion of safe sets. Lyapunov based analysis will be used to derive sufficient conditions that ensure the states always stay in the safe set. The conditions will then be stated as convex optimization problems which can be solved efficiently. Lastly, our theoretical results are illustrated through numerical simulations. ",
    "url": "https://arxiv.org/abs/2212.00593",
    "authors": [
      "Yankai Lin",
      "Michelle S. Chong",
      "Carlos Murguia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00596",
    "title": "Language models and brain alignment: beyond word-level semantics and  prediction",
    "abstract": "Pretrained language models that have been trained to predict the next word over billions of text documents have been shown to also significantly predict brain recordings of people comprehending language. Understanding the reasons behind the observed similarities between language in machines and language in the brain can lead to more insight into both systems. Recent works suggest that the prediction of the next word is a key mechanism that contributes to the alignment between the two. What is not yet understood is whether prediction of the next word is necessary for this observed alignment or simply sufficient, and whether there are other shared mechanisms or information that is similarly important. In this work, we take a first step towards a better understanding via two simple perturbations in a popular pretrained language model. The first perturbation is to improve the model's ability to predict the next word in the specific naturalistic stimulus text that the brain recordings correspond to. We show that this indeed improves the alignment with the brain recordings. However, this improved alignment may also be due to any improved word-level or multi-word level semantics for the specific world that is described by the stimulus narrative. We aim to disentangle the contribution of next word prediction and semantic knowledge via our second perturbation: scrambling the word order at inference time, which reduces the ability to predict the next word, but maintains any newly learned word-level semantics. By comparing the alignment with brain recordings of these differently perturbed models, we show that improvements in alignment with brain recordings are due to more than improvements in next word prediction and word-level semantics. ",
    "url": "https://arxiv.org/abs/2212.00596",
    "authors": [
      "Gabriele Merlin",
      "Mariya Toneva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2212.00607",
    "title": "Real-time Trust Prediction in Conditionally Automated Driving Using  Physiological Measures",
    "abstract": "Trust calibration presents a main challenge during the interaction between drivers and automated vehicles (AVs). In order to calibrate trust, it is important to measure drivers' trust in real time. One possible method is through modeling its dynamic changes using machine learning models and physiological measures. In this paper, we proposed a technique based on machine learning models to predict drivers' dynamic trust in conditional AVs using physiological measurements in real time. We conducted the study in a driving simulator where participants were requested to take over control from automated driving in three conditions that included a control condition, a false alarm condition, a miss condition with eight takeover requests (TORs) in different scenarios. Drivers' physiological measures were recorded during the experiment, including galvanic skin response (GSR), heart rate (HR) indices, and eye-tracking metrics. Using five machine learning models, we found that eXtreme Gradient Boosting (XGBoost) performed the best and was able to predict drivers' trust in real time with an f1-score of 89.1%. Our findings provide good implications on how to design an in-vehicle trust monitoring system to calibrate drivers' trust to facilitate interaction between the driver and the AV in real time. ",
    "url": "https://arxiv.org/abs/2212.00607",
    "authors": [
      "Jackie Ayoub",
      "Lilit Avetisian",
      "X. Jessie Yang",
      "Feng Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2212.00612",
    "title": "Purifier: Defending Data Inference Attacks via Transforming Confidence  Scores",
    "abstract": "Neural networks are susceptible to data inference attacks such as the membership inference attack, the adversarial model inversion attack and the attribute inference attack, where the attacker could infer useful information such as the membership, the reconstruction or the sensitive attributes of a data sample from the confidence scores predicted by the target classifier. In this paper, we propose a method, namely PURIFIER, to defend against membership inference attacks. It transforms the confidence score vectors predicted by the target classifier and makes purified confidence scores indistinguishable in individual shape, statistical distribution and prediction label between members and non-members. The experimental results show that PURIFIER helps defend membership inference attacks with high effectiveness and efficiency, outperforming previous defense methods, and also incurs negligible utility loss. Besides, our further experiments show that PURIFIER is also effective in defending adversarial model inversion attacks and attribute inference attacks. For example, the inversion error is raised about 4+ times on the Facescrub530 classifier, and the attribute inference accuracy drops significantly when PURIFIER is deployed in our experiment. ",
    "url": "https://arxiv.org/abs/2212.00612",
    "authors": [
      "Ziqi Yang",
      "Lijin Wang",
      "Da Yang",
      "Jie Wan",
      "Ziming Zhao",
      "Ee-Chien Chang",
      "Fan Zhang",
      "Kui Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.00613",
    "title": "NeuWigs: A Neural Dynamic Model for Volumetric Hair Capture and  Animation",
    "abstract": "The capture and animation of human hair are two of the major challenges in the creation of realistic avatars for the virtual reality. Both problems are highly challenging, because hair has complex geometry and appearance, as well as exhibits challenging motion. In this paper, we present a two-stage approach that models hair independently from the head to address these challenges in a data-driven manner. The first stage, state compression, learns a low-dimensional latent space of 3D hair states containing motion and appearance, via a novel autoencoder-as-a-tracker strategy. To better disentangle the hair and head in appearance learning, we employ multi-view hair segmentation masks in combination with a differentiable volumetric renderer. The second stage learns a novel hair dynamics model that performs temporal hair transfer based on the discovered latent codes. To enforce higher stability while driving our dynamics model, we employ the 3D point-cloud autoencoder from the compression stage for de-noising of the hair state. Our model outperforms the state of the art in novel view synthesis and is capable of creating novel hair animations without having to rely on hair observations as a driving signal. ",
    "url": "https://arxiv.org/abs/2212.00613",
    "authors": [
      "Ziyan Wang",
      "Giljoo Nam",
      "Tuur Stuyck",
      "Stephen Lombardi",
      "Chen Cao",
      "Jason Saragih",
      "Michael Zollhoefer",
      "Jessica Hodgins",
      "Christoph Lassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.00623",
    "title": "BEV-LGKD: A Unified LiDAR-Guided Knowledge Distillation Framework for  BEV 3D Object Detection",
    "abstract": "Recently, Bird's-Eye-View (BEV) representation has gained increasing attention in multi-view 3D object detection, which has demonstrated promising applications in autonomous driving. Although multi-view camera systems can be deployed at low cost, the lack of depth information makes current approaches adopt large models for good performance. Therefore, it is essential to improve the efficiency of BEV 3D object detection. Knowledge Distillation (KD) is one of the most practical techniques to train efficient yet accurate models. However, BEV KD is still under-explored to the best of our knowledge. Different from image classification tasks, BEV 3D object detection approaches are more complicated and consist of several components. In this paper, we propose a unified framework named BEV-LGKD to transfer the knowledge in the teacher-student manner. However, directly applying the teacher-student paradigm to BEV features fails to achieve satisfying results due to heavy background information in RGB cameras. To solve this problem, we propose to leverage the localization advantage of LiDAR points. Specifically, we transform the LiDAR points to BEV space and generate the foreground mask and view-dependent mask for the teacher-student paradigm. It is to be noted that our method only uses LiDAR points to guide the KD between RGB models. As the quality of depth estimation is crucial for BEV perception, we further introduce depth distillation to our framework. Our unified framework is simple yet effective and achieves a significant performance boost. Code will be released. ",
    "url": "https://arxiv.org/abs/2212.00623",
    "authors": [
      "Jianing Li",
      "Ming Lu",
      "Jiaming Liu",
      "Yandong Guo",
      "Li Du",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00625",
    "title": "Probabilistic Neural Circuits leveraging AI-Enhanced Codesign for Random  Number Generation",
    "abstract": "Stochasticity is ubiquitous in the world around us. However, our predominant computing paradigm is deterministic. Random number generation (RNG) can be a computationally inefficient operation in this system especially for larger workloads. Our work leverages the underlying physics of emerging devices to develop probabilistic neural circuits for RNGs from a given distribution. However, codesign for novel circuits and systems that leverage inherent device stochasticity is a hard problem. This is mostly due to the large design space and complexity of doing so. It requires concurrent input from multiple areas in the design stack from algorithms, architectures, circuits, to devices. In this paper, we present examples of optimal circuits developed leveraging AI-enhanced codesign techniques using constraints from emerging devices and algorithms. Our AI-enhanced codesign approach accelerated design and enabled interactions between experts from different areas of the microelectronics design stack including theory, algorithms, circuits, and devices. We demonstrate optimal probabilistic neural circuits using magnetic tunnel junction and tunnel diode devices that generate an RNG from a given distribution. ",
    "url": "https://arxiv.org/abs/2212.00625",
    "authors": [
      "Suma G. Cardwell",
      "Catherine D. Schuman",
      "J. Darby Smith",
      "Karan Patel",
      "Jaesuk Kwon",
      "Samuel Liu",
      "Christopher Allemang",
      "Shashank Misra",
      "Jean Anne Incorvia",
      "James B. Aimone"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2212.00671",
    "title": "Prasatul Matrix: A Direct Comparison Approach for Analyzing Evolutionary  Optimization Algorithms",
    "abstract": "The performance of individual evolutionary optimization algorithms is mostly measured in terms of statistics such as mean, median and standard deviation etc., computed over the best solutions obtained with few trails of the algorithm. To compare the performance of two algorithms, the values of these statistics are compared instead of comparing the solutions directly. This kind of comparison lacks direct comparison of solutions obtained with different algorithms. For instance, the comparison of best solutions (or worst solution) of two algorithms simply not possible. Moreover, ranking of algorithms is mostly done in terms of solution quality only, despite the fact that the convergence of algorithm is also an important factor. In this paper, a direct comparison approach is proposed to analyze the performance of evolutionary optimization algorithms. A direct comparison matrix called \\emph{Prasatul Matrix} is prepared, which accounts direct comparison outcome of best solutions obtained with two algorithms for a specific number of trials. Five different performance measures are designed based on the prasatul matrix to evaluate the performance of algorithms in terms of Optimality and Comparability of solutions. These scores are utilized to develop a score-driven approach for comparing performance of multiple algorithms as well as for ranking both in the grounds of solution quality and convergence analysis. Proposed approach is analyzed with six evolutionary optimization algorithms on 25 benchmark functions. A non-parametric statistical analysis, namely Wilcoxon paired sum-rank test is also performed to verify the outcomes of proposed direct comparison approach. ",
    "url": "https://arxiv.org/abs/2212.00671",
    "authors": [
      "Anupam Biswas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.00714",
    "title": "A Graph Neural Networks based Framework for Topology-Aware Proactive SLA  Management in a Latency Critical NFV Application Use-case",
    "abstract": "Recent advancements in the rollout of 5G and 6G have led to the emergence of a new range of latency-critical applications delivered via a Network Function Virtualization (NFV) enabled paradigm of flexible and softwarized communication networks. Evolving verticals like telecommunications, smart grid, virtual reality (VR), industry 4.0, automated vehicles, etc. are driven by the vision of low latency and high reliability, and there is a wide gap to efficiently bridge the Quality of Service (QoS) constraints for both the service providers and the end-user. In this work, we look to tackle the over-provisioning of latency-critical services by proposing a proactive SLA management framework leveraging Graph Neural Networks (GNN) and Deep Reinforcement Learning (DRL) to balance the trade-off between efficiency and reliability. To summarize our key contributions: 1) we compose a graph-based spatio-temporal multivariate time-series forecasting model with multiple time-step predictions in a multi-output scenario, delivering 74.62% improved performance over the established baseline state-of-art model on the use-case; and 2) we leverage realistic SLA definitions for the use-case to achieve a dynamic SLA-aware oversight for scaling policy management with DRL. ",
    "url": "https://arxiv.org/abs/2212.00714",
    "authors": [
      "Nikita Jalodia",
      "Mohit Taneja",
      "Alan Davy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.00727",
    "title": "Adversarial Artifact Detection in EEG-Based Brain-Computer Interfaces",
    "abstract": "Machine learning has achieved great success in electroencephalogram (EEG) based brain-computer interfaces (BCIs). Most existing BCI research focused on improving its accuracy, but few had considered its security. Recent studies, however, have shown that EEG-based BCIs are vulnerable to adversarial attacks, where small perturbations added to the input can cause misclassification. Detection of adversarial examples is crucial to both the understanding of this phenomenon and the defense. This paper, for the first time, explores adversarial detection in EEG-based BCIs. Experiments on two EEG datasets using three convolutional neural networks were performed to verify the performances of multiple detection approaches. We showed that both white-box and black-box attacks can be detected, and the former are easier to detect. ",
    "url": "https://arxiv.org/abs/2212.00727",
    "authors": [
      "Xiaoqing Chen",
      "Dongrui Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.00767",
    "title": "Exploiting Socially-Aware Tasks for Embodied Social Navigation",
    "abstract": "Learning how to navigate among humans in an occluded and spatially constrained indoor environment, is a key ability required to embodied agent to be integrated into our society. In this paper, we propose an end-to-end architecture that exploits Socially-Aware Tasks (referred as to Risk and Social Compass) to inject into a reinforcement learning navigation policy the ability to infer common-sense social behaviors. To this end, our tasks exploit the notion of immediate and future dangers of collision. Furthermore, we propose an evaluation protocol specifically designed for the Social Navigation Task in simulated environments. This is done to capture fine-grained features and characteristics of the policy by analyzing the minimal unit of human-robot spatial interaction, called Encounter. We validate our approach on Gibson4+ and Habitat-Matterport3D datasets. ",
    "url": "https://arxiv.org/abs/2212.00767",
    "authors": [
      "Enrico Cancelli",
      "Tommaso Campari",
      "Luciano Serafini",
      "Angel X. Chang",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.00770",
    "title": "On Utilizing Relationships for Transferable Few-Shot Fine-Grained Object  Detection",
    "abstract": "State-of-the-art object detectors are fast and accurate, but they require a large amount of well annotated training data to obtain good performance. However, obtaining a large amount of training annotations specific to a particular task, i.e., fine-grained annotations, is costly in practice. In contrast, obtaining common-sense relationships from text, e.g., \"a table-lamp is a lamp that sits on top of a table\", is much easier. Additionally, common-sense relationships like \"on-top-of\" are easy to annotate in a task-agnostic fashion. In this paper, we propose a probabilistic model that uses such relational knowledge to transform an off-the-shelf detector of coarse object categories (e.g., \"table\", \"lamp\") into a detector of fine-grained categories (e.g., \"table-lamp\"). We demonstrate that our method, RelDetect, achieves performance competitive to finetuning based state-of-the-art object detector baselines when an extremely low amount of fine-grained annotations is available ($0.2\\%$ of entire dataset). We also demonstrate that RelDetect is able to utilize the inherent transferability of relationship information to obtain a better performance ($+5$ mAP points) than the above baselines on an unseen dataset (zero-shot transfer). In summary, we demonstrate the power of using relationships for object detection on datasets where fine-grained object categories can be linked to coarse-grained categories via suitable relationships. ",
    "url": "https://arxiv.org/abs/2212.00770",
    "authors": [
      "Ambar Pal",
      "Arnau Ramisa",
      "Amit Kumar K C",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00771",
    "title": "Neural Representations Reveal Distinct Modes of Class Fitting in  Residual Convolutional Networks",
    "abstract": "We leverage probabilistic models of neural representations to investigate how residual networks fit classes. To this end, we estimate class-conditional density models for representations learned by deep ResNets. We then use these models to characterize distributions of representations across learned classes. Surprisingly, we find that classes in the investigated models are not fitted in an uniform way. On the contrary: we uncover two groups of classes that are fitted with markedly different distributions of representations. These distinct modes of class-fitting are evident only in the deeper layers of the investigated models, indicating that they are not related to low-level image features. We show that the uncovered structure in neural representations correlate with memorization of training examples and adversarial robustness. Finally, we compare class-conditional distributions of neural representations between memorized and typical examples. This allows us to uncover where in the network structure class labels arise for memorized and standard inputs. ",
    "url": "https://arxiv.org/abs/2212.00771",
    "authors": [
      "Micha\u0142 Jamro\u017c",
      "Marcin Kurdziel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00773",
    "title": "FakeOut: Leveraging Out-of-domain Self-supervision for Multi-modal Video  Deepfake Detection",
    "abstract": "Video synthesis methods rapidly improved in recent years, allowing easy creation of synthetic humans. This poses a problem, especially in the era of social media, as synthetic videos of speaking humans can be used to spread misinformation in a convincing manner. Thus, there is a pressing need for accurate and robust deepfake detection methods, that can detect forgery techniques not seen during training. In this work, we explore whether this can be done by leveraging a multi-modal, out-of-domain backbone trained in a self-supervised manner, adapted to the video deepfake domain. We propose FakeOut; a novel approach that relies on multi-modal data throughout both the pre-training phase and the adaption phase. We demonstrate the efficacy and robustness of FakeOut in detecting various types of deepfakes, especially manipulations which were not seen during training. Our method achieves state-of-the-art results in cross-manipulation and cross-dataset generalization. This study shows that, perhaps surprisingly, training on out-of-domain videos (i.e., videos with no speaking humans), can lead to better deepfake detection systems. Code is available on GitHub. ",
    "url": "https://arxiv.org/abs/2212.00773",
    "authors": [
      "Gil Knafo",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00780",
    "title": "Universe Points Representation Learning for Partial Multi-Graph Matching",
    "abstract": "Many challenges from natural world can be formulated as a graph matching problem. Previous deep learning-based methods mainly consider a full two-graph matching setting. In this work, we study the more general partial matching problem with multi-graph cycle consistency guarantees. Building on a recent progress in deep learning on graphs, we propose a novel data-driven method (URL) for partial multi-graph matching, which uses an object-to-universe formulation and learns latent representations of abstract universe points. The proposed approach advances the state of the art in semantic keypoint matching problem, evaluated on Pascal VOC, CUB, and Willow datasets. Moreover, the set of controlled experiments on a synthetic graph matching dataset demonstrates the scalability of our method to graphs with large number of nodes and its robustness to high partiality. ",
    "url": "https://arxiv.org/abs/2212.00780",
    "authors": [
      "Zhakshylyk Nurlanov",
      "Frank R. Schmidt",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00789",
    "title": "Attribute-based Representations for Accurate and Interpretable Video  Anomaly Detection",
    "abstract": "Video anomaly detection (VAD) is a challenging computer vision task with many practical applications. As anomalies are inherently ambiguous, it is essential for users to understand the reasoning behind a system's decision in order to determine if the rationale is sound. In this paper, we propose a simple but highly effective method that pushes the boundaries of VAD accuracy and interpretability using attribute-based representations. Our method represents every object by its velocity and pose. The anomaly scores are computed using a density-based approach. Surprisingly, we find that this simple representation is sufficient to achieve state-of-the-art performance in ShanghaiTech, the largest and most complex VAD dataset. Combining our interpretable attribute-based representations with implicit, deep representation yields state-of-the-art performance with a $99.1\\%, 93.3\\%$, and $85.9\\%$ AUROC on Ped2, Avenue, and ShanghaiTech, respectively. Our method is accurate, interpretable, and easy to implement. ",
    "url": "https://arxiv.org/abs/2212.00789",
    "authors": [
      "Tal Reiss",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00217",
    "title": "Physics-Constrained Generative Adversarial Networks for 3D Turbulence",
    "abstract": "Generative Adversarial Networks (GANs) have received wide acclaim among the machine learning (ML) community for their ability to generate realistic 2D images. ML is being applied more often to complex problems beyond those of computer vision. However, current frameworks often serve as black boxes and lack physics embeddings, leading to poor ability in enforcing constraints and unreliable models. In this work, we develop physics embeddings that can be stringently imposed, referred to as hard constraints, in the neural network architecture. We demonstrate their capability for 3D turbulence by embedding them in GANs, particularly to enforce the mass conservation constraint in incompressible fluid turbulence. In doing so, we also explore and contrast the effects of other methods of imposing physics constraints within the GANs framework, especially penalty-based physics constraints popular in literature. By using physics-informed diagnostics and statistics, we evaluate the strengths and weaknesses of our approach and demonstrate its feasibility. ",
    "url": "https://arxiv.org/abs/2212.00217",
    "authors": [
      "Dima Tretiak",
      "Arvind T. Mohan",
      "Daniel Livescu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00270",
    "title": "On the Compatibility between a Neural Network and a Partial Differential  Equation for Physics-informed Learning",
    "abstract": "We shed light on a pitfall and an opportunity in physics-informed neural networks (PINNs). We prove that a multilayer perceptron (MLP) only with ReLU (Rectified Linear Unit) or ReLU-like Lipschitz activation functions will always lead to a vanished Hessian. Such a network-imposed constraint contradicts any second- or higher-order partial differential equations (PDEs). Therefore, a ReLU-based MLP cannot form a permissible function space for the approximation of their solutions. Inspired by this pitfall, we prove that a linear PDE up to the $n$-th order can be strictly satisfied by an MLP with $C^n$ activation functions when the weights of its output layer lie on a certain hyperplane, as called the out-layer-hyperplane. An MLP equipped with the out-layer-hyperplane becomes \"physics-enforced\", no longer requiring a loss function for the PDE itself (but only those for the initial and boundary conditions). Such a hyperplane exists not only for MLPs but for any network architecture tailed by a fully-connected hidden layer. To our knowledge, this should be the first PINN architecture that enforces point-wise correctness of a PDE. We give the closed-form expression of the out-layer-hyperplane for second-order linear PDEs and provide an implementation. ",
    "url": "https://arxiv.org/abs/2212.00270",
    "authors": [
      "Kuangdai Leng",
      "Jeyan Thiyagalingam"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00542",
    "title": "Graph Convolutional Neural Networks as Parametric CoKleisli morphisms",
    "abstract": "We define the bicategory of Graph Convolutional Neural Networks $\\mathbf{GCNN}_n$ for an arbitrary graph with $n$ nodes. We show it can be factored through the already existing categorical constructions for deep learning called $\\mathbf{Para}$ and $\\mathbf{Lens}$ with the base category set to the CoKleisli category of the product comonad. We prove that there exists an injective-on-objects, faithful 2-functor $\\mathbf{GCNN}_n \\to \\mathbf{Para}(\\mathsf{CoKl}(\\mathbb{R}^{n \\times n} \\times -))$. We show that this construction allows us to treat the adjacency matrix of a GCNN as a global parameter instead of a a local, layer-wise one. This gives us a high-level categorical characterisation of a particular kind of inductive bias GCNNs possess. Lastly, we hypothesize about possible generalisations of GCNNs to general message-passing graph neural networks, connections to equivariant learning, and the (lack of) functoriality of activation functions. ",
    "url": "https://arxiv.org/abs/2212.00542",
    "authors": [
      "Bruno Gavranovi\u0107",
      "Mattia Villani"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00555",
    "title": "A Structure-guided Effective and Temporal-lag Connectivity Network for  Revealing Brain Disorder Mechanisms",
    "abstract": "Brain network provides important insights for the diagnosis of many brain disorders, and how to effectively model the brain structure has become one of the core issues in the domain of brain imaging analysis. Recently, various computational methods have been proposed to estimate the causal relationship (i.e., effective connectivity) between brain regions. Compared with traditional correlation-based methods, effective connectivity can provide the direction of information flow, which may provide additional information for the diagnosis of brain diseases. However, existing methods either ignore the fact that there is a temporal-lag in the information transmission across brain regions, or simply set the temporal-lag value between all brain regions to a fixed value. To overcome these issues, we design an effective temporal-lag neural network (termed ETLN) to simultaneously infer the causal relationships and the temporal-lag values between brain regions, which can be trained in an end-to-end manner. In addition, we also introduce three mechanisms to better guide the modeling of brain networks. The evaluation results on the Alzheimer's Disease Neuroimaging Initiative (ADNI) database demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2212.00555",
    "authors": [
      "Zhengwang Xia",
      "Tao Zhou",
      "Saqib Mamoon",
      "Amani Alfakih",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00565",
    "title": "Weakly-supervised detection of AMD-related lesions in color fundus  images using explainable deep learning",
    "abstract": "Age-related macular degeneration (AMD) is a degenerative disorder affecting the macula, a key area of the retina for visual acuity. Nowadays, it is the most frequent cause of blindness in developed countries. Although some promising treatments have been developed, their effectiveness is low in advanced stages. This emphasizes the importance of large-scale screening programs. Nevertheless, implementing such programs for AMD is usually unfeasible, since the population at risk is large and the diagnosis is challenging. All this motivates the development of automatic methods. In this sense, several works have achieved positive results for AMD diagnosis using convolutional neural networks (CNNs). However, none incorporates explainability mechanisms, which limits their use in clinical practice. In that regard, we propose an explainable deep learning approach for the diagnosis of AMD via the joint identification of its associated retinal lesions. In our proposal, a CNN is trained end-to-end for the joint task using image-level labels. The provided lesion information is of clinical interest, as it allows to assess the developmental stage of AMD. Additionally, the approach allows to explain the diagnosis from the identified lesions. This is possible thanks to the use of a CNN with a custom setting that links the lesions and the diagnosis. Furthermore, the proposed setting also allows to obtain coarse lesion segmentation maps in a weakly-supervised way, further improving the explainability. The training data for the approach can be obtained without much extra work by clinicians. The experiments conducted demonstrate that our approach can identify AMD and its associated lesions satisfactorily, while providing adequate coarse segmentation maps for most common lesions. ",
    "url": "https://arxiv.org/abs/2212.00565",
    "authors": [
      "Jos\u00e9 Morano",
      "\u00c1lvaro S. Hervella",
      "Jos\u00e9 Rouco",
      "Jorge Novo",
      "Jos\u00e9 I. Fern\u00e1ndez-Vigo",
      "Marcos Ortega"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00576",
    "title": "Quantum Neural Networks for a Supply Chain Logistics Application",
    "abstract": "Problem instances of a size suitable for practical applications are not likely to be addressed during the noisy intermediate-scale quantum (NISQ) period with (almost) pure quantum algorithms. Hybrid classical-quantum algorithms have potential, however, to achieve good performance on much larger problem instances. We investigate one such hybrid algorithm on a problem of substantial importance: vehicle routing for supply chain logistics with multiple trucks and complex demand structure. We use reinforcement learning with neural networks with embedded quantum circuits. In such neural networks, projecting high-dimensional feature vectors down to smaller vectors is necessary to accommodate restrictions on the number of qubits of NISQ hardware. However, we use a multi-head attention mechanism where, even in classical machine learning, such projections are natural and desirable. We consider data from the truck routing logistics of a company in the automotive sector, and apply our methodology by decomposing into small teams of trucks, and we find results comparable to human truck assignment. ",
    "url": "https://arxiv.org/abs/2212.00576",
    "authors": [
      "Randall Correll",
      "Sean J. Weinberg",
      "Fabio Sanches",
      "Takanori Ide",
      "Takafumi Suzuki"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00723",
    "title": "Target-centered Subject Transfer Framework for EEG Data Augmentation",
    "abstract": "Data augmentation approaches are widely explored for the enhancement of decoding electroencephalogram signals. In subject-independent brain-computer interface system, domain adaption and generalization are utilized to shift source subjects' data distribution to match the target subject as an augmentation. However, previous works either introduce noises (e.g., by noise addition or generation with random noises) or modify target data, thus, cannot well depict the target data distribution and hinder further analysis. In this paper, we propose a target-centered subject transfer framework as a data augmentation approach. A subset of source data is first constructed to maximize the source-target relevance. Then, the generative model is applied to transfer the data to target domain. The proposed framework enriches the explainability of target domain by adding extra real data, instead of noises. It shows superior performance compared with other data augmentation methods. Extensive experiments are conducted to verify the effectiveness and robustness of our approach as a prosperous tool for further research. ",
    "url": "https://arxiv.org/abs/2212.00723",
    "authors": [
      "Kang Yin",
      "Byeong-Hoo Lee",
      "Byoung-Hee Kwon",
      "Jeong-Hyun Cho"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00729",
    "title": "Edge Deep Learning Enabled Freezing of Gait Detection in Parkinson's  Patients",
    "abstract": "This paper presents the design of a wireless sensor network for detecting and alerting the freezing of gait (FoG) symptoms in patients with Parkinson's disease. Three sensor nodes, each integrating a 3-axis accelerometer, can be placed on a patient at ankle, thigh, and truck. Each sensor node can independently detect FoG using an on-device deep learning (DL) model, featuring a squeeze and excitation convolutional neural network (CNN). In a validation using a public dataset, the prototype developed achieved a FoG detection sensitivity of 88.8% and an F1 score of 85.34%, using less than 20 k trainable parameters per sensor node. Once FoG is detected, an auditory signal will be generated to alert users, and the alarm signal will also be sent to mobile phones for further actions if needed. The sensor node can be easily recharged wirelessly by inductive coupling. The system is self-contained and processes all user data locally without streaming data to external devices or the cloud, thus eliminating the cybersecurity risks and power penalty associated with wireless data transmission. The developed methodology can be used in a wide range of applications. ",
    "url": "https://arxiv.org/abs/2212.00729",
    "authors": [
      "Ourong Lin",
      "Tian Yu",
      "Yuhan Hou",
      "Yi Zhu",
      "Xilin Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00735",
    "title": "xTrimoABFold: Improving Antibody Structure Prediction without Multiple  Sequence Alignments",
    "abstract": "In the field of antibody engineering, an essential task is to design a novel antibody whose paratopes bind to a specific antigen with correct epitopes. Understanding antibody structure and its paratope can facilitate a mechanistic understanding of its function. Therefore, antibody structure prediction from its sequence alone has always been a highly valuable problem for de novo antibody design. AlphaFold2, a breakthrough in the field of structural biology, provides a solution to predict protein structure based on protein sequences and computationally expensive coevolutionary multiple sequence alignments (MSAs). However, the computational efficiency and undesirable prediction accuracy of antibodies, especially on the complementarity-determining regions (CDRs) of antibodies limit their applications in the industrially high-throughput drug design. To learn an informative representation of antibodies, we employed a deep antibody language model (ALM) on curated sequences from the observed antibody space database via a transformer model. We also developed a novel model named xTrimoABFold to predict antibody structure from antibody sequence based on the pretrained ALM as well as efficient evoformers and structural modules. The model was trained end-to-end on the antibody structures in PDB by minimizing the ensemble loss of domain-specific focal loss on CDR and the frame-aligned point loss. xTrimoABFold outperforms AlphaFold2 and other protein language model based SOTAs, e.g., OmegaFold, HelixFold-Single, and IgFold with a large significant margin (30+\\% improvement on RMSD) while performing 151 times faster than AlphaFold2. To the best of our knowledge, xTrimoABFold achieved state-of-the-art antibody structure prediction. Its improvement in both accuracy and efficiency makes it a valuable tool for de novo antibody design and could make further improvements in immuno-theory. ",
    "url": "https://arxiv.org/abs/2212.00735",
    "authors": [
      "Yining Wang",
      "Xumeng Gong",
      "Shaochuan Li",
      "Bing Yang",
      "YiWu Sun",
      "Chuan Shi",
      "Hui Li",
      "Yangang Wang",
      "Cheng Yang",
      "Le Song"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.12201",
    "title": "Improved Detection of Face Presentation Attacks Using Image  Decomposition",
    "abstract": " Comments: Conference - IJCB ",
    "url": "https://arxiv.org/abs/2103.12201",
    "authors": [
      "Shlok Kumar Mishra",
      "Kuntal Sengupta",
      "Max Horowitz-Gelb",
      "Wen-Sheng Chu",
      "Sofien Bouaziz",
      "David Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.13876",
    "title": "PDNet: Toward Better One-Stage Object Detection With Prediction  Decoupling",
    "abstract": " Comments: IEEE Transactions on Image Processing, 2022 ",
    "url": "https://arxiv.org/abs/2104.13876",
    "authors": [
      "Li Yang",
      "Yan Xu",
      "Shaoru Wang",
      "Chunfeng Yuan",
      "Ziqi Zhang",
      "Bing Li",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.01359",
    "title": "CENN: Conservative energy method based on neural networks with  subdomains for solving variational problems involving heterogeneous and  complex geometries",
    "abstract": " Comments: 39 pages, 22 figures, 1 graphical abstract ",
    "url": "https://arxiv.org/abs/2110.01359",
    "authors": [
      "Yizheng Wang",
      "Jia Sun",
      "Wei Li",
      "Zaiyuan Lu",
      "Yinghua Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.08806",
    "title": "Correlation inference attacks against machine learning models",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2112.08806",
    "authors": [
      "Ana-Maria Cre\u0163u",
      "Florent Gu\u00e9pin",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.10899",
    "title": "Speeding up Heterogeneous Federated Learning with Sequentially Trained  Superclients",
    "abstract": " Comments: Published at the 26th International Conference on Pattern Recognition (ICPR), 2022, pp. 3376-3382 ",
    "url": "https://arxiv.org/abs/2201.10899",
    "authors": [
      "Riccardo Zaccone",
      "Andrea Rizzardi",
      "Debora Caldarola",
      "Marco Ciccone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.12826",
    "title": "OptG: Optimizing Gradient-driven Criteria in Network Sparsity",
    "abstract": " Comments: 11 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2201.12826",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Mengzhao Chen",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02902",
    "title": "Redactor: A Data-centric and Individualized Defense Against Inference  Attacks",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2202.02902",
    "authors": [
      "Geon Heo",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00158",
    "title": "GROW: A Row-Stationary Sparse-Dense GEMM Accelerator for  Memory-Efficient Graph Convolutional Neural Networks",
    "abstract": " Comments: Accepted for publication at the 29th IEEE International Symposium on High-Performance Computer Architecture (HPCA), 2023 ",
    "url": "https://arxiv.org/abs/2203.00158",
    "authors": [
      "Ranggi Hwang",
      "Minhoo Kang",
      "Jiwon Lee",
      "Dongyun Kam",
      "Youngjoo Lee",
      "Minsoo Rhu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.06445",
    "title": "Random Graph Embedding and Joint Sparse Regularization for Multi-label  Feature Selection",
    "abstract": " Comments: 17pages, 7figures, 6tables ",
    "url": "https://arxiv.org/abs/2204.06445",
    "authors": [
      "Haibao Li",
      "Hongzhi Zhai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14310",
    "title": "Approximate Conditional Coverage & Calibration via Neural Model  Approximations",
    "abstract": " Comments: 19 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2205.14310",
    "authors": [
      "Allen Schmaltz",
      "Danielle Rasooly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00362",
    "title": "Retrieval-enhanced Graph Neural Networks for Graph Property Prediction",
    "abstract": " Title: Retrieval-enhanced Graph Neural Networks for Graph Property Prediction ",
    "url": "https://arxiv.org/abs/2206.00362",
    "authors": [
      "Dingmin Wang",
      "Shengchao Liu",
      "Hanchen Wang",
      "Bernardo Cuenca Grau",
      "Linfeng Song",
      "Jian Tang",
      "Song Le",
      "Qi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01888",
    "title": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "abstract": " Title: Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2206.01888",
    "authors": [
      "Young Wu",
      "Jeremy McMahan",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2206.07369",
    "title": "DiffWire: Inductive Graph Rewiring via the Lov\u00e1sz Bound",
    "abstract": " Comments: 27 pages, 24 figures and 6 tables. Accepted at Learning on Graphs Conference 2022. A. Arnaiz-Rodriguez et al., DiffWire: Inductive Graph Rewiring via the Lov\\'asz Bound. Proceedings of the First Learning on Graphs Conference (LoG 2022), PMLR 198, Virtual Event, December, 2022 ",
    "url": "https://arxiv.org/abs/2206.07369",
    "authors": [
      "Adrian Arnaiz-Rodriguez",
      "Ahmed Begga",
      "Francisco Escolano",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.15228",
    "title": "Signed ego network model and its application to Twitter",
    "abstract": " Comments: This work was partially funded by the H2020 SoBigData++ (Grant No 871042), H2020 HumaneAI-Net (Grant No 952026), and CHIST-ERA SAI (Grant No not yet available) projects ",
    "url": "https://arxiv.org/abs/2206.15228",
    "authors": [
      "Jack Tacchi",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.01356",
    "title": "Towards Real-World Video Denosing: A Practical Video Denosing Dataset  and Network",
    "abstract": " Comments: Under submission ",
    "url": "https://arxiv.org/abs/2207.01356",
    "authors": [
      "Xiaogang Xu",
      "Yitong Yu",
      "Nianjuan Jiang",
      "Jiangbo Lu",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09908",
    "title": "Integrated Finite Element Neural Network (I-FENN) for non-local  continuum damage mechanics",
    "abstract": " Title: Integrated Finite Element Neural Network (I-FENN) for non-local  continuum damage mechanics ",
    "url": "https://arxiv.org/abs/2207.09908",
    "authors": [
      "Panos Pantidis",
      "Mostafa E. Mobasher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2208.03523",
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "abstract": " Comments: Accepted at AAAI 2023; Extended version with proofs; 15 pages, 3 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2208.03523",
    "authors": [
      "Davide Bacciu",
      "Alessio Conte",
      "Francesco Landolfi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.13422",
    "title": "Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios",
    "abstract": " Title: Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex  Fire Scenarios ",
    "url": "https://arxiv.org/abs/2208.13422",
    "authors": [
      "Hao Xu",
      "Bo Li",
      "Fei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.13753",
    "title": "Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2208.13753",
    "authors": [
      "Wan-Cyuan Fan",
      "Yen-Chun Chen",
      "Dongdong Chen",
      "Yu Cheng",
      "Lu Yuan",
      "Yu-Chiang Frank Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.14878",
    "title": "Formalising the Robustness of Counterfactual Explanations for Neural  Networks",
    "abstract": " Comments: Accepted at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2208.14878",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.01084",
    "title": "Neighborhood-aware Scalable Temporal Network Representation Learning",
    "abstract": " Comments: Published in LoG 2022 ",
    "url": "https://arxiv.org/abs/2209.01084",
    "authors": [
      "Yuhong Luo",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.11414",
    "title": "Enabling Homogeneous GNNs to Handle Heterogeneous Graphs via Relation  Embedding",
    "abstract": " Title: Enabling Homogeneous GNNs to Handle Heterogeneous Graphs via Relation  Embedding ",
    "url": "https://arxiv.org/abs/2209.11414",
    "authors": [
      "Junfu Wang",
      "Yuanfang Guo",
      "Liang Yang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04017",
    "title": "Enhance Sample Efficiency and Robustness of End-to-end Urban Autonomous  Driving via Semantic Masked World Model",
    "abstract": " Comments: 12 pages, 7 figures, 1 table, accepted by NeurIPS Deep RL Workshop 2022 ",
    "url": "https://arxiv.org/abs/2210.04017",
    "authors": [
      "Zeyu Gao",
      "Yao Mu",
      "Ruoyan Shen",
      "Chen Chen",
      "Yangang Ren",
      "Jianyu Chen",
      "Shengbo Eben Li",
      "Ping Luo",
      "Yanfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04062",
    "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code  Representation Learning",
    "abstract": " Comments: Submitted to ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2210.04062",
    "authors": [
      "Chutong Meng",
      "Junyi Ao",
      "Tom Ko",
      "Mingxuan Wang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.05484",
    "title": "Architectural Optimization over Subgroups for Equivariant Neural  Networks",
    "abstract": " Title: Architectural Optimization over Subgroups for Equivariant Neural  Networks ",
    "url": "https://arxiv.org/abs/2210.05484",
    "authors": [
      "Kaitlin Maile",
      "Dennis G. Wilson",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09211",
    "title": "Conditional Neural Processes for Molecules",
    "abstract": " Title: Conditional Neural Processes for Molecules ",
    "url": "https://arxiv.org/abs/2210.09211",
    "authors": [
      "Miguel Garcia-Ortegon",
      "Andreas Bender",
      "Sergio Bacallado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09723",
    "title": "Textual Entailment Recognition with Semantic Features from Empirical  Text Representation",
    "abstract": " Comments: This paper has been accepted in SPELLL 2022, India. This is the primarily submitted version ",
    "url": "https://arxiv.org/abs/2210.09723",
    "authors": [
      "Md Atabuzzaman",
      "Md Shajalal",
      "Maksuda Bilkis Baby",
      "Md Rezaul Karim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.11068",
    "title": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly  Detection Performance",
    "abstract": " Comments: 5 pages, 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2210.11068",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Won Seok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.12714",
    "title": "Generative Knowledge Graph Construction: A Review",
    "abstract": " Comments: Accepted to EMNLP 2022 (oral) and a public repository is available in this https URL ",
    "url": "https://arxiv.org/abs/2210.12714",
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Hui Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14852",
    "title": "Causality Detection using Multiple Annotation Decisions",
    "abstract": " Title: Causality Detection using Multiple Annotation Decisions ",
    "url": "https://arxiv.org/abs/2210.14852",
    "authors": [
      "Quynh Anh Nguyen",
      "Arka Mitra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.15325",
    "title": "Geodesic packing in graphs",
    "abstract": " Title: Geodesic packing in graphs ",
    "url": "https://arxiv.org/abs/2210.15325",
    "authors": [
      "Paul Manuel",
      "Bostjan Bresar",
      "Sandi Klavzar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2211.00724",
    "title": "Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean  Estimation",
    "abstract": " Comments: 39 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2211.00724",
    "authors": [
      "Kristian Georgiev",
      "Samuel B. Hopkins"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": " Comments: In this version, some related references are added. An explicit proof to Theorem 9 is sketched in the appendix ",
    "url": "https://arxiv.org/abs/2211.05637",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2211.05656",
    "title": "Probabilistically Robust PAC Learning",
    "abstract": " Comments: Added new sections ",
    "url": "https://arxiv.org/abs/2211.05656",
    "authors": [
      "Vinod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.06687",
    "title": "Large-scale Contrastive Language-Audio Pretraining with Feature Fusion  and Keyword-to-Caption Augmentation",
    "abstract": " Title: Large-scale Contrastive Language-Audio Pretraining with Feature Fusion  and Keyword-to-Caption Augmentation ",
    "url": "https://arxiv.org/abs/2211.06687",
    "authors": [
      "Yusong Wu",
      "Ke Chen",
      "Tianyu Zhang",
      "Yuchen Hui",
      "Taylor Berg-Kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.07740",
    "title": "Denoising Diffusion Models for Out-of-Distribution Detection",
    "abstract": " Title: Denoising Diffusion Models for Out-of-Distribution Detection ",
    "url": "https://arxiv.org/abs/2211.07740",
    "authors": [
      "Mark S. Graham",
      "Walter H.L. Pinaya",
      "Petru-Daniel Tudosiu",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10962",
    "title": "PG-Schema: Schemas for Property Graphs",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2211.10962",
    "authors": [
      "Renzo Angles",
      "Angela Bonifati",
      "Stefania Dumbrava",
      "George Fletcher",
      "Alastair Green",
      "Jan Hidders",
      "Bei Li",
      "Leonid Libkin",
      "Victor Marsault",
      "Wim Martens",
      "Filip Murlak",
      "Stefan Plantikow",
      "Ognjen Savkovi\u0107",
      "Michael Schmidt",
      "Juan Sequeda",
      "S\u0142awek Staworko",
      "Dominik Tomaszuk",
      "Hannes Voigt",
      "Domagoj Vrgo\u010d",
      "Mingxi Wu",
      "Du\u0161an \u017divkovi\u0107"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.11478",
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "abstract": " Comments: AAAI Accepted ",
    "url": "https://arxiv.org/abs/2211.11478",
    "authors": [
      "Rui Huang",
      "Ruofei Wang",
      "Qing Guo",
      "Jieda Wei",
      "Yuxiang Zhang",
      "Wei Fan",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11751",
    "title": "Denoising Multi-Similarity Formulation: A Self-paced Curriculum-Driven  Approach for Robust Metric Learning",
    "abstract": " Title: Denoising Multi-Similarity Formulation: A Self-paced Curriculum-Driven  Approach for Robust Metric Learning ",
    "url": "https://arxiv.org/abs/2211.11751",
    "authors": [
      "Chenkang Zhang",
      "Lei Luo",
      "Bin Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.11949",
    "title": "A Reinforcement Learning Approach to Optimize Available Network  Bandwidth Utilization",
    "abstract": " Comments: Submitted to ICC 2023, converted to 12 pages , conference submission was for 7 pages ",
    "url": "https://arxiv.org/abs/2211.11949",
    "authors": [
      "Hasibul Jamil",
      "Elvis Rodrigues",
      "Jacob Goldverg",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2211.11962",
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.11962",
    "authors": [
      "Hai Wu",
      "Chenglu Wen",
      "Wei Li",
      "Xin Li",
      "Ruigang Yang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12006",
    "title": "Differentiable Fuzzy $\\mathcal{ALC}$: A Neural-Symbolic Representation  Language for Symbol Grounding",
    "abstract": " Title: Differentiable Fuzzy $\\mathcal{ALC}$: A Neural-Symbolic Representation  Language for Symbol Grounding ",
    "url": "https://arxiv.org/abs/2211.12006",
    "authors": [
      "Xuan Wu",
      "Xinhao Zhu",
      "Yizheng Zhao",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.12294",
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models  Against Adversarial Examples",
    "abstract": " Comments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2211.12294",
    "authors": [
      "Shengshan Hu",
      "Junwei Zhang",
      "Wei Liu",
      "Junhui Hou",
      "Minghui Li",
      "Leo Yu Zhang",
      "Hai Jin",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.14312",
    "title": "Automated Deep Aberration Detection from Chromosome Karyotype Images",
    "abstract": " Title: Automated Deep Aberration Detection from Chromosome Karyotype Images ",
    "url": "https://arxiv.org/abs/2211.14312",
    "authors": [
      "Zahra Shamsi",
      "Drew Bryant",
      "Jacob Wilson",
      "Xiaoyu Qu",
      "Avinava Dubey",
      "Konik Kothari",
      "Mostafa Dehghani",
      "Mariya Chavarha",
      "Valerii Likhosherstov",
      "Brian Williams",
      "Michael Frumkin",
      "Fred Appelbaum",
      "Krzysztof Choromanski",
      "Ali Bashir",
      "Min Fang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14559",
    "title": "Boosting COVID-19 Severity Detection with Infection-aware Contrastive  Mixup Classification",
    "abstract": " Comments: ECCV AIMIA Workshop 2022 ",
    "url": "https://arxiv.org/abs/2211.14559",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Nan Zhang",
      "Yuejie Zhang",
      "Xiaobo Zhang",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15081",
    "title": "Flip Initial Features: Generalization of Neural Networks for  Semi-supervised Node Classification",
    "abstract": " Title: Flip Initial Features: Generalization of Neural Networks for  Semi-supervised Node Classification ",
    "url": "https://arxiv.org/abs/2211.15081",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15188",
    "title": "Incremental Fourier Neural Operator",
    "abstract": " Title: Incremental Fourier Neural Operator ",
    "url": "https://arxiv.org/abs/2211.15188",
    "authors": [
      "Jiawei Zhao",
      "Robert Joseph George",
      "Yifei Zhang",
      "Zongyi Li",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15601",
    "title": "Fast-SNARF: A Fast Deformer for Articulated Neural Fields",
    "abstract": " Comments: github page: this https URL ",
    "url": "https://arxiv.org/abs/2211.15601",
    "authors": [
      "Xu Chen",
      "Tianjian Jiang",
      "Jie Song",
      "Max Rietmann",
      "Andreas Geiger",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16006",
    "title": "Lie Group Forced Variational Integrator Networks for Learning and  Control of Robot Systems",
    "abstract": " Comments: 21 pages ",
    "url": "https://arxiv.org/abs/2211.16006",
    "authors": [
      "Valentin Duruisseaux",
      "Thai Duong",
      "Melvin Leok",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2211.16401",
    "title": "Sample Complexity for Evaluating the Robust Linear Observers Performance  under Coprime Factors Uncertainty",
    "abstract": " Comments: 19 pages. arXiv admin note: text overlap with arXiv:2109.14164 ",
    "url": "https://arxiv.org/abs/2211.16401",
    "authors": [
      "Yifei Zhang",
      "Sourav Kumar Ukil",
      "Andrei Sperila",
      "Serban Sabau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.16596",
    "title": "Towards Dynamic Causal Discovery with Rare Events: A Nonparametric  Conditional Independence Test",
    "abstract": " Title: Towards Dynamic Causal Discovery with Rare Events: A Nonparametric  Conditional Independence Test ",
    "url": "https://arxiv.org/abs/2211.16596",
    "authors": [
      "Chih-Yuan Chiu",
      "Kshitij Kulkarni",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  }
]