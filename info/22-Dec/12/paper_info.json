[
  {
    "id": "arXiv:2212.04537",
    "title": "Graph Learning Indexer: A Contributor-Friendly and Metadata-Rich  Platform for Graph Learning Benchmarks",
    "abstract": "Establishing open and general benchmarks has been a critical driving force behind the success of modern machine learning techniques. As machine learning is being applied to broader domains and tasks, there is a need to establish richer and more diverse benchmarks to better reflect the reality of the application scenarios. Graph learning is an emerging field of machine learning that urgently needs more and better benchmarks. To accommodate the need, we introduce Graph Learning Indexer (GLI), a benchmark curation platform for graph learning. In comparison to existing graph learning benchmark libraries, GLI highlights two novel design objectives. First, GLI is designed to incentivize \\emph{dataset contributors}. In particular, we incorporate various measures to minimize the effort of contributing and maintaining a dataset, increase the usability of the contributed dataset, as well as encourage attributions to different contributors of the dataset. Second, GLI is designed to curate a knowledge base, instead of a plain collection, of benchmark datasets. We use multiple sources of meta information to augment the benchmark datasets with \\emph{rich characteristics}, so that they can be easily selected and used in downstream research or development. The source code of GLI is available at \\url{https://github.com/Graph-Learning-Benchmarks/gli}. ",
    "url": "https://arxiv.org/abs/2212.04537",
    "authors": [
      "Jiaqi Ma",
      "Xingjian Zhang",
      "Hezheng Fan",
      "Jin Huang",
      "Tianyue Li",
      "Ting Wei Li",
      "Yiwen Tu",
      "Chenshu Zhu",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04540",
    "title": "TinyKG: Memory-Efficient Training Framework for Knowledge Graph Neural  Recommender Systems",
    "abstract": "There has been an explosion of interest in designing various Knowledge Graph Neural Networks (KGNNs), which achieve state-of-the-art performance and provide great explainability for recommendation. The promising performance is mainly resulting from their capability of capturing high-order proximity messages over the knowledge graphs. However, training KGNNs at scale is challenging due to the high memory usage. In the forward pass, the automatic differentiation engines (\\textsl{e.g.}, TensorFlow/PyTorch) generally need to cache all intermediate activation maps in order to compute gradients in the backward pass, which leads to a large GPU memory footprint. Existing work solves this problem by utilizing multi-GPU distributed frameworks. Nonetheless, this poses a practical challenge when seeking to deploy KGNNs in memory-constrained environments, especially for industry-scale graphs. Here we present TinyKG, a memory-efficient GPU-based training framework for KGNNs for the tasks of recommendation. Specifically, TinyKG uses exact activations in the forward pass while storing a quantized version of activations in the GPU buffers. During the backward pass, these low-precision activations are dequantized back to full-precision tensors, in order to compute gradients. To reduce the quantization errors, TinyKG applies a simple yet effective quantization algorithm to compress the activations, which ensures unbiasedness with low variance. As such, the training memory footprint of KGNNs is largely reduced with negligible accuracy loss. To evaluate the performance of our TinyKG, we conduct comprehensive experiments on real-world datasets. We found that our TinyKG with INT2 quantization aggressively reduces the memory footprint of activation maps with $7 \\times$, only with $2\\%$ loss in accuracy, allowing us to deploy KGNNs on memory-constrained devices. ",
    "url": "https://arxiv.org/abs/2212.04540",
    "authors": [
      "Huiyuan Chen",
      "Xiaoting Li",
      "Kaixiong Zhou",
      "Xia Hu",
      "Chin-Chia Michael Yeh",
      "Yan Zheng",
      "Hao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.04546",
    "title": "A Dependable Hybrid Machine Learning Model for Network Intrusion  Detection",
    "abstract": "Network intrusion detection systems (NIDSs) play an important role in computer network security. There are several detection mechanisms where anomaly-based automated detection outperforms others significantly. Amid the sophistication and growing number of attacks, dealing with large amounts of data is a recognized issue in the development of anomaly-based NIDS. However, do current models meet the needs of today's networks in terms of required accuracy and dependability? In this research, we propose a new hybrid model that combines machine learning and deep learning to increase detection rates while securing dependability. Our proposed method ensures efficient pre-processing by combining SMOTE for data balancing and XGBoost for feature selection. We compared our developed method to various machine learning and deep learning algorithms to find a more efficient algorithm to implement in the pipeline. Furthermore, we chose the most effective model for network intrusion based on a set of benchmarked performance analysis criteria. Our method produces excellent results when tested on two datasets, KDDCUP'99 and CIC-MalMem-2022, with an accuracy of 99.99% and 100% for KDDCUP'99 and CIC-MalMem-2022, respectively, and no overfitting or Type-1 and Type-2 issues. ",
    "url": "https://arxiv.org/abs/2212.04546",
    "authors": [
      "Md. Alamin Talukder",
      "Khondokar Fida Hasan",
      "Md. Manowarul Islam",
      "Md Ashraf Uddin",
      "Arnisha Akhter",
      "Mohammand Abu Yousuf",
      "Fares Alharbi",
      "Mohammad Ali Moni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04548",
    "title": "STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow  Prediction",
    "abstract": "Reliable forecasting of traffic flow requires efficient modeling of traffic data. Different correlations and influences arise in a dynamic traffic network, making modeling a complicated task. Existing literature has proposed many different methods to capture the complex underlying spatial-temporal relations of traffic networks. However, methods still struggle to capture different local and global dependencies of long-range nature. Also, as more and more sophisticated methods are being proposed, models are increasingly becoming memory-heavy and, thus, unsuitable for low-powered devices. In this paper, we focus on solving these problems by proposing a novel deep learning framework - STLGRU. Specifically, our proposed STLGRU can effectively capture both local and global spatial-temporal relations of a traffic network using memory-augmented attention and gating mechanism. Instead of employing separate temporal and spatial components, we show that our memory module and gated unit can learn the spatial-temporal dependencies successfully, allowing for reduced memory usage with fewer parameters. We extensively experiment on several real-world traffic prediction datasets to show that our model performs better than existing methods while the memory footprint remains lower. Code is available at \\url{https://github.com/Kishor-Bhaumik/STLGRU}. ",
    "url": "https://arxiv.org/abs/2212.04548",
    "authors": [
      "Kishor Kumar Bhaumik",
      "Fahim Faisal Niloy",
      "Saif Mahmud",
      "Simon Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04551",
    "title": "Efficient Strategies for Graph Pattern Mining Algorithms on GPUs",
    "abstract": "Graph Pattern Mining (GPM) is an important, rapidly evolving, and computation demanding area. GPM computation relies on subgraph enumeration, which consists in extracting subgraphs that match a given property from an input graph. Graphics Processing Units (GPUs) have been an effective platform to accelerate applications in many areas. However, the irregularity of subgraph enumeration makes it challenging for efficient execution on GPU due to typical uncoalesced memory access, divergence, and load imbalance. Unfortunately, these aspects have not been fully addressed in previous work. Thus, this work proposes novel strategies to design and implement subgraph enumeration efficiently on GPU. We support a depth-first search style search (DFS-wide) that maximizes memory performance while providing enough parallelism to be exploited by the GPU, along with a warp-centric design that minimizes execution divergence and improves utilization of the computing capabilities. We also propose a low-cost load balancing layer to avoid idleness and redistribute work among thread warps in a GPU. Our strategies have been deployed in a system named DuMato, which provides a simple programming interface to allow efficient implementation of GPM algorithms. Our evaluation has shown that DuMato is often an order of magnitude faster than state-of-the-art GPM systems and can mine larger subgraphs (up to 12 vertices). ",
    "url": "https://arxiv.org/abs/2212.04551",
    "authors": [
      "Samuel Ferraz",
      "Vinicius Dias",
      "Carlos H. C. Teixeira",
      "George Teodoro",
      "Wagner Meira Jr"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.04584",
    "title": "Explaining Software Bugs Leveraging Code Structures in Neural Machine  Translation",
    "abstract": "Software bugs claim approximately 50% of development time and cost the global economy billions of dollars. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a transformer-based generative model, that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer can leverage structural information and buggy patterns from the source code to generate an explanation for a bug. Our evaluation using three performance metrics shows that Bugsplainer can generate understandable and good explanations according to Google's standard, and can outperform multiple baselines from the literature. We also conduct a developer study involving 20 participants where the explanations from Bugsplainer were found to be more accurate, more precise, more concise and more useful than the baselines. ",
    "url": "https://arxiv.org/abs/2212.04584",
    "authors": [
      "Parvez Mahbub",
      "Ohiduzzaman Shuvo",
      "Mohammad Masudur Rahman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.04592",
    "title": "Time-Synchronized State Estimation Using Graph Neural Networks in  Presence of Topology Changes",
    "abstract": "Recently, there has been a major emphasis on developing data-driven approaches involving machine learning (ML) for high-speed static state estimation (SE) in power systems. The emphasis stems from the ability of ML to overcome difficulties associated with model-based approaches, such as the handling of non-Gaussian measurement noise. However, topology changes pose a stiff challenge for performing ML-based SE because the training and test environments become different when such changes occur. This paper overcomes this challenge by formulating a graph neural network-based time-synchronized state estimator that considers the physical connections of the power system during the training itself. The superiority of the proposed approach over the model-based linear state estimator in the presence of non-Gaussian measurement noise and a regular deep neural network-based state estimator in the presence of topology changes is demonstrated for the IEEE 118-bus system. ",
    "url": "https://arxiv.org/abs/2212.04592",
    "authors": [
      "Shiva Moshtagh",
      "Anwarul Islam Sifat",
      "Behrouz Azimian",
      "Anamitra Pal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.04604",
    "title": "Localized Contrastive Learning on Graphs",
    "abstract": "Contrastive learning methods based on InfoNCE loss are popular in node representation learning tasks on graph-structured data. However, its reliance on data augmentation and its quadratic computational complexity might lead to inconsistency and inefficiency problems. To mitigate these limitations, in this paper, we introduce a simple yet effective contrastive model named Localized Graph Contrastive Learning (Local-GCL in short). Local-GCL consists of two key designs: 1) We fabricate the positive examples for each node directly using its first-order neighbors, which frees our method from the reliance on carefully-designed graph augmentations; 2) To improve the efficiency of contrastive learning on graphs, we devise a kernelized contrastive loss, which could be approximately computed in linear time and space complexity with respect to the graph size. We provide theoretical analysis to justify the effectiveness and rationality of the proposed methods. Experiments on various datasets with different scales and properties demonstrate that in spite of its simplicity, Local-GCL achieves quite competitive performance in self-supervised node representation learning tasks on graphs with various scales and properties. ",
    "url": "https://arxiv.org/abs/2212.04604",
    "authors": [
      "Hengrui Zhang",
      "Qitian Wu",
      "Yu Wang",
      "Shaofeng Zhang",
      "Junchi Yan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04613",
    "title": "Contrastive View Design Strategies to Enhance Robustness to Domain  Shifts in Downstream Object Detection",
    "abstract": "Contrastive learning has emerged as a competitive pretraining method for object detection. Despite this progress, there has been minimal investigation into the robustness of contrastively pretrained detectors when faced with domain shifts. To address this gap, we conduct an empirical study of contrastive learning and out-of-domain object detection, studying how contrastive view design affects robustness. In particular, we perform a case study of the detection-focused pretext task Instance Localization (InsLoc) and propose strategies to augment views and enhance robustness in appearance-shifted and context-shifted scenarios. Amongst these strategies, we propose changes to cropping such as altering the percentage used, adding IoU constraints, and integrating saliency based object priors. We also explore the addition of shortcut-reducing augmentations such as Poisson blending, texture flattening, and elastic deformation. We benchmark these strategies on abstract, weather, and context domain shifts and illustrate robust ways to combine them, in both pretraining on single-object and multi-object image datasets. Overall, our results and insights show how to ensure robustness through the choice of views in contrastive learning. ",
    "url": "https://arxiv.org/abs/2212.04613",
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04632",
    "title": "Category-Level 6D Object Pose Estimation with Flexible Vector-Based  Rotation Representation",
    "abstract": "In this paper, we propose a novel 3D graph convolution based pipeline for category-level 6D pose and size estimation from monocular RGB-D images. The proposed method leverages an efficient 3D data augmentation and a novel vector-based decoupled rotation representation. Specifically, we first design an orientation-aware autoencoder with 3D graph convolution for latent feature learning. The learned latent feature is insensitive to point shift and size thanks to the shift and scale-invariance properties of the 3D graph convolution. Then, to efficiently decode the rotation information from the latent feature, we design a novel flexible vector-based decomposable rotation representation that employs two decoders to complementarily access the rotation information. The proposed rotation representation has two major advantages: 1) decoupled characteristic that makes the rotation estimation easier; 2) flexible length and rotated angle of the vectors allow us to find a more suitable vector representation for specific pose estimation task. Finally, we propose a 3D deformation mechanism to increase the generalization ability of the pipeline. Extensive experiments show that the proposed pipeline achieves state-of-the-art performance on category-level tasks. Further, the experiments demonstrate that the proposed rotation representation is more suitable for the pose estimation tasks than other rotation representations. ",
    "url": "https://arxiv.org/abs/2212.04632",
    "authors": [
      "Wei Chen",
      "Xi Jia",
      "Zhongqun Zhang",
      "Hyung Jin Chang",
      "Linlin Shen",
      "Ales Leonardis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04644",
    "title": "Wasserstein Distributionally Robust Control of Partially Observable  Linear Stochastic Systems",
    "abstract": "Distributionally robust control (DRC) aims to effectively manage distributional ambiguity in stochastic systems. While most existing works address inaccurate distributional information in fully observable settings, we consider a partially observable DRC problem for discrete-time linear systems using the Wasserstein metric. For a tractable solution, we propose a novel approximation method exploiting the Gelbrich bound of Wasserstein distance. Using techniques from modern distributionally robust optimization, we derive a closed-form expression for the optimal control policy and a tractable semidefinite programming problem for the worst-case distribution policy in both finite-horizon and infinite-horizon average-cost settings. The proposed method features several salient theoretical properties, such as a guaranteed cost property and a probabilistic out-of-sample performance guarantee, demonstrating the distributional robustness of our controller. Furthermore, the resulting controller is shown to ensure the closed-loop stability of the mean-state system. The empirical performance of our method is tested through numerical experiments on a power system frequency control problem. ",
    "url": "https://arxiv.org/abs/2212.04644",
    "authors": [
      "Astghik Hakobyan",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.04646",
    "title": "DRIP: Domain Refinement Iteration with Polytopes for Backward  Reachability Analysis of Neural Feedback Loops",
    "abstract": "Safety certification of data-driven control techniques remains a major open problem. This work investigates backward reachability as a framework for providing collision avoidance guarantees for systems controlled by neural network (NN) policies. Because NNs are typically not invertible, existing methods conservatively assume a domain over which to relax the NN, which causes loose over-approximations of the set of states that could lead the system into the obstacle (i.e., backprojection (BP) sets). To address this issue, we introduce DRIP, an algorithm with a refinement loop on the relaxation domain, which substantially tightens the BP set bounds. Furthermore, we introduce a formulation that enables directly obtaining closed-form representations of polytopes to bound the BP sets tighter than prior work, which required solving linear programs and using hyper-rectangles. Furthermore, this work extends the NN relaxation algorithm to handle polytope domains, which further tightens the bounds on BP sets. DRIP is demonstrated in numerical experiments on control systems, including a ground robot controlled by a learned NN obstacle avoidance policy. ",
    "url": "https://arxiv.org/abs/2212.04646",
    "authors": [
      "Michael Everett",
      "Rudy Bunel",
      "Shayegan Omidshafiei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04655",
    "title": "MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video  Prediction",
    "abstract": "The mainstream of the existing approaches for video prediction builds up their models based on a Single-In-Single-Out (SISO) architecture, which takes the current frame as input to predict the next frame in a recursive manner. This way often leads to severe performance degradation when they try to extrapolate a longer period of future, thus limiting the practical use of the prediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that outputs all the future frames at one shot naturally breaks the recursive manner and therefore prevents error accumulation. However, only a few MIMO models for video prediction are proposed and they only achieve inferior performance due to the date. The real strength of the MIMO model in this area is not well noticed and is largely under-explored. Motivated by that, we conduct a comprehensive investigation in this paper to thoroughly exploit how far a simple MIMO architecture can go. Surprisingly, our empirical studies reveal that a simple MIMO model can outperform the state-of-the-art work with a large margin much more than expected, especially in dealing with longterm error accumulation. After exploring a number of ways and designs, we propose a new MIMO architecture based on extending the pure Transformer with local spatio-temporal blocks and a new multi-output decoder, namely MIMO-VP, to establish a new standard in video prediction. We evaluate our model in four highly competitive benchmarks (Moving MNIST, Human3.6M, Weather, KITTI). Extensive experiments show that our model wins 1st place on all the benchmarks with remarkable performance gains and surpasses the best SISO model in all aspects including efficiency, quantity, and quality. We believe our model can serve as a new baseline to facilitate the future research of video prediction tasks. The code will be released. ",
    "url": "https://arxiv.org/abs/2212.04655",
    "authors": [
      "Shuliang Ning",
      "Mengcheng Lan",
      "Yanran Li",
      "Chaofeng Chen",
      "Qian Chen",
      "Xunlai Chen",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04656",
    "title": "Robust Graph Representation Learning via Predictive Coding",
    "abstract": "Predictive coding is a message-passing framework initially developed to model information processing in the brain, and now also topic of research in machine learning due to some interesting properties. One of such properties is the natural ability of generative models to learn robust representations thanks to their peculiar credit assignment rule, that allows neural activities to converge to a solution before updating the synaptic weights. Graph neural networks are also message-passing models, which have recently shown outstanding results in diverse types of tasks in machine learning, providing interdisciplinary state-of-the-art performance on structured data. However, they are vulnerable to imperceptible adversarial attacks, and unfit for out-of-distribution generalization. In this work, we address this by building models that have the same structure of popular graph neural network architectures, but rely on the message-passing rule of predictive coding. Through an extensive set of experiments, we show that the proposed models are (i) comparable to standard ones in terms of performance in both inductive and transductive tasks, (ii) better calibrated, and (iii) robust against multiple kinds of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2212.04656",
    "authors": [
      "Billy Byiringiro",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04661",
    "title": "An Attention-based Multi-Scale Feature Learning Network for Multimodal  Medical Image Fusion",
    "abstract": "Medical images play an important role in clinical applications. Multimodal medical images could provide rich information about patients for physicians to diagnose. The image fusion technique is able to synthesize complementary information from multimodal images into a single image. This technique will prevent radiologists switch back and forth between different images and save lots of time in the diagnostic process. In this paper, we introduce a novel Dilated Residual Attention Network for the medical image fusion task. Our network is capable to extract multi-scale deep semantic features. Furthermore, we propose a novel fixed fusion strategy termed Softmax-based weighted strategy based on the Softmax weights and matrix nuclear norm. Extensive experiments show our proposed network and fusion strategy exceed the state-of-the-art performance compared with reference image fusion methods on four commonly used fusion metrics. ",
    "url": "https://arxiv.org/abs/2212.04661",
    "authors": [
      "Meng Zhou",
      "Xiaolan Xu",
      "Yuxuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04663",
    "title": "Transfer Learning Enhanced DeepONet for Long-Time Prediction of  Evolution Equations",
    "abstract": "Deep operator network (DeepONet) has demonstrated great success in various learning tasks, including learning solution operators of partial differential equations. In particular, it provides an efficient approach to predict the evolution equations in a finite time horizon. Nevertheless, the vanilla DeepONet suffers from the issue of stability degradation in the long-time prediction. This paper proposes a {\\em transfer-learning} aided DeepONet to enhance the stability. Our idea is to use transfer learning to sequentially update the DeepONets as the surrogates for propagators learned in different time frames. The evolving DeepONets can better track the varying complexities of the evolution equations, while only need to be updated by efficient training of a tiny fraction of the operator networks. Through systematic experiments, we show that the proposed method not only improves the long-time accuracy of DeepONet while maintaining similar computational cost but also substantially reduces the sample size of the training set. ",
    "url": "https://arxiv.org/abs/2212.04663",
    "authors": [
      "Wuzhe Xu",
      "Yulong Lu",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.04666",
    "title": "Neural Volume Super-Resolution",
    "abstract": "Neural volumetric representations have become a widely adopted model for radiance fields in 3D scenes. These representations are fully implicit or hybrid function approximators of the instantaneous volumetric radiance in a scene, which are typically learned from multi-view captures of the scene. We investigate the new task of neural volume super-resolution - rendering high-resolution views corresponding to a scene captured at low resolution. To this end, we propose a neural super-resolution network that operates directly on the volumetric representation of the scene. This approach allows us to exploit an advantage of operating in the volumetric domain, namely the ability to guarantee consistent super-resolution across different viewing directions. To realize our method, we devise a novel 3D representation that hinges on multiple 2D feature planes. This allows us to super-resolve the 3D scene representation by applying 2D convolutional networks on the 2D feature planes. We validate the proposed method's capability of super-resolving multi-view consistent views both quantitatively and qualitatively on a diverse set of unseen 3D scenes, demonstrating a significant advantage over existing approaches. ",
    "url": "https://arxiv.org/abs/2212.04666",
    "authors": [
      "Yuval Bahat",
      "Yuxuan Zhang",
      "Hendrik Sommerhoff",
      "Andreas Kolb",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04675",
    "title": "SemanticBEVFusion: Rethink LiDAR-Camera Fusion in Unified Bird's-Eye  View Representation for 3D Object Detection",
    "abstract": "LiDAR and camera are two essential sensors for 3D object detection in autonomous driving. LiDAR provides accurate and reliable 3D geometry information while the camera provides rich texture with color. Despite the increasing popularity of fusing these two complementary sensors, the challenge remains in how to effectively fuse 3D LiDAR point cloud with 2D camera images. Recent methods focus on point-level fusion which paints the LiDAR point cloud with camera features in the perspective view or bird's-eye view (BEV)-level fusion which unifies multi-modality features in the BEV representation. In this paper, we rethink these previous fusion strategies and analyze their information loss and influences on geometric and semantic features. We present SemanticBEVFusion to deeply fuse camera features with LiDAR features in a unified BEV representation while maintaining per-modality strengths for 3D object detection. Our method achieves state-of-the-art performance on the large-scale nuScenes dataset, especially for challenging distant objects. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2212.04675",
    "authors": [
      "Qi Jiang",
      "Hao Sun",
      "Xi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04679",
    "title": "Motion and Context-Aware Audio-Visual Conditioned Video Prediction",
    "abstract": "Existing state-of-the-art method for audio-visual conditioned video prediction uses the latent codes of the audio-visual frames from a multimodal stochastic network and a frame encoder to predict the next visual frame. However, a direct inference of per-pixel intensity for the next visual frame from the latent codes is extremely challenging because of the high-dimensional image space. To this end, we propose to decouple the audio-visual conditioned video prediction into motion and appearance modeling. The first part is the multimodal motion estimation module that learns motion information as optical flow from the given audio-visual clip. The second part is the context-aware refinement module that uses the predicted optical flow to warp the current visual frame into the next visual frame and refines it base on the given audio-visual context. Experimental results show that our method achieves competitive results on existing benchmarks. ",
    "url": "https://arxiv.org/abs/2212.04679",
    "authors": [
      "Yating Xu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04681",
    "title": "AugNet: Dynamic Test-Time Augmentation via Differentiable Functions",
    "abstract": "Distribution shifts, which often occur in the real world, degrade the accuracy of deep learning systems, and thus improving robustness is essential for practical applications. To improve robustness, we study an image enhancement method that generates recognition-friendly images without retraining the recognition model. We propose a novel image enhancement method, AugNet, which is based on differentiable data augmentation techniques and generates a blended image from many augmented images to improve the recognition accuracy under distribution shifts. In addition to standard data augmentations, AugNet can also incorporate deep neural network-based image transformation, which further improves the robustness. Because AugNet is composed of differentiable functions, AugNet can be directly trained with the classification loss of the recognition model. AugNet is evaluated on widely used image recognition datasets using various classification models, including Vision Transformer and MLP-Mixer. AugNet improves the robustness with almost no reduction in classification accuracy for clean images, which is a better result than the existing methods. Furthermore, we show that interpretation of distribution shifts using AugNet and retraining based on that interpretation can greatly improve robustness. ",
    "url": "https://arxiv.org/abs/2212.04681",
    "authors": [
      "Shohei Enomoto",
      "Monikka Roslianna Busto",
      "Takeharu Eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04687",
    "title": "Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of  Backdoor Effects in Trojaned Machine Learning Models",
    "abstract": "In this paper, we present a simple yet surprisingly effective technique to induce \"selective amnesia\" on a backdoored model. Our approach, called SEAM, has been inspired by the problem of catastrophic forgetting (CF), a long standing issue in continual learning. Our idea is to retrain a given DNN model on randomly labeled clean data, to induce a CF on the model, leading to a sudden forget on both primary and backdoor tasks; then we recover the primary task by retraining the randomized model on correctly labeled clean data. We analyzed SEAM by modeling the unlearning process as continual learning and further approximating a DNN using Neural Tangent Kernel for measuring CF. Our analysis shows that our random-labeling approach actually maximizes the CF on an unknown backdoor in the absence of triggered inputs, and also preserves some feature extraction in the network to enable a fast revival of the primary task. We further evaluated SEAM on both image processing and Natural Language Processing tasks, under both data contamination and training manipulation attacks, over thousands of models either trained on popular image datasets or provided by the TrojAI competition. Our experiments show that SEAM vastly outperforms the state-of-the-art unlearning techniques, achieving a high Fidelity (measuring the gap between the accuracy of the primary task and that of the backdoor) within a few minutes (about 30 times faster than training a model from scratch using the MNIST dataset), with only a small amount of clean data (0.1% of training data for TrojAI models). ",
    "url": "https://arxiv.org/abs/2212.04687",
    "authors": [
      "Rui Zhu",
      "Di Tang",
      "Siyuan Tang",
      "XiaoFeng Wang",
      "Haixu Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04688",
    "title": "Comparative Study of Sentiment Analysis for Multi-Sourced Social Media  Platforms",
    "abstract": "There is a vast amount of data generated every second due to the rapidly growing technology in the current world. This area of research attempts to determine the feelings or opinions of people on social media posts. The dataset we used was a multi-source dataset from the comment section of various social networking sites like Twitter, Reddit, etc. Natural Language Processing Techniques were employed to perform sentiment analysis on the obtained dataset. In this paper, we provide a comparative analysis using techniques of lexicon-based, machine learning and deep learning approaches. The Machine Learning algorithm used in this work is Naive Bayes, the Lexicon-based approach used in this work is TextBlob, and the deep-learning algorithm used in this work is LSTM. ",
    "url": "https://arxiv.org/abs/2212.04688",
    "authors": [
      "Keshav Kapur",
      "Rajitha Harikrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04689",
    "title": "Non-equispaced Fourier Neural Solvers for PDEs",
    "abstract": "Solving partial differential equations is difficult. Recently proposed neural resolution-invariant models, despite their effectiveness and efficiency, usually require equispaced spatial points of data. However, sampling in spatial domain is sometimes inevitably non-equispaced in real-world systems, limiting their applicability. In this paper, we propose a Non-equispaced Fourier PDE Solver (\\textsc{NFS}) with adaptive interpolation on resampled equispaced points and a variant of Fourier Neural Operators as its components. Experimental results on complex PDEs demonstrate its advantages in accuracy and efficiency. Compared with the spatially-equispaced benchmark methods, it achieves superior performance with $42.85\\%$ improvements on MAE, and is able to handle non-equispaced data with a tiny loss of accuracy. Besides, to our best knowledge, \\textsc{NFS} is the first ML-based method with mesh invariant inference ability to successfully model turbulent flows in non-equispaced scenarios, with a minor deviation of the error on unseen spatial points. ",
    "url": "https://arxiv.org/abs/2212.04689",
    "authors": [
      "Haitao Lin",
      "Lirong Wu",
      "Yongjie Xu",
      "Yufei Huang",
      "Siyuan Li",
      "Guojiang Zhao",
      "Stan Z",
      "Li Cari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04690",
    "title": "Benchmarking Self-Supervised Learning on Diverse Pathology Datasets",
    "abstract": "Computational pathology can lead to saving human lives, but models are annotation hungry and pathology images are notoriously expensive to annotate. Self-supervised learning has shown to be an effective method for utilizing unlabeled data, and its application to pathology could greatly benefit its downstream tasks. Yet, there are no principled studies that compare SSL methods and discuss how to adapt them for pathology. To address this need, we execute the largest-scale study of SSL pre-training on pathology image data, to date. Our study is conducted using 4 representative SSL methods on diverse downstream tasks. We establish that large-scale domain-aligned pre-training in pathology consistently out-performs ImageNet pre-training in standard SSL settings such as linear and fine-tuning evaluations, as well as in low-label regimes. Moreover, we propose a set of domain-specific techniques that we experimentally show leads to a performance boost. Lastly, for the first time, we apply SSL to the challenging task of nuclei instance segmentation and show large and consistent performance improvements under diverse settings. ",
    "url": "https://arxiv.org/abs/2212.04690",
    "authors": [
      "Mingu Kang",
      "Heon Song",
      "Seonwook Park",
      "Donggeun Yoo",
      "S\u00e9rgio Pereira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04692",
    "title": "Attention in a family of Boltzmann machines emerging from modern  Hopfield networks",
    "abstract": "Hopfield networks and Boltzmann machines (BMs) are fundamental energy-based neural network models. Recent studies on modern Hopfield networks have broaden the class of energy functions and led to a unified perspective on general Hopfield networks including an attention module. In this letter, we consider the BM counterparts of modern Hopfield networks using the associated energy functions, and study their salient properties from a trainability perspective. In particular, the energy function corresponding to the attention module naturally introduces a novel BM, which we refer to as attentional BM (AttnBM). We verify that AttnBM has a tractable likelihood function and gradient for a special case and is easy to train. Moreover, we reveal the hidden connections between AttnBM and some single-layer models, namely the Gaussian--Bernoulli restricted BM and denoising autoencoder with softmax units. We also investigate BMs introduced by other energy functions, and in particular, observe that the energy function of dense associative memory models gives BMs belonging to Exponential Family Harmoniums. ",
    "url": "https://arxiv.org/abs/2212.04692",
    "authors": [
      "Toshihiro Ota",
      "Ryo Karakida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.04701",
    "title": "4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions",
    "abstract": "In this paper, we present a novel and effective framework, named 4K-NeRF, to pursue high fidelity view synthesis on the challenging scenarios of ultra high resolutions, building on the methodology of neural radiance fields (NeRF). The rendering procedure of NeRF-based methods typically relies on a pixel wise manner in which rays (or pixels) are treated independently on both training and inference phases, limiting its representational ability on describing subtle details especially when lifting to a extremely high resolution. We address the issue by better exploring ray correlation for enhancing high-frequency details benefiting from the use of geometry-aware local context. Particularly, we use the view-consistent encoder to model geometric information effectively in a lower resolution space and recover fine details through the view-consistent decoder, conditioned on ray features and depths estimated by the encoder. Joint training with patch-based sampling further facilitates our method incorporating the supervision from perception oriented regularization beyond pixel wise loss. Quantitative and qualitative comparisons with modern NeRF methods demonstrate that our method can significantly boost rendering quality for retaining high-frequency details, achieving the state-of-the-art visual quality on 4K ultra-high-resolution scenario. Code Available at \\url{https://github.com/frozoul/4K-NeRF} ",
    "url": "https://arxiv.org/abs/2212.04701",
    "authors": [
      "Zhongshu Wang",
      "Lingzhi Li",
      "Zhen Shen",
      "Li Shen",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04718",
    "title": "Controllability of complex networks: input node placement restricting  the longest control chain",
    "abstract": "The minimum number of inputs needed to control a network is frequently used to quantify its controllability. Control of linear dynamics through a minimum set of inputs, however, often has prohibitively large energy requirements and there is an inherent trade-off between minimizing the number of inputs and control energy. To better understand this trade-off, we study the problem of identifying a minimum set of input nodes such that controllabililty is ensured while restricting the length of the longest control chain. The longest control chain is the maximum distance from input nodes to any network node, and recent work found that reducing its length significantly reduces control energy. We map the longest control chain-constraint minimum input problem to finding a joint maximum matching and minimum dominating set. We show that this graph combinatorial problem is NP-complete, and we introduce and validate a heuristic approximation. Applying this algorithm to a collection of real and model networks, we investigate how network structure affects the minimum number of inputs, revealing, for example, that for many real networks reducing the longest control chain requires only few or no additional inputs, only the rearrangement of the input nodes. ",
    "url": "https://arxiv.org/abs/2212.04718",
    "authors": [
      "Samie Alizadeh",
      "M\u00e1rton P\u00f3sfai",
      "Abdorasoul Ghasemi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2212.04725",
    "title": "Augmenting Knowledge Transfer across Graphs",
    "abstract": "Given a resource-rich source graph and a resource-scarce target graph, how can we effectively transfer knowledge across graphs and ensure a good generalization performance? In many high-impact domains (e.g., brain networks and molecular graphs), collecting and annotating data is prohibitively expensive and time-consuming, which makes domain adaptation an attractive option to alleviate the label scarcity issue. In light of this, the state-of-the-art methods focus on deriving domain-invariant graph representation that minimizes the domain discrepancy. However, it has recently been shown that a small domain discrepancy loss may not always guarantee a good generalization performance, especially in the presence of disparate graph structures and label distribution shifts. In this paper, we present TRANSNET, a generic learning framework for augmenting knowledge transfer across graphs. In particular, we introduce a novel notion named trinity signal that can naturally formulate various graph signals at different granularity (e.g., node attributes, edges, and subgraphs). With that, we further propose a domain unification module together with a trinity-signal mixup scheme to jointly minimize the domain discrepancy and augment the knowledge transfer across graphs. Finally, comprehensive empirical results show that TRANSNET outperforms all existing approaches on seven benchmark datasets by a significant margin. ",
    "url": "https://arxiv.org/abs/2212.04725",
    "authors": [
      "Yuzhen Mao",
      "Jianhui Sun",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.04726",
    "title": "Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal  Graphs",
    "abstract": "The Subset Feedback Vertex Set problem (SFVS), to delete $k$ vertices from a given graph such that any vertex in a vertex subset (called a terminal set) is not in a cycle in the remaining graph, generalizes the famous Feedback Vertex Set problem and Multiway Cut problem. SFVS remains $\\mathrm{NP}$-hard even in split and chordal graphs, and SFVS in Chordal Graphs can be considered as a special case of the 3-Hitting Set problem. However, it is not easy to solve SFVS in Chordal Graphs faster than 3-Hitting Set. In 2019, Philip, Rajan, Saurabh, and Tale (Algorithmica 2019) proved that SFVS in Chordal Graphs can be solved in $2^k n^{\\mathcal{O}(1)}$, slightly improving the best result $2.076^k n^{\\mathcal{O}(1)}$ for 3-Hitting Set. In this paper, we break the \"$2^k$-barrier\" for SFVS in Chordal Graphs by giving a $1.619^k n^{\\mathcal{O}(1)}$-time algorithm. Our algorithm uses reduction and branching rules based on the Dulmage-Mendelsohn decomposition and a divide-and-conquer method. ",
    "url": "https://arxiv.org/abs/2212.04726",
    "authors": [
      "Tian Bai",
      "Mingyu Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.04734",
    "title": "MED-SE: Medical Entity Definition-based Sentence Embedding",
    "abstract": "We propose Medical Entity Definition-based Sentence Embedding (MED-SE), a novel unsupervised contrastive learning framework designed for clinical texts, which exploits the definitions of medical entities. To this end, we conduct an extensive analysis of multiple sentence embedding techniques in clinical semantic textual similarity (STS) settings. In the entity-centric setting that we have designed, MED-SE achieves significantly better performance, while the existing unsupervised methods including SimCSE show degraded performance. Our experiments elucidate the inherent discrepancies between the general- and clinical-domain texts, and suggest that entity-centric contrastive approaches may help bridge this gap and lead to a better representation of clinical sentences. ",
    "url": "https://arxiv.org/abs/2212.04734",
    "authors": [
      "Hyeonbin Hwang",
      "Haanju Yoo",
      "Yera Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.04739",
    "title": "Lower Bounds for R\u00e9nyi Differential Privacy in a Black-Box Setting",
    "abstract": "We present new methods for assessing the privacy guarantees of an algorithm with regard to R\\'enyi Differential Privacy. To the best of our knowledge, this work is the first to address this problem in a black-box scenario, where only algorithmic outputs are available. To quantify privacy leakage, we devise a new estimator for the R\\'enyi divergence of a pair of output distributions. This estimator is transformed into a statistical lower bound that is proven to hold for large samples with high probability. Our method is applicable for a broad class of algorithms, including many well-known examples from the privacy literature. We demonstrate the effectiveness of our approach by experiments encompassing algorithms and privacy enhancing methods that have not been considered in related works. ",
    "url": "https://arxiv.org/abs/2212.04739",
    "authors": [
      "Tim Kutta",
      "\u00d6nder Askin",
      "Martin Dunsche"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.04747",
    "title": "Reminding Forgetful Organic Neuromorphic Device Networks",
    "abstract": "Organic neuromorphic device networks can accelerate neural network algorithms and directly integrate with microfluidic systems or living tissues. Proposed devices based on the bio-compatible conductive polymer PEDOT:PSS have shown high switching speeds and low energy demand. However, as electrochemical systems, they are prone to self-discharge through parasitic electrochemical reactions. Therefore, the network's synapses forget their trained conductance states over time. This work integrates single-device high-resolution charge transport models to simulate neuromorphic device networks and analyze the impact of self-discharge on network performance. Simulation of a single-layer nine-pixel image classification network reveals no significant impact of self-discharge on training efficiency. And, even though the network's weights drift significantly during self-discharge, its predictions remain 100\\% accurate for over ten hours. On the other hand, a multi-layer network for the approximation of the circle function is shown to degrade significantly over twenty minutes with a final mean-squared-error loss of 0.4. We propose to counter the effect by periodically reminding the network based on a map between a synapse's current state, the time since the last reminder, and the weight drift. We show that this method with a map obtained through validated simulations can reduce the effective loss to below 0.1 even with worst-case assumptions. Finally, while the training of this network is affected by self-discharge, a good classification is still obtained. Electrochemical organic neuromorphic devices have not been integrated into larger device networks. This work predicts their behavior under nonideal conditions, mitigates the worst-case effects of parasitic self-discharge, and opens the path toward implementing fast and efficient neural networks on organic neuromorphic hardware. ",
    "url": "https://arxiv.org/abs/2212.04747",
    "authors": [
      "Daniel Felder",
      "Katerina Muche",
      "John Linkhorst",
      "Matthias Wessling"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.04786",
    "title": "Image-Based Fire Detection in Industrial Environments with YOLOv4",
    "abstract": "Fires have destructive power when they break out and affect their surroundings on a devastatingly large scale. The best way to minimize their damage is to detect the fire as quickly as possible before it has a chance to grow. Accordingly, this work looks into the potential of AI to detect and recognize fires and reduce detection time using object detection on an image stream. Object detection has made giant leaps in speed and accuracy over the last six years, making real-time detection feasible. To our end, we collected and labeled appropriate data from several public sources, which have been used to train and evaluate several models based on the popular YOLOv4 object detector. Our focus, driven by a collaborating industrial partner, is to implement our system in an industrial warehouse setting, which is characterized by high ceilings. A drawback of traditional smoke detectors in this setup is that the smoke has to rise to a sufficient height. The AI models brought forward in this research managed to outperform these detectors by a significant amount of time, providing precious anticipation that could help to minimize the effects of fires further. ",
    "url": "https://arxiv.org/abs/2212.04786",
    "authors": [
      "Otto Zell",
      "Joel P\u00e5lsson",
      "Kevin Hernandez-Diaz",
      "Fernando Alonso-Fernandez",
      "Felix Nilsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04794",
    "title": "Visual Detection of Personal Protective Equipment and Safety Gear on  Industry Workers",
    "abstract": "Workplace injuries are common in today's society due to a lack of adequately worn safety equipment. A system that only admits appropriately equipped personnel can be created to improve working conditions. The goal is thus to develop a system that will improve workers' safety using a camera that will detect the usage of Personal Protective Equipment (PPE). To this end, we collected and labeled appropriate data from several public sources, which have been used to train and evaluate several models based on the popular YOLOv4 object detector. Our focus, driven by a collaborating industrial partner, is to implement our system into an entry control point where workers must present themselves to obtain access to a restricted area. Combined with facial identity recognition, the system would ensure that only authorized people wearing appropriate equipment are granted access. A novelty of this work is that we increase the number of classes to five objects (hardhat, safety vest, safety gloves, safety glasses, and hearing protection), whereas most existing works only focus on one or two classes, usually hardhats or vests. The AI model developed provides good detection accuracy at a distance of 3 and 5 meters in the collaborative environment where we aim at operating (mAP of 99/89%, respectively). The small size of some objects or the potential occlusion by body parts have been identified as potential factors that are detrimental to accuracy, which we have counteracted via data augmentation and cropping of the body before applying PPE detection. ",
    "url": "https://arxiv.org/abs/2212.04794",
    "authors": [
      "Jonathan Karlsson",
      "Fredrik Strand",
      "Josef Bigun",
      "Fernando Alonso-Fernandez",
      "Kevin Hernandez-Diaz",
      "Felix Nilsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04808",
    "title": "CEPHA29: Automatic Cephalometric Landmark Detection Challenge 2023",
    "abstract": "Quantitative cephalometric analysis is the most widely used clinical and research tool in modern orthodontics. Accurate localization of cephalometric landmarks enables the quantification and classification of anatomical abnormalities, however, the traditional manual way of marking these landmarks is a very tedious job. Endeavours have constantly been made to develop automated cephalometric landmark detection systems but they are inadequate for orthodontic applications. The fundamental reason for this is that the amount of publicly available datasets as well as the images provided for training in these datasets are insufficient for an AI model to perform well. To facilitate the development of robust AI solutions for morphometric analysis, we organise the CEPHA29 Automatic Cephalometric Landmark Detection Challenge in conjunction with IEEE International Symposium on Biomedical Imaging (ISBI 2023). In this context, we provide the largest known publicly available dataset, consisting of 1000 cephalometric X-ray images. We hope that our challenge will not only derive forward research and innovation in automatic cephalometric landmark identification but will also signal the beginning of a new era in the discipline. ",
    "url": "https://arxiv.org/abs/2212.04808",
    "authors": [
      "Muhammad Anwaar Khalid",
      "Kanwal Zulfiqar",
      "Ulfat Bashir",
      "Areeba Shaheen",
      "Rida Iqbal",
      "Zarnab Rizwan",
      "Ghina Rizwan",
      "Muhammad Moazam Fraz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04812",
    "title": "Reliable Multimodal Trajectory Prediction via Error Aligned Uncertainty  Optimization",
    "abstract": "Reliable uncertainty quantification in deep neural networks is very crucial in safety-critical applications such as automated driving for trustworthy and informed decision-making. Assessing the quality of uncertainty estimates is challenging as ground truth for uncertainty estimates is not available. Ideally, in a well-calibrated model, uncertainty estimates should perfectly correlate with model error. We propose a novel error aligned uncertainty optimization method and introduce a trainable loss function to guide the models to yield good quality uncertainty estimates aligning with the model error. Our approach targets continuous structured prediction and regression tasks, and is evaluated on multiple datasets including a large-scale vehicle motion prediction task involving real-world distributional shifts. We demonstrate that our method improves average displacement error by 1.69% and 4.69%, and the uncertainty correlation with model error by 17.22% and 19.13% as quantified by Pearson correlation coefficient on two state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2212.04812",
    "authors": [
      "Neslihan Kose",
      "Ranganath Krishnan",
      "Akash Dhamasia",
      "Omesh Tickoo",
      "Michael Paulitsch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04816",
    "title": "DUNE: Improving Accuracy for Sketch-INT Network Measurement Systems",
    "abstract": "In-band Network Telemetry (INT) and sketching algorithms are two promising directions for measuring network traffics in real time. To combine sketch with INT and preserve their advantages, a representative approach is to use INT to send a switch sketch in small pieces (called sketchlets) to end-host for reconstructing an identical sketch. However, in this paper, we reveal that when naively selecting buckets to sketchlets, the end-host reconstructed sketch is inaccurate. To overcome this problem, we present DUNE, an innovative sketch-INT network measurement system. DUNE incorporates two key innovations: First, we design a novel scatter sketchlet that is more efficient in transferring measurement data by allowing a switch to select individual buckets to add to sketchlets; Second, we propose lightweight data structures for tracing \"freshness\" of the sketch buckets, and present algorithms for smartly selecting buckets that contain valuable measurement data to send to end-host. We theoretically prove the effectiveness of our proposed methods, and implement a prototype on commodity programmable switch. The results of extensive experiments driven by real-world traffics on DUNE suggest that our proposed system can substantially improve the measurement accuracy at a trivial cost. ",
    "url": "https://arxiv.org/abs/2212.04816",
    "authors": [
      "Zhongxiang Wei",
      "Ye Tian",
      "Wei Chen",
      "Liyuan Gu",
      "Xinming Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.04818",
    "title": "Parallelism detection using graph labelling",
    "abstract": "Usage of multiprocessor and multicore computers implies parallel programming. Tools for preparing parallel programs include parallel languages and libraries as well as parallelizing compilers and convertors that can perform automatic parallelization. The basic approach for parallelism detection is analysis of data dependencies and properties of program components, including data use and predicates. In this article a suite of used data and predicates sets for program components is proposed and an algorithm for computing these sets is suggested. The algorithm is based on wave propagation on graphs with cycles and labelling. This method allows analyzing complex program components, improving data localization and thus providing enhanced data parallelism detection. ",
    "url": "https://arxiv.org/abs/2212.04818",
    "authors": [
      "Pavel Telegin",
      "Anton Baranov",
      "Boris Shabanov",
      "Artem Tikhomirov"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2212.04819",
    "title": "Phone2Proc: Bringing Robust Robots Into Our Chaotic World",
    "abstract": "Training embodied agents in simulation has become mainstream for the embodied AI community. However, these agents often struggle when deployed in the physical world due to their inability to generalize to real-world environments. In this paper, we present Phone2Proc, a method that uses a 10-minute phone scan and conditional procedural generation to create a distribution of training scenes that are semantically similar to the target environment. The generated scenes are conditioned on the wall layout and arrangement of large objects from the scan, while also sampling lighting, clutter, surface textures, and instances of smaller objects with randomized placement and materials. Leveraging just a simple RGB camera, training with Phone2Proc shows massive improvements from 34.7% to 70.7% success rate in sim-to-real ObjectNav performance across a test suite of over 200 trials in diverse real-world environments, including homes, offices, and RoboTHOR. Furthermore, Phone2Proc's diverse distribution of generated scenes makes agents remarkably robust to changes in the real world, such as human movement, object rearrangement, lighting changes, or clutter. ",
    "url": "https://arxiv.org/abs/2212.04819",
    "authors": [
      "Matt Deitke",
      "Rose Hendrix",
      "Luca Weihs",
      "Ali Farhadi",
      "Kiana Ehsani",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04823",
    "title": "GazeNeRF: 3D-Aware Gaze Redirection with Neural Radiance Fields",
    "abstract": "We propose GazeNeRF, a 3D-aware method for the task of gaze redirection. Existing gaze redirection methods operate on 2D images and struggle to generate 3D consistent results. Instead, we build on the intuition that the face region and eyeballs are separate 3D structures that move in a coordinated yet independent fashion. Our method leverages recent advancements in conditional image-based neural radiance fields and proposes a two-stream architecture that predicts volumetric features for the face and eye regions separately. Rigidly transforming the eye features via a 3D rotation matrix provides fine-grained control over the desired gaze angle. The final, redirected image is then attained via differentiable volume compositing. Our experiments show that this architecture outperforms naively conditioned NeRF baselines as well as previous state-of-the-art 2D gaze redirection methods in terms of redirection accuracy and identity preservation. ",
    "url": "https://arxiv.org/abs/2212.04823",
    "authors": [
      "Alessandro Ruzzi",
      "Xiangwei Shi",
      "Xi Wang",
      "Gengyan Li",
      "Shalini De Mello",
      "Hyung Jin Chang",
      "Xucong Zhang",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04844",
    "title": "Album cover art image generation with Generative Adversarial Networks",
    "abstract": "Generative Adversarial Networks (GANs) were introduced by Goodfellow in 2014, and since then have become popular for constructing generative artificial intelligence models. However, the drawbacks of such networks are numerous, like their longer training times, their sensitivity to hyperparameter tuning, several types of loss and optimization functions and other difficulties like mode collapse. Current applications of GANs include generating photo-realistic human faces, animals and objects. However, I wanted to explore the artistic ability of GANs in more detail, by using existing models and learning from them. This dissertation covers the basics of neural networks and works its way up to the particular aspects of GANs, together with experimentation and modification of existing available models, from least complex to most. The intention is to see if state of the art GANs (specifically StyleGAN2) can generate album art covers and if it is possible to tailor them by genre. This was attempted by first familiarizing myself with 3 existing GANs architectures, including the state of the art StyleGAN2. The StyleGAN2 code was used to train a model with a dataset containing 80K album cover images, then used to style images by picking curated images and mixing their styles. ",
    "url": "https://arxiv.org/abs/2212.04844",
    "authors": [
      "Felipe Perez Stoppa",
      "Ester Vida\u00f1a-Vila",
      "Joan Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.04849",
    "title": "Closed pattern mining of interval data and distributional data",
    "abstract": "We discuss pattern languages for closed pattern mining and learning of interval data and distributional data. We first introduce pattern languages relying on pairs of intersection-based constraints or pairs of inclusion based constraints, or both, applied to intervals. We discuss the encoding of such interval patterns as itemsets thus allowing to use closed itemsets mining and formal concept analysis programs. We experiment these languages on clustering and supervised learning tasks. Then we show how to extend the approach to address distributional data. ",
    "url": "https://arxiv.org/abs/2212.04849",
    "authors": [
      "Henry Soldano",
      "Guillaume Santini",
      "Stella Zevio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04858",
    "title": "Predictor networks and stop-grads provide implicit variance  regularization in BYOL/SimSiam",
    "abstract": "Self-supervised learning (SSL) learns useful representations from unlabelled data by training networks to be invariant to pairs of augmented versions of the same input. Non-contrastive methods avoid collapse either by directly regularizing the covariance matrix of network outputs or through asymmetric loss architectures, two seemingly unrelated approaches. Here, by building on DirectPred, we lay out a theoretical framework that reconciles these two views. We derive analytical expressions for the representational learning dynamics in linear networks. By expressing them in the eigenspace of the embedding covariance matrix, where the solutions decouple, we reveal the mechanism and conditions that provide implicit variance regularization. These insights allow us to formulate a new isotropic loss function that equalizes eigenvalue contribution and renders learning more robust. Finally, we show empirically that our findings translate to nonlinear networks trained on CIFAR-10 and STL-10. ",
    "url": "https://arxiv.org/abs/2212.04858",
    "authors": [
      "Manu Srinath Halvagal",
      "Axel Laborieux",
      "Friedemann Zenke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.04866",
    "title": "Deep Learning of Causal Structures in High Dimensions",
    "abstract": "Recent years have seen rapid progress at the intersection between causality and machine learning. Motivated by scientific applications involving high-dimensional data, in particular in biomedicine, we propose a deep neural architecture for learning causal relationships between variables from a combination of empirical data and prior causal knowledge. We combine convolutional and graph neural networks within a causal risk framework to provide a flexible and scalable approach. Empirical results include linear and nonlinear simulations (where the underlying causal structures are known and can be directly compared against), as well as a real biological example where the models are applied to high-dimensional molecular data and their output compared against entirely unseen validation experiments. These results demonstrate the feasibility of using deep learning approaches to learn causal networks in large-scale problems spanning thousands of variables. ",
    "url": "https://arxiv.org/abs/2212.04866",
    "authors": [
      "Kai Lagemann",
      "Christian Lagemann",
      "Bernd Taschler",
      "Sach Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04869",
    "title": "RCDT: Relational Remote Sensing Change Detection with Transformer",
    "abstract": "Deep learning based change detection methods have received wide attentoion, thanks to their strong capability in obtaining rich features from images. However, existing AI-based CD methods largely rely on three functionality-enhancing modules, i.e., semantic enhancement, attention mechanisms, and correspondence enhancement. The stacking of these modules leads to great model complexity. To unify these three modules into a simple pipeline, we introduce Relational Change Detection Transformer (RCDT), a novel and simple framework for remote sensing change detection tasks. The proposed RCDT consists of three major components, a weight-sharing Siamese Backbone to obtain bi-temporal features, a Relational Cross Attention Module (RCAM) that implements offset cross attention to obtain bi-temporal relation-aware features, and a Features Constrain Module (FCM) to achieve the final refined predictions with high-resolution constraints. Extensive experiments on four different publically available datasets suggest that our proposed RCDT exhibits superior change detection performance compared with other competing methods. The therotical, methodogical, and experimental knowledge of this study is expected to benefit future change detection efforts that involve the cross attention mechanism. ",
    "url": "https://arxiv.org/abs/2212.04869",
    "authors": [
      "Kaixuan Lu",
      "Xiao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04871",
    "title": "Spurious Features Everywhere -- Large-Scale Detection of Harmful  Spurious Features in ImageNet",
    "abstract": "Benchmark performance of deep learning classifiers alone is not a reliable predictor for the performance of a deployed model. In particular, if the image classifier has picked up spurious features in the training data, its predictions can fail in unexpected ways. In this paper, we develop a framework that allows us to systematically identify spurious features in large datasets like ImageNet. It is based on our neural PCA components and their visualization. Previous work on spurious features of image classifiers often operates in toy settings or requires costly pixel-wise annotations. In contrast, we validate our results by checking that presence of the harmful spurious feature of a class is sufficient to trigger the prediction of that class. We introduce a novel dataset \"Spurious ImageNet\" and check how much existing classifiers rely on spurious features. ",
    "url": "https://arxiv.org/abs/2212.04871",
    "authors": [
      "Yannic Neuhaus",
      "Maximilian Augustin",
      "Valentyn Boreiko",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04873",
    "title": "Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition",
    "abstract": "Current methods for few-shot action recognition mainly fall into the metric learning framework following ProtoNet. However, they either ignore the effect of representative prototypes or fail to enhance the prototypes with multimodal information adequately. In this work, we propose a novel Multimodal Prototype-Enhanced Network (MORN) to use the semantic information of label texts as multimodal information to enhance prototypes, including two modality flows. A CLIP visual encoder is introduced in the visual flow, and visual prototypes are computed by the Temporal-Relational CrossTransformer (TRX) module. A frozen CLIP text encoder is introduced in the text flow, and a semantic-enhanced module is used to enhance text features. After inflating, text prototypes are obtained. The final multimodal prototypes are then computed by a multimodal prototype-enhanced module. Besides, there exist no evaluation metrics to evaluate the quality of prototypes. To the best of our knowledge, we are the first to propose a prototype evaluation metric called Prototype Similarity Difference (PRIDE), which is used to evaluate the performance of prototypes in discriminating different categories. We conduct extensive experiments on four popular datasets. MORN achieves state-of-the-art results on HMDB51, UCF101, Kinetics and SSv2. MORN also performs well on PRIDE, and we explore the correlation between PRIDE and accuracy. ",
    "url": "https://arxiv.org/abs/2212.04873",
    "authors": [
      "Xinzhe Ni",
      "Hao Wen",
      "Yong Liu",
      "Yatai Ji",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04880",
    "title": "A Polynomial-Time Algorithm for MCS Partial Search Order on Chordal  Graphs",
    "abstract": "We study the partial search order problem (PSOP) proposed recently by Scheffler [WG 2022]. Given a graph $G$ together with a partial order over the vertices of $G$, this problem determines if there is an $\\mathcal{S}$-ordering that is consistent with the given partial order, where $\\mathcal{S}$ is a graph search paradigm like BFS, DFS, etc. This problem naturally generalizes the end-vertex problem which has received much attention over the past few years. It also generalizes the so-called ${\\mathcal{F}}$-tree recognition problem which has just been studied in the literature recently. Our main contribution is a polynomial-time dynamic programming algorithm for the PSOP on chordal graphs with respect to the maximum cardinality search (MCS). This resolves one of the most intriguing open questions left in the work of Sheffler [WG 2022]. To obtain our result, we propose the notion of layer structure and study numerous related structural properties which might be of independent interest. ",
    "url": "https://arxiv.org/abs/2212.04880",
    "authors": [
      "Guozhen Rong",
      "Yongjie Yang",
      "Wenjun Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2212.04909",
    "title": "CKG: Dynamic Representation Based on Context and Knowledge Graph",
    "abstract": "Recently, neural language representation models pre-trained on large corpus can capture rich co-occurrence information and be fine-tuned in downstream tasks to improve the performance. As a result, they have achieved state-of-the-art results in a large range of language tasks. However, there exists other valuable semantic information such as similar, opposite, or other possible meanings in external knowledge graphs (KGs). We argue that entities in KGs could be used to enhance the correct semantic meaning of language sentences. In this paper, we propose a new method CKG: Dynamic Representation Based on \\textbf{C}ontext and \\textbf{K}nowledge \\textbf{G}raph. On the one side, CKG can extract rich semantic information of large corpus. On the other side, it can make full use of inside information such as co-occurrence in large corpus and outside information such as similar entities in KGs. We conduct extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5, SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA 89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERT$_{Base}$ (88.5). ",
    "url": "https://arxiv.org/abs/2212.04909",
    "authors": [
      "Xunzhu Tang",
      "Tiezhu Sun",
      "Rujie Zhu",
      "Shi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.04934",
    "title": "Learning Graph Algorithms With Recurrent Graph Neural Networks",
    "abstract": "Classical graph algorithms work well for combinatorial problems that can be thoroughly formalized and abstracted. Once the algorithm is derived, it generalizes to instances of any size. However, developing an algorithm that handles complex structures and interactions in the real world can be challenging. Rather than specifying the algorithm, we can try to learn it from the graph-structured data. Graph Neural Networks (GNNs) are inherently capable of working on graph structures; however, they struggle to generalize well, and learning on larger instances is challenging. In order to scale, we focus on a recurrent architecture design that can learn simple graph problems end to end on smaller graphs and then extrapolate to larger instances. As our main contribution, we identify three essential techniques for recurrent GNNs to scale. By using (i) skip connections, (ii) state regularization, and (iii) edge convolutions, we can guide GNNs toward extrapolation. This allows us to train on small graphs and apply the same model to much larger graphs during inference. Moreover, we empirically validate the extrapolation capabilities of our GNNs on algorithmic datasets. ",
    "url": "https://arxiv.org/abs/2212.04934",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04960",
    "title": "BigScience: A Case Study in the Social Construction of a Multilingual  Large Language Model",
    "abstract": "The BigScience Workshop was a value-driven initiative that spanned one and half years of interdisciplinary research and culminated in the creation of ROOTS, a 1.6TB multilingual dataset that was used to train BLOOM, one of the largest multilingual language models to date. In addition to the technical outcomes and artifacts, the workshop fostered multidisciplinary collaborations around large models, datasets, and their analysis. This in turn led to a wide range of research publications spanning topics from ethics to law, data governance, modeling choices and distributed training. This paper focuses on the collaborative research aspects of BigScience and takes a step back to look at the challenges of large-scale participatory research, with respect to participant diversity and the tasks required to successfully carry out such a project. Our main goal is to share the lessons we learned from this experience, what we could have done better and what we did well. We show how the impact of such a social approach to scientific research goes well beyond the technical artifacts that were the basis of its inception. ",
    "url": "https://arxiv.org/abs/2212.04960",
    "authors": [
      "Christopher Akiki",
      "Giada Pistilli",
      "Margot Mieskes",
      "Matthias Gall\u00e9",
      "Thomas Wolf",
      "Suzana Ili\u0107",
      "Yacine Jernite"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2212.04964",
    "title": "PACMAN: a framework for pulse oximeter digit detection and reading in a  low-resource setting",
    "abstract": "In light of the COVID-19 pandemic, patients were required to manually input their daily oxygen saturation (SpO2) and pulse rate (PR) values into a health monitoring system-unfortunately, such a process trend to be an error in typing. Several studies attempted to detect the physiological value from the captured image using optical character recognition (OCR). However, the technology has limited availability with high cost. Thus, this study aimed to propose a novel framework called PACMAN (Pandemic Accelerated Human-Machine Collaboration) with a low-resource deep learning-based computer vision. We compared state-of-the-art object detection algorithms (scaled YOLOv4, YOLOv5, and YOLOR), including the commercial OCR tools for digit recognition on the captured images from pulse oximeter display. All images were derived from crowdsourced data collection with varying quality and alignment. YOLOv5 was the best-performing model against the given model comparison across all datasets, notably the correctly orientated image dataset. We further improved the model performance with the digits auto-orientation algorithm and applied a clustering algorithm to extract SpO2 and PR values. The accuracy performance of YOLOv5 with the implementations was approximately 81.0-89.5%, which was enhanced compared to without any additional implementation. Accordingly, this study highlighted the completion of PACMAN framework to detect and read digits in real-world datasets. The proposed framework has been currently integrated into the patient monitoring system utilized by hospitals nationwide. ",
    "url": "https://arxiv.org/abs/2212.04964",
    "authors": [
      "Chiraphat Boonnag",
      "Wanumaidah Saengmolee",
      "Narongrid Seesawad",
      "Amrest Chinkamol",
      "Saendee Rattanasomrerk",
      "Kanyakorn Veerakanjana",
      "Kamonwan Thanontip",
      "Warissara Limpornchitwilai",
      "Piyalitt Ittichaiwong",
      "Theerawit Wilaiprasitporn"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04966",
    "title": "Towards High-Order Complementary Recommendation via Logical Reasoning  Network",
    "abstract": "Complementary recommendation gains increasing attention in e-commerce since it expedites the process of finding frequently-bought-with products for users in their shopping journey. Therefore, learning the product representation that can reflect this complementary relationship plays a central role in modern recommender systems. In this work, we propose a logical reasoning network, LOGIREC, to effectively learn embeddings of products as well as various transformations (projection, intersection, negation) between them. LOGIREC is capable of capturing the asymmetric complementary relationship between products and seamlessly extending to high-order recommendations where more comprehensive and meaningful complementary relationship is learned for a query set of products. Finally, we further propose a hybrid network that is jointly optimized for learning a more generic product representation. We demonstrate the effectiveness of our LOGIREC on multiple public real-world datasets in terms of various ranking-based metrics under both low-order and high-order recommendation scenarios. ",
    "url": "https://arxiv.org/abs/2212.04966",
    "authors": [
      "Longfeng Wu",
      "Yao Zhou",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04970",
    "title": "Masked Lip-Sync Prediction by Audio-Visual Contextual Exploitation in  Transformers",
    "abstract": "Previous studies have explored generating accurately lip-synced talking faces for arbitrary targets given audio conditions. However, most of them deform or generate the whole facial area, leading to non-realistic results. In this work, we delve into the formulation of altering only the mouth shapes of the target person. This requires masking a large percentage of the original image and seamlessly inpainting it with the aid of audio and reference frames. To this end, we propose the Audio-Visual Context-Aware Transformer (AV-CAT) framework, which produces accurate lip-sync with photo-realistic quality by predicting the masked mouth shapes. Our key insight is to exploit desired contextual information provided in audio and visual modalities thoroughly with delicately designed Transformers. Specifically, we propose a convolution-Transformer hybrid backbone and design an attention-based fusion strategy for filling the masked parts. It uniformly attends to the textural information on the unmasked regions and the reference frame. Then the semantic audio information is involved in enhancing the self-attention computation. Additionally, a refinement network with audio injection improves both image and lip-sync quality. Extensive experiments validate that our model can generate high-fidelity lip-synced results for arbitrary subjects. ",
    "url": "https://arxiv.org/abs/2212.04970",
    "authors": [
      "Yasheng Sun",
      "Hang Zhou",
      "Kaisiyuan Wang",
      "Qianyi Wu",
      "Zhibin Hong",
      "Jingtuo Liu",
      "Errui Ding",
      "Jingdong Wang",
      "Ziwei Liu",
      "Hideki Koike"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.04974",
    "title": "Understanding stock market instability via graph auto-encoders",
    "abstract": "Understanding stock market instability is a key question in financial management as practitioners seek to forecast breakdowns in asset co-movements which expose portfolios to rapid and devastating collapses in value. The structure of these co-movements can be described as a graph where companies are represented by nodes and edges capture correlations between their price movements. Learning a timely indicator of co-movement breakdowns (manifested as modifications in the graph structure) is central in understanding both financial stability and volatility forecasting. We propose to use the edge reconstruction accuracy of a graph auto-encoder (GAE) as an indicator for how spatially homogeneous connections between assets are, which, based on financial network literature, we use as a proxy to infer market volatility. Our experiments on the S&P 500 over the 2015-2022 period show that higher GAE reconstruction error values are correlated with higher volatility. We also show that out-of-sample autoregressive modeling of volatility is improved by the addition of the proposed measure. Our paper contributes to the literature of machine learning in finance particularly in the context of understanding stock market instability. ",
    "url": "https://arxiv.org/abs/2212.04974",
    "authors": [
      "Dragos Gorduza",
      "Xiaowen Dong",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2212.04976",
    "title": "Augmentation Matters: A Simple-yet-Effective Approach to Semi-supervised  Semantic Segmentation",
    "abstract": "Recent studies on semi-supervised semantic segmentation (SSS) have seen fast progress. Despite their promising performance, current state-of-the-art methods tend to increasingly complex designs at the cost of introducing more network components and additional training procedures. Differently, in this work, we follow a standard teacher-student framework and propose AugSeg, a simple and clean approach that focuses mainly on data perturbations to boost the SSS performance. We argue that various data augmentations should be adjusted to better adapt to the semi-supervised scenarios instead of directly applying these techniques from supervised learning. Specifically, we adopt a simplified intensity-based augmentation that selects a random number of data transformations with uniformly sampling distortion strengths from a continuous space. Based on the estimated confidence of the model on different unlabeled samples, we also randomly inject labelled information to augment the unlabeled samples in an adaptive manner. Without bells and whistles, our simple AugSeg can readily achieve new state-of-the-art performance on SSS benchmarks under different partition protocols. ",
    "url": "https://arxiv.org/abs/2212.04976",
    "authors": [
      "Zhen Zhao",
      "Lihe Yang",
      "Sifan Long",
      "Jimin Pi",
      "Luping Zhou",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04983",
    "title": "Adversarial Weight Perturbation Improves Generalization in Graph Neural  Network",
    "abstract": "A lot of theoretical and empirical evidence shows that the flatter local minima tend to improve generalization. Adversarial Weight Perturbation (AWP) is an emerging technique to efficiently and effectively find such minima. In AWP we minimize the loss w.r.t. a bounded worst-case perturbation of the model parameters thereby favoring local minima with a small loss in a neighborhood around them. The benefits of AWP, and more generally the connections between flatness and generalization, have been extensively studied for i.i.d. data such as images. In this paper, we extensively study this phenomenon for graph data. Along the way, we first derive a generalization bound for non-i.i.d. node classification tasks. Then we identify a vanishing-gradient issue with all existing formulations of AWP and we propose a new Weighted Truncated AWP (WT-AWP) to alleviate this issue. We show that regularizing graph neural networks with WT-AWP consistently improves both natural and robust generalization across many different graph learning tasks and models. ",
    "url": "https://arxiv.org/abs/2212.04983",
    "authors": [
      "Yihan Wu",
      "Aleksandar Bojchevski",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04984",
    "title": "Transformer-based normative modelling for anomaly detection of early  schizophrenia",
    "abstract": "Despite the impact of psychiatric disorders on clinical health, early-stage diagnosis remains a challenge. Machine learning studies have shown that classifiers tend to be overly narrow in the diagnosis prediction task. The overlap between conditions leads to high heterogeneity among participants that is not adequately captured by classification models. To address this issue, normative approaches have surged as an alternative method. By using a generative model to learn the distribution of healthy brain data patterns, we can identify the presence of pathologies as deviations or outliers from the distribution learned by the model. In particular, deep generative models showed great results as normative models to identify neurological lesions in the brain. However, unlike most neurological lesions, psychiatric disorders present subtle changes widespread in several brain regions, making these alterations challenging to identify. In this work, we evaluate the performance of transformer-based normative models to detect subtle brain changes expressed in adolescents and young adults. We trained our model on 3D MRI scans of neurotypical individuals (N=1,765). Then, we obtained the likelihood of neurotypical controls and psychiatric patients with early-stage schizophrenia from an independent dataset (N=93) from the Human Connectome Project. Using the predicted likelihood of the scans as a proxy for a normative score, we obtained an AUROC of 0.82 when assessing the difference between controls and individuals with early-stage schizophrenia. Our approach surpassed recent normative methods based on brain age and Gaussian Process, showing the promising use of deep generative models to help in individualised analyses. ",
    "url": "https://arxiv.org/abs/2212.04984",
    "authors": [
      "Pedro F Da Costa",
      "Jessica Dafflon",
      "Sergio Leonardo Mendes",
      "Jo\u00e3o Ricardo Sato",
      "M. Jorge Cardoso",
      "Robert Leech",
      "Emily JH Jones",
      "Walter H.L. Pinaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.04985",
    "title": "Understanding and Combating Robust Overfitting via Input Loss Landscape  Analysis and Regularization",
    "abstract": "Adversarial training is widely used to improve the robustness of deep neural networks to adversarial attack. However, adversarial training is prone to overfitting, and the cause is far from clear. This work sheds light on the mechanisms underlying overfitting through analyzing the loss landscape w.r.t. the input. We find that robust overfitting results from standard training, specifically the minimization of the clean loss, and can be mitigated by regularization of the loss gradients. Moreover, we find that robust overfitting turns severer during adversarial training partially because the gradient regularization effect of adversarial training becomes weaker due to the increase in the loss landscapes curvature. To improve robust generalization, we propose a new regularizer to smooth the loss landscape by penalizing the weighted logits variation along the adversarial direction. Our method significantly mitigates robust overfitting and achieves the highest robustness and efficiency compared to similar previous methods. Code is available at https://github.com/TreeLLi/Combating-RO-AdvLC. ",
    "url": "https://arxiv.org/abs/2212.04985",
    "authors": [
      "Lin Li",
      "Michael Spratling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05009",
    "title": "Scalable Graph Convolutional Network Training on Distributed-Memory  Systems",
    "abstract": "Graph Convolutional Networks (GCNs) are extensively utilized for deep learning on graphs. The large data sizes of graphs and their vertex features make scalable training algorithms and distributed memory systems necessary. Since the convolution operation on graphs induces irregular memory access patterns, designing a memory- and communication-efficient parallel algorithm for GCN training poses unique challenges. We propose a highly parallel training algorithm that scales to large processor counts. In our solution, the large adjacency and vertex-feature matrices are partitioned among processors. We exploit the vertex-partitioning of the graph to use non-blocking point-to-point communication operations between processors for better scalability. To further minimize the parallelization overheads, we introduce a sparse matrix partitioning scheme based on a hypergraph partitioning model for full-batch training. We also propose a novel stochastic hypergraph model to encode the expected communication volume in mini-batch training. We show the merits of the hypergraph model, previously unexplored for GCN training, over the standard graph partitioning model which does not accurately encode the communication costs. Experiments performed on real-world graph datasets demonstrate that the proposed algorithms achieve considerable speedups over alternative solutions. The optimizations achieved on communication costs become even more pronounced at high scalability with many processors. The performance benefits are preserved in deeper GCNs having more layers as well as on billion-scale graphs. ",
    "url": "https://arxiv.org/abs/2212.05009",
    "authors": [
      "Gunduz Vehbi Demirci",
      "Aparajita Haldar",
      "Hakan Ferhatosmanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.05015",
    "title": "Robustness Implies Privacy in Statistical Estimation",
    "abstract": "We study the relationship between adversarial robustness and differential privacy in high-dimensional algorithmic statistics. We give the first black-box reduction from privacy to robustness which can produce private estimators with optimal tradeoffs among sample complexity, accuracy, and privacy for a wide range of fundamental high-dimensional parameter estimation problems, including mean and covariance estimation. We show that this reduction can be implemented in polynomial time in some important special cases. In particular, using nearly-optimal polynomial-time robust estimators for the mean and covariance of high-dimensional Gaussians which are based on the Sum-of-Squares method, we design the first polynomial-time private estimators for these problems with nearly-optimal samples-accuracy-privacy tradeoffs. Our algorithms are also robust to a constant fraction of adversarially-corrupted samples. ",
    "url": "https://arxiv.org/abs/2212.05015",
    "authors": [
      "Samuel B. Hopkins",
      "Gautam Kamath",
      "Mahbod Majid",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.05023",
    "title": "Mesh Neural Networks for SE(3)-Equivariant Hemodynamics Estimation on  the Artery Wall",
    "abstract": "Computational fluid dynamics (CFD) is a valuable asset for patient-specific cardiovascular-disease diagnosis and prognosis, but its high computational demands hamper its adoption in practice. Machine-learning methods that estimate blood flow in individual patients could accelerate or replace CFD simulation to overcome these limitations. In this work, we consider the estimation of vector-valued quantities on the wall of three-dimensional geometric artery models. We employ group-equivariant graph convolution in an end-to-end SE(3)-equivariant neural network that operates directly on triangular surface meshes and makes efficient use of training data. We run experiments on a large dataset of synthetic coronary arteries and find that our method estimates directional wall shear stress (WSS) with an approximation error of 7.6% and normalised mean absolute error (NMAE) of 0.4% while up to two orders of magnitude faster than CFD. Furthermore, we show that our method is powerful enough to accurately predict transient, vector-valued WSS over the cardiac cycle while conditioned on a range of different inflow boundary conditions. These results demonstrate the potential of our proposed method as a plugin replacement for CFD in the personalised prediction of hemodynamic vector and scalar fields. ",
    "url": "https://arxiv.org/abs/2212.05023",
    "authors": [
      "Julian Suk",
      "Pim de Haan",
      "Phillip Lippe",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Group Theory (math.GR)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2212.05031",
    "title": "Towards a learning-based performance modeling for accelerating Deep  Neural Networks",
    "abstract": "Emerging applications such as Deep Learning are often data-driven, thus traditional approaches based on auto-tuners are not performance effective across the wide range of inputs used in practice. In the present paper, we start an investigation of predictive models based on machine learning techniques in order to optimize Convolution Neural Networks (CNNs). As a use-case, we focus on the ARM Compute Library which provides three different implementations of the convolution operator at different numeric precision. Starting from a collation of benchmarks, we build and validate models learned by Decision Tree and naive Bayesian classifier. Preliminary experiments on Midgard-based ARM Mali GPU show that our predictive model outperforms all the convolution operators manually selected by the library. ",
    "url": "https://arxiv.org/abs/2212.05031",
    "authors": [
      "Damiano Perri",
      "Paolo Sylos Labini",
      "Osvaldo Gervasi",
      "Sergio Tasso",
      "Flavio Vella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05033",
    "title": "Mining CryptoNight-Haven on the Varium C1100 Blockchain Accelerator Card",
    "abstract": "Cryptocurrency mining is an energy-intensive process that presents a prime candidate for hardware acceleration. This work-in-progress presents the first coprocessor design for the ASIC-resistant CryptoNight-Haven Proof of Work (PoW) algorithm. We construct our hardware accelerator as a Xilinx Run Time (XRT) RTL kernel targeting the Xilinx Varium C1100 Blockchain Accelerator Card. The design employs deeply pipelined computation and High Bandwidth Memory (HBM) for the underlying scratchpad data. We aim to compare our accelerator to existing CPU and GPU miners to show increased throughput and energy efficiency of its hash computations ",
    "url": "https://arxiv.org/abs/2212.05033",
    "authors": [
      "Lucas Bex",
      "Furkan Turan",
      "Michiel Van Beirendonck",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2212.05037",
    "title": "A Topological Deep Learning Framework for Neural Spike Decoding",
    "abstract": "The brain's spatial orientation system uses different neuron ensembles to aid in environment-based navigation. One of the ways brains encode spatial information is through grid cells, layers of decked neurons that overlay to provide environment-based navigation. These neurons fire in ensembles where several neurons fire at once to activate a single grid. We want to capture this firing structure and use it to decode grid cell data. Understanding, representing, and decoding these neural structures require models that encompass higher order connectivity than traditional graph-based models may provide. To that end, in this work, we develop a topological deep learning framework for neural spike train decoding. Our framework combines unsupervised simplicial complex discovery with the power of deep learning via a new architecture we develop herein called a simplicial convolutional recurrent neural network (SCRNN). Simplicial complexes, topological spaces that use not only vertices and edges but also higher-dimensional objects, naturally generalize graphs and capture more than just pairwise relationships. Additionally, this approach does not require prior knowledge of the neural activity beyond spike counts, which removes the need for similarity measurements. The effectiveness and versatility of the SCRNN is demonstrated on head direction data to test its performance and then applied to grid cell datasets with the task to automatically predict trajectories. ",
    "url": "https://arxiv.org/abs/2212.05037",
    "authors": [
      "Edward C. Mitchell",
      "Brittany Story",
      "David Boothe",
      "Piotr J. Franaszczuk",
      "Vasileios Maroulas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.05039",
    "title": "Incorporating Emotions into Health Mention Classification Task on Social  Media",
    "abstract": "The health mention classification (HMC) task is the process of identifying and classifying mentions of health-related concepts in text. This can be useful for identifying and tracking the spread of diseases through social media posts. However, this is a non-trivial task. Here we build on recent studies suggesting that using emotional information may improve upon this task. Our study results in a framework for health mention classification that incorporates affective features. We present two methods, an intermediate task fine-tuning approach (implicit) and a multi-feature fusion approach (explicit) to incorporate emotions into our target task of HMC. We evaluated our approach on 5 HMC-related datasets from different social media platforms including three from Twitter, one from Reddit and another from a combination of social media sources. Extensive experiments demonstrate that our approach results in statistically significant performance gains on HMC tasks. By using the multi-feature fusion approach, we achieve at least a 3% improvement in F1 score over BERT baselines across all datasets. We also show that considering only negative emotions does not significantly affect performance on the HMC task. Additionally, our results indicate that HMC models infused with emotional knowledge are an effective alternative, especially when other HMC datasets are unavailable for domain-specific fine-tuning. The source code for our models is freely available at https://github.com/tahirlanre/Emotion_PHM. ",
    "url": "https://arxiv.org/abs/2212.05039",
    "authors": [
      "Olanrewaju Tahir Aduragba",
      "Jialin Yu",
      "Alexandra I. Cristea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04532",
    "title": "Framewise WaveGAN: High Speed Adversarial Vocoder in Time Domain with  Very Low Computational Complexity",
    "abstract": "GAN vocoders are currently one of the state-of-the-art methods for building high-quality neural waveform generative models. However, most of their architectures require dozens of billion floating-point operations per second (GFLOPS) to generate speech waveforms in samplewise manner. This makes GAN vocoders still challenging to run on normal CPUs without accelerators or parallel computers. In this work, we propose a new architecture for GAN vocoders that mainly depends on recurrent and fully-connected networks to directly generate the time domain signal in framewise manner. This results in considerable reduction of the computational cost and enables very fast generation on both GPUs and low-complexity CPUs. Experimental results show that our Framewise WaveGAN vocoder achieves significantly higher quality than auto-regressive maximum-likelihood vocoders such as LPCNet at a very low complexity of 1.2 GFLOPS. This makes GAN vocoders more practical on edge and low-power devices. ",
    "url": "https://arxiv.org/abs/2212.04532",
    "authors": [
      "Ahmed Mustafa",
      "Jean-Marc Valin",
      "Jan B\u00fcthe",
      "Paris Smaragdis",
      "Mike Goodwin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.04567",
    "title": "Enhanced prediction accuracy with uncertainty quantification in  monitoring CO2 sequestration using convolutional neural networks",
    "abstract": "Monitoring changes inside a reservoir in real time is crucial for the success of CO2 injection and long-term storage. Machine learning (ML) is well-suited for real-time CO2 monitoring because of its computational efficiency. However, most existing applications of ML yield only one prediction (i.e., the expectation) for a given input, which may not properly reflect the distribution of the testing data, if it has a shift with respect to that of the training data. The Simultaneous Quantile Regression (SQR) method can estimate the entire conditional distribution of the target variable of a neural network via pinball loss. Here, we incorporate this technique into seismic inversion for purposes of CO2 monitoring. The uncertainty map is then calculated pixel by pixel from a particular prediction interval around the median. We also propose a novel data-augmentation method by sampling the uncertainty to further improve prediction accuracy. The developed methodology is tested on synthetic Kimberlina data, which are created by the Department of Energy and based on a CO2 capture and sequestration (CCS) project in California. The results prove that the proposed network can estimate the subsurface velocity rapidly and with sufficient resolution. Furthermore, the computed uncertainty quantifies the prediction accuracy. The method remains robust even if the testing data are distorted due to problems in the field data acquisition. Another test demonstrates the effectiveness of the developed data-augmentation method in increasing the spatial resolution of the estimated velocity field and in reducing the prediction error. ",
    "url": "https://arxiv.org/abs/2212.04567",
    "authors": [
      "Yanhua Liu",
      "Xitong Zhang",
      "Ilya Tsvankin",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04580",
    "title": "Effective Dynamics of Generative Adversarial Networks",
    "abstract": "Generative adversarial networks (GANs) are a class of machine-learning models that use adversarial training to generate new samples with the same (potentially very complex) statistics as the training samples. One major form of training failure, known as mode collapse, involves the generator failing to reproduce the full diversity of modes in the target probability distribution. Here, we present an effective model of GAN training, which captures the learning dynamics by replacing the generator neural network with a collection of particles in the output space; particles are coupled by a universal kernel valid for certain wide neural networks and high-dimensional inputs. The generality of our simplified model allows us to study the conditions under which mode collapse occurs. Indeed, experiments which vary the effective kernel of the generator reveal a mode collapse transition, the shape of which can be related to the type of discriminator through the frequency principle. Further, we find that gradient regularizers of intermediate strengths can optimally yield convergence through critical damping of the generator dynamics. Our effective GAN model thus provides an interpretable physical framework for understanding and improving adversarial training. ",
    "url": "https://arxiv.org/abs/2212.04580",
    "authors": [
      "Steven Durr",
      "Youssef Mroueh",
      "Yuhai Tu",
      "Shenshen Wang"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.04659",
    "title": "A refinement on the structure of vertex-critical ($P_5$, gem)-free  graphs",
    "abstract": "We give a new, stronger proof that there are only finitely many $k$-vertex-critical ($P_5$,~gem)-free graphs for all $k$. Our proof further refines the structure of these graphs and allows for the implementation of a simple exhaustive computer search to completely list all $6$- and $7$-vertex-critical $(P_5$, gem)-free graphs. Our results imply the existence of polynomial-time certifying algorithms to decide the $k$-colourability of $(P_5$, gem)-free graphs for all $k$ where the certificate is either a $k$-colouring or a $(k+1)$-vertex-critical induced subgraph. Our complete lists for $k\\le 7$ allow for the implementation of these algorithms for all $k\\le 6$. ",
    "url": "https://arxiv.org/abs/2212.04659",
    "authors": [
      "Ben Cameron",
      "Ch\u00ednh T. Ho\u00e0ng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.04703",
    "title": "Implementing Neural Network-Based Equalizers in a Coherent Optical  Transmission System Using Field-Programmable Gate Arrays",
    "abstract": "In this work, we demonstrate the offline FPGA realization of both recurrent and feedforward neural network (NN)-based equalizers for nonlinearity compensation in coherent optical transmission systems. First, we present a realization pipeline showing the conversion of the models from Python libraries to the FPGA chip synthesis and implementation. Then, we review the main alternatives for the hardware implementation of nonlinear activation functions. The main results are divided into three parts: a performance comparison, an analysis of how activation functions are implemented, and a report on the complexity of the hardware. The performance in Q-factor is presented for the cases of bidirectional long-short-term memory coupled with convolutional NN (biLSTM + CNN) equalizer, CNN equalizer, and standard 1-StpS digital back-propagation (DBP) for the simulation and experiment propagation of a single channel dual-polarization (SC-DP) 16QAM at 34 GBd along 17x70km of LEAF. The biLSTM+CNN equalizer provides a similar result to DBP and a 1.7 dB Q-factor gain compared with the chromatic dispersion compensation baseline in the experimental dataset. After that, we assess the Q-factor and the impact of hardware utilization when approximating the activation functions of NN using Taylor series, piecewise linear, and look-up table (LUT) approximations. We also show how to mitigate the approximation errors with extra training and provide some insights into possible gradient problems in the LUT approximation. Finally, to evaluate the complexity of hardware implementation to achieve 400G throughput, fixed-point NN-based equalizers with approximated activation functions are developed and implemented in an FPGA. ",
    "url": "https://arxiv.org/abs/2212.04703",
    "authors": [
      "Pedro J. Freire",
      "Sasipim Srivallapanondh",
      "Michael Anderson",
      "Bernhard Spinnler",
      "Thomas Bex",
      "Tobias A. Eriksson",
      "Antonio Napoli",
      "Wolfgang Schairer",
      "Nelson Costa",
      "Michaela Blott",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04749",
    "title": "Validating quantum-supremacy experiments with exact and fast tensor  network contraction",
    "abstract": "The quantum circuits that declare quantum supremacy, such as Google Sycamore [Nature \\textbf{574}, 505 (2019)], raises a paradox in building reliable result references. While simulation on traditional computers seems the sole way to provide reliable verification, the required run time is doomed with an exponentially-increasing compute complexity. To find a way to validate current ``quantum-supremacy\" circuits with more than $50$ qubits, we propose a simulation method that exploits the ``classical advantage\" (the inherent ``store-and-compute\" operation mode of von Neumann machines) of current supercomputers, and computes uncorrelated amplitudes of a random quantum circuit with an optimal reuse of the intermediate results and a minimal memory overhead throughout the process. Such a reuse strategy reduces the original linear scaling of the total compute cost against the number of amplitudes to a sublinear pattern, with greater reduction for more amplitudes. Based on a well-optimized implementation of this method on a new-generation Sunway supercomputer, we directly verify Sycamore by computing three million exact amplitudes for the experimentally generated bitstrings, obtaining an XEB fidelity of $0.191\\%$ which closely matches the estimated value of $0.224\\%$. Our computation scales up to $41,932,800$ cores with a sustained single-precision performance of $84.8$ Pflops, which is accomplished within $8.5$ days. Our method has a far-reaching impact in solving quantum many-body problems, statistical problems as well as combinatorial optimization problems where one often needs to contract many tensor networks which share a significant portion of tensors in common. ",
    "url": "https://arxiv.org/abs/2212.04749",
    "authors": [
      "Yong Liu",
      "Yaojian Chen",
      "Chu Guo",
      "Jiawei Song",
      "Xinmin Shi",
      "Lin Gan",
      "Wenzhao Wu",
      "Wei Wu",
      "Haohuan Fu",
      "Xin Liu",
      "Dexun Chen",
      "Guangwen Yang",
      "Jiangang Gao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.04831",
    "title": "Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian  Mixture Models",
    "abstract": "Single-channel deep speech enhancement approaches often estimate a single multiplicative mask to extract clean speech without a measure of its accuracy. Instead, in this work, we propose to quantify the uncertainty associated with clean speech estimates in neural network-based speech enhancement. Predictive uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former accounts for the inherent uncertainty in data and the latter corresponds to the model uncertainty. Aiming for robust clean speech estimation and efficient predictive uncertainty quantification, we propose to integrate statistical complex Gaussian mixture models (CGMMs) into a deep speech enhancement framework. More specifically, we model the dependency between input and output stochastically by means of a conditional probability density and train a neural network to map the noisy input to the full posterior distribution of clean speech, modeled as a mixture of multiple complex Gaussian components. Experimental results on different datasets show that the proposed algorithm effectively captures predictive uncertainty and that combining powerful statistical models and deep learning also delivers a superior speech enhancement performance. ",
    "url": "https://arxiv.org/abs/2212.04831",
    "authors": [
      "Huajian Fang",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2212.04832",
    "title": "Noise2Contrast: Multi-Contrast Fusion Enables Self-Supervised  Tomographic Image Denoising",
    "abstract": "Self-supervised image denoising techniques emerged as convenient methods that allow training denoising models without requiring ground-truth noise-free data. Existing methods usually optimize loss metrics that are calculated from multiple noisy realizations of similar images, e.g., from neighboring tomographic slices. However, those approaches fail to utilize the multiple contrasts that are routinely acquired in medical imaging modalities like MRI or dual-energy CT. In this work, we propose the new self-supervised training scheme Noise2Contrast that combines information from multiple measured image contrasts to train a denoising model. We stack denoising with domain-transfer operators to utilize the independent noise realizations of different image contrasts to derive a self-supervised loss. The trained denoising operator achieves convincing quantitative and qualitative results, outperforming state-of-the-art self-supervised methods by 4.7-11.0%/4.8-7.3% (PSNR/SSIM) on brain MRI data and by 43.6-50.5%/57.1-77.1% (PSNR/SSIM) on dual-energy CT X-ray microscopy data with respect to the noisy baseline. Our experiments on different real measured data sets indicate that Noise2Contrast training generalizes to other multi-contrast imaging modalities. ",
    "url": "https://arxiv.org/abs/2212.04832",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Laura Pfaff",
      "Noah Maul",
      "Sabrina Pechmann",
      "Mingxuan Gu",
      "Jonas Utz",
      "Oliver Aust",
      "Daniela Weidner",
      "Georgiana Neag",
      "Stefan Uderhardt",
      "Jang-Hwan Choi",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04881",
    "title": "ProductGraphSleepNet: Sleep Staging using Product Spatio-Temporal Graph  Learning with Attentive Temporal Aggregation",
    "abstract": "The classification of sleep stages plays a crucial role in understanding and diagnosing sleep pathophysiology. Sleep stage scoring relies heavily on visual inspection by an expert that is time consuming and subjective procedure. Recently, deep learning neural network approaches have been leveraged to develop a generalized automated sleep staging and account for shifts in distributions that may be caused by inherent inter/intra-subject variability, heterogeneity across datasets, and different recording environments. However, these networks ignore the connections among brain regions, and disregard the sequential connections between temporally adjacent sleep epochs. To address these issues, this work proposes an adaptive product graph learning-based graph convolutional network, named ProductGraphSleepNet, for learning joint spatio-temporal graphs along with a bidirectional gated recurrent unit and a modified graph attention network to capture the attentive dynamics of sleep stage transitions. Evaluation on two public databases: the Montreal Archive of Sleep Studies (MASS) SS3; and the SleepEDF, which contain full night polysomnography recordings of 62 and 20 healthy subjects, respectively, demonstrates performance comparable to the state-of-the-art (Accuracy: 0.867;0.838, F1-score: 0.818;0.774 and Kappa: 0.802;0.775, on each database respectively). More importantly, the proposed network makes it possible for clinicians to comprehend and interpret the learned connectivity graphs for sleep stages. ",
    "url": "https://arxiv.org/abs/2212.04881",
    "authors": [
      "Aref Einizade",
      "Samaneh Nasiri",
      "Sepideh Hajipour Sardouie",
      "Gari Clifford"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04902",
    "title": "Self-Supervised PPG Representation Learning Shows High Inter-Subject  Variability",
    "abstract": "With the progress of sensor technology in wearables, the collection and analysis of PPG signals are gaining more interest. Using Machine Learning, the cardiac rhythm corresponding to PPG signals can be used to predict different tasks such as activity recognition, sleep stage detection, or more general health status. However, supervised learning is often limited by the amount of available labeled data, which is typically expensive to obtain. To address this problem, we propose a Self-Supervised Learning (SSL) method with a pretext task of signal reconstruction to learn an informative generalized PPG representation. The performance of the proposed SSL framework is compared with two fully supervised baselines. The results show that in a very limited label data setting (10 samples per class or less), using SSL is beneficial, and a simple classifier trained on SSL-learned representations outperforms fully supervised deep neural networks. However, the results reveal that the SSL-learned representations are too focused on encoding the subjects. Unfortunately, there is high inter-subject variability in the SSL-learned representations, which makes working with this data more challenging when labeled data is scarce. The high inter-subject variability suggests that there is still room for improvements in learning representations. In general, the results suggest that SSL may pave the way for the broader use of machine learning models on PPG data in label-scarce regimes. ",
    "url": "https://arxiv.org/abs/2212.04902",
    "authors": [
      "Ramin Ghorbani",
      "Marcel T.J. Reinders",
      "David M.J. Tax"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04905",
    "title": "Robust detection and attribution of climate change under interventions",
    "abstract": "Fingerprints are key tools in climate change detection and attribution (D&A) that are used to determine whether changes in observations are different from internal climate variability (detection), and whether observed changes can be assigned to specific external drivers (attribution). We propose a direct D&A approach based on supervised learning to extract fingerprints that lead to robust predictions under relevant interventions on exogenous variables, i.e., climate drivers other than the target. We employ anchor regression, a distributionally-robust statistical learning method inspired by causal inference that extrapolates well to perturbed data under the interventions considered. The residuals from the prediction achieve either uncorrelatedness or mean independence with the exogenous variables, thus guaranteeing robustness. We define D&A as a unified hypothesis testing framework that relies on the same statistical model but uses different targets and test statistics. In the experiments, we first show that the CO2 forcing can be robustly predicted from temperature spatial patterns under strong interventions on the solar forcing. Second, we illustrate attribution to the greenhouse gases and aerosols while protecting against interventions on the aerosols and CO2 forcing, respectively. Our study shows that incorporating robustness constraints against relevant interventions may significantly benefit detection and attribution of climate change. ",
    "url": "https://arxiv.org/abs/2212.04905",
    "authors": [
      "Enik\u0151 Sz\u00e9kely",
      "Sebastian Sippel",
      "Nicolai Meinshausen",
      "Guillaume Obozinski",
      "Reto Knutti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2212.04922",
    "title": "Doubly Robust Kernel Statistics for Testing Distributional Treatment  Effects Even Under One Sided Overlap",
    "abstract": "As causal inference becomes more widespread the importance of having good tools to test for causal effects increases. In this work we focus on the problem of testing for causal effects that manifest in a difference in distribution for treatment and control. We build on work applying kernel methods to causality, considering the previously introduced Counterfactual Mean Embedding framework (\\textsc{CfME}). We improve on this by proposing the \\emph{Doubly Robust Counterfactual Mean Embedding} (\\textsc{DR-CfME}), which has better theoretical properties than its predecessor by leveraging semiparametric theory. This leads us to propose new kernel based test statistics for distributional effects which are based upon doubly robust estimators of treatment effects. We propose two test statistics, one which is a direct improvement on previous work and one which can be applied even when the support of the treatment arm is a subset of that of the control arm. We demonstrate the validity of our methods on simulated and real-world data, as well as giving an application in off-policy evaluation. ",
    "url": "https://arxiv.org/abs/2212.04922",
    "authors": [
      "Jake Fawkes",
      "Robert Hu",
      "Robin J. Evans",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04928",
    "title": "P2T2: a Physically-primed deep-neural-network approach for robust  $T_{2}$ distribution estimation from quantitative $T_{2}$-weighted MRI",
    "abstract": "Estimation of the T2 distribution from multi-echo T2-Weighted MRI (T2W) data can provide insight into the microscopic content of tissue using macroscopic imaging. This information can be used as a biomarker for several pathologies, such as tumor characterization, osteoarthritis, and neurodegenerative diseases. Recently, deep neural network (DNN) based methods were proposed for T2 distribution estimation from MRI data. However, these methods are highly sensitive to distribution shifts such as variations in the echo-times (TE) used during acquisition. Therefore, DNN-based methods cannot be utilized in large-scale multi-institutional trials with heterogeneous acquisition protocols. We present P2T2, a new physically-primed DNN approach for T2 distribution estimation that is robust to different acquisition parameters while maintaining state-of-the-art estimation accuracy. Our P2T2 model encodes the forward model of the signal decay by taking as input the TE acquisition array, in addition to the MRI signal, and provides an estimate of the corresponding T2 distribution as its output. Our P2T2 model has improved the robustness against distribution shifts in the acquisition process by more than 50% compared to the previously proposed DNN model. When tested without any distribution shifts, our model achieved about the same accuracy. Finally, when applied to real human MRI data, our P2T2 model produced the most detailed Myelin-Water fraction maps compared to both the MIML model and classical approaches. Our proposed physically-primed approach improved the generalization capacity of DNN models for T2 distribution estimation and their robustness against distribution shifts compared to previous approaches without compromising the accuracy. ",
    "url": "https://arxiv.org/abs/2212.04928",
    "authors": [
      "Hadas Ben-Atya",
      "Moti Freiman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04938",
    "title": "Emergent Computations in Trained Artificial Neural Networks and Real  Brains",
    "abstract": "Synaptic plasticity allows cortical circuits to learn new tasks and to adapt to changing environments. How do cortical circuits use plasticity to acquire functions such as decision-making or working memory? Neurons are connected in complex ways, forming recurrent neural networks, and learning modifies the strength of their connections. Moreover, neurons communicate emitting brief discrete electric signals. Here we describe how to train recurrent neural networks in tasks like those used to train animals in neuroscience laboratories, and how computations emerge in the trained networks. Surprisingly, artificial networks and real brains can use similar computational strategies. ",
    "url": "https://arxiv.org/abs/2212.04938",
    "authors": [
      "Nestor Parga",
      "Luis Serrano-Fernandez",
      "Joan Falco-Roget"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1904.12060",
    "title": "Every planar graph with $\u0394\\geqslant 8$ is totally  $(\u0394+2)$-choosable",
    "abstract": " Comments: 64 pages, 77 figures ",
    "url": "https://arxiv.org/abs/1904.12060",
    "authors": [
      "Marthe Bonamy",
      "Th\u00e9o Pierron",
      "\u00c9ric Sopena"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2009.10353",
    "title": "Complexity and Approximation for Discriminating and Identifying Code  Problems in Geometric Setups",
    "abstract": " Title: Complexity and Approximation for Discriminating and Identifying Code  Problems in Geometric Setups ",
    "url": "https://arxiv.org/abs/2009.10353",
    "authors": [
      "Sanjana Dey",
      "Florent Foucaud",
      "Subhas C Nandy",
      "Arunabha Sen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2111.01528",
    "title": "Effective and Imperceptible Adversarial Textual Attack via  Multi-objectivization",
    "abstract": " Title: Effective and Imperceptible Adversarial Textual Attack via  Multi-objectivization ",
    "url": "https://arxiv.org/abs/2111.01528",
    "authors": [
      "Shengcai Liu",
      "Ning Lu",
      "Wenjing Hong",
      "Chao Qian",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.12379",
    "title": "Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks",
    "abstract": " Title: Efficient Anomaly Detection Using Self-Supervised Multi-Cue Tasks ",
    "url": "https://arxiv.org/abs/2111.12379",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.05395",
    "title": "De Rham compatible Deep Neural Network FEM",
    "abstract": " Title: De Rham compatible Deep Neural Network FEM ",
    "url": "https://arxiv.org/abs/2201.05395",
    "authors": [
      "Marcello Longo",
      "Joost A. A. Opschoor",
      "Nico Disch",
      "Christoph Schwab",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.06552",
    "title": "Neural Vector Fields for Implicit Surface Representation and Inference",
    "abstract": " Title: Neural Vector Fields for Implicit Surface Representation and Inference ",
    "url": "https://arxiv.org/abs/2204.06552",
    "authors": [
      "Edoardo Mello Rella",
      "Ajad Chhatkuli",
      "Ender Konukoglu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.04099",
    "title": "Robustness of double-layer group-dependent combat network with cascading  failure",
    "abstract": " Title: Robustness of double-layer group-dependent combat network with cascading  failure ",
    "url": "https://arxiv.org/abs/2205.04099",
    "authors": [
      "Jintao Yu",
      "Bing Xiao",
      "Yuzhu Cui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.05419",
    "title": "Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of  Neural Features",
    "abstract": " Title: Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of  Neural Features ",
    "url": "https://arxiv.org/abs/2205.05419",
    "authors": [
      "Marisa Bernabeu",
      "Antonio Javier Gallego",
      "Antonio Pertusa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.08794",
    "title": "LogiGAN: Learning Logical Reasoning via Adversarial Pre-training",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.08794",
    "authors": [
      "Xinyu Pi",
      "Wanjun Zhong",
      "Yan Gao",
      "Nan Duan",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.10583",
    "title": "Automated Repair of Code from Language Models",
    "abstract": " Comments: 12 pages, To appear in ICSE 2023 ",
    "url": "https://arxiv.org/abs/2205.10583",
    "authors": [
      "Zhiyu Fan",
      "Xiang Gao",
      "Martin Mirchev",
      "Abhik Roychoudhury",
      "Shin Hwei Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2206.00798",
    "title": "Multi-scale frequency separation network for image deblurring",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2206.00798",
    "authors": [
      "Yanni Zhang",
      "Qiang Li",
      "Miao Qi",
      "Di Liu",
      "Jun Kong",
      "Jianzhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09031",
    "title": "Decorrelative Network Architecture for Robust Electrocardiogram  Classification",
    "abstract": " Comments: 16 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2207.09031",
    "authors": [
      "Christopher Wiedeman",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Singularly Perturbed  Partial Differential Equations",
    "abstract": " Comments: 16 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2207.10241",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.07009",
    "title": "Copula-based analysis of the generalized friendship paradox in clustered  networks",
    "abstract": " Comments: 9 pages, 3 figures. arXiv admin note: text overlap with arXiv:2107.05838 ",
    "url": "https://arxiv.org/abs/2208.07009",
    "authors": [
      "Hang-Hyun Jo",
      "Eun Lee",
      "Young-Ho Eom"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2208.12681",
    "title": "Disentangle and Remerge: Interventional Knowledge Distillation for  Few-Shot Object Detection from A Conditional Causal Perspective",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2208.12681",
    "authors": [
      "Jiangmeng Li",
      "Yanan Zhang",
      "Wenwen Qiang",
      "Lingyu Si",
      "Chengbo Jiao",
      "Xiaohui Hu",
      "Changwen Zheng",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.00283",
    "title": "Conditional graph entropy as an alternating minimization problem",
    "abstract": " Title: Conditional graph entropy as an alternating minimization problem ",
    "url": "https://arxiv.org/abs/2209.00283",
    "authors": [
      "Viktor Harangi",
      "Xueyan Niu",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2209.01816",
    "title": "ADTR: Anomaly Detection Transformer with Feature Reconstruction",
    "abstract": " Comments: Accepted by ICONIP 2022 ",
    "url": "https://arxiv.org/abs/2209.01816",
    "authors": [
      "Zhiyuan You",
      "Kai Yang",
      "Wenhan Luo",
      "Lei Cui",
      "Yu Zheng",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.07902",
    "title": "MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning",
    "abstract": " Comments: Accepted by NeurIPS 2022 as Spotlight ",
    "url": "https://arxiv.org/abs/2209.07902",
    "authors": [
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Yanan Zhang",
      "Wenyi Mo",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11672",
    "title": "MiCellAnnGELo: Annotate microscopy time series of complex cell surfaces  with 3D Virtual Reality",
    "abstract": " Comments: For associated code and sample data, see this https URL ",
    "url": "https://arxiv.org/abs/2209.11672",
    "authors": [
      "Adam Platt",
      "E. Josiah Lutton",
      "Edward Offord",
      "Till Bretschneider"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.01703",
    "title": "Improving Label-Deficient Keyword Spotting Using Self-Supervised  Pretraining",
    "abstract": " Comments: 8 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2210.01703",
    "authors": [
      "Holger Severin Bovbjerg",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.15996",
    "title": "Towards Few-Shot Open-Set Object Detection",
    "abstract": " Title: Towards Few-Shot Open-Set Object Detection ",
    "url": "https://arxiv.org/abs/2210.15996",
    "authors": [
      "Binyi Su",
      "Hua Zhang",
      "Jingzhi Li",
      "Zhong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.05627",
    "title": "Representing LLVM-IR in a Code Property Graph",
    "abstract": " Title: Representing LLVM-IR in a Code Property Graph ",
    "url": "https://arxiv.org/abs/2211.05627",
    "authors": [
      "Alexander K\u00fcchler",
      "Christian Banse"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2211.05656",
    "title": "Probabilistically Robust PAC Learning",
    "abstract": " Comments: Organized sections + added new content ",
    "url": "https://arxiv.org/abs/2211.05656",
    "authors": [
      "Vinod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.07208",
    "title": "A Lego-Brick Approach to Coding for Network Communication",
    "abstract": " Title: A Lego-Brick Approach to Coding for Network Communication ",
    "url": "https://arxiv.org/abs/2211.07208",
    "authors": [
      "Nadim Ghaddar",
      "Shouvik Ganguly",
      "Lele Wang",
      "Young-Han Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.10011",
    "title": "Structural Quality Metrics to Evaluate Knowledge Graphs",
    "abstract": " Title: Structural Quality Metrics to Evaluate Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2211.10011",
    "authors": [
      "Sumin Seo",
      "Heeseon Cheon",
      "Hyunho Kim",
      "Dongseok Hyun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.10556",
    "title": "A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems",
    "abstract": " Title: A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems ",
    "url": "https://arxiv.org/abs/2211.10556",
    "authors": [
      "Julia Chuzhoy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.14794",
    "title": "Traditional Classification Neural Networks are Good Generators: They are  Competitive with DDPMs and GANs",
    "abstract": " Comments: This paper has 29 pages with 22 figures, including rich supplementary information. Project page is at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2211.14794",
    "authors": [
      "Guangrun Wang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.14939",
    "title": "Applying Deep Reinforcement Learning to the HP Model for Protein  Structure Prediction",
    "abstract": " Comments: Published at Physica A: Statistical Mechanics and its Applications, available online 7 December 2022. Extended abstract accepted by the Machine Learning and the Physical Sciences workshop, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2211.14939",
    "authors": [
      "Kaiyuan Yang",
      "Houjing Huang",
      "Olafs Vandans",
      "Adithya Murali",
      "Fujia Tian",
      "Roland H.C. Yap",
      "Liang Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2211.16494",
    "title": "On the Ability of Graph Neural Networks to Model Interactions Between  Vertices",
    "abstract": " Title: On the Ability of Graph Neural Networks to Model Interactions Between  Vertices ",
    "url": "https://arxiv.org/abs/2211.16494",
    "authors": [
      "Noam Razin",
      "Tom Verbin",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.16676",
    "title": "Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties",
    "abstract": " Title: Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties ",
    "url": "https://arxiv.org/abs/2211.16676",
    "authors": [
      "Iman Salehi",
      "Ghananeel Rotithor",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00921",
    "title": "AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization",
    "abstract": " Title: AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization ",
    "url": "https://arxiv.org/abs/2212.00921",
    "authors": [
      "Bhargavi Paranjape",
      "Pradeep Dasigi",
      "Vivek Srikumar",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.01098",
    "title": "RGB-D-based Stair Detection using Deep Learning for Autonomous Stair  Climbing",
    "abstract": " Title: RGB-D-based Stair Detection using Deep Learning for Autonomous Stair  Climbing ",
    "url": "https://arxiv.org/abs/2212.01098",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.03496",
    "title": "A Generative Approach for Script Event Prediction via Contrastive  Fine-tuning",
    "abstract": " Title: A Generative Approach for Script Event Prediction via Contrastive  Fine-tuning ",
    "url": "https://arxiv.org/abs/2212.03496",
    "authors": [
      "Fangqi Zhu",
      "Jun Gao",
      "Changlong Yu",
      "Wei Wang",
      "Chen Xu",
      "Xin Mu",
      "Min Yang",
      "Ruifeng Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.04419",
    "title": "Mining Explainable Predictive Features for Water Quality Management",
    "abstract": " Title: Mining Explainable Predictive Features for Water Quality Management ",
    "url": "https://arxiv.org/abs/2212.04419",
    "authors": [
      "Conor Muldoon",
      "Levent G\u00f6rg\u00fc",
      "John J. O'Sullivan",
      "Wim G. Meijer",
      "Gregory M. P. O'Hare"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  }
]