[
  {
    "id": "arXiv:2212.00798",
    "title": "Pre-training strategy for solving evolution equations based on  physics-informed neural networks",
    "abstract": "The physics informed neural network (PINN) is a promising method for solving time-evolution partial differential equations (PDEs). However, the standard PINN method may fail to solve the PDEs with strongly nonlinear characteristics or those with high-frequency solutions. The physics informed neural network (PINN) is a promising method for solving time-evolution partial differential equations (PDEs). However, the standard PINN method may fail to solve the PDEs with strongly nonlinear characteristics or those with high-frequency solutions. The PT-PINN method transforms the difficult problem on the entire time domain to relatively simple problems defined on small subdomains. The neural network trained on small subdomains provides the neural network initialization and extra supervised learning data for the problems on larger subdomains or on the entire time-domain. By numerical experiments, we demonstrate that the PT-PINN succeeds in solving the evolution PDEs with strong non-linearity and/or high frequency solutions, including the strongly nonlinear heat equation, the Allen-Cahn equation, the convection equation with high-frequency solutions and so on, and that the convergence and accuracy of the PT-PINN is superior to the standard PINN method. The PT-PINN method is a competitive method for solving the time-evolution PDEs. ",
    "url": "https://arxiv.org/abs/2212.00798",
    "authors": [
      "Jiawei Guo",
      "Yanzhong Yao",
      "Han Wang",
      "Tongxiang Gu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.00827",
    "title": "Architectural Implications of Embedding Dimension during GCN on CPU and  GPU",
    "abstract": "Graph Neural Networks (GNNs) are a class of neural networks designed to extract information from the graphical structure of data. Graph Convolutional Networks (GCNs) are a widely used type of GNN for transductive graph learning problems which apply convolution to learn information from graphs. GCN is a challenging algorithm from an architecture perspective due to inherent sparsity, low data reuse, and massive memory capacity requirements. Traditional neural algorithms exploit the high compute capacity of GPUs to achieve high performance for both inference and training. The architectural decision to use a GPU for GCN inference is a question explored in this work. GCN on both CPU and GPU was characterized in order to better understand the implications of graph size, embedding dimension, and sampling on performance. ",
    "url": "https://arxiv.org/abs/2212.00827",
    "authors": [
      "Matthew Adiletta",
      "David Brooks",
      "Gu-Yeon Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2212.00842",
    "title": "3D-LDM: Neural Implicit 3D Shape Generation with Latent Diffusion Models",
    "abstract": "Diffusion models have shown great promise for image generation, beating GANs in terms of generation diversity, with comparable image quality. However, their application to 3D shapes has been limited to point or voxel representations that can in practice not accurately represent a 3D surface. We propose a diffusion model for neural implicit representations of 3D shapes that operates in the latent space of an auto-decoder. This allows us to generate diverse and high quality 3D surfaces. We additionally show that we can condition our model on images or text to enable image-to-3D generation and text-to-3D generation using CLIP embeddings. Furthermore, adding noise to the latent codes of existing shapes allows us to explore shape variations. ",
    "url": "https://arxiv.org/abs/2212.00842",
    "authors": [
      "Gimin Nam",
      "Mariem Khlifi",
      "Andrew Rodriguez",
      "Alberto Tono",
      "Linqi Zhou",
      "Paul Guerrero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00850",
    "title": "When Neural Networks Fail to Generalize? A Model Sensitivity Perspective",
    "abstract": "Domain generalization (DG) aims to train a model to perform well in unseen domains under different distributions. This paper considers a more realistic yet more challenging scenario,namely Single Domain Generalization (Single-DG), where only a single source domain is available for training. To tackle this challenge, we first try to understand when neural networks fail to generalize? We empirically ascertain a property of a model that correlates strongly with its generalization that we coin as \"model sensitivity\". Based on our analysis, we propose a novel strategy of Spectral Adversarial Data Augmentation (SADA) to generate augmented images targeted at the highly sensitive frequencies. Models trained with these hard-to-learn samples can effectively suppress the sensitivity in the frequency space, which leads to improved generalization performance. Extensive experiments on multiple public datasets demonstrate the superiority of our approach, which surpasses the state-of-the-art single-DG methods. ",
    "url": "https://arxiv.org/abs/2212.00850",
    "authors": [
      "Jiajin Zhang",
      "Hanqing Chao",
      "Amit Dhurandhar",
      "Pin-Yu Chen",
      "Ali Tajer",
      "Yangyang Xu",
      "Pingkun Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00866",
    "title": "Learning Robust State Observers using Neural ODEs (longer version)",
    "abstract": "Relying on recent research results on Neural ODEs, this paper presents a methodology for the design of state observers for nonlinear systems based on Neural ODEs, learning Luenberger-like observers and their nonlinear extension (Kazantzis-Kravaris-Luenberger (KKL) observers) for systems with partially-known nonlinear dynamics and fully unknown nonlinear dynamics, respectively. In particular, for tuneable KKL observers, the relationship between the design of the observer and its trade-off between convergence speed and robustness is analysed and used as a basis for improving the robustness of the learning-based observer in training. We illustrate the advantages of this approach in numerical simulations. ",
    "url": "https://arxiv.org/abs/2212.00866",
    "authors": [
      "Keyan Miao",
      "Konstantinos Gatsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00869",
    "title": "Flexible social inference facilitates targeted social learning when  rewards are not observable",
    "abstract": "Relying on others can be as risky as it can be rewarding. Advice seekers must disentangle good advice from bad, and balance the potential benefits of shared wisdom against the risks of being misled. Groups are most effective at sharing information and solving problems together when everyone is sensitive to ``who knows what.'' Acquiring such knowledge in the first place, however, is not trivial -- especially in contexts where background information is limited. What underlying cognitive abilities are needed for social learning to be useful in information-limited environments? Here, we propose that the capacity for flexible social inference plays a key role in human group behavior, allowing latent properties such as success or skill to be inferred from others' outward behavior even when there is no direct access to others' private rewards and \"success\" manifests differently from context to context. We begin by formalizing our proposal in a cognitive model and comparing this model's predictions against those of simpler heuristics in a series of computational simulations. We then evaluated these predictions in three large-scale behavioral experiments using a multi-agent search paradigm with hidden rewards. In Experiment 1, we found that average performance improves as a function of group size at a rate predicted by our model but not by three simpler alternatives. In Experiment 2, we placed human participants in controlled scenarios with artificial agents to more systematically evaluate the conditions under which people choose to rely on social information. Finally, in Experiment 3, we generalized these findings to a more complex and noisy environment, suggesting regimes where inferences may break down. Taken together, we find that even the most rudimentary social cognition abilities may facilitate the characteristic flexibility of human collective behavior. ",
    "url": "https://arxiv.org/abs/2212.00869",
    "authors": [
      "Robert D. Hawkins",
      "Andrew M. Berdahl",
      "Alex \"Sandy\" Pentland",
      "Joshua B. Tenenbaum",
      "Noah D. Goodman",
      "P. M. Krafft"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2212.00893",
    "title": "Compositional Learning of Dynamical System Models Using Port-Hamiltonian  Neural Networks",
    "abstract": "Many dynamical systems -- from robots interacting with their surroundings to large-scale multiphysics systems -- involve a number of interacting subsystems. Toward the objective of learning composite models of such systems from data, we present i) a framework for compositional neural networks, ii) algorithms to train these models, iii) a method to compose the learned models, iv) theoretical results that bound the error of the resulting composite models, and v) a method to learn the composition itself, when it is not known a prior. The end result is a modular approach to learning: neural network submodels are trained on trajectory data generated by relatively simple subsystems, and the dynamics of more complex composite systems are then predicted without requiring additional data generated by the composite systems themselves. We achieve this compositionality by representing the system of interest, as well as each of its subsystems, as a port-Hamiltonian neural network (PHNN) -- a class of neural ordinary differential equations that uses the port-Hamiltonian systems formulation as inductive bias. We compose collections of PHNNs by using the system's physics-informed interconnection structure, which may be known a priori, or may itself be learned from data. We demonstrate the novel capabilities of the proposed framework through numerical examples involving interacting spring-mass-damper systems. Models of these systems, which include nonlinear energy dissipation and control inputs, are learned independently. Accurate compositions are learned using an amount of training data that is negligible in comparison with that required to train a new model from scratch. Finally, we observe that the composite PHNNs enjoy properties of port-Hamiltonian systems, such as cyclo-passivity -- a property that is useful for control purposes. ",
    "url": "https://arxiv.org/abs/2212.00893",
    "authors": [
      "Cyrus Neary",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00898",
    "title": "Hierarchical Model Selection for Graph Neural Netoworks",
    "abstract": "Node classification on graph data is a major problem, and various graph neural networks (GNNs) have been proposed. Variants of GNNs such as H2GCN and CPF outperform graph convolutional networks (GCNs) by improving on the weaknesses of the traditional GNN. However, there are some graph data which these GNN variants fail to perform well than other GNNs in the node classification task. This is because H2GCN has a feature thinning on graph data with high average degree, and CPF gives rise to a problem about label-propagation suitability. Accordingly, we propose a hierarchical model selection framework (HMSF) that selects an appropriate GNN model by analyzing the indicators of each graph data. In the experiment, we show that the model selected by our HMSF achieves high performance on node classification for various types of graph data. ",
    "url": "https://arxiv.org/abs/2212.00898",
    "authors": [
      "Yuga Oishi",
      "Ken Kaneiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00903",
    "title": "DeclutterCam: A Photographic Assistant System with Clutter Detection and  Removal",
    "abstract": "Photographs convey the stories of photographers to the audience. However, this story-telling aspect of photography is easily distracted by visual clutter. Informed by a pilot study, we identified the kinds of clutter that amateurs frequently include in their photos. We were thus inspired to develop DeclutterCam, a photographic assistant system that incorporates novel user interactions and AI algorithms for photographic decluttering. Clutter elements are detected by an aesthetic quality evaluation algorithm and are highlighted so that users can interactively identify distracting elements. A GAN-based iterative clutter removal tool enables users to test their photographic ideas in real-time. User studies with 32 photography beginners demonstrate that our system provides flexible interfaces, accurate algorithms, and immediate feedback that allow users to avoid clutter and explore more photographic ideas. Evaluations by photography experts show that users can take higher-quality photos that better convey the intended story using our system. ",
    "url": "https://arxiv.org/abs/2212.00903",
    "authors": [
      "Xiaoran Wu",
      "Zihan Yan",
      "Xiang Anthony Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2212.00911",
    "title": "Navigating causal deep learning",
    "abstract": "Causal deep learning (CDL) is a new and important research area in the larger field of machine learning. With CDL, researchers aim to structure and encode causal knowledge in the extremely flexible representation space of deep learning models. Doing so will lead to more informed, robust, and general predictions and inference -- which is important! However, CDL is still in its infancy. For example, it is not clear how we ought to compare different methods as they are so different in their output, the way they encode causal knowledge, or even how they represent this knowledge. This is a living paper that categorises methods in causal deep learning beyond Pearl's ladder of causation. We refine the rungs in Pearl's ladder, while also adding a separate dimension that categorises the parametric assumptions of both input and representation, arriving at the map of causal deep learning. Our map covers machine learning disciplines such as supervised learning, reinforcement learning, generative modelling and beyond. Our paradigm is a tool which helps researchers to: find benchmarks, compare methods, and most importantly: identify research gaps. With this work we aim to structure the avalanche of papers being published on causal deep learning. While papers on the topic are being published daily, our map remains fixed. We open-source our map for others to use as they see fit: perhaps to offer guidance in a related works section, or to better highlight the contribution of their paper. ",
    "url": "https://arxiv.org/abs/2212.00911",
    "authors": [
      "Jeroen Berrevoets",
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00914",
    "title": "QFF: Quantized Fourier Features for Neural Field Representations",
    "abstract": "Multilayer perceptrons (MLPs) learn high frequencies slowly. Recent approaches encode features in spatial bins to improve speed of learning details, but at the cost of larger model size and loss of continuity. Instead, we propose to encode features in bins of Fourier features that are commonly used for positional encoding. We call these Quantized Fourier Features (QFF). As a naturally multiresolution and periodic representation, our experiments show that using QFF can result in smaller model size, faster training, and better quality outputs for several applications, including Neural Image Representations (NIR), Neural Radiance Field (NeRF) and Signed Distance Function (SDF) modeling. QFF are easy to code, fast to compute, and serve as a simple drop-in addition to many neural field representations. ",
    "url": "https://arxiv.org/abs/2212.00914",
    "authors": [
      "Jae Yong Lee",
      "Yuqun Wu",
      "Chuhang Zou",
      "Shenlong Wang",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00920",
    "title": "Geometry-Aware Network for Domain Adaptive Semantic Segmentation",
    "abstract": "Measuring and alleviating the discrepancies between the synthetic (source) and real scene (target) data is the core issue for domain adaptive semantic segmentation. Though recent works have introduced depth information in the source domain to reinforce the geometric and semantic knowledge transfer, they cannot extract the intrinsic 3D information of objects, including positions and shapes, merely based on 2D estimated depth. In this work, we propose a novel Geometry-Aware Network for Domain Adaptation (GANDA), leveraging more compact 3D geometric point cloud representations to shrink the domain gaps. In particular, we first utilize the auxiliary depth supervision from the source domain to obtain the depth prediction in the target domain to accomplish structure-texture disentanglement. Beyond depth estimation, we explicitly exploit 3D topology on the point clouds generated from RGB-D images for further coordinate-color disentanglement and pseudo-labels refinement in the target domain. Moreover, to improve the 2D classifier in the target domain, we perform domain-invariant geometric adaptation from source to target and unify the 2D semantic and 3D geometric segmentation results in two domains. Note that our GANDA is plug-and-play in any existing UDA framework. Qualitative and quantitative results demonstrate that our model outperforms state-of-the-arts on GTA5->Cityscapes and SYNTHIA->Cityscapes. ",
    "url": "https://arxiv.org/abs/2212.00920",
    "authors": [
      "Yinghong Liao",
      "Wending Zhou",
      "Xu Yan",
      "Shuguang Cui",
      "Yizhou Yu",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00921",
    "title": "AGRO: Adversarial Discovery of Error-prone groups for Robust  Optimization",
    "abstract": "Models trained via empirical risk minimization (ERM) are known to rely on spurious correlations between labels and task-independent input features, resulting in poor generalization to distributional shifts. Group distributionally robust optimization (G-DRO) can alleviate this problem by minimizing the worst-case loss over a set of pre-defined groups over training data. G-DRO successfully improves performance of the worst-group, where the correlation does not hold. However, G-DRO assumes that the spurious correlations and associated worst groups are known in advance, making it challenging to apply it to new tasks with potentially multiple unknown spurious correlations. We propose AGRO -- Adversarial Group discovery for Distributionally Robust Optimization -- an end-to-end approach that jointly identifies error-prone groups and improves accuracy on them. AGRO equips G-DRO with an adversarial slicing model to find a group assignment for training examples which maximizes worst-case loss over the discovered groups. On the WILDS benchmark, AGRO results in 8% higher model performance on average on known worst-groups, compared to prior group discovery approaches used with G-DRO. AGRO also improves out-of-distribution performance on SST2, QQP, and MS-COCO -- datasets where potential spurious correlations are as yet uncharacterized. Human evaluation of ARGO groups shows that they contain well-defined, yet previously unstudied spurious correlations that lead to model errors. ",
    "url": "https://arxiv.org/abs/2212.00921",
    "authors": [
      "Bhargavi Paranjape",
      "Pradeep Dasigi",
      "Vivek Srikumar",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00935",
    "title": "Dunhuang murals contour generation network based on convolution and  self-attention fusion",
    "abstract": "Dunhuang murals are a collection of Chinese style and national style, forming a self-contained Chinese-style Buddhist art. It has very high historical and cultural value and research significance. Among them, the lines of Dunhuang murals are highly general and expressive. It reflects the character's distinctive character and complex inner emotions. Therefore, the outline drawing of murals is of great significance to the research of Dunhuang Culture. The contour generation of Dunhuang murals belongs to image edge detection, which is an important branch of computer vision, aims to extract salient contour information in images. Although convolution-based deep learning networks have achieved good results in image edge extraction by exploring the contextual and semantic features of images. However, with the enlargement of the receptive field, some local detail information is lost. This makes it impossible for them to generate reasonable outline drawings of murals. In this paper, we propose a novel edge detector based on self-attention combined with convolution to generate line drawings of Dunhuang murals. Compared with existing edge detection methods, firstly, a new residual self-attention and convolution mixed module (Ramix) is proposed to fuse local and global features in feature maps. Secondly, a novel densely connected backbone extraction network is designed to efficiently propagate rich edge feature information from shallow layers into deep layers. Compared with existing methods, it is shown on different public datasets that our method is able to generate sharper and richer edge maps. In addition, testing on the Dunhuang mural dataset shows that our method can achieve very competitive performance. ",
    "url": "https://arxiv.org/abs/2212.00935",
    "authors": [
      "Baokai Liu",
      "Fengjie He",
      "Shiqiang Du",
      "Kaiwu Zhang",
      "Jianhua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00936",
    "title": "Integer Subspace Differential Privacy",
    "abstract": "We propose new differential privacy solutions for when external \\emph{invariants} and \\emph{integer} constraints are simultaneously enforced on the data product. These requirements arise in real world applications of private data curation, including the public release of the 2020 U.S. Decennial Census. They pose a great challenge to the production of provably private data products with adequate statistical usability. We propose \\emph{integer subspace differential privacy} to rigorously articulate the privacy guarantee when data products maintain both the invariants and integer characteristics, and demonstrate the composition and post-processing properties of our proposal. To address the challenge of sampling from a potentially highly restricted discrete space, we devise a pair of unbiased additive mechanisms, the generalized Laplace and the generalized Gaussian mechanisms, by solving the Diophantine equations as defined by the constraints. The proposed mechanisms have good accuracy, with errors exhibiting sub-exponential and sub-Gaussian tail probabilities respectively. To implement our proposal, we design an MCMC algorithm and supply empirical convergence assessment using estimated upper bounds on the total variation distance via $L$-lag coupling. We demonstrate the efficacy of our proposal with applications to a synthetic problem with intersecting invariants, a sensitive contingency table with known margins, and the 2010 Census county-level demonstration data with mandated fixed state population totals. ",
    "url": "https://arxiv.org/abs/2212.00936",
    "authors": [
      "Prathamesh Dharangutte",
      "Jie Gao",
      "Ruobin Gong",
      "Fang-Yi Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2212.00951",
    "title": "SimpleMind adds thinking to deep neural networks",
    "abstract": "Deep neural networks (DNNs) detect patterns in data and have shown versatility and strong performance in many computer vision applications. However, DNNs alone are susceptible to obvious mistakes that violate simple, common sense concepts and are limited in their ability to use explicit knowledge to guide their search and decision making. While overall DNN performance metrics may be good, these obvious errors, coupled with a lack of explainability, have prevented widespread adoption for crucial tasks such as medical image analysis. The purpose of this paper is to introduce SimpleMind, an open-source software framework for Cognitive AI focused on medical image understanding. It allows creation of a knowledge base that describes expected characteristics and relationships between image objects in an intuitive human-readable form. The SimpleMind framework brings thinking to DNNs by: (1) providing methods for reasoning with the knowledge base about image content, such as spatial inferencing and conditional reasoning to check DNN outputs; (2) applying process knowledge, in the form of general-purpose software agents, that are chained together to accomplish image preprocessing, DNN prediction, and result post-processing, and (3) performing automatic co-optimization of all knowledge base parameters to adapt agents to specific problems. SimpleMind enables reasoning on multiple detected objects to ensure consistency, providing cross checking between DNN outputs. This machine reasoning improves the reliability and trustworthiness of DNNs through an interpretable model and explainable decisions. Example applications are provided that demonstrate how SimpleMind supports and improves deep neural networks by embedding them within a Cognitive AI framework. ",
    "url": "https://arxiv.org/abs/2212.00951",
    "authors": [
      "Youngwon Choi",
      "M. Wasil Wahi-Anwar",
      "Matthew S. Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00952",
    "title": "On the Limit of Explaining Black-box Temporal Graph Neural Networks",
    "abstract": "Temporal Graph Neural Network (TGNN) has been receiving a lot of attention recently due to its capability in modeling time-evolving graph-related tasks. Similar to Graph Neural Networks, it is also non-trivial to interpret predictions made by a TGNN due to its black-box nature. A major approach tackling this problems in GNNs is by analyzing the model' responses on some perturbations of the model's inputs, called perturbation-based explanation methods. While these methods are convenient and flexible since they do not need internal access to the model, does this lack of internal access prevent them from revealing some important information of the predictions? Motivated by that question, this work studies the limit of some classes of perturbation-based explanation methods. Particularly, by constructing some specific instances of TGNNs, we show (i) node-perturbation cannot reliably identify the paths carrying out the prediction, (ii) edge-perturbation is not reliable in determining all nodes contributing to the prediction and (iii) perturbing both nodes and edges does not reliably help us identify the graph's components carrying out the temporal aggregation in TGNNs. ",
    "url": "https://arxiv.org/abs/2212.00952",
    "authors": [
      "Minh N. Vu",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00959",
    "title": "UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question  Answering Over Knowledge Graph",
    "abstract": "Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG). To cope with the vast search space, existing work usually adopts a two-stage approach: it firstly retrieves a relatively small subgraph related to the question and then performs the reasoning on the subgraph to accurately find the answer entities. Although these two stages are highly related, previous work employs very different technical solutions for developing the retrieval and reasoning models, neglecting their relatedness in task essence. In this paper, we propose UniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and reasoning in both model architecture and parameter learning. For model architecture, UniKGQA consists of a semantic matching module based on a pre-trained language model~(PLM) for question-relation semantic matching, and a matching information propagation module to propagate the matching information along the edges on KGs. For parameter learning, we design a shared pre-training task based on question-relation matching for both retrieval and reasoning models, and then propose retrieval- and reasoning-oriented fine-tuning strategies. Compared with previous studies, our approach is more unified, tightly relating the retrieval and reasoning stages. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our method on the multi-hop KGQA task. Our codes and data are publicly available at https://github.com/RUCAIBox/UniKGQA. ",
    "url": "https://arxiv.org/abs/2212.00959",
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00966",
    "title": "A Hybrid Deep Learning Anomaly Detection Framework for Intrusion  Detection",
    "abstract": "Cyber intrusion attacks that compromise the users' critical and sensitive data are escalating in volume and intensity, especially with the growing connections between our daily life and the Internet. The large volume and high complexity of such intrusion attacks have impeded the effectiveness of most traditional defence techniques. While at the same time, the remarkable performance of the machine learning methods, especially deep learning, in computer vision, had garnered research interests from the cyber security community to further enhance and automate intrusion detections. However, the expensive data labeling and limitation of anomalous data make it challenging to train an intrusion detector in a fully supervised manner. Therefore, intrusion detection based on unsupervised anomaly detection is an important feature too. In this paper, we propose a three-stage deep learning anomaly detection based network intrusion attack detection framework. The framework comprises an integration of unsupervised (K-means clustering), semi-supervised (GANomaly) and supervised learning (CNN) algorithms. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON_IoT. ",
    "url": "https://arxiv.org/abs/2212.00966",
    "authors": [
      "Rahul Kale",
      "Zhi Lu",
      "Kar Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00968",
    "title": "UIU-Net: U-Net in U-Net for Infrared Small Object Detection",
    "abstract": "Learning-based infrared small object detection methods currently rely heavily on the classification backbone network. This tends to result in tiny object loss and feature distinguishability limitations as the network depth increases. Furthermore, small objects in infrared images are frequently emerged bright and dark, posing severe demands for obtaining precise object contrast information. For this reason, we in this paper propose a simple and effective ``U-Net in U-Net'' framework, UIU-Net for short, and detect small objects in infrared images. As the name suggests, UIU-Net embeds a tiny U-Net into a larger U-Net backbone, enabling the multi-level and multi-scale representation learning of objects. Moreover, UIU-Net can be trained from scratch, and the learned features can enhance global and local contrast information effectively. More specifically, the UIU-Net model is divided into two modules: the resolution-maintenance deep supervision (RM-DS) module and the interactive-cross attention (IC-A) module. RM-DS integrates Residual U-blocks into a deep supervision network to generate deep multi-scale resolution-maintenance features while learning global context information. Further, IC-A encodes the local context information between the low-level details and high-level semantic features. Extensive experiments conducted on two infrared single-frame image datasets, i.e., SIRST and Synthetic datasets, show the effectiveness and superiority of the proposed UIU-Net in comparison with several state-of-the-art infrared small object detection methods. The proposed UIU-Net also produces powerful generalization performance for video sequence infrared small object datasets, e.g., ATR ground/air video sequence dataset. The codes of this work are available openly at \\url{https://github.com/danfenghong/IEEE_TIP_UIU-Net}. ",
    "url": "https://arxiv.org/abs/2212.00968",
    "authors": [
      "Xin Wu",
      "Danfeng Hong",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00970",
    "title": "Bayesian Physics Informed Neural Networks for Data Assimilation and  Spatio-Temporal Modelling of Wildfires",
    "abstract": "We apply Physics Informed Neural Networks (PINNs) to the problem of wildfire fire-front modelling. The PINN is an approach that integrates a differential equation into the optimisation loss function of a neural network to guide the neural network to learn the physics of a problem. We apply the PINN to the level-set equation, which is a Hamilton-Jacobi partial differential equation that models a fire-front with the zero-level set. This results in a PINN that simulates a fire-front as it propagates through a spatio-temporal domain. We demonstrate the agility of the PINN to learn physical properties of a fire under extreme changes in external conditions (such as wind) and show that this approach encourages continuity of the PINN's solution across time. Furthermore, we demonstrate how data assimilation and uncertainty quantification can be incorporated into the PINN in the wildfire context. This is significant contribution to wildfire modelling as the level-set method -- which is a standard solver to the level-set equation -- does not naturally provide this capability. ",
    "url": "https://arxiv.org/abs/2212.00970",
    "authors": [
      "Joel Janek Dabrowski",
      "Daniel Edward Pagendam",
      "James Hilton",
      "Conrad Sanderson",
      "Daniel MacKinlay",
      "Carolyn Huston",
      "Andrew Bolt",
      "Petra Kuhnert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00973",
    "title": "A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention  Mechanism for Symbolic Music Modeling",
    "abstract": "Following the success of the transformer architecture in the natural language domain, transformer-like architectures have been widely applied to the domain of symbolic music recently. Symbolic music and text, however, are two different modalities. Symbolic music contains multiple attributes, both absolute attributes (e.g., pitch) and relative attributes (e.g., pitch interval). These relative attributes shape human perception of musical motifs. These important relative attributes, however, are mostly ignored in existing symbolic music modeling methods with the main reason being the lack of a musically-meaningful embedding space where both the absolute and relative embeddings of the symbolic music tokens can be efficiently represented. In this paper, we propose the Fundamental Music Embedding (FME) for symbolic music based on a bias-adjusted sinusoidal encoding within which both the absolute and the relative attributes can be embedded and the fundamental musical properties (e.g., translational invariance) are explicitly preserved. Taking advantage of the proposed FME, we further propose a novel attention mechanism based on the relative index, pitch and onset embeddings (RIPO attention) such that the musical domain knowledge can be fully utilized for symbolic music modeling. Experiment results show that our proposed model: RIPO transformer which utilizes FME and RIPO attention outperforms the state-of-the-art transformers (i.e., music transformer, linear transformer) in a melody completion task. Moreover, using the RIPO transformer in a downstream music generation task, we notice that the notorious degeneration phenomenon no longer exists and the music generated by the RIPO transformer outperforms the music generated by state-of-the-art transformer models in both subjective and objective evaluations. ",
    "url": "https://arxiv.org/abs/2212.00973",
    "authors": [
      "Z. Guo",
      "J. Kang",
      "D. Herremans"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.00977",
    "title": "PSPC: Efficient Parallel Shortest Path Counting on Large-Scale Graphs",
    "abstract": "In modern graph analytics, the shortest path is a fundamental concept. Numerous \\rrev{recent works} concentrate mostly on the distance of these shortest paths. Nevertheless, in the era of betweenness analysis, the counting of the shortest path between $s$ and $t$ is equally crucial. \\rrev{It} is \\rev{also} an important issue in the area of graph databases. In recent years, several studies have been conducted in an effort to tackle such issues. Nonetheless, the present technique faces a considerable barrier to parallel due to the dependencies in the index construction stage, hence limiting its application possibilities and wasting the potential hardware performance. To address this problem, we provide a parallel shortest path counting method that could avoid these dependencies and obtain approximately linear index time speedup as the number of threads increases. Our empirical evaluations verify the efficiency and effectiveness. ",
    "url": "https://arxiv.org/abs/2212.00977",
    "authors": [
      "You Peng",
      "Jeffrey Xu Yu",
      "Sibo Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.00979",
    "title": "PASTA: Proportional Amplitude Spectrum Training Augmentation for  Syn-to-Real Domain Generalization",
    "abstract": "Synthetic data offers the promise of cheap and bountiful training data for settings where lots of labeled real-world data for tasks is unavailable. However, models trained on synthetic data significantly underperform on real-world data. In this paper, we propose Proportional Amplitude Spectrum Training Augmentation (PASTA), a simple and effective augmentation strategy to improve out-of-the-box synthetic-to-real (syn-to-real) generalization performance. PASTA involves perturbing the amplitude spectrums of the synthetic images in the Fourier domain to generate augmented views. We design PASTA to perturb the amplitude spectrums in a structured manner such that high-frequency components are perturbed relatively more than the low-frequency ones. For the tasks of semantic segmentation (GTAV to Real), object detection (Sim10K to Real), and object recognition (VisDA-C Syn to Real), across a total of 5 syn-to-real shifts, we find that PASTA outperforms more complex state-of-the-art generalization methods while being complementary to the same. ",
    "url": "https://arxiv.org/abs/2212.00979",
    "authors": [
      "Prithvijit Chattopadhyay",
      "Kartik Sarangmath",
      "Vivek Vijaykumar",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.00990",
    "title": "Feature Aggregation and Propagation Network for Camouflaged Object  Detection",
    "abstract": "Camouflaged object detection (COD) aims to detect/segment camouflaged objects embedded in the environment, which has attracted increasing attention over the past decades. Although several COD methods have been developed, they still suffer from unsatisfactory performance due to the intrinsic similarities between the foreground objects and background surroundings. In this paper, we propose a novel Feature Aggregation and Propagation Network (FAP-Net) for camouflaged object detection. Specifically, we propose a Boundary Guidance Module (BGM) to explicitly model the boundary characteristic, which can provide boundary-enhanced features to boost the COD performance. To capture the scale variations of the camouflaged objects, we propose a Multi-scale Feature Aggregation Module (MFAM) to characterize the multi-scale information from each layer and obtain the aggregated feature representations. Furthermore, we propose a Cross-level Fusion and Propagation Module (CFPM). In the CFPM, the feature fusion part can effectively integrate the features from adjacent layers to exploit the cross-level correlations, and the feature propagation part can transmit valuable context information from the encoder to the decoder network via a gate unit. Finally, we formulate a unified and end-to-end trainable framework where cross-level features can be effectively fused and propagated for capturing rich context information. Extensive experiments on three benchmark camouflaged datasets demonstrate that our FAP-Net outperforms other state-of-the-art COD models. Moreover, our model can be extended to the polyp segmentation task, and the comparison results further validate the effectiveness of the proposed model in segmenting polyps. The source code and results will be released at https://github.com/taozh2017/FAPNet. ",
    "url": "https://arxiv.org/abs/2212.00990",
    "authors": [
      "Tao Zhou",
      "Yi Zhou",
      "Chen Gong",
      "Jian Yang",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00994",
    "title": "Knowledge Graph Quality Evaluation under Incomplete Information",
    "abstract": "Utilities of knowledge graphs (KGs) depend on their qualities. A KG that is of poor quality not only has little applicability but also leads to some unexpected errors. Therefore, quality evaluation for KGs is crucial and indispensable. Existing methods design many quality dimensions and calculate metrics in the corresponding dimensions based on details (i.e., raw data and graph structures) of KGs for evaluation. However, there are two major issues. On one hand, they consider the details as public information, which exposes the raw data and graph structures. These details are strictly confidential because they involve commercial privacy or others in practice. On the other hand, the existing methods focus on how much knowledge KGs have rather than KGs' practicability. To address the above problems, we propose a knowledge graph quality evaluation framework under incomplete information (QEII). The quality evaluation problem is transformed into an adversarial game, and the relative quality is evaluated according to the winner and loser. Participants of the game are KGs, and the adversarial gameplay is to question and answer (Q&A). In the QEII, we generate and train a question model and an answer model for each KG. The question model of a KG first asks a certain number of questions to the other KG. Then it evaluates the answers returned by the answer model of the other KG and outputs a percentage score. The relative quality is evaluated by the scores, which measures the ability to apply knowledge. Q&A messages are the only information that KGs exchange, without exposing any raw data and graph structure. Experimental results on two pairs of KGs demonstrate that, comparing with baselines, the QEII realizes a reasonable quality evaluation from the perspective of third-party evaluators under incomplete information. ",
    "url": "https://arxiv.org/abs/2212.00994",
    "authors": [
      "Xiaodong Li",
      "Chenxin Zou",
      "Yi Cai",
      "Yuelong Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00998",
    "title": "Credit Assignment for Trained Neural Networks Based on Koopman Operator  Theory",
    "abstract": "Credit assignment problem of neural networks refers to evaluating the credit of each network component to the final outputs. For an untrained neural network, approaches to tackling it have made great contributions to parameter update and model revolution during the training phase. This problem on trained neural networks receives rare attention, nevertheless, it plays an increasingly important role in neural network patch, specification and verification. Based on Koopman operator theory, this paper presents an alternative perspective of linear dynamics on dealing with the credit assignment problem for trained neural networks. Regarding a neural network as the composition of sub-dynamics series, we utilize step-delay embedding to capture snapshots of each component, characterizing the established mapping as exactly as possible. To circumvent the dimension-difference problem encountered during the embedding, a composition and decomposition of an auxiliary linear layer, termed minimal linear dimension alignment, is carefully designed with rigorous formal guarantee. Afterwards, each component is approximated by a Koopman operator and we derive the Jacobian matrix and its corresponding determinant, similar to backward propagation. Then, we can define a metric with algebraic interpretability for the credit assignment of each network component. Moreover, experiments conducted on typical neural networks demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2212.00998",
    "authors": [
      "Zhen Liang",
      "Changyuan Zhao",
      "Wanwei Liu",
      "Bai Xue",
      "Wenjing Yang",
      "Zhengbin Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01005",
    "title": "AGO: Boosting Mobile AI Inference Performance by Removing Constraints on  Graph Optimization",
    "abstract": "Traditional deep learning compilers rely on heuristics for subgraph generation, which impose extra constraints on graph optimization, e.g., each subgraph can only contain at most one complex operator. In this paper, we propose AGO, a framework for graph optimization with arbitrary structures to boost the inference performance of deep models by removing such constraints. To create new optimization opportunities for complicated subgraphs, we propose intensive operator fusion, which can effectively stitch multiple complex operators together for better performance. Further, we design a graph partitioning scheme that allows an arbitrary structure for each subgraph while guaranteeing the acyclic property among all generated subgraphs. Additionally, to enable efficient performance tuning on complicated subgraphs, we devise a novel divide-and-conquer tuning mechanism to orchestrate different system components. Through extensive experiments on various neural networks and mobile devices, we show that our system can improve the inference performance by up to 3.3x when compared with state-of-the-art deep compilers. ",
    "url": "https://arxiv.org/abs/2212.01005",
    "authors": [
      "Zhiying Xu",
      "Hongding Peng",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.01006",
    "title": "FedCoCo: A Memory Efficient Federated Self-supervised Framework for  On-Device Visual Representation Learning",
    "abstract": "The ubiquity of edge devices has led to a growing amount of unlabeled data produced at the edge. Deep learning models deployed on edge devices are required to learn from these unlabeled data to continuously improve accuracy. Self-supervised representation learning has achieved promising performances using centralized unlabeled data. However, the increasing awareness of privacy protection limits centralizing the distributed unlabeled image data on edge devices. While federated learning has been widely adopted to enable distributed machine learning with privacy preservation, without a data selection method to efficiently select streaming data, the traditional federated learning framework fails to handle these huge amounts of decentralized unlabeled data with limited storage resources on edge. To address these challenges, we propose a Federated on-device Contrastive learning framework with Coreset selection, which we call FedCoCo, to automatically select a coreset that consists of the most representative samples into the replay buffer on each device. It preserves data privacy as each client does not share raw data while learning good visual representations. Experiments demonstrate the effectiveness and significance of the proposed method in visual representation learning. ",
    "url": "https://arxiv.org/abs/2212.01006",
    "authors": [
      "Jiahe Shi",
      "Yawen Wu",
      "Dewen Zeng",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01020",
    "title": "Programming Is Hard -- Or at Least It Used to Be: Educational  Opportunities And Challenges of AI Code Generation",
    "abstract": "The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on how to overcome or otherwise mitigate the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community. ",
    "url": "https://arxiv.org/abs/2212.01020",
    "authors": [
      "Brett A. Becker",
      "Paul Denny",
      "James Finnie-Ansley",
      "Andrew Luxton-Reilly",
      "James Prather",
      "Eddie Antonio Santos"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.01026",
    "title": "Spectral Feature Augmentation for Graph Contrastive Learning and Beyond",
    "abstract": "Although augmentations (e.g., perturbation of graph edges, image crops) boost the efficiency of Contrastive Learning (CL), feature level augmentation is another plausible, complementary yet not well researched strategy. Thus, we present a novel spectral feature argumentation for contrastive learning on graphs (and images). To this end, for each data view, we estimate a low-rank approximation per feature map and subtract that approximation from the map to obtain its complement. This is achieved by the proposed herein incomplete power iteration, a non-standard power iteration regime which enjoys two valuable byproducts (under mere one or two iterations): (i) it partially balances spectrum of the feature map, and (ii) it injects the noise into rebalanced singular values of the feature map (spectral augmentation). For two views, we align these rebalanced feature maps as such an improved alignment step can focus more on less dominant singular values of matrices of both views, whereas the spectral augmentation does not affect the spectral angle alignment (singular vectors are not perturbed). We derive the analytical form for: (i) the incomplete power iteration to capture its spectrum-balancing effect, and (ii) the variance of singular values augmented implicitly by the noise. We also show that the spectral augmentation improves the generalization bound. Experiments on graph/image datasets show that our spectral feature augmentation outperforms baselines, and is complementary with other augmentation strategies and compatible with various contrastive losses. ",
    "url": "https://arxiv.org/abs/2212.01026",
    "authors": [
      "Yifei Zhang",
      "Hao Zhu",
      "Zixing Song",
      "Piotr Koniusz",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01032",
    "title": "General Framework for Self-Supervised Model Priming for  Parameter-Efficient Fine-tuning",
    "abstract": "Parameter-efficient methods (like Prompt or Adapters) for adapting pre-trained language models to downstream tasks have been popular recently. However, hindrances still prevent these methods from reaching their full potential. For example, two significant challenges are few-shot adaptation and cross-task generalization ability. To tackle these issues, we propose a general framework to enhance the few-shot adaptation and cross-domain generalization ability of parameter-efficient methods. In our framework, we prime the self-supervised model for parameter-efficient methods to rapidly adapt to various downstream few-shot tasks. To evaluate the authentic generalization ability of these parameter-efficient methods, we conduct experiments on a few-shot cross-domain benchmark containing 160 diverse NLP tasks. The experiment result reveals that priming by tuning PLM only with extra training tasks leads to the best performance. Also, we perform a comprehensive analysis of various parameter-efficient methods under few-shot cross-domain scenarios. ",
    "url": "https://arxiv.org/abs/2212.01032",
    "authors": [
      "Shih-Cheng Huang",
      "Shih-Heng Wang",
      "Min-Han Shih",
      "Saurav Sahay",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01039",
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech  Recognition",
    "abstract": "Error correction in automatic speech recognition (ASR) aims to correct those incorrect words in sentences generated by ASR models. Since recent ASR models usually have low word error rate (WER), to avoid affecting originally correct tokens, error correction models should only modify incorrect words, and therefore detecting incorrect words is important for error correction. Previous works on error correction either implicitly detect error words through target-source attention or CTC (connectionist temporal classification) loss, or explicitly locate specific deletion/substitution/insertion errors. However, implicit error detection does not provide clear signal about which tokens are incorrect and explicit error detection suffers from low detection accuracy. In this paper, we propose SoftCorrect with a soft error detection mechanism to avoid the limitations of both explicit and implicit error detection. Specifically, we first detect whether a token is correct or not through a probability produced by a dedicatedly designed language model, and then design a constrained CTC loss that only duplicates the detected incorrect tokens to let the decoder focus on the correction of error tokens. Compared with implicit error detection with CTC loss, SoftCorrect provides explicit signal about which words are incorrect and thus does not need to duplicate every token but only incorrect tokens; compared with explicit error detection, SoftCorrect does not detect specific deletion/substitution/insertion errors but just leaves it to CTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that SoftCorrect achieves 26.1% and 9.4% CER reduction respectively, outperforming previous works by a large margin, while still enjoying fast speed of parallel generation. ",
    "url": "https://arxiv.org/abs/2212.01039",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Wenjie Liu",
      "Kaitao Song",
      "Rui Wang",
      "Xiang-Yang Li",
      "Tao Qin",
      "Edward Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.01046",
    "title": "Improved Representation Learning Through Tensorized Autoencoders",
    "abstract": "The central question in representation learning is what constitutes a good or meaningful representation. In this work we argue that if we consider data with inherent cluster structures, where clusters can be characterized through different means and covariances, those data structures should be represented in the embedding as well. While Autoencoders (AE) are widely used in practice for unsupervised representation learning, they do not fulfil the above condition on the embedding as they obtain a single representation of the data. To overcome this we propose a meta-algorithm that can be used to extend an arbitrary AE architecture to a tensorized version (TAE) that allows for learning cluster-specific embeddings while simultaneously learning the cluster assignment. For the linear setting we prove that TAE can recover the principle components of the different clusters in contrast to principle component of the entire data recovered by a standard AE. We validated this on planted models and for general, non-linear and convolutional AEs we empirically illustrate that tensorizing the AE is beneficial in clustering and de-noising tasks. ",
    "url": "https://arxiv.org/abs/2212.01046",
    "authors": [
      "Pascal Mattia Esser",
      "Satyaki Mukherjee",
      "Mahalakshmi Sabanayagam",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01051",
    "title": "VeriX: Towards Verified Explainability of Deep Neural Networks",
    "abstract": "We present VeriX, a first step towards verified explainability of machine learning models in safety-critical applications. Specifically, our sound and optimal explanations can guarantee prediction invariance against bounded perturbations. We utilise constraint solving techniques together with feature sensitivity ranking to efficiently compute these explanations. We evaluate our approach on image recognition benchmarks and a real-world scenario of autonomous aircraft taxiing. ",
    "url": "https://arxiv.org/abs/2212.01051",
    "authors": [
      "Min Wu",
      "Haoze Wu",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01060",
    "title": "Exploring Faithful Rationale for Multi-hop Fact Verification via  Salience-Aware Graph Learning",
    "abstract": "The opaqueness of the multi-hop fact verification model imposes imperative requirements for explainability. One feasible way is to extract rationales, a subset of inputs, where the performance of prediction drops dramatically when being removed. Though being explainable, most rationale extraction methods for multi-hop fact verification explore the semantic information within each piece of evidence individually, while ignoring the topological information interaction among different pieces of evidence. Intuitively, a faithful rationale bears complementary information being able to extract other rationales through the multi-hop reasoning process. To tackle such disadvantages, we cast explainable multi-hop fact verification as subgraph extraction, which can be solved based on graph convolutional network (GCN) with salience-aware graph learning. In specific, GCN is utilized to incorporate the topological interaction information among multiple pieces of evidence for learning evidence representation. Meanwhile, to alleviate the influence of noisy evidence, the salience-aware graph perturbation is induced into the message passing of GCN. Moreover, the multi-task model with three diagnostic properties of rationale is elaborately designed to improve the quality of an explanation without any explicit annotations. Experimental results on the FEVEROUS benchmark show significant gains over previous state-of-the-art methods for both rationale extraction and fact verification. ",
    "url": "https://arxiv.org/abs/2212.01060",
    "authors": [
      "Jiasheng Si",
      "Yingjie Zhu",
      "Deyu Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01071",
    "title": "Fake detection in imbalance dataset by Semi-supervised learning with GAN",
    "abstract": "As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\\% in detecting fake accounts using only 100 labeled samples. ",
    "url": "https://arxiv.org/abs/2212.01071",
    "authors": [
      "Jinus Bordbar",
      "Saman Ardalan",
      "Mohammadreza Mohammadrezaie",
      "Mohammad Ebrahim Shiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.01082",
    "title": "Membership Inference Attacks Against Semantic Segmentation Models",
    "abstract": "Membership inference attacks aim to infer whether a data record has been used to train a target model by observing its predictions. In sensitive domains such as healthcare, this can constitute a severe privacy violation. In this work we attempt to address the existing knowledge gap by conducting an exhaustive study of membership inference attacks and defences in the domain of semantic image segmentation. Our findings indicate that for certain threat models, these learning settings can be considerably more vulnerable than the previously considered classification settings. We additionally investigate a threat model where a dishonest adversary can perform model poisoning to aid their inference and evaluate the effects that these adaptations have on the success of membership inference attacks. We quantitatively evaluate the attacks on a number of popular model architectures across a variety of semantic segmentation tasks, demonstrating that membership inference attacks in this domain can achieve a high success rate and defending against them may result in unfavourable privacy-utility trade-offs or increased computational costs. ",
    "url": "https://arxiv.org/abs/2212.01082",
    "authors": [
      "Tomas Chobola",
      "Dmitrii Usynin",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.01096",
    "title": "Cross-Domain Graph Anomaly Detection via Anomaly-aware Contrastive  Alignment",
    "abstract": "Cross-domain graph anomaly detection (CD-GAD) describes the problem of detecting anomalous nodes in an unlabelled target graph using auxiliary, related source graphs with labelled anomalous and normal nodes. Although it presents a promising approach to address the notoriously high false positive issue in anomaly detection, little work has been done in this line of research. There are numerous domain adaptation methods in the literature, but it is difficult to adapt them for GAD due to the unknown distributions of the anomalies and the complex node relations embedded in graph data. To this end, we introduce a novel domain adaptation approach, namely Anomaly-aware Contrastive alignmenT (ACT), for GAD. ACT is designed to jointly optimise: (i) unsupervised contrastive learning of normal representations of nodes in the target graph, and (ii) anomaly-aware one-class alignment that aligns these contrastive node representations and the representations of labelled normal nodes in the source graph, while enforcing significant deviation of the representations of the normal nodes from the labelled anomalous nodes in the source graph. In doing so, ACT effectively transfers anomaly-informed knowledge from the source graph to learn the complex node relations of the normal class for GAD on the target graph without any specification of the anomaly distributions. Extensive experiments on eight CD-GAD settings demonstrate that our approach ACT achieves substantially improved detection performance over 10 state-of-the-art GAD methods. Code is available at https://github.com/QZ-WANG/ACT. ",
    "url": "https://arxiv.org/abs/2212.01096",
    "authors": [
      "Qizhou Wang",
      "Guansong Pang",
      "Mahsa Salehi",
      "Wray Buntine",
      "Christopher Leckie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.01098",
    "title": "RGB-D based Stair Detection using Deep Learning for Autonomous Stair  Climbing",
    "abstract": "Stairs are common building structures in urban environment, and stair detection is an important part of environment perception for autonomous mobile robots. Most existing algorithms have difficulty combining the visual information from binocular sensors effectively and ensuring reliable detection at night and in the case of extremely fuzzy visual clues. To solve these problems, we propose a neural network architecture with inputs of both RGB map and depth map. Specifically, we design the selective module which can make the network learn the complementary relationship between RGB map and depth map and effectively combine the information from RGB map and depth map in different scenes. In addition, we also design a line clustering algorithm for the post-processing of detection results, which can make full use of the detection results to obtain the geometric parameters of stairs. Experiments on our dataset show that our method can achieve better accuracy and recall compared with the previous state-of-the-art deep learning method, which are 5.64% and 7.97%, respectively. Our method also has extremely fast detection speed, and a lightweight version can achieve 300 + frames per second with the same resolution, which can meet the needs of most real-time detection scenes. ",
    "url": "https://arxiv.org/abs/2212.01098",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.01109",
    "title": "Generative Data Augmentation for Non-IID Problem in Decentralized  Clinical Machine Learning",
    "abstract": "Swarm learning (SL) is an emerging promising decentralized machine learning paradigm and has achieved high performance in clinical applications. SL solves the problem of a central structure in federated learning by combining edge computing and blockchain-based peer-to-peer network. While there are promising results in the assumption of the independent and identically distributed (IID) data across participants, SL suffers from performance degradation as the degree of the non-IID data increases. To address this problem, we propose a generative augmentation framework in swarm learning called SL-GAN, which augments the non-IID data by generating the synthetic data from participants. SL-GAN trains generators and discriminators locally, and periodically aggregation via a randomly elected coordinator in SL network. Under the standard assumptions, we theoretically prove the convergence of SL-GAN using stochastic approximations. Experimental results demonstrate that SL-GAN outperforms state-of-art methods on three real world clinical datasets including Tuberculosis, Leukemia, COVID-19. ",
    "url": "https://arxiv.org/abs/2212.01109",
    "authors": [
      "Zirui Wang",
      "Shaoming Duan",
      "Chengyue Wu",
      "Wenhao Lin",
      "Xinyu Zha",
      "Peiyi Han",
      "Chuanyi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": "The spread of rumors along with breaking events seriously hinders the truth in the era of social media. Previous studies reveal that due to the lack of annotated resources, rumors presented in minority languages are hard to be detected. Furthermore, the unforeseen breaking events not involved in yesterday's news exacerbate the scarcity of data resources. In this work, we propose a novel zero-shot framework based on prompt learning to detect rumors falling in different domains or presented in different languages. More specifically, we firstly represent rumor circulated on social media as diverse propagation threads, then design a hierarchical prompt encoding mechanism to learn language-agnostic contextual representations for both prompts and rumor data. To further enhance domain adaptation, we model the domain-invariant structural features from the propagation threads, to incorporate structural position representations of influential community response. In addition, a new virtual response augmentation method is used to improve model training. Extensive experiments conducted on three real-world datasets demonstrate that our proposed model achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages. ",
    "url": "https://arxiv.org/abs/2212.01117",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.01120",
    "title": "RT-NeRF: Real-Time On-Device Neural Radiance Fields Towards Immersive  AR/VR Rendering",
    "abstract": "Neural Radiance Field (NeRF) based rendering has attracted growing attention thanks to its state-of-the-art (SOTA) rendering quality and wide applications in Augmented and Virtual Reality (AR/VR). However, immersive real-time (> 30 FPS) NeRF based rendering enabled interactions are still limited due to the low achievable throughput on AR/VR devices. To this end, we first profile SOTA efficient NeRF algorithms on commercial devices and identify two primary causes of the aforementioned inefficiency: (1) the uniform point sampling and (2) the dense accesses and computations of the required embeddings in NeRF. Furthermore, we propose RT-NeRF, which to the best of our knowledge is the first algorithm-hardware co-design acceleration of NeRF. Specifically, on the algorithm level, RT-NeRF integrates an efficient rendering pipeline for largely alleviating the inefficiency due to the commonly adopted uniform point sampling method in NeRF by directly computing the geometry of pre-existing points. Additionally, RT-NeRF leverages a coarse-grained view-dependent computing ordering scheme for eliminating the (unnecessary) processing of invisible points. On the hardware level, our proposed RT-NeRF accelerator (1) adopts a hybrid encoding scheme to adaptively switch between a bitmap- or coordinate-based sparsity encoding format for NeRF's sparse embeddings, aiming to maximize the storage savings and thus reduce the required DRAM accesses while supporting efficient NeRF decoding; and (2) integrates both a dual-purpose bi-direction adder & search tree and a high-density sparse search unit to coordinate the two aforementioned encoding formats. Extensive experiments on eight datasets consistently validate the effectiveness of RT-NeRF, achieving a large throughput improvement (e.g., 9.7x - 3,201x) while maintaining the rendering quality as compared with SOTA efficient NeRF solutions. ",
    "url": "https://arxiv.org/abs/2212.01120",
    "authors": [
      "Chaojian Li",
      "Sixu Li",
      "Yang Zhao",
      "Wenbo Zhu",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2212.01128",
    "title": "A Multi-Stream Fusion Network for Image Splicing Localization",
    "abstract": "In this paper, we address the problem of image splicing localization with a multi-stream network architecture that processes the raw RGB image in parallel with other handcrafted forensic signals. Unlike previous methods that either use only the RGB images or stack several signals in a channel-wise manner, we propose an encoder-decoder architecture that consists of multiple encoder streams. Each stream is fed with either the tampered image or handcrafted signals and processes them separately to capture relevant information from each one independently. Finally, the extracted features from the multiple streams are fused in the bottleneck of the architecture and propagated to the decoder network that generates the output localization map. We experiment with two handcrafted algorithms, i.e., DCT and Splicebuster. Our proposed approach is benchmarked on three public forensics datasets, demonstrating competitive performance against several competing methods and achieving state-of-the-art results, e.g., 0.898 AUC on CASIA. ",
    "url": "https://arxiv.org/abs/2212.01128",
    "authors": [
      "Maria Siopi",
      "Giorgos Kordopatis-Zilos",
      "Polychronis Charitidis",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01136",
    "title": "Robustness in Fatigue Strength Estimation",
    "abstract": "Fatigue strength estimation is a costly manual material characterization process in which state-of-the-art approaches follow a standardized experiment and analysis procedure. In this paper, we examine a modular, Machine Learning-based approach for fatigue strength estimation that is likely to reduce the number of experiments and, thus, the overall experimental costs. Despite its high potential, deployment of a new approach in a real-life lab requires more than the theoretical definition and simulation. Therefore, we study the robustness of the approach against misspecification of the prior and discretization of the specified loads. We identify its applicability and its advantageous behavior over the state-of-the-art methods, potentially reducing the number of costly experiments. ",
    "url": "https://arxiv.org/abs/2212.01136",
    "authors": [
      "Dorina Weichert",
      "Alexander Kister",
      "Sebastian Houben",
      "Gunar Ernis",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01168",
    "title": "Identifying Hamiltonian manifold in neural networks",
    "abstract": "Recent studies to learn physical laws via deep learning attempt to find the shared representation of the given system by introducing physics priors or inductive biases to the neural network. However, most of these approaches tackle the problem in a system-specific manner, in which one neural network trained to one particular physical system cannot be easily adapted to another system governed by a different physical law. In this work, we use a meta-learning algorithm to identify the general manifold in neural networks that represents Hamilton's equation. We meta-trained the model with the dataset composed of five dynamical systems each governed by different physical laws. We show that with only a few gradient steps, the meta-trained model adapts well to the physical system which was unseen during the meta-training phase. Our results suggest that the meta-trained model can craft the representation of Hamilton's equation in neural networks which is shared across various dynamical systems with each governed by different physical laws. ",
    "url": "https://arxiv.org/abs/2212.01168",
    "authors": [
      "Yeongwoo Song",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2212.01173",
    "title": "DWRSeg: Dilation-wise Residual Network for Real-time Semantic  Segmentation",
    "abstract": "Real-time semantic segmentation has played an important role in intelligent vehicle scenarios. Recently, numerous networks have incorporated information from multi-size receptive fields to facilitate feature extraction in real-time semantic segmentation tasks. However, these methods preferentially adopt massive receptive fields to elicit more contextual information, which may result in inefficient feature extraction. We believe that the elaborated receptive fields are crucial, considering the demand for efficient feature extraction in real-time tasks. Therefore, we propose an effective and efficient architecture termed Dilation-wise Residual segmentation (DWRSeg), which possesses different sets of receptive field sizes within different stages. The architecture involves (i) a Dilation-wise Residual (DWR) module for extracting features based on different scales of receptive fields in the high level of the network; (ii) a Simple Inverted Residual (SIR) module that uses an inverted bottleneck structure to extract features from the low stage; and (iii) a simple fully convolutional network (FCN)-like decoder for aggregating multiscale feature maps to generate the prediction. Extensive experiments on the Cityscapes and CamVid datasets demonstrate the effectiveness of our method by achieving a state-of-the-art trade-off between accuracy and inference speed, in addition to being lighter weight. Without using pretraining or resorting to any training trick, we achieve 72.7% mIoU on the Cityscapes test set at a speed of 319.5 FPS on one NVIDIA GeForce GTX 1080 Ti card, which is significantly faster than existing methods. The code and trained models are publicly available. ",
    "url": "https://arxiv.org/abs/2212.01173",
    "authors": [
      "Haoran Wei",
      "Xu Liu",
      "Shouchun Xu",
      "Zhongjian Dai",
      "Yaping Dai",
      "Xiangyang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01175",
    "title": "Flip Graphs for Matrix Multiplication",
    "abstract": "We introduce a new method for discovering matrix multiplication schemes based on random walks in a certain graph, which we call the flip graph. Using this method, we were able to reduce the number of multiplications for the matrix formats (4, 4, 5) and (5, 5, 5), both in characteristic two and for arbitrary ground fields. ",
    "url": "https://arxiv.org/abs/2212.01175",
    "authors": [
      "Manuel Kauers",
      "Jakob Moosbauer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2212.01187",
    "title": "Surrogate Gradient Spiking Neural Networks as Encoders for Large  Vocabulary Continuous Speech Recognition",
    "abstract": "Compared to conventional artificial neurons that produce dense and real-valued responses, biologically-inspired spiking neurons transmit sparse and binary information, which can also lead to energy-efficient implementations. Recent research has shown that spiking neural networks can be trained like standard recurrent neural networks using the surrogate gradient method. They have shown promising results on speech command recognition tasks. Using the same technique, we show that they are scalable to large vocabulary continuous speech recognition, where they are capable of replacing LSTMs in the encoder with only minor loss of performance. This suggests that they may be applicable to more involved sequence-to-sequence tasks. Moreover, in contrast to their recurrent non-spiking counterparts, they show robustness to exploding gradient problems without the need to use gates. ",
    "url": "https://arxiv.org/abs/2212.01187",
    "authors": [
      "Alexandre Bittar",
      "Philip N. Garner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.01189",
    "title": "Denoising after Entropy-based Debiasing A Robust Training Method for  Dataset Bias with Noisy Labels",
    "abstract": "Improperly constructed datasets can result in inaccurate inferences. For instance, models trained on biased datasets perform poorly in terms of generalization (i.e., dataset bias). Recent debiasing techniques have successfully achieved generalization performance by underestimating easy-to-learn samples (i.e., bias-aligned samples) and highlighting difficult-to-learn samples (i.e., bias-conflicting samples). However, these techniques may fail owing to noisy labels, because the trained model recognizes noisy labels as difficult-to-learn and thus highlights them. In this study, we find that earlier approaches that used the provided labels to quantify difficulty could be affected by the small proportion of noisy labels. Furthermore, we find that running denoising algorithms before debiasing is ineffective because denoising algorithms reduce the impact of difficult-to-learn samples, including valuable bias-conflicting samples. Therefore, we propose an approach called denoising after entropy-based debiasing, i.e., DENEB, which has three main stages. (1) The prejudice model is trained by emphasizing (bias-aligned, clean) samples, which are selected using a Gaussian Mixture Model. (2) Using the per-sample entropy from the output of the prejudice model, the sampling probability of each sample that is proportional to the entropy is computed. (3) The final model is trained using existing denoising algorithms with the mini-batches constructed by following the computed sampling probability. Compared to existing debiasing and denoising algorithms, our method achieves better debiasing performance on multiple benchmarks. ",
    "url": "https://arxiv.org/abs/2212.01189",
    "authors": [
      "Sumyeong Ahn",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01196",
    "title": "Vector Symbolic Finite State Machines in Attractor Neural Networks",
    "abstract": "Hopfield attractor networks are robust distributed models of human memory. We propose construction rules such that an attractor network may implement an arbitrary finite state machine (FSM), where states and stimuli are represented by high-dimensional random bipolar vectors, and all state transitions are enacted by the attractor network's dynamics. Numerical simulations show the capacity of the model, in terms of the maximum size of implementable FSM, to be linear in the size of the attractor network. We show that the model is robust to imprecise and noisy weights, and so a prime candidate for implementation with high-density but unreliable devices. By endowing attractor networks with the ability to emulate arbitrary FSMs, we propose a plausible path by which FSMs may exist as a distributed computational primitive in biological neural networks. ",
    "url": "https://arxiv.org/abs/2212.01196",
    "authors": [
      "Madison Cotteret",
      "Hugh Greatorex",
      "Martin Ziegler",
      "Elisabetta Chicca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.01215",
    "title": "Olive Branch Learning: A Topology-Aware Federated Learning Framework for  Space-Air-Ground Integrated Network",
    "abstract": "The space-air-ground integrated network (SAGIN), one of the key technologies for next-generation mobile communication systems, can facilitate data transmission for users all over the world, especially in some remote areas where vast amounts of informative data are collected by Internet of remote things (IoRT) devices to support various data-driven artificial intelligence (AI) services. However, training AI models centrally with the assistance of SAGIN faces the challenges of highly constrained network topology, inefficient data transmission, and privacy issues. To tackle these challenges, we first propose a novel topology-aware federated learning framework for the SAGIN, namely Olive Branch Learning (OBL). Specifically, the IoRT devices in the ground layer leverage their private data to perform model training locally, while the air nodes in the air layer and the ring-structured low earth orbit (LEO) satellite constellation in the space layer are in charge of model aggregation (synchronization) at different scales.To further enhance communication efficiency and inference performance of OBL, an efficient Communication and Non-IID-aware Air node-Satellite Assignment (CNASA) algorithm is designed by taking the data class distribution of the air nodes as well as their geographic locations into account. Furthermore, we extend our OBL framework and CNASA algorithm to adapt to more complex multi-orbit satellite networks. We analyze the convergence of our OBL framework and conclude that the CNASA algorithm contributes to the fast convergence of the global model. Extensive experiments based on realistic datasets corroborate the superior performance of our algorithm over the benchmark policies. ",
    "url": "https://arxiv.org/abs/2212.01215",
    "authors": [
      "Qingze Fang",
      "Zhiwei Zhai",
      "Shuai Yu",
      "Qiong Wu",
      "Xiaowen Gong",
      "Xu Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.01218",
    "title": "Answer ranking in Community Question Answering: a deep learning approach",
    "abstract": "Community Question Answering is the field of computational linguistics that deals with problems derived from the questions and answers posted to websites such as Quora or Stack Overflow. Among some of these problems we find the issue of ranking the multiple answers posted in reply to each question by how informative they are in the attempt to solve the original question. This work tries to advance the state of the art on answer ranking for community Question Answering by proceeding with a deep learning approach. We started off by creating a large data set of questions and answers posted to the Stack Overflow website. We then leveraged the natural language processing capabilities of dense embeddings and LSTM networks to produce a prediction for the accepted answer attribute, and present the answers in a ranked form ordered by how likely they are to be marked as accepted by the question asker. We also produced a set of numerical features to assist with the answer ranking task. These numerical features were either extracted from metadata found in the Stack Overflow posts or derived from the questions and answers texts. We compared the performance of our deep learning models against a set of forest and boosted trees ensemble methods and found that our models could not improve the best baseline results. We speculate that this lack of performance improvement versus the baseline models may be caused by the large number of out of vocabulary words present in the programming code snippets found in the questions and answers text. We conclude that while a deep learning approach may be helpful in answer ranking problems new methods should be developed to assist with the large number of out of vocabulary words present in the programming code snippets ",
    "url": "https://arxiv.org/abs/2212.01218",
    "authors": [
      "Lucas Valentin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.01231",
    "title": "BEV-SAN: Accurate BEV 3D Object Detection via Slice Attention Networks",
    "abstract": "Bird's-Eye-View (BEV) 3D Object Detection is a crucial multi-view technique for autonomous driving systems. Recently, plenty of works are proposed, following a similar paradigm consisting of three essential components, i.e., camera feature extraction, BEV feature construction, and task heads. Among the three components, BEV feature construction is BEV-specific compared with 2D tasks. Existing methods aggregate the multi-view camera features to the flattened grid in order to construct the BEV feature. However, flattening the BEV space along the height dimension fails to emphasize the informative features of different heights. For example, the barrier is located at a low height while the truck is located at a high height. In this paper, we propose a novel method named BEV Slice Attention Network (BEV-SAN) for exploiting the intrinsic characteristics of different heights. Instead of flattening the BEV space, we first sample along the height dimension to build the global and local BEV slices. Then, the features of BEV slices are aggregated from the camera features and merged by the attention mechanism. Finally, we fuse the merged local and global BEV features by a transformer to generate the final feature map for task heads. The purpose of local BEV slices is to emphasize informative heights. In order to find them, we further propose a LiDAR-guided sampling strategy to leverage the statistical distribution of LiDAR to determine the heights of local slices. Compared with uniform sampling, LiDAR-guided sampling can determine more informative heights. We conduct detailed experiments to demonstrate the effectiveness of BEV-SAN. Code will be released. ",
    "url": "https://arxiv.org/abs/2212.01231",
    "authors": [
      "Xiaowei Chi",
      "Jiaming Liu",
      "Ming Lu",
      "Rongyu Zhang",
      "Zhaoqing Wang",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01232",
    "title": "Loss shaping enhances exact gradient learning with EventProp in Spiking  Neural Networks",
    "abstract": "In a recent paper Wunderlich and Pehle introduced the EventProp algorithm that enables training spiking neural networks by gradient descent on exact gradients. In this paper we present extensions of EventProp to support a wider class of loss functions and an implementation in the GPU enhanced neuronal networks framework which exploits sparsity. The GPU acceleration allows us to test EventProp extensively on more challenging learning benchmarks. We find that EventProp performs well on some tasks but for others there are issues where learning is slow or fails entirely. Here, we analyse these issues in detail and discover that they relate to the use of the exact gradient of the loss function, which by its nature does not provide information about loss changes due to spike creation or spike deletion. Depending on the details of the task and loss function, descending the exact gradient with EventProp can lead to the deletion of important spikes and so to an inadvertent increase of the loss and decrease of classification accuracy and hence a failure to learn. In other situations the lack of knowledge about the benefits of creating additional spikes can lead to a lack of gradient flow into earlier layers, slowing down learning. We eventually present a first glimpse of a solution to these problems in the form of `loss shaping', where we introduce a suitable weighting function into an integral loss to increase gradient flow from the output layer towards earlier layers. ",
    "url": "https://arxiv.org/abs/2212.01232",
    "authors": [
      "Thomas Nowotny",
      "James P. Turner",
      "James C. Knight"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01254",
    "title": "Deep-Learning-based Vulnerability Detection in Binary Executables",
    "abstract": "The identification of vulnerabilities is an important element in the software development life cycle to ensure the security of software. While vulnerability identification based on the source code is a well studied field, the identification of vulnerabilities on basis of a binary executable without the corresponding source code is more challenging. Recent research [1] has shown, how such detection can be achieved by deep learning methods. However, that particular approach is limited to the identification of only 4 types of vulnerabilities. Subsequently, we analyze to what extent we could cover the identification of a larger variety of vulnerabilities. Therefore, a supervised deep learning approach using recurrent neural networks for the application of vulnerability detection based on binary executables is used. The underlying basis is a dataset with 50,651 samples of vulnerable code in the form of a standardized LLVM Intermediate Representation. The vectorised features of a Word2Vec model are used to train different variations of three basic architectures of recurrent neural networks (GRU, LSTM, SRNN). A binary classification was established for detecting the presence of an arbitrary vulnerability, and a multi-class model was trained for the identification of the exact vulnerability, which achieved an out-of-sample accuracy of 88% and 77%, respectively. Differences in the detection of different vulnerabilities were also observed, with non-vulnerable samples being detected with a particularly high precision of over 98%. Thus, the methodology presented allows an accurate detection of 23 (compared to 4 [1]) vulnerabilities. ",
    "url": "https://arxiv.org/abs/2212.01254",
    "authors": [
      "Andreas Schaad",
      "Dominik Binder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01261",
    "title": "Generative Reasoning Integrated Label Noise Robust Deep Image  Representation Learning in Remote Sensing",
    "abstract": "The development of deep learning based image representation learning (IRL) methods has attracted great attention in the context of remote sensing (RS) image understanding. Most of these methods require the availability of a high quantity and quality of annotated training images, which can be time-consuming and costly to gather. To reduce labeling costs, publicly available thematic maps, automatic labeling procedures or crowdsourced data can be used. However, such approaches increase the risk of including label noise in training data. It may result in overfitting on noisy labels when discriminative reasoning is employed as in most of the existing methods. This leads to sub-optimal learning procedures, and thus inaccurate characterization of RS images. In this paper, as a first time in RS, we introduce a generative reasoning integrated label noise robust representation learning (GRID) approach. GRID aims to model the complementary characteristics of discriminative and generative reasoning for IRL under noisy labels. To this end, we first integrate generative reasoning into discriminative reasoning through a variational autoencoder. This allows our approach to automatically detect training samples with noisy labels. Then, through our label noise robust hybrid representation learning strategy, GRID adjusts the whole learning procedure for IRL of these samples through generative reasoning and that of the other samples through discriminative reasoning. Our approach learns discriminative image representations while preventing interference of noisy labels during training independently from the IRL method. Thus, unlike the existing methods, GRID does not depend on the type of annotation, label noise, neural network, loss or learning task, and thus can be utilized for various RS image understanding problems. Experimental results show the effectiveness of GRID compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2212.01261",
    "authors": [
      "Gencer Sumbul",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01279",
    "title": "Initial Results for Pairwise Causal Discovery Using Quantitative  Information Flow",
    "abstract": "Pairwise Causal Discovery is the task of determining causal, anticausal, confounded or independence relationships from pairs of variables. Over the last few years, this challenging task has promoted not only the discovery of novel machine learning models aimed at solving the task, but also discussions on how learning the causal direction of variables may benefit machine learning overall. In this paper, we show that Quantitative Information Flow (QIF), a measure usually employed for measuring leakages of information from a system to an attacker, shows promising results as features for the task. In particular, experiments with real-world datasets indicate that QIF is statistically tied to the state of the art. Our initial results motivate further inquiries on how QIF relates to causality and what are its limitations. ",
    "url": "https://arxiv.org/abs/2212.01279",
    "authors": [
      "Felipe Giori",
      "Flavio Figueiredo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.01287",
    "title": "SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection",
    "abstract": "Change detection (CD) aims to find the difference between two images at different times and outputs a change map to represent whether the region has changed or not. To achieve a better result in generating the change map, many State-of-The-Art (SoTA) methods design a deep learning model that has a powerful discriminative ability. However, these methods still get lower performance because they ignore spatial information and scaling changes between objects, giving rise to blurry or wrong boundaries. In addition to these, they also neglect the interactive information of two different images. To alleviate these problems, we propose our network, the Scale and Relation-Aware Siamese Network (SARAS-Net) to deal with this issue. In this paper, three modules are proposed that include relation-aware, scale-aware, and cross-transformer to tackle the problem of scene change detection more effectively. To verify our model, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN, and obtained SoTA accuracy. Our code is available at https://github.com/f64051041/SARAS-Net. ",
    "url": "https://arxiv.org/abs/2212.01287",
    "authors": [
      "Chao-Peng Chen",
      "Jun-Wei Hsieh",
      "Ping-Yang Chen",
      "Yi-Kuan Hsieh",
      "Bor-Shiun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01298",
    "title": "5G-NIDD: A Comprehensive Network Intrusion Detection Dataset Generated  over 5G Wireless Network",
    "abstract": "With a plethora of new connections, features, and services introduced, the 5th generation (5G) wireless technology reflects the development of mobile communication networks and is here to stay for the next decade. The multitude of services and technologies that 5G incorporates have made modern communication networks very complex and sophisticated in nature. This complexity along with the incorporation of Machine Learning (ML) and Artificial Intelligence (AI) provides the opportunity for the attackers to launch intelligent attacks against the network and network devices. These attacks often traverse undetected due to the lack of intelligent security mechanisms to counter these threats. Therefore, the implementation of real-time, proactive, and self-adaptive security mechanisms throughout the network would be an integral part of 5G as well as future communication systems. Therefore, large amounts of data collected from real networks will play an important role in the training of AI/ML models to identify and detect malicious content in network traffic. This work presents 5G-NIDD, a fully labeled dataset built on a functional 5G test network that can be used by those who develop and test AI/ML solutions. The work further analyses the collected data using common ML models and shows the achieved accuracy levels. ",
    "url": "https://arxiv.org/abs/2212.01298",
    "authors": [
      "Sehan Samarakoon",
      "Yushan Siriwardhana",
      "Pawani Porambage",
      "Madhusanka Liyanage",
      "Sang-Yoon Chang",
      "Jinoh Kim",
      "Jonghyun Kim",
      "Mika Ylianttila"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.01302",
    "title": "DeepFT: Fault-Tolerant Edge Computing using a Self-Supervised Deep  Surrogate Model",
    "abstract": "The emergence of latency-critical AI applications has been supported by the evolution of the edge computing paradigm. However, edge solutions are typically resource-constrained, posing reliability challenges due to heightened contention for compute and communication capacities and faulty application behavior in the presence of overload conditions. Although a large amount of generated log data can be mined for fault prediction, labeling this data for training is a manual process and thus a limiting factor for automation. Due to this, many companies resort to unsupervised fault-tolerance models. Yet, failure models of this kind can incur a loss of accuracy when they need to adapt to non-stationary workloads and diverse host characteristics. To cope with this, we propose a novel modeling approach, called DeepFT, to proactively avoid system overloads and their adverse effects by optimizing the task scheduling and migration decisions. DeepFT uses a deep surrogate model to accurately predict and diagnose faults in the system and co-simulation based self-supervised learning to dynamically adapt the model in volatile settings. It offers a highly scalable solution as the model size scales by only 3 and 1 percent per unit increase in the number of active tasks and hosts. Extensive experimentation on a Raspberry-Pi based edge cluster with DeFog benchmarks shows that DeepFT can outperform state-of-the-art baseline methods in fault-detection and QoS metrics. Specifically, DeepFT gives the highest F1 scores for fault-detection, reducing service deadline violations by up to 37\\% while also improving response time by up to 9%. ",
    "url": "https://arxiv.org/abs/2212.01302",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Ludmila Cherkasova",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01321",
    "title": "Iterative Power Control for Wireless Networks with Distributed  Reconfigurable Intelligent Surfaces",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) are a new paradigm which, with judicious deployment and alignment, can enable more favorable propagation environments and better wireless network design. As such, they can offer a number of potential benefits for next generation wireless systems including improved coverage, better interference management and even security. In this paper, we consider an uplink next generation wireless system where each user is assisted with an RIS. We study the uplink power control problem in this distributed RIS-assisted wireless network. Specifically, we aim to minimize total uplink transmit power of all the users subject to each user's reliable communication requirements at the base station by a joint design of power, receiver filter and RIS phase matrices. We propose an iterative power control algorithm, combined with a successive convex approximation technique to solve the problem with non-convex phase constraints. Numerical results illustrate that distributed RIS assistance leads to uplink power savings when direct links are weak. ",
    "url": "https://arxiv.org/abs/2212.01321",
    "authors": [
      "Jiayu Mao",
      "Aylin Yener"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.01331",
    "title": "Neural Radiance Fields for Manhattan Scenes with Unknown Manhattan Frame",
    "abstract": "Novel view synthesis and 3D modeling using implicit neural field representation are shown to be very effective for calibrated multi-view cameras. Such representations are known to benefit from additional geometric and semantic supervision. Most existing methods that exploit additional supervision require dense pixel-wise labels or localized scene priors. These methods cannot benefit from high-level vague scene priors provided in terms of scenes' descriptions. In this work, we aim to leverage the geometric prior of Manhattan scenes to improve the implicit neural radiance field representations. More precisely, we assume that only the knowledge of the scene (under investigation) being Manhattan is known - with no additional information whatsoever - with an unknown Manhattan coordinate frame. Such high-level prior is then used to self-supervise the surface normals derived explicitly in the implicit neural fields. Our modeling allows us to group the derived normals, followed by exploiting their orthogonality constraints for self-supervision. Our exhaustive experiments on datasets of diverse indoor scenes demonstrate the significant benefit of the proposed method over the established baselines. ",
    "url": "https://arxiv.org/abs/2212.01331",
    "authors": [
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01356",
    "title": "Sequential Anomaly Detection Against Demodulation Reference Signal  Spoofing in 5G NR",
    "abstract": "In fifth generation (5G) new radio (NR), the demodulation reference signal (DMRS) is employed for channel estimation as part of coherent demodulation of the physical uplink shared channel. However, DMRS spoofing poses a serious threat to 5G NR since inaccurate channel estimation will severely degrade the decoding performance. In this correspondence, we propose to exploit the spatial sparsity structure of the channel to detect the DMRS spoofing, which is motivated by the fact that the spatial sparsity structure of the channel will be significantly impacted if the DMRS spoofing happens. We first extract the spatial sparsity structure of the channel by solving a sparse feature retrieval problem, then propose a sequential sparsity structure anomaly detection method to detect DMRS spoofing. In simulation experiments, we exploit clustered delay line based channel model from 3GPP standards for verifications. Numerical results show that our method outperforms both the subspace dimension based and energy detector based methods. ",
    "url": "https://arxiv.org/abs/2212.01356",
    "authors": [
      "Shao-Di Wang",
      "Hui-Ming Wang",
      "Chen Feng",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.01362",
    "title": "Fast Detection of Burst Jamming for Delay-Sensitive Internet-of-Things  Applications",
    "abstract": "In this paper, we investigate the design of a burst jamming detection method for delay-sensitive Internet-of-Things (IoT) applications. In order to obtain a timely detection of burst jamming, we propose an online principal direction anomaly detection (OPDAD) method. We consider the one-ring scatter channel model, where the base station equipped with a large number of antennas is elevated at a high altitude. In this case, since the angular spread of the legitimate IoT transmitter or the jammer is restricted within a narrow region, there is a distinct difference of the principal direction of the signal space between the jamming attack and the normal state. Unlike existing statistical features based batching methods, the proposed OPDAD method adopts an online iterative processing mode, which can quickly detect the exact attack time block instance by analyzing the newly coming signal. In addition, our detection method does not rely on the prior knowledge of the attacker, because it only cares the abrupt change in the principal direction of the signal space. Moreover, based on the high spatial resolution and the narrow angular spread, we provide the convergence rate estimate and derive a nearly optimal finite sample error bound for the proposed OPDAD method. Numerical results show the excellent real time capability and detection performance of our proposed method. ",
    "url": "https://arxiv.org/abs/2212.01362",
    "authors": [
      "Shao-Di Wang",
      "Hui-Ming Wang",
      "Peng Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.01365",
    "title": "An Information-Theoretic Analysis of Compute-Optimal Neural Scaling Laws",
    "abstract": "We study the compute-optimal trade-off between model and training data set sizes for large neural networks. Our result suggests a linear relation similar to that supported by the empirical analysis of Chinchilla. While that work studies transformer-based large language models trained on the MassiveText corpus (gopher), as a starting point for development of a mathematical theory, we focus on a simpler learning model and data generating process, each based on a neural network with a sigmoidal output unit and single hidden layer of ReLU activation units. We establish an upper bound on the minimal information-theoretically achievable expected error as a function of model and data set sizes. We then derive allocations of computation that minimize this bound. We present empirical results which suggest that this approximation correctly identifies an asymptotic linear compute-optimal scaling. This approximation can also generate new insights. Among other things, it suggests that, as the input space dimension or latent space complexity grows, as might be the case for example if a longer history of tokens is taken as input to a language model, a larger fraction of the compute budget should be allocated to growing the learning model rather than training data set. ",
    "url": "https://arxiv.org/abs/2212.01365",
    "authors": [
      "Hong Jun Jeon",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01371",
    "title": "Adaptive Robust Model Predictive Control via Uncertainty Cancellation",
    "abstract": "We propose a learning-based robust predictive control algorithm that compensates for significant uncertainty in the dynamics for a class of discrete-time systems that are nominally linear with an additive nonlinear component. Such systems commonly model the nonlinear effects of an unknown environment on a nominal system. We optimize over a class of nonlinear feedback policies inspired by certainty equivalent \"estimate-and-cancel\" control laws pioneered in classical adaptive control to achieve significant performance improvements in the presence of uncertainties of large magnitude, a setting in which existing learning-based predictive control algorithms often struggle to guarantee safety. In contrast to previous work in robust adaptive MPC, our approach allows us to take advantage of structure (i.e., the numerical predictions) in the a priori unknown dynamics learned online through function approximation. Our approach also extends typical nonlinear adaptive control methods to systems with state and input constraints even when we cannot directly cancel the additive uncertain function from the dynamics. We apply contemporary statistical estimation techniques to certify the system's safety through persistent constraint satisfaction with high probability. Moreover, we propose using Bayesian meta-learning algorithms that learn calibrated model priors to help satisfy the assumptions of the control design in challenging settings. Finally, we show in simulation that our method can accommodate more significant unknown dynamics terms than existing methods and that the use of Bayesian meta-learning allows us to adapt to the test environments more rapidly. ",
    "url": "https://arxiv.org/abs/2212.01371",
    "authors": [
      "Rohan Sinha",
      "James Harrison",
      "Spencer M. Richards",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.01372",
    "title": "Bitcoin Security-Latency Under Network Delay",
    "abstract": "We improve security-latency bounds of Nakamoto consensus by analyzing the race between adversarial and honest chains in three different phases: pre-mining, confirmation and post-confirmation. We find the probability distribution of the length of the adversarial chain and the rigged adversarial chain under jumper models during the confirmation interval. We analyze certain properties of this race to model pre-mining and post-confirmation phases with random walks that provide tighter bounds than existing results. Combining all three phases provides novel upper and lower bounds for blockchains with small $\\lambda\\Delta$. ",
    "url": "https://arxiv.org/abs/2212.01372",
    "authors": [
      "Mustafa Doger",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.01375",
    "title": "Embedding Synthetic Off-Policy Experience for Autonomous Driving via  Zero-Shot Curricula",
    "abstract": "ML-based motion planning is a promising approach to produce agents that exhibit complex behaviors, and automatically adapt to novel environments. In the context of autonomous driving, it is common to treat all available training data equally. However, this approach produces agents that do not perform robustly in safety-critical settings, an issue that cannot be addressed by simply adding more data to the training set - we show that an agent trained using only a 10% subset of the data performs just as well as an agent trained on the entire dataset. We present a method to predict the inherent difficulty of a driving situation given data collected from a fleet of autonomous vehicles deployed on public roads. We then demonstrate that this difficulty score can be used in a zero-shot transfer to generate curricula for an imitation-learning based planning agent. Compared to training on the entire unbiased training dataset, we show that prioritizing difficult driving scenarios both reduces collisions by 15% and increases route adherence by 14% in closed-loop evaluation, all while using only 10% of the training data. ",
    "url": "https://arxiv.org/abs/2212.01375",
    "authors": [
      "Eli Bronstein",
      "Sirish Srinivasan",
      "Supratik Paul",
      "Aman Sinha",
      "Matthew O'Kelly",
      "Payam Nikdel",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01376",
    "title": "D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object  Detection via Progressive Domain Adaptation",
    "abstract": "Weakly-supervised object detection (WSOD) models attempt to leverage image-level annotations in lieu of accurate but costly-to-obtain object localization labels. This oftentimes leads to substandard object detection and localization at inference time. To tackle this issue, we propose D2DF2WOD, a Dual-Domain Fully-to-Weakly Supervised Object Detection framework that leverages synthetic data, annotated with precise object localization, to supplement a natural image target domain, where only image-level labels are available. In its warm-up domain adaptation stage, the model learns a fully-supervised object detector (FSOD) to improve the precision of the object proposals in the target domain, and at the same time learns target-domain-specific and detection-aware proposal features. In its main WSOD stage, a WSOD model is specifically tuned to the target domain. The feature extractor and the object proposal generator of the WSOD model are built upon the fine-tuned FSOD model. We test D2DF2WOD on five dual-domain image benchmarks. The results show that our method results in consistently improved object detection and localization compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2212.01376",
    "authors": [
      "Yuting Wang",
      "Ricardo Guerrero",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.00796",
    "title": "Convolutional Long Short-Term Memory (convLSTM) for Spatio-Temporal  Forecastings of Saturations and Pressure in the SACROC Field",
    "abstract": "A machine learning architecture composed of convolutional long short-term memory (convLSTM) is developed to predict spatio-temporal parameters in the SACROC oil field, Texas, USA. The spatial parameters are recorded at the end of each month for 30 years (360 months), approximately 83% (300 months) of which is used for training and the rest 17% (60 months) is kept for testing. The samples for the convLSTM models are prepared by choosing ten consecutive frames as input and ten consecutive frames shifted forward by one frame as output. Individual models are trained for oil, gas, and water saturations, and pressure using the Nesterov accelerated adaptive moment estimation (Nadam) optimization algorithm. A workflow is provided to comprehend the entire process of data extraction, preprocessing, sample preparation, training, testing of machine learning models, and error analysis. Overall, the convLSTM for spatio-temporal prediction shows promising results in predicting spatio-temporal parameters in porous media. ",
    "url": "https://arxiv.org/abs/2212.00796",
    "authors": [
      "Palash Panja",
      "Wei Jia",
      "Alec Nelson",
      "Brian McPherson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00832",
    "title": "Applications of Lattice Gauge Equivariant Neural Networks",
    "abstract": "The introduction of relevant physical information into neural network architectures has become a widely used and successful strategy for improving their performance. In lattice gauge theories, such information can be identified with gauge symmetries, which are incorporated into the network layers of our recently proposed Lattice Gauge Equivariant Convolutional Neural Networks (L-CNNs). L-CNNs can generalize better to differently sized lattices than traditional neural networks and are by construction equivariant under lattice gauge transformations. In these proceedings, we present our progress on possible applications of L-CNNs to Wilson flow or continuous normalizing flow. Our methods are based on neural ordinary differential equations which allow us to modify link configurations in a gauge equivariant manner. For simplicity, we focus on simple toy models to test these ideas in practice. ",
    "url": "https://arxiv.org/abs/2212.00832",
    "authors": [
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ]
  },
  {
    "id": "arXiv:2212.00860",
    "title": "A Model-based GNN for Learning Precoding",
    "abstract": "Learning precoding policies with neural networks enables low complexity online implementation, robustness to channel impairments, and joint optimization with channel acquisition. However, existing neural networks suffer from high training complexity and poor generalization ability when they are used to learn to optimize precoding for mitigating multi-user interference. This impedes their use in practical systems where the number of users is time-varying. In this paper, we propose a graph neural network (GNN) to learn precoding policies by harnessing both the mathematical model and the property of the policies. We first show that a vanilla GNN cannot well-learn pseudo-inverse of channel matrix when the numbers of antennas and users are large, and is not generalizable to unseen numbers of users. Then, we design a GNN by resorting to the Taylor's expansion of matrix pseudo-inverse, which allows for capturing the importance of the neighbored edges to be aggregated that is crucial for learning precoding policies efficiently. Simulation results show that the proposed GNN can well learn spectral efficient and energy efficient precoding policies in single- and multi-cell multi-user multi-antenna systems with low training complexity, and can be well generalized to the numbers of users. ",
    "url": "https://arxiv.org/abs/2212.00860",
    "authors": [
      "Jia Guo",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00896",
    "title": "Nonlinear controllability and function representation by neural  stochastic differential equations",
    "abstract": "There has been a great deal of recent interest in learning and approximation of functions that can be expressed as expectations of a given nonlinearity with respect to its random internal parameters. Examples of such representations include \"infinitely wide\" neural nets, where the underlying nonlinearity is given by the activation function of an individual neuron. In this paper, we bring this perspective to function representation by neural stochastic differential equations (SDEs). A neural SDE is an It\\^o diffusion process whose drift and diffusion matrix are elements of some parametric families. We show that the ability of a neural SDE to realize nonlinear functions of its initial condition can be related to the problem of optimally steering a certain deterministic dynamical system between two given points in finite time. This auxiliary system is obtained by formally replacing the Brownian motion in the SDE by a deterministic control input. We derive upper and lower bounds on the minimum control effort needed to accomplish this steering; these bounds may be of independent interest in the context of motion planning and deterministic optimal control. ",
    "url": "https://arxiv.org/abs/2212.00896",
    "authors": [
      "Tanya Veeravalli",
      "Maxim Raginsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01108",
    "title": "SLMT-Net: A Self-supervised Learning based Multi-scale Transformer  Network for Cross-Modality MR Image Synthesis",
    "abstract": "Cross-modality magnetic resonance (MR) image synthesis aims to produce missing modalities from existing ones. Currently, several methods based on deep neural networks have been developed using both source- and target-modalities in a supervised learning manner. However, it remains challenging to obtain a large amount of completely paired multi-modal training data, which inhibits the effectiveness of existing methods. In this paper, we propose a novel Self-supervised Learning-based Multi-scale Transformer Network (SLMT-Net) for cross-modality MR image synthesis, consisting of two stages, \\ie, a pre-training stage and a fine-tuning stage. During the pre-training stage, we propose an Edge-preserving Masked AutoEncoder (Edge-MAE), which preserves the contextual and edge information by simultaneously conducting the image reconstruction and the edge generation. Besides, a patch-wise loss is proposed to treat the input patches differently regarding their reconstruction difficulty, by measuring the difference between the reconstructed image and the ground-truth. In this case, our Edge-MAE can fully leverage a large amount of unpaired multi-modal data to learn effective feature representations. During the fine-tuning stage, we present a Multi-scale Transformer U-Net (MT-UNet) to synthesize the target-modality images, in which a Dual-scale Selective Fusion (DSF) module is proposed to fully integrate multi-scale features extracted from the encoder of the pre-trained Edge-MAE. Moreover, we use the pre-trained encoder as a feature consistency module to measure the difference between high-level features of the synthesized image and the ground truth one. Experimental results show the effectiveness of the proposed SLMT-Net, and our model can reliably synthesize high-quality images when the training set is partially unpaired. Our code will be publicly available at https://github.com/lyhkevin/SLMT-Net. ",
    "url": "https://arxiv.org/abs/2212.01108",
    "authors": [
      "Yonghao Li",
      "Tao Zhou",
      "Kelei He",
      "Yi Zhou",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01199",
    "title": "Gibbs-Helmholtz Graph Neural Network: capturing the temperature  dependency of activity coefficients at infinite dilution",
    "abstract": "The accurate prediction of physicochemical properties of chemical compounds in mixtures (such as the activity coefficient at infinite dilution $\\gamma_{ij}^\\infty$) is essential for developing novel and more sustainable chemical processes. In this work, we analyze the performance of previously-proposed GNN-based models for the prediction of $\\gamma_{ij}^\\infty$, and compare them with several mechanistic models in a series of 9 isothermal studies. Moreover, we develop the Gibbs-Helmholtz Graph Neural Network (GH-GNN) model for predicting $\\ln \\gamma_{ij}^\\infty$ of molecular systems at different temperatures. Our method combines the simplicity of a Gibbs-Helmholtz-derived expression with a series of graph neural networks that incorporate explicit molecular and intermolecular descriptors for capturing dispersion and hydrogen bonding effects. We have trained this model using experimentally determined $\\ln \\gamma_{ij}^\\infty$ data of 40,219 binary-systems involving 1032 solutes and 866 solvents, overall showing superior performance compared to the popular UNIFAC-Dortmund model. We analyze the performance of GH-GNN for continuous and discrete inter/extrapolation and give indications for the model's applicability domain and expected accuracy. In general, GH-GNN is able to produce accurate predictions for extrapolated binary-systems if at least 25 systems with the same combination of solute-solvent chemical classes are contained in the training set and a similarity indicator above 0.35 is also present. This model and its applicability domain recommendations have been made open-source at https://github.com/edgarsmdn/GH-GNN. ",
    "url": "https://arxiv.org/abs/2212.01199",
    "authors": [
      "Edgar Ivan Sanchez Medina",
      "Steffen Linke",
      "Martin Stoll",
      "Kai Sundmacher"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01282",
    "title": "CHAPTER: Exploiting Convolutional Neural Network Adapters for  Self-supervised Speech Models",
    "abstract": "Self-supervised learning (SSL) is a powerful technique for learning representations from unlabeled data. Transformer based models such as HuBERT, which consist a feature extractor and transformer layers, are leading the field in the speech domain. SSL models are fine-tuned on a wide range of downstream tasks, which involves re-training the majority of the model for each task. Previous studies have introduced applying adapters, which are small lightweight modules commonly used in Natural Language Processing (NLP) to adapt pre-trained models to new tasks. However, such efficient tuning techniques only provide adaptation at the transformer layer, but failed to perform adaptation at the feature extractor. In this paper, we propose CHAPTER, an efficient tuning method specifically designed for SSL speech model, by applying CNN adapters at the feature extractor. Using this method, we can only fine-tune fewer than 5% of parameters per task compared to fully fine-tuning and achieve better and more stable performance. We empirically found that adding CNN adapters to the feature extractor can help the adaptation on emotion and speaker tasks. For instance, the accuracy of SID is improved from 87.71 to 91.56, and the accuracy of ER is improved by 5%. ",
    "url": "https://arxiv.org/abs/2212.01282",
    "authors": [
      "Zih-Ching Chen",
      "Yu-Shun Sung",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2212.01311",
    "title": "Disjoint faces in simple drawings of the complete graph and topological  Heilbronn problems",
    "abstract": "Given a complete simple topological graph $G$, a $k$-face generated by $G$ is the open bounded region enclosed by the edges of a non-self-intersecting $k$-cycle in $G$. Interestingly, there are complete simple topological graphs with the property that every odd face it generates contains the origin. In this paper, we show that every complete $n$-vertex simple topological graph generates at least $\\Omega(n^{1/3})$ pairwise disjoint 4-faces. As an immediate corollary, every complete simple topological graph on $n$ vertices drawn in the unit square generates a 4-face with area at most $O(n^{-1/3})$. Finally, we investigate a $\\mathbb Z_2$ variant of Heilbronn triangle problem. ",
    "url": "https://arxiv.org/abs/2212.01311",
    "authors": [
      "Alfredo Hubard",
      "Andrew Suk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2212.01337",
    "title": "Vizaj -- An interactive javascript tool for visualizing spatial networks",
    "abstract": "In many fields of science and technology we are confronted with complex networks. Making sense of these networks often require the ability to visualize and explore their intermingled structure consisting of nodes and links. To facilitate the identification of significant connectivity patterns, many methods have been developed based on the rearrangement of the nodes so as to avoid link criss-cross. However, real networks are often embedded in a geometrical space and the nodes code for an intrinsic physical feature of the system that one might want to preserve. For these spatial networks, it is therefore crucial to find alternative strategies operating on the links and not on the nodes. Here, we introduce Vizaj a javascript web application to visualize spatial networks based on optimized geometrical criteria that reshape the link profiles. While optimized for 3D networks, Vizaj can also be used for 2D networks and offers the possibility to interactively customize the visualization via several controlling parameters, including network filtering and the effect of internode distance on the link trajectories. Vizaj is further equipped with additional options allowing to improve the final aesthetics, such as the color/size of both nodes and links, zooming/rotating/translating, and superimposing external objects. Vizaj is an open-source software which can be freely downloaded and updated via a github repository. Here, we provide a detailed description of its main features and algorithms together with a guide on how to use it. Finally, we validate its potential on several synthetic and real spatial networks from infrastructural to biological systems. We hope that Vizaj will help scientists and practitioners to make sense of complex networks and provide aesthetic while informative visualizations. ",
    "url": "https://arxiv.org/abs/2212.01337",
    "authors": [
      "Thibault Rolland",
      "Fabrizio De Vico Fallani"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2212.01361",
    "title": "Entropy-rate as prediction method for newspapers and information  diffusion",
    "abstract": "This paper aims to show how some popular topics on social networks can be used to predict online newspaper views, related to the topics. Newspapers site and many social networks, become a good source of data to analyse and explain complex phenomena. Understanding the entropy of a topic, could help all organizations that need to share information like government, institution, newspaper or company, to expect an higher activity over their channels, and in some cases predict what the receiver expect from the senders or what is wrong about the communication. For some organization such political party, leaders, company and many others, the reputation and the communication are (for most of them) the key part of a more and complex huge system. To reach our goal, we use gathering tools and information theory to detect and analyse trends topic on social networks, with the purpose of proved a method that helps organization, newspapers to predict how many articles or communication they will have to do on a topic, and how much flow of views they will have in a given period, starting with the entropy-article ratio. Our work address the issue to explore in which entropy-rate, and through which dynamics, a suitable information diffusion performance is expected on social network and then on newspaper. We have identified some cross-cutting dynamics that, associated with the contexts, might explain how people discuss about a topic, can move on to argue and informs on newspapers sites. ",
    "url": "https://arxiv.org/abs/2212.01361",
    "authors": [
      "Andrea Russo",
      "Antonio Picone",
      "Vincenzo Miracula",
      "Giovanni Giuffrida",
      "Francesco Mazzeo Rinaldi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:1912.12027",
    "title": "A General Framework for Saliency Detection Methods",
    "abstract": " Comments: Many grammatical and spelling errors are corrected. The technical content is not changed ",
    "url": "https://arxiv.org/abs/1912.12027",
    "authors": [
      "Fateme Mostafaie",
      "Zahra Nabizadeh",
      "Nader Karimi",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2007.06309",
    "title": "Part-aware Prototype Network for Few-shot Semantic Segmentation",
    "abstract": " Comments: ECCV-2020 ",
    "url": "https://arxiv.org/abs/2007.06309",
    "authors": [
      "Yongfei Liu",
      "Xiangyi Zhang",
      "Songyang Zhang",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2010.10421",
    "title": "Distributed ADMM with linear updates over directed networks",
    "abstract": " Title: Distributed ADMM with linear updates over directed networks ",
    "url": "https://arxiv.org/abs/2010.10421",
    "authors": [
      "Kiran Rokade",
      "Rachel Kalpana Kalaimani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2106.13274",
    "title": "Prediction of geophysical properties of rocks on rare well data and  attributes of seismic waves by machine learning methods on the example of the  Achimov formation",
    "abstract": " Comments: 15 pages, 10 figures, 1 table ",
    "url": "https://arxiv.org/abs/2106.13274",
    "authors": [
      "Dmitry Ivlev"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.10822",
    "title": "Lower Bounds for Maximally Recoverable Tensor Code and Higher Order MDS  Codes",
    "abstract": " Comments: 34 pages, in IEEE Transactions on Information Theory ",
    "url": "https://arxiv.org/abs/2107.10822",
    "authors": [
      "Joshua Brakensiek",
      "Sivakanth Gopi",
      "Visu Makam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2109.13098",
    "title": "One-Hot Graph Encoder Embedding",
    "abstract": " Comments: 7 pages main + 7 pages appendix ",
    "url": "https://arxiv.org/abs/2109.13098",
    "authors": [
      "Cencheng Shen",
      "Qizhe Wang",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.14726",
    "title": "Do Invariances in Deep Neural Networks Align with Human Perception?",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2111.14726",
    "authors": [
      "Vedant Nanda",
      "Ayan Majumdar",
      "Camila Kolling",
      "John P. Dickerson",
      "Krishna P. Gummadi",
      "Bradley C. Love",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05282",
    "title": "RamBoAttack: A Robust Query Efficient Deep Neural Network Decision  Exploit",
    "abstract": " Comments: Published in Network and Distributed System Security (NDSS) Symposium 2022 ",
    "url": "https://arxiv.org/abs/2112.05282",
    "authors": [
      "Viet Quoc Vo",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.05563",
    "title": "D*+: A Risk Aware Platform Agnostic Heterogeneous Path Planner",
    "abstract": " Comments: 35 pages, 24 figures, submitted to Expert System With Application ",
    "url": "https://arxiv.org/abs/2112.05563",
    "authors": [
      "Samuel Karlsson",
      "Anton Koval",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.10936",
    "title": "Watch Those Words: Video Falsification Detection Using Word-Conditioned  Facial Motion",
    "abstract": " Comments: Accepted in WACV 2023 ",
    "url": "https://arxiv.org/abs/2112.10936",
    "authors": [
      "Shruti Agarwal",
      "Liwen Hu",
      "Evonne Ng",
      "Trevor Darrell",
      "Hao Li",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2201.04626",
    "title": "Desynchronous Learning in a Physics-Driven Learning Network",
    "abstract": " Comments: 6 pages 4 figures ",
    "url": "https://arxiv.org/abs/2201.04626",
    "authors": [
      "Jacob F Wycoff",
      "Sam Dillavou",
      "Menachem Stern",
      "Andrea J Liu",
      "Douglas J Durian"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2201.12741",
    "title": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "abstract": " Comments: Published as a conference paper at LoG 2022 ",
    "url": "https://arxiv.org/abs/2201.12741",
    "authors": [
      "Chenhui Deng",
      "Xiuyu Li",
      "Zhuo Feng",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13094",
    "title": "Designing Universal Causal Deep Learning Models: The Geometric  (Hyper)Transformer",
    "abstract": " Comments: Main Body: 31 Pages, Proofs: 16 Pages, Figures: 13, Tables: 3 ",
    "url": "https://arxiv.org/abs/2201.13094",
    "authors": [
      "Beatrice Acciaio",
      "Anastasis Kratsios",
      "Gudmund Pammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2202.07679",
    "title": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks",
    "abstract": " Title: Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2202.07679",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.09167",
    "title": "Unsigned Distance Field as an Accurate 3D Scene Representation for  Neural Scene Completion",
    "abstract": " Comments: 8 pages, 7 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2203.09167",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.01560",
    "title": "SecureSense: Defending Adversarial Attack for Secure Device-Free Human  Activity Recognition",
    "abstract": " Comments: The paper is accepted by IEEE Transactions on Mobile Computing ",
    "url": "https://arxiv.org/abs/2204.01560",
    "authors": [
      "Jianfei Yang",
      "Han Zou",
      "Lihua Xie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2204.02654",
    "title": "Adversarial Analysis of the Differentially-Private Federated Learning in  Cyber-Physical Critical Infrastructures",
    "abstract": " Comments: 16 pages, 9 figures, 5 tables. This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2204.02654",
    "authors": [
      "Md Tamjid Hossain",
      "Shahriar Badsha",
      "Hung La",
      "Haoting Shen",
      "Shafkat Islam",
      "Ibrahim Khalil",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2204.05419",
    "title": "Can Self-Supervised Learning solve the problem of child speech  recognition?",
    "abstract": " Title: Can Self-Supervised Learning solve the problem of child speech  recognition? ",
    "url": "https://arxiv.org/abs/2204.05419",
    "authors": [
      "Rishabh Jain",
      "Mariam Yiwere",
      "Dan Bigioi",
      "Peter Corcoran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2205.09613",
    "title": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual  Object Detection",
    "abstract": " Comments: 6 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2205.09613",
    "authors": [
      "Feng Liu",
      "Xiaosong Zhang",
      "Zhiliang Peng",
      "Zonghao Guo",
      "Fang Wan",
      "Xiangyang Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.12358",
    "title": "A Benchmark and Asymmetrical-Similarity Learning for Practical Image  Copy Detection",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2205.12358",
    "authors": [
      "Wenhao Wang",
      "Yifan Sun",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09527",
    "title": "Simultaneous approximation of a smooth function and its derivatives by  deep neural networks with piecewise-polynomial activations",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2206.09527",
    "authors": [
      "Denis Belomestny",
      "Alexey Naumov",
      "Nikita Puchkin",
      "Sergey Samsonov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2206.15274",
    "title": "Augment like there's no tomorrow: Consistently performing neural  networks for medical imaging",
    "abstract": " Comments: Code for the paper is available from this https URL ",
    "url": "https://arxiv.org/abs/2206.15274",
    "authors": [
      "Joona Pohjonen",
      "Carolin St\u00fcrenberg",
      "Atte F\u00f6hr",
      "Reija Randen-Brady",
      "Lassi Luomala",
      "Jouni Lohi",
      "Esa Pitk\u00e4nen",
      "Antti Rannikko",
      "Tuomas Mirtti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.04125",
    "title": "Out of Distribution Detection via Neural Network Anchoring",
    "abstract": " Comments: ACML 2022 ",
    "url": "https://arxiv.org/abs/2207.04125",
    "authors": [
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.12062",
    "title": "Adaptive Asynchronous Control Using Meta-learned Neural Ordinary  Differential Equations",
    "abstract": " Comments: 13 double column pages, 10 figures, 4 algorithms, 3 tables ",
    "url": "https://arxiv.org/abs/2207.12062",
    "authors": [
      "Achkan Salehi",
      "Steffen R\u00fchl",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.02045",
    "title": "Common Pairs of Graphs",
    "abstract": " Comments: 50 pages ",
    "url": "https://arxiv.org/abs/2208.02045",
    "authors": [
      "Natalie Behague",
      "Natasha Morrison",
      "Jonathan A. Noel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2208.02656",
    "title": "Invariant Representations with Stochastically Quantized Neural Networks",
    "abstract": " Comments: To appear in AAAI23 ",
    "url": "https://arxiv.org/abs/2208.02656",
    "authors": [
      "Mattia Cerrato",
      "Marius K\u00f6ppel",
      "Roberto Esposito",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.05650",
    "title": "Diverse Generative Perturbations on Attention Space for Transferable  Adversarial Attacks",
    "abstract": " Comments: ICIP 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2208.05650",
    "authors": [
      "Woo Jae Kim",
      "Seunghoon Hong",
      "Sung-Eui Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03341",
    "title": "Large Scale Enrichment and Statistical Cyber Characterization of Network  Traffic (Enriquecimiento a gran escala y caracterizaci\u00f3n cibern\u00e9tica  estad\u00edstica del tr\u00e1fico de red)",
    "abstract": " Comments: 17 pages, 16 figures, HPEC, Spanish version ",
    "url": "https://arxiv.org/abs/2209.03341",
    "authors": [
      "Ivan Kawaminami",
      "Arminda Estrada",
      "Youssef Elsakkary",
      "Hayden Jananthan",
      "Ayd\u0131n Bulu\u00e7",
      "Tim Davis",
      "Daniel Grant",
      "Michael Jones",
      "Chad Meiners",
      "Andrew Morris",
      "Sandeep Pisharody",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.09147",
    "title": "PARTIME: Scalable and Parallel Processing Over Time with Deep Neural  Networks",
    "abstract": " Comments: 9 pages, accepted at International Conference on Machine Learning and Applications ",
    "url": "https://arxiv.org/abs/2210.09147",
    "authors": [
      "Enrico Meloni",
      "Lapo Faggi",
      "Simone Marullo",
      "Alessandro Betti",
      "Matteo Tiezzi",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09723",
    "title": "Textual Entailment Recognition with Semantic Features from Empirical  Text Representation",
    "abstract": " Comments: This paper has been accepted in SPELLL 2022, India. This is the primarily submitted version ",
    "url": "https://arxiv.org/abs/2210.09723",
    "authors": [
      "Md Shajalal",
      "Md Atabuzzaman",
      "Maksuda Bilkis Baby",
      "Md Rezaul Karim",
      "Alexander Boden"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09819",
    "title": "Eye-tracking based classification of Mandarin Chinese readers with and  without dyslexia using neural sequence models",
    "abstract": " Title: Eye-tracking based classification of Mandarin Chinese readers with and  without dyslexia using neural sequence models ",
    "url": "https://arxiv.org/abs/2210.09819",
    "authors": [
      "Patrick Haller",
      "Andreas S\u00e4uberli",
      "Sarah Elisabeth Kiener",
      "Jinger Pan",
      "Ming Yan",
      "Lena J\u00e4ger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10530",
    "title": "Adversarial De-confounding in Individualised Treatment Effects  Estimation",
    "abstract": " Comments: (under review) ",
    "url": "https://arxiv.org/abs/2210.10530",
    "authors": [
      "Vinod Kumar Chauhan",
      "Soheila Molaei",
      "Marzia Hoque Tania",
      "Anshul Thakur",
      "Tingting Zhu",
      "David Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.11068",
    "title": "Frequency of Interest-based Noise Attenuation Method to Improve Anomaly  Detection Performance",
    "abstract": " Comments: 5 pages, 4 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2210.11068",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Won Seok Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14830",
    "title": "Personalized Federated Learning via Heterogeneous Modular Networks",
    "abstract": " Title: Personalized Federated Learning via Heterogeneous Modular Networks ",
    "url": "https://arxiv.org/abs/2210.14830",
    "authors": [
      "Tianchun Wang",
      "Wei Cheng",
      "Dongsheng Luo",
      "Wenchao Yu",
      "Jingchao Ni",
      "Liang Tong",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.02883",
    "title": "Unified Multi-View Orthonormal Non-Negative Graph Based Clustering  Framework",
    "abstract": " Title: Unified Multi-View Orthonormal Non-Negative Graph Based Clustering  Framework ",
    "url": "https://arxiv.org/abs/2211.02883",
    "authors": [
      "Liangchen Liu",
      "Qiuhong Ke",
      "Chaojie Li",
      "Feiping Nie",
      "Yingying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08597",
    "title": "SketchySGD: Reliable Stochastic Optimization via Robust Curvature  Estimates",
    "abstract": " Comments: 25 pages, 8 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2211.08597",
    "authors": [
      "Zachary Frangella",
      "Pratik Rathore",
      "Shipu Zhao",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09945",
    "title": "SparseVLR: A Novel Framework for Verified Locally Robust Sparse Neural  Networks Search",
    "abstract": " Comments: 16 pages, 9 tables, 7 figures ",
    "url": "https://arxiv.org/abs/2211.09945",
    "authors": [
      "Sawinder Kaur",
      "Asif Salekin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10904",
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.10904",
    "authors": [
      "Yi Xu",
      "Junjie Ou",
      "Hui Xu",
      "Luoyi Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10973",
    "title": "FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News  Detection on Short Video Platforms",
    "abstract": " Comments: To appear in AAAI 2023 AISI track. This version contains appendix with additional details ",
    "url": "https://arxiv.org/abs/2211.10973",
    "authors": [
      "Peng Qi",
      "Yuyan Bu",
      "Juan Cao",
      "Wei Ji",
      "Ruihao Shui",
      "Junbin Xiao",
      "Danding Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2211.12046",
    "title": "DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": " Title: DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors ",
    "url": "https://arxiv.org/abs/2211.12046",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14523",
    "title": "VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily",
    "abstract": " Title: VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily ",
    "url": "https://arxiv.org/abs/2211.14523",
    "authors": [
      "Fengzhao Shi",
      "Ren Li",
      "Yanan Cao",
      "Yanmin Shang",
      "Lanxue Zhang",
      "Chuan Zhou",
      "Jia Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15159",
    "title": "Properties of SN P system and its Configuration Graph",
    "abstract": " Comments: Invited Talk: International Conference on Membrane Computing, September 14-18, 2020, TU Wien, Austria ",
    "url": "https://arxiv.org/abs/2211.15159",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.15255",
    "title": "GADMSL: Graph Anomaly Detection on Attributed Networks via Multi-scale  Substructure Learning",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2211.15255",
    "authors": [
      "Jingcan Duan",
      "Siwei Wang",
      "Xinwang Liu",
      "Haifang Zhou",
      "Jingtao Hu",
      "Hu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": " Comments: Accepted by the LoG conference 2022 as a spotlight ",
    "url": "https://arxiv.org/abs/2211.15335",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16192",
    "title": "Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape",
    "abstract": " Title: Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape ",
    "url": "https://arxiv.org/abs/2211.16192",
    "authors": [
      "Linkun Fan",
      "Fazhi He",
      "Qing Guo",
      "Wei Tang",
      "Xiaolin Hong",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.16211",
    "title": "ResNeRF: Geometry-Guided Residual Neural Radiance Field for Indoor Scene  Novel View Synthesis",
    "abstract": " Comments: 8+2 pages,5 figures ",
    "url": "https://arxiv.org/abs/2211.16211",
    "authors": [
      "Yuting Xiao",
      "Yiqun Zhao",
      "Yanyu Xu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17179",
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks",
    "abstract": " Comments: Submitted to Neurocomputing ",
    "url": "https://arxiv.org/abs/2211.17179",
    "authors": [
      "Jean Panaioti Jordanou",
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Eduardo Gildin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.00229",
    "title": "NIR-Prompt: A Multi-task Generalized Neural Information Retrieval  Training Framework",
    "abstract": " Comments: This article is the extension of arXiv:2204.02725 ",
    "url": "https://arxiv.org/abs/2212.00229",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.00352",
    "title": "A Dataset with Multibeam Forward-Looking Sonar for Underwater Object  Detection",
    "abstract": " Title: A Dataset with Multibeam Forward-Looking Sonar for Underwater Object  Detection ",
    "url": "https://arxiv.org/abs/2212.00352",
    "authors": [
      "Kaibing Xie",
      "Jian Yang",
      "Kang Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.00535",
    "title": "Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks  with Augmented View",
    "abstract": " Comments: 9 pages, 5 figures, 6 tables, accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.00535",
    "authors": [
      "Jingcan Duan",
      "Siwei Wang",
      "Pei Zhang",
      "En Zhu",
      "Jingtao Hu",
      "Hu Jin",
      "Yue Liu",
      "Zhibin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00576",
    "title": "Quantum Neural Networks for a Supply Chain Logistics Application",
    "abstract": " Comments: 14 pages, 11 figures. arXiv admin note: text overlap with arXiv:2211.17078 - updated citation [3] to reference arXiv:2211.17078 ",
    "url": "https://arxiv.org/abs/2212.00576",
    "authors": [
      "Randall Correll",
      "Sean J. Weinberg",
      "Fabio Sanches",
      "Takanori Ide",
      "Takafumi Suzuki"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  }
]