[
  {
    "id": "arXiv:2212.09802",
    "title": "Panoptic Lifting for 3D Scene Understanding with Neural Fields",
    "abstract": "We propose Panoptic Lifting, a novel approach for learning panoptic 3D volumetric representations from images of in-the-wild scenes. Once trained, our model can render color images together with 3D-consistent panoptic segmentation from novel viewpoints. Unlike existing approaches which use 3D input directly or indirectly, our method requires only machine-generated 2D panoptic segmentation masks inferred from a pre-trained network. Our core contribution is a panoptic lifting scheme based on a neural field representation that generates a unified and multi-view consistent, 3D panoptic representation of the scene. To account for inconsistencies of 2D instance identifiers across views, we solve a linear assignment with a cost based on the model's current predictions and the machine-generated segmentation masks, thus enabling us to lift 2D instances to 3D in a consistent way. We further propose and ablate contributions that make our method more robust to noisy, machine-generated labels, including test-time augmentations for confidence estimates, segment consistency loss, bounded segmentation fields, and gradient stopping. Experimental results validate our approach on the challenging Hypersim, Replica, and ScanNet datasets, improving by 8.4, 13.8, and 10.6% in scene-level PQ over state of the art. ",
    "url": "https://arxiv.org/abs/2212.09802",
    "authors": [
      "Yawar Siddiqui",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f3",
      "Norman M\u00fcller",
      "Matthias Nie\u00dfner",
      "Angela Dai",
      "Peter Kontschieder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09808",
    "title": "Receding Horizon Control on the Broadcast of Information in Stochastic  Networks",
    "abstract": "This paper focuses on the broadcast of information on robot networks with stochastic network interconnection topologies. Problematic communication networks are almost unavoidable in areas where we wish to deploy multi-robotic systems, usually due to a lack of environmental consistency, accessibility, and structure. We tackle this problem by modeling the broadcast of information in a multi-robot communication network as a stochastic process with random arrival times, which can be produced by irregular robot movements, wireless attenuation, and other environmental factors. Using this model, we provide and analyze a receding horizon control strategy to control the statistics of the information broadcast. The resulting strategy compels the robots to re-direct their communication resources to different neighbors according to the current propagation process to fulfill global broadcast requirements. Based on this method, we provide an approach to compute the expected time to broadcast the message to all nodes. Numerical examples are provided to illustrate the results. ",
    "url": "https://arxiv.org/abs/2212.09808",
    "authors": [
      "Thales C. Silva",
      "Li Shen",
      "Xi Yu",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.09832",
    "title": "Denoising instrumented mouthguard measurements of head impact kinematics  with a convolutional neural network",
    "abstract": "Wearable sensors for measuring head kinematics can be noisy due to imperfect interfaces with the body. Mouthguards are used to measure head kinematics during impacts in traumatic brain injury (TBI) studies, but deviations from reference kinematics can still occur due to potential looseness. In this study, deep learning is used to compensate for the imperfect interface and improve measurement accuracy. A set of one-dimensional convolutional neural network (1D-CNN) models was developed to denoise mouthguard kinematics measurements along three spatial axes of linear acceleration and angular velocity. The denoised kinematics had significantly reduced errors compared to reference kinematics, and reduced errors in brain injury criteria and tissue strain and strain rate calculated via finite element modeling. The 1D-CNN models were also tested on an on-field dataset of college football impacts and a post-mortem human subject dataset, with similar denoising effects observed. The models can be used to improve detection of head impacts and TBI risk evaluation, and potentially extended to other sensors measuring kinematics. ",
    "url": "https://arxiv.org/abs/2212.09832",
    "authors": [
      "Xianghao Zhan",
      "Yuzhe Liu",
      "Nicholas J. Cecchi",
      "Ashlyn A. Callan",
      "Enora Le Flao",
      "Olivier Gevaert",
      "Michael M. Zeineh",
      "Gerald A. Grant",
      "David B. Camarillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2212.09839",
    "title": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental  Health Status on Social Media",
    "abstract": "In recent years, there has been a surge of interest in research on automatic mental health detection (MHD) from social media data leveraging advances in natural language processing and machine learning techniques. While significant progress has been achieved in this interdisciplinary research area, the vast majority of work has treated MHD as a binary classification task. The multiclass classification setup is, however, essential if we are to uncover the subtle differences among the statistical patterns of language use associated with particular mental health conditions. Here, we report on experiments aimed at predicting six conditions (anxiety, attention deficit hyperactivity disorder, bipolar disorder, post-traumatic stress disorder, depression, and psychological stress) from Reddit social media posts. We explore and compare the performance of hybrid and ensemble models leveraging transformer-based architectures (BERT and RoBERTa) and BiLSTM neural networks trained on within-text distributions of a diverse set of linguistic features. This set encompasses measures of syntactic complexity, lexical sophistication and diversity, readability, and register-specific ngram frequencies, as well as sentiment and emotion lexicons. In addition, we conduct feature ablation experiments to investigate which types of features are most indicative of particular mental health conditions. ",
    "url": "https://arxiv.org/abs/2212.09839",
    "authors": [
      "Sourabh Zanwar",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.09840",
    "title": "Dynamic Sparse Network for Time Series Classification: Learning What to  \"see''",
    "abstract": "The receptive field (RF), which determines the region of time series to be ``seen'' and used, is critical to improve the performance for time series classification (TSC). However, the variation of signal scales across and within time series data, makes it challenging to decide on proper RF sizes for TSC. In this paper, we propose a dynamic sparse network (DSN) with sparse connections for TSC, which can learn to cover various RF without cumbersome hyper-parameters tuning. The kernels in each sparse layer are sparse and can be explored under the constraint regions by dynamic sparse training, which makes it possible to reduce the resource cost. The experimental results show that the proposed DSN model can achieve state-of-art performance on both univariate and multivariate TSC datasets with less than 50\\% computational cost compared with recent baseline methods, opening the path towards more accurate resource-aware methods for time series analyses. Our code is publicly available at: https://github.com/QiaoXiao7282/DSN. ",
    "url": "https://arxiv.org/abs/2212.09840",
    "authors": [
      "Qiao Xiao",
      "Boqian Wu",
      "Yu Zhang",
      "Shiwei Liu",
      "Mykola Pechenizkiy",
      "Elena Mocanu",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09864",
    "title": "Synthetic Pre-Training Tasks for Neural Machine Translation",
    "abstract": "Pre-training is an effective technique for ensuring robust performance on a variety of machine learning tasks. It typically depends on large-scale crawled corpora that can result in toxic or biased models. Such data can also be problematic with respect to copyright, attribution, and privacy. Pre-training with synthetic tasks and data is a promising way of alleviating such concerns since no real-world information is ingested by the model. Our goal in this paper is to understand what makes for a good pre-trained model when using synthetic resources. We answer this question in the context of neural machine translation by considering two novel approaches to translation model pre-training. Our first approach studies the effect of pre-training on obfuscated data derived from a parallel corpus by mapping words to a vocabulary of 'nonsense' tokens. Our second approach explores the effect of pre-training on procedurally generated synthetic parallel data that does not depend on any real human language corpus. Our empirical evaluation on multiple language pairs shows that, to a surprising degree, the benefits of pre-training can be realized even with obfuscated or purely synthetic parallel data. In our analysis, we consider the extent to which obfuscated and synthetic pre-training techniques can be used to mitigate the issue of hallucinated model toxicity. ",
    "url": "https://arxiv.org/abs/2212.09864",
    "authors": [
      "Zexue He",
      "Graeme Blackwood",
      "Rameswar Panda",
      "Julian McAuley",
      "Rogerio Feris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09877",
    "title": "LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer",
    "abstract": "Graphic layout designs play an essential role in visual communication. Yet handcrafting layout designs are skill-demanding, time-consuming, and non-scalable to batch production. Although generative models emerge to make design automation no longer utopian, it remains non-trivial to customize designs that comply with designers' multimodal desires, i.e., constrained by background images and driven by foreground contents. In this study, we propose \\textit{LayoutDETR} that inherits the high quality and realism from generative modeling, in the meanwhile reformulating content-aware requirements as a detection problem: we learn to detect in a background image the reasonable locations, scales, and spatial relations for multimodal elements in a layout. Experiments validate that our solution yields new state-of-the-art performance for layout generation on public benchmarks and on our newly-curated ads banner dataset. For practical usage, we build our solution into a graphical system that facilitates user studies. We demonstrate that our designs attract more subjective preference than baselines by significant margins. Our code, models, dataset, graphical system, and demos are available at https://github.com/salesforce/LayoutDETR. ",
    "url": "https://arxiv.org/abs/2212.09877",
    "authors": [
      "Ning Yu",
      "Chia-Chih Chen",
      "Zeyuan Chen",
      "Rui Meng",
      "Gang Wu",
      "Paul Josel",
      "Juan Carlos Niebles",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.09884",
    "title": "Multi-Analyst Differential Privacy for Online Query Answering",
    "abstract": "Most differentially private mechanisms are designed for the use of a single analyst. In reality, however, there are often multiple stakeholders with different and possibly conflicting priorities that must share the same privacy loss budget. This motivates the problem of equitable budget-sharing for multi-analyst differential privacy. Our previous work defined desiderata that any mechanism in this space should satisfy and introduced methods for budget-sharing in the offline case where queries are known in advance. We extend our previous work on multi-analyst differentially private query answering to the case of online query answering, where queries come in one at a time and must be answered without knowledge of the following queries. We demonstrate that the unknown ordering of queries in the online case results in a fundamental limit in the number of queries that can be answered while satisfying the desiderata. In response, we develop two mechanisms, one which satisfies the desiderata in all cases but is subject to the fundamental limitations, and another that randomizes the input order ensuring that existing online query answering mechanisms can satisfy the desiderata. ",
    "url": "https://arxiv.org/abs/2212.09884",
    "authors": [
      "David Pujol",
      "Albert Sun",
      "Brandon Fain",
      "Ashwin Machanavajjhala"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.09885",
    "title": "Asking Clarification Questions for Code Generation in General-Purpose  Programming Language",
    "abstract": "Code generation from text requires understanding the user's intent from a natural language description (NLD) and generating an executable program code snippet that satisfies this intent. While recent pretrained language models (PLMs) demonstrate remarkable performance for this task, these models fail when the given NLD is ambiguous due to the lack of enough specifications for generating a high-quality code snippet. In this work, we introduce a novel and more realistic setup for this task. We hypothesize that ambiguities in the specifications of an NLD are resolved by asking clarification questions (CQs). Therefore, we collect and introduce a new dataset named CodeClarQA containing NLD-Code pairs with created CQAs. We evaluate the performance of PLMs for code generation on our dataset. The empirical results support our hypothesis that clarifications result in more precise generated code, as shown by an improvement of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7\\% in the exact match. Alongside this, our task and dataset introduce new challenges to the community, including when and what CQs should be asked. ",
    "url": "https://arxiv.org/abs/2212.09885",
    "authors": [
      "Haau-Sing Li",
      "Mohsen Mesgar",
      "Andr\u00e9 F. T. Martins",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.09910",
    "title": "An experience in automatically extracting CAPAs from code repositories",
    "abstract": "TOM (stands for Theoretically Objective Measurements of Software Development Projects) is a set of services that are in charge of helping developers or teams in the process of identifying anomilies within their software development process, and providing a list of preventive or corrective actions (aka CAPAS) that positively impact the process. and in this way to improve the quality of the final product and its development process. In order to get help from TOM, it is as simple as adding our bot (@0capa) to the list of collaborators in your repository, and with this our bot will automatically take care of obtaining different metrics from your repository, in order to suggest actions to take into account to that in your future updates the identified anomalies are not repeated. This paper presents the underlying research on this idea. ",
    "url": "https://arxiv.org/abs/2212.09910",
    "authors": [
      "Yegor Bugayenko",
      "Imre Delgado",
      "Firas Jolha",
      "Zamira Kholmatova",
      "Artem Kruglov",
      "Witold Pedrycz",
      "Giancarlo Succi",
      "Xavier Vasquez"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.09921",
    "title": "Normalized Stochastic Gradient Descent Training of Deep Neural Networks",
    "abstract": "In this paper, we introduce a novel optimization algorithm for machine learning model training called Normalized Stochastic Gradient Descent (NSGD) inspired by Normalized Least Mean Squares (NLMS) from adaptive filtering. When we train a high-complexity model on a large dataset, the learning rate is significantly important as a poor choice of optimizer parameters can lead to divergence. The algorithm updates the new set of network weights using the stochastic gradient but with $\\ell_1$ and $\\ell_2$-based normalizations on the learning rate parameter similar to the NLMS algorithm. Our main difference from the existing normalization methods is that we do not include the error term in the normalization process. We normalize the update term using the input vector to the neuron. Our experiments present that the model can be trained to a better accuracy level on different initial settings using our optimization algorithm. In this paper, we demonstrate the efficiency of our training algorithm using ResNet-20 and a toy neural network on different benchmark datasets with different initializations. The NSGD improves the accuracy of the ResNet-20 from 91.96\\% to 92.20\\% on the CIFAR-10 dataset. ",
    "url": "https://arxiv.org/abs/2212.09921",
    "authors": [
      "Salih Atici",
      "Hongyi Pan",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.09928",
    "title": "Improving the Robustness of Summarization Models by Detecting and  Removing Input Noise",
    "abstract": "The evaluation of abstractive summarization models typically uses test data that is identically distributed as training data. In real-world practice, documents to be summarized may contain input noise caused by text extraction artifacts or data pipeline bugs. The robustness of model performance under distribution shift caused by such noise is relatively under-studied. We present a large empirical study quantifying the sometimes severe loss in performance (up to 12 ROUGE-1 points) from different types of input noise for a range of datasets and model sizes. We then propose a light-weight method for detecting and removing such noise in the input during model inference without requiring any extra training, auxiliary models, or even prior knowledge of the type of noise. Our proposed approach effectively mitigates the loss in performance, recovering a large fraction of the performance drop, sometimes as large as 11 ROUGE-1 points. ",
    "url": "https://arxiv.org/abs/2212.09928",
    "authors": [
      "Kundan Krishna",
      "Yao Zhao",
      "Jie Ren",
      "Balaji Lakshminarayanan",
      "Jiaming Luo",
      "Mohammad Saleh",
      "Peter J. Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09944",
    "title": "Full-Life Cycle Intent-Driven Network Verification: Challenges and  Approaches",
    "abstract": "With the human friendly declarative intent policy expression, intent-driven network can make network management and configuration autonomous without human intervention. However, the availability and dependability of these refined policies from the expressed intents should be well ensured by full-life cycle verification. Moreover, intent-driven network verification is still in its initial stage, and there is a lack of full-life cycle end-to-end verification framework. As a result, in this article, we present and review existing verification techniques, and classify them according to objective, purpose, and feedback. Furthermore, we describe intent verification as a technology that provides assurance during the intent form conversion process and propose a novel full-life cycle verification framework that expands on the concept of traditional network verification. Finally, we verify the feasibility and validity of the presented verification framework in the case of an access control policy for different network functions with multi conflict intents. ",
    "url": "https://arxiv.org/abs/2212.09944",
    "authors": [
      "Yanbo Song",
      "Chungang Yang",
      "Jiaming Zhang",
      "Xinru Mi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2212.09945",
    "title": "Robust and Resource-efficient Machine Learning Aided Viewport Prediction  in Virtual Reality",
    "abstract": "360-degree panoramic videos have gained considerable attention in recent years due to the rapid development of head-mounted displays (HMDs) and panoramic cameras. One major problem in streaming panoramic videos is that panoramic videos are much larger in size compared to traditional ones. Moreover, the user devices are often in a wireless environment, with limited battery, computation power, and bandwidth. To reduce resource consumption, researchers have proposed ways to predict the users' viewports so that only part of the entire video needs to be transmitted from the server. However, the robustness of such prediction approaches has been overlooked in the literature: it is usually assumed that only a few models, pre-trained on past users' experiences, are applied for prediction to all users. We observe that those pre-trained models can perform poorly for some users because they might have drastically different behaviors from the majority, and the pre-trained models cannot capture the features in unseen videos. In this work, we propose a novel meta learning based viewport prediction paradigm to alleviate the worst prediction performance and ensure the robustness of viewport prediction. This paradigm uses two machine learning models, where the first model predicts the viewing direction, and the second model predicts the minimum video prefetch size that can include the actual viewport. We first train two meta models so that they are sensitive to new training data, and then quickly adapt them to users while they are watching the videos. Evaluation results reveal that the meta models can adapt quickly to each user, and can significantly increase the prediction accuracy, especially for the worst-performing predictions. ",
    "url": "https://arxiv.org/abs/2212.09945",
    "authors": [
      "Yuang Jiang",
      "Konstantinos Poularakis",
      "Diego Kiedanski",
      "Sastry Kompella",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09962",
    "title": "Distributional Robustness Bounds Generalization Errors",
    "abstract": "Bayesian methods, distributionally robust optimization methods, and regularization methods are three pillars of trustworthy machine learning hedging against distributional uncertainty, e.g., the uncertainty of an empirical distribution compared to the true underlying distribution. This paper investigates the connections among the three frameworks and, in particular, explores why these frameworks tend to have smaller generalization errors. Specifically, first, we suggest a quantitative definition for \"distributional robustness\", propose the concept of \"robustness measure\", and formalize several philosophical concepts in distributionally robust optimization. Second, we show that Bayesian methods are distributionally robust in the probably approximately correct (PAC) sense; In addition, by constructing a Dirichlet-process-like prior in Bayesian nonparametrics, it can be proven that any regularized empirical risk minimization method is equivalent to a Bayesian method. Third, we show that generalization errors of machine learning models can be characterized using the distributional uncertainty of the nominal distribution and the robustness measures of these machine learning models, which is a new perspective to bound generalization errors, and therefore, explain the reason why distributionally robust machine learning models, Bayesian models, and regularization models tend to have smaller generalization errors. ",
    "url": "https://arxiv.org/abs/2212.09962",
    "authors": [
      "Shixiong Wang",
      "Haowei Wang",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.09967",
    "title": "Learning Subgrid-scale Models with Neural Ordinary Differential  Equations",
    "abstract": "We propose a new approach to learning the subgrid-scale model effects when simulating partial differential equations (PDEs) solved by the method of lines and their representation in chaotic ordinary differential equations, based on neural ordinary differential equations (NODEs). Solving systems with fine temporal and spatial grid scales is an ongoing computational challenge, and closure models are generally difficult to tune. Machine learning approaches have increased the accuracy and efficiency of computational fluid dynamics solvers. In this approach neural networks are used to learn the coarse- to fine-grid map, which can be viewed as subgrid scale parameterization. We propose a strategy that uses the NODE and partial knowledge to learn the source dynamics at a continuous level. Our method inherits the advantages of NODEs and can be used to parameterize subgrid scales, approximate coupling operators, and improve the efficiency of low-order solvers. Numerical results using the two-scale Lorenz 96 ODE and the convection-diffusion PDE are used to illustrate this approach. ",
    "url": "https://arxiv.org/abs/2212.09967",
    "authors": [
      "Shinhoo Kang",
      "Emil M. Constantinescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09970",
    "title": "Data Augmentation on Graphs: A Survey",
    "abstract": "In recent years, graph representation learning has achieved remarkable success while suffering from low-quality data problems. As a mature technology to improve data quality in computer vision, data augmentation has also attracted increasing attention in graph domain. For promoting the development of this emerging research direction, in this survey, we comprehensively review and summarize the existing graph data augmentation (GDAug) techniques. Specifically, we first summarize a variety of feasible taxonomies, and then classify existing GDAug studies based on fine-grained graph elements. Furthermore, for each type of GDAug technique, we formalize the general definition, discuss the technical details, and give schematic illustration. In addition, we also summarize common performance metrics and specific design metrics for constructing a GDAug evaluation system. Finally, we summarize the applications of GDAug from both data and model levels, as well as future directions. ",
    "url": "https://arxiv.org/abs/2212.09970",
    "authors": [
      "Jiajun Zhou",
      "Chenxuan Xie",
      "Zhenyu Wen",
      "Xiangyu Zhao",
      "Qi Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09976",
    "title": "Towards Understanding the Impacts of Textual Dissimilarity on Duplicate  Bug Report Detection",
    "abstract": "About 40% of software bug reports are duplicates of one another, which pose a major overhead during software maintenance. Traditional techniques often focus on detecting duplicate bug reports that are textually similar. However, in bug tracking systems, many duplicate bug reports might not be textually similar, for which the traditional techniques might fall short. In this paper, we conduct a large-scale empirical study to better understand the impacts of textual dissimilarity on the detection of duplicate bug reports. First, we collect a total of 92,854 bug reports from three open-source systems and construct two datasets containing textually similar and textually dissimilar duplicate bug reports. Then we determine the performance of three existing techniques in detecting duplicate bug reports and show that their performance is significantly poor for textually dissimilar duplicate reports. Second, we analyze the two groups of bug reports using a combination of descriptive analysis, word embedding visualization, and manual analysis. We found that textually dissimilar duplicate bug reports often miss important components (e.g., expected behaviors and steps to reproduce), which could lead to their textual differences and poor performance by the existing techniques. Finally, we apply domain-specific embedding to duplicate bug report detection problems, which shows mixed results. All these findings above warrant further investigation and more effective solutions for detecting textually dissimilar duplicate bug reports. ",
    "url": "https://arxiv.org/abs/2212.09976",
    "authors": [
      "Sigma Jahan",
      "Mohammad Masudur Rahman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.09979",
    "title": "Flareon: Stealthy any2any Backdoor Injection via Poisoned Augmentation",
    "abstract": "Open software supply chain attacks, once successful, can exact heavy costs in mission-critical applications. As open-source ecosystems for deep learning flourish and become increasingly universal, they present attackers previously unexplored avenues to code-inject malicious backdoors in deep neural network models. This paper proposes Flareon, a small, stealthy, seemingly harmless code modification that specifically targets the data augmentation pipeline with motion-based triggers. Flareon neither alters ground-truth labels, nor modifies the training loss objective, nor does it assume prior knowledge of the victim model architecture, training data, and training hyperparameters. Yet, it has a surprisingly large ramification on training -- models trained under Flareon learn powerful target-conditional (or \"any2any\") backdoors. The resulting models can exhibit high attack success rates for any target choices and better clean accuracies than backdoor attacks that not only seize greater control, but also assume more restrictive attack capabilities. We also demonstrate the effectiveness of Flareon against recent defenses. Flareon is fully open-source and available online to the deep learning community: https://github.com/lafeat/flareon. ",
    "url": "https://arxiv.org/abs/2212.09979",
    "authors": [
      "Tianrui Qin",
      "Xianghuan He",
      "Xitong Gao",
      "Yiren Zhao",
      "Kejiang Ye",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.09980",
    "title": "Continual Mean Estimation Under User-Level Privacy",
    "abstract": "We consider the problem of continually releasing an estimate of the population mean of a stream of samples that is user-level differentially private (DP). At each time instant, a user contributes a sample, and the users can arrive in arbitrary order. Until now these requirements of continual release and user-level privacy were considered in isolation. But, in practice, both these requirements come together as the users often contribute data repeatedly and multiple queries are made. We provide an algorithm that outputs a mean estimate at every time instant $t$ such that the overall release is user-level $\\varepsilon$-DP and has the following error guarantee: Denoting by $M_t$ the maximum number of samples contributed by a user, as long as $\\tilde{\\Omega}(1/\\varepsilon)$ users have $M_t/2$ samples each, the error at time $t$ is $\\tilde{O}(1/\\sqrt{t}+\\sqrt{M}_t/t\\varepsilon)$. This is a universal error guarantee which is valid for all arrival patterns of the users. Furthermore, it (almost) matches the existing lower bounds for the single-release setting at all time instants when users have contributed equal number of samples. ",
    "url": "https://arxiv.org/abs/2212.09980",
    "authors": [
      "Anand Jerry George",
      "Lekshmi Ramesh",
      "Aditya Vikram Singh",
      "Himanshu Tyagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.09983",
    "title": "Texture Representation via Analysis and Synthesis with Generative  Adversarial Networks",
    "abstract": "We investigate data-driven texture modeling via analysis and synthesis with generative adversarial networks. For network training and testing, we have compiled a diverse set of spatially homogeneous textures, ranging from stochastic to regular. We adopt StyleGAN3 for synthesis and demonstrate that it produces diverse textures beyond those represented in the training data. For texture analysis, we propose GAN inversion using a novel latent domain reconstruction consistency criterion for synthesized textures, and iterative refinement with Gramian loss for real textures. We propose perceptual procedures for evaluating network capabilities, exploring the global and local behavior of latent space trajectories, and comparing with existing texture analysis-synthesis techniques. ",
    "url": "https://arxiv.org/abs/2212.09983",
    "authors": [
      "Jue Lin",
      "Gaurav Sharma",
      "Thrasyvoulos N. Pappas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.09989",
    "title": "High Impedance Fault Detection Through Quasi-Static State Estimation: A  Parameter Error Modeling Approach",
    "abstract": "This paper presents a model for detecting high-impedance faults (HIFs) using parameter error modeling and a two-step per-phase weighted least squares state estimation (SE) process. The proposed scheme leverages the use of phasor measurement units and synthetic measurements to identify per-phase power flow and injection measurements which indicate a parameter error through $\\chi^2$ Hypothesis Testing applied to the composed measurement error (CME). Although current and voltage waveforms are commonly analyzed for high-impedance fault detection, wide-area power flow and injection measurements, which are already inherent to the SE process, also show promise for real-world high-impedance fault detection applications. The error distributions after detection share the measurement function error spread observed in proven parameter error diagnostics and can be applied to HIF identification. Further, this error spread related to the HIF will be clearly discerned from measurement error. Case studies are performed on the 33-Bus Distribution System in Simulink. ",
    "url": "https://arxiv.org/abs/2212.09989",
    "authors": [
      "Austin Cooper",
      "Arturo Bretas",
      "Sean Meyn",
      "Newton G. Bretas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.09990",
    "title": "Distributed Software-Defined Network Architecture for Smart Grid  Resilience to Denial-of-Service Attacks",
    "abstract": "An important challenge for smart grid security is designing a secure and robust smart grid communications architecture to protect against cyber-threats, such as Denial-of-Service (DoS) attacks, that can adversely impact the operation of the power grid. Researchers have proposed using Software Defined Network frameworks to enhance cybersecurity of the smart grid, but there is a lack of benchmarking and comparative analyses among the many techniques. In this work, a distributed three-controller software-defined networking (D3-SDN) architecture, benchmarking and comparative analysis with other techniques is presented. The selected distributed flat SDN architecture divides the network horizontally into multiple areas or clusters, where each cluster is handled by a single Open Network Operating System (ONOS) controller. A case study using the IEEE 118-bus system is provided to compare the performance of the presented ONOS-managed D3-SDN, against the POX controller. In addition, the proposed architecture outperforms a single SDN controller framework by a tenfold increase in throughput; a reduction in latency of $>20\\%$; and an increase in throughput of approximately $11\\%$ during the DoS attack scenarios. ",
    "url": "https://arxiv.org/abs/2212.09990",
    "authors": [
      "Dennis Agnew",
      "Sharon Boamah",
      "Reynold Mathieu",
      "Austin Cooper",
      "Janise McNair",
      "Arturo Bretas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.09991",
    "title": "Dynamic Molecular Graph-based Implementation for Biophysical Properties  Prediction",
    "abstract": "Neural Networks (GNNs) have revolutionized the molecular discovery to understand patterns and identify unknown features that can aid in predicting biophysical properties and protein-ligand interactions. However, current models typically rely on 2-dimensional molecular representations as input, and while utilization of 2\\3- dimensional structural data has gained deserved traction in recent years as many of these models are still limited to static graph representations. We propose a novel approach based on the transformer model utilizing GNNs for characterizing dynamic features of protein-ligand interactions. Our message passing transformer pre-trains on a set of molecular dynamic data based off of physics-based simulations to learn coordinate construction and make binding probability and affinity predictions as a downstream task. Through extensive testing we compare our results with the existing models, our MDA-PLI model was able to outperform the molecular interaction prediction models with an RMSE of 1.2958. The geometric encodings enabled by our transformer architecture and the addition of time series data add a new dimensionality to this form of research. ",
    "url": "https://arxiv.org/abs/2212.09991",
    "authors": [
      "Carter Knutson",
      "Gihan Panapitiya",
      "Rohith Varikoti",
      "Neeraj Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2212.09993",
    "title": "Are Deep Neural Networks SMARTer than Second Graders?",
    "abstract": "Recent times have witnessed an increasing number of applications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (such as ChatGPT), etc. Such a dramatic progress raises the question: how generalizable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset, for evaluating the abstraction, deduction, and generalization abilities of neural networks in solving visuo-linguistic puzzles designed specifically for children in the 6-8 age group. Our dataset consists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spatial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically generate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision and language meta-learning model using varied state-of-the-art backbone neural networks. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization. We also evaluate the recent ChatGPT large language model on a subset of our dataset and find that while ChatGPT produces convincing reasoning abilities, the answers are often incorrect. ",
    "url": "https://arxiv.org/abs/2212.09993",
    "authors": [
      "Anoop Cherian",
      "Kuan-Chuan Peng",
      "Suhas Lohit",
      "Kevin Smith",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09994",
    "title": "Towards Robustness of Text-to-SQL Models Against Natural and Realistic  Adversarial Table Perturbation",
    "abstract": "The robustness of Text-to-SQL parsers against adversarial perturbations plays a crucial role in delivering highly reliable applications. Previous studies along this line primarily focused on perturbations in the natural language question side, neglecting the variability of tables. Motivated by this, we propose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to measure the robustness of Text-to-SQL models. Following this proposition, we curate ADVETA, the first robustness evaluation benchmark featuring natural and realistic ATPs. All tested state-of-the-art models experience dramatic performance drops on ADVETA, revealing models' vulnerability in real-world practices. To defend against ATP, we build a systematic adversarial training example generation framework tailored for better contextualization of tabular data. Experiments show that our approach not only brings the best robustness improvement against table-side perturbations but also substantially empowers models against NL-side perturbations. We release our benchmark and code at: https://github.com/microsoft/ContextualSP. ",
    "url": "https://arxiv.org/abs/2212.09994",
    "authors": [
      "Xinyu Pi",
      "Bing Wang",
      "Yan Gao",
      "Jiaqi Guo",
      "Zhoujun Li",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10002",
    "title": "Defending Against Poisoning Attacks in Open-Domain Question Answering",
    "abstract": "Recent work in open-domain question answering (ODQA) has shown that adversarial poisoning of the input contexts can cause large drops in accuracy for production systems. However, little to no work has proposed methods to defend against these attacks. To do so, we introduce a new method that uses query augmentation to search for a diverse set of retrieved passages that could answer the original question. We integrate these new passages into the model through the design of a novel confidence method, comparing the predicted answer to its appearance in the retrieved contexts (what we call Confidence from Answer Redundancy, e.g. CAR). Together these methods allow for a simple but effective way to defend against poisoning attacks and provide gains of 5-20% exact match across varying levels of data poisoning. ",
    "url": "https://arxiv.org/abs/2212.10002",
    "authors": [
      "Orion Weller",
      "Aleem Khan",
      "Nathaniel Weir",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.10005",
    "title": "Calibrating Deep Neural Networks using Explicit Regularisation and  Dynamic Data Pruning",
    "abstract": "Deep neural networks (DNN) are prone to miscalibrated predictions, often exhibiting a mismatch between the predicted output and the associated confidence scores. Contemporary model calibration techniques mitigate the problem of overconfident predictions by pushing down the confidence of the winning class while increasing the confidence of the remaining classes across all test samples. However, from a deployment perspective, an ideal model is desired to (i) generate well-calibrated predictions for high-confidence samples with predicted probability say >0.95, and (ii) generate a higher proportion of legitimate high-confidence samples. To this end, we propose a novel regularization technique that can be used with classification losses, leading to state-of-the-art calibrated predictions at test time; From a deployment standpoint in safety-critical applications, only high-confidence samples from a well-calibrated model are of interest, as the remaining samples have to undergo manual inspection. Predictive confidence reduction of these potentially ``high-confidence samples'' is a downside of existing calibration approaches. We mitigate this by proposing a dynamic train-time data pruning strategy that prunes low-confidence samples every few epochs, providing an increase in \"confident yet calibrated samples\". We demonstrate state-of-the-art calibration performance across image classification benchmarks, reducing training time without much compromise in accuracy. We provide insights into why our dynamic pruning strategy that prunes low-confidence training samples leads to an increase in high-confidence samples at test time. ",
    "url": "https://arxiv.org/abs/2212.10005",
    "authors": [
      "Ramya Hebbalaguppe",
      "Rishabh Patra",
      "Tirtharaj Dash",
      "Gautam Shroff",
      "Lovekesh Vig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10006",
    "title": "Multi-head Uncertainty Inference for Adversarial Attack Detection",
    "abstract": "Deep neural networks (DNNs) are sensitive and susceptible to tiny perturbation by adversarial attacks which causes erroneous predictions. Various methods, including adversarial defense and uncertainty inference (UI), have been developed in recent years to overcome the adversarial attacks. In this paper, we propose a multi-head uncertainty inference (MH-UI) framework for detecting adversarial attack examples. We adopt a multi-head architecture with multiple prediction heads (i.e., classifiers) to obtain predictions from different depths in the DNNs and introduce shallow information for the UI. Using independent heads at different depths, the normalized predictions are assumed to follow the same Dirichlet distribution, and we estimate distribution parameter of it by moment matching. Cognitive uncertainty brought by the adversarial attacks will be reflected and amplified on the distribution. Experimental results show that the proposed MH-UI framework can outperform all the referred UI methods in the adversarial attack detection task with different settings. ",
    "url": "https://arxiv.org/abs/2212.10006",
    "authors": [
      "Yuqi Yang",
      "Songyun Yang",
      "Jiyang Xie. Zhongwei Si",
      "Kai Guo",
      "Ke Zhang",
      "Kongming Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.10007",
    "title": "CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file  Context",
    "abstract": "While pre-trained language models (LM) for code have achieved great success in code completion, they generate code conditioned only on the contents within the file, i.e., in-file context, but ignore the rich semantics in other files within the same project, i.e., cross-file context, a critical source of information that is especially useful in modern modular software development. Such overlooking constrains code language models' capacity in code completion, leading to unexpected behaviors such as generating hallucinated class member functions or function calls with unexpected arguments. In this work, we develop a cross-file context finder tool, CCFINDER, that effectively locates and retrieves the most relevant cross-file context. We propose CoCoMIC, a framework that incorporates cross-file context to learn the in-file and cross-file context jointly on top of pretrained code LMs. CoCoMIC successfully improves the existing code LM with a 19.30% relative increase in exact match and a 15.41% relative increase in identifier matching for code completion when the cross-file context is provided. ",
    "url": "https://arxiv.org/abs/2212.10007",
    "authors": [
      "Yangruibo Ding",
      "Zijian Wang",
      "Wasi Uddin Ahmad",
      "Murali Krishna Ramanathan",
      "Ramesh Nallapati",
      "Parminder Bhatia",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.10011",
    "title": "PLUE: Language Understanding Evaluation Benchmark for Privacy Policies  in English",
    "abstract": "Privacy policies provide individuals with information about their rights and how their personal information is handled. Natural language understanding (NLU) technologies can support individuals and practitioners to understand better privacy practices described in lengthy and complex documents. However, existing efforts that use NLU technologies are limited by processing the language in a way exclusive to a single task focusing on certain privacy practices. To this end, we introduce the Privacy Policy Language Understanding Evaluation (PLUE) benchmark, a multi-task benchmark for evaluating the privacy policy language understanding across various tasks. We also collect a large corpus of privacy policies to enable privacy policy domain-specific language model pre-training. We demonstrate that domain-specific pre-training offers performance improvements across all tasks. We release the benchmark to encourage future research in this domain. ",
    "url": "https://arxiv.org/abs/2212.10011",
    "authors": [
      "Jianfeng Chi",
      "Wasi Uddin Ahmad",
      "Yuan Tian",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10017",
    "title": "Is Self-Attention Powerful to Learn Code Syntax and Semantics?",
    "abstract": "Pre-trained language models for programming languages have shown a powerful ability on processing many Software Engineering (SE) tasks, e.g., program synthesis, code completion, and code search. However, it remains to be seen what is behind their success. Recent studies have examined how pre-trained models can effectively learn syntax information based on Abstract Syntax Trees. In this paper, we figure out what role the self-attention mechanism plays in understanding code syntax and semantics based on AST and static analysis. We focus on a well-known representative code model, CodeBERT, and study how it can learn code syntax and semantics by the self-attention mechanism and Masked Language Modelling (MLM) at the token level. We propose a group of probing tasks to analyze CodeBERT. Based on AST and static analysis, we establish the relationships among the code tokens. First, Our results show that CodeBERT can acquire syntax and semantics knowledge through self-attention and MLM. Second, we demonstrate that the self-attention mechanism pays more attention to dependence-relationship tokens than to other tokens. Different attention heads play different roles in learning code semantics; we show that some of them are weak at encoding code semantics. Different layers have different competencies to represent different code properties. Deep CodeBERT layers can encode the semantic information that requires some complex inference in the code context. More importantly, we show that our analysis is helpful and leverage our conclusions to improve CodeBERT. We show an alternative approach for pre-training models, which makes fully use of the current pre-training strategy, i.e, MLM, to learn code syntax and semantics, instead of combining features from different code data formats, e.g., data-flow, running-time states, and program outputs. ",
    "url": "https://arxiv.org/abs/2212.10017",
    "authors": [
      "Wei Ma",
      "Mengjie Zhao",
      "Xiaofei Xie",
      "Qiang Hu",
      "Shangqing Liu",
      "Jie Zhang",
      "Wenhan Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10039",
    "title": "A Twitter BERT Approach for Offensive Language Detection in Marathi",
    "abstract": "Automated offensive language detection is essential in combating the spread of hate speech, particularly in social media. This paper describes our work on Offensive Language Identification in low resource Indic language Marathi. The problem is formulated as a text classification task to identify a tweet as offensive or non-offensive. We evaluate different mono-lingual and multi-lingual BERT models on this classification task, focusing on BERT models pre-trained with social media datasets. We compare the performance of MuRIL, MahaTweetBERT, MahaTweetBERT-Hateful, and MahaBERT on the HASOC 2022 test set. We also explore external data augmentation from other existing Marathi hate speech corpus HASOC 2021 and L3Cube-MahaHate. The MahaTweetBERT, a BERT model, pre-trained on Marathi tweets when fine-tuned on the combined dataset (HASOC 2021 + HASOC 2022 + MahaHate), outperforms all models with an F1 score of 98.43 on the HASOC 2022 test set. With this, we also provide a new state-of-the-art result on HASOC 2022 / MOLD v2 test set. ",
    "url": "https://arxiv.org/abs/2212.10039",
    "authors": [
      "Tanmay Chavan",
      "Shantanu Patankar",
      "Aditya Kane",
      "Omkar Gokhale",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10046",
    "title": "Causal Inference for Knowledge Graph based Recommendation",
    "abstract": "Knowledge Graph (KG), as a side-information, tends to be utilized to supplement the collaborative filtering (CF) based recommendation model. By mapping items with the entities in KGs, prior studies mostly extract the knowledge information from the KGs and inject it into the representations of users and items. Despite their remarkable performance, they fail to model the user preference on attributes in the KG, since they ignore that (1) the structure information of KG may hinder the user preference learning, and (2) the user's interacted attributes will result in the bias issue on the similarity scores. With the help of causality tools, we construct the causal-effect relation between the variables in KG-based recommendation and identify the reasons causing the mentioned challenges. Accordingly, we develop a new framework, termed Knowledge Graph-based Causal Recommendation (KGCR), which implements the deconfounded user preference learning and adopts counterfactual inference to eliminate bias in the similarity scoring. Ultimately, we evaluate our proposed model on three datasets, including Amazon-book, LastFM, and Yelp2018 datasets. By conducting extensive experiments on the datasets, we demonstrate that KGCR outperforms several state-of-the-art baselines, such as KGNN-LS, KGAT and KGIN. ",
    "url": "https://arxiv.org/abs/2212.10046",
    "authors": [
      "Yinwei Wei",
      "Xiang Wang",
      "Liqiang Nie",
      "Shaoyu Li",
      "Dingxian Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.10047",
    "title": "An Augmentation Strategy for Visually Rich Documents",
    "abstract": "Many business workflows require extracting important fields from form-like documents (e.g. bank statements, bills of lading, purchase orders, etc.). Recent techniques for automating this task work well only when trained with large datasets. In this work we propose a novel data augmentation technique to improve performance when training data is scarce, e.g. 10-250 documents. Our technique, which we call FieldSwap, works by swapping out the key phrases of a source field with the key phrases of a target field to generate new synthetic examples of the target field for use in training. We demonstrate that this approach can yield 1-7 F1 point improvements in extraction performance. ",
    "url": "https://arxiv.org/abs/2212.10047",
    "authors": [
      "Jing Xie",
      "James B. Wendt",
      "Yichao Zhou",
      "Seth Ebner",
      "Sandeep Tata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10049",
    "title": "OBMO: One Bounding Box Multiple Objects for Monocular 3D Object  Detection",
    "abstract": "Compared to typical multi-sensor systems, monocular 3D object detection has attracted much attention due to its simple configuration. However, there is still a significant gap between LiDAR-based and monocular-based methods. In this paper, we find that the ill-posed nature of monocular imagery can lead to depth ambiguity. Specifically, objects with different depths can appear with the same bounding boxes and similar visual features in the 2D image. Unfortunately, the network cannot accurately distinguish different depths from such non-discriminative visual features, resulting in unstable depth training. To facilitate depth learning, we propose a simple yet effective plug-and-play module, One Bounding Box Multiple Objects (OBMO). Concretely, we add a set of suitable pseudo labels by shifting the 3D bounding box along the viewing frustum. To constrain the pseudo-3D labels to be reasonable, we carefully design two label scoring strategies to represent their quality. In contrast to the original hard depth labels, such soft pseudo labels with quality scores allow the network to learn a reasonable depth range, boosting training stability and thus improving final performance. Extensive experiments on KITTI and Waymo benchmarks show that our method significantly improves state-of-the-art monocular 3D detectors by a significant margin (The improvements under the moderate setting on KITTI validation set are $\\mathbf{1.82\\sim 10.91\\%}$ mAP in BEV and $\\mathbf{1.18\\sim 9.36\\%}$ mAP in 3D}. Codes have been released at https://github.com/mrsempress/OBMO. ",
    "url": "https://arxiv.org/abs/2212.10049",
    "authors": [
      "Chenxi Huang",
      "Tong He",
      "Haidong Ren",
      "Wenxiao Wang",
      "Binbin Lin",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10051",
    "title": "A Framework of Customer Review Analysis Using the Aspect-Based Opinion  Mining Approach",
    "abstract": "Opinion mining is the branch of computation that deals with opinions, appraisals, attitudes, and emotions of people and their different aspects. This field has attracted substantial research interest in recent years. Aspect-level (called aspect-based opinion mining) is often desired in practical applications as it provides detailed opinions or sentiments about different aspects of entities and entities themselves, which are usually required for action. Aspect extraction and entity extraction are thus two core tasks of aspect-based opinion mining. his paper has presented a framework of aspect-based opinion mining based on the concept of transfer learning. on real-world customer reviews available on the Amazon website. The model has yielded quite satisfactory results in its task of aspect-based opinion mining. ",
    "url": "https://arxiv.org/abs/2212.10051",
    "authors": [
      "Subhasis Dasgupta",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10054",
    "title": "VoronoiPatches: Evaluating A New Data Augmentation Method",
    "abstract": "Overfitting is a problem in Convolutional Neural Networks (CNN) that causes poor generalization of models on unseen data. To remediate this problem, many new and diverse data augmentation methods (DA) have been proposed to supplement or generate more training data, and thereby increase its quality. In this work, we propose a new data augmentation algorithm: VoronoiPatches (VP). We primarily utilize non-linear recombination of information within an image, fragmenting and occluding small information patches. Unlike other DA methods, VP uses small convex polygon-shaped patches in a random layout to transport information around within an image. Sudden transitions created between patches and the original image can, optionally, be smoothed. In our experiments, VP outperformed current DA methods regarding model variance and overfitting tendencies. We demonstrate data augmentation utilizing non-linear re-combination of information within images, and non-orthogonal shapes and structures improves CNN model robustness on unseen data. ",
    "url": "https://arxiv.org/abs/2212.10054",
    "authors": [
      "Steffen Illium",
      "Gretchen Griffin",
      "Michael K\u00f6lle",
      "Maximilian Zorn",
      "Jonas N\u00fc\u00dflein",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10064",
    "title": "AdverSAR: Adversarial Search and Rescue via Multi-Agent Reinforcement  Learning",
    "abstract": "Search and Rescue (SAR) missions in remote environments often employ autonomous multi-robot systems that learn, plan, and execute a combination of local single-robot control actions, group primitives, and global mission-oriented coordination and collaboration. Often, SAR coordination strategies are manually designed by human experts who can remotely control the multi-robot system and enable semi-autonomous operations. However, in remote environments where connectivity is limited and human intervention is often not possible, decentralized collaboration strategies are needed for fully-autonomous operations. Nevertheless, decentralized coordination may be ineffective in adversarial environments due to sensor noise, actuation faults, or manipulation of inter-agent communication data. In this paper, we propose an algorithmic approach based on adversarial multi-agent reinforcement learning (MARL) that allows robots to efficiently coordinate their strategies in the presence of adversarial inter-agent communications. In our setup, the objective of the multi-robot team is to discover targets strategically in an obstacle-strewn geographical area by minimizing the average time needed to find the targets. It is assumed that the robots have no prior knowledge of the target locations, and they can interact with only a subset of neighboring robots at any time. Based on the centralized training with decentralized execution (CTDE) paradigm in MARL, we utilize a hierarchical meta-learning framework to learn dynamic team-coordination modalities and discover emergent team behavior under complex cooperative-competitive scenarios. The effectiveness of our approach is demonstrated on a collection of prototype grid-world environments with different specifications of benign and adversarial agents, target locations, and agent rewards. ",
    "url": "https://arxiv.org/abs/2212.10064",
    "authors": [
      "Aowabin Rahman",
      "Arnab Bhattacharya",
      "Thiagarajan Ramachandran",
      "Sayak Mukherjee",
      "Himanshu Sharma",
      "Ted Fujimoto",
      "Samrat Chatterjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.10066",
    "title": "RepMode: Learning to Re-parameterize Diverse Experts for Subcellular  Structure Prediction",
    "abstract": "In subcellular biological research, fluorescence staining is a key technique to reveal the locations and morphology of subcellular structures. However, fluorescence staining is slow, expensive, and harmful to cells. In this paper, we treat it as a deep learning task termed subcellular structure prediction (SSP), aiming to predict the 3D fluorescent images of multiple subcellular structures from a 3D transmitted-light image. Unfortunately, due to the limitations of current biotechnology, each image is partially labeled in SSP. Besides, naturally, the subcellular structures vary considerably in size, which causes the multi-scale issue in SSP. However, traditional solutions can not address SSP well since they organize network parameters inefficiently and inflexibly. To overcome these challenges, we propose Re-parameterizing Mixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its parameters with task-aware priors to handle specified single-label prediction tasks of SSP. In RepMode, the Mixture-of-Diverse-Experts (MoDE) block is designed to learn the generalized parameters for all tasks, and gating re-parameterization (GatRep) is performed to generate the specialized parameters for each task, by which RepMode can maintain a compact practical topology exactly like a plain network, and meanwhile achieves a powerful theoretical topology. Comprehensive experiments show that RepMode outperforms existing methods on ten of twelve prediction tasks of SSP and achieves state-of-the-art overall performance. ",
    "url": "https://arxiv.org/abs/2212.10066",
    "authors": [
      "Donghao Zhou",
      "Chunbin Gu",
      "Junde Xu",
      "Furui Liu",
      "Qiong Wang",
      "Guangyong Chen",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10076",
    "title": "Out-of-sample scoring and automatic selection of causal estimators",
    "abstract": "Recently, many causal estimators for Conditional Average Treatment Effect (CATE) and instrumental variable (IV) problems have been published and open sourced, allowing to estimate granular impact of both randomized treatments (such as A/B tests) and of user choices on the outcomes of interest. However, the practical application of such models has ben hampered by the lack of a valid way to score the performance of such models out of sample, in order to select the best one for a given application. We address that gap by proposing novel scoring approaches for both the CATE case and an important subset of instrumental variable problems, namely those where the instrumental variable is customer acces to a product feature, and the treatment is the customer's choice to use that feature. Being able to score model performance out of sample allows us to apply hyperparameter optimization methods to causal model selection and tuning. We implement that in an open source package that relies on DoWhy and EconML libraries for implementation of causal inference models (and also includes a Transformed Outcome model implementation), and on FLAML for hyperparameter optimization and for component models used in the causal models. We demonstrate on synthetic data that optimizing the proposed scores is a reliable method for choosing the model and its hyperparameter values, whose estimates are close to the true impact, in the randomized CATE and IV cases. Further, we provide examles of applying these methods to real customer data from Wise. ",
    "url": "https://arxiv.org/abs/2212.10076",
    "authors": [
      "Egor Kraev",
      "Timo Flesch",
      "Hudson Taylor Lekunze",
      "Mark Harley",
      "Pere Planell Morell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.10078",
    "title": "Constructing Organism Networks from Collaborative Self-Replicators",
    "abstract": "We introduce organism networks, which function like a single neural network but are composed of several neural particle networks; while each particle network fulfils the role of a single weight application within the organism network, it is also trained to self-replicate its own weights. As organism networks feature vastly more parameters than simpler architectures, we perform our initial experiments on an arithmetic task as well as on simplified MNIST-dataset classification as a collective. We observe that individual particle networks tend to specialise in either of the tasks and that the ones fully specialised in the secondary task may be dropped from the network without hindering the computational accuracy of the primary task. This leads to the discovery of a novel pruning-strategy for sparse neural networks ",
    "url": "https://arxiv.org/abs/2212.10078",
    "authors": [
      "Steffen Illium",
      "Maximilian Zorn",
      "Cristian Lenta",
      "Michael K\u00f6lle",
      "Claudia Linnhoff-Popien",
      "Thomas Gabor"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10079",
    "title": "A Survey on Pretrained Language Models for Neural Code Intelligence",
    "abstract": "As the complexity of modern software continues to escalate, software engineering has become an increasingly daunting and error-prone endeavor. In recent years, the field of Neural Code Intelligence (NCI) has emerged as a promising solution, leveraging the power of deep learning techniques to tackle analytical tasks on source code with the goal of improving programming efficiency and minimizing human errors within the software industry. Pretrained language models have become a dominant force in NCI research, consistently delivering state-of-the-art results across a wide range of tasks, including code summarization, generation, and translation. In this paper, we present a comprehensive survey of the NCI domain, including a thorough review of pretraining techniques, tasks, datasets, and model architectures. We hope this paper will serve as a bridge between the natural language and programming language communities, offering insights for future research in this rapidly evolving field. ",
    "url": "https://arxiv.org/abs/2212.10079",
    "authors": [
      "Yichen Xu",
      "Yanqiao Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10080",
    "title": "Rumour detection using graph neural network and oversampling in  benchmark Twitter dataset",
    "abstract": "Recently, online social media has become a primary source for new information and misinformation or rumours. In the absence of an automatic rumour detection system the propagation of rumours has increased manifold leading to serious societal damages. In this work, we propose a novel method for building automatic rumour detection system by focusing on oversampling to alleviating the fundamental challenges of class imbalance in rumour detection task. Our oversampling method relies on contextualised data augmentation to generate synthetic samples for underrepresented classes in the dataset. The key idea exploits selection of tweets in a thread for augmentation which can be achieved by introducing a non-random selection criteria to focus the augmentation process on relevant tweets. Furthermore, we propose two graph neural networks(GNN) to model non-linear conversations on a thread. To enhance the tweet representations in our method we employed a custom feature selection technique based on state-of-the-art BERTweet model. Experiments of three publicly available datasets confirm that 1) our GNN models outperform the the current state-of-the-art classifiers by more than 20%(F1-score); 2) our oversampling technique increases the model performance by more than 9%;(F1-score) 3) focusing on relevant tweets for data augmentation via non-random selection criteria can further improve the results; and 4) our method has superior capabilities to detect rumours at very early stage. ",
    "url": "https://arxiv.org/abs/2212.10080",
    "authors": [
      "Shaswat Patel",
      "Prince Bansal",
      "Preeti Kaur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10092",
    "title": "Exploring Effective Fusion Algorithms for Speech Based Self-Supervised  Learning Models",
    "abstract": "Self-supervised learning (SSL) has achieved great success in various areas including speech processing. Recently, it is proven that speech based SSL models are able to extract superior universal representations on a range of downstream tasks compared to traditional hand-craft feature (e.g. FBank, MFCC) in the SUPERB benchmark. However, different types of SSL models might exhibit distinct strengths on different downstream tasks. In order to better utilize the potential power of SSL models, in this work, we explore the effective fusion on multiple SSL models. A series of model fusion algorithms are investigated and compared by combining two types of SSL models, Hubert and Data2vec, on two representative tasks from SUPERB benchmark, which are speaker identification (SID) and automatic speech recognition (ASR) tasks. The experimental results demonstrate that our proposed fusion algorithms can further boost the individual model significantly. ",
    "url": "https://arxiv.org/abs/2212.10092",
    "authors": [
      "Changli Tang",
      "Yujin Wang",
      "Xie Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.10093",
    "title": "Visual Transformers for Primates Classification and Covid Detection",
    "abstract": "We apply the vision transformer, a deep machine learning model build around the attention mechanism, on mel-spectrogram representations of raw audio recordings. When adding mel-based data augmentation techniques and sample-weighting, we achieve comparable performance on both (PRS and CCS challenge) tasks of ComParE21, outperforming most single model baselines. We further introduce overlapping vertical patching and evaluate the influence of parameter configurations. Index Terms: audio classification, attention, mel-spectrogram, unbalanced data-sets, computational paralinguistics ",
    "url": "https://arxiv.org/abs/2212.10093",
    "authors": [
      "Steffen Illium",
      "Robert M\u00fcller",
      "Andreas Sedlmeier",
      "Claudia-Linnhoff Popien"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.10097",
    "title": "Toward a Unified Framework for Unsupervised Complex Tabular Reasoning",
    "abstract": "Structured tabular data exist across nearly all fields. Reasoning task over these data aims to answer questions or determine the truthiness of hypothesis sentences by understanding the semantic meaning of a table. While previous works have devoted significant efforts to the tabular reasoning task, they always assume there are sufficient labeled data. However, constructing reasoning samples over tables (and related text) is labor-intensive, especially when the reasoning process is complex. When labeled data is insufficient, the performance of models will suffer an unendurable decline. In this paper, we propose a unified framework for unsupervised complex tabular reasoning (UCTR), which generates sufficient and diverse synthetic data with complex logic for tabular reasoning tasks, assuming no human-annotated data at all. We first utilize a random sampling strategy to collect diverse programs of different types and execute them on tables based on a \"Program-Executor\" module. To bridge the gap between the programs and natural language sentences, we design a powerful \"NL-Generator\" module to generate natural language sentences with complex logic from these programs. Since a table often occurs with its surrounding texts, we further propose novel \"Table-to-Text\" and \"Text-to-Table\" operators to handle joint table-text reasoning scenarios. This way, we can adequately exploit the unlabeled table resources to obtain a well-performed reasoning model under an unsupervised setting. Our experiments cover different tasks (question answering and fact verification) and different domains (general and specific), showing that our unsupervised methods can achieve at most 93% performance compared to supervised models. We also find that it can substantially boost the supervised performance in low-resourced domains as a data augmentation technique. Our code is available at https://github.com/leezythu/UCTR. ",
    "url": "https://arxiv.org/abs/2212.10097",
    "authors": [
      "Zhenyu Li",
      "Xiuxing Li",
      "Zhichao Duan",
      "Bowen Dong",
      "Ning Liu",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.10103",
    "title": "VSVC: Backdoor attack against Keyword Spotting based on Voiceprint  Selection and Voice Conversion",
    "abstract": "Keyword spotting (KWS) based on deep neural networks (DNNs) has achieved massive success in voice control scenarios. However, training of such DNN-based KWS systems often requires significant data and hardware resources. Manufacturers often entrust this process to a third-party platform. This makes the training process uncontrollable, where attackers can implant backdoors in the model by manipulating third-party training data. An effective backdoor attack can force the model to make specified judgments under certain conditions, i.e., triggers. In this paper, we design a backdoor attack scheme based on Voiceprint Selection and Voice Conversion, abbreviated as VSVC. Experimental results demonstrated that VSVC is feasible to achieve an average attack success rate close to 97% in four victim models when poisoning less than 1% of the training data. ",
    "url": "https://arxiv.org/abs/2212.10103",
    "authors": [
      "Hanbo Cai",
      "Pengcheng Zhang",
      "Hai Dong",
      "Yan Xiao",
      "Shunhui Ji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.10129",
    "title": "Minimizing interference-to-signal ratios in multi-cell networks",
    "abstract": "In contemporary wireless communication networks, base-stations are organized into coordinated clusters (called cells) to jointly serve the users. However, such fixed systems are plagued by the so-called cell-edge problem: near the boundaries, the interference between neighboring clusters can result in very poor interference-to-signal-power ratios. To achieve a high quality service, it is an important objective to minimize the sum of these ratios over the cells. The most common approach to solve this minimization problem is arguably the spectral clustering method. In this paper, we propose a new clustering approach, which is deterministic and computationally much less demanding than current methods. Simulating on synthetic instances indicates that our methods typically provide higher quality solutions than earlier methods. An earlier version of this algorithm was reported in arXiv:2111.00885. ",
    "url": "https://arxiv.org/abs/2212.10129",
    "authors": [
      "P\u00e9ter L. Erd\u0151s",
      "Tam\u00e1s R\u00f3bert Mezei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2212.10132",
    "title": "Content Adaptive Latents and Decoder for Neural Image Compression",
    "abstract": "In recent years, neural image compression (NIC) algorithms have shown powerful coding performance. However, most of them are not adaptive to the image content. Although several content adaptive methods have been proposed by updating the encoder-side components, the adaptability of both latents and the decoder is not well exploited. In this work, we propose a new NIC framework that improves the content adaptability on both latents and the decoder. Specifically, to remove redundancy in the latents, our content adaptive channel dropping (CACD) method automatically selects the optimal quality levels for the latents spatially and drops the redundant channels. Additionally, we propose the content adaptive feature transformation (CAFT) method to improve decoder-side content adaptability by extracting the characteristic information of the image content, which is then used to transform the features in the decoder side. Experimental results demonstrate that our proposed methods with the encoder-side updating algorithm achieve the state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2212.10132",
    "authors": [
      "Guanbo Pan",
      "Guo Lu",
      "Zhihao Hu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.10136",
    "title": "A Comparison Between Tsetlin Machines and Deep Neural Networks in the  Context of Recommendation Systems",
    "abstract": "Recommendation Systems (RSs) are ubiquitous in modern society and are one of the largest points of interaction between humans and AI. Modern RSs are often implemented using deep learning models, which are infamously difficult to interpret. This problem is particularly exasperated in the context of recommendation scenarios, as it erodes the user's trust in the RS. In contrast, the newly introduced Tsetlin Machines (TM) possess some valuable properties due to their inherent interpretability. TMs are still fairly young as a technology. As no RS has been developed for TMs before, it has become necessary to perform some preliminary research regarding the practicality of such a system. In this paper, we develop the first RS based on TMs to evaluate its practicality in this application domain. This paper compares the viability of TMs with other machine learning models prevalent in the field of RS. We train and investigate the performance of the TM compared with a vanilla feed-forward deep learning model. These comparisons are based on model performance, interpretability/explainability, and scalability. Further, we provide some benchmark performance comparisons to similar machine learning solutions relevant to RSs. ",
    "url": "https://arxiv.org/abs/2212.10136",
    "authors": [
      "Karl Audun Borgersen",
      "Morten Goodwin",
      "Jivitesh Sharma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.10147",
    "title": "Bridging Images and Videos: A Simple Learning Framework for Large  Vocabulary Video Object Detection",
    "abstract": "Scaling object taxonomies is one of the important steps toward a robust real-world deployment of recognition systems. We have faced remarkable progress in images since the introduction of the LVIS benchmark. To continue this success in videos, a new video benchmark, TAO, was recently presented. Given the recent encouraging results from both detection and tracking communities, we are interested in marrying those two advances and building a strong large vocabulary video tracker. However, supervisions in LVIS and TAO are inherently sparse or even missing, posing two new challenges for training the large vocabulary trackers. First, no tracking supervisions are in LVIS, which leads to inconsistent learning of detection (with LVIS and TAO) and tracking (only with TAO). Second, the detection supervisions in TAO are partial, which results in catastrophic forgetting of absent LVIS categories during video fine-tuning. To resolve these challenges, we present a simple but effective learning framework that takes full advantage of all available training data to learn detection and tracking while not losing any LVIS categories to recognize. With this new learning scheme, we show that consistent improvements of various large vocabulary trackers are capable, setting strong baseline results on the challenging TAO benchmarks. ",
    "url": "https://arxiv.org/abs/2212.10147",
    "authors": [
      "Sanghyun Woo",
      "Kwanyong Park",
      "Seoung Wug Oh",
      "In So Kweon",
      "Joon-Young Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10158",
    "title": "Spreading and Structural Balance on Signed Networks",
    "abstract": "Two competing types of interactions often play an important part in shaping system behavior, such as activatory or inhibitory functions in biological systems. Hence, signed networks, where each connection can be either positive or negative, have become popular models over recent years. However, the primary focus of the literature is on the unweighted and structurally balanced ones, where all cycles have an even number of negative edges. Hence here, we first introduce a classification of signed networks into balanced, antibalanced or strictly balanced ones, and then characterize each type of signed networks in terms of the spectral properties of the signed weighted adjacency matrix. In particular, we show that the spectral radius of the matrix with signs is smaller than that without if and only if the signed network is strictly unbalanced. These properties are important to understand the dynamics on signed networks, both linear and nonlinear ones. Specifically, we find consistent patterns in a linear and a nonlinear dynamics theoretically, depending on their type of balance. We also propose two measures to further characterize strictly unbalanced networks, motivated by perturbation theory. Finally, we numerically verify these properties through experiments on both synthetic and real networks. ",
    "url": "https://arxiv.org/abs/2212.10158",
    "authors": [
      "Yu Tian",
      "Renaud Lambiotte"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2212.10170",
    "title": "Hoyer regularizer is all you need for ultra low-latency spiking neural  networks",
    "abstract": "Spiking Neural networks (SNN) have emerged as an attractive spatio-temporal computing paradigm for a wide range of low-power vision tasks. However, state-of-the-art (SOTA) SNN models either incur multiple time steps which hinder their deployment in real-time use cases or increase the training complexity significantly. To mitigate this concern, we present a training framework (from scratch) for one-time-step SNNs that uses a novel variant of the recently proposed Hoyer regularizer. We estimate the threshold of each SNN layer as the Hoyer extremum of a clipped version of its activation map, where the clipping threshold is trained using gradient descent with our Hoyer regularizer. This approach not only downscales the value of the trainable threshold, thereby emitting a large number of spikes for weight update with a limited number of iterations (due to only one time step) but also shifts the membrane potential values away from the threshold, thereby mitigating the effect of noise that can degrade the SNN accuracy. Our approach outperforms existing spiking, binary, and adder neural networks in terms of the accuracy-FLOPs trade-off for complex image recognition tasks. Downstream experiments on object detection also demonstrate the efficacy of our approach. ",
    "url": "https://arxiv.org/abs/2212.10170",
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10174",
    "title": "CGCV:Context Guided Correlation Volume for Optical Flow Neural Networks",
    "abstract": "Optical flow, which computes the apparent motion from a pair of video frames, is a critical tool for scene motion estimation. Correlation volume is the central component of optical flow computational neural models. It estimates the pairwise matching costs between cross-frame features, and is then used to decode optical flow. However, traditional correlation volume is frequently noisy, outlier-prone, and sensitive to motion blur. We observe that, although the recent RAFT algorithm also adopts the traditional correlation volume, its additional context encoder provides semantically representative features to the flow decoder, implicitly compensating for the deficiency of the correlation volume. However, the benefits of this context encoder has been barely discussed or exploited. In this paper, we first investigate the functionality of RAFT's context encoder, then propose a new Context Guided Correlation Volume (CGCV) via gating and lifting schemes. CGCV can be universally integrated with RAFT-based flow computation methods for enhanced performance, especially effective in the presence of motion blur, de-focus blur and atmospheric effects. By incorporating the proposed CGCV with previous Global Motion Aggregation (GMA) method, at a minor cost of 0.5% extra parameters, the rank of GMA is lifted by 23 places on KITTI 2015 Leader Board, and 3 places on Sintel Leader Board. Moreover, at a similar model size, our correlation volume achieves competitive or superior performance to state of the art peer supervised models that employ Transformers or Graph Reasoning, as verified by extensive experiments. ",
    "url": "https://arxiv.org/abs/2212.10174",
    "authors": [
      "Jiangpeng Li",
      "Yan Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10198",
    "title": "Non-intrusive reduced order models for the accurate prediction of  bifurcating phenomena in compressible fluid dynamics",
    "abstract": "The present works is focused on studying bifurcating solutions in compressible fluid dynamics. On one side, the physics of the problem is thoroughly investigated using high-fidelity simulations of the compressible Navier-Stokes equations discretised with the Discontinuous Galerkin method. On the other side, from a numerical modelling point of view, two different non-intrusive reduced order modelling techniques are employed to predict the overall behaviour of the bifurcation. Both approaches showed good agreement with full-order simulations even in proximity of the bifurcating points where the solution is particularly non-smooth. ",
    "url": "https://arxiv.org/abs/2212.10198",
    "authors": [
      "Niccol\u00f2 Tonicello",
      "Andrea Lario",
      "Gianluigi Rozza",
      "Gianmarco Mengaldo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.10203",
    "title": "ParallelNet: Multi-mode Trajectory Prediction by Multi-mode Trajectory  Fusion",
    "abstract": "Level 5 Autonomous Driving, a technology that a fully automated vehicle (AV) requires no human intervention, has raised serious concerns on safety and stability before widespread use. The capability of understanding and predicting future motion trajectory of road objects can help AV plan a path that is safe and easy to control. In this paper, we propose a network architecture that parallelizes multiple convolutional neural network backbones and fuses features to make multi-mode trajectory prediction. In the 2020 ICRA Nuscene Prediction challenge, our model ranks 15th on the leaderboard across all teams. ",
    "url": "https://arxiv.org/abs/2212.10203",
    "authors": [
      "Fei Wu",
      "Luoyu Chen",
      "Hao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10207",
    "title": "Graph Neural Networks in Computer Vision -- Architectures, Datasets and  Common Approaches",
    "abstract": "Graph Neural Networks (GNNs) are a family of graph networks inspired by mechanisms existing between nodes on a graph. In recent years there has been an increased interest in GNN and their derivatives, i.e., Graph Attention Networks (GAT), Graph Convolutional Networks (GCN), and Graph Recurrent Networks (GRN). An increase in their usability in computer vision is also observed. The number of GNN applications in this field continues to expand; it includes video analysis and understanding, action and behavior recognition, computational photography, image and video synthesis from zero or few shots, and many more. This contribution aims to collect papers published about GNN-based approaches towards computer vision. They are described and summarized from three perspectives. Firstly, we investigate the architectures of Graph Neural Networks and their derivatives used in this area to provide accurate and explainable recommendations for the ensuing investigations. As for the other aspect, we also present datasets used in these works. Finally, using graph analysis, we also examine relations between GNN-based studies in computer vision and potential sources of inspiration identified outside of this field. ",
    "url": "https://arxiv.org/abs/2212.10207",
    "authors": [
      "Maciej Krzywda",
      "Szymon \u0141ukasik",
      "Amir H. Gandomi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10221",
    "title": "SoK: Analysis of Root Causes and Defense Strategies for Attacks on  Microarchitectural Optimizations",
    "abstract": "Microarchitectural optimizations are expected to play a crucial role in ensuring performance scalability in future technology nodes. However, recent attacks have demonstrated that microarchitectural optimizations, which were assumed to be secure, can be exploited. Moreover, new attacks surface at a rapid pace limiting the scope of existing defenses. These developments prompt the need to review microarchitectural optimizations with an emphasis on security, understand the attack landscape and the potential defense strategies. We analyze timing-based side-channel attacks targeting a diverse set of microarchitectural optimizations. We provide a framework for analysing non-transient and transient attacks, which highlights the similarities. We identify the four root causes of timing-based side-channel attacks: determinism, sharing, access violation and information flow, through our systematic analysis. Our key insight is that a subset (or all) of the root causes are exploited by attacks and eliminating any of the exploited root causes, in any attack step, is enough to provide protection. Leveraging our framework, we systematize existing defenses and show that they target these root causes in the different attack steps. ",
    "url": "https://arxiv.org/abs/2212.10221",
    "authors": [
      "Nadja Ramh\u00f6j Holtryd",
      "Madhavan Manivannan",
      "Per Stenstr\u00f6m"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2212.10230",
    "title": "A Comprehensive Study and Comparison of the Robustness of 3D Object  Detectors Against Adversarial Attacks",
    "abstract": "Deep learning-based 3D object detectors have made significant progress in recent years and have been deployed in a wide range of applications. It is crucial to understand the robustness of detectors against adversarial attacks when employing detectors in security-critical applications. In this paper, we make the first attempt to conduct a thorough evaluation and analysis of the robustness of 3D detectors under adversarial attacks. Specifically, we first extend three kinds of adversarial attacks to the 3D object detection task to benchmark the robustness of state-of-the-art 3D object detectors against attacks on KITTI and Waymo datasets, subsequently followed by the analysis of the relationship between robustness and properties of detectors. Then, we explore the transferability of cross-model, cross-task, and cross-data attacks. We finally conduct comprehensive experiments of defense for 3D detectors, demonstrating that simple transformations like flipping are of little help in improving robustness when the strategy of transformation imposed on input point cloud data is exposed to attackers. Our findings will facilitate investigations in understanding and defending the adversarial attacks against 3D object detectors to advance this field. ",
    "url": "https://arxiv.org/abs/2212.10230",
    "authors": [
      "Yifan Zhang",
      "Junhui Hou",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10236",
    "title": "Self-Pair: Synthesizing Changes from Single Source for Object Change  Detection in Remote Sensing Imagery",
    "abstract": "For change detection in remote sensing, constructing a training dataset for deep learning models is difficult due to the requirements of bi-temporal supervision. To overcome this issue, single-temporal supervision which treats change labels as the difference of two semantic masks has been proposed. This novel method trains a change detector using two spatially unrelated images with corresponding semantic labels such as building. However, training on unpaired datasets could confuse the change detector in the case of pixels that are labeled unchanged but are visually significantly different. In order to maintain the visual similarity in unchanged area, in this paper, we emphasize that the change originates from the source image and show that manipulating the source image as an after-image is crucial to the performance of change detection. Extensive experiments demonstrate the importance of maintaining visual information between pre- and post-event images, and our method outperforms existing methods based on single-temporal supervision. code is available at https://github.com/seominseok0429/Self-Pair-for-Change-Detection. ",
    "url": "https://arxiv.org/abs/2212.10236",
    "authors": [
      "Minseok Seo",
      "Hakjin Lee",
      "Yongjin Jeon",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10245",
    "title": "Neural Belief Propagation Decoding of Quantum LDPC Codes Using  Overcomplete Check Matrices",
    "abstract": "The recent success in constructing asymptotically good quantum low-density parity-check (QLDPC) codes makes this family of codes a promising candidate for error-correcting schemes in quantum computing. However, conventional belief propagation (BP) decoding of QLDPC codes does not yield satisfying performance due to the presence of unavoidable short cycles in their Tanner graph and the special degeneracy phenomenon. In this work, we propose to decode QLDPC codes based on a check matrix with redundant rows, generated from linear combinations of the rows in the original check matrix. This approach yields a significant improvement in decoding performance with the additional advantage of very low decoding latency. Furthermore, we propose a novel neural belief propagation decoder based on the quaternary BP decoder of QLDPC codes which leads to further decoding performance improvements. ",
    "url": "https://arxiv.org/abs/2212.10245",
    "authors": [
      "Sisi Miao",
      "Alexander Schnerring",
      "Haizheng Li",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2212.10258",
    "title": "In and Out-of-Domain Text Adversarial Robustness via Label Smoothing",
    "abstract": "Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study the adversarial robustness provided by various label smoothing strategies in foundational models for diverse NLP tasks in both in-domain and out-of-domain settings. Our experiments show that label smoothing significantly improves adversarial robustness in pre-trained models like BERT, against various popular attacks. We also analyze the relationship between prediction confidence and robustness, showing that label smoothing reduces over-confident errors on adversarial examples. ",
    "url": "https://arxiv.org/abs/2212.10258",
    "authors": [
      "Yahan Yang",
      "Soham Dan",
      "Dan Roth",
      "Insup Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10264",
    "title": "ReCode: Robustness Evaluation of Code Generation Models",
    "abstract": "Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model's robustness performance. With human annotators, we verified that over 90% of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval. ",
    "url": "https://arxiv.org/abs/2212.10264",
    "authors": [
      "Shiqi Wang",
      "Zheng Li",
      "Haifeng Qian",
      "Chenghao Yang",
      "Zijian Wang",
      "Mingyue Shang",
      "Varun Kumar",
      "Samson Tan",
      "Baishakhi Ray",
      "Parminder Bhatia",
      "Ramesh Nallapati",
      "Murali Krishna Ramanathan",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.10275",
    "title": "ARO-Net: Learning Neural Fields from Anchored Radial Observations",
    "abstract": "We introduce anchored radial observations (ARO), a novel shape encoding for learning neural field representation of shapes that is category-agnostic and generalizable amid significant shape variations. The main idea behind our work is to reason about shapes through partial observations from a set of viewpoints, called anchors. We develop a general and unified shape representation by employing a fixed set of anchors, via Fibonacci sampling, and designing a coordinate-based deep neural network to predict the occupancy value of a query point in space. Differently from prior neural implicit models, that use global shape feature, our shape encoder operates on contextual, query-specific features. To predict point occupancy, locally observed shape information from the perspective of the anchors surrounding the input query point are encoded and aggregated through an attention module, before implicit decoding is performed. We demonstrate the quality and generality of our network, coined ARO-Net, on surface reconstruction from sparse point clouds, with tests on novel and unseen object categories, \"one-shape\" training, and comparisons to state-of-the-art neural and classical methods for reconstruction and tessellation. ",
    "url": "https://arxiv.org/abs/2212.10275",
    "authors": [
      "Yizhi Wang",
      "Zeyu Huang",
      "Ariel Shamir",
      "Hui Huang",
      "Hao Zhang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.10288",
    "title": "Personalized PageRank on Evolving Graphs with an Incremental  Index-Update Scheme",
    "abstract": "{\\em Personalized PageRank (PPR)} stands as a fundamental proximity measure in graph mining. Since computing an exact SSPPR query answer is prohibitive, most existing solutions turn to approximate queries with guarantees. The state-of-the-art solutions for approximate SSPPR queries are index-based and mainly focus on static graphs, while real-world graphs are usually dynamically changing. However, existing index-update schemes can not achieve a sub-linear update time. Motivated by this, we present an efficient indexing scheme to maintain indexed random walks in expected $O(1)$ time after each graph update. To reduce the space consumption, we further propose a new sampling scheme to remove the auxiliary data structure for vertices while still supporting $O(1)$ index update cost on evolving graphs. Extensive experiments show that our update scheme achieves orders of magnitude speed-up on update performance over existing index-based dynamic schemes without sacrificing the query efficiency. ",
    "url": "https://arxiv.org/abs/2212.10288",
    "authors": [
      "Guanhao Hou",
      "Qintian Guo",
      "Fangyuan Zhang",
      "Sibo Wang",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.10319",
    "title": "Image quality prediction using synthetic and natural codebooks:  comparative results",
    "abstract": "We investigate a model for image/video quality assessment based on building a set of codevectors representing in a sense some basic properties of images, similar to well-known CORNIA model. We analyze the codebook building method and propose some modifications for it. Also the algorithm is investigated from the point of inference time reduction. Both natural and synthetic images are used for building codebooks and some analysis of synthetic images used for codebooks is provided. It is demonstrated the results on quality assessment may be improves with the use if synthetic images for codebook construction. We also demonstrate regimes of the algorithm in which real time execution on CPU is possible for sufficiently high correlations with mean opinion score (MOS). Various pooling strategies are considered as well as the problem of metric sensitivity to bitrate. ",
    "url": "https://arxiv.org/abs/2212.10319",
    "authors": [
      "Maxim Koroteev",
      "Kirill Aistov",
      "Valeriy Berezovskiy",
      "Pavel Frolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10341",
    "title": "CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data  Limitation With Contrastive Learning",
    "abstract": "Machine-Generated Text (MGT) detection, a task that discriminates MGT from Human-Written Text (HWT), plays a crucial role in preventing misuse of text generative models, which excel in mimicking human writing style recently. Latest proposed detectors usually take coarse text sequence as input and output some good results by fine-tune pretrained models with standard cross-entropy loss. However, these methods fail to consider the linguistic aspect of text (e.g., coherence) and sentence-level structures. Moreover, they lack the ability to handle the low-resource problem which could often happen in practice considering the enormous amount of textual data online. In this paper, we present a coherence-based contrastive learning model named CoCo to detect the possible MGT under low-resource scenario. Inspired by the distinctiveness and permanence properties of linguistic feature, we represent text as a coherence graph to capture its entity consistency, which is further encoded by the pretrained model and graph neural network. To tackle the challenges of data limitations, we employ a contrastive learning framework and propose an improved contrastive loss for making full use of hard negative samples in training stage. The experiment results on two public datasets prove our approach outperforms the state-of-art methods significantly. ",
    "url": "https://arxiv.org/abs/2212.10341",
    "authors": [
      "Xiaoming Liu",
      "Zhaohan Zhang",
      "Yichen Wang",
      "Yu Lan",
      "Chao Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10346",
    "title": "Does It Affect You? Social and Learning Implications of Using  Cognitive-Affective State Recognition for Proactive Human-Robot Tutoring",
    "abstract": "Using robots in educational contexts has already shown to be beneficial for a student's learning and social behaviour. For levitating them to the next level of providing more effective and human-like tutoring, the ability to adapt to the user and to express proactivity is fundamental. By acting proactively, intelligent robotic tutors anticipate possible situations where problems for the student may arise and act in advance for preventing negative outcomes. Still, the decisions of when and how to behave proactively are open questions. Therefore, this paper deals with the investigation of how the student's cognitive-affective states can be used by a robotic tutor for triggering proactive tutoring dialogue. In doing so, it is aimed to improve the learning experience. For this reason, a concept learning task scenario was observed where a robotic assistant proactively helped when negative user states were detected. In a learning task, the user's states of frustration and confusion were deemed to have negative effects on the outcome of the task and were used to trigger proactive behaviour. In an empirical user study with 40 undergraduate and doctoral students, we studied whether the initiation of proactive behaviour after the detection of signs of confusion and frustration improves the student's concentration and trust in the agent. Additionally, we investigated which level of proactive dialogue is useful for promoting the student's concentration and trust. The results show that high proactive behaviour harms trust, especially when triggered during negative cognitive-affective states but contributes to keeping the student focused on the task when triggered in these states. Based on our study results, we further discuss future steps for improving the proactive assistance of robotic tutoring systems. ",
    "url": "https://arxiv.org/abs/2212.10346",
    "authors": [
      "Matthias Kraus",
      "Diana Betancourt",
      "Wolfgang Minker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10355",
    "title": "Optimizing Serially Concatenated Neural Codes with Classical Decoders",
    "abstract": "For improving short-length codes, we demonstrate that classic decoders can also be used with real-valued, neural encoders, i.e., deep-learning based codeword sequence generators. Here, the classical decoder can be a valuable tool to gain insights into these neural codes and shed light on weaknesses. Specifically, the turbo-autoencoder is a recently developed channel coding scheme where both encoder and decoder are replaced by neural networks. We first show that the limited receptive field of convolutional neural network (CNN)-based codes enables the application of the BCJR algorithm to optimally decode them with feasible computational complexity. These maximum a posteriori (MAP) component decoders then are used to form classical (iterative) turbo decoders for parallel or serially concatenated CNN encoders, offering a close-to-maximum likelihood (ML) decoding of the learned codes. To the best of our knowledge, this is the first time that a classical decoding algorithm is applied to a non-trivial, real-valued neural code. Furthermore, as the BCJR algorithm is fully differentiable, it is possible to train, or fine-tune, the neural encoder in an end-to-end fashion. ",
    "url": "https://arxiv.org/abs/2212.10355",
    "authors": [
      "Jannis Clausius",
      "Marvin Geiselhart",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10367",
    "title": "Modeling Human Eye Movements with Neural Networks in a Maze-Solving Task",
    "abstract": "From smoothly pursuing moving objects to rapidly shifting gazes during visual search, humans employ a wide variety of eye movement strategies in different contexts. While eye movements provide a rich window into mental processes, building generative models of eye movements is notoriously difficult, and to date the computational objectives guiding eye movements remain largely a mystery. In this work, we tackled these problems in the context of a canonical spatial planning task, maze-solving. We collected eye movement data from human subjects and built deep generative models of eye movements using a novel differentiable architecture for gaze fixations and gaze shifts. We found that human eye movements are best predicted by a model that is optimized not to perform the task as efficiently as possible but instead to run an internal simulation of an object traversing the maze. This not only provides a generative model of eye movements in this task but also suggests a computational theory for how humans solve the task, namely that humans use mental simulation. ",
    "url": "https://arxiv.org/abs/2212.10367",
    "authors": [
      "Jason Li",
      "Nicholas Watters",
      "Yingting",
      "Wang",
      "Hansem Sohn",
      "Mehrdad Jazayeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2212.10368",
    "title": "Masked Event Modeling: Self-Supervised Pretraining for Event Cameras",
    "abstract": "Event cameras offer the capacity to asynchronously capture brightness changes with low latency, high temporal resolution, and high dynamic range. Deploying deep learning methods for classification or other tasks to these sensors typically requires large labeled datasets. Since the amount of labeled event data is tiny compared to the bulk of labeled RGB imagery, the progress of event-based vision has remained limited. To reduce the dependency on labeled event data, we introduce Masked Event Modeling (MEM), a self-supervised pretraining framework for events. Our method pretrains a neural network on unlabeled events, which can originate from any event camera recording. Subsequently, the pretrained model is finetuned on a downstream task leading to an overall better performance while requiring fewer labels. Our method outperforms the state-of-the-art on N-ImageNet, N-Cars, and N-Caltech101, increasing the object classification accuracy on N-ImageNet by 7.96%. We demonstrate that Masked Event Modeling is superior to RGB-based pretraining on a real world dataset. ",
    "url": "https://arxiv.org/abs/2212.10368",
    "authors": [
      "Simon Klenk",
      "David Bonello",
      "Lukas Koestler",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10376",
    "title": "The Third International Verification of Neural Networks Competition  (VNN-COMP 2022): Summary and Results",
    "abstract": "This report summarizes the 3rd International Verification of Neural Networks Competition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal Methods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with the 34th International Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to facilitate the fair and objective comparison of state-of-the-art neural network verification tools, encourage the standardization of tool interfaces, and bring together the neural network verification community. To this end, standardized formats for networks (ONNX) and specification (VNN-LIB) were defined, tools were evaluated on equal-cost hardware (using an automatic evaluation pipeline based on AWS instances), and tool parameters were chosen by the participants before the final test sets were made public. In the 2022 iteration, 11 teams participated on a diverse set of 12 scored benchmarks. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this iteration of this competition. ",
    "url": "https://arxiv.org/abs/2212.10376",
    "authors": [
      "Mark Niklas M\u00fcller",
      "Christopher Brix",
      "Stanley Bak",
      "Changliu Liu",
      "Taylor T. Johnson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.10382",
    "title": "A World Full of Privacy and Security (Mis)conceptions? Findings of a  Representative Survey in 12 Countries",
    "abstract": "Misconceptions about digital security and privacy topics in the general public frequently lead to insecure behavior. However, little is known about the prevalence and extent of such misconceptions in a global context. In this work, we present the results of the first large-scale survey of a global population on misconceptions: We conducted an online survey with n = 12, 351 participants in 12 countries on four continents. By investigating influencing factors of misconceptions around eight common security and privacy topics (including E2EE, Wi-Fi, VPN, and malware), we find the country of residence to be the strongest estimate for holding misconceptions. We also identify differences between non-Western and Western countries, demonstrating the need for region-specific research on user security knowledge, perceptions, and behavior. While we did not observe many outright misconceptions, we did identify a lack of understanding and uncertainty about several fundamental privacy and security topics. ",
    "url": "https://arxiv.org/abs/2212.10382",
    "authors": [
      "Franziska Herbert",
      "Steffen Becker",
      "Leonie Schaewitz",
      "Jonas Hielscher",
      "Marvin Kowalewski",
      "M. Angela Sasse",
      "Yasemin Acar",
      "Markus D\u00fcrmuth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.10388",
    "title": "ThreatKG: A Threat Knowledge Graph for Automated Open-Source Cyber  Threat Intelligence Gathering and Management",
    "abstract": "Despite the increased adoption of open-source cyber threat intelligence (OSCTI) for acquiring knowledge about cyber threats, little effort has been made to harvest knowledge from a large number of unstructured OSCTI reports available in the wild (e.g., security articles, threat reports). These reports provide comprehensive threat knowledge in a variety of entities (e.g., IOCs, threat actors, TTPs) and relations, which, however, are hard to gather due to diverse report formats, large report quantities, and complex structures and nuances in the natural language report text. To bridge the gap, we propose ThreatKG, a system for automated open-source cyber threat knowledge gathering and management. ThreatKG automatically collects a large number of OSCTI reports from various sources, extracts high-fidelity threat knowledge, constructs a threat knowledge graph, and updates the knowledge graph by continuously ingesting new knowledge. To address multiple challenges, ThreatKG provides: (1) a hierarchical ontology for modeling a variety of threat knowledge entities and relations; (2) an accurate deep learning-based pipeline for threat knowledge extraction; (3) a scalable and extensible system architecture for threat knowledge graph construction, persistence, updating, and exploration. Evaluations on a large number of reports demonstrate the effectiveness of ThreatKG in threat knowledge gathering and management ",
    "url": "https://arxiv.org/abs/2212.10388",
    "authors": [
      "Peng Gao",
      "Xiaoyuan Liu",
      "Edward Choi",
      "Sibo Ma",
      "Xinyu Yang",
      "Zhengjie Ji",
      "Zilin Zhang",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.10392",
    "title": "Debiasing Stance Detection Models with Counterfactual Reasoning and  Adversarial Bias Learning",
    "abstract": "Stance detection models may tend to rely on dataset bias in the text part as a shortcut and thus fail to sufficiently learn the interaction between the targets and texts. Recent debiasing methods usually treated features learned by small models or big models at earlier steps as bias features and proposed to exclude the branch learning those bias features during inference. However, most of these methods fail to disentangle the ``good'' stance features and ``bad'' bias features in the text part. In this paper, we investigate how to mitigate dataset bias in stance detection. Motivated by causal effects, we leverage a novel counterfactual inference framework, which enables us to capture the dataset bias in the text part as the direct causal effect of the text on stances and reduce the dataset bias in the text part by subtracting the direct text effect from the total causal effect. We novelly model bias features as features that correlate with the stance labels but fail on intermediate stance reasoning subtasks and propose an adversarial bias learning module to model the bias more accurately. To verify whether our model could better model the interaction between texts and targets, we test our model on recently proposed test sets to evaluate the understanding of the task from various aspects. Experiments demonstrate that our proposed method (1) could better model the bias features, and (2) outperforms existing debiasing baselines on both the original dataset and most of the newly constructed test sets. ",
    "url": "https://arxiv.org/abs/2212.10392",
    "authors": [
      "Jianhua Yuan",
      "Yanyan Zhao",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10405",
    "title": "AnnoBERT: Effectively Representing Multiple Annotators' Label Choices to  Improve Hate Speech Detection",
    "abstract": "Supervised approaches generally rely on majority-based labels. However, it is hard to achieve high agreement among annotators in subjective tasks such as hate speech detection. Existing neural network models principally regard labels as categorical variables, while ignoring the semantic information in diverse label texts. In this paper, we propose AnnoBERT, a first-of-its-kind architecture integrating annotator characteristics and label text with a transformer-based model to detect hate speech, with unique representations based on each annotator's characteristics via Collaborative Topic Regression (CTR) and integrate label text to enrich textual representations. During training, the model associates annotators with their label choices given a piece of text; during evaluation, when label information is not available, the model predicts the aggregated label given by the participating annotators by utilising the learnt association. The proposed approach displayed an advantage in detecting hate speech, especially in the minority class and edge cases with annotator disagreement. Improvement in the overall performance is the largest when the dataset is more label-imbalanced, suggesting its practical value in identifying real-world hate speech, as the volume of hate speech in-the-wild is extremely small on social media, when compared with normal (non-hate) speech. Through ablation studies, we show the relative contributions of annotator embeddings and label text to the model performance, and tested a range of alternative annotator embeddings and label text combinations. ",
    "url": "https://arxiv.org/abs/2212.10405",
    "authors": [
      "Wenjie Yin",
      "Vibhor Agarwal",
      "Aiqi Jiang",
      "Arkaitz Zubiaga",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.10409",
    "title": "Reinforced Clarification Question Generation with Defeasibility Rewards  for Disambiguating Social and Moral Situations",
    "abstract": "Context is vital for commonsense moral reasoning. \"Lying to a friend\" is wrong if it is meant to deceive them, but may be morally okay if it is intended to protect them. Such nuanced but salient contextual information can potentially flip the moral judgment of an action. Thus, we present ClarifyDelphi, an interactive system that elicits missing contexts of a moral situation by generating clarification questions such as \"Why did you lie to your friend?\". Our approach is inspired by the observation that questions whose potential answers lead to diverging moral judgments are the most informative. We learn to generate questions using Reinforcement Learning, by maximizing the divergence between moral judgements of hypothetical answers to a question. Human evaluation shows that our system generates more relevant, informative and defeasible questions compared to other question generation baselines. ClarifyDelphi assists informed moral reasoning processes by seeking additional morally consequential context to disambiguate social and moral situations. ",
    "url": "https://arxiv.org/abs/2212.10409",
    "authors": [
      "Valentina Pyatkin",
      "Jena D. Hwang",
      "Vivek Srikumar",
      "Ximing Lu",
      "Liwei Jiang",
      "Yejin Choi",
      "Chandra Bhagavatula"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10411",
    "title": "DDIPNet and DDIPNet+: Discriminant Deep Image Prior Networks for Remote  Sensing Image Classification",
    "abstract": "Research on remote sensing image classification significantly impacts essential human routine tasks such as urban planning and agriculture. Nowadays, the rapid advance in technology and the availability of many high-quality remote sensing images create a demand for reliable automation methods. The current paper proposes two novel deep learning-based architectures for image classification purposes, i.e., the Discriminant Deep Image Prior Network and the Discriminant Deep Image Prior Network+, which combine Deep Image Prior and Triplet Networks learning strategies. Experiments conducted over three well-known public remote sensing image datasets achieved state-of-the-art results, evidencing the effectiveness of using deep image priors for remote sensing image classification. ",
    "url": "https://arxiv.org/abs/2212.10411",
    "authors": [
      "Daniel F. S. Santos",
      "Rafael G. Pires",
      "Leandro A. Passos",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10417",
    "title": "Scene Change Detection Using Multiscale Cascade Residual Convolutional  Neural Networks",
    "abstract": "Scene change detection is an image processing problem related to partitioning pixels of a digital image into foreground and background regions. Mostly, visual knowledge-based computer intelligent systems, like traffic monitoring, video surveillance, and anomaly detection, need to use change detection techniques. Amongst the most prominent detection methods, there are the learning-based ones, which besides sharing similar training and testing protocols, differ from each other in terms of their architecture design strategies. Such architecture design directly impacts on the quality of the detection results, and also in the device resources capacity, like memory. In this work, we propose a novel Multiscale Cascade Residual Convolutional Neural Network that integrates multiscale processing strategy through a Residual Processing Module, with a Segmentation Convolutional Neural Network. Experiments conducted on two different datasets support the effectiveness of the proposed approach, achieving average overall $\\boldsymbol{F\\text{-}measure}$ results of $\\boldsymbol{0.9622}$ and $\\boldsymbol{0.9664}$ over Change Detection 2014 and PetrobrasROUTES datasets respectively, besides comprising approximately eight times fewer parameters. Such obtained results place the proposed technique amongst the top four state-of-the-art scene change detection methods. ",
    "url": "https://arxiv.org/abs/2212.10417",
    "authors": [
      "Daniel F. S. Santos",
      "Rafael G. Pires",
      "Danilo Colombo",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10426",
    "title": "Deep Riemannian Networks for EEG Decoding",
    "abstract": "State-of-the-art performance in electroencephalography (EEG) decoding tasks is currently often achieved with either Deep-Learning or Riemannian-Geometry-based decoders. Recently, there is growing interest in Deep Riemannian Networks (DRNs) possibly combining the advantages of both previous classes of methods. However, there are still a range of topics where additional insight is needed to pave the way for a more widespread application of DRNs in EEG. These include architecture design questions such as network size and end-to-end ability as well as model training questions. How these factors affect model performance has not been explored. Additionally, it is not clear how the data within these networks is transformed, and whether this would correlate with traditional EEG decoding. Our study aims to lay the groundwork in the area of these topics through the analysis of DRNs for EEG with a wide range of hyperparameters. Networks were tested on two public EEG datasets and compared with state-of-the-art ConvNets. Here we propose end-to-end EEG SPDNet (EE(G)-SPDNet), and we show that this wide, end-to-end DRN can outperform the ConvNets, and in doing so use physiologically plausible frequency regions. We also show that the end-to-end approach learns more complex filters than traditional band-pass filters targeting the classical alpha, beta, and gamma frequency bands of the EEG, and that performance can benefit from channel specific filtering approaches. Additionally, architectural analysis revealed areas for further improvement due to the possible loss of Riemannian specific information throughout the network. Our study thus shows how to design and train DRNs to infer task-related information from the raw EEG without the need of handcrafted filterbanks and highlights the potential of end-to-end DRNs such as EE(G)-SPDNet for high-performance EEG decoding. ",
    "url": "https://arxiv.org/abs/2212.10426",
    "authors": [
      "Daniel Wilson",
      "Lukas Alexander Wilhelm Gemein",
      "Robin Tibor Schirrmeister",
      "Tonio Ball"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.10438",
    "title": "Is Semantic Communications Secure? A Tale of Multi-Domain Adversarial  Attacks",
    "abstract": "Semantic communications seeks to transfer information from a source while conveying a desired meaning to its destination. We model the transmitter-receiver functionalities as an autoencoder followed by a task classifier that evaluates the meaning of the information conveyed to the receiver. The autoencoder consists of an encoder at the transmitter to jointly model source coding, channel coding, and modulation, and a decoder at the receiver to jointly model demodulation, channel decoding and source decoding. By augmenting the reconstruction loss with a semantic loss, the two deep neural networks (DNNs) of this encoder-decoder pair are interactively trained with the DNN of the semantic task classifier. This approach effectively captures the latent feature space and reliably transfers compressed feature vectors with a small number of channel uses while keeping the semantic loss low. We identify the multi-domain security vulnerabilities of using the DNNs for semantic communications. Based on adversarial machine learning, we introduce test-time (targeted and non-targeted) adversarial attacks on the DNNs by manipulating their inputs at different stages of semantic communications. As a computer vision attack, small perturbations are injected to the images at the input of the transmitter's encoder. As a wireless attack, small perturbations signals are transmitted to interfere with the input of the receiver's decoder. By launching these stealth attacks individually or more effectively in a combined form as a multi-domain attack, we show that it is possible to change the semantics of the transferred information even when the reconstruction loss remains low. These multi-domain adversarial attacks pose as a serious threat to the semantics of information transfer (with larger impact than conventional jamming) and raise the need of defense methods for the safe adoption of semantic communications. ",
    "url": "https://arxiv.org/abs/2212.10438",
    "authors": [
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Sennur Ulukus",
      "Aylin Yener"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.10439",
    "title": "On the Convergence of Policy Gradient in Robust MDPs",
    "abstract": "Robust Markov decision processes (RMDPs) are promising models that provide reliable policies under ambiguities in model parameters. As opposed to nominal Markov decision processes (MDPs), however, the state-of-the-art solution methods for RMDPs are limited to value-based methods, such as value iteration and policy iteration. This paper proposes Double-Loop Robust Policy Gradient (DRPG), the first generic policy gradient method for RMDPs with a global convergence guarantee in tabular problems. Unlike value-based methods, DRPG does not rely on dynamic programming techniques. In particular, the inner-loop robust policy evaluation problem is solved via projected gradient descent. Finally, our experimental results demonstrate the performance of our algorithm and verify our theoretical guarantees. ",
    "url": "https://arxiv.org/abs/2212.10439",
    "authors": [
      "Qiuhao Wang",
      "Chin Pang Ho",
      "Marek Petrik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10440",
    "title": "Perplexed by Quality: A Perplexity-based Method for Adult and Harmful  Content Detection in Multilingual Heterogeneous Web Data",
    "abstract": "As demand for large corpora increases with the size of current state-of-the-art language models, using web data as the main part of the pre-training corpus for these models has become a ubiquitous practice. This, in turn, has introduced an important challenge for NLP practitioners, as they are now confronted with the task of developing highly optimized models and pipelines for pre-processing large quantities of textual data, which implies, effectively classifying and filtering multilingual, heterogeneous and noisy data, at web scale. One of the main components of this pre-processing step for the pre-training corpora of large language models, is the removal of adult and harmful content. In this paper we explore different methods for detecting adult and harmful of content in multilingual heterogeneous web data. We first show how traditional methods in harmful content detection, that seemingly perform quite well in small and specialized datasets quickly break down when confronted with heterogeneous noisy web data. We then resort to using a perplexity based approach but with a twist: Instead of using a so-called \"clean\" corpus to train a small language model and then use perplexity so select the documents with low perplexity, i.e., the documents that resemble this so-called \"clean\" corpus the most. We train solely with adult and harmful textual data, and then select the documents having a perplexity value above a given threshold. This approach will virtually cluster our documents into two distinct groups, which will greatly facilitate the choice of the threshold for the perplexity and will also allow us to obtain higher precision than with the traditional classification methods for detecting adult and harmful content. ",
    "url": "https://arxiv.org/abs/2212.10440",
    "authors": [
      "Tim Jansen",
      "Yangling Tong",
      "Victoria Zevallos",
      "Pedro Ortiz Suarez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10441",
    "title": "First CE Matters: On the Importance of Long Term Properties on Memory  Failure Prediction",
    "abstract": "Dynamic random access memory failures are a threat to the reliability of data centres as they lead to data loss and system crashes. Timely predictions of memory failures allow for taking preventive measures such as server migration and memory replacement. Thereby, memory failure prediction prevents failures from externalizing, and it is a vital task to improve system reliability. In this paper, we revisited the problem of memory failure prediction. We analyzed the correctable errors (CEs) from hardware logs as indicators for a degraded memory state. As memories do not always work with full occupancy, access to faulty memory parts is time distributed. Following this intuition, we observed that important properties for memory failure prediction are distributed through long time intervals. In contrast, related studies, to fit practical constraints, frequently only analyze the CEs from the last fixed-size time interval while ignoring the predating information. Motivated by the observed discrepancy, we study the impact of including the overall (long-range) CE evolution and propose novel features that are calculated incrementally to preserve long-range properties. By coupling the extracted features with machine learning methods, we learn a predictive model to anticipate upcoming failures three hours in advance while improving the average relative precision and recall for 21% and 19% accordingly. We evaluated our methodology on real-world memory failures from the server fleet of a large cloud provider, justifying its validity and practicality. ",
    "url": "https://arxiv.org/abs/2212.10441",
    "authors": [
      "Jasmin Bogatinovski",
      "Qiao Yu",
      "Jorge Cardoso",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2212.10446",
    "title": "Neural Network Learner for Minesweeper",
    "abstract": "Minesweeper is an interesting single player game based on logic, memory and guessing. Solving Minesweeper has been shown to be an NP-hard task. Deterministic solvers are the best known approach for solving Minesweeper. This project proposes a neural network based learner for solving Minesweeper. To choose the best learner, different architectures and configurations of neural networks were trained on hundreds of thousands of games. Surprisingly, the proposed neural network based learner has shown to be a very good approximation function for solving Minesweeper. The neural network learner competes well with the CSP solvers, especially in Beginner and Intermediate modes of the game. It was also observed that despite having high success rates, the best neural learner was considerably slower than the best deterministic solver. This report also discusses the overheads and limitations faced while creating highly successful neural networks for Minesweeper. ",
    "url": "https://arxiv.org/abs/2212.10446",
    "authors": [
      "M Hamza Sajjad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.10454",
    "title": "Wind Power Scenario Generation Using Graph Convolutional Generative  Adversarial Network",
    "abstract": "Generating wind power scenarios is very important for studying the impacts of multiple wind farms that are interconnected to the grid. We develop a graph convolutional generative adversarial network (GCGAN) approach by leveraging GAN's capability in generating large number of realistic scenarios without using statistical modeling. Unlike existing GAN-based wind power data generation approaches, we design GAN's hidden layers to match the underlying spatial and temporal characteristics. We advocate to use graph filters to embed the spatial correlation among multiple wind farms, and a one-dimensional (1D) convolutional layer for representing the temporal feature filters. The proposed graph and feature filter designs significantly reduce the GAN model complexity, leading to improvements on the training efficiency and computation complexity. Numerical results using real wind power data from Australia demonstrate that the scenarios generated by the proposed GCGAN exhibit more realistic spatial and temporal statistics than other GAN-based outputs. ",
    "url": "https://arxiv.org/abs/2212.10454",
    "authors": [
      "Young-ho Cho",
      "Shaohui Liu",
      "Duehee Lee",
      "Hao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.10465",
    "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense  Contextualization",
    "abstract": "We present SODA: the first publicly available, million-scale high-quality social dialogue dataset. Using SODA, we train COSMO: a generalizable conversation agent outperforming previous best-performing agents on both in- and out-of-domain datasets. In contrast to most existing crowdsourced, small-scale dialogue corpora, we distill 1.5M socially-grounded dialogues from a pre-trained language model (InstructGPT; Ouyang et al., 2022). Dialogues are distilled by contextualizing social commonsense knowledge from a knowledge graph (Atomic10x; West et al., 2022). Human evaluation shows that dialogues in SODA are more consistent, specific, and (surprisingly) natural than prior human-authored datasets - e.g., DailyDialog (Li et al., 2017), BlendedSkillTalk (Smith et al., 2020). In addition, extensive evaluations show that COSMO is significantly more natural and consistent on unseen datasets than best-performing dialogue models - e.g., GODEL (Peng et al., 2022), BlenderBot (Roller et al., 2021), DialoGPT (Zhang et al., 2020). Furthermore, it is sometimes even preferred to the original human-written gold responses. We make our data, models, and code public. ",
    "url": "https://arxiv.org/abs/2212.10465",
    "authors": [
      "Hyunwoo Kim",
      "Jack Hessel",
      "Liwei Jiang",
      "Ximing Lu",
      "Youngjae Yu",
      "Pei Zhou",
      "Ronan Le Bras",
      "Malihe Alikhani",
      "Gunhee Kim",
      "Maarten Sap",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10481",
    "title": "Execution-Based Evaluation for Open-Domain Code Generation",
    "abstract": "To extend the scope of coding queries to more realistic settings, we propose ODEX, the first open-domain execution-based natural language (NL) to code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries, along with 1,707 human-written test cases for execution. Our NL-Code pairs are harvested from StackOverflow forums to encourage natural and practical coding queries, which are then carefully rephrased to ensure intent clarity and prevent potential data memorization. Moreover, ODEX supports four natural languages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing behavioral differences between top-performing Code LMs: Codex performs better on open-domain queries, yet CodeGen captures a better balance between open- and closed-domain. ODEX corroborates the merits of execution-based evaluation over metrics without execution but also unveils their complementary effects. Powerful models such as CodeGen-6B only achieve an 11.96 pass rate at top-1 prediction, suggesting plenty of headroom for improvement. We release ODEX to facilitate research into open-domain problems for the code generation community. ",
    "url": "https://arxiv.org/abs/2212.10481",
    "authors": [
      "Zhiruo Wang",
      "Shuyan Zhou",
      "Daniel Fried",
      "Graham Neubig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10513",
    "title": "ECoHeN: A Hypothesis Testing Framework for Extracting Communities from  Heterogeneous Networks",
    "abstract": "Community discovery is the general process of attaining assortative communities from a network: collections of nodes that are densely connected within yet sparsely connected to the rest of the network. While community discovery has been well studied, few such techniques exist for heterogeneous networks, which contain different types of nodes and possibly different connectivity patterns between the node types. In this paper, we introduce a framework called ECoHeN, which \\textbf{e}xtracts \\textbf{co}mmunities from a \\textbf{he}terogeneous \\textbf{n}etwork in a statistically meaningful way. Using a heterogeneous configuration model as a reference distribution, ECoHeN identifies communities that are significantly more densely connected than expected given the node types and connectivity of its membership. Specifically, the ECoHeN algorithm extracts communities one at a time through a dynamic set of iterative updating rules, is guaranteed to converge, and imposes no constraints on the type composition of extracted communities. To our knowledge this is the first discovery method that distinguishes and identifies both homogeneous and heterogeneous, possibly overlapping, community structure in a network. We demonstrate the performance of ECoHeN through simulation and in application to a political blogs network to identify collections of blogs which reference one another more than expected considering the ideology of its' members. ",
    "url": "https://arxiv.org/abs/2212.10513",
    "authors": [
      "Connor P. Gibbs",
      "Bailey K. Fosdick",
      "James D. Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.10515",
    "title": "CausalDialogue: Modeling Utterance-level Causality in Conversations",
    "abstract": "Despite their widespread adoption, neural conversation models have yet to exhibit natural chat capabilities with humans. In this research, we examine user utterances as causes and generated responses as effects, recognizing that changes in a cause should produce a different effect. To further explore this concept, we have compiled and expanded upon a new dataset called CausalDialogue through crowd-sourcing. This dataset includes multiple cause-effect pairs within a directed acyclic graph (DAG) structure. Our analysis reveals that traditional loss functions can struggle to effectively incorporate the DAG structure, leading us to propose a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models. To evaluate the effectiveness of this approach, we have built a comprehensive benchmark using the CausalDialogue dataset leveraging large-scale pre-trained language models, and have assessed the results through both human and automatic evaluation metrics for coherence, diversity, and agility. Our findings show that current techniques are still unable to effectively address conversational DAGs, and that the ExMATE method can improve the diversity and agility of conventional loss functions while maintaining coherence. ",
    "url": "https://arxiv.org/abs/2212.10515",
    "authors": [
      "Yi-Lin Tuan",
      "Alon Albalak",
      "Wenda Xu",
      "Michael Saxon",
      "Connor Pryor",
      "Lise Getoor",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10553",
    "title": "RangeAugment: Efficient Online Augmentation with Range Learning",
    "abstract": "State-of-the-art automatic augmentation methods (e.g., AutoAugment and RandAugment) for visual recognition tasks diversify training data using a large set of augmentation operations. The range of magnitudes of many augmentation operations (e.g., brightness and contrast) is continuous. Therefore, to make search computationally tractable, these methods use fixed and manually-defined magnitude ranges for each operation, which may lead to sub-optimal policies. To answer the open question on the importance of magnitude ranges for each augmentation operation, we introduce RangeAugment that allows us to efficiently learn the range of magnitudes for individual as well as composite augmentation operations. RangeAugment uses an auxiliary loss based on image similarity as a measure to control the range of magnitudes of augmentation operations. As a result, RangeAugment has a single scalar parameter for search, image similarity, which we simply optimize via linear search. RangeAugment integrates seamlessly with any model and learns model- and task-specific augmentation policies. With extensive experiments on the ImageNet dataset across different networks, we show that RangeAugment achieves competitive performance to state-of-the-art automatic augmentation methods with 4-5 times fewer augmentation operations. Experimental results on semantic segmentation, object detection, foundation models, and knowledge distillation further shows RangeAugment's effectiveness. ",
    "url": "https://arxiv.org/abs/2212.10553",
    "authors": [
      "Sachin Mehta",
      "Saeid Naderiparizi",
      "Fartash Faghri",
      "Maxwell Horton",
      "Lailin Chen",
      "Ali Farhadi",
      "Oncel Tuzel",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10558",
    "title": "On-the-fly Denoising for Data Augmentation in Natural Language  Understanding",
    "abstract": "Data Augmentation (DA) is frequently used to automatically provide additional training data without extra human annotation. However, data augmentation may introduce noisy data that impairs training. To guarantee the quality of augmented data, existing methods either assume no noise exists in the augmented data and adopt consistency training or use simple heuristics such as training loss and diversity constraints to filter out ``noisy'' data. However, those filtered examples may still contain useful information, and dropping them completely causes loss of supervision signals. In this paper, based on the assumption that the original dataset is cleaner than the augmented data, we propose an on-the-fly denoising technique for data augmentation that learns from soft augmented labels provided by an organic teacher model trained on the cleaner original data. A simple self-regularization module is applied to force the model prediction to be consistent across two distinct dropouts to further prevent overfitting on noisy labels. Our method can be applied to augmentation techniques in general and can consistently improve the performance on both text classification and question-answering tasks. ",
    "url": "https://arxiv.org/abs/2212.10558",
    "authors": [
      "Tianqing Fang",
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Hongming Zhang",
      "Yangqiu Song",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.13273",
    "title": "Application-Driven Learning: A Closed-Loop Prediction and Optimization  Approach Applied to Dynamic Reserves and Demand Forecasting",
    "abstract": "Forecasting and decision-making are generally modeled as two sequential steps with no feedback, following an open-loop approach. In this paper, we present application-driven learning, a new closed-loop framework in which the processes of forecasting and decision-making are merged and co-optimized through a bilevel optimization problem. We present our methodology in a general format and prove that the solution converges to the best estimator in terms of the expected cost of the selected application. Then, we propose two solution methods: an exact method based on the KKT conditions of the second-level problem and a scalable heuristic approach suitable for decomposition methods. The proposed methodology is applied to the relevant problem of defining dynamic reserve requirements and conditional load forecasts, offering an alternative approach to current \\emph{ad hoc} procedures implemented in industry practices. We benchmark our methodology with the standard sequential least-squares forecast and dispatch planning process. We apply the proposed methodology to an illustrative system and to a wide range of instances, from dozens of buses to large-scale realistic systems with thousands of buses. Our results show that the proposed methodology is scalable and yields consistently better performance than the standard open-loop approach. ",
    "url": "https://arxiv.org/abs/2102.13273",
    "authors": [
      "Joaquim Dias Garcia",
      "Alexandre Street",
      "Tito Homem-de-Mello",
      "Francisco D. Mu\u00f1oz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.09755",
    "title": "Assessing the Cost of Network Simplifications in Long-Term Hydrothermal  Dispatch Planning Models",
    "abstract": "The sustainable utilization of hydro energy relies on accurate estimates of the opportunity cost of the water. This value is calculated through long-term hydrothermal dispatch problems (LTHDP), and the recent literature has raised awareness about the consequences of modeling simplifications in these problems. The inaccurate representation of Kirchhoff's voltage law under the premise of a DC power flow is an example. Under a non-linear AC model, however, the LTHDP becomes intractable, and the literature lacks an accurate evaluation method of different modeling alternatives. In this paper, we extend the state-of-the-art cost-assessment framework of network approximations for LTHDP and bring relevant and practical new insights. First, we increase the quality of the assessment by using an AC power flow to simulate and compare the performance of five policies based on different network approximations. Second, we find that the tightest network relaxation (based on semidefinite programming) is not the one exhibiting the best performance. Results show that the DC {power flow} with quadratic losses approximation exhibits the lowest expected cost and inconsistency gaps. Finally, its computational burden is lower than that exhibited by the semidefinite relaxation, whereas market distortions are significantly reduced in comparison to previously published benchmarks based on DC power flow. ",
    "url": "https://arxiv.org/abs/2107.09755",
    "authors": [
      "Andrew W. Rosemberg",
      "Alexandre Street",
      "Joaquim Dias Garcia",
      "Davi M. Vallad\u00e3o",
      "Thuener Silva",
      "Oscar Dowson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.09749",
    "title": "Statistical Comparison among Brain Networks with Popular Network  Measurement Algorithms",
    "abstract": "In this research, a number of popular network measurement algorithms have been applied to several brain networks (based on applicability of algorithms) for finding out statistical correlation among these popular network measurements which will help scientists to understand these popular network measurement algorithms and their applicability to brain networks. By analysing the results of correlations among these network measurement algorithms, statistical comparison among selected brain networks has also been summarized. Besides that, to understand each brain network, the visualization of each brain network and each brain network degree distribution histogram have been extrapolated. Six network measurement algorithms have been chosen to apply time to time on sixteen brain networks based on applicability of these network measurement algorithms and the results of these network measurements are put into a correlation method to show the relationship among these six network measurement algorithms for each brain network. At the end, the results of the correlations have been summarized to show the statistical comparison among these sixteen brain networks. ",
    "url": "https://arxiv.org/abs/2212.09749",
    "authors": [
      "Rakib Hassan Pran"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2212.09977",
    "title": "Conditioned Generative Transformers for Histopathology Image Synthetic  Augmentation",
    "abstract": "Deep learning networks have demonstrated state-of-the-art performance on medical image analysis tasks. However, the majority of the works rely heavily on abundantly labeled data, which necessitates extensive involvement of domain experts. Vision transformer (ViT) based generative adversarial networks (GANs) recently demonstrated superior potential in general image synthesis, yet are less explored for histopathology images. In this paper, we address these challenges by proposing a pure ViT-based conditional GAN model for histopathology image synthetic augmentation. To alleviate training instability and improve generation robustness, we first introduce a conditioned class projection method to facilitate class separation. We then implement a multi-loss weighing function to dynamically balance the losses between classification tasks. We further propose a selective augmentation mechanism to actively choose the appropriate generated images and bring additional performance improvements. Extensive experiments on the histopathology datasets show that leveraging our synthetic augmentation framework results in significant and consistent improvements in classification performance. ",
    "url": "https://arxiv.org/abs/2212.09977",
    "authors": [
      "Meng Li",
      "Chaoyi Li",
      "Can Peng",
      "Brian Lovell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10086",
    "title": "End to End Generative Meta Curriculum Learning For Medical Data  Augmentation",
    "abstract": "Current medical image synthetic augmentation techniques rely on intensive use of generative adversarial networks (GANs). However, the nature of GAN architecture leads to heavy computational resources to produce synthetic images and the augmentation process requires multiple stages to complete. To address these challenges, we introduce a novel generative meta curriculum learning method that trains the task-specific model (student) end-to-end with only one additional teacher model. The teacher learns to generate curriculum to feed into the student model for data augmentation and guides the student to improve performance in a meta-learning style. In contrast to the generator and discriminator in GAN, which compete with each other, the teacher and student collaborate to improve the student's performance on the target tasks. Extensive experiments on the histopathology datasets show that leveraging our framework results in significant and consistent improvements in classification performance. ",
    "url": "https://arxiv.org/abs/2212.10086",
    "authors": [
      "Meng Li",
      "Brian Lovell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10118",
    "title": "Diffusion equations with spatially dependent coefficients and fractal  Cauer-type networks",
    "abstract": "We give a self-contained proof of the connection existing between diffusion equations with spatially dependent coefficients and fractal Cauer-type networks initiated by J. Sabatier in 2020 and discussed in more details in [J. Sabatier and al., Fractional behaviours modelling, Springer, 2022]. ",
    "url": "https://arxiv.org/abs/2212.10118",
    "authors": [
      "Jacky Cresson",
      "Anna Szafranska"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.10254",
    "title": "A Local Optima Network View of Real Function Fitness Landscapes",
    "abstract": "The local optima network model has proved useful in the past in connection with combinatorial optimization problems. Here we examine its extension to the real continuous function domain. Through a sampling process, the model builds a weighted directed graph which captures the function's minima basin structure and its interconnection and which can be easily manipulated with the help of complex networks metrics. We show that the model provides a complementary view of function spaces that is easier to analyze and visualize, especially at higher dimension. In particular, we show that function hardness as represented by algorithm performance, is strongly related to several graph properties of the corresponding local optima network, opening the way for a classification of problem difficulty according to the corresponding graph structure and with possible extensions in the design of better metaheuristic approaches. ",
    "url": "https://arxiv.org/abs/2212.10254",
    "authors": [
      "Marco Tomassini"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.10444",
    "title": "Deep Multi-Emitter Spectrum Occupancy Mapping that is Robust to the  Number of Sensors, Noise and Threshold",
    "abstract": "One of the primary goals in spectrum occupancy mapping is to create a system that is robust to assumptions about the number of sensors, occupancy threshold (in dBm), sensor noise, number of emitters and the propagation environment. We show that such a system may be designed with neural networks using a process of aggregation to allow a variable number of sensors during training and testing. This process transforms the variable number of measurements into log-likelihood ratios (LLRs), which are fed as a fixed-resolution image into a neural network. The use of LLRs provides robustness to the effects of noise and occupancy threshold. In other words, a system may be trained for a nominal number of sensors, threshold and noise levels, and still operate well at various other levels without retraining. Our system operates without knowledge of the number of emitters and does not explicitly attempt to estimate their number or power. Receiver operating curves with realistic propagation environments using topographic maps with commercial network design tools show how performance of the neural network varies with the environment. The use of low-resolution sensors in this system does not significantly hurt performance. ",
    "url": "https://arxiv.org/abs/2212.10444",
    "authors": [
      "Abbas Termos",
      "Bertrand Hochwald"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.13227",
    "title": "Quantum causal inference in the presence of hidden common causes: An  entropic approach",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2102.11764 ",
    "url": "https://arxiv.org/abs/2104.13227",
    "authors": [
      "Mohammad Ali Javidian",
      "Vaneet Aggarwal",
      "Zubin Jacob"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.13754",
    "title": "Can crowdsourcing rescue the social marketplace of ideas?",
    "abstract": " Comments: In Press in Communications of the ACM (CACM) ",
    "url": "https://arxiv.org/abs/2104.13754",
    "authors": [
      "Taha Yasseri",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2106.14888",
    "title": "Social influence under uncertainty in interaction with peers, robots and  computers",
    "abstract": " Comments: Paper accepted for publication in International Journal of Social Robotics. Previous version: \"Trust is not all about performance: trust biases in interaction with humans, robots and computers\". arXiv admin note: text overlap with arXiv:2106.14832 ",
    "url": "https://arxiv.org/abs/2106.14888",
    "authors": [
      "Joshua Zonca",
      "Anna Folso",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2108.08976",
    "title": "ASAT: Adaptively Scaled Adversarial Training in Time Series",
    "abstract": " Comments: Accepted to Neurocomputing ",
    "url": "https://arxiv.org/abs/2108.08976",
    "authors": [
      "Zhiyuan Zhang",
      "Wei Li",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Yunfang Wu",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.00542",
    "title": "Shared Certificates for Neural Network Verification",
    "abstract": " Comments: Extended version of our CAV'22 paper ",
    "url": "https://arxiv.org/abs/2109.00542",
    "authors": [
      "Marc Fischer",
      "Christian Sprecher",
      "Dimitar I. Dimitrov",
      "Gagandeep Singh",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2109.06837",
    "title": "Simultaneous Object Reconstruction and Grasp Prediction using a  Camera-centric Object Shell Representation",
    "abstract": " Comments: 18 pages, 12 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2109.06837",
    "authors": [
      "Nikhil Chavan-Dafle",
      "Sergiy Popovych",
      "Shubham Agrawal",
      "Daniel D. Lee",
      "Volkan Isler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2109.09426",
    "title": "A Meta-Learning Approach for Training Explainable Graph Neural Networks",
    "abstract": " Title: A Meta-Learning Approach for Training Explainable Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2109.09426",
    "authors": [
      "Indro Spinelli",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.03894",
    "title": "Neural Model Reprogramming with Similarity Based Mapping for  Low-Resource Spoken Command Classification",
    "abstract": " Comments: Submitted to ICASSP 2023. The draft has been updated on its new reprogramming findings with data augmentation results (8.7% to 10.9% relatively improvements) ",
    "url": "https://arxiv.org/abs/2110.03894",
    "authors": [
      "Hao Yen",
      "Pin-Jui Ku",
      "Chao-Han Huck Yang",
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Pin-Yu Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2110.08493",
    "title": "Improvised Aerial Object Detection approach for YOLOv3 Using Weighted  Luminance",
    "abstract": " Comments: 17 pages, 4 figures, Journal Expert Systems with Applications ",
    "url": "https://arxiv.org/abs/2110.08493",
    "authors": [
      "Sai Ganesh CS",
      "Aouthithiye Barathwaj SR Y",
      "R. Swethaa S",
      "R. Azhagumurugan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.09542",
    "title": "A Formal Model for Polarization under Confirmation Bias in Social  Networks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2104.11538, arXiv:2012.02703 ",
    "url": "https://arxiv.org/abs/2112.09542",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Bernardo Amorim",
      "Sophia Knight",
      "Santiago Quintero",
      "Frank Valencia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.11088",
    "title": "EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object  Detection",
    "abstract": " Comments: Accepted by TPAMI-2022 ",
    "url": "https://arxiv.org/abs/2112.11088",
    "authors": [
      "Zhe Liu",
      "Tengteng Huang",
      "Bingling Li",
      "Xiwu Chen",
      "Xi Wang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01322",
    "title": "Opinion dynamics in social networks: From models to data",
    "abstract": " Comments: 22 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2201.01322",
    "authors": [
      "Antonio F. Peralta",
      "J\u00e1nos Kert\u00e9sz",
      "Gerardo I\u00f1iguez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2202.06539",
    "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models",
    "abstract": " Comments: ICML 2022 Camera Ready Version ",
    "url": "https://arxiv.org/abs/2202.06539",
    "authors": [
      "Nikhil Kandpal",
      "Eric Wallace",
      "Colin Raffel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.07615",
    "title": "P4E: Few-Shot Event Detection as Prompt-Guided Identification and  Localization",
    "abstract": " Comments: 13 pages, fixed typos and additional experiments ",
    "url": "https://arxiv.org/abs/2202.07615",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2202.09006",
    "title": "KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling",
    "abstract": " Title: KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling ",
    "url": "https://arxiv.org/abs/2202.09006",
    "authors": [
      "Alireza Rezazadeh",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.10201",
    "title": "OG-SGG: Ontology-Guided Scene Graph Generation. A Case Study in Transfer  Learning for Telepresence Robotics",
    "abstract": " Comments: 20 pages; version accepted and published in IEEE Access ",
    "url": "https://arxiv.org/abs/2202.10201",
    "authors": [
      "Fernando Amodeo",
      "Fernando Caballero",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Luis Merino"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.11762",
    "title": "Safe Control with Learned Certificates: A Survey of Neural Lyapunov,  Barrier, and Contraction methods",
    "abstract": " Comments: Accepted at IEEE Transactions on Robotics. Supplementary code available at this https URL ",
    "url": "https://arxiv.org/abs/2202.11762",
    "authors": [
      "Charles Dawson",
      "Sicun Gao",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.12416",
    "title": "Microgrid Optimal Energy Scheduling Considering Neural Network based  Battery Degradation",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2202.12416",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10533",
    "title": "Strategic Analysis of Griefing Attack in Lightning Network",
    "abstract": " Comments: 17 pages, Accepted in IEEE Transactions on Network and Service Management (Special Issue Advances on Blockchain) ",
    "url": "https://arxiv.org/abs/2203.10533",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Abhinandan Sinha",
      "Sushmita Ruj",
      "Bimal Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2204.00356",
    "title": "Algebraic connectivity of layered path graphs under node deletion",
    "abstract": " Title: Algebraic connectivity of layered path graphs under node deletion ",
    "url": "https://arxiv.org/abs/2204.00356",
    "authors": [
      "Ryusei Yoshise",
      "Kaoru Yamamoto"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.01875",
    "title": "Machine Learning based Framework for Robust Price-Sensitivity Estimation  with Application to Airline Pricing",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2205.01875",
    "authors": [
      "Ravi Kumar",
      "Shahin Boluki",
      "Karl Isler",
      "Jonas Rauch",
      "Darius Walczak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.00515",
    "title": "Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection",
    "abstract": " Title: Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection ",
    "url": "https://arxiv.org/abs/2206.00515",
    "authors": [
      "Omid Ghorbanzadeh",
      "Yonghao Xu",
      "Pedram Ghamisi",
      "Michael Kopp",
      "David Kreil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.01995",
    "title": "Combinatorial Causal Bandits",
    "abstract": " Comments: 30 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.01995",
    "authors": [
      "Shi Feng",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.04360",
    "title": "A general approximation lower bound in $L^p$ norm, with applications to  feed-forward neural networks",
    "abstract": " Title: A general approximation lower bound in $L^p$ norm, with applications to  feed-forward neural networks ",
    "url": "https://arxiv.org/abs/2206.04360",
    "authors": [
      "El Mehdi Achour",
      "Armand Foucault",
      "S\u00e9bastien Gerchinovitz",
      "Fran\u00e7ois Malgouyres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08368",
    "title": "Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model",
    "abstract": " Comments: 26 pages, 17 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2206.08368",
    "authors": [
      "Erik C.M. Johnson",
      "Marc Habermann",
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.09592",
    "title": "DALL-E for Detection: Language-driven Compositional Image Synthesis for  Object Detection",
    "abstract": " Comments: v2 version, update structure (add foreground generation, stable diffusion), add more experiments ",
    "url": "https://arxiv.org/abs/2206.09592",
    "authors": [
      "Yunhao Ge",
      "Jiashu Xu",
      "Brian Nlong Zhao",
      "Neel Joshi",
      "Laurent Itti",
      "Vibhav Vineet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14268",
    "title": "BertNet: Harvesting Knowledge Graphs from Pretrained Language Models",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2206.14268",
    "authors": [
      "Shibo Hao",
      "Bowen Tan",
      "Kaiwen Tang",
      "Bin Ni",
      "Hengzhe Zhang",
      "Eric P Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.06240",
    "title": "Physics Informed Symbolic Networks",
    "abstract": " Comments: Neural Information Processing Systems 2022: The Symbiosis of Deep Learning and Differential Equations Workshop ",
    "url": "https://arxiv.org/abs/2207.06240",
    "authors": [
      "Ritam Majumdar",
      "Vishal Jadhav",
      "Anirudh Deodhar",
      "Shirish Karande",
      "Lovekesh Vig",
      "Venkataramana Runkana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2208.06049",
    "title": "MILAN: Masked Image Pretraining on Language Assisted Representation",
    "abstract": " Comments: add new experiments and improved results. provide repo link ",
    "url": "https://arxiv.org/abs/2208.06049",
    "authors": [
      "Zejiang Hou",
      "Fei Sun",
      "Yen-Kuang Chen",
      "Yuan Xie",
      "Sun-Yuan Kung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12672",
    "title": "Flexible Vertical Federated Learning with Heterogeneous Parties",
    "abstract": " Title: Flexible Vertical Federated Learning with Heterogeneous Parties ",
    "url": "https://arxiv.org/abs/2208.12672",
    "authors": [
      "Timothy Castiglia",
      "Shiqiang Wang",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2208.14878",
    "title": "Formalising the Robustness of Counterfactual Explanations for Neural  Networks",
    "abstract": " Comments: Accepted at AAAI 2023, camera-ready version ",
    "url": "https://arxiv.org/abs/2208.14878",
    "authors": [
      "Junqi Jiang",
      "Francesco Leofante",
      "Antonio Rago",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.02535",
    "title": "Analyzing Transformers in Embedding Space",
    "abstract": " Title: Analyzing Transformers in Embedding Space ",
    "url": "https://arxiv.org/abs/2209.02535",
    "authors": [
      "Guy Dar",
      "Mor Geva",
      "Ankit Gupta",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.03741",
    "title": "AskewSGD : An Annealed interval-constrained Optimisation method to train  Quantized Neural Networks",
    "abstract": " Title: AskewSGD : An Annealed interval-constrained Optimisation method to train  Quantized Neural Networks ",
    "url": "https://arxiv.org/abs/2211.03741",
    "authors": [
      "Louis Leconte",
      "Sholom Schechtman",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11201",
    "title": "Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance",
    "abstract": " Title: Self-Supervised 3D Traversability Estimation with Proxy Bank Guidance ",
    "url": "https://arxiv.org/abs/2211.11201",
    "authors": [
      "Jihwan Bae",
      "Junwon Seo",
      "Taekyung Kim",
      "Hae-gon Jeon",
      "Kiho Kwak",
      "Inwook Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13762",
    "title": "ScanNeRF: a Scalable Benchmark for Neural Radiance Fields",
    "abstract": " Comments: WACV 2023. The first three authors contributed equally. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2211.13762",
    "authors": [
      "Luca De Luigi",
      "Damiano Bolognini",
      "Federico Domeniconi",
      "Daniele De Gregorio",
      "Matteo Poggi",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05330",
    "title": "Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud  Sequence Representation Learning",
    "abstract": " Title: Complete-to-Partial 4D Distillation for Self-Supervised Point Cloud  Sequence Representation Learning ",
    "url": "https://arxiv.org/abs/2212.05330",
    "authors": [
      "Zhuoyang Zhang",
      "Yuhao Dong",
      "Yunze Liu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08323",
    "title": "An ensemble neural network approach to forecast Dengue outbreak based on  climatic condition",
    "abstract": " Title: An ensemble neural network approach to forecast Dengue outbreak based on  climatic condition ",
    "url": "https://arxiv.org/abs/2212.08323",
    "authors": [
      "Madhurima Panja",
      "Tanujit Chakraborty",
      "Sk Shahid Nadim",
      "Indrajit Ghosh",
      "Uttam Kumar",
      "Nan Liu"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09000",
    "title": "Confidence-aware Training of Smoothed Classifiers for Certified  Robustness",
    "abstract": " Comments: 21 pages; AAAI 2023; Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2212.09000",
    "authors": [
      "Jongheon Jeong",
      "Seojin Kim",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09271",
    "title": "Very Large Language Model as a Unified Methodology of Text Mining",
    "abstract": " Comments: 4 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2212.09271",
    "authors": [
      "Meng Jiang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]