[
  {
    "id": "arXiv:2211.16550",
    "title": "Soft Alignment Objectives for Robust Adaptation in Machine Translation",
    "abstract": "Domain adaptation allows generative language models to address specific flaws caused by the domain shift of their application. However, the traditional adaptation by further training on in-domain data rapidly weakens the model's ability to generalize to other domains, making the open-ended deployments of the adapted models prone to errors. This work introduces novel training objectives built upon a semantic similarity of the predicted tokens to the reference. Our results show that (1) avoiding the common assumption of a single correct prediction by constructing the training target from tokens' semantic similarity can mitigate catastrophic forgetting during domain adaptation, while (2) preserving the quality of the adaptation, (3) with negligible additions to compute costs. In the broader perspective, the objectives grounded in a soft token alignment pioneer the exploration of the middle ground between the efficient but naive exact-match token-level objectives and expressive but computationally- and resource-intensive sequential objectives. ",
    "url": "https://arxiv.org/abs/2211.16550",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Marek Kadl\u010d\u00edk",
      "Petr Sojka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.16578",
    "title": "ButterflyNet2D: Bridging Classical Methods and Neural Network Methods in  Image Processing",
    "abstract": "Both classical Fourier transform-based methods and neural network methods are widely used in image processing tasks. The former has better interpretability, whereas the latter often achieves better performance in practice. This paper introduces ButterflyNet2D, a regular CNN with sparse cross-channel connections. A Fourier initialization strategy for ButterflyNet2D is proposed to approximate Fourier transforms. Numerical experiments validate the accuracy of ButterflyNet2D approximating both the Fourier and the inverse Fourier transforms. Moreover, through four image processing tasks and image datasets, we show that training ButterflyNet2D from Fourier initialization does achieve better performance than random initialized neural networks. ",
    "url": "https://arxiv.org/abs/2211.16578",
    "authors": [
      "Gengzhi Yang",
      "Yingzhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.16590",
    "title": "Artificial prediction markets present a novel opportunity for human-AI  collaboration",
    "abstract": "Despite high-profile successes in the field of Artificial Intelligence, machine-driven technologies still suffer important limitations, particularly for complex tasks where creativity, planning, common sense, intuition, or learning from limited data is required. These limitations motivate effective methods for human-machine collaboration. Our work makes two primary contributions. We thoroughly experiment with an artificial prediction market model to understand the effects of market parameters on model performance for benchmark classification tasks. We then demonstrate, through simulation, the impact of exogenous agents in the market, where these exogenous agents represent primitive human behaviors. This work lays the foundation for a novel set of hybrid human-AI machine learning algorithms. ",
    "url": "https://arxiv.org/abs/2211.16590",
    "authors": [
      "Tatiana Chakravorti",
      "Vaibhav Singh",
      "Sarah Rajmajer",
      "Michael McLaughlin",
      "Robert Fraleigh",
      "Christopher Griffin",
      "Anthony Kwasnica",
      "David Pennock",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.16592",
    "title": "Sequence learning in a spiking neuronal network with memristive synapses",
    "abstract": "Brain-inspired computing proposes a set of algorithmic principles that hold promise for advancing artificial intelligence. They endow systems with self learning capabilities, efficient energy usage, and high storage capacity. A core concept that lies at the heart of brain computation is sequence learning and prediction. This form of computation is essential for almost all our daily tasks such as movement generation, perception, and language. Understanding how the brain performs such a computation is not only important to advance neuroscience but also to pave the way to new technological brain-inspired applications. A previously developed spiking neural network implementation of sequence prediction and recall learns complex, high-order sequences in an unsupervised manner by local, biologically inspired plasticity rules. An emerging type of hardware that holds promise for efficiently running this type of algorithm is neuromorphic hardware. It emulates the way the brain processes information and maps neurons and synapses directly into a physical substrate. Memristive devices have been identified as potential synaptic elements in neuromorphic hardware. In particular, redox-induced resistive random access memories (ReRAM) devices stand out at many aspects. They permit scalability, are energy efficient and fast, and can implement biological plasticity rules. In this work, we study the feasibility of using ReRAM devices as a replacement of the biological synapses in the sequence learning model. We implement and simulate the model including the ReRAM plasticity using the neural simulator NEST. We investigate the effect of different device properties on the performance characteristics of the sequence learning model, and demonstrate resilience with respect to different on-off ratios, conductance resolutions, device variability, and synaptic failure. ",
    "url": "https://arxiv.org/abs/2211.16592",
    "authors": [
      "Younes Bouhadjar",
      "Sebastian Siegel",
      "Tom Tetzlaff",
      "Markus Diesmann",
      "Rainer Waser",
      "Dirk J. Wouters"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2211.16630",
    "title": "DINER: Depth-aware Image-based NEural Radiance fields",
    "abstract": "We present Depth-aware Image-based NEural Radiance fields (DINER). Given a sparse set of RGB input views, we predict depth and feature maps to guide the reconstruction of a volumetric scene representation that allows us to render 3D objects under novel views. Specifically, we propose novel techniques to incorporate depth information into feature fusion and efficient scene sampling. In comparison to the previous state of the art, DINER achieves higher synthesis quality and can process input views with greater disparity. This allows us to capture scenes more completely without changing capturing hardware requirements and ultimately enables larger viewpoint changes during novel view synthesis. We evaluate our method by synthesizing novel views, both for human heads and for general objects, and observe significantly improved qualitative results and increased perceptual metrics compared to the previous state of the art. The code will be made publicly available for research purposes. ",
    "url": "https://arxiv.org/abs/2211.16630",
    "authors": [
      "Malte Prinzler",
      "Otmar Hilliges",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16631",
    "title": "Every Node Counts: Improving the Training of Graph Neural Networks on  Node Classification",
    "abstract": "Graph Neural Networks (GNNs) are prominent in handling sparse and unstructured data efficiently and effectively. Specifically, GNNs were shown to be highly effective for node classification tasks, where labelled information is available for only a fraction of the nodes. Typically, the optimization process, through the objective function, considers only labelled nodes while ignoring the rest. In this paper, we propose novel objective terms for the training of GNNs for node classification, aiming to exploit all the available data and improve accuracy. Our first term seeks to maximize the mutual information between node and label features, considering both labelled and unlabelled nodes in the optimization process. Our second term promotes anisotropic smoothness in the prediction maps. Lastly, we propose a cross-validating gradients approach to enhance the learning from labelled data. Our proposed objectives are general and can be applied to various GNNs and require no architectural modifications. Extensive experiments demonstrate our approach using popular GNNs like GCN, GAT and GCNII, reading a consistent and significant accuracy improvement on 10 real-world node classification datasets. ",
    "url": "https://arxiv.org/abs/2211.16631",
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.16632",
    "title": "Hierarchical Transformer for Survival Prediction Using Multimodality  Whole Slide Images and Genomics",
    "abstract": "Learning good representation of giga-pixel level whole slide pathology images (WSI) for downstream tasks is critical. Previous studies employ multiple instance learning (MIL) to represent WSIs as bags of sampled patches because, for most occasions, only slide-level labels are available, and only a tiny region of the WSI is disease-positive area. However, WSI representation learning still remains an open problem due to: (1) patch sampling on a higher resolution may be incapable of depicting microenvironment information such as the relative position between the tumor cells and surrounding tissues, while patches at lower resolution lose the fine-grained detail; (2) extracting patches from giant WSI results in large bag size, which tremendously increases the computational cost. To solve the problems, this paper proposes a hierarchical-based multimodal transformer framework that learns a hierarchical mapping between pathology images and corresponding genes. Precisely, we randomly extract instant-level patch features from WSIs with different magnification. Then a co-attention mapping between imaging and genomics is learned to uncover the pairwise interaction and reduce the space complexity of imaging features. Such early fusion makes it computationally feasible to use MIL Transformer for the survival prediction task. Our architecture requires fewer GPU resources compared with benchmark methods while maintaining better WSI representation ability. We evaluate our approach on five cancer types from the Cancer Genome Atlas database and achieved an average c-index of $0.673$, outperforming the state-of-the-art multimodality methods. ",
    "url": "https://arxiv.org/abs/2211.16632",
    "authors": [
      "Chunyuan Li",
      "Xinliang Zhu",
      "Jiawen Yao",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16636",
    "title": "Iterative Scene Graph Generation with Generative Transformers",
    "abstract": "Scene graphs provide a rich, structured representation of a scene by encoding the entities (objects) and their spatial relationships in a graphical format. This representation has proven useful in several tasks, such as question answering, captioning, and even object detection, to name a few. Current approaches take a generation-by-classification approach where the scene graph is generated through labeling of all possible edges between objects in a scene, which adds computational overhead to the approach. This work introduces a generative transformer-based approach to generating scene graphs beyond link prediction. Using two transformer-based components, we first sample a possible scene graph structure from detected objects and their visual features. We then perform predicate classification on the sampled edges to generate the final scene graph. This approach allows us to efficiently generate scene graphs from images with minimal inference overhead. Extensive experiments on the Visual Genome dataset demonstrate the efficiency of the proposed approach. Without bells and whistles, we obtain, on average, 20.7% mean recall (mR@100) across different settings for scene graph generation (SGG), outperforming state-of-the-art SGG approaches while offering competitive performance to unbiased SGG approaches. ",
    "url": "https://arxiv.org/abs/2211.16636",
    "authors": [
      "Sanjoy Kundu",
      "Sathyanarayanan N. Aakur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16653",
    "title": "CRU: A Novel Neural Architecture for Improving the Predictive  Performance of Time-Series Data",
    "abstract": "The time-series forecasting (TSF) problem is a traditional problem in the field of artificial intelligence. Models such as Recurrent Neural Network (RNN), Long Short Term Memory (LSTM), and GRU (Gate Recurrent Units) have contributed to improving the predictive accuracy of TSF. Furthermore, model structures have been proposed to combine time-series decomposition methods, such as seasonal-trend decomposition using Loess (STL) to ensure improved predictive accuracy. However, because this approach is learned in an independent model for each component, it cannot learn the relationships between time-series components. In this study, we propose a new neural architecture called a correlation recurrent unit (CRU) that can perform time series decomposition within a neural cell and learn correlations (autocorrelation and correlation) between each decomposition component. The proposed neural architecture was evaluated through comparative experiments with previous studies using five univariate time-series datasets and four multivariate time-series data. The results showed that long- and short-term predictive performance was improved by more than 10%. The experimental results show that the proposed CRU is an excellent method for TSF problems compared to other neural architectures. ",
    "url": "https://arxiv.org/abs/2211.16653",
    "authors": [
      "Sunghyun Sim",
      "Dohee Kim",
      "Hyerim Bae"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.16676",
    "title": "Robust Learning of Nonlinear Dynamical Systems with Safety and Stability  Properties",
    "abstract": "The paper presents a robust parameter learning methodology for identification of nonlinear dynamical system from data while satisfying safety and stability constraints in the context of learning from demonstration (LfD) methods. Extreme Learning Machines (ELM) is used to approximate the system model, whose parameters are learned subject to the safety and stability constraints obtained using zeroing barrier and Lyapunov-based stability analysis in the presence of model uncertainties and external disturbances. A constrained Quadratic Program (QP) is developed, which accounts for the ELM function reconstruction error, to estimate the ELM parameters. Furthermore, a robustness lemma is presented, which proves that the learned system model guarantees safety and stability in the presence of disturbances. The method is tested in simulations. Trajectory reconstruction accuracy of the method is compared against state-of-the-art LfD methods using swept error area (SEA) metric. Robustness of the learned model is tested by conducting Monte Carlo tests. The proposed method is implemented on a Baxter robot for a pick-and-place task where the robot is constrained to an ellipsoidal safety region. ",
    "url": "https://arxiv.org/abs/2211.16676",
    "authors": [
      "Iman Salehi",
      "Ghananeel Rotithor",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.16677",
    "title": "3D Neural Field Generation using Triplane Diffusion",
    "abstract": "Diffusion models have emerged as the state-of-the-art for image generation, among other tasks. Here, we present an efficient diffusion-based model for 3D-aware generation of neural fields. Our approach pre-processes training data, such as ShapeNet meshes, by converting them to continuous occupancy fields and factoring them into a set of axis-aligned triplane feature representations. Thus, our 3D training scenes are all represented by 2D feature planes, and we can directly train existing 2D diffusion models on these representations to generate 3D neural fields with high quality and diversity, outperforming alternative approaches to 3D-aware generation. Our approach requires essential modifications to existing triplane factorization pipelines to make the resulting features easy to learn for the diffusion model. We demonstrate state-of-the-art results on 3D generation on several object classes from ShapeNet. ",
    "url": "https://arxiv.org/abs/2211.16677",
    "authors": [
      "J. Ryan Shue",
      "Eric Ryan Chan",
      "Ryan Po",
      "Zachary Ankner",
      "Jiajun Wu",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.16689",
    "title": "A Node-collaboration-informed Graph Convolutional Network for Precise  Representation to Undirected Weighted Graphs",
    "abstract": "An undirected weighted graph (UWG) is frequently adopted to describe the interactions among a solo set of nodes from real applications, such as the user contact frequency from a social network services system. A graph convolutional network (GCN) is widely adopted to perform representation learning to a UWG for subsequent pattern analysis tasks such as clustering or missing data estimation. However, existing GCNs mostly neglects the latent collaborative information hidden in its connected node pairs. To address this issue, this study proposes to model the node collaborations via a symmetric latent factor analysis model, and then regards it as a node-collaboration module for supplementing the collaboration loss in a GCN. Based on this idea, a Node-collaboration-informed Graph Convolutional Network (NGCN) is proposed with three-fold ideas: a) Learning latent collaborative information from the interaction of node pairs via a node-collaboration module; b) Building the residual connection and weighted representation propagation to obtain high representation capacity; and c) Implementing the model optimization in an end-to-end fashion to achieve precise representation to the target UWG. Empirical studies on UWGs emerging from real applications demonstrate that owing to its efficient incorporation of node-collaborations, the proposed NGCN significantly outperforms state-of-the-art GCNs in addressing the task of missing weight estimation. Meanwhile, its good scalability ensures its compatibility with more advanced GCN extensions, which will be further investigated in our future studies. ",
    "url": "https://arxiv.org/abs/2211.16689",
    "authors": [
      "Ying Wang",
      "Ye Yuan",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.16693",
    "title": "Visual-tactile Fusion for Transparent Object Grasping in Complex  Backgrounds",
    "abstract": "The accurate detection and grasping of transparent objects are challenging but of significance to robots. Here, a visual-tactile fusion framework for transparent object grasping under complex backgrounds and variant light conditions is proposed, including the grasping position detection, tactile calibration, and visual-tactile fusion based classification. First, a multi-scene synthetic grasping dataset generation method with a Gaussian distribution based data annotation is proposed. Besides, a novel grasping network named TGCNN is proposed for grasping position detection, showing good results in both synthetic and real scenes. In tactile calibration, inspired by human grasping, a fully convolutional network based tactile feature extraction method and a central location based adaptive grasping strategy are designed, improving the success rate by 36.7% compared to direct grasping. Furthermore, a visual-tactile fusion method is proposed for transparent objects classification, which improves the classification accuracy by 34%. The proposed framework synergizes the advantages of vision and touch, and greatly improves the grasping efficiency of transparent objects. ",
    "url": "https://arxiv.org/abs/2211.16693",
    "authors": [
      "Shoujie Li",
      "Haixin Yu",
      "Wenbo Ding",
      "Houde Liu",
      "Linqi Ye",
      "Chongkun Xia",
      "Xueqian Wang",
      "Xiao-Ping Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16697",
    "title": "SGDraw: Scene Graph Drawing Interface Using Object-Oriented  Representation",
    "abstract": "Scene understanding is an essential and challenging task in computer vision. To provide the visually fundamental graphical structure of an image, the scene graph has received increased attention due to its powerful semantic representation. However, it is difficult to draw a proper scene graph for image retrieval, image generation, and multi-modal applications. The conventional scene graph annotation interface is not easy to use in image annotations, and the automatic scene graph generation approaches using deep neural networks are prone to generate redundant content while disregarding details. In this work, we propose SGDraw, a scene graph drawing interface using object-oriented scene graph representation to help users draw and edit scene graphs interactively. For the proposed object-oriented representation, we consider the objects, attributes, and relationships of objects as a structural unit. SGDraw provides a web-based scene graph annotation and generation tool for scene understanding applications. To verify the effectiveness of the proposed interface, we conducted a comparison study with the conventional tool and the user experience study. The results show that SGDraw can help generate scene graphs with richer details and describe the images more accurately than traditional bounding box annotations. We believe the proposed SGDraw can be useful in various vision tasks, such as image retrieval and generation. ",
    "url": "https://arxiv.org/abs/2211.16697",
    "authors": [
      "Tianyu Zhang",
      "Xusheng Du",
      "Chia-Ming Chang",
      "Xi Yang",
      "Haoran Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2211.16712",
    "title": "Coordinating Cross-modal Distillation for Molecular Property Prediction",
    "abstract": "In recent years, molecular graph representation learning (GRL) has drawn much more attention in molecular property prediction (MPP) problems. The existing graph methods have demonstrated that 3D geometric information is significant for better performance in MPP. However, accurate 3D structures are often costly and time-consuming to obtain, limiting the large-scale application of GRL. It is an intuitive solution to train with 3D to 2D knowledge distillation and predict with only 2D inputs. But some challenging problems remain open for 3D to 2D distillation. One is that the 3D view is quite distinct from the 2D view, and the other is that the gradient magnitudes of atoms in distillation are discrepant and unstable due to the variable molecular size. To address these challenging problems, we exclusively propose a distillation framework that contains global molecular distillation and local atom distillation. We also provide a theoretical insight to justify how to coordinate atom and molecular information, which tackles the drawback of variable molecular size for atom information distillation. Experimental results on two popular molecular datasets demonstrate that our proposed model achieves superior performance over other methods. Specifically, on the largest MPP dataset PCQM4Mv2 served as an \"ImageNet Large Scale Visual Recognition Challenge\" in the field of graph ML, the proposed method achieved a 6.9% improvement compared with the best works. And we obtained fourth place with the MAE of 0.0734 on the test-challenge set for OGB-LSC 2022 Graph Regression Task. We will release the code soon. ",
    "url": "https://arxiv.org/abs/2211.16712",
    "authors": [
      "Hao Zhang",
      "Nan Zhang",
      "Ruixin Zhang",
      "Lei Shen",
      "Yingyi Zhang",
      "Meng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.16721",
    "title": "Dynamically Finding Optimal Observer States to Minimize Localization  Error with Complex State-Dependent Noise",
    "abstract": "We present DyFOS, an active perception method that Dynamically Finds Optimal States to minimize localization error while avoiding obstacles and occlusions. We consider the scenario where a ground target without any exteroceptive sensors must rely on an aerial observer for pose and uncertainty estimates to localize itself along an obstacle-filled path. The observer uses a downward-facing camera to estimate the target's pose and uncertainty. However, the pose uncertainty is a function of the states of the observer, target, and surrounding environment. To find an optimal state that minimizes the target's localization uncertainty, DyFOS uses a localization error prediction pipeline in an optimization search. Given the states mentioned above, the pipeline predicts the target's localization uncertainty with the help of a trained, complex state-dependent sensor measurement model (which is a probabilistic neural network in our case). Our pipeline also predicts target occlusion and obstacle collision to remove undesirable observer states. The output of the optimization search is an optimal observer state that minimizes target localization uncertainty while avoiding occlusion and collision. We evaluate the proposed method using numerical and simulated (Gazebo) experiments. Our results show that DyFOS is almost 100x faster than yet as good as brute force. Furthermore, DyFOS yielded lower localization errors than random and heuristic searches. ",
    "url": "https://arxiv.org/abs/2211.16721",
    "authors": [
      "Troi Williams",
      "Po-Lun Chen",
      "Sparsh Bhogavilli",
      "Vaibhav Sanjay",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16726",
    "title": "Boosted Dynamic Neural Networks",
    "abstract": "Early-exiting dynamic neural networks (EDNN), as one type of dynamic neural networks, has been widely studied recently. A typical EDNN has multiple prediction heads at different layers of the network backbone. During inference, the model will exit at either the last prediction head or an intermediate prediction head where the prediction confidence is higher than a predefined threshold. To optimize the model, these prediction heads together with the network backbone are trained on every batch of training data. This brings a train-test mismatch problem that all the prediction heads are optimized on all types of data in training phase while the deeper heads will only see difficult inputs in testing phase. Treating training and testing inputs differently at the two phases will cause the mismatch between training and testing data distributions. To mitigate this problem, we formulate an EDNN as an additive model inspired by gradient boosting, and propose multiple training techniques to optimize the model effectively. We name our method BoostNet. Our experiments show it achieves the state-of-the-art performance on CIFAR100 and ImageNet datasets in both anytime and budgeted-batch prediction modes. Our code is released at https://github.com/SHI-Labs/Boosted-Dynamic-Networks. ",
    "url": "https://arxiv.org/abs/2211.16726",
    "authors": [
      "Haichao Yu",
      "Haoxiang Li",
      "Gang Hua",
      "Gao Huang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16740",
    "title": "Explicit Knowledge Transfer for Weakly-Supervised Code Generation",
    "abstract": "Large language models (LLMs) can acquire strong code-generation capabilities through few-shot learning. In contrast, supervised fine-tuning is still needed for smaller models to achieve good performance. Such fine-tuning demands a large number of task-specific NL-code pairs, which are expensive to obtain. In this paper, we attempt to transfer the code generation ability of an LLM to a smaller model with the aid of weakly-supervised data. More specifically, we propose explicit knowledge transfer (EKT), which uses the few-shot capabilities of a teacher LLM to create NL-code pairs that we then filter for correctness and fine-tune the student on. We evaluate EKT on the task of generating code solutions to math word problems from the GSM8k dataset. We find that EKT not only yields better performance than training with expert iteration, but also outperforms knowledge distillation, another form of knowledge transfer. A GPT-Neo 1.3B model trained using EKT with a GPT-J teacher achieves a 12.4% pass@100 on GSM8k, while the same student and teacher trained with knowledge distillation yield only a 3.7% pass@100. We also show that it is possible for a student model to outperform the teacher using EKT. ",
    "url": "https://arxiv.org/abs/2211.16740",
    "authors": [
      "Zhangir Azerbayev",
      "Ansong Ni",
      "Hailey Schoelkopf",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.16751",
    "title": "DiProber: Using Dual Probing to Estimate Tor Relay Capacities in  Underloaded Networks",
    "abstract": "Tor is the most popular anonymous communication network. It has millions of daily users seeking privacy while browsing the internet. It has thousands of relays to route and anonymize the source and destinations of the users packets. To create a path, Tor authorities generate a probability distribution over relays based on the estimates of the capacities of the relays. An incoming user will then sample this probability distribution and choose three relays for their paths. The estimates are based on the bandwidths of observation probes the authority assigns to each relay in the network. Thus, in order to achieve better load balancing between users, accurate estimates are necessary. Unfortunately, the currently implemented estimation algorithm generate inaccurate estimates causing the network to be under utilized and its capacities unfairly distributed between the users paths. We propose DiProber, a new relay capacity estimation algorithm. The algorithm proposes a new measurement scheme in Tor consisting of two probes per relay and uses maximum likelihood to estimate their capacities. We show that the new technique works better in the case of under-utilized networks where users tend to have very low demand on the Tor network. ",
    "url": "https://arxiv.org/abs/2211.16751",
    "authors": [
      "Hussein Darir",
      "Nikita Borisov",
      "Geir Dullerud"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.16753",
    "title": "VI-PINNs: Variance-involved Physics-informed Neural Networks for Fast  and Accurate Prediction of Partial Differential Equations",
    "abstract": "Although physics-informed neural networks(PINNs) have progressed a lot in many real applications recently, there remains problems to be further studied, such as achieving more accurate results, taking less training time, and quantifying the uncertainty of the predicted results. Recent advances in PINNs have indeed significantly improved the performance of PINNs in many aspects, but few have considered the effect of variance in the training process. In this work, we take into consideration the effect of variance and propose our VI-PINNs to give better predictions. We output two values in the final layer of the network to represent the predicted mean and variance respectively, and the latter is used to represent the uncertainty of the output. A modified negative log-likelihood loss and an auxiliary task are introduced for fast and accurate training. We perform several experiments on a wide range of different problems to highlight the advantages of our approach. The results convey that our method not only gives more accurate predictions but also converges faster. ",
    "url": "https://arxiv.org/abs/2211.16753",
    "authors": [
      "Bin Shan",
      "Ye Li",
      "Shengjun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.16762",
    "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation",
    "abstract": "The recent neural implicit representation-based methods have greatly advanced the state of the art for solving the long-standing and challenging problem of reconstructing a discrete surface from a sparse point cloud. These methods generally learn either a binary occupancy or signed/unsigned distance field (SDF/UDF) as surface representation. However, all the existing SDF/UDF-based methods use neural networks to implicitly regress the distance in a purely data-driven manner, thus limiting the accuracy and generalizability to some extent. In contrast, we propose the first geometry-guided method for UDF and its gradient estimation that explicitly formulates the unsigned distance of a query point as the learnable affine averaging of its distances to the tangent planes of neighbouring points. Besides, we model the local geometric structure of the input point clouds by explicitly learning a quadratic polynomial for each point. This not only facilitates upsampling the input sparse point cloud but also naturally induces unoriented normal, which further augments UDF estimation. Finally, to extract triangle meshes from the predicted UDF we propose a customized edge-based marching cube module. We conduct extensive experiments and ablation studies to demonstrate the significant advantages of our method over state-of-the-art methods in terms of reconstruction accuracy, efficiency, and generalizability. The source code is publicly available at https://github.com/rsy6318/GeoUDF. ",
    "url": "https://arxiv.org/abs/2211.16762",
    "authors": [
      "Siyu Ren",
      "Junhui Hou",
      "Xiaodong Chen",
      "Ying He",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16771",
    "title": "Handling Missing Data via Max-Entropy Regularized Graph Autoencoder",
    "abstract": "Graph neural networks (GNNs) are popular weapons for modeling relational data. Existing GNNs are not specified for attribute-incomplete graphs, making missing attribute imputation a burning issue. Until recently, many works notice that GNNs are coupled with spectral concentration, which means the spectrum obtained by GNNs concentrates on a local part in spectral domain, e.g., low-frequency due to oversmoothing issue. As a consequence, GNNs may be seriously flawed for reconstructing graph attributes as graph spectral concentration tends to cause a low imputation precision. In this work, we present a regularized graph autoencoder for graph attribute imputation, named MEGAE, which aims at mitigating spectral concentration problem by maximizing the graph spectral entropy. Notably, we first present the method for estimating graph spectral entropy without the eigen-decomposition of Laplacian matrix and provide the theoretical upper error bound. A maximum entropy regularization then acts in the latent space, which directly increases the graph spectral entropy. Extensive experiments show that MEGAE outperforms all the other state-of-the-art imputation methods on a variety of benchmark datasets. ",
    "url": "https://arxiv.org/abs/2211.16771",
    "authors": [
      "Ziqi Gao",
      "Yifan Niu",
      "Jiashun Cheng",
      "Jianheng Tang",
      "Tingyang Xu",
      "Peilin Zhao",
      "Lanqing Li",
      "Fugee Tsung",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16778",
    "title": "Rethinking Out-of-Distribution Detection From a Human-Centric  Perspective",
    "abstract": "Out-Of-Distribution (OOD) detection has received broad attention over the years, aiming to ensure the reliability and safety of deep neural networks (DNNs) in real-world scenarios by rejecting incorrect predictions. However, we notice a discrepancy between the conventional evaluation vs. the essential purpose of OOD detection. On the one hand, the conventional evaluation exclusively considers risks caused by label-space distribution shifts while ignoring the risks from input-space distribution shifts. On the other hand, the conventional evaluation reward detection methods for not rejecting the misclassified image in the validation dataset. However, the misclassified image can also cause risks and should be rejected. We appeal to rethink OOD detection from a human-centric perspective, that a proper detection method should reject the case that the deep model's prediction mismatches the human expectations and adopt the case that the deep model's prediction meets the human expectations. We propose a human-centric evaluation and conduct extensive experiments on 45 classifiers and 8 test datasets. We find that the simple baseline OOD detection method can achieve comparable and even better performance than the recently proposed methods, which means that the development in OOD detection in the past years may be overestimated. Additionally, our experiments demonstrate that model selection is non-trivial for OOD detection and should be considered as an integral of the proposed method, which differs from the claim in existing works that proposed methods are universal across different models. ",
    "url": "https://arxiv.org/abs/2211.16778",
    "authors": [
      "Yao Zhu",
      "Yuefeng Chen",
      "Xiaodan Li",
      "Rong Zhang",
      "Hui Xue",
      "Xiang Tian",
      "Rongxin Jiang",
      "Bolun Zheng",
      "Yaowu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16779",
    "title": "Attention-based Depth Distillation with 3D-Aware Positional Encoding for  Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection is a low-cost but challenging task, as it requires generating accurate 3D localization solely from a single image input. Recent developed depth-assisted methods show promising results by using explicit depth maps as intermediate features, which are either precomputed by monocular depth estimation networks or jointly evaluated with 3D object detection. However, inevitable errors from estimated depth priors may lead to misaligned semantic information and 3D localization, hence resulting in feature smearing and suboptimal predictions. To mitigate this issue, we propose ADD, an Attention-based Depth knowledge Distillation framework with 3D-aware positional encoding. Unlike previous knowledge distillation frameworks that adopt stereo- or LiDAR-based teachers, we build up our teacher with identical architecture as the student but with extra ground-truth depth as input. Credit to our teacher design, our framework is seamless, domain-gap free, easily implementable, and is compatible with object-wise ground-truth depth. Specifically, we leverage intermediate features and responses for knowledge distillation. Considering long-range 3D dependencies, we propose \\emph{3D-aware self-attention} and \\emph{target-aware cross-attention} modules for student adaptation. Extensive experiments are performed to verify the effectiveness of our framework on the challenging KITTI 3D object detection benchmark. We implement our framework on three representative monocular detectors, and we achieve state-of-the-art performance with no additional inference computational cost relative to baseline models. Our code is available at https://github.com/rockywind/ADD. ",
    "url": "https://arxiv.org/abs/2211.16779",
    "authors": [
      "Zizhang Wu",
      "Yunzhe Wu",
      "Jian Pu",
      "Xianzhi Li",
      "Xiaoquan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16784",
    "title": "Robust and Fast Measure of Information via Low-rank Representation",
    "abstract": "The matrix-based R\\'enyi's entropy allows us to directly quantify information measures from given data, without explicit estimation of the underlying probability distribution. This intriguing property makes it widely applied in statistical inference and machine learning tasks. However, this information theoretical quantity is not robust against noise in the data, and is computationally prohibitive in large-scale applications. To address these issues, we propose a novel measure of information, termed low-rank matrix-based R\\'enyi's entropy, based on low-rank representations of infinitely divisible kernel matrices. The proposed entropy functional inherits the specialty of of the original definition to directly quantify information from data, but enjoys additional advantages including robustness and effective calculation. Specifically, our low-rank variant is more sensitive to informative perturbations induced by changes in underlying distributions, while being insensitive to uninformative ones caused by noises. Moreover, low-rank R\\'enyi's entropy can be efficiently approximated by random projection and Lanczos iteration techniques, reducing the overall complexity from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(n^2 s)$ or even $\\mathcal{O}(ns^2)$, where $n$ is the number of data samples and $s \\ll n$. We conduct large-scale experiments to evaluate the effectiveness of this new information measure, demonstrating superior results compared to matrix-based R\\'enyi's entropy in terms of both performance and computational efficiency. ",
    "url": "https://arxiv.org/abs/2211.16784",
    "authors": [
      "Yuxin Dong",
      "Tieliang Gong",
      "Shujian Yu",
      "Hong Chen",
      "Chen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.16785",
    "title": "SafeSpace MFNet: Precise and Efficient MultiFeature Drone Detection  Network",
    "abstract": "Unmanned air vehicles (UAVs) popularity is on the rise as it enables the services like traffic monitoring, emergency communications, deliveries, and surveillance. However, the unauthorized usage of UAVs (a.k.a drone) may violate security and privacy protocols for security-sensitive national and international institutions. The presented challenges require fast, efficient, and precise detection of UAVs irrespective of harsh weather conditions, the presence of different objects, and their size to enable SafeSpace. Recently, there has been significant progress in using the latest deep learning models, but those models have shortcomings in terms of computational complexity, precision, and non-scalability. To overcome these limitations, we propose a precise and efficient multiscale and multifeature UAV detection network for SafeSpace, i.e., \\textit{MultiFeatureNet} (\\textit{MFNet}), an improved version of the popular object detection algorithm YOLOv5s. In \\textit{MFNet}, we perform multiple changes in the backbone and neck of the YOLOv5s network to focus on the various small and ignored features required for accurate and fast UAV detection. To further improve the accuracy and focus on the specific situation and multiscale UAVs, we classify the \\textit{MFNet} into small (S), medium (M), and large (L): these are the combinations of various size filters in the convolution and the bottleneckCSP layers, reside in the backbone and neck of the architecture. This classification helps to overcome the computational cost by training the model on a specific feature map rather than all the features. The dataset and code are available as an open source: github.com/ZeeshanKaleem/MultiFeatureNet. ",
    "url": "https://arxiv.org/abs/2211.16785",
    "authors": [
      "Mahnoor Dil",
      "Misha Urooj Khan",
      "Muhammad Zeshan Alam",
      "Farooq Alam Orakazi",
      "Zeeshan Kaleem",
      "Chau Yuen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16786",
    "title": "Two-branch Multi-scale Deep Neural Network for Generalized Document  Recapture Attack Detection",
    "abstract": "The image recapture attack is an effective image manipulation method to erase certain forensic traces, and when targeting on personal document images, it poses a great threat to the security of e-commerce and other web applications. Considering the current learning-based methods suffer from serious overfitting problem, in this paper, we propose a novel two-branch deep neural network by mining better generalized recapture artifacts with a designed frequency filter bank and multi-scale cross-attention fusion module. In the extensive experiment, we show that our method can achieve better generalization capability compared with state-of-the-art techniques on different scenarios. ",
    "url": "https://arxiv.org/abs/2211.16786",
    "authors": [
      "Jiaxing Li",
      "Chenqi Kong",
      "Shiqi Wang",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16791",
    "title": "Adaptive adversarial training method for improving multi-scale GAN based  on generalization bound theory",
    "abstract": "In recent years, multi-scale generative adversarial networks (GANs) have been proposed to build generalized image processing models based on single sample. Constraining on the sample size, multi-scale GANs have much difficulty converging to the global optimum, which ultimately leads to limitations in their capabilities. In this paper, we pioneered the introduction of PAC-Bayes generalized bound theory into the training analysis of specific models under different adversarial training methods, which can obtain a non-vacuous upper bound on the generalization error for the specified multi-scale GAN structure. Based on the drastic changes we found of the generalization error bound under different adversarial attacks and different training states, we proposed an adaptive training method which can greatly improve the image manipulation ability of multi-scale GANs. The final experimental results show that our adaptive training method in this paper has greatly contributed to the improvement of the quality of the images generated by multi-scale GANs on several image manipulation tasks. In particular, for the image super-resolution restoration task, the multi-scale GAN model trained by the proposed method achieves a 100% reduction in natural image quality evaluator (NIQE) and a 60% reduction in root mean squared error (RMSE), which is better than many models trained on large-scale datasets. ",
    "url": "https://arxiv.org/abs/2211.16791",
    "authors": [
      "Jing Tang",
      "Bo Tao",
      "Zeyu Gong",
      "Zhouping Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.16799",
    "title": "NOPE-SAC: Neural One-Plane RANSAC for Sparse-View Planar 3D  Reconstruction",
    "abstract": "This paper studies the challenging two-view 3D reconstruction in a rigorous sparse-view configuration, which is suffering from insufficient correspondences in the input image pairs for camera pose estimation. We present a novel Neural One-PlanE RANSAC framework (termed NOPE-SAC in short) that exerts excellent capability to learn one-plane pose hypotheses from 3D plane correspondences. Building on the top of a siamese plane detection network, our NOPE-SAC first generates putative plane correspondences with a coarse initial pose. It then feeds the learned 3D plane parameters of correspondences into shared MLPs to estimate the one-plane camera pose hypotheses, which are subsequently reweighed in a RANSAC manner to obtain the final camera pose. Because the neural one-plane pose minimizes the number of plane correspondences for adaptive pose hypotheses generation, it enables stable pose voting and reliable pose refinement in a few plane correspondences for the sparse-view inputs. In the experiments, we demonstrate that our NOPE-SAC significantly improves the camera pose estimation for the two-view inputs with severe viewpoint changes, setting several new state-of-the-art performances on two challenging benchmarks, i.e., MatterPort3D and ScanNet, for sparse-view 3D reconstruction. The source code is released at https://github.com/IceTTTb/NopeSAC for reproducible research. ",
    "url": "https://arxiv.org/abs/2211.16799",
    "authors": [
      "Bin Tan",
      "Nan Xue",
      "Tianfu Wu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16801",
    "title": "Generalised Spherical Text Embedding",
    "abstract": "This paper aims to provide an unsupervised modelling approach that allows for a more flexible representation of text embeddings. It jointly encodes the words and the paragraphs as individual matrices of arbitrary column dimension with unit Frobenius norm. The representation is also linguistically motivated with the introduction of a novel similarity metric. The proposed modelling and the novel similarity metric exploits the matrix structure of embeddings. We then go on to show that the same matrices can be reshaped into vectors of unit norm and transform our problem into an optimization problem over the spherical manifold. We exploit manifold optimization to efficiently train the matrix embeddings. We also quantitatively verify the quality of our text embeddings by showing that they demonstrate improved results in document classification, document clustering, and semantic textual similarity benchmark tests. ",
    "url": "https://arxiv.org/abs/2211.16801",
    "authors": [
      "Souvik Banerjee",
      "Bamdev Mishra",
      "Pratik Jawanpuria",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.16808",
    "title": "Efficient Adversarial Input Generation via Neural Net Patching",
    "abstract": "The adversarial input generation problem has become central in establishing the robustness and trustworthiness of deep neural nets, especially when they are used in safety-critical application domains such as autonomous vehicles and precision medicine. This is also practically challenging for multiple reasons-scalability is a common issue owing to large-sized networks, and the generated adversarial inputs often lack important qualities such as naturalness and output-impartiality. We relate this problem to the task of patching neural nets, i.e. applying small changes in some of the network$'$s weights so that the modified net satisfies a given property. Intuitively, a patch can be used to produce an adversarial input because the effect of changing the weights can also be brought about by changing the inputs instead. This work presents a novel technique to patch neural networks and an innovative approach of using it to produce perturbations of inputs which are adversarial for the original net. We note that the proposed solution is significantly more effective than the prior state-of-the-art techniques. ",
    "url": "https://arxiv.org/abs/2211.16808",
    "authors": [
      "Tooba Khan",
      "Kumar Madhukar",
      "Subodh Vishnu Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.16822",
    "title": "A Probabilistic-Logic based Commonsense Representation Framework for  Modelling Inferences with Multiple Antecedents and Varying Likelihoods",
    "abstract": "Commonsense knowledge-graphs (CKGs) are important resources towards building machines that can 'reason' on text or environmental inputs and make inferences beyond perception. While current CKGs encode world knowledge for a large number of concepts and have been effectively utilized for incorporating commonsense in neural models, they primarily encode declarative or single-condition inferential knowledge and assume all conceptual beliefs to have the same likelihood. Further, these CKGs utilize a limited set of relations shared across concepts and lack a coherent knowledge organization structure resulting in redundancies as well as sparsity across the larger knowledge graph. Consequently, today's CKGs, while useful for a first level of reasoning, do not adequately capture deeper human-level commonsense inferences which can be more nuanced and influenced by multiple contextual or situational factors. Accordingly, in this work, we study how commonsense knowledge can be better represented by -- (i) utilizing a probabilistic logic representation scheme to model composite inferential knowledge and represent conceptual beliefs with varying likelihoods, and (ii) incorporating a hierarchical conceptual ontology to identify salient concept-relevant relations and organize beliefs at different conceptual levels. Our resulting knowledge representation framework can encode a wider variety of world knowledge and represent beliefs flexibly using grounded concepts as well as free-text phrases. As a result, the framework can be utilized as both a traditional free-text knowledge graph and a grounded logic-based inference system more suitable for neuro-symbolic applications. We describe how we extend the PrimeNet knowledge base with our framework through crowd-sourcing and expert-annotation, and demonstrate its application for more interpretable passage-based semantic parsing and question answering. ",
    "url": "https://arxiv.org/abs/2211.16822",
    "authors": [
      "Shantanu Jaiswal",
      "Liu Yan",
      "Dongkyu Choi",
      "Kenneth Kwok"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.16841",
    "title": "Linking Sketch Patches by Learning Synonymous Proximity for Graphic  Sketch Representation",
    "abstract": "Graphic sketch representations are effective for representing sketches. Existing methods take the patches cropped from sketches as the graph nodes, and construct the edges based on sketch's drawing order or Euclidean distances on the canvas. However, the drawing order of a sketch may not be unique, while the patches from semantically related parts of a sketch may be far away from each other on the canvas. In this paper, we propose an order-invariant, semantics-aware method for graphic sketch representations. The cropped sketch patches are linked according to their global semantics or local geometric shapes, namely the synonymous proximity, by computing the cosine similarity between the captured patch embeddings. Such constructed edges are learnable to adapt to the variation of sketch drawings, which enable the message passing among synonymous patches. Aggregating the messages from synonymous patches by graph convolutional networks plays a role of denoising, which is beneficial to produce robust patch embeddings and accurate sketch representations. Furthermore, we enforce a clustering constraint over the embeddings jointly with the network learning. The synonymous patches are self-organized as compact clusters, and their embeddings are guided to move towards their assigned cluster centroids. It raises the accuracy of the computed synonymous proximity. Experimental results show that our method significantly improves the performance on both controllable sketch synthesis and sketch healing. ",
    "url": "https://arxiv.org/abs/2211.16841",
    "authors": [
      "Sicong Zang",
      "Shikui Tu",
      "Lei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16865",
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "abstract": "A temporal knowledge graph (TKG) stores the events derived from the data involving time. Predicting events is extremely challenging due to the time-sensitive property of events. Besides, the previous TKG completion (TKGC) approaches cannot represent both the timeliness and the causality properties of events, simultaneously. To address these challenges, we propose a Logic and Commonsense-Guided Embedding model (LCGE) to jointly learn the time-sensitive representation involving timeliness and causality of events, together with the time-independent representation of events from the perspective of commonsense. Specifically, we design a temporal rule learning algorithm to construct a rule-guided predicate embedding regularization strategy for learning the causality among events. Furthermore, we could accurately evaluate the plausibility of events via auxiliary commonsense knowledge. The experimental results of TKGC task illustrate the significant performance improvements of our model compared with the existing approaches. More interestingly, our model is able to provide the explainability of the predicted results in the view of causal inference. The source code and datasets of this paper are available at https://github.com/ngl567/LCGE. ",
    "url": "https://arxiv.org/abs/2211.16865",
    "authors": [
      "Guanglin Niu",
      "Bo Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.16869",
    "title": "NeAF: Learning Neural Angle Fields for Point Normal Estimation",
    "abstract": "Normal estimation for unstructured point clouds is an important task in 3D computer vision. Current methods achieve encouraging results by mapping local patches to normal vectors or learning local surface fitting using neural networks. However, these methods are not generalized well to unseen scenarios and are sensitive to parameter settings. To resolve these issues, we propose an implicit function to learn an angle field around the normal of each point in the spherical coordinate system, which is dubbed as Neural Angle Fields (NeAF). Instead of directly predicting the normal of an input point, we predict the angle offset between the ground truth normal and a randomly sampled query normal. This strategy pushes the network to observe more diverse samples, which leads to higher prediction accuracy in a more robust manner. To predict normals from the learned angle fields at inference time, we randomly sample query vectors in a unit spherical space and take the vectors with minimal angle values as the predicted normals. To further leverage the prior learned by NeAF, we propose to refine the predicted normal vectors by minimizing the angle offsets. The experimental results with synthetic data and real scans show significant improvements over the state-of-the-art under widely used benchmarks. ",
    "url": "https://arxiv.org/abs/2211.16869",
    "authors": [
      "Shujuan Li",
      "Junsheng Zhou",
      "Baorui Ma",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16883",
    "title": "X-PuDu at SemEval-2022 Task 6: Multilingual Learning for English and  Arabic Sarcasm Detection",
    "abstract": "Detecting sarcasm and verbal irony from people's subjective statements is crucial to understanding their intended meanings and real sentiments and positions in social scenarios. This paper describes the X-PuDu system that participated in SemEval-2022 Task 6, iSarcasmEval - Intended Sarcasm Detection in English and Arabic, which aims at detecting intended sarcasm in various settings of natural language understanding. Our solution finetunes pre-trained language models, such as ERNIE-M and DeBERTa, under the multilingual settings to recognize the irony from Arabic and English texts. Our system ranked second out of 43, and ninth out of 32 in Task A: one-sentence detection in English and Arabic; fifth out of 22 in Task B: binary multi-label classification in English; first out of 16, and fifth out of 13 in Task C: sentence-pair detection in English and Arabic. ",
    "url": "https://arxiv.org/abs/2211.16883",
    "authors": [
      "Yaqian Han",
      "Yekun Chai",
      "Shuohuan Wang",
      "Yu Sun",
      "Hongyi Huang",
      "Guanghao Chen",
      "Yitong Xu",
      "Yang Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.16887",
    "title": "T2G-Former: Organizing Tabular Features into Relation Graphs Promotes  Heterogeneous Feature Interaction",
    "abstract": "Recent development of deep neural networks (DNNs) for tabular learning has largely benefited from the capability of DNNs for automatic feature interaction. However, the heterogeneity nature of tabular features makes such features relatively independent, and developing effective methods to promote tabular feature interaction still remains an open problem. In this paper, we propose a novel Graph Estimator, which automatically estimates the relations among tabular features and builds graphs by assigning edges between related features. Such relation graphs organize independent tabular features into a kind of graph data such that interaction of nodes (tabular features) can be conducted in an orderly fashion. Based on our proposed Graph Estimator, we present a bespoke Transformer network tailored for tabular learning, called T2G-Former, which processes tabular data by performing tabular feature interaction guided by the relation graphs. A specific Cross-level Readout collects salient features predicted by the layers in T2G-Former across different levels, and attains global semantics for final prediction. Comprehensive experiments show that our T2G-Former achieves superior performance among DNNs and is competitive with non-deep Gradient Boosted Decision Tree models. ",
    "url": "https://arxiv.org/abs/2211.16887",
    "authors": [
      "Jiahuan Yan",
      "Jintai Chen",
      "Yixuan Wu",
      "Danny Z. Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16889",
    "title": "Generating Realistic Synthetic Relational Data through Graph Variational  Autoencoders",
    "abstract": "Synthetic data generation has recently gained widespread attention as a more reliable alternative to traditional data anonymization. The involved methods are originally developed for image synthesis. Hence, their application to the typically tabular and relational datasets from healthcare, finance and other industries is non-trivial. While substantial research has been devoted to the generation of realistic tabular datasets, the study of synthetic relational databases is still in its infancy. In this paper, we combine the variational autoencoder framework with graph neural networks to generate realistic synthetic relational databases. We then apply the obtained method to two publicly available databases in computational experiments. The results indicate that real databases' structures are accurately preserved in the resulting synthetic datasets, even for large datasets with advanced data types. ",
    "url": "https://arxiv.org/abs/2211.16889",
    "authors": [
      "Ciro Antonio Mami",
      "Andrea Coser",
      "Eric Medvet",
      "Alexander T.P. Boudewijn",
      "Marco Volpe",
      "Michael Whitworth",
      "Borut Svara",
      "Gabriele Sgroi",
      "Daniele Panfilo",
      "Sebastiano Saccani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16891",
    "title": "Quantitative Information Flow for Hardware: Advancing the Attack  Landscape",
    "abstract": "Security still remains an afterthought in modern Electronic Design Automation (EDA) tools, which solely focus on enhancing performance and reducing the chip size. Typically, the security analysis is conducted by hand, leading to vulnerabilities in the design remaining unnoticed. Security-aware EDA tools assist the designer in the identification and removal of security threats while keeping performance and area in mind. State-of-the-art approaches utilize information flow analysis to spot unintended information leakages in design structures. However, the classification of such threats is binary, resulting in negligible leakages being listed as well. A novel quantitative analysis allows the application of a metric to determine a numeric value for a leakage. Nonetheless, current approximations to quantify the leakage are still prone to overlooking leakages. The mathematical model 2D-QModel introduced in this work aims to overcome this shortcoming. Additionally, as previous work only includes a limited threat model, multiple threat models can be applied using the provided approach. Open-source benchmarks are used to show the capabilities of 2D-QModel to identify hardware Trojans in the design while ignoring insignificant leakages. ",
    "url": "https://arxiv.org/abs/2211.16891",
    "authors": [
      "Lennart M. Reimann",
      "Sarp Erd\u00f6nmez",
      "Dominik Sisejkovic",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2211.16938",
    "title": "Evaluating Digital Agriculture Recommendations with Causal Inference",
    "abstract": "In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of smart farming tools. While AI-driven digital agriculture tools can offer high-performing predictive functionalities, they lack tangible quantitative evidence on their benefits to the farmers. Field experiments can derive such evidence, but are often costly, time consuming and hence limited in scope and scale of application. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators (e.g., yield in this case). This way, we can increase farmers' trust via enhancing the transparency of the digital agriculture market and accelerate the adoption of technologies that aim to secure farmer income resilience and global agricultural sustainability. As a case study, we designed and implemented a recommendation system for the optimal sowing time of cotton based on numerical weather predictions, which was used by a farmers' cooperative during the growing season of 2021. We then leverage agricultural knowledge, collected yield data, and environmental information to develop a causal graph of the farm system. Using the back-door criterion, we identify the impact of sowing recommendations on the yield and subsequently estimate it using linear regression, matching, inverse propensity score weighting and meta-learners. The results reveal that a field sown according to our recommendations exhibited a statistically significant yield increase that ranged from 12% to 17%, depending on the method. The effect estimates were robust, as indicated by the agreement among the estimation methods and four successful refutation tests. We argue that this approach can be implemented for decision support systems of other fields, extending their evaluation beyond a performance assessment of internal functionalities. ",
    "url": "https://arxiv.org/abs/2211.16938",
    "authors": [
      "Ilias Tsoumas",
      "Georgios Giannarakis",
      "Vasileios Sitokonstantinou",
      "Alkiviadis Koukos",
      "Dimitra Loka",
      "Nikolaos Bartsotas",
      "Charalampos Kontoes",
      "Ioannis Athanasiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16960",
    "title": "BASiS: Batch Aligned Spectral Embedding Space",
    "abstract": "Graph is a highly generic and diverse representation, suitable for almost any data processing problem. Spectral graph theory has been shown to provide powerful algorithms, backed by solid linear algebra theory. It thus can be extremely instrumental to design deep network building blocks with spectral graph characteristics. For instance, such a network allows the design of optimal graphs for certain tasks or obtaining a canonical orthogonal low-dimensional embedding of the data. Recent attempts to solve this problem were based on minimizing Rayleigh-quotient type losses. We propose a different approach of directly learning the eigensapce. A severe problem of the direct approach, applied in batch-learning, is the inconsistent mapping of features to eigenspace coordinates in different batches. We analyze the degrees of freedom of learning this task using batches and propose a stable alignment mechanism that can work both with batch changes and with graph-metric changes. We show that our learnt spectral embedding is better in terms of NMI, ACC, Grassman distance, orthogonality and classification accuracy, compared to SOTA. In addition, the learning is more stable. ",
    "url": "https://arxiv.org/abs/2211.16960",
    "authors": [
      "Or Streicher",
      "Ido Cohen",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.16978",
    "title": "Combining Neuro-Evolution of Augmenting Topologies with Convolutional  Neural Networks",
    "abstract": "Current deep convolutional networks are fixed in their topology. We explore the possibilites of making the convolutional topology a parameter itself by combining NeuroEvolution of Augmenting Topologies (NEAT) with Convolutional Neural Networks (CNNs) and propose such a system using blocks of Residual Networks (ResNets). We then explain how our suggested system can only be built once additional optimizations have been made, as genetic algorithms are way more demanding than training per backpropagation. On the way there we explain most of those buzzwords and offer a gentle and brief introduction to the most important modern areas of machine learning ",
    "url": "https://arxiv.org/abs/2211.16978",
    "authors": [
      "Jan Hohenheim",
      "Mathias Fischler",
      "Sara Zarubica",
      "Jeremy Stucki"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.16980",
    "title": "Infinite-width limit of deep linear neural networks",
    "abstract": "This paper studies the infinite-width limit of deep linear neural networks initialized with random parameters. We obtain that, when the number of neurons diverges, the training dynamics converge (in a precise sense) to the dynamics obtained from a gradient descent on an infinitely wide deterministic linear neural network. Moreover, even if the weights remain random, we get their precise law along the training dynamics, and prove a quantitative convergence result of the linear predictor in terms of the number of neurons. We finally study the continuous-time limit obtained for infinitely wide linear neural networks and show that the linear predictors of the neural network converge at an exponential rate to the minimal $\\ell_2$-norm minimizer of the risk. ",
    "url": "https://arxiv.org/abs/2211.16980",
    "authors": [
      "L\u00e9na\u00efc Chizat",
      "Maria Colombo",
      "Xavier Fern\u00e1ndez-Real",
      "Alessio Figalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.17010",
    "title": "Carbon Emission Prediction on the World Bank Dataset for Canada",
    "abstract": "The continuous rise in CO2 emission into the environment is one of the most crucial issues facing the whole world. Many countries are making crucial decisions to control their carbon footprints to escape some of their catastrophic outcomes. There has been a lot of research going on to project the amount of carbon emissions in the future, which can help us to develop innovative techniques to deal with it in advance. Machine learning is one of the most advanced and efficient techniques for predicting the amount of carbon emissions from current data. This paper provides the methods for predicting carbon emissions (CO2 emissions) for the next few years. The predictions are based on data from the past 50 years. The dataset, which is used for making the prediction, is collected from World Bank datasets. This dataset contains CO2 emissions (metric tons per capita) of all the countries from 1960 to 2018. Our method consists of using machine learning techniques to take the idea of what carbon emission measures will look like in the next ten years and project them onto the dataset taken from the World Bank's data repository. The purpose of this research is to compare how different machine learning models (Decision Tree, Linear Regression, Random Forest, and Support Vector Machine) perform on a similar dataset and measure the difference between their predictions. ",
    "url": "https://arxiv.org/abs/2211.17010",
    "authors": [
      "Aman Desai",
      "Shyamal Gandhi",
      "Sachin Gupta",
      "Manan Shah",
      "Samir Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.17012",
    "title": "Correlation of the importances of neural network weights calculated by  modern methods of overcoming catastrophic forgetting",
    "abstract": "Following the invention in 2017 of the EWC method, several methods have been proposed to calculate the importance of neural network weights for use in the EWC method. Despite the significant difference in calculating the importance of weights, they all proved to be effective. Accordingly, a reasonable question arises as to how similar the importances of the weights calculated by different methods. To answer this question, we calculated layer-by-layer correlations of the importance of weights calculated by all those methods. As a result, it turned out that the importances of several of the methods correlated with each other quite strongly and we were able to present an explanation for such a correlation. At the same time, for other methods, the correlation can vary from strong on some layers of the network to negative on other layers. Which raises a reasonable question: why, despite the very different calculation methods, all those importances allow EWC method to overcome the catastrophic forgetting of neural networks perfectly? ",
    "url": "https://arxiv.org/abs/2211.17012",
    "authors": [
      "Alexey Kutalev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17029",
    "title": "Directed Acyclic Graph Structure Learning from Dynamic Graphs",
    "abstract": "Estimating the structure of directed acyclic graphs (DAGs) of features (variables) plays a vital role in revealing the latent data generation process and providing causal insights in various applications. Although there have been many studies on structure learning with various types of data, the structure learning on the dynamic graph has not been explored yet, and thus we study the learning problem of node feature generation mechanism on such ubiquitous dynamic graph data. In a dynamic graph, we propose to simultaneously estimate contemporaneous relationships and time-lagged interaction relationships between the node features. These two kinds of relationships form a DAG, which could effectively characterize the feature generation process in a concise way. To learn such a DAG, we cast the learning problem as a continuous score-based optimization problem, which consists of a differentiable score function to measure the validity of the learned DAGs and a smooth acyclicity constraint to ensure the acyclicity of the learned DAGs. These two components are translated into an unconstraint augmented Lagrangian objective which could be minimized by mature continuous optimization techniques. The resulting algorithm, named GraphNOTEARS, outperforms baselines on simulated data across a wide range of settings that may encounter in real-world applications. We also apply the proposed approach on two dynamic graphs constructed from the real-world Yelp dataset, demonstrating our method could learn the connections between node features, which conforms with the domain knowledge. ",
    "url": "https://arxiv.org/abs/2211.17029",
    "authors": [
      "Shaohua Fan",
      "Shuyang Zhang",
      "Xiao Wang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.17039",
    "title": "Neural Network Representation of Time Integrators",
    "abstract": "Deep neural network (DNN) architectures are constructed that are the exact equivalent of explicit Runge-Kutta schemes for numerical time integration. The network weights and biases are given, i.e., no training is needed. In this way, the only task left for physics-based integrators is the DNN approximation of the right-hand side. This allows to clearly delineate the approximation estimates for right-hand side errors and time integration errors. The architecture required for the integration of a simple mass-damper-stiffness case is included as an example. ",
    "url": "https://arxiv.org/abs/2211.17039",
    "authors": [
      "Rainald L\u00f6hner",
      "Harbir Antil"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17042",
    "title": "Spatio-Temporal Crop Aggregation for Video Representation Learning",
    "abstract": "We propose Spatio-temporal Crop Aggregation for video representation LEarning (SCALE), a novel method that enjoys high scalability at both training and inference time. Our model builds long-range video features by learning from sets of video clip-level features extracted with a pre-trained backbone. To train the model, we propose a self-supervised objective consisting of masked clip feature prediction. We apply sparsity to both the input, by extracting a random set of video clips, and to the loss function, by only reconstructing the sparse inputs. Moreover, we use dimensionality reduction by working in the latent space of a pre-trained backbone applied to single video clips. The video representation is then obtained by taking the ensemble of the concatenation of embeddings of separate video clips with a video clip set summarization token. These techniques make our method not only extremely efficient to train, but also highly effective in transfer learning. We demonstrate that our video representation yields state-of-the-art performance with linear, non-linear, and $k$-NN probing on common action classification datasets. ",
    "url": "https://arxiv.org/abs/2211.17042",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17045",
    "title": "From Actions to Events: A Transfer Learning Approach Using Improved Deep  Belief Networks",
    "abstract": "In the last decade, exponential data growth supplied machine learning-based algorithms' capacity and enabled their usage in daily-life activities. Additionally, such an improvement is partially explained due to the advent of deep learning techniques, i.e., stacks of simple architectures that end up in more complex models. Although both factors produce outstanding results, they also pose drawbacks regarding the learning process as training complex models over large datasets are expensive and time-consuming. Such a problem is even more evident when dealing with video analysis. Some works have considered transfer learning or domain adaptation, i.e., approaches that map the knowledge from one domain to another, to ease the training burden, yet most of them operate over individual or small blocks of frames. This paper proposes a novel approach to map the knowledge from action recognition to event recognition using an energy-based model, denoted as Spectral Deep Belief Network. Such a model can process all frames simultaneously, carrying spatial and temporal information through the learning process. The experimental results conducted over two public video dataset, the HMDB-51 and the UCF-101, depict the effectiveness of the proposed model and its reduced computational burden when compared to traditional energy-based models, such as Restricted Boltzmann Machines and Deep Belief Networks. ",
    "url": "https://arxiv.org/abs/2211.17045",
    "authors": [
      "Mateus Roder",
      "Jurandy Almeida",
      "Gustavo H. de Rosa",
      "Leandro A. Passos",
      "Andr\u00e9 L. D. Rossi",
      "Jo\u00e3o P. Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.17046",
    "title": "RAFT: Rationale adaptor for few-shot abusive language detection",
    "abstract": "Abusive language is a concerning problem in online social media. Past research on detecting abusive language covers different platforms, languages, demographies, etc. However, models trained using these datasets do not perform well in cross-domain evaluation settings. To overcome this, a common strategy is to use a few samples from the target domain to train models to get better performance in that domain (cross-domain few-shot training). However, this might cause the models to overfit the artefacts of those samples. A compelling solution could be to guide the models toward rationales, i.e., spans of text that justify the text's label. This method has been found to improve model performance in the in-domain setting across various NLP tasks. In this paper, we propose RAFT (Rationale Adaptor for Few-shoT classification) for abusive language detection. We first build a multitask learning setup to jointly learn rationales, targets, and labels, and find a significant improvement of 6% macro F1 on the rationale detection task over training solely rationale classifiers. We introduce two rationale-integrated BERT-based architectures (the RAFT models) and evaluate our systems over five different abusive language datasets, finding that in the few-shot classification setting, RAFT-based models outperform baseline models by about 7% in macro F1 scores and perform competitively to models finetuned on other source domains. Furthermore, RAFT-based models outperform LIME/SHAP-based approaches in terms of plausibility and are close in performance in terms of faithfulness. ",
    "url": "https://arxiv.org/abs/2211.17046",
    "authors": [
      "Punyajoy Saha",
      "Divyanshu Sheth",
      "Kushal Kedia",
      "Binny Mathew",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2211.17056",
    "title": "Improving the Thresholds of Generalized LDPC Codes with Convolutional  Code Constraints",
    "abstract": "CC-GLPDC codes are a class of generalized low-density parity-check (GLDPC) codes where the constraint nodes (CNs) represent convolutional codes. This allows for efficient decoding in the trellis with the forward-backward algorithm, and the strength of the component codes easily can be controlled by the encoder memory without changing the graph structure. In this letter, we extend the class of CC-GLDPC codes by introducing different types of irregularity at the CNs and investigating their effect on the BP and MAP decoding thresholds for the binary erasure channel (BEC). For the considered class of codes, an exhaustive grid search is performed to find the BP-optimized and MAP-optimized ensembles and compare their thresholds with the regular ensemble of the same design rate. The results show that irregularity can significantly improve the BP thresholds, whereas the thresholds of the MAP-optimized ensembles are only slightly different from the regular ensembles. Simulation results for the AWGN channel are presented as well and compared to the corresponding thresholds. ",
    "url": "https://arxiv.org/abs/2211.17056",
    "authors": [
      "Muhammad Umar Farooq",
      "Michael Lentmaier",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.17068",
    "title": "Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces",
    "abstract": "Continual graph learning routinely finds its role in a variety of real-world applications where the graph data with different tasks come sequentially. Despite the success of prior works, it still faces great challenges. On the one hand, existing methods work with the zero-curvature Euclidean space, and largely ignore the fact that curvature varies over the coming graph sequence. On the other hand, continual learners in the literature rely on abundant labels, but labeling graph in practice is particularly hard especially for the continuously emerging graphs on-the-fly. To address the aforementioned challenges, we propose to explore a challenging yet practical problem, the self-supervised continual graph learning in adaptive Riemannian spaces. In this paper, we propose a novel self-supervised Riemannian Graph Continual Learner (RieGrace). In RieGrace, we first design an Adaptive Riemannian GCN (AdaRGCN), a unified GCN coupled with a neural curvature adapter, so that Riemannian space is shaped by the learnt curvature adaptive to each graph. Then, we present a Label-free Lorentz Distillation approach, in which we create teacher-student AdaRGCN for the graph sequence. The student successively performs intra-distillation from itself and inter-distillation from the teacher so as to consolidate knowledge without catastrophic forgetting. In particular, we propose a theoretically grounded Generalized Lorentz Projection for the contrastive distillation in Riemannian space. Extensive experiments on the benchmark datasets show the superiority of RieGrace, and additionally, we investigate on how curvature changes over the graph sequence. ",
    "url": "https://arxiv.org/abs/2211.17068",
    "authors": [
      "Li Sun",
      "Junda Ye",
      "Hao Peng",
      "Feiyang Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17071",
    "title": "Towards Interpreting Vulnerability of Multi-Instance Learning via  Customized and Universal Adversarial Perturbations",
    "abstract": "Multi-instance learning (MIL) is a great paradigm for dealing with complex data and has achieved impressive achievements in a number of fields, including image classification, video anomaly detection, and far more. Each data sample is referred to as a bag containing several unlabeled instances, and the supervised information is only provided at the bag-level. The safety of MIL learners is concerning, though, as we can greatly fool them by introducing a few adversarial perturbations. This can be fatal in some cases, such as when users are unable to access desired images and criminals are attempting to trick surveillance cameras. In this paper, we design two adversarial perturbations to interpret the vulnerability of MIL methods. The first method can efficiently generate the bag-specific perturbation (called customized) with the aim of outsiding it from its original classification region. The second method builds on the first one by investigating the image-agnostic perturbation (called universal) that aims to affect all bags in a given data set and obtains some generalizability. We conduct various experiments to verify the performance of these two perturbations, and the results show that both of them can effectively fool MIL learners. We additionally propose a simple strategy to lessen the effects of adversarial perturbations. Source codes are available at https://github.com/InkiInki/MI-UAP. ",
    "url": "https://arxiv.org/abs/2211.17071",
    "authors": [
      "Yu-Xuan Zhang",
      "Hua Meng",
      "Xuemei Cao",
      "Zhengchun Zhou",
      "Mei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17072",
    "title": "Security Investment Over Networks with Bounded Rational Agents: Analysis  and Distributed Algorithm",
    "abstract": "This paper considers the security investment problem over a network in which the resource owners aim to allocate their constrained security resources to heterogeneous targets strategically. Investing in each target makes it less vulnerable, and thus lowering its probability of a successful attack. However, humans tend to perceive such probabilities inaccurately yielding bounded rational behaviors; a phenomenon frequently observed in their decision-making when facing uncertainties. We capture this human nature through the lens of cumulative prospect theory and establish a behavioral resource allocation framework to account for the human's misperception in security investment. We analyze how this misperception behavior affects the resource allocation plan by comparing it with the accurate perception counterpart. The network can become highly complex with a large number of participating agents. To this end, we further develop a fully distributed algorithm to compute the behavioral security investment strategy efficiently. Finally, we corroborate our results and illustrate the impacts of human's bounded rationality on the resource allocation scheme using cases studies. ",
    "url": "https://arxiv.org/abs/2211.17072",
    "authors": [
      "Jason Hughes",
      "Juntao Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.17081",
    "title": "Self-Emphasizing Network for Continuous Sign Language Recognition",
    "abstract": "Hand and face play an important role in expressing sign language. Their features are usually especially leveraged to improve system performance. However, to effectively extract visual representations and capture trajectories for hands and face, previous methods always come at high computations with increased training complexity. They usually employ extra heavy pose-estimation networks to locate human body keypoints or rely on additional pre-extracted heatmaps for supervision. To relieve this problem, we propose a self-emphasizing network (SEN) to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision. Specifically, SEN first employs a lightweight subnetwork to incorporate local spatial-temporal features to identify informative regions, and then dynamically augment original features via attention maps. It's also observed that not all frames contribute equally to recognition. We present a temporal self-emphasizing module to adaptively emphasize those discriminative frames and suppress redundant ones. A comprehensive comparison with previous methods equipped with hand and face features demonstrates the superiority of our method, even though they always require huge computations and rely on expensive extra supervision. Remarkably, with few extra computations, SEN achieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on emphasizing informative spatial and temporal features. Code is available at https://github.com/hulianyuyy/SEN_CSLR ",
    "url": "https://arxiv.org/abs/2211.17081",
    "authors": [
      "Lianyu Hu",
      "Liqing Gao",
      "Zekang liu",
      "Wei Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17108",
    "title": "An Emotion-guided Approach to Domain Adaptive Fake News Detection using  Adversarial Learning",
    "abstract": "Recent works on fake news detection have shown the efficacy of using emotions as a feature for improved performance. However, the cross-domain impact of emotion-guided features for fake news detection still remains an open problem. In this work, we propose an emotion-guided, domain-adaptive, multi-task approach for cross-domain fake news detection, proving the efficacy of emotion-guided models in cross-domain settings for various datasets. ",
    "url": "https://arxiv.org/abs/2211.17108",
    "authors": [
      "Arkajyoti Chakraborty",
      "Inder Khatri",
      "Arjun Choudhry",
      "Pankaj Gupta",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.17126",
    "title": "Multi-latent Space Alignments for Unsupervised Domain Adaptation in  Multi-view 3D Object Detection",
    "abstract": "Vision-Centric Bird-Eye-View (BEV) perception has shown promising potential and attracted increasing attention in autonomous driving. Recent works mainly focus on improving efficiency or accuracy but neglect the domain shift problem, resulting in severe degradation of transfer performance. With extensive observations, we figure out the significant domain gaps existing in the scene, weather, and day-night changing scenarios and make the first attempt to solve the domain adaption problem for multi-view 3D object detection. Since BEV perception approaches are usually complicated and contain several components, the domain shift accumulation on multi-latent spaces makes BEV domain adaptation challenging. In this paper, we propose a novel Multi-level Multi-space Alignment Teacher-Student ($M^{2}ATS$) framework to ease the domain shift accumulation, which consists of a Depth-Aware Teacher (DAT) and a Multi-space Feature Aligned (MFA) student model. Specifically, DAT model adopts uncertainty guidance to sample reliable depth information in target domain. After constructing domain-invariant BEV perception, it then transfers pixel and instance-level knowledge to student model. To further alleviate the domain shift at the global level, MFA student model is introduced to align task-relevant multi-space features of two domains. To verify the effectiveness of $M^{2}ATS$, we conduct BEV 3D object detection experiments on four cross domain scenarios and achieve state-of-the-art performance (e.g., +12.6% NDS and +9.1% mAP on Day-Night). Code and dataset will be released. ",
    "url": "https://arxiv.org/abs/2211.17126",
    "authors": [
      "Jiaming Liu",
      "Rongyu Zhang",
      "Xiaowei Chi",
      "Xiaoqi Li",
      "Ming Lu",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17161",
    "title": "Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot  Image Classification",
    "abstract": "The main challenge for fine-grained few-shot image classification is to learn feature representations with higher inter-class and lower intra-class variations, with a mere few labelled samples. Conventional few-shot learning methods however cannot be naively adopted for this fine-grained setting -- a quick pilot study reveals that they in fact push for the opposite (i.e., lower inter-class variations and higher intra-class variations). To alleviate this problem, prior works predominately use a support set to reconstruct the query image and then utilize metric learning to determine its category. Upon careful inspection, we further reveal that such unidirectional reconstruction methods only help to increase inter-class variations and are not effective in tackling intra-class variations. In this paper, we for the first time introduce a bi-reconstruction mechanism that can simultaneously accommodate for inter-class and intra-class variations. In addition to using the support set to reconstruct the query set for increasing inter-class variations, we further use the query set to reconstruct the support set for reducing intra-class variations. This design effectively helps the model to explore more subtle and discriminative features which is key for the fine-grained problem in hand. Furthermore, we also construct a self-reconstruction module to work alongside the bi-directional module to make the features even more discriminative. Experimental results on three widely used fine-grained image classification datasets consistently show considerable improvements compared with other methods. Codes are available at: https://github.com/PRIS-CV/Bi-FRN. ",
    "url": "https://arxiv.org/abs/2211.17161",
    "authors": [
      "Jijie Wu",
      "Dongliang Chang",
      "Aneeshan Sain",
      "Xiaoxu Li",
      "Zhanyu Ma",
      "Jie Cao",
      "Jun Guo",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17170",
    "title": "How to Train an Accurate and Efficient Object Detection Model on Any  Dataset",
    "abstract": "The rapidly evolving industry demands high accuracy of the models without the need for time-consuming and computationally expensive experiments required for fine-tuning. Moreover, a model and training pipeline, which was once carefully optimized for a specific dataset, rarely generalizes well to training on a different dataset. This makes it unrealistic to have carefully fine-tuned models for each use case. To solve this, we propose an alternative approach that also forms a backbone of Intel Geti platform: a dataset-agnostic template for object detection trainings, consisting of carefully chosen and pre-trained models together with a robust training pipeline for further training. Our solution works out-of-the-box and provides a strong baseline on a wide range of datasets. It can be used on its own or as a starting point for further fine-tuning for specific use cases when needed. We obtained dataset-agnostic templates by performing parallel training on a corpus of datasets and optimizing the choice of architectures and training tricks with respect to the average results on the whole corpora. We examined a number of architectures, taking into account the performance-accuracy trade-off. Consequently, we propose 3 finalists, VFNet, ATSS, and SSD, that can be deployed on CPU using the OpenVINO toolkit. The source code is available as a part of the OpenVINO Training Extensions (https://github.com/openvinotoolkit/training_extensions} ",
    "url": "https://arxiv.org/abs/2211.17170",
    "authors": [
      "Galina Zalesskaya",
      "Bogna Bylicka",
      "Eugene Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17171",
    "title": "CDSM: Cascaded Deep Semantic Matching on Textual Graphs Leveraging  Ad-hoc Neighbor Selection",
    "abstract": "Deep semantic matching aims to discriminate the relationship between documents based on deep neural networks. In recent years, it becomes increasingly popular to organize documents with a graph structure, then leverage both the intrinsic document features and the extrinsic neighbor features to derive discrimination. Most of the existing works mainly care about how to utilize the presented neighbors, whereas limited effort is made to filter appropriate neighbors. We argue that the neighbor features could be highly noisy and partially useful. Thus, a lack of effective neighbor selection will not only incur a great deal of unnecessary computation cost, but also restrict the matching accuracy severely. In this work, we propose a novel framework, Cascaded Deep Semantic Matching (CDSM), for accurate and efficient semantic matching on textual graphs. CDSM is highlighted for its two-stage workflow. In the first stage, a lightweight CNN-based ad-hod neighbor selector is deployed to filter useful neighbors for the matching task with a small computation cost. We design both one-step and multi-step selection methods. In the second stage, a high-capacity graph-based matching network is employed to compute fine-grained relevance scores based on the well-selected neighbors. It is worth noting that CDSM is a generic framework which accommodates most of the mainstream graph-based semantic matching networks. The major challenge is how the selector can learn to discriminate the neighbors usefulness which has no explicit labels. To cope with this problem, we design a weak-supervision strategy for optimization, where we train the graph-based matching network at first and then the ad-hoc neighbor selector is learned on top of the annotations from the matching network. ",
    "url": "https://arxiv.org/abs/2211.17171",
    "authors": [
      "Jing Yao",
      "Zheng Liu",
      "Junhan Yang",
      "Zhicheng Dou",
      "Xing Xie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.17174",
    "title": "Optimizing Explanations by Network Canonization and Hyperparameter  Search",
    "abstract": "Explainable AI (XAI) is slowly becoming a key component for many AI applications. Rule-based and modified backpropagation XAI approaches however often face challenges when being applied to modern model architectures including innovative layer building blocks, which is caused by two reasons. Firstly, the high flexibility of rule-based XAI methods leads to numerous potential parameterizations. Secondly, many XAI methods break the implementation-invariance axiom because they struggle with certain model components, e.g., BatchNorm layers. The latter can be addressed with model canonization, which is the process of re-structuring the model to disregard problematic components without changing the underlying function. While model canonization is straightforward for simple architectures (e.g., VGG, ResNet), it can be challenging for more complex and highly interconnected models (e.g., DenseNet). Moreover, there is only little quantifiable evidence that model canonization is beneficial for XAI. In this work, we propose canonizations for currently relevant model blocks applicable to popular deep neural network architectures,including VGG, ResNet, EfficientNet, DenseNets, as well as Relation Networks. We further suggest a XAI evaluation framework with which we quantify and compare the effect sof model canonization for various XAI methods in image classification tasks on the Pascal-VOC and ILSVRC2017 datasets, as well as for Visual Question Answering using CLEVR-XAI. Moreover, addressing the former issue outlined above, we demonstrate how our evaluation framework can be applied to perform hyperparameter search for XAI methods to optimize the quality of explanations. ",
    "url": "https://arxiv.org/abs/2211.17174",
    "authors": [
      "Frederik Pahde",
      "Galip \u00dcmit Yolcu",
      "Alexander Binder",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17179",
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks",
    "abstract": "Echo State Networks (ESN) are a type of Recurrent Neural Networks that yields promising results in representing time series and nonlinear dynamic systems. Although they are equipped with a very efficient training procedure, Reservoir Computing strategies, such as the ESN, require the use of high order networks, i.e. large number of layers, resulting in number of states that is magnitudes higher than the number of model inputs and outputs. This not only makes the computation of a time step more costly, but also may pose robustness issues when applying ESNs to problems such as Model Predictive Control (MPC) and other optimal control problems. One such way to circumvent this is through Model Order Reduction strategies such as the Proper Orthogonal Decomposition (POD) and its variants (POD-DEIM), whereby we find an equivalent lower order representation to an already trained high dimension ESN. The objective of this work is to investigate and analyze the performance of POD methods in Echo State Networks, evaluating their effectiveness. To this end, we evaluate the Memory Capacity (MC) of the POD-reduced network in comparison to the original (full order) ENS. We also perform experiments on two different numerical case studies: a NARMA10 difference equation and an oil platform containing two wells and one riser. The results show that there is little loss of performance comparing the original ESN to a POD-reduced counterpart, and also that the performance of a POD-reduced ESN tend to be superior to a normal ESN of the same size. Also we attain speedups of around $80\\%$ in comparison to the original ESN. ",
    "url": "https://arxiv.org/abs/2211.17179",
    "authors": [
      "Jean Panaioti Jordanou",
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Eduardo Gildin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.17180",
    "title": "Average Path Length: Sparsification of Nonlinearties Creates  Surprisingly Shallow Networks",
    "abstract": "We perform an empirical study of the behaviour of deep networks when pushing its activation functions to become fully linear in some of its feature channels through a sparsity prior on the overall number of nonlinear units in the network. To measure the depth of the resulting partially linearized network, we compute the average number of active nonlinearities encountered along a path in the network graph. In experiments on CNNs with sparsified PReLUs on typical image classification tasks, we make several observations: Under sparsity pressure, the remaining nonlinear units organize into distinct structures, forming core-networks of near constant effective depth and width, which in turn depend on task difficulty. We consistently observe a slow decay of performance with depth until the onset of a rapid collapse in accuracy, allowing for surprisingly shallow networks at moderate losses in accuracy that outperform base-line networks of similar depth, even after increasing width to a comparable number of parameters. In terms of training, we observe a nonlinear advantage: Reducing nonlinearity after training leads to a better performance than before, in line with previous findings in linearized training, but with a gap depending on task difficulty that vanishes for easy problems. ",
    "url": "https://arxiv.org/abs/2211.17180",
    "authors": [
      "Christian H.X. Ali Mehmeti-G\u00f6pel",
      "Jan Disselhoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17200",
    "title": "CKS: A Community-based K-shell Decomposition Approach using Community  Bridge Nodes for Influence Maximization",
    "abstract": "Social networks have enabled user-specific advertisements and recommendations on their platforms, which puts a significant focus on Influence Maximisation (IM) for target advertising and related tasks. The aim is to identify nodes in the network which can maximize the spread of information through a diffusion cascade. We propose a community structures-based approach that employs K-Shell algorithm with community structures to generate a score for the connections between seed nodes and communities. Further, our approach employs entropy within communities to ensure the proper spread of information within the communities. We validate our approach on four publicly available networks and show its superiority to four state-of-the-art approaches while still being relatively efficient. ",
    "url": "https://arxiv.org/abs/2211.17200",
    "authors": [
      "Inder Khatri",
      "Aaryan Gupta",
      "Arjun Choudhry",
      "Aryan Tyagi",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.17217",
    "title": "A Tutorial on Neural Networks and Gradient-free Training",
    "abstract": "This paper presents a compact, matrix-based representation of neural networks in a self-contained tutorial fashion. Specifically, we develop neural networks as a composition of several vector-valued functions. Although neural networks are well-understood pictorially in terms of interconnected neurons, neural networks are mathematical nonlinear functions constructed by composing several vector-valued functions. Using basic results from linear algebra, we represent a neural network as an alternating sequence of linear maps and scalar nonlinear functions, also known as activation functions. The training of neural networks requires the minimization of a cost function, which in turn requires the computation of a gradient. Using basic multivariable calculus results, the cost gradient is also shown to be a function composed of a sequence of linear maps and nonlinear functions. In addition to the analytical gradient computation, we consider two gradient-free training methods and compare the three training methods in terms of convergence rate and prediction accuracy. ",
    "url": "https://arxiv.org/abs/2211.17217",
    "authors": [
      "Turibius Rozario",
      "Arjun Trivedi",
      "Ankit Goel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17226",
    "title": "GENNAPE: Towards Generalized Neural Architecture Performance Estimators",
    "abstract": "Predicting neural architecture performance is a challenging task and is crucial to neural architecture design and search. Existing approaches either rely on neural performance predictors which are limited to modeling architectures in a predefined design space involving specific sets of operators and connection rules, and cannot generalize to unseen architectures, or resort to zero-cost proxies which are not always accurate. In this paper, we propose GENNAPE, a Generalized Neural Architecture Performance Estimator, which is pretrained on open neural architecture benchmarks, and aims to generalize to completely unseen architectures through combined innovations in network representation, contrastive pretraining, and fuzzy clustering-based predictor ensemble. Specifically, GENNAPE represents a given neural network as a Computation Graph (CG) of atomic operations which can model an arbitrary architecture. It first learns a graph encoder via Contrastive Learning to encourage network separation by topological features, and then trains multiple predictor heads, which are soft-aggregated according to the fuzzy membership of a neural network. Experiments show that GENNAPE pretrained on NAS-Bench-101 can achieve superior transferability to 5 different public neural network benchmarks, including NAS-Bench-201, NAS-Bench-301, MobileNet and ResNet families under no or minimum fine-tuning. We further introduce 3 challenging newly labelled neural network benchmarks: HiAML, Inception and Two-Path, which can concentrate in narrow accuracy ranges. Extensive experiments show that GENNAPE can correctly discern high-performance architectures in these families. Finally, when paired with a search algorithm, GENNAPE can find architectures that improve accuracy while reducing FLOPs on three families. ",
    "url": "https://arxiv.org/abs/2211.17226",
    "authors": [
      "Keith G. Mills",
      "Fred X. Han",
      "Jialin Zhang",
      "Fabian Chudak",
      "Ali Safari Mamaghani",
      "Mohammad Salameh",
      "Wei Lu",
      "Shangling Jui",
      "Di Niu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.17228",
    "title": "AIO-P: Expanding Neural Performance Predictors Beyond Image  Classification",
    "abstract": "Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as well as methods to transfer to downstream tasks/spaces. Extensive experimental results show that AIO-P can achieve Mean Absolute Error (MAE) and Spearman's Rank Correlation (SRCC) below 1% and above 0.5, respectively, on a breadth of target downstream CV tasks with or without fine-tuning, outperforming a number of baselines. Moreover, AIO-P can directly transfer to new architectures not seen during training, accurately rank them and serve as an effective performance estimator when paired with an algorithm designed to preserve performance while reducing FLOPs. ",
    "url": "https://arxiv.org/abs/2211.17228",
    "authors": [
      "Keith G. Mills",
      "Di Niu",
      "Mohammad Salameh",
      "Weichen Qiu",
      "Fred X. Han",
      "Puyuan Liu",
      "Jialin Zhang",
      "Wei Lu",
      "Shangling Jui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.17230",
    "title": "The Bounded Gaussian Mechanism for Differential Privacy",
    "abstract": "The Gaussian mechanism is one differential privacy mechanism commonly used to protect numerical data. However, it may be ill-suited to some applications because it has unbounded support and thus can produce invalid numerical answers to queries, such as negative ages or human heights in the tens of meters. One can project such private values onto valid ranges of data, though such projections lead to the accumulation of private query responses at the boundaries of such ranges, thereby harming accuracy. Motivated by the need for both privacy and accuracy over bounded domains, we present a bounded Gaussian mechanism for differential privacy, which has support only on a given region. We present both univariate and multivariate versions of this mechanism and illustrate a significant reduction in variance relative to comparable existing work. ",
    "url": "https://arxiv.org/abs/2211.17230",
    "authors": [
      "Bo Chen",
      "Matthew Hale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.17244",
    "title": "Overcoming the Convex Relaxation Barrier for Neural Network Verification  via Nonconvex Low-Rank Semidefinite Relaxations",
    "abstract": "To rigorously certify the robustness of neural networks to adversarial perturbations, most state-of-the-art techniques rely on a triangle-shaped linear programming (LP) relaxation of the ReLU activation. While the LP relaxation is exact for a single neuron, recent results suggest that it faces an inherent \"convex relaxation barrier\" as additional activations are added, and as the attack budget is increased. In this paper, we propose a nonconvex relaxation for the ReLU relaxation, based on a low-rank restriction of a semidefinite programming (SDP) relaxation. We show that the nonconvex relaxation has a similar complexity to the LP relaxation, but enjoys improved tightness that is comparable to the much more expensive SDP relaxation. Despite nonconvexity, we prove that the verification problem satisfies constraint qualification, and therefore a Riemannian staircase approach is guaranteed to compute a near-globally optimal solution in polynomial time. Our experiments provide evidence that our nonconvex relaxation almost completely overcome the \"convex relaxation barrier\" faced by the LP relaxation. ",
    "url": "https://arxiv.org/abs/2211.17244",
    "authors": [
      "Hong-Ming Chiu",
      "Richard Y. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.16416",
    "title": "Exploiting Data Locality to Improve Performance of Heterogeneous Server  Clusters",
    "abstract": "We consider load balancing in large-scale heterogeneous server systems in the presence of data locality that imposes constraints on which tasks can be assigned to which servers. The constraints are naturally captured by a bipartite graph between the servers and the dispatchers handling assignments of various arrival flows. When a task arrives, the corresponding dispatcher assigns it to a server with the shortest queue among $d\\geq 2$ randomly selected servers obeying the above constraints. Server processing speeds are heterogeneous and they depend on the server-type. For a broad class of bipartite graphs, we characterize the limit of the appropriately scaled occupancy process, both on the process-level and in steady state, as the system size becomes large. Using such a characterization, we show that data locality constraints can be used to significantly improve the performance of heterogeneous systems. This is in stark contrast to either heterogeneous servers in a full flexible system or data locality constraints in systems with homogeneous servers, both of which have been observed to degrade the system performance. Extensive numerical experiments corroborate the theoretical results. ",
    "url": "https://arxiv.org/abs/2211.16416",
    "authors": [
      "Zhisheng Zhao",
      "Debankur Mukherjee",
      "Ruoyu Wu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2211.16596",
    "title": "A Novel Statistical Independence Test for Dynamic Causal Discovery with  Rare Events",
    "abstract": "Causal phenomena associated with rare events frequently occur across a wide range of engineering and mathematical problems, such as risk-sensitive safety analysis, accident analysis and prevention, and extreme value theory. However, current methods for causal discovery are often unable to uncover causal links between random variables that manifest only when the variables first experience low-probability realizations. To address this issue, we introduce a novel algorithm that performs statistical independence tests on data collected from time-invariant dynamical systems in which rare but consequential events occur. We seek to understand if the state of the dynamical system causally affects the likelihood of the rare event. In particular, we exploit the time-invariance of the underlying data to superimpose the occurrences of rare events, thus creating a new dataset, with rare events are better represented, on which conditional independence tests can be more efficiently performed. We provide non-asymptotic bounds for the consistency of our algorithm, and validate the performance of our algorithm across various simulated scenarios, with applications to traffic accidents. ",
    "url": "https://arxiv.org/abs/2211.16596",
    "authors": [
      "Chih-Yuan Chiu",
      "Kshitij Kulkarni",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.16654",
    "title": "Stochastic Parameterization of Column Physics using Generative  Adversarial Networks",
    "abstract": "We demonstrate the use of a probabilistic machine learning technique to develop stochastic parameterizations of atmospheric column-physics. After suitable preprocessing of NASA's Modern-Era Retrospective analysis for Research and Applications, version 2 (MERRA2) data to minimize the effects of high-frequency, high-wavenumber component of MERRA2 estimate of vertical velocity, we use generative adversarial networks to learn the probability distribution of vertical profiles of diabatic sources conditioned on vertical profiles of temperature and humidity. This may be viewed as an improvement over previous similar but deterministic approaches that seek to alleviate both, shortcomings of human-designed physics parameterizations, and the computational demand of the \"physics\" step in climate models. ",
    "url": "https://arxiv.org/abs/2211.16654",
    "authors": [
      "B.T. Nadiga",
      "X. Sun",
      "C. Nash"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16684",
    "title": "Capturing long-range interaction with reciprocal space neural network",
    "abstract": "Machine Learning (ML) interatomic models and potentials have been widely employed in simulations of materials. Long-range interactions often dominate in some ionic systems whose dynamics behavior is significantly influenced. However, the long-range effect such as Coulomb and Van der Wales potential is not considered in most ML interatomic potentials. To address this issue, we put forward a method that can take long-range effects into account for most ML local interatomic models with the reciprocal space neural network. The structure information in real space is firstly transformed into reciprocal space and then encoded into a reciprocal space potential or a global descriptor with full atomic interactions. The reciprocal space potential and descriptor keep full invariance of Euclidean symmetry and choice of the cell. Benefiting from the reciprocal-space information, ML interatomic models can be extended to describe the long-range potential including not only Coulomb but any other long-range interaction. A model NaCl system considering Coulomb interaction and the GaxNy system with defects are applied to illustrate the advantage of our approach. At the same time, our approach helps to improve the prediction accuracy of some global properties such as the band gap where the full atomic interaction beyond local atomic environments plays a very important role. In summary, our work has expanded the ability of current ML interatomic models and potentials when dealing with the long-range effect, hence paving a new way for accurate prediction of global properties and large-scale dynamic simulations of systems with defects. ",
    "url": "https://arxiv.org/abs/2211.16684",
    "authors": [
      "Hongyu Yu",
      "Liangliang Hong",
      "Shiyou Chen",
      "Xingao Gong",
      "Hongjun Xiang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.16700",
    "title": "AirCon: Over-the-Air Consensus for Wireless Blockchain Networks",
    "abstract": "Blockchain has been deemed as a promising solution for providing security and privacy protection in the next-generation wireless networks. Large-scale concurrent access for massive wireless devices to accomplish the consensus procedure may consume prohibitive communication and computing resources, and thus may limit the application of blockchain in wireless conditions. As most existing consensus protocols are designed for wired networks, directly apply them for wireless users may exhaust their scarce spectrum and computing resources. In this paper, we propose AirCon, a byzantine fault-tolerant (BFT) consensus protocol for wireless users via the over-the-air computation. The novelty of AirCon is to take advantage of the intrinsic characteristic of the wireless channel and automatically achieve the consensus in the physical layer while receiving from the end users, which greatly reduces the communication and computational cost that would be caused by traditional consensus protocols. We implement the AirCon protocol integrated into an LTE system and provide solutions to the critical issues for over-the-air consensus implementation. Experimental results are provided to show the feasibility of the proposed protocol, and simulation results to show the performance of the AirCon protocol under different wireless conditions. ",
    "url": "https://arxiv.org/abs/2211.16700",
    "authors": [
      "Xin Xie",
      "Cunqing Hua",
      "Pengwenlong Gu",
      "Wenchao Xu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.16708",
    "title": "Statistical treatment of convolutional neural network super-resolution  of inland surface wind for subgrid-scale variability quantification",
    "abstract": "Machine learning models are frequently employed to perform either purely physics-free or hybrid downscaling of climate data. However, the majority of these implementations operate over relatively small downscaling factors of about 4--6x. This study examines the ability of convolutional neural networks (CNN) to downscale surface wind speed data from three different coarse resolutions (25km, 48km, and 100km side-length grid cells) to 3km and additionally focuses on the ability to recover subgrid-scale variability. Within each downscaling factor, namely 8x, 16x, and 32x, we consider models that produce fine-scale wind speed predictions as functions of different input features: coarse wind fields only; coarse wind and fine-scale topography; and coarse wind, topography, and temporal information in the form of a timestamp. Furthermore, we train one model at 25km to 3km resolution whose fine-scale outputs are probability density function parameters through which sample wind speeds can be generated. All CNN predictions performed on one out-of-sample data outperform classical interpolation. Models with coarse wind and fine topography are shown to exhibit the best performance compared to other models operating across the same downscaling factor. Our timestamp encoding results in lower out-of-sample generalizability compared to other input configurations. Overall, the downscaling factor plays the largest role in model performance. ",
    "url": "https://arxiv.org/abs/2211.16708",
    "authors": [
      "Daniel Getter",
      "Julie Bessac",
      "Johann Rudi",
      "Yan Feng"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.16806",
    "title": "Toward Robust Diagnosis: A Contour Attention Preserving Adversarial  Defense for COVID-19 Detection",
    "abstract": "As the COVID-19 pandemic puts pressure on healthcare systems worldwide, the computed tomography image based AI diagnostic system has become a sustainable solution for early diagnosis. However, the model-wise vulnerability under adversarial perturbation hinders its deployment in practical situation. The existing adversarial training strategies are difficult to generalized into medical imaging field challenged by complex medical texture features. To overcome this challenge, we propose a Contour Attention Preserving (CAP) method based on lung cavity edge extraction. The contour prior features are injected to attention layer via a parameter regularization and we optimize the robust empirical risk with hybrid distance metric. We then introduce a new cross-nation CT scan dataset to evaluate the generalization capability of the adversarial robustness under distribution shift. Experimental results indicate that the proposed method achieves state-of-the-art performance in multiple adversarial defense and generalization tasks. The code and dataset are available at https://github.com/Quinn777/CAP. ",
    "url": "https://arxiv.org/abs/2211.16806",
    "authors": [
      "Kun Xiang",
      "Xing Zhang",
      "Jinwen She",
      "Jinpeng Liu",
      "Haohan Wang",
      "Shiqi Deng",
      "Shancheng Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16852",
    "title": "Challenging mitosis detection algorithms: Global labels allow centroid  localization",
    "abstract": "Mitotic activity is a crucial proliferation biomarker for the diagnosis and prognosis of different types of cancers. Nevertheless, mitosis counting is a cumbersome process for pathologists, prone to low reproducibility, due to the large size of augmented biopsy slides, the low density of mitotic cells, and pattern heterogeneity. To improve reproducibility, deep learning methods have been proposed in the last years using convolutional neural networks. However, these methods have been hindered by the process of data labelling, which usually solely consist of the mitosis centroids. Therefore, current literature proposes complex algorithms with multiple stages to refine the labels at pixel level, and to reduce the number of false positives. In this work, we propose to avoid complex scenarios, and we perform the localization task in a weakly supervised manner, using only image-level labels on patches. The results obtained on the publicly available TUPAC16 dataset are competitive with state-of-the-art methods, using only one training phase. Our method achieves an F1-score of 0.729 and challenges the efficiency of previous methods, which required multiple stages and strong mitosis location information. ",
    "url": "https://arxiv.org/abs/2211.16852",
    "authors": [
      "Claudio Fernandez-Mart\u00edn",
      "Umay Kiraz",
      "Julio Silva-Rodr\u00edguez",
      "Sandra Morales",
      "Emiel Janssen",
      "Valery Naranjo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16854",
    "title": "Resolving Prime Modules: The Structure of Pseudo-cographs and  Galled-Tree Explainable Graphs",
    "abstract": "The modular decomposition of a graph $G$ is a natural construction to capture key features of $G$ in terms of a labeled tree $(T,t)$ whose vertices are labeled as \"series\" ($1$), \"parallel\" ($0$) or \"prime\". However, full information of $G$ is provided by its modular decomposition tree $(T,t)$ only, if $G$ is a cograph, i.e., $G$ does not contain prime modules. In this case, $(T,t)$ explains $G$, i.e., $\\{x,y\\}\\in E(G)$ if and only if the lowest common ancestor $\\mathrm{lca}_T(x,y)$ of $x$ and $y$ has label \"$1$\". Pseudo-cographs, or, more general, GaTEx graphs $G$ are graphs that can be explained by labeled galled-trees, i.e., labeled networks $(N,t)$ that are obtained from the modular decomposition tree $(T,t)$ of $G$ by replacing the prime vertices in $T$ by simple labeled cycles. GaTEx graphs can be recognized and labeled galled-trees that explain these graphs can be constructed in linear time. In this contribution, we provide a novel characterization of GaTEx graphs in terms of a set $\\mathfrak{F}_{\\mathrm{GT}}$ of 25 forbidden induced subgraphs. This characterization, in turn, allows us to show that GaTEx graphs are closely related to many other well-known graph classes such as $P_4$-sparse and $P_4$-reducible graphs, weakly-chordal graphs, perfect graphs with perfect order, comparability and permutation graphs, murky graphs as well as interval graphs, Meyniel graphs or very strongly-perfect and brittle graphs. ",
    "url": "https://arxiv.org/abs/2211.16854",
    "authors": [
      "Marc Hellmuth",
      "Guillaume E. Scholz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.16855",
    "title": "ATASI-Net: An Efficient Sparse Reconstruction Network for Tomographic  SAR Imaging with Adaptive Threshold",
    "abstract": "Tomographic SAR technique has attracted remarkable interest for its ability of three-dimensional resolving along the elevation direction via a stack of SAR images collected from different cross-track angles. The emerged compressed sensing (CS)-based algorithms have been introduced into TomoSAR considering its super-resolution ability with limited samples. However, the conventional CS-based methods suffer from several drawbacks, including weak noise resistance, high computational complexity, and complex parameter fine-tuning. Aiming at efficient TomoSAR imaging, this paper proposes a novel efficient sparse unfolding network based on the analytic learned iterative shrinkage thresholding algorithm (ALISTA) architecture with adaptive threshold, named Adaptive Threshold ALISTA-based Sparse Imaging Network (ATASI-Net). The weight matrix in each layer of ATASI-Net is pre-computed as the solution of an off-line optimization problem, leaving only two scalar parameters to be learned from data, which significantly simplifies the training stage. In addition, adaptive threshold is introduced for each azimuth-range pixel, enabling the threshold shrinkage to be not only layer-varied but also element-wise. Moreover, the final learned thresholds can be visualized and combined with the SAR image semantics for mutual feedback. Finally, extensive experiments on simulated and real data are carried out to demonstrate the effectiveness and efficiency of the proposed method. ",
    "url": "https://arxiv.org/abs/2211.16855",
    "authors": [
      "Muhan Wang",
      "Zhe Zhang",
      "Xiaolan Qiu",
      "Silin Gao",
      "Yue Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16871",
    "title": "A Deep Learning Approach to the Prediction of Drug Side-Effects on  Molecular Graphs",
    "abstract": "Predicting drug side-effects before they occur is a key task in keeping the number of drug-related hospitalizations low and to improve drug discovery processes. Automatic predictors of side-effects generally are not able to process the structure of the drug, resulting in a loss of information. Graph neural networks have seen great success in recent years, thanks to their ability of exploiting the information conveyed by the graph structure and labels. These models have been used in a wide variety of biological applications, among which the prediction of drug side-effects on a large knowledge graph. Exploiting the molecular graph encoding the structure of the drug represents a novel approach, in which the problem is formulated as a multi-class multi-label graph-focused classification. We developed a methodology to carry out this task, using recurrent Graph Neural Networks, and building a dataset from freely accessible and well established data sources. The results show that our method has an improved classification capability, under many parameters and metrics, with respect to previously available predictors. ",
    "url": "https://arxiv.org/abs/2211.16871",
    "authors": [
      "Pietro Bongini",
      "Elisa Messori",
      "Niccol\u00f2 Pancino",
      "Monica Bianchini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.16950",
    "title": "DSNet: a simple yet efficient network with dual-stream attention for  lesion segmentation",
    "abstract": "Lesion segmentation requires both speed and accuracy. In this paper, we propose a simple yet efficient network DSNet, which consists of a encoder based on Transformer and a convolutional neural network(CNN)-based distinct pyramid decoder containing three dual-stream attention (DSA) modules. Specifically, the DSA module fuses features from two adjacent levels through the false positive stream attention (FPSA) branch and the false negative stream attention (FNSA) branch to obtain features with diversified contextual information. We compare our method with various state-of-the-art (SOTA) lesion segmentation methods with several public datasets, including CVC-ClinicDB, Kvasir-SEG, and ISIC-2018 Task 1. The experimental results show that our method achieves SOTA performance in terms of mean Dice coefficient (mDice) and mean Intersection over Union (mIoU) with low model complexity and memory consumption. ",
    "url": "https://arxiv.org/abs/2211.16950",
    "authors": [
      "Yunxiao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16992",
    "title": "Extreme Audio Time Stretching Using Neural Synthesis",
    "abstract": "A deep neural network solution for time-scale modification (TSM) focused on large stretching factors is proposed, targeting environmental sounds. Traditional TSM artifacts such as transient smearing, loss of presence, and phasiness are heavily accentuated and cause poor audio quality when the TSM factor is four or larger. The weakness of established TSM methods, often based on a phase vocoder structure, lies in the poor description and scaling of the transient and noise components, or nuances, of a sound. Our novel solution combines a sines-transients-noise decomposition with an independent WaveNet synthesizer to provide a better description of the noise component and an improve sound quality for large stretching factors. Results of a subjective listening test against four other TSM algorithms are reported, showing the proposed method to be often superior. The proposed method is stereo compatible and has a wide range of applications related to the slow motion of media content. ",
    "url": "https://arxiv.org/abs/2211.16992",
    "authors": [
      "Leonardo Fierro",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Matti H\u00e4m\u00e4l\u00e4inen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.17048",
    "title": "SNAF: Sparse-view CBCT Reconstruction with Neural Attenuation Fields",
    "abstract": "Cone beam computed tomography (CBCT) has been widely used in clinical practice, especially in dental clinics, while the radiation dose of X-rays when capturing has been a long concern in CBCT imaging. Several research works have been proposed to reconstruct high-quality CBCT images from sparse-view 2D projections, but the current state-of-the-arts suffer from artifacts and the lack of fine details. In this paper, we propose SNAF for sparse-view CBCT reconstruction by learning the neural attenuation fields, where we have invented a novel view augmentation strategy to overcome the challenges introduced by insufficient data from sparse input views. Our approach achieves superior performance in terms of high reconstruction quality (30+ PSNR) with only 20 input views (25 times fewer than clinical collections), which outperforms the state-of-the-arts. We have further conducted comprehensive experiments and ablation analysis to validate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2211.17048",
    "authors": [
      "Yu Fang",
      "Lanzhuju Mei",
      "Changjian Li",
      "Yuan Liu",
      "Wenping Wang",
      "Zhiming Cui",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2009.09778",
    "title": "Computation of Parameter Dependent Robust Invariant Sets for LPV Models  with Guaranteed Performance",
    "abstract": " Comments: 15 pages, 6 figures, preprint submitted to Automatica ",
    "url": "https://arxiv.org/abs/2009.09778",
    "authors": [
      "Ankit Gupta",
      "Manas Mejari",
      "Paolo Falcone",
      "Dario Piga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2108.13650",
    "title": "Heterogeneous Graph Neural Network with Multi-view Representation  Learning",
    "abstract": " Comments: Accepted by TKDE ",
    "url": "https://arxiv.org/abs/2108.13650",
    "authors": [
      "Zezhi Shao",
      "Yongjun Xu",
      "Wei Wei",
      "Fei Wang",
      "Zhao Zhang",
      "Feida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2109.08958",
    "title": "AutoInit: Analytic Signal-Preserving Weight Initialization for Neural  Networks",
    "abstract": " Comments: To appear in AAAI 2023. 19 pages, 10 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2109.08958",
    "authors": [
      "Garrett Bingham",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.00944",
    "title": "Kalman Bayesian Neural Networks for Closed-form Online Learning",
    "abstract": " Comments: 37th AAAI Conference on Artificial Intelligence (AAAI) ",
    "url": "https://arxiv.org/abs/2110.00944",
    "authors": [
      "Philipp Wagner",
      "Xinyang Wu",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.14476",
    "title": "An Arbitrary Scale Super-Resolution Approach for 3D MR Images via  Implicit Neural Representation",
    "abstract": " Comments: 12 pagee, acceted by IEEE J-BHI ",
    "url": "https://arxiv.org/abs/2110.14476",
    "authors": [
      "Qing Wu",
      "Yuwei Li",
      "Yawen Sun",
      "Yan Zhou",
      "Hongjiang Wei",
      "Jingyi Yu",
      "Yuyao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01773",
    "title": "Adaptive Zeroing-Type Neural Dynamics for Solving Quadratic Minimization  and Applied to Target Tracking",
    "abstract": " Comments: 24 pages, 25 figures ",
    "url": "https://arxiv.org/abs/2112.01773",
    "authors": [
      "Huiting He",
      "Chengze Jiang",
      "Yudong Zhang",
      "Xiuchun Xiao",
      "Zhiyuan Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.08806",
    "title": "Dataset correlation inference attacks against machine learning models",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2112.08806",
    "authors": [
      "Ana-Maria Cre\u0163u",
      "Florent Gu\u00e9pin",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2201.08984",
    "title": "PiCO+: Contrastive Label Disambiguation for Robust Partial Label  Learning",
    "abstract": " Comments: Extended version of the ICLR 2022 paper PiCO; see this https URL ",
    "url": "https://arxiv.org/abs/2201.08984",
    "authors": [
      "Haobo Wang",
      "Ruixuan Xiao",
      "Yixuan Li",
      "Lei Feng",
      "Gang Niu",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.10047",
    "title": "Are Commercial Face Detection Models as Biased as Academic Models?",
    "abstract": " Comments: This preprint and arXiv:2108.12508 were combined and a more rigorous analysis added to result in the NeurIPS Datasets & Benchmark 2022 paper arXiv:2211.15937 ",
    "url": "https://arxiv.org/abs/2201.10047",
    "authors": [
      "Samuel Dooley",
      "George Z. Wei",
      "Tom Goldstein",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.12741",
    "title": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "abstract": " Comments: Published as a conference paper at LoG 2020 ",
    "url": "https://arxiv.org/abs/2201.12741",
    "authors": [
      "Chenhui Deng",
      "Xiuyu Li",
      "Zhuo Feng",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15756",
    "title": "Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data",
    "abstract": " Title: Causal de Finetti: On the Identification of Invariant Causal Structure  in Exchangeable Data ",
    "url": "https://arxiv.org/abs/2203.15756",
    "authors": [
      "Siyuan Guo",
      "Viktor T\u00f3th",
      "Bernhard Sch\u00f6lkopf",
      "Ferenc Husz\u00e1r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2204.00071",
    "title": "Numerical Solution of the Steady-State Network Flow Equations for a  Non-Ideal Gas",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2204.00071",
    "authors": [
      "Shriram Srinivasan",
      "Kaarthik Sundar",
      "Vitaliy Gyrya",
      "Anatoly Zlotnik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.01584",
    "title": "Synthesizing Attack-Aware Control and Active Sensing Strategies under  Reactive Sensor Attacks",
    "abstract": " Comments: 7 pages, 3 figure, 1 table, 1 algorithm ",
    "url": "https://arxiv.org/abs/2204.01584",
    "authors": [
      "Sumukha Udupa",
      "Abhishek N. Kulkarni",
      "Shuo Han",
      "Nandi O. Leslie",
      "Charles A. Kamhoua",
      "Jie Fu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.06240",
    "title": "CowClip: Reducing CTR Prediction Model Training Time from 12 hours to 10  minutes on 1 GPU",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2204.06240",
    "authors": [
      "Zangwei Zheng",
      "Pengtai Xu",
      "Xuan Zou",
      "Da Tang",
      "Zhen Li",
      "Chenguang Xi",
      "Peng Wu",
      "Leqi Zou",
      "Yijie Zhu",
      "Ming Chen",
      "Xiangzhuo Ding",
      "Fuzhao Xue",
      "Ziheng Qin",
      "Youlong Cheng",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2204.10037",
    "title": "DropMessage: Unifying Random Dropping for Graph Neural Networks",
    "abstract": " Title: DropMessage: Unifying Random Dropping for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2204.10037",
    "authors": [
      "Taoran Fang",
      "Zhiqing Xiao",
      "Chunping Wang",
      "Jiarong Xu",
      "Xuan Yang",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.10070",
    "title": "Multi-UAV trajectory planning for 3D visual inspection of complex  structures",
    "abstract": " Comments: Revised version, final fixes and improvements, 17 pages ",
    "url": "https://arxiv.org/abs/2204.10070",
    "authors": [
      "Stefan Ivi\u0107",
      "Bojan Crnkovi\u0107",
      "Luka Grb\u010di\u0107",
      "Lea Matlekovi\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach",
    "abstract": " Title: Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach ",
    "url": "https://arxiv.org/abs/2205.01420",
    "authors": [
      "Marco Bernardo",
      "Claudio Antares Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": " Title: Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation ",
    "url": "https://arxiv.org/abs/2205.09389",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.10683",
    "title": "Scalable and Efficient Training of Large Convolutional Neural Networks  with Differential Privacy",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.10683",
    "authors": [
      "Zhiqi Bu",
      "Jialin Mao",
      "Shiyun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC - Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": " Title: ARC - Actor Residual Critic for Adversarial Imitation Learning ",
    "url": "https://arxiv.org/abs/2206.02095",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.02777",
    "title": "Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation",
    "abstract": " Title: Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation ",
    "url": "https://arxiv.org/abs/2206.02777",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Huaizhe xu",
      "Shilong Liu",
      "Lei Zhang",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.03211",
    "title": "Variational Meta Reinforcement Learning for Social Robotics",
    "abstract": " Comments: 16 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2206.03211",
    "authors": [
      "Anand Ballou",
      "Xavier Alameda-Pineda",
      "Chris Reinke"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03776",
    "title": "Circuit Privacy and Novel Protocols for Semi-Honest Three-Party Secure  Multiparty Computation with an Honest Majority",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2206.03776",
    "authors": [
      "Christopher Harth-Kitzerow"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07729",
    "title": "Taxonomy of Benchmarks in Graph Representation Learning",
    "abstract": " Comments: In Proceedings of the First Learning on Graphs Conference (LoG 2022) ",
    "url": "https://arxiv.org/abs/2206.07729",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Sarah McGuire",
      "Xinyi Wang",
      "Anna Little",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10092",
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object  Detection",
    "abstract": " Comments: Accepted by AAAI2023 ",
    "url": "https://arxiv.org/abs/2206.10092",
    "authors": [
      "Yinhao Li",
      "Zheng Ge",
      "Guanyi Yu",
      "Jinrong Yang",
      "Zengran Wang",
      "Yukang Shi",
      "Jianjian Sun",
      "Zeming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12556",
    "title": "Graph Component Contrastive Learning for Concept Relatedness Estimation",
    "abstract": " Comments: 7 pages, Accepted to AAAI23, Github: this https URL ",
    "url": "https://arxiv.org/abs/2206.12556",
    "authors": [
      "Yueen Ma",
      "Zixing Song",
      "Xuming Hu",
      "Jingjing Li",
      "Yifei Zhang",
      "Irwin King"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": " Comments: 18 pages (including 8 pages Appendix), 8 figures and 6 tables. v4: Final version with reviewers' comments included, to appear in AAAI-23 (up to formatting differences) ",
    "url": "https://arxiv.org/abs/2206.14282",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07883",
    "title": "Neural modal ordinary differential equations: Integrating physics-based  modeling with neural ordinary differential equations for modeling  high-dimensional monitored structures",
    "abstract": " Comments: Accepted for publication in Data-Centric Engineering ",
    "url": "https://arxiv.org/abs/2207.07883",
    "authors": [
      "Zhilu Lai",
      "Wei Liu",
      "Xudong Jian",
      "Kiran Bacsa",
      "Limin Sun",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2207.13798",
    "title": "Look at Adjacent Frames: Video Anomaly Detection without Offline  Training",
    "abstract": " Comments: Accepted in ECCV 2022 RWS ",
    "url": "https://arxiv.org/abs/2207.13798",
    "authors": [
      "Yuqi Ouyang",
      "Guodong Shen",
      "Victor Sanchez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07448",
    "title": "Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs:  Application to Seizure Analysis",
    "abstract": " Comments: 9 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2208.07448",
    "authors": [
      "Thi Kieu Khanh Ho",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.08133",
    "title": "Metric Residual Networks for Sample Efficient Goal-Conditioned  Reinforcement Learning",
    "abstract": " Comments: Goal-conditioned reinforcement learning, neural architecture design ",
    "url": "https://arxiv.org/abs/2208.08133",
    "authors": [
      "Bo Liu",
      "Yihao Feng",
      "Qiang Liu",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.08268",
    "title": "Prediction of Oral Food Challenge Outcomes via Ensemble Learning",
    "abstract": " Title: Prediction of Oral Food Challenge Outcomes via Ensemble Learning ",
    "url": "https://arxiv.org/abs/2208.08268",
    "authors": [
      "Justin Zhang",
      "Deborah Lee",
      "Kylie Jungles",
      "Diane Shaltis",
      "Kayvan Najarian",
      "Rajan Ravikumar",
      "Georgiana Sanders",
      "Jonathan Gryak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10162",
    "title": "Unscented Kalman filter with stable embedding for simple, accurate and  computationally efficient state estimation of systems on manifolds in  Euclidean space",
    "abstract": " Comments: This paper is published in International Journal of Robust and Nonliner Control ",
    "url": "https://arxiv.org/abs/2208.10162",
    "authors": [
      "Jae-Hyeon Park",
      "Dong Eui Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.08064",
    "title": "A Systematic Evaluation of Node Embedding Robustness",
    "abstract": " Title: A Systematic Evaluation of Node Embedding Robustness ",
    "url": "https://arxiv.org/abs/2209.08064",
    "authors": [
      "Alexandru Mara",
      "Jefrey Lijffijt",
      "Stephan G\u00fcnnemann",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.10271",
    "title": "Analyzing Social Media Activities at Bellingcat",
    "abstract": " Title: Analyzing Social Media Activities at Bellingcat ",
    "url": "https://arxiv.org/abs/2209.10271",
    "authors": [
      "Dominik B\u00e4r",
      "Fausto Calderon",
      "Michael Lawlor",
      "Sophia Licklederer",
      "Manuel Totzauer",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.13812",
    "title": "Universal Policy Tracking: Scheduling for Wireless Networks with Delayed  State Observation",
    "abstract": " Title: Universal Policy Tracking: Scheduling for Wireless Networks with Delayed  State Observation ",
    "url": "https://arxiv.org/abs/2209.13812",
    "authors": [
      "Bai Liu",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.07996",
    "title": "Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions",
    "abstract": " Title: Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions ",
    "url": "https://arxiv.org/abs/2210.07996",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.13371",
    "title": "Time-Varying ALIP Model and Robust Foot-Placement Control for  Underactuated Bipedal Robot Walking on a Swaying Rigid Surface",
    "abstract": " Title: Time-Varying ALIP Model and Robust Foot-Placement Control for  Underactuated Bipedal Robot Walking on a Swaying Rigid Surface ",
    "url": "https://arxiv.org/abs/2210.13371",
    "authors": [
      "Yuan Gao",
      "Yukai Gong",
      "Victor Paredes",
      "Ayonga Hereid",
      "Yan Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.15068",
    "title": "Improving Adversarial Robustness with Self-Paced Hard-Class Pair  Reweighting",
    "abstract": " Comments: AAAI-23 ",
    "url": "https://arxiv.org/abs/2210.15068",
    "authors": [
      "Pengyue Hou",
      "Jie Han",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.02050",
    "title": "Adaptive Batch Normalization for Training Data with Heterogeneous  Features",
    "abstract": " Comments: 6 pages,6 figures ",
    "url": "https://arxiv.org/abs/2211.02050",
    "authors": [
      "Wael Alsobhi",
      "Tarik Alafif",
      "Alaa Abdel-Hakim",
      "Weiwei Zong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.07263",
    "title": "Efficient Adversarial Training with Robust Early-Bird Tickets",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2211.07263",
    "authors": [
      "Zhiheng Xi",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.10866",
    "title": "Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods",
    "abstract": " Title: Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods ",
    "url": "https://arxiv.org/abs/2211.10866",
    "authors": [
      "Venkatachalam Natchiappan",
      "Shrihari Vasudevan",
      "Thalanayar Muthukumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.12850",
    "title": "OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries",
    "abstract": " Title: OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries ",
    "url": "https://arxiv.org/abs/2211.12850",
    "authors": [
      "Shikhar Jaiswal",
      "Ravishankar Krishnaswamy",
      "Ankit Garg",
      "Harsha Vardhan Simhadri",
      "Sheshansh Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.13523",
    "title": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "abstract": " Title: Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark ",
    "url": "https://arxiv.org/abs/2211.13523",
    "authors": [
      "Floriana Ciaglia",
      "Francesco Saverio Zuppichini",
      "Paul Guerrie",
      "Mark McQuade",
      "Jacob Solawetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14406",
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": " Comments: Accepted to AAAI2023 ",
    "url": "https://arxiv.org/abs/2211.14406",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Anna Hambitzer",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.14521",
    "title": "Robust One-shot Segmentation of Brain Tissues via Image-aligned Style  Transformation",
    "abstract": " Comments: Accepted by AAAI-2023 ",
    "url": "https://arxiv.org/abs/2211.14521",
    "authors": [
      "Jinxin Lv",
      "Xiaoyu Zeng",
      "Sheng Wang",
      "Ran Duan",
      "Zhiwei Wang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14753",
    "title": "A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types",
    "abstract": " Title: A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types ",
    "url": "https://arxiv.org/abs/2211.14753",
    "authors": [
      "Zhenhao Shuai",
      "Hongbo Liu",
      "Zhaolin Wan",
      "Wei-Jie Yu",
      "Jun Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15516",
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and  Grounding",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.15516",
    "authors": [
      "Shilong Liu",
      "Yaoyuan Liang",
      "Feng Li",
      "Shijia Huang",
      "Hao Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15557",
    "title": "Beyond CAGE: Investigating Generalization of Learned Autonomous Network  Defense Policies",
    "abstract": " Comments: NeurIPS 2022 Workshop: Reinforcement Learning for Real Life ",
    "url": "https://arxiv.org/abs/2211.15557",
    "authors": [
      "Melody Wolk",
      "Andy Applebaum",
      "Camron Dennler",
      "Patrick Dwyer",
      "Marina Moskowitz",
      "Harold Nguyen",
      "Nicole Nichols",
      "Nicole Park",
      "Paul Rachwalski",
      "Frank Rau",
      "Adrian Webster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.15728",
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in  Marketing",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.15728",
    "authors": [
      "Hao Zhou",
      "Shaoming Li",
      "Guibin Jiang",
      "Jiaqi Zheng",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.15977",
    "title": "One is All: Bridging the Gap Between Neural Radiance Fields  Architectures with Progressive Volume Distillation",
    "abstract": " Comments: Accepted by AAAI2023. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2211.15977",
    "authors": [
      "Shuangkang Fang",
      "Weixin Xu",
      "Heng Wang",
      "Yi Yang",
      "Yufeng Wang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16010",
    "title": "Graph Search based Polar Code Design",
    "abstract": " Comments: 5 pages, 8 figures, accepted to the 2022 Asilomar Conference on Signals, Systems, and Computers ",
    "url": "https://arxiv.org/abs/2211.16010",
    "authors": [
      "Marvin Geiselhart",
      "Andreas Zunker",
      "Ahmed Elkelesh",
      "Jannis Clausius",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.16335",
    "title": "X-ICP: Localizability-Aware LiDAR Registration for Robust Localization  in Extreme Environments",
    "abstract": " Comments: 17 Pages, 17 Figures Submitted to IEEE Transactions On Robotics. Supplementary Video: this https URL Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2211.16335",
    "authors": [
      "Turcan Tuna",
      "Julian Nubert",
      "Yoshua Nava",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.16367",
    "title": "Optimisation of a global climate model ensemble for prediction of  extreme heat days",
    "abstract": " Title: Optimisation of a global climate model ensemble for prediction of  extreme heat days ",
    "url": "https://arxiv.org/abs/2211.16367",
    "authors": [
      "Mala Virdee",
      "Markus Kaiser",
      "Emily Shuckburgh",
      "Carl Henrik Ek",
      "Ieva Kazlauskaite"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16398",
    "title": "Self-Supervised Mental Disorder Classifiers via Time Reversal",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2211.16398",
    "authors": [
      "Zafar Iqbal",
      "Usman Mahmood",
      "Zening Fu",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]