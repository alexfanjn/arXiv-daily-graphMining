[
  {
    "id": "arXiv:2304.03778",
    "title": "Conformal Regression in Calorie Prediction for Team Jumbo-Visma",
    "abstract": "UCI WorldTour races, the premier men's elite road cycling tour, are grueling events that put riders' physical fitness and endurance to the test. The coaches of Team Jumbo-Visma have long been responsible for predicting the energy needs of each rider of the Dutch team for every race on the calendar. Those must be estimated to ensure riders have the energy and resources necessary to maintain a high level of performance throughout a race. This task, however, is both time-consuming and challenging, as it requires precise estimates of race speed and power output. Traditionally, the approach to predicting energy needs has relied on coaches' judgement and experience, but this method has its limitations and often leads to inaccurate predictions. In this paper, we propose a new, more effective approach to predicting energy needs for cycling races. By predicting the speed and power with regression models, we provide the coaches with calorie needs estimate for each individual rider per stage instantly. In addition, we compare methods to quantify uncertainty in estimating the speed and power of Team Jumbo-Visma riders for cycling races. The empirical analysis of the jackknife+, jackknife-minmax, jackknife-minmax-after-bootstrap, CV+, CV-minmax, conformalized quantile regression (CQR) and inductive conformal prediction (ICP) methods in conformal prediction reveals all methods except minmax based methods achieve valid prediction intervals while producing prediction intervals tight enough to be used for decision making. Furthermore, methods computing prediction intervals of fixed size produce significantly tighter intervals for low significance value. Among the methods computing intervals of varying length across the input space, namely the CQR and ICP methods, ICP computes tighter prediction intervals at larger significance level. ",
    "url": "https://arxiv.org/abs/2304.03778",
    "authors": [
      "Kristian van Kuijk",
      "Mark Dirksen",
      "Christof Seiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2304.03779",
    "title": "A roadmap to fair and trustworthy prediction model validation in  healthcare",
    "abstract": "A prediction model is most useful if it generalizes beyond the development data with external validations, but to what extent should it generalize remains unclear. In practice, prediction models are externally validated using data from very different settings, including populations from other health systems or countries, with predictably poor results. This may not be a fair reflection of the performance of the model which was designed for a specific target population or setting, and may be stretching the expected model generalizability. To address this, we suggest to externally validate a model using new data from the target population to ensure clear implications of validation performance on model reliability, whereas model generalizability to broader settings should be carefully investigated during model development instead of explored post-hoc. Based on this perspective, we propose a roadmap that facilitates the development and application of reliable, fair, and trustworthy artificial intelligence prediction models. ",
    "url": "https://arxiv.org/abs/2304.03779",
    "authors": [
      "Yilin Ning",
      "Victor Volovici",
      "Marcus Eng Hock Ong",
      "Benjamin Alan Goldstein",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.03782",
    "title": "AutoQNN: An End-to-End Framework for Automatically Quantizing Neural  Networks",
    "abstract": "Exploring the expected quantizing scheme with suitable mixed-precision policy is the key point to compress deep neural networks (DNNs) in high efficiency and accuracy. This exploration implies heavy workloads for domain experts, and an automatic compression method is needed. However, the huge search space of the automatic method introduces plenty of computing budgets that make the automatic process challenging to be applied in real scenarios. In this paper, we propose an end-to-end framework named AutoQNN, for automatically quantizing different layers utilizing different schemes and bitwidths without any human labor. AutoQNN can seek desirable quantizing schemes and mixed-precision policies for mainstream DNN models efficiently by involving three techniques: quantizing scheme search (QSS), quantizing precision learning (QPL), and quantized architecture generation (QAG). QSS introduces five quantizing schemes and defines three new schemes as a candidate set for scheme search, and then uses the differentiable neural architecture search (DNAS) algorithm to seek the layer- or model-desired scheme from the set. QPL is the first method to learn mixed-precision policies by reparameterizing the bitwidths of quantizing schemes, to the best of our knowledge. QPL optimizes both classification loss and precision loss of DNNs efficiently and obtains the relatively optimal mixed-precision model within limited model size and memory footprint. QAG is designed to convert arbitrary architectures into corresponding quantized ones without manual intervention, to facilitate end-to-end neural network quantization. We have implemented AutoQNN and integrated it into Keras. Extensive experiments demonstrate that AutoQNN can consistently outperform state-of-the-art quantization. ",
    "url": "https://arxiv.org/abs/2304.03782",
    "authors": [
      "Cheng Gong",
      "Ye Lu",
      "Surong Dai",
      "Deng Qian",
      "Chenkun Du",
      "Tao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03797",
    "title": "Bridging Nations: Quantifying the Role of Multilinguals in Communication  on Social Media",
    "abstract": "Social media enables the rapid spread of many kinds of information, from memes to social movements. However, little is known about how information crosses linguistic boundaries. We apply causal inference techniques on the European Twitter network to quantify multilingual users' structural role and communication influence in cross-lingual information exchange. Overall, multilinguals play an essential role; posting in multiple languages increases betweenness centrality by 13%, and having a multilingual network neighbor increases monolinguals' odds of sharing domains and hashtags from another language 16-fold and 4-fold, respectively. We further show that multilinguals have a greater impact on diffusing information less accessible to their monolingual compatriots, such as information from far-away countries and content about regional politics, nascent social movements, and job opportunities. By highlighting information exchange across borders, this work sheds light on a crucial component of how information and ideas spread around the world. ",
    "url": "https://arxiv.org/abs/2304.03797",
    "authors": [
      "Julia Mendelsohn",
      "Sayan Ghosh",
      "David Jurgens",
      "Ceren Budak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.03805",
    "title": "Correcting Model Misspecification via Generative Adversarial Networks",
    "abstract": "Machine learning models are often misspecified in the likelihood, which leads to a lack of robustness in the predictions. In this paper, we introduce a framework for correcting likelihood misspecifications in several paradigm agnostic noisy prior models and test the model's ability to remove the misspecification. The \"ABC-GAN\" framework introduced is a novel generative modeling paradigm, which combines Generative Adversarial Networks (GANs) and Approximate Bayesian Computation (ABC). This new paradigm assists the existing GANs by incorporating any subjective knowledge available about the modeling process via ABC, as a regularizer, resulting in a partially interpretable model that operates well under low data regimes. At the same time, unlike any Bayesian analysis, the explicit knowledge need not be perfect, since the generator in the GAN can be made arbitrarily complex. ABC-GAN eliminates the need for summary statistics and distance metrics as the discriminator implicitly learns them and enables simultaneous specification of multiple generative models. The model misspecification is simulated in our experiments by introducing noise of various biases and variances. The correction term is learnt via the ABC-GAN, with skip connections, referred to as skipGAN. The strength of the skip connection indicates the amount of correction needed or how misspecified the prior model is. Based on a simple experimental setup, we show that the ABC-GAN models not only correct the misspecification of the prior, but also perform as well as or better than the respective priors under noisier conditions. In this proposal, we show that ABC-GANs get the best of both worlds. ",
    "url": "https://arxiv.org/abs/2304.03805",
    "authors": [
      "Pronoma Banerjee",
      "Manasi V Gude",
      "Rajvi J Sampat",
      "Sharvari M Hedaoo",
      "Soma Dhavala",
      "Snehanshu Saha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03810",
    "title": "On Testability of First-Order Properties in Bounded-Degree Graphs and  Connections to Proximity-Oblivious Testing",
    "abstract": "We study property testing of properties that are definable in first-order logic (FO) in the bounded-degree graph and relational structure models. We show that any FO property that is defined by a formula with quantifier prefix $\\exists^*\\forall^*$ is testable (i.e., testable with constant query complexity), while there exists an FO property that is expressible by a formula with quantifier prefix $\\forall^*\\exists^*$ that is not testable. In the dense graph model, a similar picture is long known (Alon, Fischer, Krivelevich, Szegedy, Combinatorica 2000), despite the very different nature of the two models. In particular, we obtain our lower bound by an FO formula that defines a class of bounded-degree expanders, based on zig-zag products of graphs. We expect this to be of independent interest. We then use our class of FO definable bounded-degree expanders to answer a long-standing open problem for proximity-oblivious testers (POTs). POTs are a class of particularly simple testing algorithms, where a basic test is performed a number of times that may depend on the proximity parameter, but the basic test itself is independent of the proximity parameter. In their seminal work, Goldreich and Ron [STOC 2009; SICOMP 2011] show that the graph properties that are constant-query proximity-oblivious testable in the bounded-degree model are precisely the properties that can be expressed as a generalised subgraph freeness (GSF) property that satisfies the non-propagation condition. It is left open whether the non-propagation condition is necessary. We give a negative answer by showing that our property is a GSF property which is propagating. Hence in particular, our property does not admit a POT. For this result we establish a new connection between FO properties and GSF-local properties via neighbourhood profiles. ",
    "url": "https://arxiv.org/abs/2304.03810",
    "authors": [
      "Isolde Adler",
      "Noleen K\u00f6hler",
      "Pan Peng"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2304.03812",
    "title": "High-order Spatial Interactions Enhanced Lightweight Model for Optical  Remote Sensing Image-based Small Ship Detection",
    "abstract": "Accurate and reliable optical remote sensing image-based small-ship detection is crucial for maritime surveillance systems, but existing methods often struggle with balancing detection performance and computational complexity. In this paper, we propose a novel lightweight framework called \\textit{HSI-ShipDetectionNet} that is based on high-order spatial interactions and is suitable for deployment on resource-limited platforms, such as satellites and unmanned aerial vehicles. HSI-ShipDetectionNet includes a prediction branch specifically for tiny ships and a lightweight hybrid attention block for reduced complexity. Additionally, the use of a high-order spatial interactions module improves advanced feature understanding and modeling ability. Our model is evaluated using the public Kaggle marine ship detection dataset and compared with multiple state-of-the-art models including small object detection models, lightweight detection models, and ship detection models. The results show that HSI-ShipDetectionNet outperforms the other models in terms of recall, and mean average precision (mAP) while being lightweight and suitable for deployment on resource-limited platforms. ",
    "url": "https://arxiv.org/abs/2304.03812",
    "authors": [
      "Yifan Yin",
      "Xu Cheng",
      "Fan Shi",
      "Xiufeng Liu",
      "Huan Huo",
      "Shengyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03815",
    "title": "Policy Poisoning in Batch Learning for Linear Quadratic Control Systems  via State Manipulation",
    "abstract": "In this work, we study policy poisoning through state manipulation, also known as sensor spoofing, and focus specifically on the case of an agent forming a control policy through batch learning in a linear-quadratic (LQ) system. In this scenario, an attacker aims to trick the learner into implementing a targeted malicious policy by manipulating the batch data before the agent begins its learning process. An attack model is crafted to carry out the poisoning strategically, with the goal of modifying the batch data as little as possible to avoid detection by the learner. We establish an optimization framework to guide the design of such policy poisoning attacks. The presence of bi-linear constraints in the optimization problem requires the design of a computationally efficient algorithm to obtain a solution. Therefore, we develop an iterative scheme based on the Alternating Direction Method of Multipliers (ADMM) which is able to return solutions that are approximately optimal. Several case studies are used to demonstrate the effectiveness of the algorithm in carrying out the sensor-based attack on the batch-learning agent in LQ control systems. ",
    "url": "https://arxiv.org/abs/2304.03815",
    "authors": [
      "Courtney M. King",
      "Son Tung Do",
      "Juntao Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.03816",
    "title": "Towards Generating Functionally Correct Code Edits from Natural Language  Issue Descriptions",
    "abstract": "Large language models (LLMs), such as OpenAI's Codex, have demonstrated their potential to generate code from natural language descriptions across a wide range of programming tasks. Several benchmarks have recently emerged to evaluate the ability of LLMs to generate functionally correct code from natural language intent with respect to a set of hidden test cases. This has enabled the research community to identify significant and reproducible advancements in LLM capabilities. However, there is currently a lack of benchmark datasets for assessing the ability of LLMs to generate functionally correct code edits based on natural language descriptions of intended changes. This paper aims to address this gap by motivating the problem NL2Fix of translating natural language descriptions of code changes (namely bug fixes described in Issue reports in repositories) into correct code fixes. To this end, we introduce Defects4J-NL2Fix, a dataset of 283 Java programs from the popular Defects4J dataset augmented with high-level descriptions of bug fixes, and empirically evaluate the performance of several state-of-the-art LLMs for the this task. Results show that these LLMS together are capable of generating plausible fixes for 64.6% of the bugs, and the best LLM-based technique can achieve up to 21.20% top-1 and 35.68% top-5 accuracy on this benchmark. ",
    "url": "https://arxiv.org/abs/2304.03816",
    "authors": [
      "Sarah Fakhoury",
      "Saikat Chakraborty",
      "Madan Musuvathi",
      "Shuvendu K. Lahiri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03828",
    "title": "TDANetVis: Suggesting temporal resolutions for graph visualization using  zigzag persistent homology",
    "abstract": "Temporal graphs are commonly used to represent complex systems and track the evolution of their constituents over time. Visualizing these graphs is crucial as it allows one to quickly identify anomalies, trends, patterns, and other properties leading to better decision-making. In this context, the to-be-adopted temporal resolution is crucial in constructing and analyzing the layout visually. The choice of a resolution is critical, e.g., when dealing with temporally sparse graphs. In such cases, changing the temporal resolution by grouping events (i.e., edges) from consecutive timestamps, a technique known as timeslicing, can aid in the analysis and reveal patterns that might not be discernible otherwise. However, choosing a suitable temporal resolution is not trivial. In this paper, we propose TDANetVis, a methodology that suggests temporal resolutions potentially relevant for analyzing a given graph, i.e., resolutions that lead to substantial topological changes in the graph structure. To achieve this goal, TDANetVis leverages zigzag persistent homology, a well-established technique from Topological Data Analysis (TDA). To enhance visual graph analysis, TDANetVis also incorporates the colored barcode, a novel timeline-based visualization built on the persistence barcodes commonly used in TDA. We demonstrate the usefulness and effectiveness of TDANetVis through a usage scenario and a user study involving 27 participants. ",
    "url": "https://arxiv.org/abs/2304.03828",
    "authors": [
      "Rapha\u00ebl Tinarrage",
      "Jean R. Ponciano",
      "Claudio D. G. Linhares",
      "Agma J. M. Traina",
      "Jorge Poco"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2304.03844",
    "title": "Multilingual Augmentation for Robust Visual Question Answering in Remote  Sensing Images",
    "abstract": "Aiming at answering questions based on the content of remotely sensed images, visual question answering for remote sensing data (RSVQA) has attracted much attention nowadays. However, previous works in RSVQA have focused little on the robustness of RSVQA. As we aim to enhance the reliability of RSVQA models, how to learn robust representations against new words and different question templates with the same meaning is the key challenge. With the proposed augmented dataset, we are able to obtain more questions in addition to the original ones with the same meaning. To make better use of this information, in this study, we propose a contrastive learning strategy for training robust RSVQA models against diverse question templates and words. Experimental results demonstrate that the proposed augmented dataset is effective in improving the robustness of the RSVQA model. In addition, the contrastive learning strategy performs well on the low resolution (LR) dataset. ",
    "url": "https://arxiv.org/abs/2304.03844",
    "authors": [
      "Zhenghang Yuan",
      "Lichao Mou",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03849",
    "title": "Lipschitz Continuity of Signal Temporal Logic Robustness Measures:  Synthesizing Control Barrier Functions from One Expert Demonstration",
    "abstract": "Control Barrier Functions (CBFs) allow for efficient synthesis of controllers to maintain desired invariant properties of safety-critical systems. However, the problem of identifying a CBF remains an open question. As such, this paper provides a constructive method for control barrier function synthesis around one expert demonstration that realizes a desired system specification formalized in Signal Temporal Logic (STL). First, we prove that all STL specifications have Lipschitz-continuous robustness measures. Second, we leverage this Lipschitz continuity to synthesize a time-varying control barrier function. By filtering control inputs to maintain the positivity of this function, we ensure that the system trajectory satisfies the desired STL specification. Finally, we demonstrate the effectiveness of our approach on the Robotarium. ",
    "url": "https://arxiv.org/abs/2304.03849",
    "authors": [
      "Prithvi Akella",
      "Apurva Badithela",
      "Richard M. Murray",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.03864",
    "title": "SGDP: A Stream-Graph Neural Network Based Data Prefetcher",
    "abstract": "Data prefetching is important for storage system optimization and access performance improvement. Traditional prefetchers work well for mining access patterns of sequential logical block address (LBA) but cannot handle complex non-sequential patterns that commonly exist in real-world applications. The state-of-the-art (SOTA) learning-based prefetchers cover more LBA accesses. However, they do not adequately consider the spatial interdependencies between LBA deltas, which leads to limited performance and robustness. This paper proposes a novel Stream-Graph neural network-based Data Prefetcher (SGDP). Specifically, SGDP models LBA delta streams using a weighted directed graph structure to represent interactive relations among LBA deltas and further extracts hybrid features by graph neural networks for data prefetching. We conduct extensive experiments on eight real-world datasets. Empirical results verify that SGDP outperforms the SOTA methods in terms of the hit ratio by 6.21%, the effective prefetching ratio by 7.00%, and speeds up inference time by 3.13X on average. Besides, we generalize SGDP to different variants by different stream constructions, further expanding its application scenarios and demonstrating its robustness. SGDP offers a novel data prefetching solution and has been verified in commercial hybrid storage systems in the experimental phase. Our codes and appendix are available at https://github.com/yyysjz1997/SGDP/. ",
    "url": "https://arxiv.org/abs/2304.03864",
    "authors": [
      "Yiyuan Yang",
      "Rongshang Li",
      "Qiquan Shi",
      "Xijun Li",
      "Gang Hu",
      "Xing Li",
      "Mingxuan Yuan"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03870",
    "title": "ASPEST: Bridging the Gap Between Active Learning and Selective  Prediction",
    "abstract": "Selective prediction aims to learn a reliable model that abstains from making predictions when the model uncertainty is high. These predictions can then be deferred to a human expert for further evaluation. In many real-world scenarios, however, the distribution of test data is different from the training data. This results in more inaccurate predictions, necessitating increased human labeling, which is difficult and expensive in many scenarios. Active learning circumvents this difficulty by only querying the most informative examples and, in several cases, has been shown to lower the overall labeling effort. In this work, we bridge the gap between selective prediction and active learning, proposing a new learning paradigm called active selective prediction which learns to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new problem, we propose a simple but effective solution, ASPEST, that trains ensembles of model snapshots using self-training with their aggregated outputs as pseudo labels. Extensive experiments on several image, text and structured datasets with domain shifts demonstrate that active selective prediction can significantly outperform prior work on selective prediction and active learning (e.g. on the MNIST$\\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop. ",
    "url": "https://arxiv.org/abs/2304.03870",
    "authors": [
      "Jiefeng Chen",
      "Jinsung Yoon",
      "Sayna Ebrahimi",
      "Sercan Arik",
      "Somesh Jha",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03872",
    "title": "SGIDN-LCD: An Appearance-based Loop Closure Detection Algorithm using  Superpixel Grids and Incremental Dynamic Nodes",
    "abstract": "Loop Closure Detection (LCD) is an essential component of visual simultaneous localization and mapping (SLAM) systems. It enables the recognition of previously visited scenes to eliminate pose and map estimate drifts arising from long-term exploration. However, current appearance-based LCD methods face significant challenges, including high computational costs, viewpoint variance, and dynamic objects in scenes. This paper introduces an online based on Superpixel Grids (SGs) LCD approach, SGIDN-LCD, to find similarities between scenes via hand-crafted features extracted from SGs. Unlike traditional Bag-of-Words (BoW) models requiring pre-training, we propose an adaptive mechanism to group similar images called $\\textbf{\\textit{dynamic}}$ $\\textbf{\\textit{node}}$, which incremental adjusts the database in an online manner, allowing for efficient retrieval of previously viewed images. Experimental results demonstrate the SGIDN-LCD significantly improving LCD precision-recall and efficiency. Moreover, our proposed overall LCD method outperforms state-of-the-art approaches on multiple typical datasets. ",
    "url": "https://arxiv.org/abs/2304.03872",
    "authors": [
      "Baosheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.03896",
    "title": "Spiking Neural Networks for Detecting Satellite-Based Internet-of-Things  Signals",
    "abstract": "With the rapid growth of IoT networks, ubiquitous coverage is becoming increasingly necessary. Low Earth Orbit (LEO) satellite constellations for IoT have been proposed to provide coverage to regions where terrestrial systems cannot. However, LEO constellations for uplink communications are severely limited by the high density of user devices, which causes a high level of co-channel interference. This research presents a novel framework that utilizes spiking neural networks (SNNs) to detect IoT signals in the presence of uplink interference. The key advantage of SNNs is the extremely low power consumption relative to traditional deep learning (DL) networks. The performance of the spiking-based neural network detectors is compared against state-of-the-art DL networks and the conventional matched filter detector. Results indicate that both DL and SNN-based receivers surpass the matched filter detector in interference-heavy scenarios, owing to their capacity to effectively distinguish target signals amidst co-channel interference. Moreover, our work highlights the ultra-low power consumption of SNNs compared to other DL methods for signal detection. The strong detection performance and low power consumption of SNNs make them particularly suitable for onboard signal detection in IoT LEO satellites, especially in high interference conditions. ",
    "url": "https://arxiv.org/abs/2304.03896",
    "authors": [
      "Kosta Dakic",
      "Bassel Al Homssi",
      "Sumeet Walia",
      "Akram Al-Hourani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.03907",
    "title": "Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic  Embedding",
    "abstract": "Optimal control is notoriously difficult for stochastic nonlinear systems. Ren et al. introduced Spectral Dynamics Embedding for developing reinforcement learning methods for controlling an unknown system. It uses an infinite-dimensional feature to linearly represent the state-value function and exploits finite-dimensional truncation approximation for practical implementation. However, the finite-dimensional approximation properties in control have not been investigated even when the model is known. In this paper, we provide a tractable stochastic nonlinear control algorithm that exploits the nonlinear dynamics upon the finite-dimensional feature approximation, Spectral Dynamics Embedding Control (SDEC), with an in-depth theoretical analysis to characterize the approximation error induced by the finite-dimension truncation and statistical error induced by finite-sample approximation in both policy evaluation and policy optimization. We also empirically test the algorithm and compare the performance with Koopman-based methods and iLQR methods on the pendulum swingup problem. ",
    "url": "https://arxiv.org/abs/2304.03907",
    "authors": [
      "Tongzheng Ren",
      "Zhaolin Ren",
      "Na Li",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.03910",
    "title": "Co-attention Propagation Network for Zero-Shot Video Object Segmentation",
    "abstract": "Zero-shot video object segmentation (ZS-VOS) aims to segment foreground objects in a video sequence without prior knowledge of these objects. However, existing ZS-VOS methods often struggle to distinguish between foreground and background or to keep track of the foreground in complex scenarios. The common practice of introducing motion information, such as optical flow, can lead to overreliance on optical flow estimation. To address these challenges, we propose an encoder-decoder-based hierarchical co-attention propagation network (HCPN) capable of tracking and segmenting objects. Specifically, our model is built upon multiple collaborative evolutions of the parallel co-attention module (PCM) and the cross co-attention module (CCM). PCM captures common foreground regions among adjacent appearance and motion features, while CCM further exploits and fuses cross-modal motion features returned by PCM. Our method is progressively trained to achieve hierarchical spatio-temporal feature propagation across the entire video. Experimental results demonstrate that our HCPN outperforms all previous methods on public benchmarks, showcasing its effectiveness for ZS-VOS. ",
    "url": "https://arxiv.org/abs/2304.03910",
    "authors": [
      "Gensheng Pei",
      "Yazhou Yao",
      "Fumin Shen",
      "Dan Huang",
      "Xingguo Huang",
      "Heng-Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03935",
    "title": "Last-Layer Fairness Fine-tuning is Simple and Effective for Neural  Networks",
    "abstract": "As machine learning has been deployed ubiquitously across applications in modern data science, algorithmic fairness has become a great concern and varieties of fairness criteria have been proposed. Among them, imposing fairness constraints during learning, i.e. in-processing fair training, has been a popular type of training method because they don't require accessing sensitive attributes during test time in contrast to post-processing methods. Although imposing fairness constraints have been studied extensively for classical machine learning models, the effect these techniques have on deep neural networks is still unclear. Recent research has shown that adding fairness constraints to the objective function leads to severe over-fitting to fairness criteria in large models, and how to solve this challenge is an important open question. To address this challenge, we leverage the wisdom and power of pre-training and fine-tuning and develop a simple but novel framework to train fair neural networks in an efficient and inexpensive way. We conduct comprehensive experiments on two popular image datasets with state-of-art architectures under different fairness notions to show that last-layer fine-tuning is sufficient for promoting fairness of the deep neural network. Our framework brings new insights into representation learning in training fair neural networks. ",
    "url": "https://arxiv.org/abs/2304.03935",
    "authors": [
      "Yuzhen Mao",
      "Zhun Deng",
      "Huaxiu Yao",
      "Ting Ye",
      "Kenji Kawaguchi",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03938",
    "title": "Comparing Code Explanations Created by Students and Large Language  Models",
    "abstract": "Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course ($n \\approx 1000$) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education. ",
    "url": "https://arxiv.org/abs/2304.03938",
    "authors": [
      "Juho Leinonen",
      "Paul Denny",
      "Stephen MacNeil",
      "Sami Sarsa",
      "Seth Bernstein",
      "Joanne Kim",
      "Andrew Tran",
      "Arto Hellas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.03940",
    "title": "Unsupervised Speech Representation Pooling Using Vector Quantization",
    "abstract": "With the advent of general-purpose speech representations from large-scale self-supervised models, applying a single model to multiple downstream tasks is becoming a de-facto approach. However, the pooling problem remains; the length of speech representations is inherently variable. The naive average pooling is often used, even though it ignores the characteristics of speech, such as differently lengthed phonemes. Hence, we design a novel pooling method to squash acoustically similar representations via vector quantization, which does not require additional training, unlike attention-based pooling. Further, we evaluate various unsupervised pooling methods on various self-supervised models. We gather diverse methods scattered around speech and text to evaluate on various tasks: keyword spotting, speaker identification, intent classification, and emotion recognition. Finally, we quantitatively and qualitatively analyze our method, comparing it with supervised pooling methods. ",
    "url": "https://arxiv.org/abs/2304.03940",
    "authors": [
      "Jeongkyun Park",
      "Kwanghee Choi",
      "Hyunjun Heo",
      "Hyung-Min Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03945",
    "title": "Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction  Modeling for Neural Graph Forgetting Knowledge Tracing",
    "abstract": "Recently, knowledge tracing models have been applied in educational data mining such as the Self-attention knowledge tracing model(SAKT), which models the relationship between exercises and Knowledge concepts(Kcs). However, relation modeling in traditional Knowledge tracing models only considers the static question-knowledge relationship and knowledge-knowledge relationship and treats these relationships with equal importance. This kind of relation modeling is difficult to avoid the influence of subjective labeling and considers the relationship between exercises and KCs, or KCs and KCs separately. In this work, a novel knowledge tracing model, named Knowledge Relation Rank Enhanced Heterogeneous Learning Interaction Modeling for Neural Graph Forgetting Knowledge Tracing(NGFKT), is proposed to reduce the impact of the subjective labeling by calibrating the skill relation matrix and the Q-matrix and apply the Graph Convolutional Network(GCN) to model the heterogeneous interactions between students, exercises, and skills. Specifically, the skill relation matrix and Q-matrix are generated by the Knowledge Relation Importance Rank Calibration method(KRIRC). Then the calibrated skill relation matrix, Q-matrix, and the heterogeneous interactions are treated as the input of the GCN to generate the exercise embedding and skill embedding. Next, the exercise embedding, skill embedding, item difficulty, and contingency table are incorporated to generate an exercise relation matrix as the inputs of the Position-Relation-Forgetting attention mechanism. Finally, the Position-Relation-Forgetting attention mechanism is applied to make the predictions. Experiments are conducted on the two public educational datasets and results indicate that the NGFKT model outperforms all baseline models in terms of AUC, ACC, and Performance Stability(PS). ",
    "url": "https://arxiv.org/abs/2304.03945",
    "authors": [
      "Linqing Li",
      "Zhifeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03950",
    "title": "GANHead: Towards Generative Animatable Neural Head Avatars",
    "abstract": "To bring digital avatars into people's lives, it is highly demanded to efficiently generate complete, realistic, and animatable head avatars. This task is challenging, and it is difficult for existing methods to satisfy all the requirements at once. To achieve these goals, we propose GANHead (Generative Animatable Neural Head Avatar), a novel generative head model that takes advantages of both the fine-grained control over the explicit expression parameters and the realistic rendering results of implicit representations. Specifically, GANHead represents coarse geometry, fine-gained details and texture via three networks in canonical space to obtain the ability to generate complete and realistic head avatars. To achieve flexible animation, we define the deformation filed by standard linear blend skinning (LBS), with the learned continuous pose and expression bases and LBS weights. This allows the avatars to be directly animated by FLAME parameters and generalize well to unseen poses and expressions. Compared to state-of-the-art (SOTA) methods, GANHead achieves superior performance on head avatar generation and raw scan fitting. ",
    "url": "https://arxiv.org/abs/2304.03950",
    "authors": [
      "Sijing Wu",
      "Yichao Yan",
      "Yunhao Li",
      "Yuhao Cheng",
      "Wenhan Zhu",
      "Ke Gao",
      "Xiaobo Li",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03951",
    "title": "Shepherding Heterogeneous Flocks: Overview and Prospect",
    "abstract": "The problem of guiding a flock of several autonomous agents using repulsion force exerted by a smaller number of agents is called the shepherding problem and has been attracting attention due to its potential engineering applications. Although several works propose methodologies for achieving the shepherding task in this context, most assume that sheep agents have the same dynamics, which only sometimes holds in reality. The objective of this discussion paper is to overview a recent research trend addressing the gap mentioned above between the commonly placed uniformity assumption and the reality. Specifically, we first introduce recent guidance methods for heterogeneous flocks and then describe the prospects of the shepherding problem for heterogeneous flocks. ",
    "url": "https://arxiv.org/abs/2304.03951",
    "authors": [
      "Anna Fujioka",
      "Masaki Ogura",
      "Naoki Wakamiya"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.03955",
    "title": "Robust Deep Learning Models Against Semantic-Preserving Adversarial  Attack",
    "abstract": "Deep learning models can be fooled by small $l_p$-norm adversarial perturbations and natural perturbations in terms of attributes. Although the robustness against each perturbation has been explored, it remains a challenge to address the robustness against joint perturbations effectively. In this paper, we study the robustness of deep learning models against joint perturbations by proposing a novel attack mechanism named Semantic-Preserving Adversarial (SPA) attack, which can then be used to enhance adversarial training. Specifically, we introduce an attribute manipulator to generate natural and human-comprehensible perturbations and a noise generator to generate diverse adversarial noises. Based on such combined noises, we optimize both the attribute value and the diversity variable to generate jointly-perturbed samples. For robust training, we adversarially train the deep learning model against the generated joint perturbations. Empirical results on four benchmarks show that the SPA attack causes a larger performance decline with small $l_{\\infty}$ norm-ball constraints compared to existing approaches. Furthermore, our SPA-enhanced training outperforms existing defense methods against such joint perturbations. ",
    "url": "https://arxiv.org/abs/2304.03955",
    "authors": [
      "Dashan Gao",
      "Yunce Zhao",
      "Yinghua Yao",
      "Zeqi Zhang",
      "Bifei Mao",
      "Xin Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03957",
    "title": "A Continued Fraction-Hyperbola based Attack on RSA cryptosystem",
    "abstract": "In this paper we present new arithmetical and algebraic results following the work of Babindamana and al. on hyperbolas and describe from the new results an approach to attacking a RSA-type modulus based on continued fractions, independent and not bounded by the size of the private key $d$ nor public exponent $e$ compared to Wiener's attack. When successful, this attack is bounded by $\\displaystyle\\mathcal{O}\\left( b\\log{\\alpha_{j4}}\\log{(\\alpha_{i3}+\\alpha_{j3})}\\right)$ with $b=10^{y}$, $\\alpha_{i3}+\\alpha_{j3}$ a non trivial factor of $n$ and $\\alpha_{j4}$ such that $(n+1)/(n-1)=\\alpha_{i4}/\\alpha_{j4}$. The primary goal of this attack is to find a point $\\displaystyle X_{\\alpha}=\\left(-\\alpha_{3}, \\ \\alpha_{3}+1 \\right) \\in \\mathbb{Z}^{2}_{\\star}$ that satisfies $\\displaystyle\\left\\langle X_{\\alpha_{3}}, \\ P_{3} \\right\\rangle =0$ from a convergent of $\\displaystyle\\frac{\\alpha_{i4}}{\\alpha_{j4}}+\\delta$, with $P_{3}\\in \\mathcal{B}_{n}(x, y)_{\\mid_{x\\geq 4n}}$. We finally present some experimental examples. We believe these results constitute a new direction in RSA Cryptanalysis using continued fractions. ",
    "url": "https://arxiv.org/abs/2304.03957",
    "authors": [
      "Gilda Rech Bansimba",
      "Regis Freguin Babindamana",
      "Basile Guy R. Bossoto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ]
  },
  {
    "id": "arXiv:2304.03968",
    "title": "Benchmarking the Robustness of Quantized Models",
    "abstract": "Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. Extensive experiments demonstrate that lower-bit quantization is more resilient to adversarial attacks but is more susceptible to natural corruptions and systematic noises. Notably, our investigation reveals that impulse noise (in natural corruptions) and the nearest neighbor interpolation (in systematic noises) have the most significant impact on quantized models. Our research contributes to advancing the robust quantization of models and their deployment in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2304.03968",
    "authors": [
      "Yisong Xiao",
      "Tianyuan Zhang",
      "Shunchang Liu",
      "Haotong Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03973",
    "title": "RobCaps: Evaluating the Robustness of Capsule Networks against Affine  Transformations and Adversarial Attacks",
    "abstract": "Capsule Networks (CapsNets) are able to hierarchically preserve the pose relationships between multiple objects for image classification tasks. Other than achieving high accuracy, another relevant factor in deploying CapsNets in safety-critical applications is the robustness against input transformations and malicious adversarial attacks. In this paper, we systematically analyze and evaluate different factors affecting the robustness of CapsNets, compared to traditional Convolutional Neural Networks (CNNs). Towards a comprehensive comparison, we test two CapsNet models and two CNN models on the MNIST, GTSRB, and CIFAR10 datasets, as well as on the affine-transformed versions of such datasets. With a thorough analysis, we show which properties of these architectures better contribute to increasing the robustness and their limitations. Overall, CapsNets achieve better robustness against adversarial examples and affine transformations, compared to a traditional CNN with a similar number of parameters. Similar conclusions have been derived for deeper versions of CapsNets and CNNs. Moreover, our results unleash a key finding that the dynamic routing does not contribute much to improving the CapsNets' robustness. Indeed, the main generalization contribution is due to the hierarchical feature learning through capsules. ",
    "url": "https://arxiv.org/abs/2304.03973",
    "authors": [
      "Alberto Marchisio",
      "Antonio De Marco",
      "Alessio Colucci",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03977",
    "title": "EMP-SSL: Towards Self-Supervised Learning in One Training Epoch",
    "abstract": "Recently, self-supervised learning (SSL) has achieved tremendous success in learning image representation. Despite the empirical success, most self-supervised learning methods are rather \"inefficient\" learners, typically taking hundreds of training epochs to fully converge. In this work, we show that the key towards efficient self-supervised learning is to increase the number of crops from each image instance. Leveraging one of the state-of-the-art SSL method, we introduce a simplistic form of self-supervised learning method called Extreme-Multi-Patch Self-Supervised-Learning (EMP-SSL) that does not rely on many heuristic techniques for SSL such as weight sharing between the branches, feature-wise normalization, output quantization, and stop gradient, etc, and reduces the training epochs by two orders of magnitude. We show that the proposed method is able to converge to 85.1% on CIFAR-10, 58.5% on CIFAR-100, 38.1% on Tiny ImageNet and 58.5% on ImageNet-100 in just one epoch. Furthermore, the proposed method achieves 91.5% on CIFAR-10, 70.1% on CIFAR-100, 51.5% on Tiny ImageNet and 78.9% on ImageNet-100 with linear probing in less than ten training epochs. In addition, we show that EMP-SSL shows significantly better transferability to out-of-domain datasets compared to baseline SSL methods. We will release the code in https://github.com/tsb0601/EMP-SSL. ",
    "url": "https://arxiv.org/abs/2304.03977",
    "authors": [
      "Shengbang Tong",
      "Yubei Chen",
      "Yi Ma",
      "Yann Lecun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03984",
    "title": "DREAM: Adaptive Reinforcement Learning based on Attention Mechanism for  Temporal Knowledge Graph Reasoning",
    "abstract": "Temporal knowledge graphs (TKGs) model the temporal evolution of events and have recently attracted increasing attention. Since TKGs are intrinsically incomplete, it is necessary to reason out missing elements. Although existing TKG reasoning methods have the ability to predict missing future events, they fail to generate explicit reasoning paths and lack explainability. As reinforcement learning (RL) for multi-hop reasoning on traditional knowledge graphs starts showing superior explainability and performance in recent advances, it has opened up opportunities for exploring RL techniques on TKG reasoning. However, the performance of RL-based TKG reasoning methods is limited due to: (1) lack of ability to capture temporal evolution and semantic dependence jointly; (2) excessive reliance on manually designed rewards. To overcome these challenges, we propose an adaptive reinforcement learning model based on attention mechanism (DREAM) to predict missing elements in the future. Specifically, the model contains two components: (1) a multi-faceted attention representation learning method that captures semantic dependence and temporal evolution jointly; (2) an adaptive RL framework that conducts multi-hop reasoning by adaptively learning the reward functions. Experimental results demonstrate DREAM outperforms state-of-the-art models on public dataset ",
    "url": "https://arxiv.org/abs/2304.03984",
    "authors": [
      "Shangfei Zheng",
      "Hongzhi Yin",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Wei Chen",
      "Lei Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.03996",
    "title": "A Unified Characterization of Private Learnability via Graph Theory",
    "abstract": "We provide a unified framework for characterizing pure and approximate differentially private (DP) learnabiliity. The framework uses the language of graph theory: for a concept class $\\mathcal{H}$, we define the contradiction graph $G$ of $\\mathcal{H}$. It vertices are realizable datasets, and two datasets $S,S'$ are connected by an edge if they contradict each other (i.e., there is a point $x$ that is labeled differently in $S$ and $S'$). Our main finding is that the combinatorial structure of $G$ is deeply related to learning $\\mathcal{H}$ under DP. Learning $\\mathcal{H}$ under pure DP is captured by the fractional clique number of $G$. Learning $\\mathcal{H}$ under approximate DP is captured by the clique number of $G$. Consequently, we identify graph-theoretic dimensions that characterize DP learnability: the clique dimension and fractional clique dimension. Along the way, we reveal properties of the contradiction graph which may be of independent interest. We also suggest several open questions and directions for future research. ",
    "url": "https://arxiv.org/abs/2304.03996",
    "authors": [
      "Noga Alon",
      "Shay Moran",
      "Hilla Schefler",
      "Amir Yehudayoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03997",
    "title": "REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using  Long Short Term Memory Network",
    "abstract": "The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two other state of the art forecasting algorithms namely, Facebook Prophet and Support Vector Regressor. The experimental results show that the proposed REDf model can accurately predict energy demand with a mean absolute error of 1.4%. This approach has the potential to improve the efficiency and stability of the power grid by allowing for better management of the integration of renewable energy sources. ",
    "url": "https://arxiv.org/abs/2304.03997",
    "authors": [
      "Md Saef Ullah Miah",
      "Junaida Sulaiman",
      "Md. Imamul Islam",
      "Md. Masuduzzaman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04005",
    "title": "A new transformation for embedded convolutional neural network approach  toward real-time servo motor overload fault-detection",
    "abstract": "Overloading in DC servo motors is a major concern in industries, as many companies face the problem of finding expert operators, and also human monitoring may not be an effective solution. Therefore, this paper proposed an embedded Artificial intelligence (AI) approach using a Convolutional Neural Network (CNN) using a new transformation to extract faults from real-time input signals without human interference. Our main purpose is to extract as many as possible features from the input signal to achieve a relaxed dataset that results in an effective but compact network to provide real-time fault detection even in a low-memory microcontroller. Besides, fault detection method a synchronous dual-motor system is also proposed to take action in faulty events. To fulfill this intention, a one-dimensional input signal from the output current of each DC servo motor is monitored and transformed into a 3d stack of data and then the CNN is implemented into the processor to detect any fault corresponding to overloading, finally experimental setup results in 99.9997% accuracy during testing for a model with nearly 8000 parameters. In addition, the proposed dual-motor system could achieve overload reduction and provide a fault-tolerant system and it is shown that this system also takes advantage of less energy consumption. ",
    "url": "https://arxiv.org/abs/2304.04005",
    "authors": [
      "Seyed Mohammad Hossein Abedy Nejad",
      "Mohammad Amin Behzadi",
      "Abdolrahim Taheri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04007",
    "title": "Sky-GVINS: a Sky-segmentation Aided GNSS-Visual-Inertial System for  Robust Navigation in Urban Canyons",
    "abstract": "Integrating Global Navigation Satellite Systems (GNSS) in Simultaneous Localization and Mapping (SLAM) systems draws increasing attention to a global and continuous localization solution. Nonetheless, in dense urban environments, GNSS-based SLAM systems will suffer from the Non-Line-Of-Sight (NLOS) measurements, which might lead to a sharp deterioration in localization results. In this paper, we propose to detect the sky area from the up-looking camera to improve GNSS measurement reliability for more accurate position estimation. We present Sky-GVINS: a sky-aware GNSS-Visual-Inertial system based on a recent work called GVINS. Specifically, we adopt a global threshold method to segment the sky regions and non-sky regions in the fish-eye sky-pointing image and then project satellites to the image using the geometric relationship between satellites and the camera. After that, we reject satellites in non-sky regions to eliminate NLOS signals. We investigated various segmentation algorithms for sky detection and found that the Otsu algorithm reported the highest classification rate and computational efficiency, despite the algorithm's simplicity and ease of implementation. To evaluate the effectiveness of Sky-GVINS, we built a ground robot and conducted extensive real-world experiments on campus. Experimental results show that our method improves localization accuracy in both open areas and dense urban environments compared to the baseline method. Finally, we also conduct a detailed analysis and point out possible further directions for future research. For detailed information, visit our project website at https://github.com/SJTU-ViSYS/Sky-GVINS. ",
    "url": "https://arxiv.org/abs/2304.04007",
    "authors": [
      "Jie Yin",
      "Tao Li",
      "Hao Yin",
      "Wenxian Yu",
      "Danping Zou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.04008",
    "title": "Infinitely wide limits for deep Stable neural networks: sub-linear,  linear and super-linear activation functions",
    "abstract": "There is a growing literature on the study of large-width properties of deep Gaussian neural networks (NNs), i.e. deep NNs with Gaussian-distributed parameters or weights, and Gaussian stochastic processes. Motivated by some empirical and theoretical studies showing the potential of replacing Gaussian distributions with Stable distributions, namely distributions with heavy tails, in this paper we investigate large-width properties of deep Stable NNs, i.e. deep NNs with Stable-distributed parameters. For sub-linear activation functions, a recent work has characterized the infinitely wide limit of a suitable rescaled deep Stable NN in terms of a Stable stochastic process, both under the assumption of a ``joint growth\" and under the assumption of a ``sequential growth\" of the width over the NN's layers. Here, assuming a ``sequential growth\" of the width, we extend such a characterization to a general class of activation functions, which includes sub-linear, asymptotically linear and super-linear functions. As a novelty with respect to previous works, our results rely on the use of a generalized central limit theorem for heavy tails distributions, which allows for an interesting unified treatment of infinitely wide limits for deep Stable NNs. Our study shows that the scaling of Stable NNs and the stability of their infinitely wide limits may depend on the choice of the activation function, bringing out a critical difference with respect to the Gaussian setting. ",
    "url": "https://arxiv.org/abs/2304.04008",
    "authors": [
      "Alberto Bordino",
      "Stefano Favaro",
      "Sandra Fortini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.04010",
    "title": "Non-asymptotic approximations of Gaussian neural networks via  second-order Poincar\u00e9 inequalities",
    "abstract": "There is a growing interest on large-width asymptotic properties of Gaussian neural networks (NNs), namely NNs whose weights are initialized according to Gaussian distributions. A well-established result is that, as the width goes to infinity, a Gaussian NN converges in distribution to a Gaussian stochastic process, which provides an asymptotic or qualitative Gaussian approximation of the NN. In this paper, we introduce some non-asymptotic or quantitative Gaussian approximations of Gaussian NNs, quantifying the approximation error with respect to some popular distances for (probability) distributions, e.g. the $1$-Wasserstein distance, the total variation distance and the Kolmogorov-Smirnov distance. Our results rely on the use of second-order Gaussian Poincar\\'e inequalities, which provide tight estimates of the approximation error, with optimal rates. This is a novel application of second-order Gaussian Poincar\\'e inequalities, which are well-known in the probabilistic literature for being a powerful tool to obtain Gaussian approximations of general functionals of Gaussian stochastic processes. A generalization of our results to deep Gaussian NNs is discussed. ",
    "url": "https://arxiv.org/abs/2304.04010",
    "authors": [
      "Alberto Bordino",
      "Stefano Favaro",
      "Sandra Fortini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.04023",
    "title": "Attack is Good Augmentation: Towards Skeleton-Contrastive Representation  Learning",
    "abstract": "Contrastive learning, relying on effective positive and negative sample pairs, is beneficial to learn informative skeleton representations in unsupervised skeleton-based action recognition. To achieve these positive and negative pairs, existing weak/strong data augmentation methods have to randomly change the appearance of skeletons for indirectly pursuing semantic perturbations. However, such approaches have two limitations: 1) solely perturbing appearance cannot well capture the intrinsic semantic information of skeletons, and 2) randomly perturbation may change the original positive/negative pairs to soft positive/negative ones. To address the above dilemma, we start the first attempt to explore an attack-based augmentation scheme that additionally brings in direct semantic perturbation, for constructing hard positive pairs and further assisting in constructing hard negative pairs. In particular, we propose a novel Attack-Augmentation Mixing-Contrastive learning (A$^2$MC) to contrast hard positive features and hard negative features for learning more robust skeleton representations. In A$^2$MC, Attack-Augmentation (Att-Aug) is designed to collaboratively perform targeted and untargeted perturbations of skeletons via attack and augmentation respectively, for generating high-quality hard positive features. Meanwhile, Positive-Negative Mixer (PNM) is presented to mix hard positive features and negative features for generating hard negative features, which are adopted for updating the mixed memory banks. Extensive experiments on three public datasets demonstrate that A$^2$MC is competitive with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.04023",
    "authors": [
      "Binqian Xu",
      "Xiangbo Shu",
      "Rui Yan",
      "Guo-Sen Xie",
      "Yixiao Ge",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04033",
    "title": "Exploring the Connection between Robust and Generative Models",
    "abstract": "We offer a study that connects robust discriminative classifiers trained with adversarial training (AT) with generative modeling in the form of Energy-based Models (EBM). We do so by decomposing the loss of a discriminative classifier and showing that the discriminative model is also aware of the input data density. Though a common assumption is that adversarial points leave the manifold of the input data, our study finds out that, surprisingly, untargeted adversarial points in the input space are very likely under the generative model hidden inside the discriminative classifier -- have low energy in the EBM. We present two evidence: untargeted attacks are even more likely than the natural data and their likelihood increases as the attack strength increases. This allows us to easily detect them and craft a novel attack called High-Energy PGD that fools the classifier yet has energy similar to the data set. ",
    "url": "https://arxiv.org/abs/2304.04033",
    "authors": [
      "Senad Beadini",
      "Iacopo Masi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04039",
    "title": "EnforceSNN: Enabling Resilient and Energy-Efficient Spiking Neural  Network Inference considering Approximate DRAMs for Embedded Systems",
    "abstract": "Spiking Neural Networks (SNNs) have shown capabilities of achieving high accuracy under unsupervised settings and low operational power/energy due to their bio-plausible computations. Previous studies identified that DRAM-based off-chip memory accesses dominate the energy consumption of SNN processing. However, state-of-the-art works do not optimize the DRAM energy-per-access, thereby hindering the SNN-based systems from achieving further energy efficiency gains. To substantially reduce the DRAM energy-per-access, an effective solution is to decrease the DRAM supply voltage, but it may lead to errors in DRAM cells (i.e., so-called approximate DRAM). Towards this, we propose \\textit{EnforceSNN}, a novel design framework that provides a solution for resilient and energy-efficient SNN inference using reduced-voltage DRAM for embedded systems. The key mechanisms of our EnforceSNN are: (1) employing quantized weights to reduce the DRAM access energy; (2) devising an efficient DRAM mapping policy to minimize the DRAM energy-per-access; (3) analyzing the SNN error tolerance to understand its accuracy profile considering different bit error rate (BER) values; (4) leveraging the information for developing an efficient fault-aware training (FAT) that considers different BER values and bit error locations in DRAM to improve the SNN error tolerance; and (5) developing an algorithm to select the SNN model that offers good trade-offs among accuracy, memory, and energy consumption. The experimental results show that our EnforceSNN maintains the accuracy (i.e., no accuracy loss for BER less-or-equal 10^-3) as compared to the baseline SNN with accurate DRAM, while achieving up to 84.9\\% of DRAM energy saving and up to 4.1x speed-up of DRAM data throughput across different network sizes. ",
    "url": "https://arxiv.org/abs/2304.04039",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04041",
    "title": "RescueSNN: Enabling Reliable Executions on Spiking Neural Network  Accelerators under Permanent Faults",
    "abstract": "To maximize the performance and energy efficiency of Spiking Neural Network (SNN) processing on resource-constrained embedded systems, specialized hardware accelerators/chips are employed. However, these SNN chips may suffer from permanent faults which can affect the functionality of weight memory and neuron behavior, thereby causing potentially significant accuracy degradation and system malfunctioning. Such permanent faults may come from manufacturing defects during the fabrication process, and/or from device/transistor damages (e.g., due to wear out) during the run-time operation. However, the impact of permanent faults in SNN chips and the respective mitigation techniques have not been thoroughly investigated yet. Toward this, we propose RescueSNN, a novel methodology to mitigate permanent faults in the compute engine of SNN chips without requiring additional retraining, thereby significantly cutting down the design time and retraining costs, while maintaining the throughput and quality. The key ideas of our RescueSNN methodology are (1) analyzing the characteristics of SNN under permanent faults; (2) leveraging this analysis to improve the SNN fault-tolerance through effective fault-aware mapping (FAM); and (3) devising lightweight hardware enhancements to support FAM. Our FAM technique leverages the fault map of SNN compute engine for (i) minimizing weight corruption when mapping weight bits on the faulty memory cells, and (ii) selectively employing faulty neurons that do not cause significant accuracy degradation to maintain accuracy and throughput, while considering the SNN operations and processing dataflow. The experimental results show that our RescueSNN improves accuracy by up to 80% while maintaining the throughput reduction below 25% in high fault rate (e.g., 0.5 of the potential fault locations), as compared to running SNNs on the faulty chip without mitigation. ",
    "url": "https://arxiv.org/abs/2304.04041",
    "authors": [
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Abdullah Hanif",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04051",
    "title": "Generating a Graph Colouring Heuristic with Deep Q-Learning and Graph  Neural Networks",
    "abstract": "The graph colouring problem consists of assigning labels, or colours, to the vertices of a graph such that no two adjacent vertices share the same colour. In this work we investigate whether deep reinforcement learning can be used to discover a competitive construction heuristic for graph colouring. Our proposed approach, ReLCol, uses deep Q-learning together with a graph neural network for feature extraction, and employs a novel way of parameterising the graph that results in improved performance. Using standard benchmark graphs with varied topologies, we empirically evaluate the benefits and limitations of the heuristic learned by ReLCol relative to existing construction algorithms, and demonstrate that reinforcement learning is a promising direction for further research on the graph colouring problem. ",
    "url": "https://arxiv.org/abs/2304.04051",
    "authors": [
      "George Watkins",
      "Giovanni Montana",
      "Juergen Branke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04054",
    "title": "tmn at SemEval-2023 Task 9: Multilingual Tweet Intimacy Detection using  XLM-T, Google Translate, and Ensemble Learning",
    "abstract": "The paper describes a transformer-based system designed for SemEval-2023 Task 9: Multilingual Tweet Intimacy Analysis. The purpose of the task was to predict the intimacy of tweets in a range from 1 (not intimate at all) to 5 (very intimate). The official training set for the competition consisted of tweets in six languages (English, Spanish, Italian, Portuguese, French, and Chinese). The test set included the given six languages as well as external data with four languages not presented in the training set (Hindi, Arabic, Dutch, and Korean). We presented a solution based on an ensemble of XLM-T, a multilingual RoBERTa model adapted to the Twitter domain. To improve the performance of unseen languages, each tweet was supplemented by its English translation. We explored the effectiveness of translated data for the languages seen in fine-tuning compared to unseen languages and estimated strategies for using translated data in transformer-based models. Our solution ranked 4th on the leaderboard while achieving an overall Pearson's r of 0.599 over the test set. The proposed system improves up to 0.088 Pearson's r over a score averaged across all 45 submissions. ",
    "url": "https://arxiv.org/abs/2304.04054",
    "authors": [
      "Anna Glazkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04060",
    "title": "Application of Self-Supervised Learning to MICA Model for Reconstructing  Imperfect 3D Facial Structures",
    "abstract": "In this study, we emphasize the integration of a pre-trained MICA model with an imperfect face dataset, employing a self-supervised learning approach. We present an innovative method for regenerating flawed facial structures, yielding 3D printable outputs that effectively support physicians in their patient treatment process. Our results highlight the model's capacity for concealing scars and achieving comprehensive facial reconstructions without discernible scarring. By capitalizing on pre-trained models and necessitating only a few hours of supplementary training, our methodology adeptly devises an optimal model for reconstructing damaged and imperfect facial features. Harnessing contemporary 3D printing technology, we institute a standardized protocol for fabricating realistic, camouflaging mask models for patients in a laboratory environment. ",
    "url": "https://arxiv.org/abs/2304.04060",
    "authors": [
      "Phuong D. Nguyen",
      "Thinh D. Le",
      "Duong Q. Nguyen",
      "Binh Nguyen",
      "H. Nguyen-Xuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04062",
    "title": "Predicting multiple sclerosis disease severity with multimodal deep  neural networks",
    "abstract": "Multiple Sclerosis (MS) is a chronic disease developed in human brain and spinal cord, which can cause permanent damage or deterioration of the nerves. The severity of MS disease is monitored by the Expanded Disability Status Scale (EDSS), composed of several functional sub-scores. Early and accurate classification of MS disease severity is critical for slowing down or preventing disease progression via applying early therapeutic intervention strategies. Recent advances in deep learning and the wide use of Electronic Health Records (EHR) creates opportunities to apply data-driven and predictive modeling tools for this goal. Previous studies focusing on using single-modal machine learning and deep learning algorithms were limited in terms of prediction accuracy due to the data insufficiency or model simplicity. In this paper, we proposed an idea of using patients' multimodal longitudinal and longitudinal EHR data to predict multiple sclerosis disease severity at the hospital visit. This work has two important contributions. First, we describe a pilot effort to leverage structured EHR data, neuroimaging data and clinical notes to build a multi-modal deep learning framework to predict patient's MS disease severity. The proposed pipeline demonstrates up to 25% increase in terms of the area under the Area Under the Receiver Operating Characteristic curve (AUROC) compared to models using single-modal data. Second, the study also provides insights regarding the amount useful signal embedded in each data modality with respect to MS disease prediction, which may improve data collection processes. ",
    "url": "https://arxiv.org/abs/2304.04062",
    "authors": [
      "Kai Zhang",
      "John A. Lincoln",
      "Xiaoqian Jiang",
      "Elmer V. Bernstam",
      "Shayan Shams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04063",
    "title": "Counterfactual Explanations of Neural Network-Generated Response Curves",
    "abstract": "Response curves exhibit the magnitude of the response of a sensitive system to a varying stimulus. However, response of such systems may be sensitive to multiple stimuli (i.e., input features) that are not necessarily independent. As a consequence, the shape of response curves generated for a selected input feature (referred to as \"active feature\") might depend on the values of the other input features (referred to as \"passive features\"). In this work we consider the case of systems whose response is approximated using regression neural networks. We propose to use counterfactual explanations (CFEs) for the identification of the features with the highest relevance on the shape of response curves generated by neural network black boxes. CFEs are generated by a genetic algorithm-based approach that solves a multi-objective optimization problem. In particular, given a response curve generated for an active feature, a CFE finds the minimum combination of passive features that need to be modified to alter the shape of the response curve. We tested our method on a synthetic dataset with 1-D inputs and two crop yield prediction datasets with 2-D inputs. The relevance ranking of features and feature combinations obtained on the synthetic dataset coincided with the analysis of the equation that was used to generate the problem. Results obtained on the yield prediction datasets revealed that the impact on fertilizer responsivity of passive features depends on the terrain characteristics of each field. ",
    "url": "https://arxiv.org/abs/2304.04063",
    "authors": [
      "Giorgio Morales",
      "John Sheppard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04077",
    "title": "Deep Prototypical-Parts Ease Morphological Kidney Stone Identification  and are Competitively Robust to Photometric Perturbations",
    "abstract": "Identifying the type of kidney stones can allow urologists to determine their cause of formation, improving the prescription of appropriate treatments to diminish future relapses. Currently, the associated ex-vivo diagnosis (known as Morpho-constitutional Analysis, MCA) is time-consuming, expensive and requires a great deal of experience, as it requires a visual analysis component that is highly operator dependant. Recently, machine learning methods have been developed for in-vivo endoscopic stone recognition. Deep Learning (DL) based methods outperform non-DL methods in terms of accuracy but lack explainability. Despite this trade-off, when it comes to making high-stakes decisions, it's important to prioritize understandable Computer-Aided Diagnosis (CADx) that suggests a course of action based on reasonable evidence, rather than a model prescribing a course of action. In this proposal, we learn Prototypical Parts (PPs) per kidney stone subtype, which are used by the DL model to generate an output classification. Using PPs in the classification task enables case-based reasoning explanations for such output, thus making the model interpretable. In addition, we modify global visual characteristics to describe their relevance to the PPs and the sensitivity of our model's performance. With this, we provide explanations with additional information at the sample, class and model levels in contrast to previous works. Although our implementation's average accuracy is lower than state-of-the-art (SOTA) non-interpretable DL models by 1.5 %, our models perform 2.8% better on perturbed images with a lower standard deviation, without adversarial training. Thus, Learning PPs has the potential to create more robust DL models. ",
    "url": "https://arxiv.org/abs/2304.04077",
    "authors": [
      "Daniel Flores-Araiza",
      "Francisco Lopez-Tiro",
      "Jonathan El-Beze",
      "Jacques Hubert",
      "Miguel Gonzalez-Mendoza",
      "Gilberto Ochoa-Ruiz",
      "Christian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04099",
    "title": "Unsupervised Story Discovery from Continuous News Streams via Scalable  Thematic Embedding",
    "abstract": "Unsupervised discovery of stories with correlated news articles in real-time helps people digest massive news streams without expensive human annotations. A common approach of the existing studies for unsupervised online story discovery is to represent news articles with symbolic- or graph-based embedding and incrementally cluster them into stories. Recent large language models are expected to improve the embedding further, but a straightforward adoption of the models by indiscriminately encoding all information in articles is ineffective to deal with text-rich and evolving news streams. In this work, we propose a novel thematic embedding with an off-the-shelf pretrained sentence encoder to dynamically represent articles and stories by considering their shared temporal themes. To realize the idea for unsupervised online story discovery, a scalable framework USTORY is introduced with two main techniques, theme- and time-aware dynamic embedding and novelty-aware adaptive clustering, fueled by lightweight story summaries. A thorough evaluation with real news data sets demonstrates that USTORY achieves higher story discovery performances than baselines while being robust and scalable to various streaming settings. ",
    "url": "https://arxiv.org/abs/2304.04099",
    "authors": [
      "Susik Yoon",
      "Dongha Lee",
      "Yunyi Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04117",
    "title": "No Code AI: Automatic generation of Function Block Diagrams from  documentation and associated heuristic for context-aware ML algorithm  training",
    "abstract": "Industrial process engineering and PLC program development have traditionally favored Function Block Diagram (FBD) programming over classical imperative style programming like the object oriented and functional programming paradigms. The increasing momentum in the adoption and trial of ideas now classified as 'No Code' or 'Low Code' alongside the mainstream success of statistical learning theory or the so-called machine learning is redefining the way in which we structure programs for the digital machine to execute. A principal focus of 'No Code' is deriving executable programs directly from a set of requirement documents or any other documentation that defines consumer or customer expectation. We present a method for generating Function Block Diagram (FBD) programs as either the intermediate or final artifact that can be executed by a target system from a set of requirement documents using a constrained selection algorithm that draws from the top line of an associated recommender system. The results presented demonstrate that this type of No-code generative model is a viable option for industrial process design. ",
    "url": "https://arxiv.org/abs/2304.04117",
    "authors": [
      "Oluwatosin Ogundare",
      "Gustavo Quiros Araya",
      "Yassine Qamsane"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04120",
    "title": "Surrogate Lagrangian Relaxation: A Path To Retrain-free Deep Neural  Network Pruning",
    "abstract": "Network pruning is a widely used technique to reduce computation cost and model size for deep neural networks. However, the typical three-stage pipeline significantly increases the overall training time. In this paper, we develop a systematic weight-pruning optimization approach based on Surrogate Lagrangian relaxation, which is tailored to overcome difficulties caused by the discrete nature of the weight-pruning problem. We prove that our method ensures fast convergence of the model compression problem, and the convergence of the SLR is accelerated by using quadratic penalties. Model parameters obtained by SLR during the training phase are much closer to their optimal values as compared to those obtained by other state-of-the-art methods. We evaluate our method on image classification tasks using CIFAR-10 and ImageNet with state-of-the-art MLP-Mixer, Swin Transformer, and VGG-16, ResNet-18, ResNet-50 and ResNet-110, MobileNetV2. We also evaluate object detection and segmentation tasks on COCO, KITTI benchmark, and TuSimple lane detection dataset using a variety of models. Experimental results demonstrate that our SLR-based weight-pruning optimization approach achieves a higher compression rate than state-of-the-art methods under the same accuracy requirement and also can achieve higher accuracy under the same compression rate requirement. Under classification tasks, our SLR approach converges to the desired accuracy $3\\times$ faster on both of the datasets. Under object detection and segmentation tasks, SLR also converges $2\\times$ faster to the desired accuracy. Further, our SLR achieves high model accuracy even at the hard-pruning stage without retraining, which reduces the traditional three-stage pruning into a two-stage process. Given a limited budget of retraining epochs, our approach quickly recovers the model's accuracy. ",
    "url": "https://arxiv.org/abs/2304.04120",
    "authors": [
      "Shanglin Zhou",
      "Mikhail A. Bragin",
      "Lynn Pepin",
      "Deniz Gurevin",
      "Fei Miao",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04122",
    "title": "Estimation and Fault Detection on Hydraulic System with Adaptive-Scaling  Kalman and Consensus Filtering",
    "abstract": "The area of fault detection is becoming more interesting since there have been many unique designs to detect or even compensate the faults, either from sensor or actuator. This paper applies the hydraulic system with interconnected tanks by implementing a leakage on one of the three tanks. The mathematical model along with the details of stability properties are highly discussed in this paper by imposing the Lyapunov and boundedness stability. The theory of fault detection with certain threshold after the occurrence of the fault corresponding to the state estimation error is mathematically presented ended by simulation. Moreover, the system compares the effectiveness of the proposed observer using Luenberger observer, adaptive-scaling Kalman and consensus filtering. The results for some different initial condition guarantee the detection of the fault for some time $t_d > t_f$ ",
    "url": "https://arxiv.org/abs/2304.04122",
    "authors": [
      "Moh Kamalul Wafi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04125",
    "title": "Training Neural Networks for Execution on Approximate Hardware",
    "abstract": "Approximate computing methods have shown great potential for deep learning. Due to the reduced hardware costs, these methods are especially suitable for inference tasks on battery-operated devices that are constrained by their power budget. However, approximate computing hasn't reached its full potential due to the lack of work on training methods. In this work, we discuss training methods for approximate hardware. We demonstrate how training needs to be specialized for approximate hardware, and propose methods to speed up the training process by up to 18X. ",
    "url": "https://arxiv.org/abs/2304.04125",
    "authors": [
      "Tianmu Li",
      "Shurui Li",
      "Puneet Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2304.04147",
    "title": "FedPNN: One-shot Federated Classification via Evolving Clustering Method  and Probabilistic Neural Network hybrid",
    "abstract": "Protecting data privacy is paramount in the fields such as finance, banking, and healthcare. Federated Learning (FL) has attracted widespread attention due to its decentralized, distributed training and the ability to protect the privacy while obtaining a global shared model. However, FL presents challenges such as communication overhead, and limited resource capability. This motivated us to propose a two-stage federated learning approach toward the objective of privacy protection, which is a first-of-its-kind study as follows: (i) During the first stage, the synthetic dataset is generated by employing two different distributions as noise to the vanilla conditional tabular generative adversarial neural network (CTGAN) resulting in modified CTGAN, and (ii) In the second stage, the Federated Probabilistic Neural Network (FedPNN) is developed and employed for building globally shared classification model. We also employed synthetic dataset metrics to check the quality of the generated synthetic dataset. Further, we proposed a meta-clustering algorithm whereby the cluster centers obtained from the clients are clustered at the server for training the global model. Despite PNN being a one-pass learning classifier, its complexity depends on the training data size. Therefore, we employed a modified evolving clustering method (ECM), another one-pass algorithm to cluster the training data thereby increasing the speed further. Moreover, we conducted sensitivity analysis by varying Dthr, a hyperparameter of ECM at the server and client, one at a time. The effectiveness of our approach is validated on four finance and medical datasets. ",
    "url": "https://arxiv.org/abs/2304.04147",
    "authors": [
      "Polaki Durga Prasad",
      "Yelleti Vivek",
      "Vadlamani Ravi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04152",
    "title": "Continual Graph Convolutional Network for Text Classification",
    "abstract": "Graph convolutional network (GCN) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. However, while GCN-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. It is a challenge to deploy them in online systems to infer steaming text data. In this work, we present a continual GCN model (ContGCN) to generalize inferences from observed documents to unobserved documents. Concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update ContGCN in a label-free manner. A 3-month A/B test on Huawei public opinion analysis system shows ContGCN achieves 8.86% performance gain compared with state-of-the-art methods. Offline experiments on five public datasets also show ContGCN can improve inference quality. The source code will be released at https://github.com/Jyonn/ContGCN. ",
    "url": "https://arxiv.org/abs/2304.04152",
    "authors": [
      "Tiandeng Wu",
      "Qijiong Liu",
      "Yi Cao",
      "Yao Huang",
      "Xiao-Ming Wu",
      "Jiandong Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04159",
    "title": "List-Based Detection and Selection of Access Points in Cell-Free Massive  MIMO Networks",
    "abstract": "This paper proposes a cell-free massive multiple-input multiple-output (CF-mMIMO) architecture with joint list-based detection with soft interference cancelation (soft-IC) and access points (APs) selection. In particular, we derive a new closed-form expression for the minimum mean-square error receive filter while taking the uplink transmit powers and APs selection into account. This is achieved by optimizing the receive combining vector by minimizing the mean square error between the detected symbol estimate and transmitted symbol, after canceling the multi-user interference (MUI). By using low-density parity check (LDPC) codes, an iterative detection and decoding (IDD) scheme based on a message passing is devised. In order to perform joint detection at the central processing unit (CPU), the access points locally estimate the channel and send their received sample data to the CPU via the front haul links. In order to enhance the system's bit error rate performance, the detected symbols are iteratively exchanged between the joint detector and the LDPC decoder in log likelihood ratio form. Furthermore, we draw insights into the derived detector as the number of IDD iterations increase. Finally, the proposed list detector is compared with existing detection techniques. ",
    "url": "https://arxiv.org/abs/2304.04159",
    "authors": [
      "T. Ssettumba",
      "L. T. N. Landau",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.04163",
    "title": "Energy-Efficient URLLC Service Provision via a Near-Space Information  Network",
    "abstract": "The integration of a near-space information network (NSIN) with the reconfigurable intelligent surface (RIS) is envisioned to significantly enhance the communication performance of future wireless communication systems by proactively altering wireless channels. This paper investigates the problem of deploying a RIS-integrated NSIN to provide energy-efficient, ultra-reliable and low-latency communications (URLLC) services. We mathematically formulate this problem as a resource optimization problem, aiming to maximize the effective throughput and minimize the system power consumption, subject to URLLC and physical resource constraints. The formulated problem is challenging in terms of accurate channel estimation, RIS phase alignment, theoretical analysis, and effective solution. We propose a joint resource allocation algorithm to handle these challenges. In this algorithm, we develop an accurate channel estimation approach by exploring message passing and optimize phase shifts of RIS reflecting elements to further increase the channel gain. Besides, we derive an analysis-friend expression of decoding error probability and decompose the problem into two-layered optimization problems by analyzing the monotonicity, which makes the formulated problem analytically tractable. Extensive simulations have been conducted to verify the performance of the proposed algorithm. Simulation results show that the proposed algorithm can achieve outstanding channel estimation performance and is more energy-efficient than diverse benchmark algorithms. ",
    "url": "https://arxiv.org/abs/2304.04163",
    "authors": [
      "Puguang An",
      "Xianbin Cao",
      "Peng Yang",
      "Kun Guo",
      "Yue Gao",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.04164",
    "title": "Gradient Sparsification for Efficient Wireless Federated Learning with  Differential Privacy",
    "abstract": "Federated learning (FL) enables distributed clients to collaboratively train a machine learning model without sharing raw data with each other. However, it suffers the leakage of private information from uploading models. In addition, as the model size grows, the training latency increases due to limited transmission bandwidth and the model performance degrades while using differential privacy (DP) protection. In this paper, we propose a gradient sparsification empowered FL framework over wireless channels, in order to improve training efficiency without sacrificing convergence performance. Specifically, we first design a random sparsification algorithm to retain a fraction of the gradient elements in each client's local training, thereby mitigating the performance degradation induced by DP and and reducing the number of transmission parameters over wireless channels. Then, we analyze the convergence bound of the proposed algorithm, by modeling a non-convex FL problem. Next, we formulate a time-sequential stochastic optimization problem for minimizing the developed convergence bound, under the constraints of transmit power, the average transmitting delay, as well as the client's DP requirement. Utilizing the Lyapunov drift-plus-penalty framework, we develop an analytical solution to the optimization problem. Extensive experiments have been implemented on three real life datasets to demonstrate the effectiveness of our proposed algorithm. We show that our proposed algorithms can fully exploit the interworking between communication and computation to outperform the baselines, i.e., random scheduling, round robin and delay-minimization algorithms. ",
    "url": "https://arxiv.org/abs/2304.04164",
    "authors": [
      "Kang Wei",
      "Jun Li",
      "Chuan Ma",
      "Ming Ding",
      "Haitao Zhao",
      "Wen Chen",
      "Hongbo Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.04166",
    "title": "Experience-Based Evolutionary Algorithms for Expensive Optimization",
    "abstract": "Optimization algorithms are very different from human optimizers. A human being would gain more experiences through problem-solving, which helps her/him in solving a new unseen problem. Yet an optimization algorithm never gains any experiences by solving more problems. In recent years, efforts have been made towards endowing optimization algorithms with some abilities of experience learning, which is regarded as experience-based optimization. In this paper, we argue that hard optimization problems could be tackled efficiently by making better use of experiences gained in related problems. We demonstrate our ideas in the context of expensive optimization, where we aim to find a near-optimal solution to an expensive optimization problem with as few fitness evaluations as possible. To achieve this, we propose an experience-based surrogate-assisted evolutionary algorithm (SAEA) framework to enhance the optimization efficiency of expensive problems, where experiences are gained across related expensive tasks via a novel meta-learning method. These experiences serve as the task-independent parameters of a deep kernel learning surrogate, then the solutions sampled from the target task are used to adapt task-specific parameters for the surrogate. With the help of experience learning, competitive regression-based surrogates can be initialized using only 1$d$ solutions from the target task ($d$ is the dimension of the decision space). Our experimental results on expensive multi-objective and constrained optimization problems demonstrate that experiences gained from related tasks are beneficial for the saving of evaluation budgets on the target problem. ",
    "url": "https://arxiv.org/abs/2304.04166",
    "authors": [
      "Xunzhao Yu",
      "Yan Wang",
      "Ling Zhu",
      "Dimitar Filev",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04168",
    "title": "Adversarially Robust Neural Architecture Search for Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) obtain tremendous success in modeling relational data. Still, they are prone to adversarial attacks, which are massive threats to applying GNNs to risk-sensitive domains. Existing defensive methods neither guarantee performance facing new data/tasks or adversarial attacks nor provide insights to understand GNN robustness from an architectural perspective. Neural Architecture Search (NAS) has the potential to solve this problem by automating GNN architecture designs. Nevertheless, current graph NAS approaches lack robust design and are vulnerable to adversarial attacks. To tackle these challenges, we propose a novel Robust Neural Architecture search framework for GNNs (G-RNA). Specifically, we design a robust search space for the message-passing mechanism by adding graph structure mask operations into the search space, which comprises various defensive operation candidates and allows us to search for defensive GNNs. Furthermore, we define a robustness metric to guide the search procedure, which helps to filter robust architectures. In this way, G-RNA helps understand GNN robustness from an architectural perspective and effectively searches for optimal adversarial robust GNNs. Extensive experimental results on benchmark datasets show that G-RNA significantly outperforms manually designed robust GNNs and vanilla graph NAS baselines by 12.1% to 23.4% under adversarial attacks. ",
    "url": "https://arxiv.org/abs/2304.04168",
    "authors": [
      "Beini Xie",
      "Heng Chang",
      "Ziwei Zhang",
      "Xin Wang",
      "Daixin Wang",
      "Zhiqiang Zhang",
      "Rex Ying",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.04175",
    "title": "Token Boosting for Robust Self-Supervised Visual Transformer  Pre-training",
    "abstract": "Learning with large-scale unlabeled data has become a powerful tool for pre-training Visual Transformers (VTs). However, prior works tend to overlook that, in real-world scenarios, the input data may be corrupted and unreliable. Pre-training VTs on such corrupted data can be challenging, especially when we pre-train via the masked autoencoding approach, where both the inputs and masked ``ground truth\" targets can potentially be unreliable in this case. To address this limitation, we introduce the Token Boosting Module (TBM) as a plug-and-play component for VTs that effectively allows the VT to learn to extract clean and robust features during masked autoencoding pre-training. We provide theoretical analysis to show how TBM improves model pre-training with more robust and generalizable representations, thus benefiting downstream tasks. We conduct extensive experiments to analyze TBM's effectiveness, and results on four corrupted datasets demonstrate that TBM consistently improves performance on downstream tasks. ",
    "url": "https://arxiv.org/abs/2304.04175",
    "authors": [
      "Tianjiao Li",
      "Lin Geng Foo",
      "Ping Hu",
      "Xindi Shang",
      "Hossein Rahmani",
      "Zehuan Yuan",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04179",
    "title": "Sparse Dense Fusion for 3D Object Detection",
    "abstract": "With the prevalence of multimodal learning, camera-LiDAR fusion has gained popularity in 3D object detection. Although multiple fusion approaches have been proposed, they can be classified into either sparse-only or dense-only fashion based on the feature representation in the fusion module. In this paper, we analyze them in a common taxonomy and thereafter observe two challenges: 1) sparse-only solutions preserve 3D geometric prior and yet lose rich semantic information from the camera, and 2) dense-only alternatives retain the semantic continuity but miss the accurate geometric information from LiDAR. By analyzing these two formulations, we conclude that the information loss is inevitable due to their design scheme. To compensate for the information loss in either manner, we propose Sparse Dense Fusion (SDF), a complementary framework that incorporates both sparse-fusion and dense-fusion modules via the Transformer architecture. Such a simple yet effective sparse-dense fusion structure enriches semantic texture and exploits spatial structure information simultaneously. Through our SDF strategy, we assemble two popular methods with moderate performance and outperform baseline by 4.3% in mAP and 2.5% in NDS, ranking first on the nuScenes benchmark. Extensive ablations demonstrate the effectiveness of our method and empirically align our analysis. ",
    "url": "https://arxiv.org/abs/2304.04179",
    "authors": [
      "Yulu Gao",
      "Chonghao Sima",
      "Shaoshuai Shi",
      "Shangzhe Di",
      "Si Liu",
      "Hongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04185",
    "title": "BEVStereo++: Accurate Depth Estimation in Multi-view 3D Object Detection  via Dynamic Temporal Stereo",
    "abstract": "Bounded by the inherent ambiguity of depth perception, contemporary multi-view 3D object detection methods fall into the performance bottleneck. Intuitively, leveraging temporal multi-view stereo (MVS) technology is the natural knowledge for tackling this ambiguity. However, traditional attempts of MVS has two limitations when applying to 3D object detection scenes: 1) The affinity measurement among all views suffers expensive computational cost; 2) It is difficult to deal with outdoor scenarios where objects are often mobile. To this end, we propose BEVStereo++: by introducing a dynamic temporal stereo strategy, BEVStereo++ is able to cut down the harm that is brought by introducing temporal stereo when dealing with those two scenarios. Going one step further, we apply Motion Compensation Module and long sequence Frame Fusion to BEVStereo++, which shows further performance boosting and error reduction. Without bells and whistles, BEVStereo++ achieves state-of-the-art(SOTA) on both Waymo and nuScenes dataset. ",
    "url": "https://arxiv.org/abs/2304.04185",
    "authors": [
      "Yinhao Li",
      "Jinrong Yang",
      "Jianjian Sun",
      "Han Bao",
      "Zheng Ge",
      "Li Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04187",
    "title": "Similarity-Aware Multimodal Prompt Learning for Fake News Detection",
    "abstract": "The standard paradigm for fake news detection mainly utilizes text information to model the truthfulness of news. However, the discourse of online fake news is typically subtle and it requires expert knowledge to use textual information to debunk fake news. Recently, studies focusing on multimodal fake news detection have outperformed text-only methods. Recent approaches utilizing the pre-trained model to extract unimodal features, or fine-tuning the pre-trained model directly, have become a new paradigm for detecting fake news. Again, this paradigm either requires a large number of training instances, or updates the entire set of pre-trained model parameters, making real-world fake news detection impractical. Furthermore, traditional multimodal methods fuse the cross-modal features directly without considering that the uncorrelated semantic representation might inject noise into the multimodal features. This paper proposes a Similarity-Aware Multimodal Prompt Learning (SAMPLE) framework. First, we incorporate prompt learning into multimodal fake news detection. Prompt learning, which only tunes prompts with a frozen language model, can reduce memory usage significantly and achieve comparable performances, compared with fine-tuning. We analyse three prompt templates with a soft verbalizer to detect fake news. In addition, we introduce the similarity-aware fusing method to adaptively fuse the intensity of multimodal representation and mitigate the noise injection via uncorrelated cross-modal features. For evaluation, SAMPLE surpasses the F1 and the accuracies of previous works on two benchmark multimodal datasets, demonstrating the effectiveness of the proposed method in detecting fake news. In addition, SAMPLE also is superior to other approaches regardless of few-shot and data-rich settings. ",
    "url": "https://arxiv.org/abs/2304.04187",
    "authors": [
      "Ye Jiang",
      "Xiaomin Yu",
      "Yimin Wang",
      "Xiaoman Xu",
      "Xingyi Song",
      "Diana Maynard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04188",
    "title": "HyperINR: A Fast and Predictive Hypernetwork for Implicit Neural  Representations via Knowledge Distillation",
    "abstract": "Implicit Neural Representations (INRs) have recently exhibited immense potential in the field of scientific visualization for both data generation and visualization tasks. However, these representations often consist of large multi-layer perceptrons (MLPs), necessitating millions of operations for a single forward pass, consequently hindering interactive visual exploration. While reducing the size of the MLPs and employing efficient parametric encoding schemes can alleviate this issue, it compromises generalizability for unseen parameters, rendering it unsuitable for tasks such as temporal super-resolution. In this paper, we introduce HyperINR, a novel hypernetwork architecture capable of directly predicting the weights for a compact INR. By harnessing an ensemble of multiresolution hash encoding units in unison, the resulting INR attains state-of-the-art inference performance (up to 100x higher inference bandwidth) and can support interactive photo-realistic volume visualization. Additionally, by incorporating knowledge distillation, exceptional data and visualization generation quality is achieved, making our method valuable for real-time parameter exploration. We validate the effectiveness of the HyperINR architecture through a comprehensive ablation study. We showcase the versatility of HyperINR across three distinct scientific domains: novel view synthesis, temporal super-resolution of volume data, and volume rendering with dynamic global shadows. By simultaneously achieving efficiency and generalizability, HyperINR paves the way for applying INR in a wider array of scientific visualization applications. ",
    "url": "https://arxiv.org/abs/2304.04188",
    "authors": [
      "Qi Wu",
      "David Bauer",
      "Yuyang Chen",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04192",
    "title": "Exploring Operational Flexibility of Active Distribution Networks with  Low Observability",
    "abstract": "Power electronic interfaced devices progressively enable the increasing provision of flexible operational actions in distribution networks. The feasible flexibility these devices can effectively provide requires estimation and quantification so the network operators can plan operations close to real-time. Existing approaches estimating the distribution network flexibility require the full observability of the system, meaning topological and state knowledge. However, the assumption of full observability is unrealistic and represents a barrier to system operators' adaptation. This paper proposes a definition of the distribution network flexibility problem that considers the limited observability in real-time operation. A critical review and assessment of the most prominent approaches are done based on the proposed definition. This assessment showcases the limitations and benefits of existing approaches for estimating flexibility with low observability. A case study on the CIGRE MV distribution system highlights the drawbacks brought by low observability. ",
    "url": "https://arxiv.org/abs/2304.04192",
    "authors": [
      "Demetris Chrysostomou",
      "Jose Luis Rueda Torres",
      "Jochen Lorenz Cremer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04195",
    "title": "Fast Charging of Lithium-Ion Batteries Using Deep Bayesian Optimization  with Recurrent Neural Network",
    "abstract": "Fast charging has attracted increasing attention from the battery community for electrical vehicles (EVs) to alleviate range anxiety and reduce charging time for EVs. However, inappropriate charging strategies would cause severe degradation of batteries or even hazardous accidents. To optimize fast-charging strategies under various constraints, particularly safety limits, we propose a novel deep Bayesian optimization (BO) approach that utilizes Bayesian recurrent neural network (BRNN) as the surrogate model, given its capability in handling sequential data. In addition, a combined acquisition function of expected improvement (EI) and upper confidence bound (UCB) is developed to better balance the exploitation and exploration. The effectiveness of the proposed approach is demonstrated on the PETLION, a porous electrode theory-based battery simulator. Our method is also compared with the state-of-the-art BO methods that use Gaussian process (GP) and non-recurrent network as surrogate models. The results verify the superior performance of the proposed fast charging approaches, which mainly results from that: (i) the BRNN-based surrogate model provides a more precise prediction of battery lifetime than that based on GP or non-recurrent network; and (ii) the combined acquisition function outperforms traditional EI or UCB criteria in exploring the optimal charging protocol that maintains the longest battery lifetime. ",
    "url": "https://arxiv.org/abs/2304.04195",
    "authors": [
      "Benben Jiang",
      "Yixing Wang",
      "Zhenghua Ma",
      "Qiugang Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04199",
    "title": "Information-Theoretic Testing and Debugging of Fairness Defects in Deep  Neural Networks",
    "abstract": "The deep feedforward neural networks (DNNs) are increasingly deployed in socioeconomic critical decision support software systems. DNNs are exceptionally good at finding minimal, sufficient statistical patterns within their training data. Consequently, DNNs may learn to encode decisions -- amplifying existing biases or introducing new ones -- that may disadvantage protected individuals/groups and may stand to violate legal protections. While the existing search based software testing approaches have been effective in discovering fairness defects, they do not supplement these defects with debugging aids -- such as severity and causal explanations -- crucial to help developers triage and decide on the next course of action. Can we measure the severity of fairness defects in DNNs? Are these defects symptomatic of improper training or they merely reflect biases present in the training data? To answer such questions, we present DICE: an information-theoretic testing and debugging framework to discover and localize fairness defects in DNNs. The key goal of DICE is to assist software developers in triaging fairness defects by ordering them by their severity. Towards this goal, we quantify fairness in terms of protected information (in bits) used in decision making. A quantitative view of fairness defects not only helps in ordering these defects, our empirical evaluation shows that it improves the search efficiency due to resulting smoothness of the search space. Guided by the quantitative fairness, we present a causal debugging framework to localize inadequately trained layers and neurons responsible for fairness defects. Our experiments over ten DNNs, developed for socially critical tasks, show that DICE efficiently characterizes the amounts of discrimination, effectively generates discriminatory instances, and localizes layers/neurons with significant biases. ",
    "url": "https://arxiv.org/abs/2304.04199",
    "authors": [
      "Verya Monjezi",
      "Ashutosh Trivedi",
      "Gang Tan",
      "Saeid Tizpaz-Niari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04203",
    "title": "OpenDriver: an open-road driver state detection dataset",
    "abstract": "In modern society, road safety relies heavily on the psychological and physiological state of drivers. Negative factors such as fatigue, drowsiness, and stress can impair drivers' reaction time and decision making abilities, leading to an increased incidence of traffic accidents. Among the numerous studies for impaired driving detection, wearable physiological measurement is a real-time approach to monitoring a driver's state. However, currently, there are few driver physiological datasets in open road scenarios and the existing datasets suffer from issues such as poor signal quality, small sample sizes, and short data collection periods. Therefore, in this paper, a large-scale multimodal driving dataset for driver impairment detection and biometric data recognition is designed and described. The dataset contains two modalities of driving signals: six-axis inertial signals and electrocardiogram (ECG) signals, which were recorded while over one hundred drivers were following the same route through open roads during several months. Both the ECG signal sensor and the six-axis inertial signal sensor are installed on a specially designed steering wheel cover, allowing for data collection without disturbing the driver. Additionally, electrodermal activity (EDA) signals were also recorded during the driving process and will be integrated into the presented dataset soon. Future work can build upon this dataset to advance the field of driver impairment detection. New methods can be explored for integrating other types of biometric signals, such as eye tracking, to further enhance the understanding of driver states. The insights gained from this dataset can also inform the development of new driver assistance systems, promoting safer driving practices and reducing the risk of traffic accidents. The OpenDriver dataset will be publicly available soon. ",
    "url": "https://arxiv.org/abs/2304.04203",
    "authors": [
      "Delong Liu",
      "Shichao Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04207",
    "title": "Scalable Multiple Patterning Layout Decomposition Implemented by a  Distribution Evolutionary Algorithm",
    "abstract": "As the feature size of semiconductor technology shrinks to 10 nm and beyond, the multiple patterning lithography (MPL) attracts more attention from the industry. In this paper, we model the layout decomposition of MPL as a generalized graph coloring problem, which is addressed by a distribution evolutionary algorithm based on a population of probabilistic model (DEA-PPM). DEA-PPM can strike a balance between decomposition results and running time, being scalable for varied settings of mask number and lithography resolution. Due to its robustness of decomposition results, this could be an alternative technique for multiple patterning layout decomposition in next-generation technology nodes. ",
    "url": "https://arxiv.org/abs/2304.04207",
    "authors": [
      "Yu Chen",
      "Yongjian Xu",
      "Ning Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.04211",
    "title": "AGAD: Adversarial Generative Anomaly Detection",
    "abstract": "Anomaly detection suffered from the lack of anomalies due to the diversity of abnormalities and the difficulties of obtaining large-scale anomaly data. Semi-supervised anomaly detection methods are often used to solely leverage normal data to detect abnormalities that deviated from the learnt normality distributions. Meanwhile, given the fact that limited anomaly data can be obtained with a minor cost in practice, some researches also investigated anomaly detection methods under supervised scenarios with limited anomaly data. In order to address the lack of abnormal data for robust anomaly detection, we propose Adversarial Generative Anomaly Detection (AGAD), a self-contrast-based anomaly detection paradigm that learns to detect anomalies by generating \\textit{contextual adversarial information} from the massive normal examples. Essentially, our method generates pseudo-anomaly data for both supervised and semi-supervised anomaly detection scenarios. Extensive experiments are carried out on multiple benchmark datasets and real-world datasets, the results show significant improvement in both supervised and semi-supervised scenarios. Importantly, our approach is data-efficient that can boost up the detection accuracy with no more than 5% anomalous training data. ",
    "url": "https://arxiv.org/abs/2304.04211",
    "authors": [
      "Jian Shi",
      "Ni Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04225",
    "title": "Transformer Utilization in Medical Image Segmentation Networks",
    "abstract": "Owing to success in the data-rich domain of natural images, Transformers have recently become popular in medical image segmentation. However, the pairing of Transformers with convolutional blocks in varying architectural permutations leaves their relative effectiveness to open interpretation. We introduce Transformer Ablations that replace the Transformer blocks with plain linear operators to quantify this effectiveness. With experiments on 8 models on 2 medical image segmentation tasks, we explore -- 1) the replaceable nature of Transformer-learnt representations, 2) Transformer capacity alone cannot prevent representational replaceability and works in tandem with effective design, 3) The mere existence of explicit feature hierarchies in transformer blocks is more beneficial than accompanying self-attention modules, 4) Major spatial downsampling before Transformer modules should be used with caution. ",
    "url": "https://arxiv.org/abs/2304.04225",
    "authors": [
      "Saikat Roy",
      "Gregor Koehler",
      "Michael Baumgartner",
      "Constantin Ulrich",
      "Jens Petersen",
      "Fabian Isensee",
      "Klaus Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04228",
    "title": "Unsupervised Multi-Criteria Adversarial Detection in Deep Image  Retrieval",
    "abstract": "The vulnerability in the algorithm supply chain of deep learning has imposed new challenges to image retrieval systems in the downstream. Among a variety of techniques, deep hashing is gaining popularity. As it inherits the algorithmic backend from deep learning, a handful of attacks are recently proposed to disrupt normal image retrieval. Unfortunately, the defense strategies in softmax classification are not readily available to be applied in the image retrieval domain. In this paper, we propose an efficient and unsupervised scheme to identify unique adversarial behaviors in the hamming space. In particular, we design three criteria from the perspectives of hamming distance, quantization loss and denoising to defend against both untargeted and targeted attacks, which collectively limit the adversarial space. The extensive experiments on four datasets demonstrate 2-23% improvements of detection rates with minimum computational overhead for real-time image queries. ",
    "url": "https://arxiv.org/abs/2304.04228",
    "authors": [
      "Yanru Xiao",
      "Cong Wang",
      "Xing Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.04234",
    "title": "Variational operator learning: A unified paradigm for training neural  operators and solving partial differential equations",
    "abstract": "Based on the variational method, we propose a novel paradigm that provides a unified framework of training neural operators and solving partial differential equations (PDEs) with the variational form, which we refer to as the variational operator learning (VOL). We first derive the functional approximation of the system from the node solution prediction given by neural operators, and then conduct the variational operation by automatic differentiation, constructing a forward-backward propagation loop to derive the residual of the linear system. One or several update steps of the steepest decent method (SD) and the conjugate gradient method (CG) are provided in every iteration as a cheap yet effective update for training the neural operators. Experimental results show the proposed VOL can learn a variety of solution operators in PDEs of the steady heat transfer and the variable stiffness elasticity with satisfactory results and small error. The proposed VOL achieves nearly label-free training. Only five to ten labels are used for the output distribution-shift session in all experiments. Generalization benefits of the VOL are investigated and discussed. ",
    "url": "https://arxiv.org/abs/2304.04234",
    "authors": [
      "Tengfei Xu",
      "Dachuan Liu",
      "Peng Hao",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.04248",
    "title": "Curricular Object Manipulation in LiDAR-based Object Detection",
    "abstract": "This paper explores the potential of curriculum learning in LiDAR-based 3D object detection by proposing a curricular object manipulation (COM) framework. The framework embeds the curricular training strategy into both the loss design and the augmentation process. For the loss design, we propose the COMLoss to dynamically predict object-level difficulties and emphasize objects of different difficulties based on training stages. On top of the widely-used augmentation technique called GT-Aug in LiDAR detection tasks, we propose a novel COMAug strategy which first clusters objects in ground-truth database based on well-designed heuristics. Group-level difficulties rather than individual ones are then predicted and updated during training for stable results. Model performance and generalization capabilities can be improved by sampling and augmenting progressively more difficult objects into the training samples. Extensive experiments and ablation studies reveal the superior and generality of the proposed framework. The code is available at https://github.com/ZZY816/COM. ",
    "url": "https://arxiv.org/abs/2304.04248",
    "authors": [
      "Ziyue Zhu",
      "Qiang Meng",
      "Xiao Wang",
      "Ke Wang",
      "Liujiang Yan",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04254",
    "title": "Secure Routing Protocol To Mitigate Attacks By Using Blockchain  Technology In Manet",
    "abstract": "MANET is a collection of mobile nodes that communicate through wireless networks as they move from one point to another. MANET is an infrastructure-less network with a changeable topology; as a result, it is very susceptible to attacks. MANET attack prevention represents a serious difficulty. Malicious network nodes are the source of network-based attacks. In a MANET, attacks can take various forms, and each one alters the network's operation in its unique way. In general, attacks can be separated into two categories: those that target the data traffic on a network and those that target the control traffic. This article explains the many sorts of assaults, their impact on MANET, and the MANET-based defence measures that are currently in place. The suggested SRA that employs blockchain technology (SRABC) protects MANET from attacks and authenticates nodes. The secure routing algorithm (SRA) proposed by blockchain technology safeguards control and data flow against threats. This is achieved by generating a Hash Function for every transaction. We will begin by discussing the security of the MANET. This article's second section explores the role of blockchain in MANET security. In the third section, the SRA is described in connection with blockchain. In the fourth phase, PDR and Throughput are utilised to conduct an SRA review using Blockchain employing PDR and Throughput. The results suggest that the proposed technique enhances MANET security while concurrently decreasing delay. The performance of the proposed technique is analysed and compared to the routing protocols Q-AODV and DSR. ",
    "url": "https://arxiv.org/abs/2304.04254",
    "authors": [
      "Nitesh Ghodichor",
      "Raj Thaneeghavl. V",
      "Dinesh Sahu",
      "Gautam Borkar",
      "Ankush Sawarkar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.04278",
    "title": "Point-SLAM: Dense Neural Point Cloud-based SLAM",
    "abstract": "We propose a dense neural simultaneous localization and mapping (SLAM) approach for monocular RGBD input which anchors the features of a neural scene representation in a point cloud that is iteratively generated in an input-dependent data-driven manner. We demonstrate that both tracking and mapping can be performed with the same point-based neural scene representation by minimizing an RGBD-based re-rendering loss. In contrast to recent dense neural SLAM methods which anchor the scene features in a sparse grid, our point-based approach allows dynamically adapting the anchor point density to the information density of the input. This strategy reduces runtime and memory usage in regions with fewer details and dedicates higher point density to resolve fine details. Our approach performs either better or competitive to existing dense neural RGBD SLAM methods in tracking, mapping and rendering accuracy on the Replica, TUM-RGBD and ScanNet datasets. The source code is available at https://github.com/tfy14esa/Point-SLAM. ",
    "url": "https://arxiv.org/abs/2304.04278",
    "authors": [
      "Erik Sandstr\u00f6m",
      "Yue Li",
      "Luc Van Gool",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04298",
    "title": "Unsupervised Sampling Promoting for Stochastic Human Trajectory  Prediction",
    "abstract": "The indeterminate nature of human motion requires trajectory prediction systems to use a probabilistic model to formulate the multi-modality phenomenon and infer a finite set of future trajectories. However, the inference processes of most existing methods rely on Monte Carlo random sampling, which is insufficient to cover the realistic paths with finite samples, due to the long tail effect of the predicted distribution. To promote the sampling process of stochastic prediction, we propose a novel method, called BOsampler, to adaptively mine potential paths with Bayesian optimization in an unsupervised manner, as a sequential design strategy in which new prediction is dependent on the previously drawn samples. Specifically, we model the trajectory sampling as a Gaussian process and construct an acquisition function to measure the potential sampling value. This acquisition function applies the original distribution as prior and encourages exploring paths in the long-tail region. This sampling method can be integrated with existing stochastic predictive models without retraining. Experimental results on various baseline methods demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2304.04298",
    "authors": [
      "Guangyi Chen",
      "Zhenhao Chen",
      "Shunxing Fan",
      "Kun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04308",
    "title": "Ensemble Modeling for Time Series Forecasting: an Adaptive Robust  Optimization Approach",
    "abstract": "Accurate time series forecasting is critical for a wide range of problems with temporal data. Ensemble modeling is a well-established technique for leveraging multiple predictive models to increase accuracy and robustness, as the performance of a single predictor can be highly variable due to shifts in the underlying data distribution. This paper proposes a new methodology for building robust ensembles of time series forecasting models. Our approach utilizes Adaptive Robust Optimization (ARO) to construct a linear regression ensemble in which the models' weights can adapt over time. We demonstrate the effectiveness of our method through a series of synthetic experiments and real-world applications, including air pollution management, energy consumption forecasting, and tropical cyclone intensity forecasting. Our results show that our adaptive ensembles outperform the best ensemble member in hindsight by 16-26% in root mean square error and 14-28% in conditional value at risk and improve over competitive ensemble techniques. ",
    "url": "https://arxiv.org/abs/2304.04308",
    "authors": [
      "Dimitris Bertsimas",
      "Leonard Boussioux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.04325",
    "title": "Self-Supervised Learning of Object Segmentation from Unlabeled RGB-D  Videos",
    "abstract": "This work proposes a self-supervised learning system for segmenting rigid objects in RGB images. The proposed pipeline is trained on unlabeled RGB-D videos of static objects, which can be captured with a camera carried by a mobile robot. A key feature of the self-supervised training process is a graph-matching algorithm that operates on the over-segmentation output of the point cloud that is reconstructed from each video. The graph matching, along with point cloud registration, is able to find reoccurring object patterns across videos and combine them into 3D object pseudo labels, even under occlusions or different viewing angles. Projected 2D object masks from 3D pseudo labels are used to train a pixel-wise feature extractor through contrastive learning. During online inference, a clustering method uses the learned features to cluster foreground pixels into object segments. Experiments highlight the method's effectiveness on both real and synthetic video datasets, which include cluttered scenes of tabletop objects. The proposed method outperforms existing unsupervised methods for object segmentation by a large margin. ",
    "url": "https://arxiv.org/abs/2304.04325",
    "authors": [
      "Shiyang Lu",
      "Yunfu Deng",
      "Abdeslam Boularias",
      "Kostas Bekris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.04327",
    "title": "Online Networks of Support in Distressed Environments: Solidarity and  Mobilization during the Russian Invasion of Ukraine",
    "abstract": "Despite their drawbacks and unintended consequences, social media networks have recently emerged as a crucial resource for individuals in distress, particularly during times of crisis. These platforms serve as a means to seek assistance and support, share reliable information, and appeal for action and solidarity. In this paper, we examine the online networks of support during the Russia-Ukraine conflict by analyzing four major social media networks- Twitter, Facebook, Instagram, and YouTube. Using a large dataset of 68 million posts, we explore the temporal patterns and interconnectedness between these platforms and online support websites. Our analysis highlights the prevalence of crowdsourcing and crowdfunding websites as the two main support platforms to mobilize resources and solicit donations, revealing their purpose and contents, and investigating different support-seeking and -receiving practices. Overall, our study underscores the potential of social media in facilitating online support in distressed environments through grassroots mobilization, contributing to the growing body of research on the positive impact of online platforms in promoting social good and protecting vulnerable populations during times of crisis and conflict. ",
    "url": "https://arxiv.org/abs/2304.04327",
    "authors": [
      "Jinyi Ye",
      "Nikhil Jindal",
      "Francesco Pierri",
      "Luca Luceri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.04333",
    "title": "Agronav: Autonomous Navigation Framework for Agricultural Robots and  Vehicles using Semantic Segmentation and Semantic Line Detection",
    "abstract": "The successful implementation of vision-based navigation in agricultural fields hinges upon two critical components: 1) the accurate identification of key components within the scene, and 2) the identification of lanes through the detection of boundary lines that separate the crops from the traversable ground. We propose Agronav, an end-to-end vision-based autonomous navigation framework, which outputs the centerline from the input image by sequentially processing it through semantic segmentation and semantic line detection models. We also present Agroscapes, a pixel-level annotated dataset collected across six different crops, captured from varying heights and angles. This ensures that the framework trained on Agroscapes is generalizable across both ground and aerial robotic platforms. Codes, models and dataset will be released at \\href{https://github.com/shivamkumarpanda/agronav}{github.com/shivamkumarpanda/agronav}. ",
    "url": "https://arxiv.org/abs/2304.04333",
    "authors": [
      "Shivam K Panda",
      "Yongkyu Lee",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04343",
    "title": "Certifiable Black-Box Attack: Ensuring Provably Successful Attack for  Adversarial Examples",
    "abstract": "Black-box adversarial attacks have shown strong potential to subvert machine learning models. Existing black-box adversarial attacks craft the adversarial examples by iteratively querying the target model and/or leveraging the transferability of a local surrogate model. Whether such attack can succeed remains unknown to the adversary when empirically designing the attack. In this paper, to our best knowledge, we take the first step to study a new paradigm of adversarial attacks -- certifiable black-box attack that can guarantee the attack success rate of the crafted adversarial examples. Specifically, we revise the randomized smoothing to establish novel theories for ensuring the attack success rate of the adversarial examples. To craft the adversarial examples with the certifiable attack success rate (CASR) guarantee, we design several novel techniques, including a randomized query method to query the target model, an initialization method with smoothed self-supervised perturbation to derive certifiable adversarial examples, and a geometric shifting method to reduce the perturbation size of the certifiable adversarial examples for better imperceptibility. We have comprehensively evaluated the performance of the certifiable black-box attack on CIFAR10 and ImageNet datasets against different levels of defenses. Both theoretical and experimental results have validated the effectiveness of the proposed certifiable attack. ",
    "url": "https://arxiv.org/abs/2304.04343",
    "authors": [
      "Hanbin Hong",
      "Yuan Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.04368",
    "title": "Locality Preserving Multiview Graph Hashing for Large Scale Remote  Sensing Image Search",
    "abstract": "Hashing is very popular for remote sensing image search. This article proposes a multiview hashing with learnable parameters to retrieve the queried images for a large-scale remote sensing dataset. Existing methods always neglect that real-world remote sensing data lies on a low-dimensional manifold embedded in high-dimensional ambient space. Unlike previous methods, this article proposes to learn the consensus compact codes in a view-specific low-dimensional subspace. Furthermore, we have added a hyperparameter learnable module to avoid complex parameter tuning. In order to prove the effectiveness of our method, we carried out experiments on three widely used remote sensing data sets and compared them with seven state-of-the-art methods. Extensive experiments show that the proposed method can achieve competitive results compared to the other method. ",
    "url": "https://arxiv.org/abs/2304.04368",
    "authors": [
      "Wenyun Li",
      "Guo Zhong",
      "Xingyu Lu",
      "Chi-Man Pun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04385",
    "title": "On Robustness in Multimodal Learning",
    "abstract": "Multimodal learning is defined as learning over multiple heterogeneous input modalities such as video, audio, and text. In this work, we are concerned with understanding how models behave as the type of modalities differ between training and deployment, a situation that naturally arises in many applications of multimodal learning to hardware platforms. We present a multimodal robustness framework to provide a systematic analysis of common multimodal representation learning methods. Further, we identify robustness short-comings of these approaches and propose two intervention techniques leading to $1.5\\times$-$4\\times$ robustness improvements on three datasets, AudioSet, Kinetics-400 and ImageNet-Captions. Finally, we demonstrate that these interventions better utilize additional modalities, if present, to achieve competitive results of $44.2$ mAP on AudioSet 20K. ",
    "url": "https://arxiv.org/abs/2304.04385",
    "authors": [
      "randon McKinzie",
      "Joseph Cheng",
      "Vaishaal Shankar",
      "Yinfei Yang",
      "Jonathon Shlens",
      "Alexander Toshev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04386",
    "title": "Generating Adversarial Attacks in the Latent Space",
    "abstract": "Adversarial attacks in the input (pixel) space typically incorporate noise margins such as $L_1$ or $L_{\\infty}$-norm to produce imperceptibly perturbed data that confound deep learning networks. Such noise margins confine the magnitude of permissible noise. In this work, we propose injecting adversarial perturbations in the latent (feature) space using a generative adversarial network, removing the need for margin-based priors. Experiments on MNIST, CIFAR10, Fashion-MNIST, CIFAR100 and Stanford Dogs datasets support the effectiveness of the proposed method in generating adversarial attacks in the latent space while ensuring a high degree of visual realism with respect to pixel-based adversarial attack methods. ",
    "url": "https://arxiv.org/abs/2304.04386",
    "authors": [
      "Nitish Shukla",
      "Sudipta Banerjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04389",
    "title": "Deep Active Alignment of Knowledge Graph Entities and Schemata",
    "abstract": "Knowledge graphs (KGs) store rich facts about the real world. In this paper, we study KG alignment, which aims to find alignment between not only entities but also relations and classes in different KGs. Alignment at the entity level can cross-fertilize alignment at the schema level. We propose a new KG alignment approach, called DAAKG, based on deep learning and active learning. With deep learning, it learns the embeddings of entities, relations and classes, and jointly aligns them in a semi-supervised manner. With active learning, it estimates how likely an entity, relation or class pair can be inferred, and selects the best batch for human labeling. We design two approximation algorithms for efficient solution to batch selection. Our experiments on benchmark datasets show the superior accuracy and generalization of DAAKG and validate the effectiveness of all its modules. ",
    "url": "https://arxiv.org/abs/2304.04389",
    "authors": [
      "Jiacheng Huang",
      "Zequn Sun",
      "Qijin Chen",
      "Xiaozhou Xu",
      "Weijun Ren",
      "Wei Hu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04391",
    "title": "CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised  Representation Learning on Graphs",
    "abstract": "Unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. When deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. Consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. One major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). In this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. We propose CAFIN (Centrality Aware Fairness inducing IN-processing), an in-processing technique that leverages graph structure to improve GraphSAGE's representations - a popular framework in the unsupervised inductive setting. We demonstrate the efficacy of CAFIN in the inductive setting on two popular downstream tasks - Link prediction and Node Classification. Empirically, they consistently minimize the disparity in fairness between groups across datasets (varying from 18 to 80% reduction in imparity, a measure of group fairness) from different domains while incurring only a minimal performance cost. ",
    "url": "https://arxiv.org/abs/2304.04391",
    "authors": [
      "Arvindh Arun",
      "Aakash Aanegola",
      "Amul Agrawal",
      "Ramasuri Narayanam",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.04395",
    "title": "Instance Neural Radiance Field",
    "abstract": "This paper presents one of the first learning-based NeRF 3D instance segmentation pipelines, dubbed as Instance Neural Radiance Field, or Instance NeRF. Taking a NeRF pretrained from multi-view RGB images as input, Instance NeRF can learn 3D instance segmentation of a given scene, represented as an instance field component of the NeRF model. To this end, we adopt a 3D proposal-based mask prediction network on the sampled volumetric features from NeRF, which generates discrete 3D instance masks. The coarse 3D mask prediction is then projected to image space to match 2D segmentation masks from different views generated by existing panoptic segmentation models, which are used to supervise the training of the instance field. Notably, beyond generating consistent 2D segmentation maps from novel views, Instance NeRF can query instance information at any 3D point, which greatly enhances NeRF object segmentation and manipulation. Our method is also one of the first to achieve such results without ground-truth instance information during inference. Experimented on synthetic and real-world NeRF datasets with complex indoor scenes, Instance NeRF surpasses previous NeRF segmentation works and competitive 2D segmentation methods in segmentation performance on unseen views. See the demo video at https://youtu.be/wW9Bme73coI. ",
    "url": "https://arxiv.org/abs/2304.04395",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04398",
    "title": "Ransomware Detection and Classification Strategies",
    "abstract": "Ransomware uses encryption methods to make data inaccessible to legitimate users. To date a wide range of ransomware families have been developed and deployed, causing immense damage to governments, corporations, and private users. As these cyberthreats multiply, researchers have proposed a range of ransomware detection and classification schemes. Most of these methods use advanced machine learning techniques to process and analyze real-world ransomware binaries and action sequences. Hence this paper presents a survey of this critical space and classifies existing solutions into several categories, i.e., including network-based, host-based, forensic characterization, and authorship attribution. Key facilities and tools for ransomware analysis are also presented along with open challenges. ",
    "url": "https://arxiv.org/abs/2304.04398",
    "authors": [
      "Aldin Vehabovic",
      "Nasir Ghani",
      "Elias Bou-Harb",
      "Jorge Crichigno",
      "Aysegul Yayimli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.04403",
    "title": "H2RBox-v2: Boosting HBox-supervised Oriented Object Detection via  Symmetric Learning",
    "abstract": "With the increasing demand for oriented object detection e.g. in autonomous driving and remote sensing, the oriented annotation has become a labor-intensive work. To make full use of existing horizontally annotated datasets and reduce the annotation cost, a weakly-supervised detector H2RBox for learning the rotated box (RBox) from the horizontal box (HBox) has been proposed and received great attention. This paper presents a new version, H2RBox-v2, to further bridge the gap between HBox-supervised and RBox-supervised oriented object detection. While exploiting axisymmetry via flipping and rotating consistencies is available through our theoretical analysis, H2RBox-v2, using a weakly-supervised branch similar to H2RBox, is embedded with a novel self-supervised branch that learns orientations from the symmetry inherent in the image of objects. Complemented by modules to cope with peripheral issues, e.g. angular periodicity, a stable and effective solution is achieved. To our knowledge, H2RBox-v2 is the first symmetry-supervised paradigm for oriented object detection. Compared to H2RBox, our method is less susceptible to low annotation quality and insufficient training data, which in such cases is expected to give a competitive performance much closer to fully-supervised oriented object detectors. Specifically, the performance comparison between H2RBox-v2 and Rotated FCOS on DOTA-v1.0/1.5/2.0 is 72.31%/64.76%/50.33% vs. 72.44%/64.53%/51.77%, 89.66% vs. 88.99% on HRSC, and 42.27% vs. 41.25% on FAIR1M. ",
    "url": "https://arxiv.org/abs/2304.04403",
    "authors": [
      "Yi Yu",
      "Xue Yang",
      "Qingyun Li",
      "Yue Zhou",
      "Gefan Zhang",
      "Junchi Yan",
      "Feipeng Da"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04420",
    "title": "Feature Representation Learning with Adaptive Displacement Generation  and Transformer Fusion for Micro-Expression Recognition",
    "abstract": "Micro-expressions are spontaneous, rapid and subtle facial movements that can neither be forged nor suppressed. They are very important nonverbal communication clues, but are transient and of low intensity thus difficult to recognize. Recently deep learning based methods have been developed for micro-expression (ME) recognition using feature extraction and fusion techniques, however, targeted feature learning and efficient feature fusion still lack further study according to the ME characteristics. To address these issues, we propose a novel framework Feature Representation Learning with adaptive Displacement Generation and Transformer fusion (FRL-DGT), in which a convolutional Displacement Generation Module (DGM) with self-supervised learning is used to extract dynamic features from onset/apex frames targeted to the subsequent ME recognition task, and a well-designed Transformer Fusion mechanism composed of three Transformer-based fusion modules (local, global fusions based on AU regions and full-face fusion) is applied to extract the multi-level informative features after DGM for the final ME prediction. The extensive experiments with solid leave-one-subject-out (LOSO) evaluation results have demonstrated the superiority of our proposed FRL-DGT to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.04420",
    "authors": [
      "Zhijun Zhai",
      "Jianhui Zhao",
      "Chengjiang Long",
      "Wenju Xu",
      "Shuangjiang He",
      "Huijuan Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04442",
    "title": "Monte Carlo Linear Clustering with Single-Point Supervision is Enough  for Infrared Small Target Detection",
    "abstract": "Single-frame infrared small target (SIRST) detection aims at separating small targets from clutter backgrounds on infrared images. Recently, deep learning based methods have achieved promising performance on SIRST detection, but at the cost of a large amount of training data with expensive pixel-level annotations. To reduce the annotation burden, we propose the first method to achieve SIRST detection with single-point supervision. The core idea of this work is to recover the per-pixel mask of each target from the given single point label by using clustering approaches, which looks simple but is indeed challenging since targets are always insalient and accompanied with background clutters. To handle this issue, we introduce randomness to the clustering process by adding noise to the input images, and then obtain much more reliable pseudo masks by averaging the clustered results. Thanks to this \"Monte Carlo\" clustering approach, our method can accurately recover pseudo masks and thus turn arbitrary fully supervised SIRST detection networks into weakly supervised ones with only single point annotation. Experiments on four datasets demonstrate that our method can be applied to existing SIRST detection networks to achieve comparable performance with their fully supervised counterparts, which reveals that single-point supervision is strong enough for SIRST detection. Our code will be available at: https://github.com/YeRen123455/SIRST-Single-Point-Supervision. ",
    "url": "https://arxiv.org/abs/2304.04442",
    "authors": [
      "Boyang Li",
      "Yingqian Wang",
      "Longguang Wang",
      "Fei Zhang",
      "Ting Liu",
      "Zaiping Lin",
      "Wei An",
      "Yulan Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04452",
    "title": "Neural Residual Radiance Fields for Streamably Free-Viewpoint Videos",
    "abstract": "The success of the Neural Radiance Fields (NeRFs) for modeling and free-view rendering static objects has inspired numerous attempts on dynamic scenes. Current techniques that utilize neural rendering for facilitating free-view videos (FVVs) are restricted to either offline rendering or are capable of processing only brief sequences with minimal motion. In this paper, we present a novel technique, Residual Radiance Field or ReRF, as a highly compact neural representation to achieve real-time FVV rendering on long-duration dynamic scenes. ReRF explicitly models the residual information between adjacent timestamps in the spatial-temporal feature space, with a global coordinate-based tiny MLP as the feature decoder. Specifically, ReRF employs a compact motion grid along with a residual feature grid to exploit inter-frame feature similarities. We show such a strategy can handle large motions without sacrificing quality. We further present a sequential training scheme to maintain the smoothness and the sparsity of the motion/residual grids. Based on ReRF, we design a special FVV codec that achieves three orders of magnitudes compression rate and provides a companion ReRF player to support online streaming of long-duration FVVs of dynamic scenes. Extensive experiments demonstrate the effectiveness of ReRF for compactly representing dynamic radiance fields, enabling an unprecedented free-viewpoint viewing experience in speed and quality. ",
    "url": "https://arxiv.org/abs/2304.04452",
    "authors": [
      "Liao Wang",
      "Qiang Hu",
      "Qihan He",
      "Ziyu Wang",
      "Jingyi Yu",
      "Tinne Tuytelaars",
      "Lan Xu",
      "Minye Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04455",
    "title": "Bayesian optimization for sparse neural networks with trainable  activation functions",
    "abstract": "In the literature on deep neural networks, there is considerable interest in developing activation functions that can enhance neural network performance. In recent years, there has been renewed scientific interest in proposing activation functions that can be trained throughout the learning process, as they appear to improve network performance, especially by reducing overfitting. In this paper, we propose a trainable activation function whose parameters need to be estimated. A fully Bayesian model is developed to automatically estimate from the learning data both the model weights and activation function parameters. An MCMC-based optimization scheme is developed to build the inference. The proposed method aims to solve the aforementioned problems and improve convergence time by using an efficient sampling scheme that guarantees convergence to the global maximum. The proposed scheme is tested on three datasets with three different CNNs. Promising results demonstrate the usefulness of our proposed approach in improving model accuracy due to the proposed activation function and Bayesian estimation of the parameters. ",
    "url": "https://arxiv.org/abs/2304.04455",
    "authors": [
      "Mohamed Fakhfakh",
      "Lotfi Chaari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2304.04468",
    "title": "Toward Cohort Intelligence: A Universal Cohort Representation Learning  Framework for Electronic Health Record Analysis",
    "abstract": "Electronic Health Records (EHR) are generated from clinical routine care recording valuable information of broad patient populations, which provide plentiful opportunities for improving patient management and intervention strategies in clinical practice. To exploit the enormous potential of EHR data, a popular EHR data analysis paradigm in machine learning is EHR representation learning, which first leverages the individual patient's EHR data to learn informative representations by a backbone, and supports diverse health-care downstream tasks grounded on the representations. Unfortunately, such a paradigm fails to access the in-depth analysis of patients' relevance, which is generally known as cohort studies in clinical practice. Specifically, patients in the same cohort tend to share similar characteristics, implying their resemblance in medical conditions such as symptoms or diseases. In this paper, we propose a universal COhort Representation lEarning (CORE) framework to augment EHR utilization by leveraging the fine-grained cohort information among patients. In particular, CORE first develops an explicit patient modeling task based on the prior knowledge of patients' diagnosis codes, which measures the latent relevance among patients to adaptively divide the cohorts for each patient. Based on the constructed cohorts, CORE recodes the pre-extracted EHR data representation from intra- and inter-cohort perspectives, yielding augmented EHR data representation learning. CORE is readily applicable to diverse backbone models, serving as a universal plug-in framework to infuse cohort information into healthcare methods for boosted performance. We conduct an extensive experimental evaluation on two real-world datasets, and the experimental results demonstrate the effectiveness and generalizability of CORE. ",
    "url": "https://arxiv.org/abs/2304.04468",
    "authors": [
      "Changshuo Liu",
      "Wenqiao Zhang",
      "Lingze Zeng",
      "Beng Chin Ooi",
      "James Wei Luen Yip",
      "Kaiping Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04470",
    "title": "Kernel Code for DNA Digital Data Storage",
    "abstract": "The biggest challenge when using DNA as a storage medium is maintaining its stability. The relative occurrence of Guanine (G) and Cytosine (C) is essential for the longevity of DNA. In addition to that, reverse complementary base pairs should not be present in the code. These challenges are overcome by a proper choice of group homomorphisms. Algorithms for storage and retrieval of information in DNA stings are written by using kernel code. Complexities of these algorithms are less compared to the existing algorithms. Construction procedures followed in this paper are capable of constructing codes of required sizes and Reverse complement distance. ",
    "url": "https://arxiv.org/abs/2304.04470",
    "authors": [
      "NallappaBhavithran G",
      "Selvakumar R"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.04472",
    "title": "Modeling Speaker-Listener Interaction for Backchannel Prediction",
    "abstract": "We present our latest findings on backchannel modeling novelly motivated by the canonical use of the minimal responses Yeah and Uh-huh in English and their correspondent tokens in German, and the effect of encoding the speaker-listener interaction. Backchanneling theories emphasize the active and continuous role of the listener in the course of the conversation, their effects on the speaker's subsequent talk, and the consequent dynamic speaker-listener interaction. Therefore, we propose a neural-based acoustic backchannel classifier on minimal responses by processing acoustic features from the speaker speech, capturing and imitating listeners' backchanneling behavior, and encoding speaker-listener interaction. Our experimental results on the Switchboard and GECO datasets reveal that in almost all tested scenarios the speaker or listener behavior embeddings help the model make more accurate backchannel predictions. More importantly, a proper interaction encoding strategy, i.e., combining the speaker and listener embeddings, leads to the best performance on both datasets in terms of F1-score. ",
    "url": "https://arxiv.org/abs/2304.04472",
    "authors": [
      "Daniel Ortega",
      "Sarina Meyer",
      "Antje Schweitzer",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04474",
    "title": "Missing Data Imputation with Graph Laplacian Pyramid Network",
    "abstract": "Data imputation is a prevalent and important task due to the ubiquitousness of missing data. Many efforts try to first draft a completed data and second refine to derive the imputation results, or \"draft-then-refine\" for short. In this work, we analyze this widespread practice from the perspective of Dirichlet energy. We find that a rudimentary \"draft\" imputation will decrease the Dirichlet energy, thus an energy-maintenance \"refine\" step is in need to recover the overall energy. Since existing \"refine\" methods such as Graph Convolutional Network (GCN) tend to cause further energy decline, in this work, we propose a novel framework called Graph Laplacian Pyramid Network (GLPN) to preserve Dirichlet energy and improve imputation performance. GLPN consists of a U-shaped autoencoder and residual networks to capture global and local detailed information respectively. By extensive experiments on several real-world datasets, GLPN shows superior performance over state-of-the-art methods under three different missing mechanisms. Our source code is available at https://github.com/liguanlue/GLPN. ",
    "url": "https://arxiv.org/abs/2304.04474",
    "authors": [
      "Weiqi Zhang",
      "Guanlve Li",
      "Jianheng Tang",
      "Jia Li",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04480",
    "title": "On the existence of highly organized communities in networks of locally  interacting agents",
    "abstract": "In this paper we investigate phenomena of spontaneous emergence or purposeful formation of highly organized structures in networks of related agents. We show that the formation of large organized structures requires exponentially large, in the size of the structures, networks. Our approach is based on Kolmogorov, or descriptional, complexity of networks viewed as finite size strings. We apply this approach to the study of the emergence or formation of simple organized, hierarchical, structures based on Sierpinski Graphs and we prove a Ramsey type theorem that bounds the number of vertices in Kolmogorov random graphs that contain Sierpinski Graphs as subgraphs. Moreover, we show that Sierpinski Graphs encompass close-knit relationships among their vertices that facilitate fast spread and learning of information when agents in their vertices are engaged in pairwise interactions modelled as two person games. Finally, we generalize our findings for any organized structure with succinct representations. Our work can be deployed, in particular, to study problems related to the security of networks by identifying conditions which enable or forbid the formation of sufficiently large insider subnetworks with malicious common goal to overtake the network or cause disruption of its operation. ",
    "url": "https://arxiv.org/abs/2304.04480",
    "authors": [
      "V. Liagkou",
      "P.E. Nastou",
      "P. Spirakis",
      "Y.C. Stamatiou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.04496",
    "title": "DeFeeNet: Consecutive 3D Human Motion Prediction with Deviation Feedback",
    "abstract": "Let us rethink the real-world scenarios that require human motion prediction techniques, such as human-robot collaboration. Current works simplify the task of predicting human motions into a one-off process of forecasting a short future sequence (usually no longer than 1 second) based on a historical observed one. However, such simplification may fail to meet practical needs due to the neglect of the fact that motion prediction in real applications is not an isolated ``observe then predict'' unit, but a consecutive process composed of many rounds of such unit, semi-overlapped along the entire sequence. As time goes on, the predicted part of previous round has its corresponding ground truth observable in the new round, but their deviation in-between is neither exploited nor able to be captured by existing isolated learning fashion. In this paper, we propose DeFeeNet, a simple yet effective network that can be added on existing one-off prediction models to realize deviation perception and feedback when applied to consecutive motion prediction task. At each prediction round, the deviation generated by previous unit is first encoded by our DeFeeNet, and then incorporated into the existing predictor to enable a deviation-aware prediction manner, which, for the first time, allows for information transmit across adjacent prediction units. We design two versions of DeFeeNet as MLP-based and GRU-based, respectively. On Human3.6M and more complicated BABEL, experimental results indicate that our proposed network improves consecutive human motion prediction performance regardless of the basic model. ",
    "url": "https://arxiv.org/abs/2304.04496",
    "authors": [
      "Xiaoning Sun",
      "Huaijiang Sun",
      "Bin Li",
      "Dong Wei",
      "Weiqing Li",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04497",
    "title": "Graph Neural Network-Aided Exploratory Learning for Community Detection  with Unknown Topology",
    "abstract": "In social networks, the discovery of community structures has received considerable attention as a fundamental problem in various network analysis tasks. However, due to privacy concerns or access restrictions, the network structure is often unknown, thereby rendering established community detection approaches ineffective without costly network topology acquisition. To tackle this challenge, we present META-CODE, a novel end-to-end solution for detecting overlapping communities in networks with unknown topology via exploratory learning aided by easy-to-collect node metadata. Specifically, META-CODE consists of three iterative steps in addition to the initial network inference step: 1) node-level community-affiliation embeddings based on graph neural networks (GNNs) trained by our new reconstruction loss, 2) network exploration via community affiliation-based node queries, and 3) network inference using an edge connectivity-based Siamese neural network model from the explored network. Through comprehensive evaluations using five real-world datasets, we demonstrate that META-CODE exhibits (a) its superiority over benchmark community detection methods, (b) empirical evaluations as well as theoretical findings to see the effectiveness of our node query, (c) the influence of each module, and (d) its computational efficiency. ",
    "url": "https://arxiv.org/abs/2304.04497",
    "authors": [
      "Yu Hou",
      "Cong Tran",
      "Ming Li",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.04503",
    "title": "Head-tail Loss: A simple function for Oriented Object Detection and  Anchor-free models",
    "abstract": "This paper presents a new loss function for the prediction of oriented bounding boxes, named head-tail-loss. The loss function consists in minimizing the distance between the prediction and the annotation of two key points that are representing the annotation of the object. The first point is the center point and the second is the head of the object. However, for the second point, the minimum distance between the prediction and either the head or tail of the groundtruth is used. On this way, either prediction is valid (with the head pointing to the tail or the tail pointing to the head). At the end the importance is to detect the direction of the object but not its heading. The new loss function has been evaluated on the DOTA and HRSC2016 datasets and has shown potential for elongated objects such as ships and also for other types of objects with different shapes. ",
    "url": "https://arxiv.org/abs/2304.04503",
    "authors": [
      "Pau Gall\u00e9s",
      "Xi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04512",
    "title": "Defense-Prefix for Preventing Typographic Attacks on CLIP",
    "abstract": "Vision-language pre-training models (VLPs) have exhibited revolutionary improvements in various vision-language tasks. In VLP, some adversarial attacks fool a model into false or absurd classifications. Previous studies addressed these attacks by fine-tuning the model or changing its architecture. However, these methods risk losing the original model's performance and are difficult to apply to downstream tasks. In particular, their applicability to other tasks has not been considered. In this study, we addressed the reduction of the impact of typographic attacks on CLIP without changing the model parameters. To achieve this, we expand the idea of ``prefix learning'' and introduce our simple yet effective method: Defense-Prefix (DP), which inserts the DP token before a class name to make words ``robust'' against typographic attacks. Our method can be easily applied to downstream tasks, such as object detection, because the proposed method is independent of the model parameters. Our method significantly improves the accuracy of classification tasks for typographic attack datasets, while maintaining the zero-shot capabilities of the model. In addition, we leverage our proposed method for object detection, demonstrating its high applicability and effectiveness. The codes and datasets will be publicly available. ",
    "url": "https://arxiv.org/abs/2304.04512",
    "authors": [
      "Hiroki Azuma",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04514",
    "title": "DetCLIPv2: Scalable Open-Vocabulary Object Detection Pre-training via  Word-Region Alignment",
    "abstract": "This paper presents DetCLIPv2, an efficient and scalable training framework that incorporates large-scale image-text pairs to achieve open-vocabulary object detection (OVD). Unlike previous OVD frameworks that typically rely on a pre-trained vision-language model (e.g., CLIP) or exploit image-text pairs via a pseudo labeling process, DetCLIPv2 directly learns the fine-grained word-region alignment from massive image-text pairs in an end-to-end manner. To accomplish this, we employ a maximum word-region similarity between region proposals and textual words to guide the contrastive objective. To enable the model to gain localization capability while learning broad concepts, DetCLIPv2 is trained with a hybrid supervision from detection, grounding and image-text pair data under a unified data formulation. By jointly training with an alternating scheme and adopting low-resolution input for image-text pairs, DetCLIPv2 exploits image-text pair data efficiently and effectively: DetCLIPv2 utilizes 13X more image-text pairs than DetCLIP with a similar training time and improves performance. With 13M image-text pairs for pre-training, DetCLIPv2 demonstrates superior open-vocabulary detection performance, e.g., DetCLIPv2 with Swin-T backbone achieves 40.4% zero-shot AP on the LVIS benchmark, which outperforms previous works GLIP/GLIPv2/DetCLIP by 14.4/11.4/4.5% AP, respectively, and even beats its fully-supervised counterpart by a large margin. ",
    "url": "https://arxiv.org/abs/2304.04514",
    "authors": [
      "Lewei Yao",
      "Jianhua Han",
      "Xiaodan Liang",
      "Dan Xu",
      "Wei Zhang",
      "Zhenguo Li",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04515",
    "title": "SOOD: Towards Semi-Supervised Oriented Object Detection",
    "abstract": "Semi-Supervised Object Detection (SSOD), aiming to explore unlabeled data for boosting object detectors, has become an active task in recent years. However, existing SSOD approaches mainly focus on horizontal objects, leaving multi-oriented objects that are common in aerial images unexplored. This paper proposes a novel Semi-supervised Oriented Object Detection model, termed SOOD, built upon the mainstream pseudo-labeling framework. Towards oriented objects in aerial scenes, we design two loss functions to provide better supervision. Focusing on the orientations of objects, the first loss regularizes the consistency between each pseudo-label-prediction pair (includes a prediction and its corresponding pseudo label) with adaptive weights based on their orientation gap. Focusing on the layout of an image, the second loss regularizes the similarity and explicitly builds the many-to-many relation between the sets of pseudo-labels and predictions. Such a global consistency constraint can further boost semi-supervised learning. Our experiments show that when trained with the two proposed losses, SOOD surpasses the state-of-the-art SSOD methods under various settings on the DOTA-v1.5 benchmark. The code will be available at https://github.com/HamPerdredes/SOOD. ",
    "url": "https://arxiv.org/abs/2304.04515",
    "authors": [
      "Wei Hua",
      "Dingkang Liang",
      "Jingyu Li",
      "Xiaolong Liu",
      "Zhikang Zou",
      "Xiaoqing Ye",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04518",
    "title": "Are Visual Recognition Models Robust to Image Compression?",
    "abstract": "Reducing the data footprint of visual content via image compression is essential to reduce storage requirements, but also to reduce the bandwidth and latency requirements for transmission. In particular, the use of compressed images allows for faster transfer of data, and faster response times for visual recognition in edge devices that rely on cloud-based services. In this paper, we first analyze the impact of image compression using traditional codecs, as well as recent state-of-the-art neural compression approaches, on three visual recognition tasks: image classification, object detection, and semantic segmentation. We consider a wide range of compression levels, ranging from 0.1 to 2 bits-per-pixel (bpp). We find that for all three tasks, the recognition ability is significantly impacted when using strong compression. For example, for segmentation mIoU is reduced from 44.5 to 30.5 mIoU when compressing to 0.1 bpp using the best compression model we evaluated. Second, we test to what extent this performance drop can be ascribed to a loss of relevant information in the compressed image, or to a lack of generalization of visual recognition models to images with compression artefacts. We find that to a large extent the performance loss is due to the latter: by finetuning the recognition models on compressed training images, most of the performance loss is recovered. For example, bringing segmentation accuracy back up to 42 mIoU, i.e. recovering 82% of the original drop in accuracy. ",
    "url": "https://arxiv.org/abs/2304.04518",
    "authors": [
      "Jo\u00e3o Maria Janeiro",
      "Stanislav Frolov",
      "Alaaeldin El-Nouby",
      "Jakob Verbeek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04521",
    "title": "Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models",
    "abstract": "Removing out-of-distribution (OOD) images from noisy images scraped from the Internet is an important preprocessing for constructing datasets, which can be addressed by zero-shot OOD detection with vision language foundation models (CLIP). The existing zero-shot OOD detection setting does not consider the realistic case where an image has both in-distribution (ID) objects and OOD objects. However, it is important to identify such images as ID images when collecting the images of rare classes or ethically inappropriate classes that must not be missed. In this paper, we propose a novel problem setting called in-distribution (ID) detection, where we identify images containing ID objects as ID images, even if they contain OOD objects, and images lacking ID objects as OOD images. To solve this problem, we present a new approach, \\textbf{G}lobal-\\textbf{L}ocal \\textbf{M}aximum \\textbf{C}oncept \\textbf{M}atching (GL-MCM), based on both global and local visual-text alignments of CLIP features, which can identify any image containing ID objects as ID images. Extensive experiments demonstrate that GL-MCM outperforms comparison methods on both multi-object datasets and single-object ImageNet benchmarks. ",
    "url": "https://arxiv.org/abs/2304.04521",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04523",
    "title": "PoseFusion: Robust Object-in-Hand Pose Estimation with SelectLSTM",
    "abstract": "Accurate estimation of the relative pose between an object and a robot hand is critical for many manipulation tasks. However, most of the existing object-in-hand pose datasets use two-finger grippers and also assume that the object remains fixed in the hand without any relative movements, which is not representative of real-world scenarios. To address this issue, a 6D object-in-hand pose dataset is proposed using a teleoperation method with an anthropomorphic Shadow Dexterous hand. Our dataset comprises RGB-D images, proprioception and tactile data, covering diverse grasping poses, finger contact states, and object occlusions. To overcome the significant hand occlusion and limited tactile sensor contact in real-world scenarios, we propose PoseFusion, a hybrid multi-modal fusion approach that integrates the information from visual and tactile perception channels. PoseFusion generates three candidate object poses from three estimators (tactile only, visual only, and visuo-tactile fusion), which are then filtered by a SelectLSTM network to select the optimal pose, avoiding inferior fusion poses resulting from modality collapse. Extensive experiments demonstrate the robustness and advantages of our framework. All data and codes are available on the project website: https://elevenjiang1.github.io/ObjectInHand-Dataset/ ",
    "url": "https://arxiv.org/abs/2304.04523",
    "authors": [
      "Yuyang Tu",
      "Junnan Jiang",
      "Shuang Li",
      "Norman Hendrich",
      "Miao Li",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.04529",
    "title": "FAN: Fatigue-Aware Network for Click-Through Rate Prediction in  E-commerce Recommendation",
    "abstract": "Since clicks usually contain heavy noise, increasing research efforts have been devoted to modeling implicit negative user behaviors (i.e., non-clicks). However, they either rely on explicit negative user behaviors (e.g., dislikes) or simply treat non-clicks as negative feedback, failing to learn negative user interests comprehensively. In such situations, users may experience fatigue because of seeing too many similar recommendations. In this paper, we propose Fatigue-Aware Network (FAN), a novel CTR model that directly perceives user fatigue from non-clicks. Specifically, we first apply Fourier Transformation to the time series generated from non-clicks, obtaining its frequency spectrum which contains comprehensive information about user fatigue. Then the frequency spectrum is modulated by category information of the target item to model the bias that both the upper bound of fatigue and users' patience is different for different categories. Moreover, a gating network is adopted to model the confidence of user fatigue and an auxiliary task is designed to guide the learning of user fatigue, so we can obtain a well-learned fatigue representation and combine it with user interests for the final CTR prediction. Experimental results on real-world datasets validate the superiority of FAN and online A/B tests also show FAN outperforms representative CTR models significantly. ",
    "url": "https://arxiv.org/abs/2304.04529",
    "authors": [
      "Ming Li",
      "Naiyin Liu",
      "Xiaofeng Pan",
      "Yang Huang",
      "Ningning Li",
      "Yingmin Su",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04537",
    "title": "Deepfake Detection of Occluded Images Using a Patch-based Approach",
    "abstract": "DeepFake involves the use of deep learning and artificial intelligence techniques to produce or change video and image contents typically generated by GANs. Moreover, it can be misused and leads to fictitious news, ethical and financial crimes, and also affects the performance of facial recognition systems. Thus, detection of real or fake images is significant specially to authenticate originality of people's images or videos. One of the most important challenges in this topic is obstruction that decreases the system precision. In this study, we present a deep learning approach using the entire face and face patches to distinguish real/fake images in the presence of obstruction with a three-path decision: first entire-face reasoning, second a decision based on the concatenation of feature vectors of face patches, and third a majority vote decision based on these features. To test our approach, new datasets including real and fake images are created. For producing fake images, StyleGAN and StyleGAN2 are trained by FFHQ images and also StarGAN and PGGAN are trained by CelebA images. The CelebA and FFHQ datasets are used as real images. The proposed approach reaches higher results in early epochs than other methods and increases the SoTA results by 0.4\\%-7.9\\% in the different built data-sets. Also, we have shown in experimental results that weighing the patches may improve accuracy. ",
    "url": "https://arxiv.org/abs/2304.04537",
    "authors": [
      "Mahsa Soleimani",
      "Ali Nazari",
      "Mohsen Ebrahimi Moghaddam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04539",
    "title": "UATTA-EB: Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for  Classifying Common Mental Illnesses on Social Media Posts",
    "abstract": "Given the current state of the world, because of existing situations around the world, millions of people suffering from mental illnesses feel isolated and unable to receive help in person. Psychological studies have shown that our state of mind can manifest itself in the linguistic features we use to communicate. People have increasingly turned to online platforms to express themselves and seek help with their conditions. Deep learning methods have been commonly used to identify and analyze mental health conditions from various sources of information, including social media. Still, they face challenges, including a lack of reliability and overconfidence in predictions resulting in the poor calibration of the models. To solve these issues, We propose UATTA-EB: Uncertainty-Aware Test-Time Augmented Ensembling of BERTs for producing reliable and well-calibrated predictions to classify six possible types of mental illnesses- None, Depression, Anxiety, Bipolar Disorder, ADHD, and PTSD by analyzing unstructured user data on Reddit. ",
    "url": "https://arxiv.org/abs/2304.04539",
    "authors": [
      "Pratinav Seth",
      "Mihir Agarwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04540",
    "title": "FreConv: Frequency Branch-and-Integration Convolutional Networks",
    "abstract": "Recent researches indicate that utilizing the frequency information of input data can enhance the performance of networks. However, the existing popular convolutional structure is not designed specifically for utilizing the frequency information contained in datasets. In this paper, we propose a novel and effective module, named FreConv (frequency branch-and-integration convolution), to replace the vanilla convolution. FreConv adopts a dual-branch architecture to extract and integrate high- and low-frequency information. In the high-frequency branch, a derivative-filter-like architecture is designed to extract the high-frequency information while a light extractor is employed in the low-frequency branch because the low-frequency information is usually redundant. FreConv is able to exploit the frequency information of input data in a more reasonable way to enhance feature representation ability and reduce the memory and computational cost significantly. Without any bells and whistles, experimental results on various tasks demonstrate that FreConv-equipped networks consistently outperform state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2304.04540",
    "authors": [
      "Zhaowen Li",
      "Xu Zhao",
      "Peigeng Ding",
      "Zongxin Gao",
      "Yuting Yang",
      "Ming Tang",
      "Jinqiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04545",
    "title": "PrivLava: Synthesizing Relational Data with Foreign Keys under  Differential Privacy",
    "abstract": "Answering database queries while preserving privacy is an important problem that has attracted considerable research attention in recent years. A canonical approach to this problem is to use synthetic data. That is, we replace the input database R with a synthetic database R* that preserves the characteristics of R, and use R* to answer queries. Existing solutions for relational data synthesis, however, either fail to provide strong privacy protection, or assume that R contains a single relation. In addition, it is challenging to extend the existing single-relation solutions to the case of multiple relations, because they are unable to model the complex correlations induced by the foreign keys. Therefore, multi-relational data synthesis with strong privacy guarantees is an open problem. In this paper, we address the above open problem by proposing PrivLava, the first solution for synthesizing relational data with foreign keys under differential privacy, a rigorous privacy framework widely adopted in both academia and industry. The key idea of PrivLava is to model the data distribution in R using graphical models, with latent variables included to capture the inter-relational correlations caused by foreign keys. We show that PrivLava supports arbitrary foreign key references that form a directed acyclic graph, and is able to tackle the common case when R contains a mixture of public and private relations. Extensive experiments on census data sets and the TPC-H benchmark demonstrate that PrivLava significantly outperforms its competitors in terms of the accuracy of aggregate queries processed on the synthetic data. ",
    "url": "https://arxiv.org/abs/2304.04545",
    "authors": [
      "Kuntai Cai",
      "Xiaokui Xiao",
      "Graham Cormode"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2304.04546",
    "title": "Kinship Representation Learning with Face Componential Relation",
    "abstract": "Kinship recognition aims to determine whether the subjects in two facial images are kin or non-kin, which is an emerging and challenging problem. However, most previous methods focus on heuristic designs without considering the spatial correlation between face images. In this paper, we aim to learn discriminative kinship representations embedded with the relation information between face components (e.g., eyes, nose, etc.). To achieve this goal, we propose the Face Componential Relation Network, which learns the relationship between face components among images with a cross-attention mechanism, which automatically learns the important facial regions for kinship recognition. Moreover, we propose \\Learning, which adapts the loss function by the guidance from cross-attention to learn more discriminative feature representations. The proposed \\MainMethodAbbr~outperforms previous state-of-the-art methods by large margins for the largest public kinship recognition FIW benchmark. The code will be publicly released upon acceptance. ",
    "url": "https://arxiv.org/abs/2304.04546",
    "authors": [
      "Weng-Tai Su",
      "Min-Hung Chen",
      "Chien-Yi Wang",
      "Shang-Hong Lai",
      "Trista Pei-Chun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04554",
    "title": "Use the Detection Transformer as a Data Augmenter",
    "abstract": "Detection Transformer (DETR) is a Transformer architecture based object detection model. In this paper, we demonstrate that it can also be used as a data augmenter. We term our approach as DETR assisted CutMix, or DeMix for short. DeMix builds on CutMix, a simple yet highly effective data augmentation technique that has gained popularity in recent years. CutMix improves model performance by cutting and pasting a patch from one image onto another, yielding a new image. The corresponding label for this new example is specified as the weighted average of the original labels, where the weight is proportional to the area of the patches. CutMix selects a random patch to be cut. In contrast, DeMix elaborately selects a semantically rich patch, located by a pre-trained DETR. The label of the new image is specified in the same way as in CutMix. Experimental results on benchmark datasets for image classification demonstrate that DeMix significantly outperforms prior art data augmentation methods including CutMix. ",
    "url": "https://arxiv.org/abs/2304.04554",
    "authors": [
      "Luping Wang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04555",
    "title": "Neural Diffeomorphic Non-uniform B-spline Flows",
    "abstract": "Normalizing flows have been successfully modeling a complex probability distribution as an invertible transformation of a simple base distribution. However, there are often applications that require more than invertibility. For instance, the computation of energies and forces in physics requires the second derivatives of the transformation to be well-defined and continuous. Smooth normalizing flows employ infinitely differentiable transformation, but with the price of slow non-analytic inverse transforms. In this work, we propose diffeomorphic non-uniform B-spline flows that are at least twice continuously differentiable while bi-Lipschitz continuous, enabling efficient parametrization while retaining analytic inverse transforms based on a sufficient condition for diffeomorphism. Firstly, we investigate the sufficient condition for Ck-2-diffeomorphic non-uniform kth-order B-spline transformations. Then, we derive an analytic inverse transformation of the non-uniform cubic B-spline transformation for neural diffeomorphic non-uniform B-spline flows. Lastly, we performed experiments on solving the force matching problem in Boltzmann generators, demonstrating that our C2-diffeomorphic non-uniform B-spline flows yielded solutions better than previous spline flows and faster than smooth normalizing flows. Our source code is publicly available at https://github.com/smhongok/Non-uniform-B-spline-Flow. ",
    "url": "https://arxiv.org/abs/2304.04555",
    "authors": [
      "Seongmin Hong",
      "Se Young Chun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04566",
    "title": "Linking a predictive model to causal effect estimation",
    "abstract": "A predictive model makes outcome predictions based on some given features, i.e., it estimates the conditional probability of the outcome given a feature vector. In general, a predictive model cannot estimate the causal effect of a feature on the outcome, i.e., how the outcome will change if the feature is changed while keeping the values of other features unchanged. This is because causal effect estimation requires interventional probabilities. However, many real world problems such as personalised decision making, recommendation, and fairness computing, need to know the causal effect of any feature on the outcome for a given instance. This is different from the traditional causal effect estimation problem with a fixed treatment variable. This paper first tackles the challenge of estimating the causal effect of any feature (as the treatment) on the outcome w.r.t. a given instance. The theoretical results naturally link a predictive model to causal effect estimations and imply that a predictive model is causally interpretable when the conditions identified in the paper are satisfied. The paper also reveals the robust property of a causally interpretable model. We use experiments to demonstrate that various types of predictive models, when satisfying the conditions identified in this paper, can estimate the causal effects of features as accurately as state-of-the-art causal effect estimation methods. We also show the potential of such causally interpretable predictive models for robust predictions and personalised decision making. ",
    "url": "https://arxiv.org/abs/2304.04566",
    "authors": [
      "Jiuyong Li",
      "Lin Liu",
      "Ziqi Xu",
      "Ha Xuan Tran",
      "Thuc Duy Le",
      "Jixue Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2304.04589",
    "title": "Hyperspectral Image Super-Resolution via Dual-domain Network Based on  Hybrid Convolution",
    "abstract": "Since the number of incident energies is limited, it is difficult to directly acquire hyperspectral images (HSI) with high spatial resolution. Considering the high dimensionality and correlation of HSI, super-resolution (SR) of HSI remains a challenge in the absence of auxiliary high-resolution images. Furthermore, it is very important to extract the spatial features effectively and make full use of the spectral information. This paper proposes a novel HSI super-resolution algorithm, termed dual-domain network based on hybrid convolution (SRDNet). Specifically, a dual-domain network is designed to fully exploit the spatial-spectral and frequency information among the hyper-spectral data. To capture inter-spectral self-similarity, a self-attention learning mechanism (HSL) is devised in the spatial domain. Meanwhile the pyramid structure is applied to increase the acceptance field of attention, which further reinforces the feature representation ability of the network. Moreover, to further improve the perceptual quality of HSI, a frequency loss(HFL) is introduced to optimize the model in the frequency domain. The dynamic weighting mechanism drives the network to gradually refine the generated frequency and excessive smoothing caused by spatial loss. Finally, In order to better fully obtain the mapping relationship between high-resolution space and low-resolution space, a hybrid module of 2D and 3D units with progressive upsampling strategy is utilized in our method. Experiments on a widely used benchmark dataset illustrate that the proposed SRDNet method enhances the texture information of HSI and is superior to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.04589",
    "authors": [
      "Tingting Liu",
      "Yuan Liu",
      "Chuncheng Zhang",
      "Xiubao Sui",
      "Qian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.04598",
    "title": "In-situ crack and keyhole pore detection in laser directed energy  deposition through acoustic signal and deep learning",
    "abstract": "Cracks and keyhole pores are detrimental defects in alloys produced by laser directed energy deposition (LDED). Laser-material interaction sound may hold information about underlying complex physical events such as crack propagation and pores formation. However, due to the noisy environment and intricate signal content, acoustic-based monitoring in LDED has received little attention. This paper proposes a novel acoustic-based in-situ defect detection strategy in LDED. The key contribution of this study is to develop an in-situ acoustic signal denoising, feature extraction, and sound classification pipeline that incorporates convolutional neural networks (CNN) for online defect prediction. Microscope images are used to identify locations of the cracks and keyhole pores within a part. The defect locations are spatiotemporally registered with acoustic signal. Various acoustic features corresponding to defect-free regions, cracks, and keyhole pores are extracted and analysed in time-domain, frequency-domain, and time-frequency representations. The CNN model is trained to predict defect occurrences using the Mel-Frequency Cepstral Coefficients (MFCCs) of the lasermaterial interaction sound. The CNN model is compared to various classic machine learning models trained on the denoised acoustic dataset and raw acoustic dataset. The validation results shows that the CNN model trained on the denoised dataset outperforms others with the highest overall accuracy (89%), keyhole pore prediction accuracy (93%), and AUC-ROC score (98%). Furthermore, the trained CNN model can be deployed into an in-house developed software platform for online quality monitoring. The proposed strategy is the first study to use acoustic signals with deep learning for insitu defect detection in LDED process. ",
    "url": "https://arxiv.org/abs/2304.04598",
    "authors": [
      "Lequn Chen",
      "Xiling Yao",
      "Chaolin Tan",
      "Weiyang He",
      "Jinlong Su",
      "Fei Weng",
      "Youxiang Chew",
      "Nicholas Poh Huat Ng",
      "Seung Ki Moon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.04610",
    "title": "Attention at SemEval-2023 Task 10: Explainable Detection of Online  Sexism (EDOS)",
    "abstract": "In this paper, we have worked on interpretability, trust, and understanding of the decisions made by models in the form of classification tasks. The task is divided into 3 subtasks. The first task consists of determining Binary Sexism Detection. The second task describes the Category of Sexism. The third task describes a more Fine-grained Category of Sexism. Our work explores solving these tasks as a classification problem by fine-tuning transformer-based architecture. We have performed several experiments with our architecture, including combining multiple transformers, using domain adaptive pretraining on the unlabelled dataset provided by Reddit and Gab, Joint learning, and taking different layers of transformers as input to a classification head. Our system (with team name Attention) was able to achieve a macro F1 score of 0.839 for task A, 0.5835 macro F1 score for task B and 0.3356 macro F1 score for task C at the Codalab SemEval Competition. Later we improved the accuracy of Task B to 0.6228 and Task C to 0.3693 in the test set. ",
    "url": "https://arxiv.org/abs/2304.04610",
    "authors": [
      "Debashish Roy",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04614",
    "title": "HST-MRF: Heterogeneous Swin Transformer with Multi-Receptive Field for  Medical Image Segmentation",
    "abstract": "The Transformer has been successfully used in medical image segmentation due to its excellent long-range modeling capabilities. However, patch segmentation is necessary when building a Transformer class model. This process may disrupt the tissue structure in medical images, resulting in the loss of relevant information. In this study, we proposed a Heterogeneous Swin Transformer with Multi-Receptive Field (HST-MRF) model based on U-shaped networks for medical image segmentation. The main purpose is to solve the problem of loss of structural information caused by patch segmentation using transformer by fusing patch information under different receptive fields. The heterogeneous Swin Transformer (HST) is the core module, which achieves the interaction of multi-receptive field patch information through heterogeneous attention and passes it to the next stage for progressive learning. We also designed a two-stage fusion module, multimodal bilinear pooling (MBP), to assist HST in further fusing multi-receptive field information and combining low-level and high-level semantic information for accurate localization of lesion regions. In addition, we developed adaptive patch embedding (APE) and soft channel attention (SCA) modules to retain more valuable information when acquiring patch embedding and filtering channel features, respectively, thereby improving model segmentation quality. We evaluated HST-MRF on multiple datasets for polyp and skin lesion segmentation tasks. Experimental results show that our proposed method outperforms state-of-the-art models and can achieve superior performance. Furthermore, we verified the effectiveness of each module and the benefits of multi-receptive field segmentation in reducing the loss of structural information through ablation experiments. ",
    "url": "https://arxiv.org/abs/2304.04614",
    "authors": [
      "Xiaofei Huang",
      "Hongfang Gong",
      "Jin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04624",
    "title": "NF-Atlas: Multi-Volume Neural Feature Fields for Large Scale LiDAR  Mapping",
    "abstract": "LiDAR Mapping has been a long-standing problem in robotics. Recent progress in neural implicit representation has brought new opportunities to robotic mapping. In this paper, we propose the multi-volume neural feature fields, called NF-Atlas, which bridge the neural feature volumes with pose graph optimization. By regarding the neural feature volume as pose graph nodes and the relative pose between volumes as pose graph edges, the entire neural feature field becomes both locally rigid and globally elastic. Locally, the neural feature volume employs a sparse feature Octree and a small MLP to encode the submap SDF with an option of semantics. Learning the map using this structure allows for end-to-end solving of maximum a posteriori (MAP) based probabilistic mapping. Globally, the map is built volume by volume independently, avoiding catastrophic forgetting when mapping incrementally. Furthermore, when a loop closure occurs, with the elastic pose graph based representation, only updating the origin of neural volumes is required without remapping. Finally, these functionalities of NF-Atlas are validated. Thanks to the sparsity and the optimization based formulation, NF-Atlas shows competitive performance in terms of accuracy, efficiency and memory usage on both simulation and real-world datasets. ",
    "url": "https://arxiv.org/abs/2304.04624",
    "authors": [
      "Xuan Yu",
      "Yili Liu",
      "Sitong Mao",
      "Shunbo Zhou",
      "Rong Xiong",
      "Yiyi Liao",
      "Yue Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.04625",
    "title": "Reinforcement Learning-Based Black-Box Model Inversion Attacks",
    "abstract": "Model inversion attacks are a type of privacy attack that reconstructs private data used to train a machine learning model, solely by accessing the model. Recently, white-box model inversion attacks leveraging Generative Adversarial Networks (GANs) to distill knowledge from public datasets have been receiving great attention because of their excellent attack performance. On the other hand, current black-box model inversion attacks that utilize GANs suffer from issues such as being unable to guarantee the completion of the attack process within a predetermined number of query accesses or achieve the same level of performance as white-box attacks. To overcome these limitations, we propose a reinforcement learning-based black-box model inversion attack. We formulate the latent space search as a Markov Decision Process (MDP) problem and solve it with reinforcement learning. Our method utilizes the confidence scores of the generated images to provide rewards to an agent. Finally, the private data can be reconstructed using the latent vectors found by the agent trained in the MDP. The experiment results on various datasets and models demonstrate that our attack successfully recovers the private information of the target model by achieving state-of-the-art attack performance. We emphasize the importance of studies on privacy-preserving machine learning by proposing a more advanced black-box model inversion attack. ",
    "url": "https://arxiv.org/abs/2304.04625",
    "authors": [
      "Gyojin Han",
      "Jaehyun Choi",
      "Haeil Lee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04658",
    "title": "GraphBinMatch: Graph-based Similarity Learning for Cross-Language Binary  and Source Code Matching",
    "abstract": "Matching binary to source code and vice versa has various applications in different fields, such as computer security, software engineering, and reverse engineering. Even though there exist methods that try to match source code with binary code to accelerate the reverse engineering process, most of them are designed to focus on one programming language. However, in real life, programs are developed using different programming languages depending on their requirements. Thus, cross-language binary-to-source code matching has recently gained more attention. Nonetheless, the existing approaches still struggle to have precise predictions due to the inherent difficulties when the problem of matching binary code and source code needs to be addressed across programming languages. In this paper, we address the problem of cross-language binary source code matching. We propose GraphBinMatch, an approach based on a graph neural network that learns the similarity between binary and source codes. We evaluate GraphBinMatch on several tasks, such as cross-language binary-to-source code matching and cross-language source-to-source matching. We also evaluate our approach performance on single-language binary-to-source code matching. Experimental results show that GraphBinMatch outperforms state-of-the-art significantly, with improvements as high as 15% over the F1 score. ",
    "url": "https://arxiv.org/abs/2304.04658",
    "authors": [
      "Ali TehraniJamsaz",
      "Hanze Chen",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.04682",
    "title": "Weight Try-Once-Discard Protocol-Based L_2 L_infinity State Estimation  for Markovian Jumping Neural Networks with Partially Known Transition  Probabilities",
    "abstract": "It was the L_2 L_infinity performance index that for the first time is initiated into the discussion on state estimation of delayed MJNNs with with partially known transition probabilities, which provides a more general promotion for the estimation error.The WTOD protocol is adopted to dispatch the sensor nodes so as to effectively alleviate the updating frequency of output signals. The hybrid effects of the time delays, Markov chain, and protocol parameters are apparently reflected in the co-designed estimator which can be solved by a combination of comprehensive matrix inequalities. ",
    "url": "https://arxiv.org/abs/2304.04682",
    "authors": [
      "Cong Zou",
      "Wei Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.04688",
    "title": "Interaction-Aware Prompting for Zero-Shot Spatio-Temporal Action  Detection",
    "abstract": "The goal of spatial-temporal action detection is to determine the time and place where each person's action occurs in a video and classify the corresponding action category. Most of the existing methods adopt fully-supervised learning, which requires a large amount of training data, making it very difficult to achieve zero-shot learning. In this paper, we propose to utilize a pre-trained visual-language model to extract the representative image and text features, and model the relationship between these features through different interaction modules to obtain the interaction feature. In addition, we use this feature to prompt each label to obtain more appropriate text features. Finally, we calculate the similarity between the interaction feature and the text feature for each label to determine the action category. Our experiments on J-HMDB and UCF101-24 datasets demonstrate that the proposed interaction module and prompting make the visual-language features better aligned, thus achieving excellent accuracy for zero-shot spatio-temporal action detection. The code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2304.04688",
    "authors": [
      "Wei-Jhe Huang",
      "Jheng-Hsien Yeh",
      "Gueter Josmy Faure",
      "Min-Hung Chen",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04697",
    "title": "Brain-Inspired Spiking Neural Network for Online Unsupervised Time  Series Prediction",
    "abstract": "Energy and data-efficient online time series prediction for predicting evolving dynamical systems are critical in several fields, especially edge AI applications that need to update continuously based on streaming data. However, current DNN-based supervised online learning models require a large amount of training data and cannot quickly adapt when the underlying system changes. Moreover, these models require continuous retraining with incoming data making them highly inefficient. To solve these issues, we present a novel Continuous Learning-based Unsupervised Recurrent Spiking Neural Network Model (CLURSNN), trained with spike timing dependent plasticity (STDP). CLURSNN makes online predictions by reconstructing the underlying dynamical system using Random Delay Embedding by measuring the membrane potential of neurons in the recurrent layer of the RSNN with the highest betweenness centrality. We also use topological data analysis to propose a novel methodology using the Wasserstein Distance between the persistence homologies of the predicted and observed time series as a loss function. We show that the proposed online time series prediction methodology outperforms state-of-the-art DNN models when predicting an evolving Lorenz63 dynamical system. ",
    "url": "https://arxiv.org/abs/2304.04697",
    "authors": [
      "Biswadeep Chakraborty",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.04699",
    "title": "Efficient Distributed Decomposition and Routing Algorithms in Minor-Free  Networks and Their Applications",
    "abstract": "In the LOCAL model, low-diameter decomposition is a useful tool in designing algorithms, as it allows us to shift from the general graph setting to the low-diameter graph setting, where brute-force information gathering can be done efficiently. Recently, Chang and Su [PODC 2022] showed that any high-conductance network excluding a fixed minor contains a high-degree vertex, so the entire graph topology can be gathered to one vertex efficiently in the CONGEST model using expander routing. Therefore, in networks excluding a fixed minor, many problems that can be solved efficiently in LOCAL via low-diameter decomposition can also be solved efficiently in CONGEST via expander decomposition. In this work, we show improved decomposition and routing algorithms for networks excluding a fixed minor in the CONGEST model. Our algorithms cost $\\text{poly}(\\log n, 1/\\epsilon)$ rounds deterministically. For bounded-degree graphs, our algorithms finish in $O(\\epsilon^{-1}\\log n) + \\epsilon^{-O(1)}$ rounds. Our algorithms have a wide range of applications, including the following results in CONGEST. 1. A $(1-\\epsilon)$-approximate maximum independent set in a network excluding a fixed minor can be computed deterministically in $O(\\epsilon^{-1}\\log^\\ast n) + \\epsilon^{-O(1)}$ rounds, nearly matching the $\\Omega(\\epsilon^{-1}\\log^\\ast n)$ lower bound of Lenzen and Wattenhofer [DISC 2008]. 2. Property testing of any additive minor-closed property can be done deterministically in $O(\\log n)$ rounds if $\\epsilon$ is a constant or $O(\\epsilon^{-1}\\log n) + \\epsilon^{-O(1)}$ rounds if the maximum degree $\\Delta$ is a constant, nearly matching the $\\Omega(\\epsilon^{-1}\\log n)$ lower bound of Levi, Medina, and Ron [PODC 2018]. ",
    "url": "https://arxiv.org/abs/2304.04699",
    "authors": [
      "Yi-Jun Chang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.04709",
    "title": "Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection",
    "abstract": "SAM is a segmentation model recently released by Meta AI Research and has been gaining attention quickly due to its impressive performance in generic object segmentation. However, its ability to generalize to specific scenes such as camouflaged scenes is still unknown. Camouflaged object detection (COD) involves identifying objects that are seamlessly integrated into their surroundings and has numerous practical applications in fields such as medicine, art, and agriculture. In this study, we try to ask if SAM can address the COD task and evaluate the performance of SAM on the COD benchmark by employing maximum segmentation evaluation and camouflage location evaluation. We also compare SAM's performance with 22 state-of-the-art COD methods. Our results indicate that while SAM shows promise in generic object segmentation, its performance on the COD task is limited. This presents an opportunity for further research to explore how to build a stronger SAM that may address the COD task. The results of this paper are provided in \\url{https://github.com/luckybird1994/SAMCOD}. ",
    "url": "https://arxiv.org/abs/2304.04709",
    "authors": [
      "Lv Tang",
      "Haoke Xiao",
      "Bo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04717",
    "title": "Incorporating Structured Sentences with Time-enhanced BERT for  Fully-inductive Temporal Relation Prediction",
    "abstract": "Temporal relation prediction in incomplete temporal knowledge graphs (TKGs) is a popular temporal knowledge graph completion (TKGC) problem in both transductive and inductive settings. Traditional embedding-based TKGC models (TKGE) rely on structured connections and can only handle a fixed set of entities, i.e., the transductive setting. In the inductive setting where test TKGs contain emerging entities, the latest methods are based on symbolic rules or pre-trained language models (PLMs). However, they suffer from being inflexible and not time-specific, respectively. In this work, we extend the fully-inductive setting, where entities in the training and test sets are totally disjoint, into TKGs and take a further step towards a more flexible and time-sensitive temporal relation prediction approach SST-BERT, incorporating Structured Sentences with Time-enhanced BERT. Our model can obtain the entity history and implicitly learn rules in the semantic space by encoding structured sentences, solving the problem of inflexibility. We propose to use a time masking MLM task to pre-train BERT in a corpus rich in temporal tokens specially generated for TKGs, enhancing the time sensitivity of SST-BERT. To compute the probability of occurrence of a target quadruple, we aggregate all its structured sentences from both temporal and semantic perspectives into a score. Experiments on the transductive datasets and newly generated fully-inductive benchmarks show that SST-BERT successfully improves over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2304.04717",
    "authors": [
      "Zhongwu Chen",
      "Chengjin Xu",
      "Fenglong Su",
      "Zhen Huang",
      "Yong Dou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.04718",
    "title": "Investigating Graph Structure Information for Entity Alignment with  Dangling Cases",
    "abstract": "Entity alignment (EA) aims to discover the equivalent entities in different knowledge graphs (KGs), which play an important role in knowledge engineering. Recently, EA with dangling entities has been proposed as a more realistic setting, which assumes that not all entities have corresponding equivalent entities. In this paper, we focus on this setting. Some work has explored this problem by leveraging translation API, pre-trained word embeddings, and other off-the-shelf tools. However, these approaches over-rely on the side information (e.g., entity names), and fail to work when the side information is absent. On the contrary, they still insufficiently exploit the most fundamental graph structure information in KG. To improve the exploitation of the structural information, we propose a novel entity alignment framework called Weakly-Optimal Graph Contrastive Learning (WOGCL), which is refined on three dimensions : (i) Model. We propose a novel Gated Graph Attention Network to capture local and global graph structure similarity. (ii) Training. Two learning objectives: contrastive learning and optimal transport learning are designed to obtain distinguishable entity representations via the optimal transport plan. (iii) Inference. In the inference phase, a PageRank-based method is proposed to calculate higher-order structural similarity. Extensive experiments on two dangling benchmarks demonstrate that our WOGCL outperforms the current state-of-the-art methods with pure structural information in both traditional (relaxed) and dangling (consolidated) settings. The code will be public soon. ",
    "url": "https://arxiv.org/abs/2304.04718",
    "authors": [
      "Jin Xu",
      "Yangning Li",
      "Xiangjin Xie",
      "Yinghui Li",
      "Niu Hu",
      "Haitao Zheng",
      "Yong Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04733",
    "title": "Artifact magnification on deepfake videos increases human detection and  subjective confidence",
    "abstract": "The development of technologies for easily and automatically falsifying video has raised practical questions about people's ability to detect false information online. How vulnerable are people to deepfake videos? What technologies can be applied to boost their performance? Human susceptibility to deepfake videos is typically measured in laboratory settings, which do not reflect the challenges of real-world browsing. In typical browsing, deepfakes are rare, engagement with the video may be short, participants may be distracted, or the video streaming quality may be degraded. Here, we tested deepfake detection under these ecological viewing conditions, and found that detection was lowered in all cases. Principles from signal detection theory indicated that different viewing conditions affected different dimensions of detection performance. Overall, this suggests that the current literature underestimates people's susceptibility to deepfakes. Next, we examined how computer vision models might be integrated into users' decision process to increase accuracy and confidence during deepfake detection. We evaluated the effectiveness of communicating the model's prediction to the user by amplifying artifacts in fake videos. We found that artifact amplification was highly effective at making fake video distinguishable from real, in a manner that was robust across viewing conditions. Additionally, compared to a traditional text-based prompt, artifact amplification was more convincing: people accepted the model's suggestion more often, and reported higher final confidence in their model-supported decision, particularly for more challenging videos. Overall, this suggests that visual indicators that cause distortions on fake videos may be highly effective at mitigating the impact of falsified video. ",
    "url": "https://arxiv.org/abs/2304.04733",
    "authors": [
      "Emilie Josephs",
      "Camilo Fosco",
      "Aude Oliva"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.04736",
    "title": "On the Possibilities of AI-Generated Text Detection",
    "abstract": "Our work focuses on the challenge of detecting outputs generated by Large Language Models (LLMs) from those generated by humans. The ability to distinguish between the two is of utmost importance in numerous applications. However, the possibility and impossibility of such discernment have been subjects of debate within the community. Therefore, a central question is whether we can detect AI-generated text and, if so, when. In this work, we provide evidence that it should almost always be possible to detect the AI-generated text unless the distributions of human and machine generated texts are exactly the same over the entire support. This observation follows from the standard results in information theory and relies on the fact that if the machine text is becoming more like a human, we need more samples to detect it. We derive a precise sample complexity bound of AI-generated text detection, which tells how many samples are needed to detect. This gives rise to additional challenges of designing more complicated detectors that take in n samples to detect than just one, which is the scope of future research on this topic. Our empirical evaluations support our claim about the existence of better detectors demonstrating that AI-Generated text detection should be achievable in the majority of scenarios. Our results emphasize the importance of continued research in this area ",
    "url": "https://arxiv.org/abs/2304.04736",
    "authors": [
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Sicheng Zhu",
      "Bang An",
      "Dinesh Manocha",
      "Furong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04742",
    "title": "Detection Transformer with Stable Matching",
    "abstract": "This paper is concerned with the matching stability problem across different decoder layers in DEtection TRansformers (DETR). We point out that the unstable matching in DETR is caused by a multi-optimization path problem, which is highlighted by the one-to-one matching design in DETR. To address this problem, we show that the most important design is to use and only use positional metrics (like IOU) to supervise classification scores of positive examples. Under the principle, we propose two simple yet effective modifications by integrating positional metrics to DETR's classification loss and matching cost, named position-supervised loss and position-modulated cost. We verify our methods on several DETR variants. Our methods show consistent improvements over baselines. By integrating our methods with DINO, we achieve 50.4 and 51.5 AP on the COCO detection benchmark using ResNet-50 backbones under 12 epochs and 24 epochs training settings, achieving a new record under the same setting. We achieve 63.8 AP on COCO detection test-dev with a Swin-Large backbone. Our code will be made available at https://github.com/IDEA-Research/Stable-DINO. ",
    "url": "https://arxiv.org/abs/2304.04742",
    "authors": [
      "Shilong Liu",
      "Tianhe Ren",
      "Jiayu Chen",
      "Zhaoyang Zeng",
      "Hao Zhang",
      "Feng Li",
      "Hongyang Li",
      "Jun Huang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03949",
    "title": "Capturing dynamical correlations using implicit neural representations",
    "abstract": "The observation and description of collective excitations in solids is a fundamental issue when seeking to understand the physics of a many-body system. Analysis of these excitations is usually carried out by measuring the dynamical structure factor, S(Q, $\\omega$), with inelastic neutron or x-ray scattering techniques and comparing this against a calculated dynamical model. Here, we develop an artificial intelligence framework which combines a neural network trained to mimic simulated data from a model Hamiltonian with automatic differentiation to recover unknown parameters from experimental data. We benchmark this approach on a Linear Spin Wave Theory (LSWT) simulator and advanced inelastic neutron scattering data from the square-lattice spin-1 antiferromagnet La$_2$NiO$_4$. We find that the model predicts the unknown parameters with excellent agreement relative to analytical fitting. In doing so, we illustrate the ability to build and train a differentiable model only once, which then can be applied in real-time to multi-dimensional scattering data, without the need for human-guided peak finding and fitting algorithms. This prototypical approach promises a new technology for this field to automatically detect and refine more advanced models for ordered quantum systems. ",
    "url": "https://arxiv.org/abs/2304.03949",
    "authors": [
      "Sathya Chitturi",
      "Zhurun Ji",
      "Alexander Petsch",
      "Cheng Peng",
      "Zhantao Chen",
      "Rajan Plumley",
      "Mike Dunne",
      "Sougata Mardanya",
      "Sugata Chowdhury",
      "Hongwei Chen",
      "Arun Bansil",
      "Adrian Feiguin",
      "Alexander Kolesnikov",
      "Dharmalingam Prabhakaran",
      "Stephen Hayden",
      "Daniel Ratner",
      "Chunjing Jia",
      "Youssef Nashed",
      "Joshua Turner"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2304.04027",
    "title": "NeBLa: Neural Beer-Lambert for 3D Reconstruction of Oral Structures from  Panoramic Radiographs",
    "abstract": "Panoramic radiography (panoramic X-ray, PX) is a widely used imaging modality for dental examination. However, its applicability is limited as compared to 3D Cone-beam computed tomography (CBCT), because PX only provides 2D flattened images of the oral structure. In this paper, we propose a new framework which estimates 3D oral structure from real-world PX images. Since there are not many matching PX and CBCT data, we used simulated PX from CBCT for training, however, we used real-world panoramic radiographs at the inference time. We propose a new ray-sampling method to make simulated panoramic radiographs inspired by the principle of panoramic radiography along with the rendering function derived from the Beer-Lambert law. Our model consists of three parts: translation module, generation module, and refinement module. The translation module changes the real-world panoramic radiograph to the simulated training image style. The generation module makes the 3D structure from the input image without any prior information such as a dental arch. Our ray-based generation approach makes it possible to reverse the process of generating PX from oral structure in order to reconstruct CBCT data. Lastly, the refinement module enhances the quality of the 3D output. Results show that our approach works better for simulated and real-world images compared to other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.04027",
    "authors": [
      "Sihwa Park",
      "Seongjun Kim",
      "Doeyoung Kwon",
      "Yohan Jang",
      "Seungjun Baek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04161",
    "title": "Detection of COVID19 in Chest X-Ray Images Using Transfer Learning",
    "abstract": "COVID19 is a highly contagious disease infected millions of people worldwide. With limited testing components, screening tools such as chest radiography can assist the clinicians in the diagnosis and assessing the progress of disease. The performance of deep learning-based systems for diagnosis of COVID-19 disease in radiograph images has been encouraging. This paper investigates the concept of transfer learning using two of the most well-known VGGNet architectures, namely VGG-16 and VGG-19. The classifier block and hyperparameters are fine-tuned to adopt the models for automatic detection of Covid-19 in chest x-ray images. We generated two different datasets to evaluate the performance of the proposed system for the identification of positive Covid-19 instances in a multiclass and binary classification problems. The experimental outcome demonstrates the usefulness of transfer learning for small-sized datasets particularly in the field of medical imaging, not only to prevent over-fitting and convergence problems but also to attain optimal classification performance as well. ",
    "url": "https://arxiv.org/abs/2304.04161",
    "authors": [
      "Zanoby N.Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04315",
    "title": "Microseismic source imaging using physics-informed neural networks with  hard constraints",
    "abstract": "Microseismic source imaging plays a significant role in passive seismic monitoring. However, such a process is prone to failure due to the aliasing problem when dealing with sparse measured data. Thus, we propose a direct microseismic imaging framework based on physics-informed neural networks (PINNs), which can generate focused source images, even with very sparse recordings. We use the PINNs to represent a multi-frequency wavefield and then apply the inverse Fourier transform to extract the source image. Specially, we modify the representation of the frequency-domain wavefield to inherently satisfy the boundary conditions (the measured data on the surface) by means of the hard constraint, which helps to avoid the difficulty in balancing the data and PDE losses in PINNs. Furthermore, we propose the causality loss implementation with respect to depth to enhance the convergence of PINNs. The numerical experiments on the Overthrust model show that the method can admit reliable and accurate source imaging for single- or multiple- sources and even in passive monitoring settings. Then, we further apply our method on the hydraulic fracturing field data, and demonstrate that our method can correctly image the source. ",
    "url": "https://arxiv.org/abs/2304.04315",
    "authors": [
      "Xinquan Huang",
      "Tariq Alkhalifah"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2304.04394",
    "title": "Leveraging Neural Representations for Audio Manipulation",
    "abstract": "We investigate applying audio manipulations using pretrained neural network-based autoencoders as an alternative to traditional signal processing methods, since the former may provide greater semantic or perceptual organization. To establish the potential of this approach, we first establish if representations from these models encode information about manipulations. We carry out experiments and produce visualizations using representations from two different pretrained autoencoders. Our findings indicate that, while some information about audio manipulations is encoded, this information is both limited and encoded in a non-trivial way. This is supported by our attempts to visualize these representations, which demonstrated that trajectories of representations for common manipulations are typically nonlinear and content dependent, even for linear signal manipulations. As a result, it is not yet clear how these pretrained autoencoders can be used to manipulate audio signals, however, our results indicate this may be due to the lack of disentanglement with respect to common audio manipulations. ",
    "url": "https://arxiv.org/abs/2304.04394",
    "authors": [
      "Scott H. Hawley",
      "Christian J. Steinmetz"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2304.04443",
    "title": "Approximation of Nonlinear Functionals Using Deep ReLU Networks",
    "abstract": "In recent years, functional neural networks have been proposed and studied in order to approximate nonlinear continuous functionals defined on $L^p([-1, 1]^s)$ for integers $s\\ge1$ and $1\\le p<\\infty$. However, their theoretical properties are largely unknown beyond universality of approximation or the existing analysis does not apply to the rectified linear unit (ReLU) activation function. To fill in this void, we investigate here the approximation power of functional deep neural networks associated with the ReLU activation function by constructing a continuous piecewise linear interpolation under a simple triangulation. In addition, we establish rates of approximation of the proposed functional deep ReLU networks under mild regularity conditions. Finally, our study may also shed some light on the understanding of functional data learning algorithms. ",
    "url": "https://arxiv.org/abs/2304.04443",
    "authors": [
      "Linhao Song",
      "Jun Fan",
      "Di-Rong Chen",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04531",
    "title": "Alon-Tarsi Number of Some Complete Multipartite Graphs",
    "abstract": "The Alon-Tarsi number of a polynomial is a parameter related to the exponents of its monomials. For graphs, their Alon-Tarsi number is the Alon-Tarsi number of their graph polynomials. As such, it provides an upper bound on their choice and online choice numbers. In this paper, we obtain the Alon-Tarsi number of some complete multipartite graphs and line graphs of some complete graphs of even order. ",
    "url": "https://arxiv.org/abs/2304.04531",
    "authors": [
      "Prajnanaswaroopa S"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2304.04597",
    "title": "Accelerated deep self-supervised ptycho-laminography for  three-dimensional nanoscale imaging of integrated circuits",
    "abstract": "Three-dimensional inspection of nanostructures such as integrated circuits is important for security and reliability assurance. Two scanning operations are required: ptychographic to recover the complex transmissivity of the specimen; and rotation of the specimen to acquire multiple projections covering the 3D spatial frequency domain. Two types of rotational scanning are possible: tomographic and laminographic. For flat, extended samples, for which the full 180 degree coverage is not possible, the latter is preferable because it provides better coverage of the 3D spatial frequency domain compared to limited-angle tomography. It is also because the amount of attenuation through the sample is approximately the same for all projections. However, both techniques are time consuming because of extensive acquisition and computation time. Here, we demonstrate the acceleration of ptycho-laminographic reconstruction of integrated circuits with 16-times fewer angular samples and 4.67-times faster computation by using a physics-regularized deep self-supervised learning architecture. We check the fidelity of our reconstruction against a densely sampled reconstruction that uses full scanning and no learning. As already reported elsewhere [Zhou and Horstmeyer, Opt. Express, 28(9), pp. 12872-12896], we observe improvement of reconstruction quality even over the densely sampled reconstruction, due to the ability of the self-supervised learning kernel to fill the missing cone. ",
    "url": "https://arxiv.org/abs/2304.04597",
    "authors": [
      "Iksung Kang",
      "Yi Jiang",
      "Mirko Holler",
      "Manuel Guizar-Sicairos",
      "A. F. J. Levi",
      "Jeffrey Klug",
      "Stefan Vogt",
      "George Barbastathis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2304.04662",
    "title": "SELFormer: Molecular Representation Learning via SELFIES Language Models",
    "abstract": "Automated computational analysis of the vast chemical space is critical for numerous fields of research such as drug discovery and material science. Representation learning techniques have recently been employed with the primary objective of generating compact and informative numerical expressions of complex data. One approach to efficiently learn molecular representations is processing string-based notations of chemicals via natural language processing (NLP) algorithms. Majority of the methods proposed so far utilize SMILES notations for this purpose; however, SMILES is associated with numerous problems related to validity and robustness, which may prevent the model from effectively uncovering the knowledge hidden in the data. In this study, we propose SELFormer, a transformer architecture-based chemical language model that utilizes a 100% valid, compact and expressive notation, SELFIES, as input, in order to learn flexible and high-quality molecular representations. SELFormer is pre-trained on two million drug-like compounds and fine-tuned for diverse molecular property prediction tasks. Our performance evaluation has revealed that, SELFormer outperforms all competing methods, including graph learning-based approaches and SMILES-based chemical language models, on predicting aqueous solubility of molecules and adverse drug reactions. We also visualized molecular representations learned by SELFormer via dimensionality reduction, which indicated that even the pre-trained model can discriminate molecules with differing structural properties. We shared SELFormer as a programmatic tool, together with its datasets and pre-trained models. Overall, our research demonstrates the benefit of using the SELFIES notations in the context of chemical language modeling and opens up new possibilities for the design and discovery of novel drug candidates with desired features. ",
    "url": "https://arxiv.org/abs/2304.04662",
    "authors": [
      "Atakan Y\u00fcksel",
      "Erva Ulusoy",
      "Atabey \u00dcnl\u00fc",
      "Gamze Deniz",
      "Tunca Do\u011fan"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04664",
    "title": "Inductive biases in deep learning models for weather prediction",
    "abstract": "Deep learning has recently gained immense popularity in the Earth sciences as it enables us to formulate purely data-driven models of complex Earth system processes. Deep learning-based weather prediction (DLWP) models have made significant progress in the last few years, achieving forecast skills comparable to established numerical weather prediction (NWP) models with comparatively lesser computational costs. In order to train accurate, reliable, and tractable DLWP models with several millions of parameters, the model design needs to incorporate suitable inductive biases that encode structural assumptions about the data and modelled processes. When chosen appropriately, these biases enable faster learning and better generalisation to unseen data. Although inductive biases play a crucial role in successful DLWP models, they are often not stated explicitly and how they contribute to model performance remains unclear. Here, we review and analyse the inductive biases of six state-of-the-art DLWP models, involving a deeper look at five key design elements: input data, forecasting objective, loss components, layered design of the deep learning architectures, and optimisation methods. We show how the design choices made in each of the five design elements relate to structural assumptions. Given recent developments in the broader DL community, we anticipate that the future of DLWP will likely see a wider use of foundation models -- large models pre-trained on big databases with self-supervised learning -- combined with explicit physics-informed inductive biases that allow the models to provide competitive forecasts even at the more challenging subseasonal-to-seasonal scales. ",
    "url": "https://arxiv.org/abs/2304.04664",
    "authors": [
      "Jannik Thuemmel",
      "Matthias Karlbauer",
      "Sebastian Otte",
      "Christiane Zarfl",
      "Georg Martius",
      "Nicole Ludwig",
      "Thomas Scholten",
      "Ulrich Friedrich",
      "Volker Wulfmeyer",
      "Bedartha Goswami",
      "Martin V. Butz"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04673",
    "title": "Regional Deep Atrophy: a Self-Supervised Learning Method to  Automatically Identify Regions Associated With Alzheimer's Disease  Progression From Longitudinal MRI",
    "abstract": "Longitudinal assessment of brain atrophy, particularly in the hippocampus, is a well-studied biomarker for neurodegenerative diseases, such as Alzheimer's disease (AD). In clinical trials, estimation of brain progressive rates can be applied to track therapeutic efficacy of disease modifying treatments. However, most state-of-the-art measurements calculate changes directly by segmentation and/or deformable registration of MRI images, and may misreport head motion or MRI artifacts as neurodegeneration, impacting their accuracy. In our previous study, we developed a deep learning method DeepAtrophy that uses a convolutional neural network to quantify differences between longitudinal MRI scan pairs that are associated with time. DeepAtrophy has high accuracy in inferring temporal information from longitudinal MRI scans, such as temporal order or relative inter-scan interval. DeepAtrophy also provides an overall atrophy score that was shown to perform well as a potential biomarker of disease progression and treatment efficacy. However, DeepAtrophy is not interpretable, and it is unclear what changes in the MRI contribute to progression measurements. In this paper, we propose Regional Deep Atrophy (RDA), which combines the temporal inference approach from DeepAtrophy with a deformable registration neural network and attention mechanism that highlights regions in the MRI image where longitudinal changes are contributing to temporal inference. RDA has similar prediction accuracy as DeepAtrophy, but its additional interpretability makes it more acceptable for use in clinical settings, and may lead to more sensitive biomarkers for disease monitoring in clinical trials of early AD. ",
    "url": "https://arxiv.org/abs/2304.04673",
    "authors": [
      "Mengjin Dong",
      "Long Xie",
      "Sandhitsu R. Das",
      "Jiancong Wang",
      "Laura E.M. Wisse",
      "Robin deFlores",
      "David A. Wolk",
      "Paul A. Yushkevich"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:1805.04071",
    "title": "The Energy Complexity of Diameter and Minimum Cut Computation in  Bounded-Genus Networks",
    "abstract": " Comments: Removing results that were already moved to arXiv:2007.09816. Polishing the writing. Changing the title. To appear in SIROCCO 2023 ",
    "url": "https://arxiv.org/abs/1805.04071",
    "authors": [
      "Yi-Jun Chang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2101.07243",
    "title": "Gauge Invariant and Anyonic Symmetric Autoregressive Neural Networks for  Quantum Lattice Models",
    "abstract": " Title: Gauge Invariant and Anyonic Symmetric Autoregressive Neural Networks for  Quantum Lattice Models ",
    "url": "https://arxiv.org/abs/2101.07243",
    "authors": [
      "Di Luo",
      "Zhuo Chen",
      "Kaiwen Hu",
      "Zhizhen Zhao",
      "Vera Mikyoung Hur",
      "Bryan K. Clark"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2107.02306",
    "title": "Connectivity Matters: Neural Network Pruning Through the Lens of  Effective Sparsity",
    "abstract": " Title: Connectivity Matters: Neural Network Pruning Through the Lens of  Effective Sparsity ",
    "url": "https://arxiv.org/abs/2107.02306",
    "authors": [
      "Artem Vysogorets",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.13681",
    "title": "Rate-Independent Computation in Continuous Chemical Reaction Networks",
    "abstract": " Comments: accepted to JACM (this https URL); preliminary version appeared in ITCS 2014: this http URL ",
    "url": "https://arxiv.org/abs/2107.13681",
    "authors": [
      "Ho-Lin Chen",
      "David Doty",
      "Wyatt Reeves",
      "David Soloveichik"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2109.01494",
    "title": "Computing Graph Descriptors on Edge Streams",
    "abstract": " Comments: Extension of work accepted to PAKDD 2020. Accepted to ACM TKDD in 2023 ",
    "url": "https://arxiv.org/abs/2109.01494",
    "authors": [
      "Zohair Raza Hassan",
      "Sarwan Ali",
      "Imdadullah Khan",
      "Mudassir Shabbir",
      "Waseem Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2110.00744",
    "title": "Random Subgraph Detection Using Queries",
    "abstract": " Comments: 29 pages ",
    "url": "https://arxiv.org/abs/2110.00744",
    "authors": [
      "Wasim Huleihel",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2112.04395",
    "title": "On anti-stochastic properties of unlabeled graphs",
    "abstract": " Title: On anti-stochastic properties of unlabeled graphs ",
    "url": "https://arxiv.org/abs/2112.04395",
    "authors": [
      "Sergei Kiselev",
      "Andrey Kupavskii",
      "Oleg Verbitsky",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2112.11165",
    "title": "Scalable High-Rate Twin-Field Quantum Key Distribution Networks without  Constraint of Probability and Intensity",
    "abstract": " Comments: 17 pages, 6 figures, 3 tables, Accepted for Publication in Phys. Rev. A ",
    "url": "https://arxiv.org/abs/2112.11165",
    "authors": [
      "Yuan-Mei Xie",
      "Chen-Xun Weng",
      "Yu-Shuo Lu",
      "Yao Fu",
      "Yang Wang",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2201.04828",
    "title": "Multi-Scale Adaptive Graph Neural Network for Multivariate Time Series  Forecasting",
    "abstract": " Comments: Accepted by TKDE ",
    "url": "https://arxiv.org/abs/2201.04828",
    "authors": [
      "Ling Chen",
      "Donghui Chen",
      "Zongjiang Shang",
      "Binqing Wu",
      "Cen Zheng",
      "Bo Wen",
      "Wei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.04213",
    "title": "Structure-aware Protein Self-supervised Learning",
    "abstract": " Comments: Accepted by Bioinformatics; 7 pages 4 figures ",
    "url": "https://arxiv.org/abs/2204.04213",
    "authors": [
      "Can Chen",
      "Jingbo Zhou",
      "Fan Wang",
      "Xue Liu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2204.05999",
    "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
    "abstract": " Comments: ICLR 2023. v3: camera-ready that includes PLBART and OpenAI baselines ",
    "url": "https://arxiv.org/abs/2204.05999",
    "authors": [
      "Daniel Fried",
      "Armen Aghajanyan",
      "Jessy Lin",
      "Sida Wang",
      "Eric Wallace",
      "Freda Shi",
      "Ruiqi Zhong",
      "Wen-tau Yih",
      "Luke Zettlemoyer",
      "Mike Lewis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10581",
    "title": "FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection",
    "abstract": " Title: FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection ",
    "url": "https://arxiv.org/abs/2204.10581",
    "authors": [
      "Tuan Truong",
      "Matthias Lenga",
      "Antoine Serrurier",
      "Sadegh Mohammadi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.08041",
    "title": "Detection and Physical Interaction with Deformable Linear Objects",
    "abstract": " Comments: Presented at ICRA 2022 2nd Workshop on Representing and Manipulating Deformable Objects (this https URL) ",
    "url": "https://arxiv.org/abs/2205.08041",
    "authors": [
      "Azarakhsh Keipour",
      "Mohammadreza Mousaei",
      "Maryam Bandari",
      "Stefan Schaal",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.00137",
    "title": "Social Bias Meets Data Bias: The Impacts of Labeling and Measurement  Errors on Fairness Criteria",
    "abstract": " Title: Social Bias Meets Data Bias: The Impacts of Labeling and Measurement  Errors on Fairness Criteria ",
    "url": "https://arxiv.org/abs/2206.00137",
    "authors": [
      "Yiqiao Liao",
      "Parinaz Naghizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.00535",
    "title": "Deepfake Caricatures: Amplifying attention to artifacts increases  deepfake detection by humans and machines",
    "abstract": " Comments: 9 pages, 5 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2206.00535",
    "authors": [
      "Camilo Fosco",
      "Emilie Josephs",
      "Alex Andonian",
      "Allen Lee",
      "Xi Wang",
      "Aude Oliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.02386",
    "title": "Restructuring Graph for Higher Homophily via Adaptive Spectral  Clustering",
    "abstract": " Comments: 13 pages, 9 figures, AAAI 2023 ",
    "url": "https://arxiv.org/abs/2206.02386",
    "authors": [
      "Shouheng Li",
      "Dongwoo Kim",
      "Qing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.05378",
    "title": "Collaborative Neural Rendering using Anime Character Sheets",
    "abstract": " Comments: The first three authors contribute equally. In the Arts and Creativity Track of IJCAI2023 ",
    "url": "https://arxiv.org/abs/2207.05378",
    "authors": [
      "Zuzeng Lin",
      "Ailin Huang",
      "Zhewei Huang",
      "Chen Hu",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.08367",
    "title": "Protecting Global Properties of Datasets with Distribution Privacy  Mechanisms",
    "abstract": " Title: Protecting Global Properties of Datasets with Distribution Privacy  Mechanisms ",
    "url": "https://arxiv.org/abs/2207.08367",
    "authors": [
      "Michelle Chen",
      "Olga Ohrimenko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11232",
    "title": "Neural Groundplans: Persistent Neural Scene Representations from a  Single Image",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2207.11232",
    "authors": [
      "Prafull Sharma",
      "Ayush Tewari",
      "Yilun Du",
      "Sergey Zakharov",
      "Rares Ambrus",
      "Adrien Gaidon",
      "William T. Freeman",
      "Fredo Durand",
      "Joshua B. Tenenbaum",
      "Vincent Sitzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.12943",
    "title": "Unique in what sense? Heterogeneous relationships between multiple types  of uniqueness and popularity in music",
    "abstract": " Comments: Accepted at the International AAAI Conference on Web and Social Media (ICWSM, 2023). Special Recognition Award at 7th International Conference on Computational Social Science (IC2S2, 2021) ",
    "url": "https://arxiv.org/abs/2207.12943",
    "authors": [
      "Yulin Yu",
      "Pui Yin Cheung",
      "Yong-Yeol Ahn",
      "Paramveer Dhillon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2208.07282",
    "title": "Differentiable WORLD Synthesizer-based Neural Vocoder With Application  To End-To-End Audio Style Transfer",
    "abstract": " Comments: A revised version of this work has been accepted to the 154th AES Convention; 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2208.07282",
    "authors": [
      "Shahan Nercessian"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2208.13035",
    "title": "SoK: Decentralized Finance (DeFi) Attacks",
    "abstract": " Title: SoK: Decentralized Finance (DeFi) Attacks ",
    "url": "https://arxiv.org/abs/2208.13035",
    "authors": [
      "Liyi Zhou",
      "Xihan Xiong",
      "Jens Ernstberger",
      "Stefanos Chaliasos",
      "Zhipeng Wang",
      "Ye Wang",
      "Kaihua Qin",
      "Roger Wattenhofer",
      "Dawn Song",
      "Arthur Gervais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.04938",
    "title": "Ensuring both Provable Convergence and Differential Privacy in Nash  Equilibrium Seeking on Directed Graphs",
    "abstract": " Title: Ensuring both Provable Convergence and Differential Privacy in Nash  Equilibrium Seeking on Directed Graphs ",
    "url": "https://arxiv.org/abs/2209.04938",
    "authors": [
      "Yongqiang Wang",
      "Tamer Basar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.06388",
    "title": "TSFool: Crafting Highly-imperceptible Adversarial Time Series through  Multi-objective Black-box Attack to Fool RNN Classifiers",
    "abstract": " Comments: 9 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2209.06388",
    "authors": [
      "Yanyun Wang",
      "Dehui Du",
      "Yuanhao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.13351",
    "title": "SuperYOLO: Super Resolution Assisted Object Detection in Multimodal  Remote Sensing Imagery",
    "abstract": " Comments: The article is accepted by IEEE Transactions on Geoscience and Remote Sensing ",
    "url": "https://arxiv.org/abs/2209.13351",
    "authors": [
      "Jiaqing Zhang",
      "Jie Lei",
      "Weiying Xie",
      "Zhenman Fang",
      "Yunsong Li",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.00102",
    "title": "MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP  Initialization",
    "abstract": " Comments: Accepted by ICLR2023 ",
    "url": "https://arxiv.org/abs/2210.00102",
    "authors": [
      "Xiaotian Han",
      "Tong Zhao",
      "Yozen Liu",
      "Xia Hu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.00173",
    "title": "Predictive Inference with Feature Conformal Prediction",
    "abstract": " Comments: Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.00173",
    "authors": [
      "Jiaye Teng",
      "Chuan Wen",
      "Dinghuai Zhang",
      "Yoshua Bengio",
      "Yang Gao",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.01217",
    "title": "One-shot Detail Retouching with Patch Space Neural Transformation  Blending",
    "abstract": " Title: One-shot Detail Retouching with Patch Space Neural Transformation  Blending ",
    "url": "https://arxiv.org/abs/2210.01217",
    "authors": [
      "Fazilet Gokbudak",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.04222",
    "title": "Correlative Information Maximization Based Biologically Plausible Neural  Networks for Correlated Source Separation",
    "abstract": " Comments: ICLR Accepted, 34 pages ",
    "url": "https://arxiv.org/abs/2210.04222",
    "authors": [
      "Bariscan Bozkurt",
      "Ates Isfendiyaroglu",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09060",
    "title": "An introduction to programming Physics-Informed Neural Network-based  computational solid mechanics",
    "abstract": " Comments: 32 pages, 20 figures are include in this manuscript ",
    "url": "https://arxiv.org/abs/2210.09060",
    "authors": [
      "Jinshuai Bai",
      "Hyogu Jeong",
      "C. P. Batuwatta-Gamage",
      "Shusheng Xiao",
      "Qingxia Wang",
      "C.M. Rathnayaka",
      "Laith Alzubaidi",
      "Gui-Rong Liu",
      "Yuantong Gu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.11452",
    "title": "Global Convergence of SGD On Two Layer Neural Nets",
    "abstract": " Comments: 23 pages, 6 figures. Extended abstract accepted at DeepMath 2022. v2 update: New experiments added in Section 3.2 to study the effect of the regularization value. Statement of Theorem 3.4 about SoftPlus nets has been improved ",
    "url": "https://arxiv.org/abs/2210.11452",
    "authors": [
      "Pulkit Gopalani",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.02763",
    "title": "Bayesian learning of Causal Structure and Mechanisms with GFlowNets and  Variational Bayes",
    "abstract": " Title: Bayesian learning of Causal Structure and Mechanisms with GFlowNets and  Variational Bayes ",
    "url": "https://arxiv.org/abs/2211.02763",
    "authors": [
      "Mizu Nishikawa-Toomey",
      "Tristan Deleu",
      "Jithendaraa Subramanian",
      "Yoshua Bengio",
      "Laurent Charlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.06524",
    "title": "Quantum Split Neural Network Learning using Cross-Channel Pooling",
    "abstract": " Title: Quantum Split Neural Network Learning using Cross-Channel Pooling ",
    "url": "https://arxiv.org/abs/2211.06524",
    "authors": [
      "Won Joon Yun",
      "Hankyul Baek",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.06687",
    "title": "Large-scale Contrastive Language-Audio Pretraining with Feature Fusion  and Keyword-to-Caption Augmentation",
    "abstract": " Title: Large-scale Contrastive Language-Audio Pretraining with Feature Fusion  and Keyword-to-Caption Augmentation ",
    "url": "https://arxiv.org/abs/2211.06687",
    "authors": [
      "Yusong Wu",
      "Ke Chen",
      "Tianyu Zhang",
      "Yuchen Hui",
      "Taylor Berg-Kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.09981",
    "title": "Weighted Ensemble Self-Supervised Learning",
    "abstract": " Comments: Accepted by ICLR 2023 ",
    "url": "https://arxiv.org/abs/2211.09981",
    "authors": [
      "Yangjun Ruan",
      "Saurabh Singh",
      "Warren Morningstar",
      "Alexander A. Alemi",
      "Sergey Ioffe",
      "Ian Fischer",
      "Joshua V. Dillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.10832",
    "title": "NeuroSketch: Fast and Approximate Evaluation of Range Aggregate Queries  with Neural Networks",
    "abstract": " Comments: Conference paper in SIGMOD 2023. arXiv admin note: text overlap with arXiv:2107.04922 ",
    "url": "https://arxiv.org/abs/2211.10832",
    "authors": [
      "Sepanta Zeighami",
      "Cyrus Shahabi",
      "Vatsal Sharan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2211.14043",
    "title": "Detrimental role of fluctuations in the resource dependency networks",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2211.14043",
    "authors": [
      "Saumitra Kulkarni",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.14425",
    "title": "PatchGT: Transformer over Non-trainable Clusters for Learning Graph  Representations",
    "abstract": " Comments: 25 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2211.14425",
    "authors": [
      "Han Gao",
      "Xu Han",
      "Jiaoyang Huang",
      "Jian-Xun Wang",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2211.15845",
    "title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs",
    "abstract": " Comments: Accepted in the 37th AAAI Conference on Artificial Intelligence (AAAI 2023) ",
    "url": "https://arxiv.org/abs/2211.15845",
    "authors": [
      "Yuanning Cui",
      "Yuxin Wang",
      "Zequn Sun",
      "Wenqiang Liu",
      "Yiqiao Jiang",
      "Kexin Han",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06898",
    "title": "Bridging Graph Position Encodings for Transformers with Weighted  Graph-Walking Automata",
    "abstract": " Comments: Camera-ready version, reduced certain claims and minor rewording ",
    "url": "https://arxiv.org/abs/2212.06898",
    "authors": [
      "Patrick Soga",
      "David Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.13466",
    "title": "General GAN-generated image detection by data augmentation in  fingerprint domain",
    "abstract": " Title: General GAN-generated image detection by data augmentation in  fingerprint domain ",
    "url": "https://arxiv.org/abs/2212.13466",
    "authors": [
      "Huaming Wang",
      "Jianwei Fei",
      "Yunshu Dai",
      "Lingyun Leng",
      "Zhihua Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14548",
    "title": "How would Stance Detection Techniques Evolve after the Launch of  ChatGPT?",
    "abstract": " Title: How would Stance Detection Techniques Evolve after the Launch of  ChatGPT? ",
    "url": "https://arxiv.org/abs/2212.14548",
    "authors": [
      "Bowen Zhang",
      "Daijun Ding",
      "Liwen Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.14776",
    "title": "On the Interpretability of Attention Networks",
    "abstract": " Comments: ACML 2022, proceedings to be appeared in PMLR, Volume 189 ",
    "url": "https://arxiv.org/abs/2212.14776",
    "authors": [
      "Lakshmi Narayan Pandey",
      "Rahul Vashisht",
      "Harish G. Ramaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01026",
    "title": "Continual Causal Effect Estimation: Challenges and Opportunities",
    "abstract": " Comments: The 37th AAAI conference on artificial intelligence Continual Causality Bridge Program ",
    "url": "https://arxiv.org/abs/2301.01026",
    "authors": [
      "Zhixuan Chu",
      "Sheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.04497",
    "title": "Dynamic Background Reconstruction via MAE for Infrared Small Target  Detection",
    "abstract": " Title: Dynamic Background Reconstruction via MAE for Infrared Small Target  Detection ",
    "url": "https://arxiv.org/abs/2301.04497",
    "authors": [
      "Jingchao Peng",
      "Haitao Zhao",
      "Kaijie Zhao",
      "Zhongze Wang",
      "Lujian Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06083",
    "title": "Discrete Point-wise Attack Is Not Enough: Generalized Manifold  Adversarial Attack for Face Recognition",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2301.06083",
    "authors": [
      "Qian Li",
      "Yuxiao Hu",
      "Ye Liu",
      "Dongxiao Zhang",
      "Xin Jin",
      "Yuntian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06601",
    "title": "A Dataset of Coordinated Cryptocurrency-Related Social Media Campaigns",
    "abstract": " Comments: Camera-ready version for the ICWSM 2023 Conference. This paper describes the dataset available at this https URL ",
    "url": "https://arxiv.org/abs/2301.06601",
    "authors": [
      "Karolis Zilius",
      "Tasos Spiliotopoulos",
      "Aad van Moorsel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.00873",
    "title": "Predicting the Silent Majority on Graphs: Knowledge Transferable Graph  Neural Network",
    "abstract": " Comments: Paper was accepted by WWW2023 ",
    "url": "https://arxiv.org/abs/2302.00873",
    "authors": [
      "Wendong Bi",
      "Bingbing Xu",
      "Xiaoqian Sun",
      "Li Xu",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2302.01313",
    "title": "Double Permutation Equivariance for Knowledge Graph Completion",
    "abstract": " Title: Double Permutation Equivariance for Knowledge Graph Completion ",
    "url": "https://arxiv.org/abs/2302.01313",
    "authors": [
      "Jianfei Gao",
      "Yangze Zhou",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.01579",
    "title": "Semantic 3D-aware Portrait Synthesis and Manipulation Based on  Compositional Neural Radiance Field",
    "abstract": " Comments: Accepted by AAAI2023 Oral ",
    "url": "https://arxiv.org/abs/2302.01579",
    "authors": [
      "Tianxiang Ma",
      "Bingchuan Li",
      "Qian He",
      "Jing Dong",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06120",
    "title": "Knowledge from Large-Scale Protein Contact Prediction Models Can Be  Transferred to the Data-Scarce RNA Contact Prediction Task",
    "abstract": " Comments: Minor revision. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2302.06120",
    "authors": [
      "Yiren Jian",
      "Chongyang Gao",
      "Chen Zeng",
      "Yunjie Zhao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10126",
    "title": "iQPP: A Benchmark for Image Query Performance Prediction",
    "abstract": " Comments: Accepted at SIGIR 2023 ",
    "url": "https://arxiv.org/abs/2302.10126",
    "authors": [
      "Eduard Poesina",
      "Radu Tudor Ionescu",
      "Josiane Mothe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.03388",
    "title": "Multi-modal Multi-kernel Graph Learning for Autism Prediction and  Biomarker Discovery",
    "abstract": " Title: Multi-modal Multi-kernel Graph Learning for Autism Prediction and  Biomarker Discovery ",
    "url": "https://arxiv.org/abs/2303.03388",
    "authors": [
      "Junbin Mao",
      "Jin Liu",
      "Hanhe Lin",
      "Hulin Kuang",
      "Shirui Pan",
      "Yi Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05735",
    "title": "Hardware Acceleration of Neural Graphics",
    "abstract": " Title: Hardware Acceleration of Neural Graphics ",
    "url": "https://arxiv.org/abs/2303.05735",
    "authors": [
      "Muhammad Husnain Mubarik",
      "Ramakrishna Kanungo",
      "Tobias Zirr",
      "Rakesh Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06561",
    "title": "Phase Diagram of Initial Condensation for Two-layer Neural Networks",
    "abstract": " Title: Phase Diagram of Initial Condensation for Two-layer Neural Networks ",
    "url": "https://arxiv.org/abs/2303.06561",
    "authors": [
      "Zhengan Chen",
      "Yuqing Li",
      "Tao Luo",
      "Zhangchen Zhou",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.08435",
    "title": "Physics-Informed Optical Kernel Regression Using Complex-valued Neural  Fields",
    "abstract": " Comments: Accepted by DAC23 ",
    "url": "https://arxiv.org/abs/2303.08435",
    "authors": [
      "Guojin Chen",
      "Zehua Pei",
      "Haoyu Yang",
      "Yuzhe Ma",
      "Bei Yu",
      "Martin D. F. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.11470",
    "title": "Did You Train on My Dataset? Towards Public Dataset Protection with  Clean-Label Backdoor Watermarking",
    "abstract": " Title: Did You Train on My Dataset? Towards Public Dataset Protection with  Clean-Label Backdoor Watermarking ",
    "url": "https://arxiv.org/abs/2303.11470",
    "authors": [
      "Ruixiang Tang",
      "Qizhang Feng",
      "Ninghao Liu",
      "Fan Yang",
      "Xia Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.14584",
    "title": "Learning video embedding space with Natural Language Supervision",
    "abstract": " Title: Learning video embedding space with Natural Language Supervision ",
    "url": "https://arxiv.org/abs/2303.14584",
    "authors": [
      "Phani Krishna Uppala",
      "Abhishek Bamotra",
      "Shriti Priya",
      "Vaidehi Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15354",
    "title": "From Single-Hospital to Multi-Centre Applications: Enhancing the  Generalisability of Deep Learning Models for Adverse Event Prediction in the  ICU",
    "abstract": " Title: From Single-Hospital to Multi-Centre Applications: Enhancing the  Generalisability of Deep Learning Models for Adverse Event Prediction in the  ICU ",
    "url": "https://arxiv.org/abs/2303.15354",
    "authors": [
      "Patrick Rockenschaub",
      "Adam Hilbert",
      "Tabea Kossen",
      "Falk von Dincklage",
      "Vince Istvan Madai",
      "Dietmar Frey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15742",
    "title": "System-status-aware Adaptive Network for Online Streaming Video  Understanding",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.15742",
    "authors": [
      "Lin Geng Foo",
      "Jia Gong",
      "Zhipeng Fan",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16242",
    "title": "CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image  Arbitrary-Scale Super Resolution",
    "abstract": " Title: CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image  Arbitrary-Scale Super Resolution ",
    "url": "https://arxiv.org/abs/2303.16242",
    "authors": [
      "Zixuan Chen",
      "Jianhuang Lai",
      "Lingxiao Yang",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00160",
    "title": "Secure Federated Learning against Model Poisoning Attacks via Client  Filtering",
    "abstract": " Title: Secure Federated Learning against Model Poisoning Attacks via Client  Filtering ",
    "url": "https://arxiv.org/abs/2304.00160",
    "authors": [
      "Duygu Nur Yaldiz",
      "Tuo Zhang",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.00252",
    "title": "Recover Triggered States: Protect Model Against Backdoor Attack in  Reinforcement Learning",
    "abstract": " Title: Recover Triggered States: Protect Model Against Backdoor Attack in  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2304.00252",
    "authors": [
      "Hao Chen",
      "Chen Gong",
      "Yizhe Wang",
      "Xinwen Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.00947",
    "title": "RePAST: Relative Pose Attention Scene Representation Transformer",
    "abstract": " Title: RePAST: Relative Pose Attention Scene Representation Transformer ",
    "url": "https://arxiv.org/abs/2304.00947",
    "authors": [
      "Aleksandr Safin",
      "Daniel Duckworth",
      "Mehdi S. M. Sajjadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.01005",
    "title": "Federated Learning Based Multilingual Emoji Prediction In Clean and  Attack Scenarios",
    "abstract": " Comments: 5 pages, 1 figure, conference ",
    "url": "https://arxiv.org/abs/2304.01005",
    "authors": [
      "Karim Gamal",
      "Ahmed Gaber",
      "Hossam Amer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.01075",
    "title": "Conformal Prediction Regions for Time Series using Linear  Complementarity Programming",
    "abstract": " Title: Conformal Prediction Regions for Time Series using Linear  Complementarity Programming ",
    "url": "https://arxiv.org/abs/2304.01075",
    "authors": [
      "Matthew Cleaveland",
      "Insup Lee",
      "George J. Pappas",
      "Lars Lindemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.01168",
    "title": "DeepAccident: A Motion and Accident Prediction Benchmark for V2X  Autonomous Driving",
    "abstract": " Title: DeepAccident: A Motion and Accident Prediction Benchmark for V2X  Autonomous Driving ",
    "url": "https://arxiv.org/abs/2304.01168",
    "authors": [
      "Tianqi Wang",
      "Sukmin Kim",
      "Wenxuan Ji",
      "Enze Xie",
      "Chongjian Ge",
      "Junsong Chen",
      "Zhenguo Li",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.01492",
    "title": "A Unified Contrastive Transfer Framework with Propagation Structure for  Boosting Low-Resource Rumor Detection",
    "abstract": " Comments: A significant extension of the first contrastive approach for low-resource rumor detection (arXiv:2204.08143) ",
    "url": "https://arxiv.org/abs/2304.01492",
    "authors": [
      "Hongzhan Lin",
      "Jing Ma",
      "Ruichao Yang",
      "Zhiwei Yang",
      "Mingfei Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.02220",
    "title": "On the universal approximation property of radial basis function neural  networks",
    "abstract": " Comments: 11 pages, a short proof of Theorem 3.3 added ",
    "url": "https://arxiv.org/abs/2304.02220",
    "authors": [
      "Aysu Ismayilova",
      "Muhammad Ismayilov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.02323",
    "title": "FASTAGEDS: Fast Approximate Graph Entity Dependency Discovery",
    "abstract": " Comments: 7 pages, 5 figures. arXiv admin note: text overlap with arXiv:2301.06264 ",
    "url": "https://arxiv.org/abs/2304.02323",
    "authors": [
      "Guangtong Zhou",
      "Selasi Kwashie",
      "Yidi Zhang",
      "Michael Bewong",
      "Vincent M. Nofong",
      "Debo Cheng",
      "Keqing He",
      "Zaiwen Feng"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2304.02431",
    "title": "MS3D: Leveraging Multiple Detectors for Unsupervised Domain Adaptation  in 3D Object Detection",
    "abstract": " Comments: Our code is available at this https URL ",
    "url": "https://arxiv.org/abs/2304.02431",
    "authors": [
      "Darren Tsai",
      "Julie Stephany Berrio",
      "Mao Shan",
      "Eduardo Nebot",
      "Stewart Worrall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.02845",
    "title": "Robust Neural Architecture Search",
    "abstract": " Title: Robust Neural Architecture Search ",
    "url": "https://arxiv.org/abs/2304.02845",
    "authors": [
      "Xunyu Zhu",
      "Jian Li",
      "Yong Liu",
      "Weiping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03468",
    "title": "Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs:  New Datasets and A New Method",
    "abstract": " Comments: 11 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2304.03468",
    "authors": [
      "Xuhui Jiang",
      "Chengjin Xu",
      "Yinghan Shen",
      "Fenglong Su",
      "Yuanzhuo Wang",
      "Fei Sun",
      "Zixuan Li",
      "Huawei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03586",
    "title": "Graph Attention for Automated Audio Captioning",
    "abstract": " Comments: Accepted by IEEE Signal Processing Letters ",
    "url": "https://arxiv.org/abs/2304.03586",
    "authors": [
      "Feiyang Xiao",
      "Jian Guan",
      "Qiaoxi Zhu",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03588",
    "title": "Anomalous Sound Detection using Audio Representation with Machine ID  based Contrastive Learning Pretraining",
    "abstract": " Comments: To appear in IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023) ",
    "url": "https://arxiv.org/abs/2304.03588",
    "authors": [
      "Jian Guan",
      "Feiyang Xiao",
      "Youde Liu",
      "Qiaoxi Zhu",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  }
]