[
  {
    "id": "arXiv:2304.11161",
    "title": "altiro3D: Scene representation from single image and novel view  synthesis",
    "abstract": "We introduce altiro3D, a free extended library developed to represent reality starting from a given original RGB image or flat video. It allows to generate a light-field (or Native) image or video and get a realistic 3D experience. To synthesize N-number of virtual images and add them sequentially into a Quilt collage, we apply MiDaS models for the monocular depth estimation, simple OpenCV and Telea inpainting techniques to map all pixels, and implement a 'Fast' algorithm to handle 3D projection camera and scene transformations along N-viewpoints. We use the degree of depth to move proportionally the pixels, assuming the original image to be at the center of all the viewpoints. altiro3D can also be used with DIBR algorithm to compute intermediate snapshots from a equivalent 'Real (slower)' camera with N-geometric viewpoints, which requires to calibrate a priori several intrinsic and extrinsic camera parameters. We adopt a pixel- and device-based Lookup Table to optimize computing time. The multiple viewpoints and video generated from a single image or frame can be displayed in a free-view LCD display. ",
    "url": "https://arxiv.org/abs/2304.11161",
    "authors": [
      "E. Canessa",
      "L. Tenze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.11171",
    "title": "Granular ball computing: an efficient, robust, and interpretable  adaptive multi-granularity representation and computation method",
    "abstract": "Human cognition has a ``large-scale first'' cognitive mechanism, therefore possesses adaptive multi-granularity description capabilities. This results in computational characteristics such as efficiency, robustness, and interpretability. Although most existing artificial intelligence learning methods have certain multi-granularity features, they do not fully align with the ``large-scale first'' cognitive mechanism. Multi-granularity granular-ball computing is an important model method developed in recent years. This method can use granular-balls of different sizes to adaptively represent and cover the sample space, and perform learning based on granular-balls. Since the number of coarse-grained \"granular-ball\" is smaller than the number of sample points, granular-ball computing is more efficient; the coarse-grained characteristics of granular-balls are less likely to be affected by fine-grained sample points, making them more robust; the multi-granularity structure of granular-balls can produce topological structures and coarse-grained descriptions, providing natural interpretability. Granular-ball computing has now been effectively extended to various fields of artificial intelligence, developing theoretical methods such as granular-ball classifiers, granular-ball clustering methods, granular-ball neural networks, granular-ball rough sets, and granular-ball evolutionary computation, significantly improving the efficiency, noise robustness, and interpretability of existing methods. It has good innovation, practicality, and development potential. This article provides a systematic introduction to these methods and analyzes the main problems currently faced by granular-ball computing, discussing both the primary applicable scenarios for granular-ball computing and offering references and suggestions for future researchers to improve this theory. ",
    "url": "https://arxiv.org/abs/2304.11171",
    "authors": [
      "Shuyin Xia",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11193",
    "title": "Combining Vision and Tactile Sensation for Video Prediction",
    "abstract": "In this paper, we explore the impact of adding tactile sensation to video prediction models for physical robot interactions. Predicting the impact of robotic actions on the environment is a fundamental challenge in robotics. Current methods leverage visual and robot action data to generate video predictions over a given time period, which can then be used to adjust robot actions. However, humans rely on both visual and tactile feedback to develop and maintain a mental model of their physical surroundings. In this paper, we investigate the impact of integrating tactile feedback into video prediction models for physical robot interactions. We propose three multi-modal integration approaches and compare the performance of these tactile-enhanced video prediction models. Additionally, we introduce two new datasets of robot pushing that use a magnetic-based tactile sensor for unsupervised learning. The first dataset contains visually identical objects with different physical properties, while the second dataset mimics existing robot-pushing datasets of household object clusters. Our results demonstrate that incorporating tactile feedback into video prediction models improves scene prediction accuracy and enhances the agent's perception of physical interactions and understanding of cause-effect relationships during physical robot interactions. ",
    "url": "https://arxiv.org/abs/2304.11193",
    "authors": [
      "Willow Mandil",
      "Amir Ghalamzan-E"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11196",
    "title": "Fast GraspNeXt: A Fast Self-Attention Neural Network Architecture for  Multi-task Learning in Computer Vision Tasks for Robotic Grasping on the Edge",
    "abstract": "Multi-task learning has shown considerable promise for improving the performance of deep learning-driven vision systems for the purpose of robotic grasping. However, high architectural and computational complexity can result in poor suitability for deployment on embedded devices that are typically leveraged in robotic arms for real-world manufacturing and warehouse environments. As such, the design of highly efficient multi-task deep neural network architectures tailored for computer vision tasks for robotic grasping on the edge is highly desired for widespread adoption in manufacturing environments. Motivated by this, we propose Fast GraspNeXt, a fast self-attention neural network architecture tailored for embedded multi-task learning in computer vision tasks for robotic grasping. To build Fast GraspNeXt, we leverage a generative network architecture search strategy with a set of architectural constraints customized to achieve a strong balance between multi-task learning performance and embedded inference efficiency. Experimental results on the MetaGraspNet benchmark dataset show that the Fast GraspNeXt network design achieves the highest performance (average precision (AP), accuracy, and mean squared error (MSE)) across multiple computer vision tasks when compared to other efficient multi-task network architecture designs, while having only 17.8M parameters (about >5x smaller), 259 GFLOPs (as much as >5x lower) and as much as >3.15x faster on a NVIDIA Jetson TX2 embedded processor. ",
    "url": "https://arxiv.org/abs/2304.11196",
    "authors": [
      "Alexander Wong",
      "Yifan Wu",
      "Saad Abbasi",
      "Saeejith Nair",
      "Yuhao Chen",
      "Mohammad Javad Shafiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11199",
    "title": "EdgeRIC: Empowering Realtime Intelligent Optimization and Control in  NextG Networks",
    "abstract": "Radio Access Networks (RAN) are increasingly softwarized and accessible via data-collection and control interfaces. RAN intelligent control (RIC) is an approach to manage these interfaces at different timescales. In this paper, we develop a RIC platform called RICworld, consisting of (i) EdgeRIC, which is colocated, but decoupled from the RAN stack, and can access RAN and application-level information to execute AI-optimized and other policies in realtime (sub-millisecond) and (ii) DigitalTwin, a full-stack, trace-driven emulator for training AI-based policies offline. We demonstrate that realtime EdgeRIC operates as if embedded within the RAN stack and significantly outperforms a cloud-based near-realtime RIC (> 15 ms latency) in terms of attained throughput. We train AI-based polices on DigitalTwin, execute them on EdgeRIC, and show that these policies are robust to channel dynamics, and outperform queueing-model based policies by 5% to 25% on throughput and application-level benchmarks in a variety of mobile environments. ",
    "url": "https://arxiv.org/abs/2304.11199",
    "authors": [
      "Woo-Hyun Ko",
      "Ujwal Dinesha",
      "Ushasi Ghosh",
      "Srinivas Shakkottai",
      "Dinesh Bharadia",
      "Raini Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11207",
    "title": "SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional  Semantic Segmentation",
    "abstract": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks. It uses RandLA-Net, an off-the-shelf point-based network, as a super-network to enable weight sharing and reduce search time by 99.67% for single-stage searches. SSS3D has a complex search space composed of sampling and architectural parameters that can form 2.88 * 10^17 possible networks. To further reduce search time, SSS3D splits the complete search space and introduces a two-stage search that finds optimal subnetworks in 54% of the time required by single-stage searches. ",
    "url": "https://arxiv.org/abs/2304.11207",
    "authors": [
      "Olivier Therrien",
      "Marihan Amein",
      "Zhuoran Xiong",
      "Warren J. Gross",
      "Brett H. Meyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11223",
    "title": "A Group-Specific Approach to NLP for Hate Speech Detection",
    "abstract": "Automatic hate speech detection is an important yet complex task, requiring knowledge of common sense, stereotypes of protected groups, and histories of discrimination, each of which may constantly evolve. In this paper, we propose a group-specific approach to NLP for online hate speech detection. The approach consists of creating and infusing historical and linguistic knowledge about a particular protected group into hate speech detection models, analyzing historical data about discrimination against a protected group to better predict spikes in hate speech against that group, and critically evaluating hate speech detection models through lenses of intersectionality and ethics. We demonstrate this approach through a case study on NLP for detection of antisemitic hate speech. The case study synthesizes the current English-language literature on NLP for antisemitism detection, introduces a novel knowledge graph of antisemitic history and language from the 20th century to the present, infuses information from the knowledge graph into a set of tweets over Logistic Regression and uncased DistilBERT baselines, and suggests that incorporating context from the knowledge graph can help models pick up subtle stereotypes. ",
    "url": "https://arxiv.org/abs/2304.11223",
    "authors": [
      "Karina Halevy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.11237",
    "title": "Effective Neural Network $L_0$ Regularization With BinMask",
    "abstract": "$L_0$ regularization of neural networks is a fundamental problem. In addition to regularizing models for better generalizability, $L_0$ regularization also applies to selecting input features and training sparse neural networks. There is a large body of research on related topics, some with quite complicated methods. In this paper, we show that a straightforward formulation, BinMask, which multiplies weights with deterministic binary masks and uses the identity straight-through estimator for backpropagation, is an effective $L_0$ regularizer. We evaluate BinMask on three tasks: feature selection, network sparsification, and model regularization. Despite its simplicity, BinMask achieves competitive performance on all the benchmarks without task-specific tuning compared to methods designed for each task. Our results suggest that decoupling weights from mask optimization, which has been widely adopted by previous work, is a key component for effective $L_0$ regularization. ",
    "url": "https://arxiv.org/abs/2304.11237",
    "authors": [
      "Kai Jia",
      "Martin Rinard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11244",
    "title": "Bilevel optimisation with embedded neural networks: Application to  scheduling and control integration",
    "abstract": "Scheduling problems requires to explicitly account for control considerations in their optimisation. The literature proposes two traditional ways to solve this integrated problem: hierarchical and monolithic. The monolithic approach ignores the control level's objective and incorporates it as a constraint into the upper level at the cost of suboptimality. The hierarchical approach requires solving a mathematically complex bilevel problem with the scheduling acting as the leader and control as the follower. The linking variables between both levels belong to a small subset of scheduling and control decision variables. For this subset of variables, data-driven surrogate models have been used to learn follower responses to different leader decisions. In this work, we propose to use ReLU neural networks for the control level. Consequently, the bilevel problem is collapsed into a single-level MILP that is still able to account for the control level's objective. This single-level MILP reformulation is compared with the monolithic approach and benchmarked against embedding a nonlinear expression of the neural networks into the optimisation. Moreover, a neural network is used to predict control level feasibility. The case studies involve batch reactor and sequential batch process scheduling problems. The proposed methodology finds optimal solutions while largely outperforming both approaches in terms of computational time. Additionally, due to well-developed MILP solvers, adding ReLU neural networks in a MILP form marginally impacts the computational time. The solution's error due to prediction accuracy is correlated with the neural network training error. Overall, we expose how - by using an existing big-M reformulation and being careful about integrating machine learning and optimisation pipelines - we can more efficiently solve the bilevel scheduling-control problem with high accuracy. ",
    "url": "https://arxiv.org/abs/2304.11244",
    "authors": [
      "Roberto X. Jim\u00e9nez J.",
      "Damien van de Berg",
      "Ehecatl Antonio Del Rio-Chanona"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11247",
    "title": "Quantum physics-informed neural networks for simulating computational  fluid dynamics in complex shapes",
    "abstract": "Finding the distribution of the velocities and pressures of a fluid (by solving the Navier-Stokes equations) is a principal task in the chemical, energy, and pharmaceutical industries, as well as in mechanical engineering and the design of pipeline systems. With existing solvers, such as OpenFOAM and Ansys, simulations of fluid dynamics in intricate geometries are computationally expensive and require re-simulation whenever the geometric parameters or the initial and boundary conditions are altered. Physics-informed neural networks (PINNs) are a promising tool for simulating fluid flows in complex geometries, as they can adapt to changes in the geometry and mesh definitions, allowing for generalization across different shapes. We present a hybrid quantum physics-informed neural network that simulates laminar fluid flows in 3D Y-shaped mixers. Our approach combines the expressive power of a quantum model with the flexibility of a PINN, resulting in a 21% higher accuracy compared to a purely classical neural network. Our findings highlight the potential of machine learning approaches, and in particular quantum PINNs, for complex shape optimization tasks in computational fluid dynamics. By improving the accuracy of fluid simulations in complex geometries, our research using quantum PINNs contributes to the development of more efficient and reliable fluid dynamics solvers. ",
    "url": "https://arxiv.org/abs/2304.11247",
    "authors": [
      "Alexandr Sedykh",
      "Maninadh Podapaka",
      "Asel Sagingalieva",
      "Nikita Smertyak",
      "Karan Pinto",
      "Markus Pflitsch",
      "Alexey Melnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2304.11249",
    "title": "eWaSR -- an embedded-compute-ready maritime obstacle detection network",
    "abstract": "Maritime obstacle detection is critical for safe navigation of autonomous surface vehicles (ASVs). While the accuracy of image-based detection methods has advanced substantially, their computational and memory requirements prohibit deployment on embedded devices. In this paper we analyze the currently best-performing maritime obstacle detection network WaSR. Based on the analysis we then propose replacements for the most computationally intensive stages and propose its embedded-compute-ready variant eWaSR. In particular, the new design follows the most recent advancements of transformer-based lightweight networks. eWaSR achieves comparable detection results to state-of-the-art WaSR with only 0.52% F1 score performance drop and outperforms other state-of-the-art embedded-ready architectures by over 9.74% in F1 score. On a standard GPU, eWaSR runs 10x faster than the original WaSR (115 FPS vs 11 FPS). Tests on a real embedded device OAK-D show that, while WaSR cannot run due to memory restrictions, eWaSR runs comfortably at 5.5 FPS. This makes eWaSR the first practical embedded-compute-ready maritime obstacle detection network. The source code and trained eWaSR models are publicly available here: https://github.com/tersekmatija/eWaSR. ",
    "url": "https://arxiv.org/abs/2304.11249",
    "authors": [
      "Matija Ter\u0161ek",
      "Lojze \u017dust",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11262",
    "title": "Stochastic MPC Based Attacks on Object Tracking in Autonomous Driving  Systems",
    "abstract": "Decision making in advanced driver assistance systems involves in general the estimated trajectories of the surrounding objects. Multiple object tracking refers to the process of estimating in real time these trajectories, leveraging for this purpose sensors to detect the objects. This paper deals with devising attacks on object tracking in automated vehicles. The vehicle is assumed to have a detection-based object tracking system that relies on multiple sensors and uses an estimator such as a Kalman filter for sensor fusion and state estimation. The attack goal is to modify the object's state estimated by the victim vehicle to put the vehicle in an unsafe situation. This goal is achieved by judiciously perturbing some or all of the sensor outputs corresponding to the object of interest over a desired horizon. A stochastic model predictive control (SMPC) problem is formulated to compute the sequence of perturbations, whereby hard constraints on the perturbations and probabilistic chance constraints on the object's state are imposed. The chance constraints ensure that some desired conditions for a successful attack are satisfied with a prespecified probability. Reasonable assumptions are then made to obtain a computationally tractable linear SMPC program. The approach is demonstrated on an adaptive cruise control system in a simulation environment, where successful sequential attacks are generated, leading the victim vehicle into dangerous driving situations including collisions. ",
    "url": "https://arxiv.org/abs/2304.11262",
    "authors": [
      "Sourav Sinha",
      "Mazen Farhood"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.11263",
    "title": "Benchmarking Low-Shot Robustness to Natural Distribution Shifts",
    "abstract": "Robustness to natural distribution shifts has seen remarkable progress thanks to recent pre-training strategies combined with better fine-tuning methods. However, such fine-tuning assumes access to large amounts of labelled data, and the extent to which the observations hold when the amount of training data is not as high remains unknown. We address this gap by performing the first in-depth study of robustness to various natural distribution shifts in different low-shot regimes: spanning datasets, architectures, pre-trained initializations, and state-of-the-art robustness interventions. Most importantly, we find that there is no single model of choice that is often more robust than others, and existing interventions can fail to improve robustness on some datasets even if they do so in the full-shot regime. We hope that our work will motivate the community to focus on this problem of practical importance. ",
    "url": "https://arxiv.org/abs/2304.11263",
    "authors": [
      "Aaditya Singh",
      "Kartik Sarangmath",
      "Prithvijit Chattopadhyay",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11275",
    "title": "Semantic-Aware Graph Matching Mechanism for Multi-Label Image  Recognition",
    "abstract": "Multi-label image recognition aims to predict a set of labels that present in an image. The key to deal with such problem is to mine the associations between image contents and labels, and further obtain the correct assignments between images and their labels. In this paper, we treat each image as a bag of instances, and formulate the task of multi-label image recognition as an instance-label matching selection problem. To model such problem, we propose an innovative Semantic-aware Graph Matching framework for Multi-Label image recognition (ML-SGM), in which Graph Matching mechanism is introduced owing to its good performance of excavating the instance and label relationship. The framework explicitly establishes category correlations and instance-label correspondences by modeling the relation among content-aware (instance) and semantic-aware (label) category representations, to facilitate multi-label image understanding and reduce the dependency of large amounts of training samples for each category. Specifically, we first construct an instance spatial graph and a label semantic graph respectively and then incorporate them into a constructed assignment graph by connecting each instance to all labels. Subsequently, the graph network block is adopted to aggregate and update all nodes and edges state on the assignment graph to form structured representations for each instance and label. Our network finally derives a prediction score for each instance-label correspondence and optimizes such correspondence with a weighted cross-entropy loss. Empirical results conducted on generic multi-label image recognition demonstrate the superiority of our proposed method. Moreover, the proposed method also shows advantages in multi-label recognition with partial labels and multi-label few-shot learning, as well as outperforms current state-of-the-art methods with a clear margin. ",
    "url": "https://arxiv.org/abs/2304.11275",
    "authors": [
      "Yanan Wu",
      "Songhe Feng",
      "Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11284",
    "title": "Optimal Vehicle Charging in Bilevel Power-Traffic Networks via Charging  Demand Function",
    "abstract": "Electric vehicle (EV) charging couples the operation of power and traffic networks. Specifically, the power network determines the charging price at various locations, while EVs on the traffic network optimize the charging power given the price, acting as price-takers. We model such decision-making processes by a bilevel program, with the power network at the upper-level and the traffic network at the lower-level. However, since the two networks are managed by separate entities and the charging expense term, calculated as the product of charging price and charging demand, is nonlinear. Solving the bilevel program is nontrivial. To overcome these challenges, we derive the charging demand function using multiparametric programming theory. This function establishes a piecewise linear relationship between the charging price and the optimal charging power, enabling the power network operator to manage EV charging power independently while accounting for the coupling between the two networks. With the derived function, we are also able to replace the nonlinear charging expense term with a piecewise quadratic one, thus guaranteeing solution optimality. Our numerical studies demonstrate that different traffic demands can have an impact on charging patterns and the power network can effectively incentivize charging at low-price nodes through price setting. ",
    "url": "https://arxiv.org/abs/2304.11284",
    "authors": [
      "Yufan Zhang",
      "Sujit Dey",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11285",
    "title": "Identifying Appropriate Intellectual Property Protection Mechanisms for  Machine Learning Models: A Systematization of Watermarking, Fingerprinting,  Model Access, and Attacks",
    "abstract": "The commercial use of Machine Learning (ML) is spreading; at the same time, ML models are becoming more complex and more expensive to train, which makes Intellectual Property Protection (IPP) of trained models a pressing issue. Unlike other domains that can build on a solid understanding of the threats, attacks and defenses available to protect their IP, the ML-related research in this regard is still very fragmented. This is also due to a missing unified view as well as a common taxonomy of these aspects. In this paper, we systematize our findings on IPP in ML, while focusing on threats and attacks identified and defenses proposed at the time of writing. We develop a comprehensive threat model for IP in ML, categorizing attacks and defenses within a unified and consolidated taxonomy, thus bridging research from both the ML and security communities. ",
    "url": "https://arxiv.org/abs/2304.11285",
    "authors": [
      "Isabell Lederer",
      "Rudolf Mayer",
      "Andreas Rauber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.11295",
    "title": "Planning-inspired Hierarchical Trajectory Prediction for Autonomous  Driving",
    "abstract": "Recently, anchor-based trajectory prediction methods have shown promising performance, which directly selects a final set of anchors as future intents in the spatio-temporal coupled space. However, such methods typically neglect a deeper semantic interpretation of path intents and suffer from inferior performance under the imperfect High-Definition (HD) map. To address this challenge, we propose a novel Planning-inspired Hierarchical (PiH) trajectory prediction framework that selects path and speed intents through a hierarchical lateral and longitudinal decomposition. Especially, a hybrid lateral predictor is presented to select a set of fixed-distance lateral paths from map-based road-following and cluster-based free-move path candidates. {Then, the subsequent longitudinal predictor selects plausible goals sampled from a set of lateral paths as speed intents.} Finally, a trajectory decoder is given to generate future trajectories conditioned on a categorical distribution over lateral-longitudinal intents. Experiments demonstrate that PiH achieves competitive and more balanced results against state-of-the-art methods on the Argoverse motion forecasting benchmark and has the strongest robustness under the imperfect HD map. ",
    "url": "https://arxiv.org/abs/2304.11295",
    "authors": [
      "Ding Li",
      "Qichao Zhang",
      "Zhongpu Xia",
      "Kuan Zhang",
      "Menglong Yi",
      "Wenda Jin",
      "Dongbin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.11300",
    "title": "MAWSEO: Adversarial Wiki Search Poisoning for Illicit Online Promotion",
    "abstract": "As a prominent instance of vandalism edits, Wiki search poisoning for illicit promotion is a cybercrime in which the adversary aims at editing Wiki articles to promote illicit businesses through Wiki search results of relevant queries. In this paper, we report a study that, for the first time, shows that such stealthy blackhat SEO on Wiki can be automated. Our technique, called MAWSEO, employs adversarial revisions to achieve real-world cybercriminal objectives, including rank boosting, vandalism detection evasion, topic relevancy, semantic consistency, user awareness (but not alarming) of promotional content, etc. Our evaluation and user study demonstrate that MAWSEO is able to effectively and efficiently generate adversarial vandalism edits, which can bypass state-of-the-art built-in Wiki vandalism detectors, and also get promotional content through to Wiki users without triggering their alarms. In addition, we investigated potential defense, including coherence based detection and adversarial training of vandalism detection, against our attack in the Wiki ecosystem. ",
    "url": "https://arxiv.org/abs/2304.11300",
    "authors": [
      "Zilong Lin",
      "Zhengyi Li",
      "Xiaojing Liao",
      "XiaoFeng Wang",
      "Xiaozhong Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.11306",
    "title": "Biomimetic IGA neuron growth modeling with neurite morphometric features  and CNN-based prediction",
    "abstract": "Neuron growth is a complex, multi-stage process that develops sophisticated morphologies and interwoven neurite networks. Recent advances have enabled us to examine the effects of neuron growth factors and seek causes for neurodegenerative diseases, such as Alzheimer's disease, Parkinson's disease, and amyotrophic lateral sclerosis. A computational tool that studies neuron growth could shed crucial insights into the effects of various factors and help find a neurodegeneration cure. However, there lacks a computational tool to accurately and realistically simulate neuron growth within reasonable time frames. Bio-phenomenon models ignore potential factors and cannot generate realistic results, and bio-physics models require computationally expensive high-order governing equations. This paper incorporates experimental neurite features into a phase field method-based neuron growth model using an isogeometric analysis collocation (IGA-C) approach. Based on a semi-automated quantitative analysis of neurite morphology, we obtain relative turning angle, average tortuosity, neurite endpoints, average segment length, and the total length of neurites. We use the total neurite length to determine the evolving days in vitro (DIV) and select corresponding neurite features to drive and constrain neuron growth. This approach archives biomimetic neuron growth patterns with automatic growth stage transitions by incorporating corresponding DIV neurite morphometric data based on the total neurite length of the evolving neurite morphology. Furthermore, we built a convolutional neural network (CNN) to significantly reduce computational costs for predicting neurite growth. With a customized convolutional autoencoder as the backbone, our CNN model can predict neurite patterns with a high prediction accuracy, 97.77%, while taking 7 orders of magnitude less computational times than our IGA-C solver. ",
    "url": "https://arxiv.org/abs/2304.11306",
    "authors": [
      "Kuanren Qian",
      "Ashlee S. Liao",
      "Shixuan Gu",
      "Victoria A. Webster-Wood",
      "Yongjie Jessica Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.11315",
    "title": "Unmatched uncertainty mitigation through neural network supported model  predictive control",
    "abstract": "This paper presents a deep learning based model predictive control (MPC) algorithm for systems with unmatched and bounded state-action dependent uncertainties of unknown structure. We utilize a deep neural network (DNN) as an oracle in the underlying optimization problem of learning based MPC (LBMPC) to estimate unmatched uncertainties. Generally, non-parametric oracles such as DNN are considered difficult to employ with LBMPC due to the technical difficulties associated with estimation of their coefficients in real time. We employ a dual-timescale adaptation mechanism, where the weights of the last layer of the neural network are updated in real time while the inner layers are trained on a slower timescale using the training data collected online and selectively stored in a buffer. Our results are validated through a numerical experiment on the compression system model of jet engine. These results indicate that the proposed approach is implementable in real time and carries the theoretical guarantees of LBMPC. ",
    "url": "https://arxiv.org/abs/2304.11315",
    "authors": [
      "Mateus V. Gasparino",
      "Prabhat K. Mishra",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11318",
    "title": "A Semi-Supervised Framework for Misinformation Detection",
    "abstract": "The spread of misinformation in social media outlets has become a prevalent societal problem and is the cause of many kinds of social unrest. Curtailing its prevalence is of great importance and machine learning has shown significant promise. However, there are two main challenges when applying machine learning to this problem. First, while much too prevalent in one respect, misinformation, actually, represents only a minor proportion of all the postings seen on social media. Second, labeling the massive amount of data necessary to train a useful classifier becomes impractical. Considering these challenges, we propose a simple semi-supervised learning framework in order to deal with extreme class imbalances that has the advantage, over other approaches, of using actual rather than simulated data to inflate the minority class. We tested our framework on two sets of Covid-related Twitter data and obtained significant improvement in F1-measure on extremely imbalanced scenarios, as compared to simple classical and deep-learning data generation methods such as SMOTE, ADASYN, or GAN-based data generation. ",
    "url": "https://arxiv.org/abs/2304.11318",
    "authors": [
      "Yueyang Liu",
      "Zois Boukouvalas",
      "Nathalie Japkowicz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11330",
    "title": "Self-supervised Learning by View Synthesis",
    "abstract": "We present view-synthesis autoencoders (VSA) in this paper, which is a self-supervised learning framework designed for vision transformers. Different from traditional 2D pretraining methods, VSA can be pre-trained with multi-view data. In each iteration, the input to VSA is one view (or multiple views) of a 3D object and the output is a synthesized image in another target pose. The decoder of VSA has several cross-attention blocks, which use the source view as value, source pose as key, and target pose as query. They achieve cross-attention to synthesize the target view. This simple approach realizes large-angle view synthesis and learns spatial invariant representation, where the latter is decent initialization for transformers on downstream tasks, such as 3D classification on ModelNet40, ShapeNet Core55, and ScanObjectNN. VSA outperforms existing methods significantly for linear probing and is competitive for fine-tuning. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2304.11330",
    "authors": [
      "Shaoteng Liu",
      "Xiangyu Zhang",
      "Tao Hu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11332",
    "title": "Input Augmentation with SAM: Boosting Medical Image Segmentation with  Segmentation Foundation Model",
    "abstract": "The Segment Anything Model (SAM) is a recently developed large model for general-purpose segmentation for computer vision tasks. SAM was trained using 11 million images with over 1 billion masks and can produce segmentation results for a wide range of objects in natural scene images. SAM can be viewed as a general perception model for segmentation (partitioning images into semantically meaningful regions). Thus, how to utilize such a large foundation model for medical image segmentation is an emerging research target. This paper shows that although SAM does not immediately give high-quality segmentation for medical images, its generated masks, features, and stability scores are useful for building and training better medical image segmentation models. In particular, we demonstrate how to use SAM to augment image inputs for a commonly-used medical image segmentation model (e.g., U-Net). Experiments on two datasets show the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2304.11332",
    "authors": [
      "Yizhe Zhang",
      "Tao Zhou",
      "Peixian Liang",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11337",
    "title": "A Deep Neural Network Deployment Based on Resistive Memory Accelerator  Simulation",
    "abstract": "The objective of this study is to illustrate the process of training a Deep Neural Network (DNN) within a Resistive RAM (ReRAM) Crossbar-based simulation environment using CrossSim, an Application Programming Interface (API) developed for this purpose. The CrossSim API is designed to simulate neural networks while taking into account factors that may affect the accuracy of solutions during training on non-linear and noisy ReRAM devices. ReRAM-based neural cores that serve as memory accelerators for digital cores on a chip can significantly reduce energy consumption by minimizing data transfers between the processor and SRAM and DRAM. CrossSim employs lookup tables obtained from experimentally derived datasets of real fabricated ReRAM devices to digitally reproduce noisy weight updates to the neural network. The CrossSim directory comprises eight device configurations that operate at different temperatures and are made of various materials. This study aims to analyse the results of training a Neural Network on the Breast Cancer Wisconsin (Diagnostic) dataset using CrossSim, plotting the innercore weight updates and average training and validation loss to investigate the outcomes of all the devices. ",
    "url": "https://arxiv.org/abs/2304.11337",
    "authors": [
      "Tejaswanth Reddy Maram",
      "Ria Barnwal",
      "Dr. Bindu B"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.11342",
    "title": "NaviNeRF: NeRF-based 3D Representation Disentanglement by Latent  Semantic Navigation",
    "abstract": "3D representation disentanglement aims to identify, decompose, and manipulate the underlying explanatory factors of 3D data, which helps AI fundamentally understand our 3D world. This task is currently under-explored and poses great challenges: (i) the 3D representations are complex and in general contains much more information than 2D image; (ii) many 3D representations are not well suited for gradient-based optimization, let alone disentanglement. To address these challenges, we use NeRF as a differentiable 3D representation, and introduce a self-supervised Navigation to identify interpretable semantic directions in the latent space. To our best knowledge, this novel method, dubbed NaviNeRF, is the first work to achieve fine-grained 3D disentanglement without any priors or supervisions. Specifically, NaviNeRF is built upon the generative NeRF pipeline, and equipped with an Outer Navigation Branch and an Inner Refinement Branch. They are complementary -- the outer navigation is to identify global-view semantic directions, and the inner refinement dedicates to fine-grained attributes. A synergistic loss is further devised to coordinate two branches. Extensive experiments demonstrate that NaviNeRF has a superior fine-grained 3D disentanglement ability than the previous 3D-aware models. Its performance is also comparable to editing-oriented models relying on semantic or geometry priors. ",
    "url": "https://arxiv.org/abs/2304.11342",
    "authors": [
      "Baao Xie",
      "Bohan Li",
      "Zequn Zhang",
      "Junting Dong",
      "Xin Jin",
      "Jingyu Yang",
      "Wenjun Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11350",
    "title": "Romanian Multiword Expression Detection Using Multilingual Adversarial  Training and Lateral Inhibition",
    "abstract": "Multiword expressions are a key ingredient for developing large-scale and linguistically sound natural language processing technology. This paper describes our improvements in automatically identifying Romanian multiword expressions on the corpus released for the PARSEME v1.2 shared task. Our approach assumes a multilingual perspective based on the recently introduced lateral inhibition layer and adversarial training to boost the performance of the employed multilingual language models. With the help of these two methods, we improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen multiword expressions, the main task of the PARSEME 1.2 edition. In addition, our results can be considered SOTA performance, as they outperform the previous results on Romanian obtained by the participants in this competition. ",
    "url": "https://arxiv.org/abs/2304.11350",
    "authors": [
      "Andrei-Marius Avram",
      "Verginica Barbu Mititelu",
      "Dumitru-Clementin Cercel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.11353",
    "title": "Transition System Representation of Boolean Control Networks",
    "abstract": "First, the topological structure of a transition system is studied. Then, two types of transition system (TS) representations of Boolean networks (BNs) and Boolean control networks (BCNs) are investigated. The first kind of representation is state-based, which converts a BCN into a TS with either distinct control or non-distinct control. The second representation is output-based, which is also called the simulation of the original BCN. Some applications are also studied. ",
    "url": "https://arxiv.org/abs/2304.11353",
    "authors": [
      "Daizhan Cheng",
      "Xiao Zhang",
      "Zhengping Ji"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11359",
    "title": "Detecting Adversarial Faces Using Only Real Face Self-Perturbations",
    "abstract": "Adversarial attacks aim to disturb the functionality of a target system by adding specific noise to the input samples, bringing potential threats to security and robustness when applied to facial recognition systems. Although existing defense techniques achieve high accuracy in detecting some specific adversarial faces (adv-faces), new attack methods especially GAN-based attacks with completely different noise patterns circumvent them and reach a higher attack success rate. Even worse, existing techniques require attack data before implementing the defense, making it impractical to defend newly emerging attacks that are unseen to defenders. In this paper, we investigate the intrinsic generality of adv-faces and propose to generate pseudo adv-faces by perturbing real faces with three heuristically designed noise patterns. We are the first to train an adv-face detector using only real faces and their self-perturbations, agnostic to victim facial recognition systems, and agnostic to unseen attacks. By regarding adv-faces as out-of-distribution data, we then naturally introduce a novel cascaded system for adv-face detection, which consists of training data self-perturbations, decision boundary regularization, and a max-pooling-based binary classifier focusing on abnormal local color aberrations. Experiments conducted on LFW and CelebA-HQ datasets with eight gradient-based and two GAN-based attacks validate that our method generalizes to a variety of unseen adversarial attacks. ",
    "url": "https://arxiv.org/abs/2304.11359",
    "authors": [
      "Qian Wang",
      "Yongqin Xian",
      "Hefei Ling",
      "Jinyuan Zhang",
      "Xiaorui Lin",
      "Ping Li",
      "Jiazhong Chen",
      "Ning Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11367",
    "title": "Detecting Political Opinions in Tweets through Bipartite Graph Analysis:  A Skip Aggregation Graph Convolution Approach",
    "abstract": "Public opinion is a crucial factor in shaping political decision-making. Nowadays, social media has become an essential platform for individuals to engage in political discussions and express their political views, presenting researchers with an invaluable resource for analyzing public opinion. In this paper, we focus on the 2020 US presidential election and create a large-scale dataset from Twitter. To detect political opinions in tweets, we build a user-tweet bipartite graph based on users' posting and retweeting behaviors and convert the task into a Graph Neural Network (GNN)-based node classification problem. Then, we introduce a novel skip aggregation mechanism that makes tweet nodes aggregate information from second-order neighbors, which are also tweet nodes due to the graph's bipartite nature, effectively leveraging user behavioral information. The experimental results show that our proposed model significantly outperforms several competitive baselines. Further analyses demonstrate the significance of user behavioral information and the effectiveness of skip aggregation. ",
    "url": "https://arxiv.org/abs/2304.11367",
    "authors": [
      "Xingyu Peng",
      "Zhenkun Zhou",
      "Chong Zhang",
      "Ke Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11379",
    "title": "LiDAR2Map: In Defense of LiDAR-Based Semantic Map Construction Using  Online Camera Distillation",
    "abstract": "Semantic map construction under bird's-eye view (BEV) plays an essential role in autonomous driving. In contrast to camera image, LiDAR provides the accurate 3D observations to project the captured 3D features onto BEV space inherently. However, the vanilla LiDAR-based BEV feature often contains many indefinite noises, where the spatial features have little texture and semantic cues. In this paper, we propose an effective LiDAR-based method to build semantic map. Specifically, we introduce a BEV pyramid feature decoder that learns the robust multi-scale BEV features for semantic map construction, which greatly boosts the accuracy of the LiDAR-based method. To mitigate the defects caused by lacking semantic cues in LiDAR data, we present an online Camera-to-LiDAR distillation scheme to facilitate the semantic learning from image to point cloud. Our distillation scheme consists of feature-level and logit-level distillation to absorb the semantic information from camera in BEV. The experimental results on challenging nuScenes dataset demonstrate the efficacy of our proposed LiDAR2Map on semantic map construction, which significantly outperforms the previous LiDAR-based methods over 27.9% mIoU and even performs better than the state-of-the-art camera-based approaches. Source code is available at: https://github.com/songw-zju/LiDAR2Map. ",
    "url": "https://arxiv.org/abs/2304.11379",
    "authors": [
      "Song Wang",
      "Wentong Li",
      "Wenyu Liu",
      "Xiaolu Liu",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.11397",
    "title": "Vehicle as a Service (VaaS): Leverage Vehicles to Build Service Networks  and Capabilities for Smart Cities",
    "abstract": "Smart cities demand resources for rich immersive sensing, ubiquitous communications, powerful computing, large storage, and high intelligence (SCCSI) to support various kinds of applications, such as public safety, connected and autonomous driving, smart and connected health, and smart living. At the same time, it is widely recognized that vehicles such as autonomous cars, equipped with significantly powerful SCCSI capabilities, will become ubiquitous in future smart cities. By observing the convergence of these two trends, this article advocates the use of vehicles to build a cost-effective service network, called the Vehicle as a Service (VaaS) paradigm, where vehicles empowered with SCCSI capability form a web of mobile servers and communicators to provide SCCSI services in smart cities. Towards this direction, we first examine the potential use cases in smart cities and possible upgrades required for the transition from traditional vehicular ad hoc networks (VANETs) to VaaS. Then, we will introduce the system architecture of the VaaS paradigm and discuss how it can provide SCCSI services in future smart cities, respectively. At last, we identify the open problems of this paradigm and future research directions, including architectural design, service provisioning, incentive design, and security & privacy. We expect that this paper paves the way towards developing an economically effective and sustainable approach for building smart cities. ",
    "url": "https://arxiv.org/abs/2304.11397",
    "authors": [
      "Xianhao Chen",
      "Yiqin Deng",
      "Haichuan Ding",
      "Guanqiao Qu",
      "Haixia Zhang",
      "Pan Li",
      "Yuguang Fang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.11404",
    "title": "SSN: Stockwell Scattering Network for SAR Image Change Detection",
    "abstract": "Recently, synthetic aperture radar (SAR) image change detection has become an interesting yet challenging direction due to the presence of speckle noise. Although both traditional and modern learning-driven methods attempted to overcome this challenge, deep convolutional neural networks (DCNNs)-based methods are still hindered by the lack of interpretability and the requirement of large computation power. To overcome this drawback, wavelet scattering network (WSN) and Fourier scattering network (FSN) are proposed. Combining respective merits of WSN and FSN, we propose Stockwell scattering network (SSN) based on Stockwell transform which is widely applied against noisy signals and shows advantageous characteristics in speckle reduction. The proposed SSN provides noise-resilient feature representation and obtains state-of-art performance in SAR image change detection as well as high computational efficiency. Experimental results on three real SAR image datasets demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2304.11404",
    "authors": [
      "Gong Chen",
      "Yanan Zhao",
      "Yi Wang",
      "Kim-Hui Yap"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.11408",
    "title": "Lightweight Toxicity Detection in Spoken Language: A Transformer-based  Approach for Edge Devices",
    "abstract": "Toxicity is a prevalent social behavior that involves the use of hate speech, offensive language, bullying, and abusive speech. While text-based approaches for toxicity detection are common, there is limited research on processing speech signals in the physical world. Detecting toxicity in the physical world is challenging due to the difficulty of integrating AI-capable computers into the environment. We propose a lightweight transformer model based on wav2vec2.0 and optimize it using techniques such as quantization and knowledge distillation. Our model uses multitask learning and achieves an average macro F1-score of 90.3\\% and a weighted accuracy of 88\\%, outperforming state-of-the-art methods on DeToxy-B and a public dataset. Our results show that quantization reduces the model size by almost 4 times and RAM usage by 3.3\\%, with only a 1\\% F1 score decrease. Knowledge distillation reduces the model size by 3.7 times, RAM usage by 1.9, and inference time by 2 times, but decreases accuracy by 8\\%. Combining both techniques reduces the model size by 14.6 times and RAM usage by around 4.3 times, with a two-fold inference time improvement. Our compact model is the first end-to-end speech-based toxicity detection model based on a lightweight transformer model suitable for deployment in physical spaces. The results show its feasibility for toxicity detection on edge devices in real-world environments. ",
    "url": "https://arxiv.org/abs/2304.11408",
    "authors": [
      "Ahlam Husni Abu Nada",
      "Siddique Latif",
      "Junaid Qadir"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.11411",
    "title": "Detecting Spoilers in Movie Reviews with External Movie Knowledge and  User Networks",
    "abstract": "Online movie review platforms are providing crowdsourced feedback for the film industry and the general public, while spoiler reviews greatly compromise user experience. Although preliminary research efforts were made to automatically identify spoilers, they merely focus on the review content itself, while robust spoiler detection requires putting the review into the context of facts and knowledge regarding movies, user behavior on film review platforms, and more. In light of these challenges, we first curate a large-scale network-based spoiler detection dataset LCS and a comprehensive and up-to-date movie knowledge base UKM. We then propose MVSD, a novel Multi-View Spoiler Detection framework that takes into account the external knowledge about movies and user activities on movie review platforms. Specifically, MVSD constructs three interconnecting heterogeneous information networks to model diverse data sources and their multi-view attributes, while we design and employ a novel heterogeneous graph neural network architecture for spoiler detection as node-level classification. Extensive experiments demonstrate that MVSD advances the state-of-the-art on two spoiler detection datasets, while the introduction of external knowledge and user interactions help ground robust spoiler detection. Our data and code are available at https://github.com/Arthur-Heng/Spoiler-Detection ",
    "url": "https://arxiv.org/abs/2304.11411",
    "authors": [
      "Heng Wang",
      "Wenqian Zhang",
      "Yuyang Bai",
      "Zhaoxuan Tan",
      "Shangbin Feng",
      "Qinghua Zheng",
      "Minnan Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11422",
    "title": "STNet: Spatial and Temporal feature fusion network for change detection  in remote sensing images",
    "abstract": "As an important task in remote sensing image analysis, remote sensing change detection (RSCD) aims to identify changes of interest in a region from spatially co-registered multi-temporal remote sensing images, so as to monitor the local development. Existing RSCD methods usually formulate RSCD as a binary classification task, representing changes of interest by merely feature concatenation or feature subtraction and recovering the spatial details via densely connected change representations, whose performances need further improvement. In this paper, we propose STNet, a RSCD network based on spatial and temporal feature fusions. Specifically, we design a temporal feature fusion (TFF) module to combine bi-temporal features using a cross-temporal gating mechanism for emphasizing changes of interest; a spatial feature fusion module is deployed to capture fine-grained information using a cross-scale attention mechanism for recovering the spatial details of change representations. Experimental results on three benchmark datasets for RSCD demonstrate that the proposed method achieves the state-of-the-art performance. Code is available at https://github.com/xwmaxwma/rschange. ",
    "url": "https://arxiv.org/abs/2304.11422",
    "authors": [
      "Xiaowen Ma",
      "Jiawei Yang",
      "Tingfeng Hong",
      "Mengting Ma",
      "Ziyan Zhao",
      "Tian Feng",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11424",
    "title": "SACANet: scene-aware class attention network for semantic segmentation  of remote sensing images",
    "abstract": "Spatial attention mechanism has been widely used in semantic segmentation of remote sensing images given its capability to model long-range dependencies. Many methods adopting spatial attention mechanism aggregate contextual information using direct relationships between pixels within an image, while ignoring the scene awareness of pixels (i.e., being aware of the global context of the scene where the pixels are located and perceiving their relative positions). Given the observation that scene awareness benefits context modeling with spatial correlations of ground objects, we design a scene-aware attention module based on a refined spatial attention mechanism embedding scene awareness. Besides, we present a local-global class attention mechanism to address the problem that general attention mechanism introduces excessive background noises while hardly considering the large intra-class variance in remote sensing images. In this paper, we integrate both scene-aware and class attentions to propose a scene-aware class attention network (SACANet) for semantic segmentation of remote sensing images. Experimental results on three datasets show that SACANet outperforms other state-of-the-art methods and validate its effectiveness. Code is available at https://github.com/xwmaxwma/rssegmentation. ",
    "url": "https://arxiv.org/abs/2304.11424",
    "authors": [
      "Xiaowen Ma",
      "Rui Che",
      "Tingfeng Hong",
      "Mengting Ma",
      "Ziyan Zhao",
      "Tian Feng",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11432",
    "title": "Universal Adversarial Backdoor Attacks to Fool Vertical Federated  Learning in Cloud-Edge Collaboration",
    "abstract": "Vertical federated learning (VFL) is a cloud-edge collaboration paradigm that enables edge nodes, comprising resource-constrained Internet of Things (IoT) devices, to cooperatively train artificial intelligence (AI) models while retaining their data locally. This paradigm facilitates improved privacy and security for edges and IoT devices, making VFL an essential component of Artificial Intelligence of Things (AIoT) systems. Nevertheless, the partitioned structure of VFL can be exploited by adversaries to inject a backdoor, enabling them to manipulate the VFL predictions. In this paper, we aim to investigate the vulnerability of VFL in the context of binary classification tasks. To this end, we define a threat model for backdoor attacks in VFL and introduce a universal adversarial backdoor (UAB) attack to poison the predictions of VFL. The UAB attack, consisting of universal trigger generation and clean-label backdoor injection, is incorporated during the VFL training at specific iterations. This is achieved by alternately optimizing the universal trigger and model parameters of VFL sub-problems. Our work distinguishes itself from existing studies on designing backdoor attacks for VFL, as those require the knowledge of auxiliary information not accessible within the split VFL architecture. In contrast, our approach does not necessitate any additional data to execute the attack. On the LendingClub and Zhongyuan datasets, our approach surpasses existing state-of-the-art methods, achieving up to 100\\% backdoor task performance while maintaining the main task performance. Our results in this paper make a major advance to revealing the hidden backdoor risks of VFL, hence paving the way for the future development of secure AIoT. ",
    "url": "https://arxiv.org/abs/2304.11432",
    "authors": [
      "Peng Chen",
      "Xin Du",
      "Zhihui Lu",
      "Hongfeng Chai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11436",
    "title": "Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack",
    "abstract": "Federated Learning with Model Distillation (FedMD) is a nascent collaborative learning paradigm, where only output logits of public datasets are transmitted as distilled knowledge, instead of passing on private model parameters that are susceptible to gradient inversion attacks, a known privacy risk in federated learning. In this paper, we found that even though sharing output logits of public datasets is safer than directly sharing gradients, there still exists a substantial risk of data exposure caused by carefully designed malicious attacks. Our study shows that a malicious server can inject a PLI (Paired-Logits Inversion) attack against FedMD and its variants by training an inversion neural network that exploits the confidence gap between the server and client models. Experiments on multiple facial recognition datasets validate that under FedMD-like schemes, by using paired server-client logits of public datasets only, the malicious server is able to reconstruct private images on all tested benchmarks with a high success rate. ",
    "url": "https://arxiv.org/abs/2304.11436",
    "authors": [
      "Hideaki Takahashi",
      "Jingjing Liu",
      "Yang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11438",
    "title": "Constructing a meta-learner for unsupervised anomaly detection",
    "abstract": "Unsupervised anomaly detection (AD) is critical for a wide range of practical applications, from network security to health and medical tools. Due to the diversity of problems, no single algorithm has been found to be superior for all AD tasks. Choosing an algorithm, otherwise known as the Algorithm Selection Problem (ASP), has been extensively examined in supervised classification problems, through the use of meta-learning and AutoML, however, it has received little attention in unsupervised AD tasks. This research proposes a new meta-learning approach that identifies an appropriate unsupervised AD algorithm given a set of meta-features generated from the unlabelled input dataset. The performance of the proposed meta-learner is superior to the current state of the art solution. In addition, a mixed model statistical analysis has been conducted to examine the impact of the meta-learner components: the meta-model, meta-features, and the base set of AD algorithms, on the overall performance of the meta-learner. The analysis was conducted using more than 10,000 datasets, which is significantly larger than previous studies. Results indicate that a relatively small number of meta-features can be used to identify an appropriate AD algorithm, but the choice of a meta-model in the meta-learner has a considerable impact. ",
    "url": "https://arxiv.org/abs/2304.11438",
    "authors": [
      "Ma\u0142gorzata Gutowska",
      "Suzanne Little",
      "Andrew McCarren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11448",
    "title": "Dehazing-NeRF: Neural Radiance Fields from Hazy Images",
    "abstract": "Neural Radiance Field (NeRF) has received much attention in recent years due to the impressively high quality in 3D scene reconstruction and novel view synthesis. However, image degradation caused by the scattering of atmospheric light and object light by particles in the atmosphere can significantly decrease the reconstruction quality when shooting scenes in hazy conditions. To address this issue, we propose Dehazing-NeRF, a method that can recover clear NeRF from hazy image inputs. Our method simulates the physical imaging process of hazy images using an atmospheric scattering model, and jointly learns the atmospheric scattering model and a clean NeRF model for both image dehazing and novel view synthesis. Different from previous approaches, Dehazing-NeRF is an unsupervised method with only hazy images as the input, and also does not rely on hand-designed dehazing priors. By jointly combining the depth estimated from the NeRF 3D scene with the atmospheric scattering model, our proposed model breaks through the ill-posed problem of single-image dehazing while maintaining geometric consistency. Besides, to alleviate the degradation of image quality caused by information loss, soft margin consistency regularization, as well as atmospheric consistency and contrast discriminative loss, are addressed during the model training process. Extensive experiments demonstrate that our method outperforms the simple combination of single-image dehazing and NeRF on both image dehazing and novel view image synthesis. ",
    "url": "https://arxiv.org/abs/2304.11448",
    "authors": [
      "Tian Li",
      "LU Li",
      "Wei Wang",
      "Zhangchi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11461",
    "title": "Recurrent Neural Networks and Long Short-Term Memory Networks: Tutorial  and Survey",
    "abstract": "This is a tutorial paper on Recurrent Neural Network (RNN), Long Short-Term Memory Network (LSTM), and their variants. We start with a dynamical system and backpropagation through time for RNN. Then, we discuss the problems of gradient vanishing and explosion in long-term dependencies. We explain close-to-identity weight matrix, long delays, leaky units, and echo state networks for solving this problem. Then, we introduce LSTM gates and cells, history and variants of LSTM, and Gated Recurrent Units (GRU). Finally, we introduce bidirectional RNN, bidirectional LSTM, and the Embeddings from Language Model (ELMo) network, for processing a sequence in both directions. ",
    "url": "https://arxiv.org/abs/2304.11461",
    "authors": [
      "Benyamin Ghojogh",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.11463",
    "title": "OmniLabel: A Challenging Benchmark for Language-Based Object Detection",
    "abstract": "Language-based object detection is a promising direction towards building a natural interface to describe objects in images that goes far beyond plain category names. While recent methods show great progress in that direction, proper evaluation is lacking. With OmniLabel, we propose a novel task definition, dataset, and evaluation metric. The task subsumes standard- and open-vocabulary detection as well as referring expressions. With more than 28K unique object descriptions on over 25K images, OmniLabel provides a challenging benchmark with diverse and complex object descriptions in a naturally open-vocabulary setting. Moreover, a key differentiation to existing benchmarks is that our object descriptions can refer to one, multiple or even no object, hence, providing negative examples in free-form text. The proposed evaluation handles the large label space and judges performance via a modified average precision metric, which we validate by evaluating strong language-based baselines. OmniLabel indeed provides a challenging test bed for future research on language-based detection. ",
    "url": "https://arxiv.org/abs/2304.11463",
    "authors": [
      "Samuel Schulter",
      "Vijay Kumar B G",
      "Yumin Suh",
      "Konstantinos M. Dafnis",
      "Zhixing Zhang",
      "Shiyu Zhao",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11464",
    "title": "Model-Free Learning of Optimal Two-Stage Beamformers for Passive  IRS-Aided Network Design",
    "abstract": "Electronically tunable metasurfaces, or Intelligent Reflective Surfaces (IRSs), are a popular technology for achieving high spectral efficiency in modern wireless systems by shaping channels using a multitude of tunable passive reflective elements. Capitalizing on key practical limitations of IRS-aided beamforming pertaining to system modeling and channel sensing/estimation, we propose a novel, fully data-driven Zeroth-order Stochastic Gradient Ascent (ZoSGA) algorithm for general two-stage (i.e., short/long-term), fully-passive IRS-aided stochastic utility maximization. ZoSGA learns long-term optimal IRS beamformers jointly with short-term optimal precoders (e.g., WMMSE-based) via minimal zeroth-order reinforcement and in a strictly model-free fashion, relying solely on the \\textit{effective} compound channels observed at the terminals, while being independent of channel models or network/IRS configurations. Another remarkable feature of ZoSGA is being amenable to analysis, enabling us to establish a state-of-the-art (SOTA) convergence rate of the order of $\\boldsymbol{O}(\\sqrt{S}\\epsilon^{-4})$ under minimal assumptions, where $S$ is the total number of IRS elements, and $\\epsilon$ is a desired suboptimality target. Our numerical results on a standard MISO downlink IRS-aided sumrate maximization setting establish SOTA empirical behavior of ZoSGA as well, consistently and substantially outperforming standard fully model-based baselines. Lastly, we demonstrate that ZoSGA can in fact operate \\textit{in the field}, by directly optimizing the capacitances of a varactor-based electromagnetic IRS model (unknown to ZoSGA) on a multiple user/IRS, compute-heavy network setting, with essentially no computational overheads or performance degradation. ",
    "url": "https://arxiv.org/abs/2304.11464",
    "authors": [
      "Hassaan Hashmi",
      "Spyridon Pougkakiotis",
      "Dionysios S. Kalogerias"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.11482",
    "title": "Preliminary results on the herdability of complex multiagent systems via  local information",
    "abstract": "We present preliminary results on the problem of driving the dynamics of a group of agents, the herders, so as to steer the collective behaviour of another group of agents, the targets, interacting with them. We define this problem as the multiagent herding control problem and study the herdability of the target agents by relaxing some strong assumptions often made in the existing literature, namely that targets are cohesive in the absence of herders and that herders possess global information. We find that scaling laws exist linking crucial parameters such as the herders' sensing radius and the targets density with the herdability of the system. Our most surprising observation, supported by exhaustive numerical experiments, is that the crucial effect of limited sensing is that the minimum number of herders required to solve the problem significantly increases below a critical minimum density of the target agents. ",
    "url": "https://arxiv.org/abs/2304.11482",
    "authors": [
      "Andrea Lama",
      "Mario Di Bernardo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2304.11485",
    "title": "Understanding Lexical Biases when Identifying Gang-related Social Media  Communications",
    "abstract": "Individuals involved in gang-related activity use mainstream social media including Facebook and Twitter to express taunts and threats as well as grief and memorializing. However, identifying the impact of gang-related activity in order to serve community member needs through social media sources has a unique set of challenges. This includes the difficulty of ethically identifying training data of individuals impacted by gang activity and the need to account for a non-standard language style commonly used in the tweets from these individuals. Our study provides evidence of methods where natural language processing tools can be helpful in efficiently identifying individuals who may be in need of community care resources such as counselors, conflict mediators, or academic/professional training programs. We demonstrate that our binary logistic classifier outperforms baseline standards in identifying individuals impacted by gang-related violence using a sample of gang-related tweets associated with Chicago. We ultimately found that the language of a tweet is highly relevant and that uses of ``big data'' methods or machine learning models need to better understand how language impacts the model's performance and how it discriminates among populations. ",
    "url": "https://arxiv.org/abs/2304.11485",
    "authors": [
      "Dhiraj Murthy",
      "Constantine Caramanis",
      "Koustav Rudra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.11488",
    "title": "Physics-guided generative adversarial network to learn physical models",
    "abstract": "This short note describes the concept of guided training of deep neural networks (DNNs) to learn physically reasonable solutions. DNNs are being widely used to predict phenomena in physics and mechanics. One of the issues of DNNs is that their output does not always satisfy physical equations. One approach to consider physical equations is adding a residual of equations into the loss function; this is called physics-informed neural network (PINN). One feature of PINNs is that the physical equations and corresponding residual must be implemented as part of a neural network model. In addition, the residual does not always converge to a small value. The proposed model is a physics-guided generative adversarial network (PG-GAN) that uses a GAN architecture in which physical equations are used to judge whether the neural network's output is consistent with physics. The proposed method was applied to a simple problem to assess its potential usability. ",
    "url": "https://arxiv.org/abs/2304.11488",
    "authors": [
      "Kazuo Yonekura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2304.11501",
    "title": "Translationese Reduction using Abstract Meaning Representation",
    "abstract": "Translated texts or utterances bear several hallmarks distinct from texts originating in the language. This phenomenon, known as translationese, is well-documented, and when found in training or test sets can affect model performance. Still, work to mitigate the effect of translationese in human translated text is understudied. We hypothesize that Abstract Meaning Representation (AMR), a semantic representation which abstracts away from the surface form, can be used as an interlingua to reduce the amount of translationese in translated texts. By parsing English translations into an AMR graph and then generating text from that AMR, we obtain texts that more closely resemble non-translationese by macro-level measures. We show that across four metrics, and qualitatively, using AMR as an interlingua enables the reduction of translationese and we compare our results to two additional approaches: one based on round-trip machine translation and one based on syntactically controlled generation. ",
    "url": "https://arxiv.org/abs/2304.11501",
    "authors": [
      "Shira Wein",
      "Nathan Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.11503",
    "title": "Improved Churn Causal Analysis Through Restrained High-Dimensional  Feature Space Effects in Financial Institutions",
    "abstract": "Customer churn describes terminating a relationship with a business or reducing customer engagement over a specific period. Customer acquisition cost can be five to six times that of customer retention, hence investing in customers with churn risk is wise. Causal analysis of the churn model can predict whether a customer will churn in the foreseeable future and identify effects and possible causes for churn. In general, this study presents a conceptual framework to discover the confounding features that correlate with independent variables and are causally related to those dependent variables that impact churn. We combine different algorithms including the SMOTE, ensemble ANN, and Bayesian networks to address churn prediction problems on a massive and high-dimensional finance data that is usually generated in financial institutions due to employing interval-based features used in Customer Relationship Management systems. The effects of the curse and blessing of dimensionality assessed by utilising the Recursive Feature Elimination method to overcome the high dimension feature space problem. Moreover, a causal discovery performed to find possible interpretation methods to describe cause probabilities that lead to customer churn. Evaluation metrics on validation data confirm the random forest and our ensemble ANN model, with %86 accuracy, outperformed other approaches. Causal analysis results confirm that some independent causal variables representing the level of super guarantee contribution, account growth, and account balance amount were identified as confounding variables that cause customer churn with a high degree of belief. This article provides a real-world customer churn analysis from current status inference to future directions in local superannuation funds. ",
    "url": "https://arxiv.org/abs/2304.11503",
    "authors": [
      "David Hason Rudd",
      "Huan Huo",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.11507",
    "title": "Machine learning framework for end-to-end implementation of Incident  duration prediction",
    "abstract": "Traffic congestion caused by non-recurring incidents such as vehicle crashes and debris is a key issue for Traffic Management Centers (TMCs). Clearing incidents in a timely manner is essential for improving safety and reducing delays and emissions for the traveling public. However, TMCs and other responders face a challenge in predicting the duration of incidents (until the roadway is clear), making decisions of what resources to deploy difficult. To address this problem, this research developed an analytical framework and end-to-end machine-learning solution for predicting incident duration based on information available as soon as an incident report is received. Quality predictions of incident duration can help TMCs and other responders take a proactive approach in deploying responder services such as tow trucks, maintenance crews or activating alternative routes. The predictions use a combination of classification and regression machine learning modules. The performance of the developed solution has been evaluated based on the Mean Absolute Error (MAE), or deviation from the actual incident duration as well as Area Under the Curve (AUC) and Mean Absolute Percentage Error (MAPE). The results showed that the framework significantly improved incident duration prediction compared to methods from previous research. ",
    "url": "https://arxiv.org/abs/2304.11507",
    "authors": [
      "Smrithi Ajit",
      "Varsha R Mouli",
      "Skylar Knickerbocker",
      "Jonathan S. Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11513",
    "title": "Detecting Socially Abnormal Highway Driving Behaviors via Recurrent  Graph Attention Networks",
    "abstract": "With the rapid development of Internet of Things technologies, the next generation traffic monitoring infrastructures are connected via the web, to aid traffic data collection and intelligent traffic management. One of the most important tasks in traffic is anomaly detection, since abnormal drivers can reduce traffic efficiency and cause safety issues. This work focuses on detecting abnormal driving behaviors from trajectories produced by highway video surveillance systems. Most of the current abnormal driving behavior detection methods focus on a limited category of abnormal behaviors that deal with a single vehicle without considering vehicular interactions. In this work, we consider the problem of detecting a variety of socially abnormal driving behaviors, i.e., behaviors that do not conform to the behavior of other nearby drivers. This task is complicated by the variety of vehicular interactions and the spatial-temporal varying nature of highway traffic. To solve this problem, we propose an autoencoder with a Recurrent Graph Attention Network that can capture the highway driving behaviors contextualized on the surrounding cars, and detect anomalies that deviate from learned patterns. Our model is scalable to large freeways with thousands of cars. Experiments on data generated from traffic simulation software show that our model is the only one that can spot the exact vehicle conducting socially abnormal behaviors, among the state-of-the-art anomaly detection models. We further show the performance on real world HighD traffic dataset, where our model detects vehicles that violate the local driving norms. ",
    "url": "https://arxiv.org/abs/2304.11513",
    "authors": [
      "Yue Hu",
      "Yuhang Zhang",
      "Yanbing Wang",
      "Daniel Work"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11514",
    "title": "Joint Beamforming and Phase Shift Design for Hybrid-IRS-and-UAV-aided  Directional Modulation Network",
    "abstract": "Recently, intelligent reflecting surface (IRS) and unmanned aerial vehicle (UAV) have been introduced into wireless communication systems to enhance the performance of air-ground transmission. To make a good balance between performance, cost, and power consumption, a hybrid-IRS-and-UAV-assisted directional modulation (DM) network is investigated in this paper, where the hybrid IRS consists of passive and active reflecting elements. To maximize the achievable rate, three optimization algorithms, called maximum signal-to-noise ratio (SNR)-fractional programming (FP) (Max-SNR-FP), maximum SNR-equal amplitude reflecting (EAR) (Max-SNR-EAR), and maximum SNR-majorization-minimization (MM) (Max-SNR-MM), are proposed to jointly design the beamforming vector and phase shift matrix (PSM) of hybrid IRS by alternately optimizing one and giving another. The Max-SNR-FP method employs the successive convex approximation and FP methods to derive the beamforming vector and hybrid IRS PSM. The Max-SNR-EAR method adopts the maximum signal-to-leakage-noise ratio method and the criteria of phase alignment and EAR to design them. In addition, the Max-SNR-MM method utilizes the MM criterion to derive the IRS PSM. Simulation results show that the rates harvested by the proposed three methods are slightly lower than those of active IRS with higher power consumption, which are 35 percent higher than those of no IRS and random phase IRS, while passive IRS achieves only about 17 percent rate gain over the latter. Moreover, compared to Max-SNR-FP, the proposed Max-SNR-EAR and Max-SNR-MM methods make an obvious complexity degradation at the price of a slight performance loss. ",
    "url": "https://arxiv.org/abs/2304.11514",
    "authors": [
      "Rongen Dong",
      "Hangjia He",
      "Feng Shu",
      "Qi Zhang",
      "Riqing Chen",
      "Shihao Yan",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.11517",
    "title": "LayerNAS: Neural Architecture Search in Polynomial Complexity",
    "abstract": "Neural Architecture Search (NAS) has become a popular method for discovering effective model architectures, especially for target hardware. As such, NAS methods that find optimal architectures under constraints are essential. In our paper, we propose LayerNAS to address the challenge of multi-objective NAS by transforming it into a combinatorial optimization problem, which effectively constrains the search complexity to be polynomial. For a model architecture with $L$ layers, we perform layerwise-search for each layer, selecting from a set of search options $\\mathbb{S}$. LayerNAS groups model candidates based on one objective, such as model size or latency, and searches for the optimal model based on another objective, thereby splitting the cost and reward elements of the search. This approach limits the search complexity to $ O(H \\cdot |\\mathbb{S}| \\cdot L) $, where $H$ is a constant set in LayerNAS. Our experiments show that LayerNAS is able to consistently discover superior models across a variety of search spaces in comparison to strong baselines, including search spaces derived from NATS-Bench, MobileNetV2 and MobileNetV3. ",
    "url": "https://arxiv.org/abs/2304.11517",
    "authors": [
      "Yicheng Fan",
      "Dana Alon",
      "Jingyue Shen",
      "Daiyi Peng",
      "Keshav Kumar",
      "Yun Long",
      "Xin Wang",
      "Fotis Iliopoulos",
      "Da-Cheng Juan",
      "Erik Vee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11519",
    "title": "Hierarchical Weight Averaging for Deep Neural Networks",
    "abstract": "Despite the simplicity, stochastic gradient descent (SGD)-like algorithms are successful in training deep neural networks (DNNs). Among various attempts to improve SGD, weight averaging (WA), which averages the weights of multiple models, has recently received much attention in the literature. Broadly, WA falls into two categories: 1) online WA, which averages the weights of multiple models trained in parallel, is designed for reducing the gradient communication overhead of parallel mini-batch SGD, and 2) offline WA, which averages the weights of one model at different checkpoints, is typically used to improve the generalization ability of DNNs. Though online and offline WA are similar in form, they are seldom associated with each other. Besides, these methods typically perform either offline parameter averaging or online parameter averaging, but not both. In this work, we firstly attempt to incorporate online and offline WA into a general training framework termed Hierarchical Weight Averaging (HWA). By leveraging both the online and offline averaging manners, HWA is able to achieve both faster convergence speed and superior generalization performance without any fancy learning rate adjustment. Besides, we also analyze the issues faced by existing WA methods, and how our HWA address them, empirically. Finally, extensive experiments verify that HWA outperforms the state-of-the-art methods significantly. ",
    "url": "https://arxiv.org/abs/2304.11519",
    "authors": [
      "Xiaozhe Gu",
      "Zixun Zhang",
      "Yuncheng Jiang",
      "Tao Luo",
      "Ruimao Zhang",
      "Shuguang Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11524",
    "title": "Personalized Federated Learning via Gradient Modulation for  Heterogeneous Text Summarization",
    "abstract": "Text summarization is essential for information aggregation and demands large amounts of training data. However, concerns about data privacy and security limit data collection and model training. To eliminate this concern, we propose a federated learning text summarization scheme, which allows users to share the global model in a cooperative learning manner without sharing raw data. Personalized federated learning (PFL) balances personalization and generalization in the process of optimizing the global model, to guide the training of local models. However, multiple local data have different distributions of semantics and context, which may cause the local model to learn deviated semantic and context information. In this paper, we propose FedSUMM, a dynamic gradient adapter to provide more appropriate local parameters for local model. Simultaneously, FedSUMM uses differential privacy to prevent parameter leakage during distributed training. Experimental evidence verifies FedSUMM can achieve faster model convergence on PFL algorithm for task-specific text summarization, and the method achieves superior performance for different optimization metrics for text summarization. ",
    "url": "https://arxiv.org/abs/2304.11524",
    "authors": [
      "Rongfeng Pan",
      "Jianzong Wang",
      "Lingwei Kong",
      "Zhangcheng Huang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11533",
    "title": "Bi-Level Attention Graph Neural Networks",
    "abstract": "Recent graph neural networks (GNNs) with the attention mechanism have historically been limited to small-scale homogeneous graphs (HoGs). However, GNNs handling heterogeneous graphs (HeGs), which contain several entity and relation types, all have shortcomings in handling attention. Most GNNs that learn graph attention for HeGs learn either node-level or relation-level attention, but not both, limiting their ability to predict both important entities and relations in the HeG. Even the best existing method that learns both levels of attention has the limitation of assuming graph relations are independent and that its learned attention disregards this dependency association. To effectively model both multi-relational and multi-entity large-scale HeGs, we present Bi-Level Attention Graph Neural Networks (BA-GNN), scalable neural networks (NNs) that use a novel bi-level graph attention mechanism. BA-GNN models both node-node and relation-relation interactions in a personalized way, by hierarchically attending to both types of information from local neighborhood contexts instead of the global graph context. Rigorous experiments on seven real-world HeGs show BA-GNN consistently outperforms all baselines, and demonstrate quality and transferability of its learned relation-level attention to improve performance of other GNNs. ",
    "url": "https://arxiv.org/abs/2304.11533",
    "authors": [
      "Roshni G. Iyer",
      "Wei Wang",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.11534",
    "title": "Graph Neural Networks for Text Classification: A Survey",
    "abstract": "Text Classification is the most essential and fundamental problem in Natural Language Processing. While numerous recent text classification models applied the sequential deep learning technique, graph neural network-based models can directly deal with complex structured text data and exploit global information. Many real text classification applications can be naturally cast into a graph, which captures words, documents, and corpus global features. In this survey, we bring the coverage of methods up to 2023, including corpus-level and document-level graph neural networks. We discuss each of these methods in detail, dealing with the graph construction mechanisms and the graph-based learning process. As well as the technological survey, we look at issues behind and future directions addressed in text classification using graph neural networks. We also cover datasets, evaluation metrics, and experiment design and present a summary of published performance on the publicly available benchmarks. Note that we present a comprehensive comparison between different techniques and identify the pros and cons of various evaluation metrics in this survey. ",
    "url": "https://arxiv.org/abs/2304.11534",
    "authors": [
      "Kunze Wang",
      "Yihao Ding",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.11546",
    "title": "CANet: Curved Guide Line Network with Adaptive Decoder for Lane  Detection",
    "abstract": "Lane detection is challenging due to the complicated on road scenarios and line deformation from different camera perspectives. Lots of solutions were proposed, but can not deal with corner lanes well. To address this problem, this paper proposes a new top-down deep learning lane detection approach, CANET. A lane instance is first responded by the heat-map on the U-shaped curved guide line at global semantic level, thus the corresponding features of each lane are aggregated at the response point. Then CANET obtains the heat-map response of the entire lane through conditional convolution, and finally decodes the point set to describe lanes via adaptive decoder. The experimental results show that CANET reaches SOTA in different metrics. Our code will be released soon. ",
    "url": "https://arxiv.org/abs/2304.11546",
    "authors": [
      "Zhongyu Yang",
      "Chen Shen",
      "Wei Shao",
      "Tengfei Xing",
      "Runbo Hu",
      "Pengfei Xu",
      "Hua Chai",
      "Ruini Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11547",
    "title": "SAR: Self-Supervised Anti-Distortion Representation for End-To-End  Speech Model",
    "abstract": "In recent Text-to-Speech (TTS) systems, a neural vocoder often generates speech samples by solely conditioning on acoustic features predicted from an acoustic model. However, there are always distortions existing in the predicted acoustic features, compared to those of the groundtruth, especially in the common case of poor acoustic modeling due to low-quality training data. To overcome such limits, we propose a Self-supervised learning framework to learn an Anti-distortion acoustic Representation (SAR) to replace human-crafted acoustic features by introducing distortion prior to an auto-encoder pre-training process. The learned acoustic representation from the proposed framework is proved anti-distortion compared to the most commonly used mel-spectrogram through both objective and subjective evaluation. ",
    "url": "https://arxiv.org/abs/2304.11547",
    "authors": [
      "Jianzong Wang",
      "Xulong Zhang",
      "Haobin Tang",
      "Aolan Sun",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.11561",
    "title": "Understanding people's needs in viewing diverse social opinions about  controversial topics",
    "abstract": "Social media (i.e., Reddit) users are overloaded with people's opinions when viewing discourses about divisive topics. Traditional user interfaces in such media present those opinions in a linear structure, which can limit users in viewing diverse social opinions at scale. Prior work has recognized this limitation, that the linear structure can reinforce biases, where a certain point of view becomes widespread simply because many viewers seem to believe it. This limitation can make it difficult for users to have a truly conversational mode of mediated discussion. Thus, when designing a user interface for viewing people's opinions, we should consider ways to mitigate selective exposure to information and polarization of opinions. We conducted a needs-finding study with 11 Reddit users, who follow climate change threads and make posts and comments regularly. In the study, we aimed to understand key limitations in people viewing online controversial discourses and to extract design implications to address these problems. Our findings discuss potential future directions to address these problems. ",
    "url": "https://arxiv.org/abs/2304.11561",
    "authors": [
      "Hayeong Song",
      "Zhengyang Qi",
      "John Stasko",
      "Diyi Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.11574",
    "title": "Meta-multigraph Search: Rethinking Meta-structure on Heterogeneous  Information Networks",
    "abstract": "Meta-structures are widely used to define which subset of neighbors to aggregate information in heterogeneous information networks (HINs). In this work, we investigate existing meta-structures, including meta-path and meta-graph, and observe that they are initially designed manually with fixed patterns and hence are insufficient to encode various rich semantic information on diverse HINs. Through reflection on their limitation, we define a new concept called meta-multigraph as a more expressive and flexible generalization of meta-graph, and propose a stable differentiable search method to automatically optimize the meta-multigraph for specific HINs and tasks. As the flexibility of meta-multigraphs may propagate redundant messages, we further introduce a complex-to-concise (C2C) meta-multigraph that propagates messages from complex to concise along the depth of meta-multigraph. Moreover, we observe that the differentiable search typically suffers from unstable search and a significant gap between the meta-structures in search and evaluation. To this end, we propose a progressive search algorithm by implicitly narrowing the search space to improve search stability and reduce inconsistency. Extensive experiments are conducted on six medium-scale benchmark datasets and one large-scale benchmark dataset over two representative tasks, i.e., node classification and recommendation. Empirical results demonstrate that our search methods can automatically find expressive meta-multigraphs and C2C meta-multigraphs, enabling our model to outperform state-of-the-art heterogeneous graph neural networks. ",
    "url": "https://arxiv.org/abs/2304.11574",
    "authors": [
      "Chao Li",
      "Hao Xu",
      "Kun He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11579",
    "title": "StyLess: Boosting the Transferability of Adversarial Examples",
    "abstract": "Adversarial attacks can mislead deep neural networks (DNNs) by adding imperceptible perturbations to benign examples. The attack transferability enables adversarial examples to attack black-box DNNs with unknown architectures or parameters, which poses threats to many real-world applications. We find that existing transferable attacks do not distinguish between style and content features during optimization, limiting their attack transferability. To improve attack transferability, we propose a novel attack method called style-less perturbation (StyLess). Specifically, instead of using a vanilla network as the surrogate model, we advocate using stylized networks, which encode different style features by perturbing an adaptive instance normalization. Our method can prevent adversarial examples from using non-robust style features and help generate transferable perturbations. Comprehensive experiments show that our method can significantly improve the transferability of adversarial examples. Furthermore, our approach is generic and can outperform state-of-the-art transferable attacks when combined with other attack techniques. ",
    "url": "https://arxiv.org/abs/2304.11579",
    "authors": [
      "Kaisheng Liang",
      "Bin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11580",
    "title": "A Framework for Benchmarking Real-Time Embedded Object Detection",
    "abstract": "Object detection is one of the key tasks in many applications of computer vision. Deep Neural Networks (DNNs) are undoubtedly a well-suited approach for object detection. However, such DNNs need highly adapted hardware together with hardware-specific optimization to guarantee high efficiency during inference. This is especially the case when aiming for efficient object detection in video streaming applications on limited hardware such as edge devices. Comparing vendor-specific hardware and related optimization software pipelines in a fair experimental setup is a challenge. In this paper, we propose a framework that uses a host computer with a host software application together with a light-weight interface based on the Message Queuing Telemetry Transport (MQTT) protocol. Various different target devices with target apps can be connected via MQTT with this host computer. With well-defined and standardized MQTT messages, object detection results can be reported to the host computer, where the results are evaluated without harming or influencing the processing on the device. With this quite generic framework, we can measure the object detection performance, the runtime, and the energy efficiency at the same time. The effectiveness of this framework is demonstrated in multiple experiments that offer deep insights into the optimization of DNNs. ",
    "url": "https://arxiv.org/abs/2304.11580",
    "authors": [
      "Michael Schlosser",
      "Daniel K\u00f6nig",
      "Michael Teutsch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11584",
    "title": "OSP2B: One-Stage Point-to-Box Network for 3D Siamese Tracking",
    "abstract": "Two-stage point-to-box network acts as a critical role in the recent popular 3D Siamese tracking paradigm, which first generates proposals and then predicts corresponding proposal-wise scores. However, such a network suffers from tedious hyper-parameter tuning and task misalignment, limiting the tracking performance. Towards these concerns, we propose a simple yet effective one-stage point-to-box network for point cloud-based 3D single object tracking. It synchronizes 3D proposal generation and center-ness score prediction by a parallel predictor without tedious hyper-parameters. To guide a task-aligned score ranking of proposals, a center-aware focal loss is proposed to supervise the training of the center-ness branch, which enhances the network's discriminative ability to distinguish proposals of different quality. Besides, we design a binary target classifier to identify target-relevant points. By integrating the derived classification scores with the center-ness scores, the resulting network can effectively suppress interference proposals and further mitigate task misalignment. Finally, we present a novel one-stage Siamese tracker OSP2B equipped with the designed network. Extensive experiments on challenging benchmarks including KITTI and Waymo SOT Dataset show that our OSP2B achieves leading performance with a considerable real-time speed. ",
    "url": "https://arxiv.org/abs/2304.11584",
    "authors": [
      "Jiahao Nie",
      "Zhiwei He",
      "Yuxiang Yang",
      "Zhengyi Bao",
      "Mingyu Gao",
      "Jing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11592",
    "title": "Broken Rail Detection With Texture Image Processing Using  Two-Dimensional Gray Level Co-occurrence Matrix",
    "abstract": "Application of electronic railway systems as well as the implication of Automatic Train Control (ATC) System has increased the safety of rail transportation. However, one of the most important causes of accidents on the railway is rail damage and breakage. In this paper, we have proposed a method that the rail region is first recognized from the observation area, then by investigating the image texture processing data, the types of rail defects including cracks, wear, peeling, disintegration, and breakage are detected. In order to reduce the computational cost, the image is changed from the RGB color spectrum to the gray spectrum. Image texture processing data is obtained by the two-dimensional Gray Levels Co-occurrence Matrix (GLCM) at different angles; this data demonstrates second-order features of the images. Large data of features has a negative effect on the overall accuracy of the classifiers. To tackle this issue and acquire faster response, Principal Component Analysis (PCA) algorithm is used, before entering the band into the classifier. Then the features extracted from the images are compared by three different classifiers including Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbor (KNN) classification. The results obtained from this method indicate that the Random Forest classifier has better performance (accuracy 97%, precision 96%, and recall 96%) than other classifiers. ",
    "url": "https://arxiv.org/abs/2304.11592",
    "authors": [
      "Mohsen Ebrahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.11597",
    "title": "Learning Partial Correlation based Deep Visual Representation for Image  Classification",
    "abstract": "Visual representation based on covariance matrix has demonstrates its efficacy for image classification by characterising the pairwise correlation of different channels in convolutional feature maps. However, pairwise correlation will become misleading once there is another channel correlating with both channels of interest, resulting in the ``confounding'' effect. For this case, ``partial correlation'' which removes the confounding effect shall be estimated instead. Nevertheless, reliably estimating partial correlation requires to solve a symmetric positive definite matrix optimisation, known as sparse inverse covariance estimation (SICE). How to incorporate this process into CNN remains an open issue. In this work, we formulate SICE as a novel structured layer of CNN. To ensure end-to-end trainability, we develop an iterative method to solve the above matrix optimisation during forward and backward propagation steps. Our work obtains a partial correlation based deep visual representation and mitigates the small sample problem often encountered by covariance matrix estimation in CNN. Computationally, our model can be effectively trained with GPU and works well with a large number of channels of advanced CNNs. Experiments show the efficacy and superior classification performance of our deep visual representation compared to covariance matrix based counterparts. ",
    "url": "https://arxiv.org/abs/2304.11597",
    "authors": [
      "Saimunur Rahman",
      "Piotr Koniusz",
      "Lei Wang",
      "Luping Zhou",
      "Peyman Moghadam or Changming Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11598",
    "title": "Transductive Few-shot Learning with Prototype-based Label Propagation by  Iterative Graph Refinement",
    "abstract": "Few-shot learning (FSL) is popular due to its ability to adapt to novel classes. Compared with inductive few-shot learning, transductive models typically perform better as they leverage all samples of the query set. The two existing classes of methods, prototype-based and graph-based, have the disadvantages of inaccurate prototype estimation and sub-optimal graph construction with kernel functions, respectively. In this paper, we propose a novel prototype-based label propagation to solve these issues. Specifically, our graph construction is based on the relation between prototypes and samples rather than between samples. As prototypes are being updated, the graph changes. We also estimate the label of each prototype instead of considering a prototype be the class centre. On mini-ImageNet, tiered-ImageNet, CIFAR-FS and CUB datasets, we show the proposed method outperforms other state-of-the-art methods in transductive FSL and semi-supervised FSL when some unlabeled data accompanies the novel few-shot task. ",
    "url": "https://arxiv.org/abs/2304.11598",
    "authors": [
      "Hao Zhu",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11600",
    "title": "Safe Control Synthesis Using Environmentally Robust Control Barrier  Functions",
    "abstract": "In this paper, we study a safe control design for dynamical systems in the presence of uncertainty in a dynamical environment. The worst-case error approach is considered to formulate robust Control Barrier Functions (CBFs) in an optimization-based control synthesis framework. It is first shown that environmentally robust CBF formulations result in second-order cone programs (SOCPs). Then, a novel scheme is presented to formulate robust CBFs which takes the nominally safe control as its desired control input in optimization-based control design and then tries to minimally modify it whenever the robust CBF constraint is violated. This proposed scheme leads to quadratic programs (QPs) which can be easily solved. Finally, the effectiveness of the proposed approach is demonstrated on an adaptive cruise control example. ",
    "url": "https://arxiv.org/abs/2304.11600",
    "authors": [
      "Vahid Hamdipoor",
      "Nader Meskin",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11611",
    "title": "Robust Short-term Operation of AC Power Network with Injection  Uncertainties",
    "abstract": "With uncertain injections from Renewable Energy Sources (RESs) and loads, deterministic AC Optimal Power Flow (OPF) often fails to provide optimal setpoints of conventional generators. A computationally time-efficient, economical, and robust solution is essential for ACOPF with short-term injection uncertainties. Usually, applying Robust Optimization (RO) for conventional non-linear ACOPF results in computationally intractable Robust Counterpart (RC), which is undesirable as ACOPF is an operational problem. Hence, this paper proposes a single-stage non-integer non-recursive RC of ACOPF, using a dual transformation, for short-term injection uncertainties. The proposed RC is convex, tractable, and provides base-point active power generations and terminal voltage magnitudes (setpoints) of conventional generators that satisfy all constraints for all realizations of defined injection uncertainties. The non-linear impact of uncertainties on other variables is inherently modeled without using any affine policy. The proposed approach also includes the budget of uncertainty constraints for low conservatism of the obtained setpoints. Monte-Carlo Simulation (MCS) based participation factored AC power flows validate the robustness of the obtained setpoints on NESTA and case9241pegase systems for different injection uncertainties. Comparison with previous approaches indicates the efficacy of the proposed approach in terms of low operational cost and computation time. ",
    "url": "https://arxiv.org/abs/2304.11611",
    "authors": [
      "Anamika Tiwari",
      "Abheejeet Mohapatra",
      "Soumya Ranjan Sahoo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11618",
    "title": "Modality-Aware Negative Sampling for Multi-modal Knowledge Graph  Embedding",
    "abstract": "Negative sampling (NS) is widely used in knowledge graph embedding (KGE), which aims to generate negative triples to make a positive-negative contrast during training. However, existing NS methods are unsuitable when multi-modal information is considered in KGE models. They are also inefficient due to their complex design. In this paper, we propose Modality-Aware Negative Sampling (MANS) for multi-modal knowledge graph embedding (MMKGE) to address the mentioned problems. MANS could align structural and visual embeddings for entities in KGs and learn meaningful embeddings to perform better in multi-modal KGE while keeping lightweight and efficient. Empirical results on two benchmarks demonstrate that MANS outperforms existing NS methods. Meanwhile, we make further explorations about MANS to confirm its effectiveness. ",
    "url": "https://arxiv.org/abs/2304.11618",
    "authors": [
      "Yichi Zhang",
      "Mingyang Chen",
      "Wen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11623",
    "title": "Cache-Aided Communications in MISO Networks with Dynamic User Behavior:  A Universal Solution",
    "abstract": "A practical barrier to the implementation of cache-aided networks is dynamic and unpredictable user behavior. In dynamic setups, users can freely depart and enter the network at any moment. The shared caching concept has the potential to handle this issue by assigning $K$ users to $P$ caching profiles, where all $\\eta_{p}$ users assigned to profile $p$ store the same cache content defined by that profile. The existing schemes, however, cannot be applied in general and are not dynamic in the true sense as they put constraints on the transmitter-side spatial multiplexing gain $\\alpha$. Specifically, they work only if $\\alpha \\leq \\min_{p} \\eta_{p}$ or $\\alpha \\geq \\hat{\\eta}$, where in the latter case, $\\gamma$ is the normalized cache size of each user, $\\hat{\\eta}$ is an arbitrary parameter satisfying $1 \\leq \\hat{\\eta} \\leq \\max_{p} \\eta_{p}$, and the extra condition of $\\alpha \\geq K\\gamma$ should also be met. In this work, we propose a universal caching scheme based on the same shared-cache model that can be applied to any dynamic setup, extending the working region of existing schemes to networks with $\\min_{p} \\eta_{p} \\leq \\alpha \\leq \\hat{\\eta}$ and removing any other constraints of existing schemes. We also derive the closed-form expressions for the achievable degrees-of-freedom (DoF) of the proposed scheme and show that it achieves the optimal DoF for uniform user distributions. Notably, it is the first scheme to achieve the optimal DoF of $K\\gamma+\\alpha$ for networks with uniform user distribution, $\\alpha > \\hat{\\eta}$, and non-integer $\\frac{\\alpha}{\\hat{\\eta}}$, without imposing any other constraints. Finally, we use numerical simulations to assess how non-uniform user distribution impacts the DoF performance and illustrate that the proposed scheme provides a noticeable improvement over unicasting for uneven distributions. ",
    "url": "https://arxiv.org/abs/2304.11623",
    "authors": [
      "Milad Abolpour",
      "MohammadJavad Salehi",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.11624",
    "title": "Consolidation of Ground Truth Sets for Weakness Detection in Smart  Contracts",
    "abstract": "Smart contracts are small programs on the blockchain that often handle valuable assets. Vulnerabilities in smart contracts can be costly, as time has shown over and over again. Countermeasures are high in demand and include best practice recommendations as well as tools supporting development, program verification, and post-deployment analysis. Many tools focus on detecting the absence or presence of a subset of the known vulnerabilities, delivering results of varying quality. Most comparative tool evaluations resort to selecting a handful of tools and testing them against each other. In the best case, the evaluation is based on a smallish ground truth. For Ethereum, there are commendable efforts by several author groups to manually classify contracts. However, a comprehensive ground truth is still lacking. In this work, we construct a ground truth based on publicly available benchmark sets for Ethereum smart contracts with manually checked ground truth data. We develop a method to unify these sets. Additionally, we devise strategies for matching entries that pertain to the same contract, such that we can determine overlaps and disagreements between the sets and consolidate the disagreements. Finally, we assess the quality of the included ground truth sets. Our work reduces inconsistencies, redundancies, and incompleteness while increasing the number of data points and heterogeneity. ",
    "url": "https://arxiv.org/abs/2304.11624",
    "authors": [
      "Monika di Angelo",
      "Gernot Salzer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.11625",
    "title": "Meaningful Causal Aggregation and Paradoxical Confounding",
    "abstract": "In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation. ",
    "url": "https://arxiv.org/abs/2304.11625",
    "authors": [
      "Yuchen Zhu",
      "Kailash Budhathoki",
      "Jonas Kuebler",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.11636",
    "title": "U Owns the Code That Changes and How Marginal Owners Resolve Issues  Slower in Low-Quality Source Code",
    "abstract": "[Context] Accurate time estimation is a critical aspect of predictable software engineering. Previous work shows that low source code quality increases the uncertainty in issue resolution times. [Objective] Our goal is to evaluate how developers' project experience and file ownership are related to issue resolution times. [Method] We mine 40 proprietary software repositories and conduct an observational study. Using CodeScene, we measure source code quality and active development time connected to Jira issues. [Results] Most source code changes are made by either a marginal or dominant code owner. Also, most changes to low-quality source code are made by developers with low levels of ownership. In low-quality source code, marginal owners need 45\\% more time for small changes, and 93\\% more time for large changes. [Conclusions] Collective code ownership is a popular target, but industry practice results in many dominant and marginal owners. Marginal owners are particularly hampered when working with low-quality source code, which leads to productivity losses. In codebases plagued by technical debt, newly onboarded developers will require more time to complete tasks. ",
    "url": "https://arxiv.org/abs/2304.11636",
    "authors": [
      "Markus Borg",
      "Adam Tornhill",
      "Enys Mones"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.11643",
    "title": "Privacy Computing Meets Metaverse: Necessity, Taxonomy and Challenges",
    "abstract": "Metaverse, the core of the next-generation Internet, is a computer-generated holographic digital environment that simultaneously combines spatio-temporal, immersive, real-time, sustainable, interoperable, and data-sensitive characteristics. It cleverly blends the virtual and real worlds, allowing users to create, communicate, and transact in virtual form. With the rapid development of emerging technologies including augmented reality, virtual reality and blockchain, the metaverse system is becoming more and more sophisticated and widely used in various fields such as social, tourism, industry and economy. However, the high level of interaction with the real world also means a huge risk of privacy leakage both for individuals and enterprises, which has hindered the wide deployment of metaverse. Then, it is inevitable to apply privacy computing techniques in the framework of metaverse, which is a current research hotspot. In this paper, we conduct a comprehensive research of the necessity, taxonomy and challenges when privacy computing meets metaverse. Specifically, we first introduce the underlying technologies and various applications of metaverse, on which we analyze the challenges of data usage in metaverse, especially data privacy. Next, we review and summarize state-of-the-art solutions based on federated learning, differential privacy, homomorphic encryption, and zero-knowledge proofs for different privacy problems in metaverse. Finally, we show the current security and privacy challenges in the development of metaverse and provide open directions for building a well-established privacy-preserving metaverse system. ",
    "url": "https://arxiv.org/abs/2304.11643",
    "authors": [
      "Chuan Chen",
      "Yuecheng Li",
      "Zhenpeng Wu",
      "Chengyuan Mai",
      "Youming Liu",
      "Yanming Hu",
      "Zibin Zheng",
      "Jiawen Kang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.11654",
    "title": "Stochastic Cell Transmission Models of Traffic Networks",
    "abstract": "We introduce a rigorous framework for stochastic cell transmission models for general traffic networks. The performance of traffic systems is evaluated based on preference functionals and acceptable designs. The numerical implementation combines simulation, Gaussian process regression, and a stochastic exploration procedure. The approach is illustrated in two case studies. ",
    "url": "https://arxiv.org/abs/2304.11654",
    "authors": [
      "Zachary Feinstein",
      "Marcel Kleiber",
      "Stefan Weber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.11658",
    "title": "Capturing Fine-grained Semantics in Contrastive Graph Representation  Learning",
    "abstract": "Graph contrastive learning defines a contrastive task to pull similar instances close and push dissimilar instances away. It learns discriminative node embeddings without supervised labels, which has aroused increasing attention in the past few years. Nevertheless, existing methods of graph contrastive learning ignore the differences between diverse semantics existed in graphs, which learn coarse-grained node embeddings and lead to sub-optimal performances on downstream tasks. To bridge this gap, we propose a novel Fine-grained Semantics enhanced Graph Contrastive Learning (FSGCL) in this paper. Concretely, FSGCL first introduces a motif-based graph construction, which employs graph motifs to extract diverse semantics existed in graphs from the perspective of input data. Then, the semantic-level contrastive task is explored to further enhance the utilization of fine-grained semantics from the perspective of model training. Experiments on five real-world datasets demonstrate the superiority of our proposed FSGCL over state-of-the-art methods. To make the results reproducible, we will make our codes public on GitHub after this paper is accepted. ",
    "url": "https://arxiv.org/abs/2304.11658",
    "authors": [
      "Lin Shu",
      "Chuan Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11664",
    "title": "IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering  in Islamic Text Resources",
    "abstract": "Nowadays, one of the main challenges for Question Answering Systems is to answer complex questions using various sources of information. Multi-hop questions are a type of complex questions that require multi-step reasoning to answer. In this article, the IslamicPCQA dataset is introduced. This is the first Persian dataset for answering complex questions based on non-structured information sources and consists of 12,282 question-answer pairs extracted from 9 Islamic encyclopedias. This dataset has been created inspired by the HotpotQA English dataset approach, which was customized to suit the complexities of the Persian language. Answering questions in this dataset requires more than one paragraph and reasoning. The questions are not limited to any prior knowledge base or ontology, and to provide robust reasoning ability, the dataset also includes supporting facts and key sentences. The prepared dataset covers a wide range of Islamic topics and aims to facilitate answering complex Persian questions within this subject matter ",
    "url": "https://arxiv.org/abs/2304.11664",
    "authors": [
      "Arash Ghafouri",
      "Hasan Naderi",
      "Mohammad Aghajani asl",
      "Mahdi Firouzmandi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11669",
    "title": "Device management and network connectivity as missing elements in TinyML  landscape",
    "abstract": "Deployment of solutions based on TinyML requires meeting several challenges. These include hardware heterogeneity, microprocessor (MCU) architectures, and resource availability constraints. Another challenge is the variety of operating systems for MCU, limited memory management implementations and limited software interoperability between devices. A number of these challenges are solved by dedicated programming libraries and the ability to compile code for specific devices. Nevertheless, the challenge discussed in the paper is the issue of network connectivity for such solutions. We point out that more emphasis should be placed on standard protocols, interoperability of solutions and security. Finally, the paper discusses how the LwM2M protocol can solve the identified challenges related to network connectivity and interoperability. ",
    "url": "https://arxiv.org/abs/2304.11669",
    "authors": [
      "Tomasz Szydlo",
      "Marcin Nagy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11670",
    "title": "Evading DeepFake Detectors via Adversarial Statistical Consistency",
    "abstract": "In recent years, as various realistic face forgery techniques known as DeepFake improves by leaps and bounds,more and more DeepFake detection techniques have been proposed. These methods typically rely on detecting statistical differences between natural (i.e., real) and DeepFakegenerated images in both spatial and frequency domains. In this work, we propose to explicitly minimize the statistical differences to evade state-of-the-art DeepFake detectors. To this end, we propose a statistical consistency attack (StatAttack) against DeepFake detectors, which contains two main parts. First, we select several statistical-sensitive natural degradations (i.e., exposure, blur, and noise) and add them to the fake images in an adversarial way. Second, we find that the statistical differences between natural and DeepFake images are positively associated with the distribution shifting between the two kinds of images, and we propose to use a distribution-aware loss to guide the optimization of different degradations. As a result, the feature distributions of generated adversarial examples is close to the natural images.Furthermore, we extend the StatAttack to a more powerful version, MStatAttack, where we extend the single-layer degradation to multi-layer degradations sequentially and use the loss to tune the combination weights jointly. Comprehensive experimental results on four spatial-based detectors and two frequency-based detectors with four datasets demonstrate the effectiveness of our proposed attack method in both white-box and black-box settings. ",
    "url": "https://arxiv.org/abs/2304.11670",
    "authors": [
      "Yang Hou",
      "Qing Guo",
      "Yihao Huang",
      "Xiaofei Xie",
      "Lei Ma",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.11674",
    "title": "A Lightweight Recurrent Learning Network for Sustainable Compressed  Sensing",
    "abstract": "Recently, deep learning-based compressed sensing (CS) has achieved great success in reducing the sampling and computational cost of sensing systems and improving the reconstruction quality. These approaches, however, largely overlook the issue of the computational cost; they rely on complex structures and task-specific operator designs, resulting in extensive storage and high energy consumption in CS imaging systems. In this paper, we propose a lightweight but effective deep neural network based on recurrent learning to achieve a sustainable CS system; it requires a smaller number of parameters but obtains high-quality reconstructions. Specifically, our proposed network consists of an initial reconstruction sub-network and a residual reconstruction sub-network. While the initial reconstruction sub-network has a hierarchical structure to progressively recover the image, reducing the number of parameters, the residual reconstruction sub-network facilitates recurrent residual feature extraction via recurrent learning to perform both feature fusion and deep reconstructions across different scales. In addition, we also demonstrate that, after the initial reconstruction, feature maps with reduced sizes are sufficient to recover the residual information, and thus we achieved a significant reduction in the amount of memory required. Extensive experiments illustrate that our proposed model can achieve a better reconstruction quality than existing state-of-the-art CS algorithms, and it also has a smaller number of network parameters than these algorithms. Our source codes are available at: https://github.com/C66YU/CSRN. ",
    "url": "https://arxiv.org/abs/2304.11674",
    "authors": [
      "Yu Zhou",
      "Yu Chen",
      "Xiao Zhang",
      "Pan Lai",
      "Lei Huang",
      "Jianmin Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.11684",
    "title": "Moving-horizon False Data Injection Attack Design against Cyber-Physical  Systems",
    "abstract": "Systematic attack design is essential to understanding the vulnerabilities of cyber-physical systems (CPSs), to better design for resiliency. In particular, false data injection attacks (FDIAs) are well-known and have been shown to be capable of bypassing bad data detection (BDD) while causing targeted biases in resulting state estimates. However, their effectiveness against moving horizon estimators (MHE) is not well understood. In fact, this paper shows that conventional FDIAs are generally ineffective against MHE. One of the main reasons is that the moving window renders the static FDIA recursively infeasible. This paper proposes a new attack methodology, moving-horizon FDIA (MH-FDIA), by considering both the performance of historical attacks and the current system's status. Theoretical guarantees for successful attack generation and recursive feasibility are given. Numerical simulations on the IEEE-14 bus system further validate the theoretical claims and show that the proposed MH-FDIA outperforms state-of-the-art counterparts in both stealthiness and effectiveness. In addition, \\textcolor{blue}{an experiment on} a path-tracking control system of an autonomous vehicle shows the feasibility of the MH-FDIA in real-world nonlinear systems. ",
    "url": "https://arxiv.org/abs/2304.11684",
    "authors": [
      "Yu Zheng",
      "Sridhar Babu Mudhangulla",
      "Olugbenga Moses Anubi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.11694",
    "title": "Vehicle State Estimation and Prediction",
    "abstract": "This paper presents methods for vehicle state estimation and prediction for autonomous driving. A roundabout is chosen to apply the methods and illustrate the results as autonomous vehicles have difficulty in handling roundabouts. State estimation based on the unscented Kalman filter (UKF) is introduced first with application to a roundabout. The microscopic traffic simulator SUMO is used to generate realistic traffic in the roundabout for the simulation experiments. Change point detection based driving behavior prediction using a multi policy approach is then introduced and evaluated for the round intersection example. Finally, these methods are combined for vehicle trajectory estimation based on UKF and policy prediction and demonstrated using the roundabout example. ",
    "url": "https://arxiv.org/abs/2304.11694",
    "authors": [
      "Xinchen Li",
      "Levent Guvenc",
      "Bilin Aksun-Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.11697",
    "title": "Informative Data Selection with Uncertainty for Multi-modal Object  Detection",
    "abstract": "Noise has always been nonnegligible trouble in object detection by creating confusion in model reasoning, thereby reducing the informativeness of the data. It can lead to inaccurate recognition due to the shift in the observed pattern, that requires a robust generalization of the models. To implement a general vision model, we need to develop deep learning models that can adaptively select valid information from multi-modal data. This is mainly based on two reasons. Multi-modal learning can break through the inherent defects of single-modal data, and adaptive information selection can reduce chaos in multi-modal data. To tackle this problem, we propose a universal uncertainty-aware multi-modal fusion model. It adopts a multi-pipeline loosely coupled architecture to combine the features and results from point clouds and images. To quantify the correlation in multi-modal information, we model the uncertainty, as the inverse of data information, in different modalities and embed it in the bounding box generation. In this way, our model reduces the randomness in fusion and generates reliable output. Moreover, we conducted a completed investigation on the KITTI 2D object detection dataset and its derived dirty data. Our fusion model is proven to resist severe noise interference like Gaussian, motion blur, and frost, with only slight degradation. The experiment results demonstrate the benefits of our adaptive fusion. Our analysis on the robustness of multi-modal fusion will provide further insights for future research. ",
    "url": "https://arxiv.org/abs/2304.11697",
    "authors": [
      "Xinyu Zhang",
      "Zhiwei Li",
      "Zhenhong Zou",
      "Xin Gao",
      "Yijin Xiong",
      "Dafeng Jin",
      "Jun Li",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.11701",
    "title": "HKNAS: Classification of Hyperspectral Imagery Based on Hyper Kernel  Neural Architecture Search",
    "abstract": "Recent neural architecture search (NAS) based approaches have made great progress in hyperspectral image (HSI) classification tasks. However, the architectures are usually optimized independently of the network weights, increasing searching time and restricting model performances. To tackle these issues, in this paper, different from previous methods that extra define structural parameters, we propose to directly generate structural parameters by utilizing the specifically designed hyper kernels, ingeniously converting the original complex dual optimization problem into easily implemented one-tier optimizations, and greatly shrinking searching costs. Then, we develop a hierarchical multi-module search space whose candidate operations only contain convolutions, and these operations can be integrated into unified kernels. Using the above searching strategy and searching space, we obtain three kinds of networks to separately conduct pixel-level or image-level classifications with 1-D or 3-D convolutions. In addition, by combining the proposed hyper kernel searching scheme with the 3-D convolution decomposition mechanism, we obtain diverse architectures to simulate 3-D convolutions, greatly improving network flexibilities. A series of quantitative and qualitative experiments on six public datasets demonstrate that the proposed methods achieve state-of-the-art results compared with other advanced NAS-based HSI classification approaches. ",
    "url": "https://arxiv.org/abs/2304.11701",
    "authors": [
      "Di Wang",
      "Bo Du",
      "Liangpei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11702",
    "title": "Controlled physics-informed data generation for deep learning-based  remaining useful life prediction under unseen operation conditions",
    "abstract": "Limited availability of representative time-to-failure (TTF) trajectories either limits the performance of deep learning (DL)-based approaches on remaining useful life (RUL) prediction in practice or even precludes their application. Generating synthetic data that is physically plausible is a promising way to tackle this challenge. In this study, a novel hybrid framework combining the controlled physics-informed data generation approach with a deep learning-based prediction model for prognostics is proposed. In the proposed framework, a new controlled physics-informed generative adversarial network (CPI-GAN) is developed to generate synthetic degradation trajectories that are physically interpretable and diverse. Five basic physics constraints are proposed as the controllable settings in the generator. A physics-informed loss function with penalty is designed as the regularization term, which ensures that the changing trend of system health state recorded in the synthetic data is consistent with the underlying physical laws. Then, the generated synthetic data is used as input of the DL-based prediction model to obtain the RUL estimations. The proposed framework is evaluated based on new Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS), a turbofan engine prognostics dataset where a limited avail-ability of TTF trajectories is assumed. The experimental results demonstrate that the proposed framework is able to generate synthetic TTF trajectories that are consistent with underlying degradation trends. The generated trajectories enable to significantly improve the accuracy of RUL predictions. ",
    "url": "https://arxiv.org/abs/2304.11702",
    "authors": [
      "Jiawei Xiong",
      "Olga Fink",
      "Jian Zhou",
      "Yizhong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11706",
    "title": "Deep Convolutional Tables: Deep Learning without Convolutions",
    "abstract": "We propose a novel formulation of deep networks that do not use dot-product neurons and rely on a hierarchy of voting tables instead, denoted as Convolutional Tables (CT), to enable accelerated CPU-based inference. Convolutional layers are the most time-consuming bottleneck in contemporary deep learning techniques, severely limiting their use in Internet of Things and CPU-based devices. The proposed CT performs a fern operation at each image location: it encodes the location environment into a binary index and uses the index to retrieve the desired local output from a table. The results of multiple tables are combined to derive the final output. The computational complexity of a CT transformation is independent of the patch (filter) size and grows gracefully with the number of channels, outperforming comparable convolutional layers. It is shown to have a better capacity:compute ratio than dot-product neurons, and that deep CT networks exhibit a universal approximation property similar to neural networks. As the transformation involves computing discrete indices, we derive a soft relaxation and gradient-based approach for training the CT hierarchy. Deep CT networks have been experimentally shown to have accuracy comparable to that of CNNs of similar architectures. In the low compute regime, they enable an error:speed trade-off superior to alternative efficient CNN architectures. ",
    "url": "https://arxiv.org/abs/2304.11706",
    "authors": [
      "Shay Dekel",
      "Yosi Keller",
      "Aharon Bar-Hillel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11717",
    "title": "Automatized marine vessel monitoring from sentinel-1 data using  convolution neural network",
    "abstract": "The advancement of multi-channel synthetic aperture radar (SAR) system is considered as an upgraded technology for surveillance activities. SAR sensors onboard provide data for coastal ocean surveillance and a view of the oceanic surface features. Vessel monitoring has earlier been performed using Constant False Alarm Rate (CFAR) algorithm which is not a smart technique as it lacks decision-making capabilities, therefore we introduce wavelet transformation-based Convolution Neural Network approach to recognize objects from SAR images during the heavy naval traffic, which corresponds to the numerous object detection. The utilized information comprises Sentinel-1 SAR-C dual-polarization data acquisitions over the western coastal zones of India and with help of the proposed technique we have obtained 95.46% detection accuracy. Utilizing this model can automatize the monitoring of naval objects and recognition of foreign maritime intruders. ",
    "url": "https://arxiv.org/abs/2304.11717",
    "authors": [
      "Surya Prakash Tiwari",
      "Sudhir Kumar Chaturvedi",
      "Subhrangshu Adhikary",
      "Saikat Banerjee",
      "Sourav Basu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.11718",
    "title": "No Free Lunch in Self Supervised Representation Learning",
    "abstract": "Self-supervised representation learning in computer vision relies heavily on hand-crafted image transformations to learn meaningful and invariant features. However few extensive explorations of the impact of transformation design have been conducted in the literature. In particular, the dependence of downstream performances to transformation design has been established, but not studied in depth. In this work, we explore this relationship, its impact on a domain other than natural images, and show that designing the transformations can be viewed as a form of supervision. First, we demonstrate that not only do transformations have an effect on downstream performance and relevance of clustering, but also that each category in a supervised dataset can be impacted in a different way. Following this, we explore the impact of transformation design on microscopy images, a domain where the difference between classes is more subtle and fuzzy than in natural images. In this case, we observe a greater impact on downstream tasks performances. Finally, we demonstrate that transformation design can be leveraged as a form of supervision, as careful selection of these by a domain expert can lead to a drastic increase in performance on a given downstream task. ",
    "url": "https://arxiv.org/abs/2304.11718",
    "authors": [
      "Ihab Bendidi",
      "Adrien Bardes",
      "Ethan Cohen",
      "Alexis Lamiable",
      "Guillaume Bollot",
      "Auguste Genovesio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11720",
    "title": "Images Within Images? A Multi-image Paradigm with Novel Key-Value Graph  Oriented Steganography",
    "abstract": "Steganographic methods have been in the limelight of research and development for concealing secret data within a cover media without being noticed through general visualization. The Least Significant Bits (LSBs) of 8-bit color code for the RGB image arises the possibility of replacing the last two bits with the bits of the encrypted message. Several procedures have been developed to hide an image within another image however in most cases the payload image has to be within the accommodatable range of the cover image and very little literature have shown methods to hide multiple images within multiple images. This paper presents a novel approach to split the image into JSON styled dictionary of key-value pairs and using a metadata graph to locate different parts and positions of the payload images in the entire cluster of cover images. The model could be easily used in the real world scenario for privately sharing secret data over public communication channels without being noticed. ",
    "url": "https://arxiv.org/abs/2304.11720",
    "authors": [
      "Subhrangshu Adhikary"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.11733",
    "title": "COVID-19 Spreading Prediction and Impact Analysis by Using Artificial  Intelligence for Sustainable Global Health Assessment",
    "abstract": "The COVID-19 pandemic is considered as the most alarming global health calamity of this century. COVID-19 has been confirmed to be mutated from coronavirus family. As stated by the records of The World Health Organization (WHO at April 18 2020), the present epidemic of COVID-19, has influenced more than 2,164,111 persons and killed more than 146,198 folks in over 200 countries across the globe and billions had confronted impacts in lifestyle because of this virus outbreak. The ongoing overall outbreak of the COVID-19 opened up new difficulties to the research sectors. Artificial intelligence (AI) driven strategies can be valuable to predict the parameters, hazards, and impacts of such an epidemic in a cost-efficient manner. The fundamental difficulties of AI in this situation is the limited availability of information and the uncertain nature of the disease. Here in this article, we have tried to integrate AI to predict the infection outbreak and along with this, we have also tried to test whether AI with help deep learning can recognize COVID-19 infected chest X-Rays or not. The global outbreak of the virus posed enormous economic, ecological and societal challenges into the human population and with help of this paper, we have tried to give a message that AI can help us to identify certain features of the disease outbreak that could prove to be essential to protect the humanity from this deadly disease. ",
    "url": "https://arxiv.org/abs/2304.11733",
    "authors": [
      "Subhrangshu Adhikary",
      "Sonam Chaturvedi",
      "Sudhir Kumar Chaturvedi",
      "Saikat Banerjee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11740",
    "title": "A Neuro-Symbolic Approach for Enhanced Human Motion Prediction",
    "abstract": "Reasoning on the context of human beings is crucial for many real-world applications especially for those deploying autonomous systems (e.g. robots). In this paper, we present a new approach for context reasoning to further advance the field of human motion prediction. We therefore propose a neuro-symbolic approach for human motion prediction (NeuroSyM), which weights differently the interactions in the neighbourhood by leveraging an intuitive technique for spatial representation called Qualitative Trajectory Calculus (QTC). The proposed approach is experimentally tested on medium and long term time horizons using two architectures from the state of art, one of which is a baseline for human motion prediction and the other is a baseline for generic multivariate time-series prediction. Six datasets of challenging crowded scenarios, collected from both fixed and mobile cameras, were used for testing. Experimental results show that the NeuroSyM approach outperforms in most cases the baseline architectures in terms of prediction accuracy. ",
    "url": "https://arxiv.org/abs/2304.11740",
    "authors": [
      "Sariah Mghames",
      "Luca Castri",
      "Marc Hanheide",
      "Nicola Bellotto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11741",
    "title": "Robust and differentially private stochastic linear bandits",
    "abstract": "In this paper, we study the stochastic linear bandit problem under the additional requirements of differential privacy, robustness and batched observations. In particular, we assume an adversary randomly chooses a constant fraction of the observed rewards in each batch, replacing them with arbitrary numbers. We present differentially private and robust variants of the arm elimination algorithm using logarithmic batch queries under two privacy models and provide regret bounds in both settings. In the first model, every reward in each round is reported by a potentially different client, which reduces to standard local differential privacy (LDP). In the second model, every action is \"owned\" by a different client, who may aggregate the rewards over multiple queries and privatize the aggregate response instead. To the best of our knowledge, our algorithms are the first simultaneously providing differential privacy and adversarial robustness in the stochastic linear bandits problem. ",
    "url": "https://arxiv.org/abs/2304.11741",
    "authors": [
      "Vasileios Charisopoulos",
      "Hossein Esfandiari",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.11752",
    "title": "Query-specific Variable Depth Pooling via Query Performance Prediction  towards Reducing Relevance Assessment Effort",
    "abstract": "Due to the massive size of test collections, a standard practice in IR evaluation is to construct a 'pool' of candidate relevant documents comprised of the top-k documents retrieved by a wide range of different retrieval systems - a process called depth-k pooling. A standard practice is to set the depth (k) to a constant value for each query constituting the benchmark set. However, in this paper we argue that the annotation effort can be substantially reduced if the depth of the pool is made a variable quantity for each query, the rationale being that the number of documents relevant to the information need can widely vary across queries. Our hypothesis is that a lower depth for the former class of queries and a higher depth for the latter can potentially reduce the annotation effort without a significant change in retrieval effectiveness evaluation. We make use of standard query performance prediction (QPP) techniques to estimate the number of potentially relevant documents for each query, which is then used to determine the depth of the pool. Our experiments conducted on standard test collections demonstrate that this proposed method of employing query-specific variable depths is able to adequately reflect the relative effectiveness of IR systems with a substantially smaller annotation effort. ",
    "url": "https://arxiv.org/abs/2304.11752",
    "authors": [
      "Debasis Ganguly",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.11758",
    "title": "Improving Classification Neural Networks by using Absolute activation  function (MNIST/LeNET-5 example)",
    "abstract": "The paper discusses the use of the Absolute activation function in classification neural networks. An examples are shown of using this activation function in simple and more complex problems. Using as a baseline LeNet-5 network for solving the MNIST problem, the efficiency of Absolute activation function is shown in comparison with the use of Tanh, ReLU and SeLU activations. It is shown that in deep networks Absolute activation does not cause vanishing and exploding gradients, and therefore Absolute activation can be used in both simple and deep neural networks. Due to high volatility of training networks with Absolute activation, a special modification of ADAM training algorithm is used, that estimates lower bound of accuracy at any test dataset using validation dataset analysis at each training epoch, and uses this value to stop/decrease learning rate, and re-initializes ADAM algorithm between these steps. It is shown that solving the MNIST problem with the LeNet-like architectures based on Absolute activation allows to significantly reduce the number of trained parameters in the neural network with improving the prediction accuracy. ",
    "url": "https://arxiv.org/abs/2304.11758",
    "authors": [
      "Oleg I.Berngardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11761",
    "title": "Hier-RTLMP: A Hierarchical Automatic Macro Placer for Large-scale  Complex IP Blocks",
    "abstract": "In a typical RTL to GDSII flow, floorplanning or macro placement is a critical step in achieving decent quality of results (QoR). Moreover, in today's physical synthesis flows (e.g., Synopsys Fusion Compiler or Cadence Genus iSpatial), a floorplan .def with macro and IO pin placements is typically needed as an input to the front-end physical synthesis. Recently, with the increasing complexity of IP blocks, and in particular with auto-generated RTL for machine learning (ML) accelerators, the number of hard macros in a single RTL block can easily run into the several hundreds. This makes the task of generating an automatic floorplan (.def) with IO pin and macro placements for front-end physical synthesis even more critical and challenging. The so-called peripheral approach of forcing macros to the periphery of the layout is no longer viable when the ratio of the sum of the macro perimeters to the floorplan perimeter is large, since this increases the required stacking depth of macros. In this paper, we develop a novel multilevel physical planning approach that exploits the hierarchy and dataflow inherent in the design RTL, and describe its realization in a new hierarchical macro placer, Hier-RTLMP. Hier-RTLMP borrows from traditional approaches used in manual system-on-chip (SoC) floorplanning to create an automatic macro placement for use with large IP blocks containing very large numbers of hard macros. Empirical studies demonstrate substantial improvements over the previous RTL-MP macro placement approach, and promising post-route improvements relative to a leading commercial place-and-route tool. ",
    "url": "https://arxiv.org/abs/2304.11761",
    "authors": [
      "Andrew B. Kahng",
      "Ravi Varadarajan",
      "Zhiang Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11763",
    "title": "The Case for Hierarchical Deep Learning Inference at the Network Edge",
    "abstract": "Resource-constrained Edge Devices (EDs), e.g., IoT sensors and microcontroller units, are expected to make intelligent decisions using Deep Learning (DL) inference at the edge of the network. Toward this end, there is a significant research effort in developing tinyML models - Deep Learning (DL) models with reduced computation and memory storage requirements - that can be embedded on these devices. However, tinyML models have lower inference accuracy. On a different front, DNN partitioning and inference offloading techniques were studied for distributed DL inference between EDs and Edge Servers (ESs). In this paper, we explore Hierarchical Inference (HI), a novel approach proposed by Vishnu et al. 2023, arXiv:2304.00891v1 , for performing distributed DL inference at the edge. Under HI, for each data sample, an ED first uses a local algorithm (e.g., a tinyML model) for inference. Depending on the application, if the inference provided by the local algorithm is incorrect or further assistance is required from large DL models on edge or cloud, only then the ED offloads the data sample. At the outset, HI seems infeasible as the ED, in general, cannot know if the local inference is sufficient or not. Nevertheless, we present the feasibility of implementing HI for machine fault detection and image classification applications. We demonstrate its benefits using quantitative analysis and argue that using HI will result in low latency, bandwidth savings, and energy savings in edge AI systems. ",
    "url": "https://arxiv.org/abs/2304.11763",
    "authors": [
      "Ghina Al-Atat",
      "Andrea Fresa",
      "Adarsh Prasad Behera",
      "Vishnu Narayanan Moothedath",
      "James Gross",
      "Jaya Prakash Champati"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11764",
    "title": "Learning-enabled multi-modal motion prediction in urban environments",
    "abstract": "Motion prediction is a key factor towards the full deployment of autonomous vehicles. It is fundamental in order to assure safety while navigating through highly interactive complex scenarios. In this work, the framework IAMP (Interaction- Aware Motion Prediction), producing multi-modal probabilistic outputs from the integration of a Dynamic Bayesian Network and Markov Chains, is extended with a learning-based approach. The integration of a machine learning model tackles the limitations of the ruled-based mechanism since it can better adapt to different driving styles and driving situations. The method here introduced generates context-dependent acceleration distributions used in a Markov-chain-based motion prediction. This hybrid approach results in better evaluation metrics when compared with the baseline in the four ",
    "url": "https://arxiv.org/abs/2304.11764",
    "authors": [
      "Vinicius Trentin",
      "Chenxu Ma",
      "Jorge Villagra",
      "Zaid Al-Ars"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11779",
    "title": "Now You See Me: Robust approach to Partial Occlusions",
    "abstract": "Occlusions of objects is one of the indispensable problems in Computer vision. While Convolutional Neural Net-works (CNNs) provide various state of the art approaches for regular image classification, they however, prove to be not as effective for the classification of images with partial occlusions. Partial occlusion is scenario where an object is occluded partially by some other object/space. This problem when solved,holds tremendous potential to facilitate various scenarios. We in particular are interested in autonomous driving scenario and its implications in the same. Autonomous vehicle research is one of the hot topics of this decade, there are ample situations of partial occlusions of a driving sign or a person or other objects at different angles. Considering its prime importance in situations which can be further extended to video analytics of traffic data to handle crimes, anticipate income levels of various groups etc.,this holds the potential to be exploited in many ways. In this paper, we introduce our own synthetically created dataset by utilising Stanford Car Dataset and adding occlusions of various sizes and nature to it. On this created dataset, we conducted a comprehensive analysis using various state of the art CNN models such as VGG-19, ResNet 50/101, GoogleNet, DenseNet 121. We further in depth study the effect of varying occlusion proportions and nature on the performance of these models by fine tuning and training these from scratch on dataset and how is it likely to perform when trained in different scenarios, i.e., performance when training with occluded images and unoccluded images, which model is more robust to partial occlusions and soon. ",
    "url": "https://arxiv.org/abs/2304.11779",
    "authors": [
      "Karthick Prasad Gunasekaran",
      "Nikita Jaiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11794",
    "title": "FineEHR: Refine Clinical Note Representations to Improve Mortality  Prediction",
    "abstract": "Monitoring the health status of patients in the ICU is crucial for providing them with better care and treatment. Massive raw electronic health records (EHR) give machine learning models more clinical texts and vital signs to make accurate predictions. Currently, many advanced NLP models have emerged for clinical note analysis. However, due to the complicated textual structure and noise in raw clinical data, coarse embedding approaches without domain-specific refining limit the accuracy improvement. To address this issue, we propose FINEEHR, a system adopting two representation learning techniques, including metric learning and fine-tuning, to refine clinical note embeddings, utilizing the inner correlation among different health statuses and note categories. We evaluate the performance of FINEEHR using two metrics, AUC and AUC-PR, on a real-world MIMIC III dataset. Our experimental results demonstrate that both refining approaches can improve prediction accuracy, and their combination presents the best results. It outperforms previous works, achieving an AUC improvement of over 10%, with an average AUC of 96.04% and an average AUC-PR of 96.48% across various classifiers. ",
    "url": "https://arxiv.org/abs/2304.11794",
    "authors": [
      "Jun Wu",
      "Xuesong Ye",
      "Chengjie Mou",
      "Weinan Dai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11805",
    "title": "OGMN: Occlusion-guided Multi-task Network for Object Detection in UAV  Images",
    "abstract": "Occlusion between objects is one of the overlooked challenges for object detection in UAV images. Due to the variable altitude and angle of UAVs, occlusion in UAV images happens more frequently than that in natural scenes. Compared to occlusion in natural scene images, occlusion in UAV images happens with feature confusion problem and local aggregation characteristic. And we found that extracting or localizing occlusion between objects is beneficial for the detector to address this challenge. According to this finding, the occlusion localization task is introduced, which together with the object detection task constitutes our occlusion-guided multi-task network (OGMN). The OGMN contains the localization of occlusion and two occlusion-guided multi-task interactions. In detail, an occlusion estimation module (OEM) is proposed to precisely localize occlusion. Then the OGMN utilizes the occlusion localization results to implement occlusion-guided detection with two multi-task interactions. One interaction for the guide is between two task decoders to address the feature confusion problem, and an occlusion decoupling head (ODH) is proposed to replace the general detection head. Another interaction for guide is designed in the detection process according to local aggregation characteristic, and a two-phase progressive refinement process (TPP) is proposed to optimize the detection process. Extensive experiments demonstrate the effectiveness of our OGMN on the Visdrone and UAVDT datasets. In particular, our OGMN achieves 35.0% mAP on the Visdrone dataset and outperforms the baseline by 5.3%. And our OGMN provides a new insight for accurate occlusion localization and achieves competitive detection performance. ",
    "url": "https://arxiv.org/abs/2304.11805",
    "authors": [
      "Xuexue Li",
      "Wenhui Diao",
      "Yongqiang Mao",
      "Peng Gao",
      "Xiuhua Mao",
      "Xinming Li",
      "Xian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11823",
    "title": "Enhancing Fine-Tuning Based Backdoor Defense with Sharpness-Aware  Minimization",
    "abstract": "Backdoor defense, which aims to detect or mitigate the effect of malicious triggers introduced by attackers, is becoming increasingly critical for machine learning security and integrity. Fine-tuning based on benign data is a natural defense to erase the backdoor effect in a backdoored model. However, recent studies show that, given limited benign data, vanilla fine-tuning has poor defense performance. In this work, we provide a deep study of fine-tuning the backdoored model from the neuron perspective and find that backdoorrelated neurons fail to escape the local minimum in the fine-tuning process. Inspired by observing that the backdoorrelated neurons often have larger norms, we propose FTSAM, a novel backdoor defense paradigm that aims to shrink the norms of backdoor-related neurons by incorporating sharpness-aware minimization with fine-tuning. We demonstrate the effectiveness of our method on several benchmark datasets and network architectures, where it achieves state-of-the-art defense performance. Overall, our work provides a promising avenue for improving the robustness of machine learning models against backdoor attacks. ",
    "url": "https://arxiv.org/abs/2304.11823",
    "authors": [
      "Mingli Zhu",
      "Shaokui Wei",
      "Li Shen",
      "Yanbo Fan",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11834",
    "title": "Robust Tickets Can Transfer Better: Drawing More Transferable  Subnetworks in Transfer Learning",
    "abstract": "Transfer learning leverages feature representations of deep neural networks (DNNs) pretrained on source tasks with rich data to empower effective finetuning on downstream tasks. However, the pretrained models are often prohibitively large for delivering generalizable representations, which limits their deployment on edge devices with constrained resources. To close this gap, we propose a new transfer learning pipeline, which leverages our finding that robust tickets can transfer better, i.e., subnetworks drawn with properly induced adversarial robustness can win better transferability over vanilla lottery ticket subnetworks. Extensive experiments and ablation studies validate that our proposed transfer learning pipeline can achieve enhanced accuracy-sparsity trade-offs across both diverse downstream tasks and sparsity patterns, further enriching the lottery ticket hypothesis. ",
    "url": "https://arxiv.org/abs/2304.11834",
    "authors": [
      "Yonggan Fu",
      "Ye Yuan",
      "Shang Wu",
      "Jiayi Yuan",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11835",
    "title": "Auto-CARD: Efficient and Robust Codec Avatar Driving for Real-time  Mobile Telepresence",
    "abstract": "Real-time and robust photorealistic avatars for telepresence in AR/VR have been highly desired for enabling immersive photorealistic telepresence. However, there still exists one key bottleneck: the considerable computational expense needed to accurately infer facial expressions captured from headset-mounted cameras with a quality level that can match the realism of the avatar's human appearance. To this end, we propose a framework called Auto-CARD, which for the first time enables real-time and robust driving of Codec Avatars when exclusively using merely on-device computing resources. This is achieved by minimizing two sources of redundancy. First, we develop a dedicated neural architecture search technique called AVE-NAS for avatar encoding in AR/VR, which explicitly boosts both the searched architectures' robustness in the presence of extreme facial expressions and hardware friendliness on fast evolving AR/VR headsets. Second, we leverage the temporal redundancy in consecutively captured images during continuous rendering and develop a mechanism dubbed LATEX to skip the computation of redundant frames. Specifically, we first identify an opportunity from the linearity of the latent space derived by the avatar decoder and then propose to perform adaptive latent extrapolation for redundant frames. For evaluation, we demonstrate the efficacy of our Auto-CARD framework in real-time Codec Avatar driving settings, where we achieve a 5.05x speed-up on Meta Quest 2 while maintaining a comparable or even better animation quality than state-of-the-art avatar encoder designs. ",
    "url": "https://arxiv.org/abs/2304.11835",
    "authors": [
      "Yonggan Fu",
      "Yuecheng Li",
      "Chenghui Li",
      "Jason Saragih",
      "Peizhao Zhang",
      "Xiaoliang Dai",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11840",
    "title": "Robust and Efficient Memory Network for Video Object Segmentation",
    "abstract": "This paper proposes a Robust and Efficient Memory Network, referred to as REMN, for studying semi-supervised video object segmentation (VOS). Memory-based methods have recently achieved outstanding VOS performance by performing non-local pixel-wise matching between the query and memory. However, these methods have two limitations. 1) Non-local matching could cause distractor objects in the background to be incorrectly segmented. 2) Memory features with high temporal redundancy consume significant computing resources. For limitation 1, we introduce a local attention mechanism that tackles the background distraction by enhancing the features of foreground objects with the previous mask. For limitation 2, we first adaptively decide whether to update the memory features depending on the variation of foreground objects to reduce temporal redundancy. Second, we employ a dynamic memory bank, which uses a lightweight and differentiable soft modulation gate to decide how many memory features need to be removed in the temporal dimension. Experiments demonstrate that our REMN achieves state-of-the-art results on DAVIS 2017, with a $\\mathcal{J\\&F}$ score of 86.3% and on YouTube-VOS 2018, with a $\\mathcal{G}$ over mean of 85.5%. Furthermore, our network shows a high inference speed of 25+ FPS and uses relatively few computing resources. ",
    "url": "https://arxiv.org/abs/2304.11840",
    "authors": [
      "Yadang Chen",
      "Dingwei Zhang",
      "Zhi-xin Yang",
      "Enhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.11842",
    "title": "Gen-NeRF: Efficient and Generalizable Neural Radiance Fields via  Algorithm-Hardware Co-Design",
    "abstract": "Novel view synthesis is an essential functionality for enabling immersive experiences in various Augmented- and Virtual-Reality (AR/VR) applications, for which generalizable Neural Radiance Fields (NeRFs) have gained increasing popularity thanks to their cross-scene generalization capability. Despite their promise, the real-device deployment of generalizable NeRFs is bottlenecked by their prohibitive complexity due to the required massive memory accesses to acquire scene features, causing their ray marching process to be memory-bounded. To this end, we propose Gen-NeRF, an algorithm-hardware co-design framework dedicated to generalizable NeRF acceleration, which for the first time enables real-time generalizable NeRFs. On the algorithm side, Gen-NeRF integrates a coarse-then-focus sampling strategy, leveraging the fact that different regions of a 3D scene contribute differently to the rendered pixel, to enable sparse yet effective sampling. On the hardware side, Gen-NeRF highlights an accelerator micro-architecture to maximize the data reuse opportunities among different rays by making use of their epipolar geometric relationship. Furthermore, our Gen-NeRF accelerator features a customized dataflow to enhance data locality during point-to-hardware mapping and an optimized scene feature storage strategy to minimize memory bank conflicts. Extensive experiments validate the effectiveness of our proposed Gen-NeRF framework in enabling real-time and generalizable novel view synthesis. ",
    "url": "https://arxiv.org/abs/2304.11842",
    "authors": [
      "Yonggan Fu",
      "Zhifan Ye",
      "Jiayi Yuan",
      "Shunyao Zhang",
      "Sixu Li",
      "Haoran You",
      "Yingyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2304.11853",
    "title": "Human intuition as a defense against attribute inference",
    "abstract": "Attribute inference - the process of analyzing publicly available data in order to uncover hidden information - has become a major threat to privacy, given the recent technological leap in machine learning. One way to tackle this threat is to strategically modify one's publicly available data in order to keep one's private information hidden from attribute inference. We evaluate people's ability to perform this task, and compare it against algorithms designed for this purpose. We focus on three attributes: the gender of the author of a piece of text, the country in which a set of photos was taken, and the link missing from a social network. For each of these attributes, we find that people's effectiveness is inferior to that of AI, especially when it comes to hiding the attribute in question. Moreover, when people are asked to modify the publicly available information in order to hide these attributes, they are less likely to make high-impact modifications compared to AI. This suggests that people are unable to recognize the aspects of the data that are critical to an inference algorithm. Taken together, our findings highlight the limitations of relying on human intuition to protect privacy in the age of AI, and emphasize the need for algorithmic support to protect private information from attribute inference. ",
    "url": "https://arxiv.org/abs/2304.11853",
    "authors": [
      "Marcin Waniek",
      "Navya Suri",
      "Abdullah Zameek",
      "Bedoor AlShebli",
      "Talal Rahwan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.11857",
    "title": "Accurate and Efficient Event-based Semantic Segmentation Using Adaptive  Spiking Encoder-Decoder Network",
    "abstract": "Low-power event-driven computation and inherent temporal dynamics render spiking neural networks (SNNs) ideal candidates for processing highly dynamic and asynchronous signals from event-based sensors. However, due to the challenges in training and architectural design constraints, there is a scarcity of competitive demonstrations of SNNs in event-based dense prediction compared to artificial neural networks (ANNs). In this work, we construct an efficient spiking encoder-decoder network for large-scale event-based semantic segmentation tasks, optimizing the encoder with hierarchical search. To improve learning from highly dynamic event streams, we exploit the intrinsic adaptive threshold of spiking neurons to modulate network activation. Additionally, we develop a dual-path spiking spatially-adaptive modulation (SSAM) block to enhance the representation of sparse events, significantly improving network performance. Our network achieves 72.57% mean intersection over union (MIoU) on the DDD17 dataset and 57.22% MIoU on the newly proposed larger DSEC-Semantic dataset, surpassing current record ANNs by 4% while utilizing much lower computation costs. To the best of our knowledge, this is the first instance of SNNs outperforming ANNs in challenging event-based semantic segmentation tasks, demonstrating their immense potential in event-based vision. Our code will be publicly available. ",
    "url": "https://arxiv.org/abs/2304.11857",
    "authors": [
      "Rui Zhang",
      "Luziwei Leng",
      "Kaiwei Che",
      "Hu Zhang",
      "Jie Cheng",
      "Qinghai Guo",
      "Jiangxing Liao",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.11868",
    "title": "A Benchmark for Cycling Close Pass Near Miss Event Detection from Video  Streams",
    "abstract": "Cycling is a healthy and sustainable mode of transport. However, interactions with motor vehicles remain a key barrier to increased cycling participation. The ability to detect potentially dangerous interactions from on-bike sensing could provide important information to riders and policy makers. Thus, automated detection of conflict between cyclists and drivers has attracted researchers from both computer vision and road safety communities. In this paper, we introduce a novel benchmark, called Cyc-CP, towards cycling close pass near miss event detection from video streams. We first divide this task into scene-level and instance-level problems. Scene-level detection asks an algorithm to predict whether there is a close pass near miss event in the input video clip. Instance-level detection aims to detect which vehicle in the scene gives rise to a close pass near miss. We propose two benchmark models based on deep learning techniques for these two problems. For training and testing those models, we construct a synthetic dataset and also collect a real-world dataset. Our models can achieve 88.13% and 84.60% accuracy on the real-world dataset, respectively. We envision this benchmark as a test-bed to accelerate cycling close pass near miss detection and facilitate interaction between the fields of road safety, intelligent transportation systems and artificial intelligence. Both the benchmark datasets and detection models will be available at https://github.com/SustainableMobility/cyc-cp to facilitate experimental reproducibility and encourage more in-depth research in the field. ",
    "url": "https://arxiv.org/abs/2304.11868",
    "authors": [
      "Mingjie Li",
      "Tharindu Rathnayake",
      "Ben Beck",
      "Lingheng Meng",
      "Zijue Chen",
      "Akansel Cosgun",
      "Xiaojun Chang",
      "Dana Kuli\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11881",
    "title": "Resource sharing in wireless networks with co-location",
    "abstract": "With more and more demand from devices to use wireless communication networks, there has been an increased interest in resource sharing among operators, to give a better link quality. However, in the analysis of the benefits of resource sharing among these operators, the important factor of co-location is often overlooked. Indeed, often in wireless communication networks, different operators co-locate: they place their base stations at the same locations due to cost efficiency. We therefore use stochastic geometry to investigate the effect of co-location on the benefits of resource sharing. We develop an intricate relation between the co-location factor and the optimal radius to operate the network, which shows that indeed co-location is an important factor to take into account. We also investigate the limiting behavior of the expected gains of sharing, and find that for unequal operators, sharing may not always be beneficial when taking co-location into account. ",
    "url": "https://arxiv.org/abs/2304.11881",
    "authors": [
      "Clara Stegehuis",
      "Lotte Weedage"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2304.11906",
    "title": "Transformer-based stereo-aware 3D object detection from binocular images",
    "abstract": "Vision Transformers have shown promising progress in various object detection tasks, including monocular 2D/3D detection and surround-view 3D detection. However, when used in essential and classic stereo 3D object detection, directly adopting those surround-view Transformers leads to slow convergence and significant precision drops. We argue that one of the causes of this defect is that the surround-view Transformers do not consider the stereo-specific image correspondence information. In a surround-view system, the overlapping areas are small, and thus correspondence is not a primary issue. In this paper, we explore the model design of vision Transformers in stereo 3D object detection, focusing particularly on extracting and encoding the task-specific image correspondence information. To achieve this goal, we present TS3D, a Transformer-based Stereo-aware 3D object detector. In the TS3D, a Disparity-Aware Positional Encoding (DAPE) model is proposed to embed the image correspondence information into stereo features. The correspondence is encoded as normalized disparity and is used in conjunction with sinusoidal 2D positional encoding to provide the location information of the 3D scene. To extract enriched multi-scale stereo features, we propose a Stereo Reserving Feature Pyramid Network (SRFPN). The SRFPN is designed to reserve the correspondence information while fusing intra-scale and aggregating cross-scale stereo features. Our proposed TS3D achieves a 41.29% Moderate Car detection average precision on the KITTI test set and takes 88 ms to detect objects from each binocular image pair. It is competitive with advanced counterparts in terms of both precision and inference speed. ",
    "url": "https://arxiv.org/abs/2304.11906",
    "authors": [
      "Hanqing Sun",
      "Yanwei Pang",
      "Jiale Cao",
      "Jin Xie",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11924",
    "title": "KInITVeraAI at SemEval-2023 Task 3: Simple yet Powerful Multilingual  Fine-Tuning for Persuasion Techniques Detection",
    "abstract": "This paper presents the best-performing solution to the SemEval 2023 Task 3 on the subtask 3 dedicated to persuasion techniques detection. Due to a high multilingual character of the input data and a large number of 23 predicted labels (causing a lack of labelled data for some language-label combinations), we opted for fine-tuning pre-trained transformer-based language models. Conducting multiple experiments, we find the best configuration, which consists of large multilingual model (XLM-RoBERTa large) trained jointly on all input data, with carefully calibrated confidence thresholds for seen and surprise languages separately. Our final system performed the best on 6 out of 9 languages (including two surprise languages) and achieved highly competitive results on the remaining three languages. ",
    "url": "https://arxiv.org/abs/2304.11924",
    "authors": [
      "Timo Hromadka",
      "Timotej Smolen",
      "Tomas Remis",
      "Branislav Pecher",
      "Ivan Srba"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11925",
    "title": "Data-driven modelling of brain activity using neural networks, Diffusion  Maps, and the Koopman operator",
    "abstract": "We propose a machine-learning approach to model long-term out-of-sample dynamics of brain activity from task-dependent fMRI data. Our approach is a three stage one. First, we exploit Diffusion maps (DMs) to discover a set of variables that parametrize the low-dimensional manifold on which the emergent high-dimensional fMRI time series evolve. Then, we construct reduced-order-models (ROMs) on the embedded manifold via two techniques: Feedforward Neural Networks (FNNs) and the Koopman operator. Finally, for predicting the out-of-sample long-term dynamics of brain activity in the ambient fMRI space, we solve the pre-image problem coupling DMs with Geometric Harmonics (GH) when using FNNs and the Koopman modes per se. For our illustrations, we have assessed the performance of the two proposed schemes using a benchmark fMRI dataset with recordings during a visuo-motor task. The results suggest that just a few (for the particular task, five) non-linear coordinates of the high-dimensional fMRI time series provide a good basis for modelling and out-of-sample prediction of the brain activity. Furthermore, we show that the proposed approaches outperform the one-step ahead predictions of the naive random walk model, which, in contrast to our scheme, relies on the knowledge of the signals in the previous time step. Importantly, we show that the proposed Koopman operator approach provides, for any practical purposes, equivalent results to the FNN-GH approach, thus bypassing the need to train a non-linear map and to use GH to extrapolate predictions in the ambient fMRI space; one can use instead the low-frequency truncation of the DMs function space of L^2-integrable functions, to predict the entire list of coordinate functions in the fMRI space and to solve the pre-image problem. ",
    "url": "https://arxiv.org/abs/2304.11925",
    "authors": [
      "Ioannis K. Gallos",
      "Daniel Lehmberg",
      "Felix Dietrich",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2304.11940",
    "title": "MoniLog: An Automated Log-Based Anomaly Detection System for Cloud  Computing Infrastructures",
    "abstract": "Within today's large-scale systems, one anomaly can impact millions of users. Detecting such events in real-time is essential to maintain the quality of services. It allows the monitoring team to prevent or diminish the impact of a failure. Logs are a core part of software development and maintenance, by recording detailed information at runtime. Such log data are universally available in nearly all computer systems. They enable developers as well as system maintainers to monitor and dissect anomalous events. For Cloud computing companies and large online platforms in general, growth is linked to the scaling potential. Automatizing the anomaly detection process is a promising way to ensure the scalability of monitoring capacities regarding the increasing volume of logs generated by modern systems. In this paper, we will introduce MoniLog, a distributed approach to detect real-time anomalies within large-scale environments. It aims to detect sequential and quantitative anomalies within a multi-source log stream. MoniLog is designed to structure a log stream and perform the monitoring of anomalous sequences. Its output classifier learns from the administrator's actions to label and evaluate the criticality level of anomalies. ",
    "url": "https://arxiv.org/abs/2304.11940",
    "authors": [
      "Arthur Vervaet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.11941",
    "title": "Partitioning and Deployment of Deep Neural Networks on Edge Clusters",
    "abstract": "Edge inference has become more widespread, as its diverse applications range from retail to wearable technology. Clusters of networked resource-constrained edge devices are becoming common, yet no system exists to split a DNN across these clusters while maximizing the inference throughput of the system. Additionally, no production-ready orchestration system exists for deploying said models over such edge networks which adopts the robustness and scalability of the cloud. We present an algorithm which partitions DNNs and distributes them across a set of edge devices with the goal of minimizing the bottleneck latency and therefore maximizing inference throughput. The system scales well to systems of different node memory capacities and numbers of nodes, while being node fault-tolerant. We find that we can reduce the bottleneck latency by 10x over a random algorithm and 35% over a greedy joint partitioning-placement algorithm, although the joint-partitioning algorithm outperforms our algorithm in most practical use-cases. Furthermore we find empirically that for the set of representative models we tested, the algorithm produces results within 9.2% of the optimal bottleneck latency. We then developed a standalone cluster network emulator on which we tested configurations of up to 20 nodes and found a steady increase in throughput and decrease in end-to-end latency as the cluster size scales. In these tests, we observed that our system has multi-node fault-tolerance as well as network and system IO fault-tolerance. We have implemented our framework in open-source software that is publicly available to the research community at https://github.com/ANRGUSC/SEIFER. ",
    "url": "https://arxiv.org/abs/2304.11941",
    "authors": [
      "Arjun Parthasarathy",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.11954",
    "title": "Spikingformer: Spike-driven Residual Learning for Transformer-based  Spiking Neural Network",
    "abstract": "Spiking neural networks (SNNs) offer a promising energy-efficient alternative to artificial neural networks, due to their event-driven spiking computation. However, state-of-the-art deep SNNs (including Spikformer and SEW ResNet) suffer from non-spike computations (integer-float multiplications) caused by the structure of their residual connection. These non-spike computations increase SNNs' power consumption and make them unsuitable for deployment on mainstream neuromorphic hardware, which only supports spike operations. In this paper, we propose a hardware-friendly spike-driven residual learning architecture for SNNs to avoid non-spike computations. Based on this residual design, we develop Spikingformer, a pure transformer-based spiking neural network. We evaluate Spikingformer on ImageNet, CIFAR10, CIFAR100, CIFAR10-DVS and DVS128 Gesture datasets, and demonstrated that Spikingformer outperforms the state-of-the-art in directly trained pure SNNs as a novel advanced backbone (74.79$\\%$ top-1 accuracy on ImageNet, + 1.41$\\%$ compared with Spikformer). Furthermore, our experiments verify that Spikingformer effectively avoids non-spike computations and reduces energy consumption by 60.34$\\%$ compared with Spikformer on ImageNet. To our best knowledge, this is the first time that a pure event-driven transformer-based SNN has been developed. ",
    "url": "https://arxiv.org/abs/2304.11954",
    "authors": [
      "Chenlin Zhou",
      "Liutao Yu",
      "Zhaokun Zhou",
      "Han Zhang",
      "Zhengyu Ma",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11963",
    "title": "Optimal Design of Neural Network Structure for Power System Frequency  Security Constraints",
    "abstract": "Recently, frequency security is challenged by high uncertainty and low inertia in power system with high penetration of Renewable Energy Sources (RES). In the context of Unit Commitment (UC) problems, frequency security constraints represented by neural networks have been developed and embedded into the optimization problem to represent complicated frequency dynamics. However, there are two major disadvantages related to this technique: the risk of overconfident prediction and poor computational efficiency. To handle these disadvantages, novel methodologies are proposed to optimally design the neural network structure, including the use of asymmetric loss function during the training stage and scientifically selecting neural network size and topology. The effectiveness of the proposed methodologies are validated by case study which reveals the improvement of conservativeness and mitigation of computation performance issues. ",
    "url": "https://arxiv.org/abs/2304.11963",
    "authors": [
      "Zhuoxuan Li",
      "Zhongda Chu",
      "Fei Teng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.11969",
    "title": "Causal Effect Estimation with Variational AutoEncoder and the Front Door  Criterion",
    "abstract": "An essential problem in causal inference is estimating causal effects from observational data. The problem becomes more challenging with the presence of unobserved confounders. When there are unobserved confounders, the commonly used back-door adjustment is not applicable. Although the instrumental variable (IV) methods can deal with unobserved confounders, they all assume that the treatment directly affects the outcome, and there is no mediator between the treatment and the outcome. This paper aims to use the front-door criterion to address the challenging problem with the presence of unobserved confounders and mediators. In practice, it is often difficult to identify the set of variables used for front-door adjustment from data. By leveraging the ability of deep generative models in representation learning, we propose FDVAE to learn the representation of a Front-Door adjustment set with a Variational AutoEncoder, instead of trying to search for a set of variables for front-door adjustment. Extensive experiments on synthetic datasets validate the effectiveness of FDVAE and its superiority over existing methods. The experiments also show that the performance of FDVAE is not sensitive to the causal strength of unobserved confounders and is feasible in the case of dimensionality mismatch between learned representations and the ground truth. We further apply the method to three real-world datasets to demonstrate its potential applications. ",
    "url": "https://arxiv.org/abs/2304.11969",
    "authors": [
      "Ziqi Xu",
      "Debo Cheng",
      "Jiuyong Li",
      "Jixue Liu",
      "Lin Liu",
      "Kui Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2304.11975",
    "title": "MRSN: Multi-Relation Support Network for Video Action Detection",
    "abstract": "Action detection is a challenging video understanding task, requiring modeling spatio-temporal and interaction relations. Current methods usually model actor-actor and actor-context relations separately, ignoring their complementarity and mutual support. To solve this problem, we propose a novel network called Multi-Relation Support Network (MRSN). In MRSN, Actor-Context Relation Encoder (ACRE) and Actor-Actor Relation Encoder (AARE) model the actor-context and actor-actor relation separately. Then Relation Support Encoder (RSE) computes the supports between the two relations and performs relation-level interactions. Finally, Relation Consensus Module (RCM) enhances two relations with the long-term relations from the Long-term Relation Bank (LRB) and yields a consensus. Our experiments demonstrate that modeling relations separately and performing relation-level interactions can achieve and outperformer state-of-the-art results on two challenging video datasets: AVA and UCF101-24. ",
    "url": "https://arxiv.org/abs/2304.11975",
    "authors": [
      "Yin-Dong Zheng",
      "Guo Chen",
      "Minglei Yuan",
      "Tong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11976",
    "title": "Zero-shot text-to-speech synthesis conditioned using self-supervised  speech representation model",
    "abstract": "This paper proposes a zero-shot text-to-speech (TTS) conditioned by a self-supervised speech-representation model acquired through self-supervised learning (SSL). Conventional methods with embedding vectors from x-vector or global style tokens still have a gap in reproducing the speaker characteristics of unseen speakers. A novel point of the proposed method is the direct use of the SSL model to obtain embedding vectors from speech representations trained with a large amount of data. We also introduce the separate conditioning of acoustic features and a phoneme duration predictor to obtain the disentangled embeddings between rhythm-based speaker characteristics and acoustic-feature-based ones. The disentangled embeddings will enable us to achieve better reproduction performance for unseen speakers and rhythm transfer conditioned by different speeches. Objective and subjective evaluations showed that the proposed method can synthesize speech with improved similarity and achieve speech-rhythm transfer. ",
    "url": "https://arxiv.org/abs/2304.11976",
    "authors": [
      "Kenichi Fujita",
      "Takanori Ashihara",
      "Hiroki Kanagawa",
      "Takafumi Moriya",
      "Yusuke Ijima"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.11979",
    "title": "Attention-guided Multi-step Fusion: A Hierarchical Fusion Network for  Multimodal Recommendation",
    "abstract": "The main idea of multimodal recommendation is the rational utilization of the item's multimodal information to improve the recommendation performance. Previous works directly integrate item multimodal features with item ID embeddings, ignoring the inherent semantic relations contained in the multimodal features. In this paper, we propose a novel and effective aTtention-guided Multi-step FUsion Network for multimodal recommendation, named TMFUN. Specifically, our model first constructs modality feature graph and item feature graph to model the latent item-item semantic structures. Then, we use the attention module to identify inherent connections between user-item interaction data and multimodal data, evaluate the impact of multimodal data on different interactions, and achieve early-step fusion of item features. Furthermore, our model optimizes item representation through the attention-guided multi-step fusion strategy and contrastive learning to improve recommendation performance. The extensive experiments on three real-world datasets show that our model has superior performance compared to the state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2304.11979",
    "authors": [
      "Yan Zhou",
      "Jie Guo",
      "Hao Sun",
      "Bin Song",
      "Fei Richard Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.11987",
    "title": "Causal fault localisation in dataflow systems",
    "abstract": "Dataflow computing was shown to bring significant benefits to multiple niches of systems engineering and has the potential to become a general-purpose paradigm of choice for data-driven application development. One of the characteristic features of dataflow computing is the natural access to the dataflow graph of the entire system. Recently it has been observed that these dataflow graphs can be treated as complete graphical causal models, opening opportunities to apply causal inference techniques to dataflow systems. In this demonstration paper we aim to provide the first practical validation of this idea with a particular focus on causal fault localisation. We provide multiple demonstrations of how causal inference can be used to detect software bugs and data shifts in multiple scenarios with three modern dataflow engines. ",
    "url": "https://arxiv.org/abs/2304.11987",
    "authors": [
      "Andrei Paleyes",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11989",
    "title": "Generative Flow Networks for Precise Reward-Oriented Active Learning on  Graphs",
    "abstract": "Many score-based active learning methods have been successfully applied to graph-structured data, aiming to reduce the number of labels and achieve better performance of graph neural networks based on predefined score functions. However, these algorithms struggle to learn policy distributions that are proportional to rewards and have limited exploration capabilities. In this paper, we innovatively formulate the graph active learning problem as a generative process, named GFlowGNN, which generates various samples through sequential actions with probabilities precisely proportional to a predefined reward function. Furthermore, we propose the concept of flow nodes and flow features to efficiently model graphs as flows based on generative flow networks, where the policy network is trained with specially designed rewards. Extensive experiments on real datasets show that the proposed approach has good exploration capability and transferability, outperforming various state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.11989",
    "authors": [
      "Yinchuan Li",
      "Zhigang Li",
      "Wenqian Li",
      "Yunfeng Shao",
      "Yan Zheng",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12015",
    "title": "ITER: Iterative Neural Repair for Multi-Location Patches",
    "abstract": "Automated program repair (APR) has achieved promising results, especially using neural networks. Yet, the overwhelming majority of patches produced by APR tools are confined to one single location. When looking at the patches produced with neural repair, most of them fail to compile, while a few uncompilable ones go in the right direction. In both cases, the fundamental problem is to ignore the potential of partial patches. In this paper, we propose an iterative program repair paradigm called ITER founded on the concept of improving partial patches until they become plausible and correct. First, ITER iteratively improves partial single-location patches by fixing compilation errors and further refining the previously generated code. Second, ITER iteratively improves partial patches to construct multi-location patches, with fault localization re-execution. ITER is implemented for Java based on battle-proven deep neural networks and code representation. ITER is evaluated on 476 bugs from 10 open-source projects in Defects4J 2.0. ITER succeeds in repairing 76 of them, including 15 multi-location bugs which is a new frontier in the field. ",
    "url": "https://arxiv.org/abs/2304.12015",
    "authors": [
      "He Ye",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.12033",
    "title": "A Spatial Calibration Method for Robust Cooperative Perception",
    "abstract": "Cooperative perception is a promising technique for enhancing the perception capabilities of automated vehicles through vehicle-to-everything (V2X) cooperation, provided that accurate relative pose transforms are available. Nevertheless, obtaining precise positioning information often entails high costs associated with navigation systems. Moreover, signal drift resulting from factors such as occlusion and multipath effects can compromise the stability of the positioning information. Hence, a low-cost and robust method is required to calibrate relative pose information for multi-agent cooperative perception. In this paper, we propose a simple but effective inter-agent object association approach (CBM), which constructs contexts using the detected bounding boxes, followed by local context matching and global consensus maximization. Based on the matched correspondences, optimal relative pose transform is estimated, followed by cooperative perception fusion. Extensive experimental studies are conducted on both the simulated and real-world datasets, high object association precision and decimeter level relative pose calibration accuracy is achieved among the cooperating agents even with larger inter-agent localization errors. Furthermore, the proposed approach outperforms the state-of-the-art methods in terms of object association and relative pose estimation accuracy, as well as the robustness of cooperative perception against the pose errors of the connected agents. The code will be available at https://github.com/zhyingS/CBM. ",
    "url": "https://arxiv.org/abs/2304.12033",
    "authors": [
      "Zhiying Song",
      "Tenghui Xie",
      "Hailiang Zhang",
      "Fuxi Wen",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.12043",
    "title": "MixPro: Data Augmentation with MaskMix and Progressive Attention  Labeling for Vision Transformer",
    "abstract": "The recently proposed data augmentation TransMix employs attention labels to help visual transformers (ViT) achieve better robustness and performance. However, TransMix is deficient in two aspects: 1) The image cropping method of TransMix may not be suitable for vision transformer. 2) At the early stage of training, the model produces unreliable attention maps. TransMix uses unreliable attention maps to compute mixed attention labels that can affect the model. To address the aforementioned issues, we propose MaskMix and Progressive Attention Labeling (PAL) in image and label space, respectively. In detail, from the perspective of image space, we design MaskMix, which mixes two images based on a patch-like grid mask. In particular, the size of each mask patch is adjustable and is a multiple of the image patch size, which ensures each image patch comes from only one image and contains more global contents. From the perspective of label space, we design PAL, which utilizes a progressive factor to dynamically re-weight the attention weights of the mixed attention label. Finally, we combine MaskMix and Progressive Attention Labeling as our new data augmentation method, named MixPro. The experimental results show that our method can improve various ViT-based models at scales on ImageNet classification (73.8\\% top-1 accuracy based on DeiT-T for 300 epochs). After being pre-trained with MixPro on ImageNet, the ViT-based models also demonstrate better transferability to semantic segmentation, object detection, and instance segmentation. Furthermore, compared to TransMix, MixPro also shows stronger robustness on several benchmarks. The code will be released at https://github.com/fistyee/MixPro. ",
    "url": "https://arxiv.org/abs/2304.12043",
    "authors": [
      "Qihao Zhao",
      "Yangyu Huang",
      "Wei Hu",
      "Fan Zhang",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12053",
    "title": "Improving Synthetically Generated Image Detection in Cross-Concept  Settings",
    "abstract": "New advancements for the detection of synthetic images are critical for fighting disinformation, as the capabilities of generative AI models continuously evolve and can lead to hyper-realistic synthetic imagery at unprecedented scale and speed. In this paper, we focus on the challenge of generalizing across different concept classes, e.g., when training a detector on human faces and testing on synthetic animal images - highlighting the ineffectiveness of existing approaches that randomly sample generated images to train their models. By contrast, we propose an approach based on the premise that the robustness of the detector can be enhanced by training it on realistic synthetic images that are selected based on their quality scores according to a probabilistic quality estimation model. We demonstrate the effectiveness of the proposed approach by conducting experiments with generated images from two seminal architectures, StyleGAN2 and Latent Diffusion, and using three different concepts for each, so as to measure the cross-concept generalization ability. Our results show that our quality-based sampling method leads to higher detection performance for nearly all concepts, improving the overall effectiveness of the synthetic image detectors. ",
    "url": "https://arxiv.org/abs/2304.12053",
    "authors": [
      "Pantelis Dogoulis",
      "Giorgos Kordopatis-Zilos",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12069",
    "title": "Occlusion Robust 3D Human Pose Estimation with StridedPoseGraphFormer  and Data Augmentation",
    "abstract": "Occlusion is an omnipresent challenge in 3D human pose estimation (HPE). In spite of the large amount of research dedicated to 3D HPE, only a limited number of studies address the problem of occlusion explicitly. To fill this gap, we propose to combine exploitation of spatio-temporal features with synthetic occlusion augmentation during training to deal with occlusion. To this end, we build a spatio-temporal 3D HPE model, StridedPoseGraphFormer based on graph convolution and transformers, and train it using occlusion augmentation. Unlike the existing occlusion-aware methods, that are only tested for limited occlusion, we extensively evaluate our method for varying degrees of occlusion. We show that our proposed method compares favorably with the state-of-the-art (SoA). Our experimental results also reveal that in the absence of any occlusion handling mechanism, the performance of SoA 3D HPE methods degrades significantly when they encounter occlusion. ",
    "url": "https://arxiv.org/abs/2304.12069",
    "authors": [
      "Soubarna Banik",
      "Patricia Gscho\u00dfmann",
      "Alejandro Mendoza Garcia",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12082",
    "title": "Deep Audio-Visual Singing Voice Transcription based on Self-Supervised  Learning Models",
    "abstract": "Singing voice transcription converts recorded singing audio to musical notation. Sound contamination (such as accompaniment) and lack of annotated data make singing voice transcription an extremely difficult task. We take two approaches to tackle the above challenges: 1) introducing multimodal learning for singing voice transcription together with a new multimodal singing dataset, N20EMv2, enhancing noise robustness by utilizing video information (lip movements to predict the onset/offset of notes), and 2) adapting self-supervised learning models from the speech domain to the singing voice transcription task, significantly reducing annotated data requirements while preserving pretrained features. We build a self-supervised learning based audio-only singing voice transcription system, which not only outperforms current state-of-the-art technologies as a strong baseline, but also generalizes well to out-of-domain singing data. We then develop a self-supervised learning based video-only singing voice transcription system that detects note onsets and offsets with an accuracy of about 80\\%. Finally, based on the powerful acoustic and visual representations extracted by the above two systems as well as the feature fusion design, we create an audio-visual singing voice transcription system that improves the noise robustness significantly under different acoustic environments compared to the audio-only systems. ",
    "url": "https://arxiv.org/abs/2304.12082",
    "authors": [
      "Xiangming Gu",
      "Wei Zeng",
      "Jianan Zhang",
      "Longshen Ou",
      "Ye Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.12083",
    "title": "Joint Semantic and Structural Representation Learning for Enhancing User  Preference Modelling",
    "abstract": "Knowledge graphs (KGs) have become important auxiliary information for helping recommender systems obtain a good understanding of user preferences. Despite recent advances in KG-based recommender systems, existing methods are prone to suboptimal performance due to the following two drawbacks: 1) current KG-based methods over-emphasize the heterogeneous structural information within a KG and overlook the underlying semantics of its connections, hindering the recommender from distilling the explicit user preferences; and 2) the inherent incompleteness of a KG (i.e., missing facts, relations and entities) will deteriorate the information extracted from KG and weaken the representation learning of recommender systems. To tackle the aforementioned problems, we investigate the potential of jointly incorporating the structural and semantic information within a KG to model user preferences in finer granularity. A new framework for KG-based recommender systems, namely \\textit{K}nowledge \\textit{I}nfomax \\textit{R}ecommender \\textit{S}ystem with \\textit{C}ontrastive \\textit{L}earning (KIRS-CL) is proposed in this paper. Distinct from previous KG-based approaches, KIRS-CL utilizes structural and connectivity information with high-quality item embeddings learned by encoding KG triples with a pre-trained language model. These well-trained entity representations enable KIRS-CL to find the item to recommend via the preference connection between the user and the item. Additionally, to improve the generalizability of our framework, we introduce a contrastive warm-up learning strategy, making it capable of dealing with both warm- and cold-start recommendation scenarios. Extensive experiments on two real-world datasets demonstrate remarkable improvements over state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2304.12083",
    "authors": [
      "Xuhui Ren",
      "Wei Yuan",
      "Tong Chen",
      "Chaoqun Yang",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.12090",
    "title": "Reinforcement Learning with Knowledge Representation and Reasoning: A  Brief Survey",
    "abstract": "Reinforcement Learning(RL) has achieved tremendous development in recent years, but still faces significant obstacles in addressing complex real-life problems due to the issues of poor system generalization, low sample efficiency as well as safety and interpretability concerns. The core reason underlying such dilemmas can be attributed to the fact that most of the work has focused on the computational aspect of value functions or policies using a representational model to describe atomic components of rewards, states and actions etc, thus neglecting the rich high-level declarative domain knowledge of facts, relations and rules that can be either provided a priori or acquired through reasoning over time. Recently, there has been a rapidly growing interest in the use of Knowledge Representation and Reasoning(KRR) methods, usually using logical languages, to enable more abstract representation and efficient learning in RL. In this survey, we provide a preliminary overview on these endeavors that leverage the strengths of KRR to help solving various problems in RL, and discuss the challenging open problems and possible directions for future work in this area. ",
    "url": "https://arxiv.org/abs/2304.12090",
    "authors": [
      "Chao Yu",
      "Xuejing Zheng",
      "Hankz Hankui Zhuo",
      "Hai Wan",
      "Weilin Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12112",
    "title": "Coordinated Dynamic Spectrum Sharing Between Terrestrial and  Non-Terrestrial Networks in 5G and Beyond",
    "abstract": "The emerging Non-Terrestrial Networks (NTNs) can aid to provide 5G and beyond services everywhere and anytime. However, the vast emergence of NTN systems will introduce an unseen interference to both the existing satellite systems and Terrestrial Networks (TNs). For that, there is a need for novel ideas on how to efficiently utilize the co-existing systems with the ever-increasing competition on scarce spectrum resources. Dynamic Spectrum Sharing (DSS) is a promising technique in which different systems can operate on the same spectrum, thus increasing the spectrum efficiency and offering better coverage for the users. In this paper, we present a centralized scheme for achieving coordinated DSS to protect the primary TN while providing NTN with sufficient resources. The scheme is evaluated by system simulations in a scenario with a TN and low earth orbit satellite. The results reveal that in a low traffic demand situation, the primary TN users are not affected negatively while the NTN can provide service to the rural area. In high-demand traffic situations, the peak performance of the TN inevitably suffers but the TN cell edge and NTN users' performance is improved. ",
    "url": "https://arxiv.org/abs/2304.12112",
    "authors": [
      "Henrik Martikainen",
      "Mikko Majamaa",
      "Jani Puttonen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.12115",
    "title": "SQLi Detection with ML: A data-source perspective",
    "abstract": "Almost 50 years after the invention of SQL, injection attacks are still top-tier vulnerabilities of today's ICT systems. Consequently, SQLi detection is still an active area of research, where the most recent works incorporate machine learning techniques into the proposed solutions. In this work, we highlight the shortcomings of the previous ML-based results focusing on four aspects: the evaluation methods, the optimization of the model parameters, the distribution of utilized datasets, and the feature selection. Since no single work explored all of these aspects satisfactorily, we fill this gap and provide an in-depth and comprehensive empirical analysis. Moreover, we cross-validate the trained models by using data from other distributions. This aspect of ML models (trained for SQLi detection) was never studied. Yet, the sensitivity of the model's performance to this is crucial for any real-life deployment. Finally, we validate our findings on a real-world industrial SQLi dataset. ",
    "url": "https://arxiv.org/abs/2304.12115",
    "authors": [
      "Balazs Pejo",
      "Nikolett Kapui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12151",
    "title": "Policy Resilience to Environment Poisoning Attacks on Reinforcement  Learning",
    "abstract": "This paper investigates policy resilience to training-environment poisoning attacks on reinforcement learning (RL) policies, with the goal of recovering the deployment performance of a poisoned RL policy. Due to the fact that the policy resilience is an add-on concern to RL algorithms, it should be resource-efficient, time-conserving, and widely applicable without compromising the performance of RL algorithms. This paper proposes such a policy-resilience mechanism based on an idea of knowledge sharing. We summarize the policy resilience as three stages: preparation, diagnosis, recovery. Specifically, we design the mechanism as a federated architecture coupled with a meta-learning manner, pursuing an efficient extraction and sharing of the environment knowledge. With the shared knowledge, a poisoned agent can quickly identify the deployment condition and accordingly recover its policy performance. We empirically evaluate the resilience mechanism for both model-based and model-free RL algorithms, showing its effectiveness and efficiency in restoring the deployment performance of a poisoned policy. ",
    "url": "https://arxiv.org/abs/2304.12151",
    "authors": [
      "Hang Xu",
      "Xinghua Qu",
      "Zinovi Rabinovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.12161",
    "title": "Meta-tuning Loss Functions and Data Augmentation for Few-shot Object  Detection",
    "abstract": "Few-shot object detection, the problem of modelling novel object detection categories with few training instances, is an emerging topic in the area of few-shot learning and object detection. Contemporary techniques can be divided into two groups: fine-tuning based and meta-learning based approaches. While meta-learning approaches aim to learn dedicated meta-models for mapping samples to novel class models, fine-tuning approaches tackle few-shot detection in a simpler manner, by adapting the detection model to novel classes through gradient based optimization. Despite their simplicity, fine-tuning based approaches typically yield competitive detection results. Based on this observation, we focus on the role of loss functions and augmentations as the force driving the fine-tuning process, and propose to tune their dynamics through meta-learning principles. The proposed training scheme, therefore, allows learning inductive biases that can boost few-shot detection, while keeping the advantages of fine-tuning based approaches. In addition, the proposed approach yields interpretable loss functions, as opposed to highly parametric and complex few-shot meta-models. The experimental results highlight the merits of the proposed scheme, with significant improvements over the strong fine-tuning based few-shot detection baselines on benchmark Pascal VOC and MS-COCO datasets, in terms of both standard and generalized few-shot performance metrics. ",
    "url": "https://arxiv.org/abs/2304.12161",
    "authors": [
      "Berkan Demirel",
      "Orhun Bu\u011fra Baran",
      "Ramazan Gokberk Cinbis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12183",
    "title": "Small-footprint slimmable networks for keyword spotting",
    "abstract": "In this work, we present Slimmable Neural Networks applied to the problem of small-footprint keyword spotting. We show that slimmable neural networks allow us to create super-nets from Convolutioanl Neural Networks and Transformers, from which sub-networks of different sizes can be extracted. We demonstrate the usefulness of these models on in-house Alexa data and Google Speech Commands, and focus our efforts on models for the on-device use case, limiting ourselves to less than 250k parameters. We show that slimmable models can match (and in some cases, outperform) models trained from scratch. Slimmable neural networks are therefore a class of models particularly useful when the same functionality is to be replicated at different memory and compute budgets, with different accuracy requirements. ",
    "url": "https://arxiv.org/abs/2304.12183",
    "authors": [
      "Zuhaib Akhtar",
      "Mohammad Omar Khursheed",
      "Dongsu Du",
      "Yuzong Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.12194",
    "title": "Neural Architecture Search Using Genetic Algorithm for Facial Expression  Recognition",
    "abstract": "Facial expression is one of the most powerful, natural, and universal signals for human beings to express emotional states and intentions. Thus, it is evident the importance of correct and innovative facial expression recognition (FER) approaches in Artificial Intelligence. The current common practice for FER is to correctly design convolutional neural networks' architectures (CNNs) using human expertise. However, finding a well-performing architecture is often a very tedious and error-prone process for deep learning researchers. Neural architecture search (NAS) is an area of growing interest as demonstrated by the large number of scientific works published in recent years thanks to the impressive results achieved in recent years. We propose a genetic algorithm approach that uses an ingenious encoding-decoding mechanism that allows to automatically evolve CNNs on FER tasks attaining high accuracy classification rates. The experimental results demonstrate that the proposed algorithm achieves the best-known results on the CK+ and FERG datasets as well as competitive results on the JAFFE dataset. ",
    "url": "https://arxiv.org/abs/2304.12194",
    "authors": [
      "Shuchao Deng",
      "Yanan Sun",
      "Edgar Galvan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12210",
    "title": "A Cookbook of Self-Supervised Learning",
    "abstract": "Self-supervised learning, dubbed the dark matter of intelligence, is a promising path to advance machine learning. Yet, much like cooking, training SSL methods is a delicate art with a high barrier to entry. While many components are familiar, successfully training a SSL method involves a dizzying set of choices from the pretext tasks to training hyper-parameters. Our goal is to lower the barrier to entry into SSL research by laying the foundations and latest SSL recipes in the style of a cookbook. We hope to empower the curious researcher to navigate the terrain of methods, understand the role of the various knobs, and gain the know-how required to explore how delicious SSL can be. ",
    "url": "https://arxiv.org/abs/2304.12210",
    "authors": [
      "Randall Balestriero",
      "Mark Ibrahim",
      "Vlad Sobal",
      "Ari Morcos",
      "Shashank Shekhar",
      "Tom Goldstein",
      "Florian Bordes",
      "Adrien Bardes",
      "Gregoire Mialon",
      "Yuandong Tian",
      "Avi Schwarzschild",
      "Andrew Gordon Wilson",
      "Jonas Geiping",
      "Quentin Garrido",
      "Pierre Fernandez",
      "Amir Bar",
      "Hamed Pirsiavash",
      "Yann LeCun",
      "Micah Goldblum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12212",
    "title": "An Efficient Built-in Temporal Support in MVCC-based Graph Databases",
    "abstract": "Real-world graphs are often dynamic and evolve over time. To trace the evolving properties of graphs, it is necessary to maintain every change of both vertices and edges in graph databases with the support of temporal features. Existing works either maintain all changes in a single graph or periodically materialize snapshots to maintain the historical states of each vertex and edge and process queries over proper snapshots. The former approach presents poor query performance due to the ever-growing graph size as time goes by, while the latter one suffers from prohibitively high storage overheads due to large redundant copies of graph data across different snapshots. In this paper, we propose a hybrid data storage engine, which is based on the MVCC mechanism, to separately manage current and historical data, which keeps the current graph as small as possible. In our design, changes in each vertex or edge are stored once. To further reduce the storage overhead, we simply store the changes as opposed to storing the complete snapshot. To boost the query performance, we place a few anchors as snapshots to avoid deep historical version traversals. Based on the storage engine, a temporal query engine is proposed to reconstruct subgraphs as needed on the fly. Therefore, our alternative approach can provide fast querying capabilities over subgraphs at a past time point or range with small storage overheads. To provide native support of temporal features, we integrate our approach into Memgraph, and call the extended database system TGDB(Temporal Graph Database). Extensive experiments are conducted on four real and synthetic datasets. The results show TGDB performs better in terms of both storage and performance against state-of-the-art methods and has almost no performance overheads by introducing the temporal features. ",
    "url": "https://arxiv.org/abs/2304.12212",
    "authors": [
      "Jiamin Hou",
      "Zhouyu Wang",
      "Zhanhao Zhao",
      "Wei Lu",
      "Xiaoyong Du"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2304.12214",
    "title": "Neurogenesis Dynamics-inspired Spiking Neural Network Training  Acceleration",
    "abstract": "Biologically inspired Spiking Neural Networks (SNNs) have attracted significant attention for their ability to provide extremely energy-efficient machine intelligence through event-driven operation and sparse activities. As artificial intelligence (AI) becomes ever more democratized, there is an increasing need to execute SNN models on edge devices. Existing works adopt weight pruning to reduce SNN model size and accelerate inference. However, these methods mainly focus on how to obtain a sparse model for efficient inference, rather than training efficiency. To overcome these drawbacks, in this paper, we propose a Neurogenesis Dynamics-inspired Spiking Neural Network training acceleration framework, NDSNN. Our framework is computational efficient and trains a model from scratch with dynamic sparsity without sacrificing model fidelity. Specifically, we design a new drop-and-grow strategy with decreasing number of non-zero weights, to maintain extreme high sparsity and high accuracy. We evaluate NDSNN using VGG-16 and ResNet-19 on CIFAR-10, CIFAR-100 and TinyImageNet. Experimental results show that NDSNN achieves up to 20.52\\% improvement in accuracy on Tiny-ImageNet using ResNet-19 (with a sparsity of 99\\%) as compared to other SOTA methods (e.g., Lottery Ticket Hypothesis (LTH), SET-SNN, RigL-SNN). In addition, the training cost of NDSNN is only 40.89\\% of the LTH training cost on ResNet-19 and 31.35\\% of the LTH training cost on VGG-16 on CIFAR-10. ",
    "url": "https://arxiv.org/abs/2304.12214",
    "authors": [
      "Shaoyi Huang",
      "Haowen Fang",
      "Kaleel Mahmood",
      "Bowen Lei",
      "Nuo Xu",
      "Bin Lei",
      "Yue Sun",
      "Dongkuan Xu",
      "Wujie Wen",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.12217",
    "title": "Impact-Oriented Contextual Scholar Profiling using Self-Citation Graphs",
    "abstract": "Quantitatively profiling a scholar's scientific impact is important to modern research society. Current practices with bibliometric indicators (e.g., h-index), lists, and networks perform well at scholar ranking, but do not provide structured context for scholar-centric, analytical tasks such as profile reasoning and understanding. This work presents GeneticFlow (GF), a suite of novel graph-based scholar profiles that fulfill three essential requirements: structured-context, scholar-centric, and evolution-rich. We propose a framework to compute GF over large-scale academic data sources with millions of scholars. The framework encompasses a new unsupervised advisor-advisee detection algorithm, a well-engineered citation type classifier using interpretable features, and a fine-tuned graph neural network (GNN) model. Evaluations are conducted on the real-world task of scientific award inference. Experiment outcomes show that the F1 score of best GF profile significantly outperforms alternative methods of impact indicators and bibliometric networks in all the 6 computer science fields considered. Moreover, the core GF profiles, with 63.6%-66.5% nodes and 12.5%-29.9% edges of the full profile, still significantly outrun existing methods in 5 out of 6 fields studied. Visualization of GF profiling result also reveals human explainable patterns for high-impact scholars. ",
    "url": "https://arxiv.org/abs/2304.12217",
    "authors": [
      "Yuankai Luo",
      "Lei Shi",
      "Mufan Xu",
      "Yuwen Ji",
      "Fengli Xiao",
      "Chunming Hu",
      "Zhiguang Shan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12219",
    "title": "Mono Video-Based AI Corridor for Model-Free Detection of  Collision-Relevant Obstacles",
    "abstract": "The detection of previously unseen, unexpected obstacles on the road is a major challenge for automated driving systems. Different from the detection of ordinary objects with pre-definable classes, detecting unexpected obstacles on the road cannot be resolved by upscaling the sensor technology alone (e.g., high resolution video imagers / radar antennas, denser LiDAR scan lines). This is due to the fact, that there is a wide variety in the types of unexpected obstacles that also do not share a common appearance (e.g., lost cargo as a suitcase or bicycle, tire fragments, a tree stem). Also adding object classes or adding \\enquote{all} of these objects to a common \\enquote{unexpected obstacle} class does not scale. In this contribution, we study the feasibility of using a deep learning video-based lane corridor (called \\enquote{AI ego-corridor}) to ease the challenge by inverting the problem: Instead of detecting a previously unseen object, the AI ego-corridor detects that the ego-lane ahead ends. A smart ground-truth definition enables an easy feature-based classification of an abrupt end of the ego-lane. We propose two neural network designs and research among other things the potential of training with synthetic data. We evaluate our approach on a test vehicle platform. It is shown that the approach is able to detect numerous previously unseen obstacles at a distance of up to 300 m with a detection rate of 95 %. ",
    "url": "https://arxiv.org/abs/2304.12219",
    "authors": [
      "Thomas Michalke",
      "Yassin Kaddar",
      "Thomas N\u00fcrnberg",
      "Linh K\u00e4stner",
      "Jens Lambrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.12228",
    "title": "Hierarchical Contrastive Learning Enhanced Heterogeneous Graph Neural  Network",
    "abstract": "Heterogeneous graph neural networks (HGNNs) as an emerging technique have shown superior capacity of dealing with heterogeneous information network (HIN). However, most HGNNs follow a semi-supervised learning manner, which notably limits their wide use in reality since labels are usually scarce in real applications. Recently, contrastive learning, a self-supervised method, becomes one of the most exciting learning paradigms and shows great potential when there are no labels. In this paper, we study the problem of self-supervised HGNNs and propose a novel co-contrastive learning mechanism for HGNNs, named HeCo. Different from traditional contrastive learning which only focuses on contrasting positive and negative samples, HeCo employs cross-view contrastive mechanism. Specifically, two views of a HIN (network schema and meta-path views) are proposed to learn node embeddings, so as to capture both of local and high-order structures simultaneously. Then the cross-view contrastive learning, as well as a view mask mechanism, is proposed, which is able to extract the positive and negative embeddings from two views. This enables the two views to collaboratively supervise each other and finally learn high-level node embeddings. Moreover, to further boost the performance of HeCo, two additional methods are designed to generate harder negative samples with high quality. Besides the invariant factors, view-specific factors complementally provide the diverse structure information between different nodes, which also should be contained into the final embeddings. Therefore, we need to further explore each view independently and propose a modified model, called HeCo++. Specifically, HeCo++ conducts hierarchical contrastive learning, including cross-view and intra-view contrasts, which aims to enhance the mining of respective structures. ",
    "url": "https://arxiv.org/abs/2304.12228",
    "authors": [
      "Nian Liu",
      "Xiao Wang",
      "Hui Han",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12244",
    "title": "WizardLM: Empowering Large Language Models to Follow Complex  Instructions",
    "abstract": "Training large language models (LLM) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM model are preferred to outputs from OpenAI ChatGPT. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing large language models. Our codes and generated data are public at https://github.com/nlpxucan/WizardLM ",
    "url": "https://arxiv.org/abs/2304.12244",
    "authors": [
      "Can Xu",
      "Qingfeng Sun",
      "Kai Zheng",
      "Xiubo Geng",
      "Pu Zhao",
      "Jiazhan Feng",
      "Chongyang Tao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12269",
    "title": "Enriching Source Code with Contextual Data for Code Completion Models:  An Empirical Study",
    "abstract": "Transformer-based pre-trained models have recently achieved great results in solving many software engineering tasks including automatic code completion which is a staple in a developer's toolkit. While many have striven to improve the code-understanding abilities of such models, the opposite -- making the code easier to understand -- has not been properly investigated. In this study, we aim to answer whether making code easier to understand through using contextual data improves the performance of pre-trained code language models for the task of code completion. We consider type annotations and comments as two common forms of additional contextual information that often help developers understand code better. For the experiments, we study code completion in two granularity levels; token and line completion and take three recent and large-scale language models for source code: UniXcoder, CodeGPT, and InCoder with five evaluation metrics. Finally, we perform the Wilcoxon Signed Rank test to gauge significance and measure the effect size. Contrary to our expectations, all models perform better if type annotations are removed (albeit the effect sizes are small). For comments, we find that the models perform better in the presence of multi-line comments (again with small effect sizes). Based on our observations, we recommend making proper design choices when training, fine-tuning, or simply selecting such models given the intended data and application. Better evaluations and multi-modal techniques can also be further investigated to improve the practicality and accuracy of auto-completions. ",
    "url": "https://arxiv.org/abs/2304.12269",
    "authors": [
      "Tim van Dam",
      "Maliheh Izadi",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.12281",
    "title": "HOSNeRF: Dynamic Human-Object-Scene Neural Radiance Fields from a Single  Video",
    "abstract": "We introduce HOSNeRF, a novel 360{\\deg} free-viewpoint rendering method that reconstructs neural radiance fields for dynamic human-object-scene from a single monocular in-the-wild video. Our method enables pausing the video at any frame and rendering all scene details (dynamic humans, objects, and backgrounds) from arbitrary viewpoints. The first challenge in this task is the complex object motions in human-object interactions, which we tackle by introducing the new object bones into the conventional human skeleton hierarchy to effectively estimate large object deformations in our dynamic human-object model. The second challenge is that humans interact with different objects at different times, for which we introduce two new learnable object state embeddings that can be used as conditions for learning our human-object representation and scene representation, respectively. Extensive experiments show that HOSNeRF significantly outperforms SOTA approaches on two challenging datasets by a large margin of 40% ~ 50% in terms of LPIPS. The code, data, and compelling examples of 360{\\deg} free-viewpoint renderings from single videos will be released in https://showlab.github.io/HOSNeRF. ",
    "url": "https://arxiv.org/abs/2304.12281",
    "authors": [
      "Jia-Wei Liu",
      "Yan-Pei Cao",
      "Tianyuan Yang",
      "Eric Zhongcong Xu",
      "Jussi Keppo",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12289",
    "title": "Moving Forward by Moving Backward: Embedding Action Impact over Action  Semantics",
    "abstract": "A common assumption when training embodied agents is that the impact of taking an action is stable; for instance, executing the \"move ahead\" action will always move the agent forward by a fixed distance, perhaps with some small amount of actuator-induced noise. This assumption is limiting; an agent may encounter settings that dramatically alter the impact of actions: a move ahead action on a wet floor may send the agent twice as far as it expects and using the same action with a broken wheel might transform the expected translation into a rotation. Instead of relying that the impact of an action stably reflects its pre-defined semantic meaning, we propose to model the impact of actions on-the-fly using latent embeddings. By combining these latent action embeddings with a novel, transformer-based, policy head, we design an Action Adaptive Policy (AAP). We evaluate our AAP on two challenging visual navigation tasks in the AI2-THOR and Habitat environments and show that our AAP is highly performant even when faced, at inference-time with missing actions and, previously unseen, perturbed action space. Moreover, we observe significant improvement in robustness against these actions when evaluating in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2304.12289",
    "authors": [
      "Kuo-Hao Zeng",
      "Luca Weihs",
      "Roozbeh Mottaghi",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.12294",
    "title": "Explicit Correspondence Matching for Generalizable Neural Radiance  Fields",
    "abstract": "We present a new generalizable NeRF method that is able to directly generalize to new unseen scenarios and perform novel view synthesis with as few as two source views. The key to our approach lies in the explicitly modeled correspondence matching information, so as to provide the geometry prior to the prediction of NeRF color and density for volume rendering. The explicit correspondence matching is quantified with the cosine similarity between image features sampled at the 2D projections of a 3D point on different views, which is able to provide reliable cues about the surface geometry. Unlike previous methods where image features are extracted independently for each view, we consider modeling the cross-view interactions via Transformer cross-attention, which greatly improves the feature matching quality. Our method achieves state-of-the-art results on different evaluation settings, with the experiments showing a strong correlation between our learned cosine feature similarity and volume density, demonstrating the effectiveness and superiority of our proposed method. Code is at https://github.com/donydchen/matchnerf ",
    "url": "https://arxiv.org/abs/2304.12294",
    "authors": [
      "Yuedong Chen",
      "Haofei Xu",
      "Qianyi Wu",
      "Chuanxia Zheng",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12298",
    "title": "BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor  Attacks to InstructGPT",
    "abstract": "Recently, ChatGPT has gained significant attention in research due to its ability to interact with humans effectively. The core idea behind this model is reinforcement learning (RL) fine-tuning, a new paradigm that allows language models to align with human preferences, i.e., InstructGPT. In this study, we propose BadGPT, the first backdoor attack against RL fine-tuning in language models. By injecting a backdoor into the reward model, the language model can be compromised during the fine-tuning stage. Our initial experiments on movie reviews, i.e., IMDB, demonstrate that an attacker can manipulate the generated text through BadGPT. ",
    "url": "https://arxiv.org/abs/2304.12298",
    "authors": [
      "Jiawen Shi",
      "Yixin Liu",
      "Pan Zhou",
      "Lichao Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.12300",
    "title": "Large-capacity and Flexible Video Steganography via Invertible Neural  Network",
    "abstract": "Video steganography is the art of unobtrusively concealing secret data in a cover video and then recovering the secret data through a decoding protocol at the receiver end. Although several attempts have been made, most of them are limited to low-capacity and fixed steganography. To rectify these weaknesses, we propose a Large-capacity and Flexible Video Steganography Network (LF-VSN) in this paper. For large-capacity, we present a reversible pipeline to perform multiple videos hiding and recovering through a single invertible neural network (INN). Our method can hide/recover 7 secret videos in/from 1 cover video with promising performance. For flexibility, we propose a key-controllable scheme, enabling different receivers to recover particular secret videos from the same cover video through specific keys. Moreover, we further improve the flexibility by proposing a scalable strategy in multiple videos hiding, which can hide variable numbers of secret videos in a cover video with a single model and a single training session. Extensive experiments demonstrate that with the significant improvement of the video steganography performance, our proposed LF-VSN has high security, large hiding capacity, and flexibility. The source code is available at https://github.com/MC-E/LF-VSN. ",
    "url": "https://arxiv.org/abs/2304.12300",
    "authors": [
      "Chong Mou",
      "Youmin Xu",
      "Jiechong Song",
      "Chen Zhao",
      "Bernard Ghanem",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.12303",
    "title": "Inoculation strategies for bounded degree graphs",
    "abstract": "We analyze a game-theoretic abstraction of epidemic containment played on an undirected graph $G$: each player is associated with a node in $G$ and can either acquire protection from a contagious process or risk infection. After decisions are made, an infection starts at a random node $v$ and propagates through all unprotected nodes reachable from $v$. It is known that the price of anarchy (PoA) in $n$-node graphs can be as large as $\\Theta(n)$. Our main result is a tight bound of order $\\sqrt{n\\Delta}$ on the PoA, where $\\Delta$ is the maximum degree of the graph. We also study additional factors that can reduce the PoA, such as higher thresholds for contagion and varying the costs of becoming infected vs. acquiring protection. ",
    "url": "https://arxiv.org/abs/2304.12303",
    "authors": [
      "Mason DiCicco",
      "Henry Poskanzer",
      "Daniel Reichman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2304.12310",
    "title": "Fully Sparse Fusion for 3D Object Detection",
    "abstract": "Currently prevalent multimodal 3D detection methods are built upon LiDAR-based detectors that usually use dense Bird's-Eye-View (BEV) feature maps. However, the cost of such BEV feature maps is quadratic to the detection range, making it not suitable for long-range detection. Fully sparse architecture is gaining attention as they are highly efficient in long-range perception. In this paper, we study how to effectively leverage image modality in the emerging fully sparse architecture. Particularly, utilizing instance queries, our framework integrates the well-studied 2D instance segmentation into the LiDAR side, which is parallel to the 3D instance segmentation part in the fully sparse detector. This design achieves a uniform query-based fusion framework in both the 2D and 3D sides while maintaining the fully sparse characteristic. Extensive experiments showcase state-of-the-art results on the widely used nuScenes dataset and the long-range Argoverse 2 dataset. Notably, the inference speed of the proposed method under the long-range LiDAR perception setting is 2.7 $\\times$ faster than that of other state-of-the-art multimodal 3D detection methods. Code will be released at \\url{https://github.com/BraveGroup/FullySparseFusion}. ",
    "url": "https://arxiv.org/abs/2304.12310",
    "authors": [
      "Yingyan Li",
      "Lue Fan",
      "Yang Liu",
      "Zehao Huang",
      "Yuntao Chen",
      "Naiyan Wang",
      "Zhaoxiang Zhang",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12315",
    "title": "Once Detected, Never Lost: Surpassing Human Performance in Offline LiDAR  based 3D Object Detection",
    "abstract": "This paper aims for high-performance offline LiDAR-based 3D object detection. We first observe that experienced human annotators annotate objects from a track-centric perspective. They first label the objects with clear shapes in a track, and then leverage the temporal coherence to infer the annotations of obscure objects. Drawing inspiration from this, we propose a high-performance offline detector in a track-centric perspective instead of the conventional object-centric perspective. Our method features a bidirectional tracking module and a track-centric learning module. Such a design allows our detector to infer and refine a complete track once the object is detected at a certain moment. We refer to this characteristic as \"onCe detecTed, neveR Lost\" and name the proposed system CTRL. Extensive experiments demonstrate the remarkable performance of our method, surpassing the human-level annotating accuracy and the previous state-of-the-art methods in the highly competitive Waymo Open Dataset without model ensemble. The code will be made publicly available at https://github.com/tusen-ai/SST. ",
    "url": "https://arxiv.org/abs/2304.12315",
    "authors": [
      "Lue Fan",
      "Yuxue Yang",
      "Yiming Mao",
      "Feng Wang",
      "Yuntao Chen",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.11168",
    "title": "Learning Self-Supervised Representations for Label Efficient  Cross-Domain Knowledge Transfer on Diabetic Retinopathy Fundus Images",
    "abstract": "This work presents a novel label-efficient selfsupervised representation learning-based approach for classifying diabetic retinopathy (DR) images in cross-domain settings. Most of the existing DR image classification methods are based on supervised learning which requires a lot of time-consuming and expensive medical domain experts-annotated data for training. The proposed approach uses the prior learning from the source DR image dataset to classify images drawn from the target datasets. The image representations learned from the unlabeled source domain dataset through contrastive learning are used to classify DR images from the target domain dataset. Moreover, the proposed approach requires a few labeled images to perform successfully on DR image classification tasks in cross-domain settings. The proposed work experiments with four publicly available datasets: EyePACS, APTOS 2019, MESSIDOR-I, and Fundus Images for self-supervised representation learning-based DR image classification in cross-domain settings. The proposed method achieves state-of-the-art results on binary and multiclassification of DR images, even in cross-domain settings. The proposed method outperforms the existing DR image binary and multi-class classification methods proposed in the literature. The proposed method is also validated qualitatively using class activation maps, revealing that the method can learn explainable image representations. The source code and trained models are published on GitHub. ",
    "url": "https://arxiv.org/abs/2304.11168",
    "authors": [
      "Ekta Gupta",
      "Varun Gupta",
      "Muskaan Chopra",
      "Prakash Chandra Chhipa",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11320",
    "title": "SAWU-Net: Spatial Attention Weighted Unmixing Network for Hyperspectral  Images",
    "abstract": "Hyperspectral unmixing is a critical yet challenging task in hyperspectral image interpretation. Recently, great efforts have been made to solve the hyperspectral unmixing task via deep autoencoders. However, existing networks mainly focus on extracting spectral features from mixed pixels, and the employment of spatial feature prior knowledge is still insufficient. To this end, we put forward a spatial attention weighted unmixing network, dubbed as SAWU-Net, which learns a spatial attention network and a weighted unmixing network in an end-to-end manner for better spatial feature exploitation. In particular, we design a spatial attention module, which consists of a pixel attention block and a window attention block to efficiently model pixel-based spectral information and patch-based spatial information, respectively. While in the weighted unmixing framework, the central pixel abundance is dynamically weighted by the coarse-grained abundances of surrounding pixels. In addition, SAWU-Net generates dynamically adaptive spatial weights through the spatial attention mechanism, so as to dynamically integrate surrounding pixels more effectively. Experimental results on real and synthetic datasets demonstrate the better accuracy and superiority of SAWU-Net, which reflects the effectiveness of the proposed spatial attention mechanism. ",
    "url": "https://arxiv.org/abs/2304.11320",
    "authors": [
      "Lin Qi",
      "Xuewen Qin",
      "Feng Gao",
      "Junyu Dong",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.11691",
    "title": "Covering multigraphs with bipartite graphs",
    "abstract": "Hansel's lemma states that $\\sum_{H\\in \\mathcal{H}}|H| \\geq n \\log_2 n$ holds where $\\mathcal{H}$ is a collection of bipartite graphs covering all the edges of $K_n$. We generalize this lemma to the corresponding multigraph covering problem and the graphon covering problem. We also prove an upper bound on $\\sum_{H\\in \\mathcal{H}}|H|$ which shows that our generalization is asymptotically tight in some sense. ",
    "url": "https://arxiv.org/abs/2304.11691",
    "authors": [
      "Jaehoon Kim",
      "Hyunwoo Lee"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2304.11783",
    "title": "UAV-Video-Based Rip Current Detection in Nearshore Areas",
    "abstract": "Rip currents pose a significant danger to those who visit beaches, as they can swiftly pull swimmers away from shore. Detecting these currents currently relies on costly equipment and is challenging to implement on a larger scale. The advent of unmanned aerial vehicles (UAVs) and camera technology, however, has made monitoring near-shore regions more accessible and scalable. This paper proposes a new framework for detecting rip currents using video-based methods that leverage optical flow estimation, offshore direction calculation, and temporal data fusion techniques. Through the analysis of videos from multiple beaches, including Palm Beach, Haulover, Ocean Reef Park, and South Beach, as well as YouTube footage, we demonstrate the efficacy of our approach, which aligns with human experts' annotations. ",
    "url": "https://arxiv.org/abs/2304.11783",
    "authors": [
      "Anchen Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.11795",
    "title": "Fractional eternal domination: securely distributing resources across a  network",
    "abstract": "This paper initiates the study of fractional eternal domination in graphs, a natural relaxation of the well-studied eternal domination problem. We study the connections to flows and linear programming in order to obtain results on the complexity of determining the fractional eternal domination number of a graph $G$, which we denote $\\gamma_{\\,\\textit{f}}^{\\infty}(G)$. We study the behaviour of $\\gamma_{\\,\\textit{f}}^{\\infty}(G)$ as it relates to other domination parameters. We also determine bounds on, and in some cases exact values for, $\\gamma_{\\,\\textit{f}}^{\\infty}(G)$ when $G$ is a member of one of a variety of important graph classes, including trees, split graphs, strongly chordal graphs, Kneser graphs, abelian Cayley graphs, and graph products. ",
    "url": "https://arxiv.org/abs/2304.11795",
    "authors": [
      "Fnu Devvrit",
      "Aaron Krim-Yee",
      "Nithish Kumar",
      "Gary MacGillivray",
      "Ben Seamone",
      "Virg\u00e9lot Virgile",
      "AnQi Xu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.11856",
    "title": "Portfolio Optimization using Predictive Auxiliary Classifier Generative  Adversarial Networks with Measuring Uncertainty",
    "abstract": "In financial engineering, portfolio optimization has been of consistent interest. Portfolio optimization is a process of modulating asset distributions to maximize expected returns and minimize risks. To obtain the expected returns, deep learning models have been explored in recent years. However, due to the deterministic nature of the models, it is difficult to consider the risk of portfolios because conventional deep learning models do not know how reliable their predictions can be. To address this limitation, this paper proposes a probabilistic model, namely predictive auxiliary classifier generative adversarial networks (PredACGAN). The proposed PredACGAN utilizes the characteristic of the ACGAN framework in which the output of the generator forms a distribution. While ACGAN has not been employed for predictive models and is generally utilized for image sample generation, this paper proposes a method to use the ACGAN structure for a probabilistic and predictive model. Additionally, an algorithm to use the risk measurement obtained by PredACGAN is proposed. In the algorithm, the assets that are predicted to be at high risk are eliminated from the investment universe at the rebalancing moment. Therefore, PredACGAN considers both return and risk to optimize portfolios. The proposed algorithm and PredACGAN have been evaluated with daily close price data of S&P 500 from 1990 to 2020. Experimental scenarios are assumed to rebalance the portfolios monthly according to predictions and risk measures with PredACGAN. As a result, a portfolio using PredACGAN exhibits 9.123% yearly returns and a Sharpe ratio of 1.054, while a portfolio without considering risk measures shows 1.024% yearly returns and a Sharpe ratio of 0.236 in the same scenario. Also, the maximum drawdown of the proposed portfolio is lower than the portfolio without PredACGAN. ",
    "url": "https://arxiv.org/abs/2304.11856",
    "authors": [
      "Jiwook Kim",
      "Minhyeok Lee"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2304.12073",
    "title": "The Game Chromatic Number of Complete Multipartite Graphs with No  Singletons",
    "abstract": "In this paper we investigate the game chromatic number for complete multipartite graphs. We devise several strategies for Alice, and one strategy for Bob, and we prove their optimality in all complete multipartite graphs with no singletons. All the strategies presented are computable in linear time, and the values of the game chromatic number depend directly only on the number and the sizes of sets in the partition. ",
    "url": "https://arxiv.org/abs/2304.12073",
    "authors": [
      "Pawe\u0142 Obszarski",
      "Krzysztof Turowski",
      "Hubert Zi\u0119ba"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.12085",
    "title": "Dangoron: Network Construction on Large-scale Time Series Data across  Sliding Windows",
    "abstract": "Complex networks represent system dynamics through the interactions of a set of anomalous time series. Consider the problem of computing correlations for highly correlated pairs of time series across sliding windows. Efficiently computing and updating the correlation matrix for user-defined sliding periods and thresholds enables large-scale time series network dynamics analysis. We introduce Dangoron, a framework for effectively identifying highly correlated pairs of time series over sliding windows and computing their exact correlation. By predicting dynamic correlation across sliding windows and pruning unrelated time series, Dangoron is at least an order of magnitude faster than a baseline. Additionally, we propose Tomborg, the first benchmark for the problem of correlation matrix computation. ",
    "url": "https://arxiv.org/abs/2304.12085",
    "authors": [
      "Yunlong Xu",
      "Peizhen Yang",
      "Zhengbin Tao"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2304.12200",
    "title": "SplitAMC: Split Learning for Robust Automatic Modulation Classification",
    "abstract": "Automatic modulation classification (AMC) is a technology that identifies a modulation scheme without prior signal information and plays a vital role in various applications, including cognitive radio and link adaptation. With the development of deep learning (DL), DL-based AMC methods have emerged, while most of them focus on reducing computational complexity in a centralized structure. This centralized learning-based AMC (CentAMC) violates data privacy in the aspect of direct transmission of client-side raw data. Federated learning-based AMC (FedeAMC) can bypass this issue by exchanging model parameters, but causes large resultant latency and client-side computational load. Moreover, both CentAMC and FedeAMC are vulnerable to large-scale noise occured in the wireless channel between the client and the server. To this end, we develop a novel AMC method based on a split learning (SL) framework, coined SplitAMC, that can achieve high accuracy even in poor channel conditions, while guaranteeing data privacy and low latency. In SplitAMC, each client can benefit from data privacy leakage by exchanging smashed data and its gradient instead of raw data, and has robustness to noise with the help of high scale of smashed data. Numerical evaluations validate that SplitAMC outperforms CentAMC and FedeAMC in terms of accuracy for all SNRs as well as latency. ",
    "url": "https://arxiv.org/abs/2304.12200",
    "authors": [
      "Jihoon Park",
      "Seungeun Oh",
      "Seong-Lyun Kim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.12239",
    "title": "Uni-QSAR: an Auto-ML Tool for Molecular Property Prediction",
    "abstract": "Recently deep learning based quantitative structure-activity relationship (QSAR) models has shown surpassing performance than traditional methods for property prediction tasks in drug discovery. However, most DL based QSAR models are restricted to limited labeled data to achieve better performance, and also are sensitive to model scale and hyper-parameters. In this paper, we propose Uni-QSAR, a powerful Auto-ML tool for molecule property prediction tasks. Uni-QSAR combines molecular representation learning (MRL) of 1D sequential tokens, 2D topology graphs, and 3D conformers with pretraining models to leverage rich representation from large-scale unlabeled data. Without any manual fine-tuning or model selection, Uni-QSAR outperforms SOTA in 21/22 tasks of the Therapeutic Data Commons (TDC) benchmark under designed parallel workflow, with an average performance improvement of 6.09\\%. Furthermore, we demonstrate the practical usefulness of Uni-QSAR in drug discovery domains. ",
    "url": "https://arxiv.org/abs/2304.12239",
    "authors": [
      "Zhifeng Gao",
      "Xiaohong Ji",
      "Guojiang Zhao",
      "Hongshuai Wang",
      "Hang Zheng",
      "Guolin Ke",
      "Linfeng Zhang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12299",
    "title": "Developing a cost-effective emulator for groundwater flow modeling using  deep neural operators",
    "abstract": "Current groundwater models face a significant challenge in their implementation due to heavy computational burdens. To overcome this, our work proposes a cost-effective emulator that efficiently and accurately forecasts the impact of abstraction in an aquifer. Our approach uses a deep neural operator (DeepONet) to learn operators that map between infinite-dimensional function spaces via deep neural networks. The goal is to infer the distribution of hydraulic head in a confined aquifer in the presence of a pumping well. We successfully tested the DeepONet on four problems, including two forward problems, an inverse analysis, and a nonlinear system. Additionally, we propose a novel extension of the DeepONet-based architecture to generate accurate predictions for varied hydraulic conductivity fields and pumping well locations that are unseen during training. Our emulator's predictions match the target data with excellent performance, demonstrating that the proposed model can act as an efficient and fast tool to support a range of tasks that require repetitive forward numerical simulations or inverse simulations of groundwater flow problems. Overall, our work provides a promising avenue for developing cost-effective and accurate groundwater models. ",
    "url": "https://arxiv.org/abs/2304.12299",
    "authors": [
      "Maria Luisa Taccari",
      "He Wang",
      "Somdatta Goswami",
      "Jonathan Nuttall",
      "Xiaohui Chen",
      "Peter K. Jimack"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:1901.09193",
    "title": "Scene Text Synthesis for Efficient and Effective Deep Network Training",
    "abstract": " Comments: This work has been merged into another project ",
    "url": "https://arxiv.org/abs/1901.09193",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Hongyuan Zhu",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.07356",
    "title": "Implicit Bias of Gradient Descent for Mean Squared Error Regression with  Two-Layer Wide Neural Networks",
    "abstract": " Comments: 97 pages, 14 figures. Added the discussion of SGD and implications to generalization ",
    "url": "https://arxiv.org/abs/2006.07356",
    "authors": [
      "Hui Jin",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.07066",
    "title": "Towards Realistic 3D Embedding via View Alignment",
    "abstract": " Comments: This work has been merged into another project ",
    "url": "https://arxiv.org/abs/2007.07066",
    "authors": [
      "Changgong Zhang",
      "Fangneng Zhan",
      "Shijian Lu",
      "Feiying Ma",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.02774",
    "title": "Robust Model Selection and Nearly-Proper Learning for GMMs",
    "abstract": " Title: Robust Model Selection and Nearly-Proper Learning for GMMs ",
    "url": "https://arxiv.org/abs/2106.02774",
    "authors": [
      "Jerry Li",
      "Allen Liu",
      "Ankur Moitra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.08574",
    "title": "A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues",
    "abstract": " Title: A Modulation Layer to Increase Neural Network Robustness Against Data  Quality Issues ",
    "url": "https://arxiv.org/abs/2107.08574",
    "authors": [
      "Mohamed Abdelhack",
      "Jiaming Zhang",
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Daniel Felsky",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2108.13097",
    "title": "A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods",
    "abstract": " Title: A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods ",
    "url": "https://arxiv.org/abs/2108.13097",
    "authors": [
      "Adam X. Yang",
      "Maxime Robeyns",
      "Edward Milsom",
      "Nandi Schoots",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.04684",
    "title": "Physics-informed neural networks for understanding shear migration of  particles in viscous flow",
    "abstract": " Comments: 19 pages, 9 figures; v2: minor updates & provided data accessibility statement; v3: accepted for publication in International Journal of Multiphase Flow ",
    "url": "https://arxiv.org/abs/2111.04684",
    "authors": [
      "Daihui Lu",
      "Ivan C. Christov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2111.10481",
    "title": "PatchCensor: Patch Robustness Certification for Transformers via  Exhaustive Testing",
    "abstract": " Comments: This paper has been accepted by ACM Transactions on Software Engineering and Methodology (TOSEM'23) in \"Continuous Special Section: AI and SE.\" Please include TOSEM for any citations ",
    "url": "https://arxiv.org/abs/2111.10481",
    "authors": [
      "Yuheng Huang",
      "Lei Ma",
      "Yuanchun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.01360",
    "title": "Probabilistic Approach for Road-Users Detection",
    "abstract": " Comments: This work has been accepted for publication as a REGULAR PAPER in the Transactions on Intelligent Transportation Systems-ITS ",
    "url": "https://arxiv.org/abs/2112.01360",
    "authors": [
      "G. Melotti",
      "W. Lu",
      "P. Conde",
      "D. Zhao",
      "A. Asvadi",
      "N. Gon\u00e7alves",
      "C. Premebida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05871",
    "title": "On Adversarial Robustness of Point Cloud Semantic Segmentation",
    "abstract": " Title: On Adversarial Robustness of Point Cloud Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2112.05871",
    "authors": [
      "Jiacen Xu",
      "Zhe Zhou",
      "Boyuan Feng",
      "Yufei Ding",
      "Zhou Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.13143",
    "title": "GREED: A Neural Framework for Learning Graph Distance Functions",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2112.13143",
    "authors": [
      "Rishabh Ranjan",
      "Siddharth Grover",
      "Sourav Medya",
      "Venkatesan Chakaravarthy",
      "Yogish Sabharwal",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01859",
    "title": "Robust PAC$^m$: Training Ensemble Models Under Misspecification and  Outliers",
    "abstract": " Title: Robust PAC$^m$: Training Ensemble Models Under Misspecification and  Outliers ",
    "url": "https://arxiv.org/abs/2203.01859",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone",
      "Marios Kountouris",
      "David Gesbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03549",
    "title": "Question-Answer Sentence Graph for Joint Modeling Answer Selection",
    "abstract": " Title: Question-Answer Sentence Graph for Joint Modeling Answer Selection ",
    "url": "https://arxiv.org/abs/2203.03549",
    "authors": [
      "Roshni G. Iyer",
      "Thuy Vu",
      "Alessandro Moschitti",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11316",
    "title": "Random vector functional link network: recent developments,  applications, and future directions",
    "abstract": " Title: Random vector functional link network: recent developments,  applications, and future directions ",
    "url": "https://arxiv.org/abs/2203.11316",
    "authors": [
      "A. K. Malik",
      "Ruobin Gao",
      "M.A. Ganaie",
      "M. Tanveer",
      "P.N. Suganthan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04792",
    "title": "Robust Fingerprint of Location Trajectories Under Differential Privacy",
    "abstract": " Title: Robust Fingerprint of Location Trajectories Under Differential Privacy ",
    "url": "https://arxiv.org/abs/2204.04792",
    "authors": [
      "Yuzhou Jiang",
      "Emre Yilmaz",
      "Erman Ayday"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.08952",
    "title": "Retrieval Enhanced Data Augmentation for Question Answering on Privacy  Policies",
    "abstract": " Comments: EACL 2023 ",
    "url": "https://arxiv.org/abs/2204.08952",
    "authors": [
      "Md Rizwan Parvez",
      "Jianfeng Chi",
      "Wasi Uddin Ahmad",
      "Yuan Tian",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.12420",
    "title": "Interpretable Battery Cycle Life Range Prediction Using Early  Degradation Data at Cell Level",
    "abstract": " Title: Interpretable Battery Cycle Life Range Prediction Using Early  Degradation Data at Cell Level ",
    "url": "https://arxiv.org/abs/2204.12420",
    "authors": [
      "Huang Zhang",
      "Yang Su",
      "Faisal Altaf",
      "Torsten Wik",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach",
    "abstract": " Title: Bridging Causal Reversibility and Time Reversibility: A Stochastic  Process Algebraic Approach ",
    "url": "https://arxiv.org/abs/2205.01420",
    "authors": [
      "Marco Bernardo",
      "Claudio A. Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.03670",
    "title": "Automated Algorithm Selection for Radar Network Configuration",
    "abstract": " Comments: Author-generated version of a paper in the proceedings of The Genetic and Evolutionary Computation Conference 2022 (GECCO 2022) ",
    "url": "https://arxiv.org/abs/2205.03670",
    "authors": [
      "Quentin Renau",
      "Johann Dreo",
      "Alain Peres",
      "Yann Semet",
      "Carola Doerr",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.06109",
    "title": "Equivariant quantum circuits for learning on weighted graphs",
    "abstract": " Comments: 17+3 pages, 10 figures, version accepted at journal ",
    "url": "https://arxiv.org/abs/2205.06109",
    "authors": [
      "Andrea Skolik",
      "Michele Cattelan",
      "Sheir Yarkoni",
      "Thomas B\u00e4ck",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14307",
    "title": "TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning  over Temporal Knowledge Graph",
    "abstract": " Title: TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning  over Temporal Knowledge Graph ",
    "url": "https://arxiv.org/abs/2205.14307",
    "authors": [
      "Xueyuan Lin",
      "Chengjin Xu",
      "Haihong E",
      "Fenglong Su",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Ningyuan Li",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14557",
    "title": "Frustratingly Easy Regularization on Representation Can Boost Deep  Reinforcement Learning",
    "abstract": " Comments: Accepted to CVPR23. Website: this https URL ",
    "url": "https://arxiv.org/abs/2205.14557",
    "authors": [
      "Qiang He",
      "Huangyuan Su",
      "Jieyu Zhang",
      "Xinwen Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.05437",
    "title": "ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle  Phase Transition",
    "abstract": " Comments: 26 pages, 5 figures. NeurIPS 2022 Workshop on GLFrontiers (Oral). ICLR 2023 (Spotlight) ",
    "url": "https://arxiv.org/abs/2206.05437",
    "authors": [
      "Yuelin Wang",
      "Kai Yi",
      "Xinliang Liu",
      "Yu Guang Wang",
      "Shi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2206.06602",
    "title": "Deep Isolation Forest for Anomaly Detection",
    "abstract": " Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE) ",
    "url": "https://arxiv.org/abs/2206.06602",
    "authors": [
      "Hongzuo Xu",
      "Guansong Pang",
      "Yijie Wang",
      "Yongjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02727",
    "title": "An Unsupervised STDP-based Spiking Neural Network Inspired By  Biologically Plausible Learning Rules and Connections",
    "abstract": " Title: An Unsupervised STDP-based Spiking Neural Network Inspired By  Biologically Plausible Learning Rules and Connections ",
    "url": "https://arxiv.org/abs/2207.02727",
    "authors": [
      "Yiting Dong",
      "Dongcheng Zhao",
      "Yang Li",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2207.03578",
    "title": "Code Translation with Compiler Representations",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2207.03578",
    "authors": [
      "Marc Szafraniec",
      "Baptiste Roziere",
      "Hugh Leather",
      "Francois Charton",
      "Patrick Labatut",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04785",
    "title": "SALSA: Attacking Lattice Cryptography with Transformers",
    "abstract": " Comments: Extended version of work published at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.04785",
    "authors": [
      "Emily Wenger",
      "Mingjie Chen",
      "Fran\u00e7ois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.11900",
    "title": "GA2MIF: Graph and Attention Based Two-Stage Multi-Source Information  Fusion for Conversational Emotion Detection",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2207.11900",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.12261",
    "title": "GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation  Approach for Multimodal Conversational Emotion Recognition",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2207.12261",
    "authors": [
      "Jiang Li",
      "Xiaoping Wang",
      "Guoqing Lv",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.03296",
    "title": "Accelerating discrete dislocation dynamics simulations with graph neural  networks",
    "abstract": " Title: Accelerating discrete dislocation dynamics simulations with graph neural  networks ",
    "url": "https://arxiv.org/abs/2208.03296",
    "authors": [
      "Nicolas Bertin",
      "Fei Zhou"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.03944",
    "title": "Robust and Imperceptible Black-box DNN Watermarking Based on Fourier  Perturbation Analysis and Frequency Sensitivity Clustering",
    "abstract": " Comments: this https URL&hl=en ",
    "url": "https://arxiv.org/abs/2208.03944",
    "authors": [
      "Yong Liu",
      "Hanzhou Wu",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.11197",
    "title": "Modelling Latent Dynamics of StyleGAN using Neural ODEs",
    "abstract": " Title: Modelling Latent Dynamics of StyleGAN using Neural ODEs ",
    "url": "https://arxiv.org/abs/2208.11197",
    "authors": [
      "Weihao Xia",
      "Yujiu Yang",
      "Jing-Hao Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.13692",
    "title": "Embedding Hindsight Reasoning in Separation Logic",
    "abstract": " Title: Embedding Hindsight Reasoning in Separation Logic ",
    "url": "https://arxiv.org/abs/2209.13692",
    "authors": [
      "Roland Meyer",
      "Thomas Wies",
      "Sebastian Wolff"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.01338",
    "title": "Learning to Collocate Visual-Linguistic Neural Modules for Image  Captioning",
    "abstract": " Comments: Accepted to IJCV. Codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2210.01338",
    "authors": [
      "Xu Yang",
      "Hanwang Zhang",
      "Chongyang Gao",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.04700",
    "title": "Bio-inspired Algorithms in the Optimisation of Wireless Sensor Networks",
    "abstract": " Comments: We will not continue this research ",
    "url": "https://arxiv.org/abs/2210.04700",
    "authors": [
      "Joana Matos",
      "Carine M. Rebello",
      "Erbet A. Costa",
      "Luana P. Queiroz",
      "Maria Joao B. Regufe",
      "Idelfonso B.R. Nogueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.05509",
    "title": "Finding the global semantic representation in GAN through Frechet Mean",
    "abstract": " Comments: 25 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2210.05509",
    "authors": [
      "Jaewoong Choi",
      "Geonho Hwang",
      "Hyunsoo Cho",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12361",
    "title": "MS-DCANet: A Novel Segmentation Network For Multi-Modality COVID-19  Medical Images",
    "abstract": " Title: MS-DCANet: A Novel Segmentation Network For Multi-Modality COVID-19  Medical Images ",
    "url": "https://arxiv.org/abs/2210.12361",
    "authors": [
      "Xiaoyu Pan",
      "Huazheng Zhu",
      "Jinglong Du",
      "Guangtao Hu",
      "Baoru Han",
      "Yuanyuan Jia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15578",
    "title": "GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs",
    "abstract": " Title: GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2210.15578",
    "authors": [
      "Dong Yang",
      "Peijun Qing",
      "Yang Li",
      "Haonan Lu",
      "Xiaodong Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.15741",
    "title": "Spatio-temporal predictive tasks for abnormal event detection in videos",
    "abstract": " Comments: Accepted at the 18th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2022 ",
    "url": "https://arxiv.org/abs/2210.15741",
    "authors": [
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.00381",
    "title": "An Empirical Study on Data Leakage and Generalizability of Link  Prediction Models for Issues and Commits",
    "abstract": " Title: An Empirical Study on Data Leakage and Generalizability of Link  Prediction Models for Issues and Commits ",
    "url": "https://arxiv.org/abs/2211.00381",
    "authors": [
      "Maliheh Izadi",
      "Pooya Rostami Mazrae",
      "Tom Mens",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00435",
    "title": "Spreading dynamics in networks under context-dependent behavior",
    "abstract": " Comments: 23 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2211.00435",
    "authors": [
      "Giulio Burgio",
      "Sergio G\u00f3mez",
      "Alex Arenas"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.05119",
    "title": "The $[1,0]$-twisted generalized Reed-Solomon code",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2211.04511 ",
    "url": "https://arxiv.org/abs/2211.05119",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.11082",
    "title": "DynIBaR: Neural Dynamic Image-Based Rendering",
    "abstract": " Comments: Award Candidate, CVPR 2023 Project page: dynibar.github.io ",
    "url": "https://arxiv.org/abs/2211.11082",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Forrester Cole",
      "Richard Tucker",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15279",
    "title": "Establishment of Neural Networks Robust to Label Noise",
    "abstract": " Comments: 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2211.15279",
    "authors": [
      "Pengwei Yang",
      "Chongyangzi Teng",
      "Jack George Mangos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15444",
    "title": "DAMO-YOLO : A Report on Real-Time Object Detection Design",
    "abstract": " Comments: Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2211.15444",
    "authors": [
      "Xianzhe Xu",
      "Yiqi Jiang",
      "Weihua Chen",
      "Yilun Huang",
      "Yuan Zhang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16199",
    "title": "Latent Graph Inference using Product Manifolds",
    "abstract": " Title: Latent Graph Inference using Product Manifolds ",
    "url": "https://arxiv.org/abs/2211.16199",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Anees Kazi",
      "Federico Barbero",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01995",
    "title": "Approximate Order-Preserving Pattern Mining for Time Series",
    "abstract": " Title: Approximate Order-Preserving Pattern Mining for Time Series ",
    "url": "https://arxiv.org/abs/2212.01995",
    "authors": [
      "Yan Li",
      "Jin Liu",
      "Yingchun Guo",
      "Jing Liu",
      "Youxi Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2212.03120",
    "title": "Towards a Better Understanding of the Characteristics of Fractal  Networks",
    "abstract": " Title: Towards a Better Understanding of the Characteristics of Fractal  Networks ",
    "url": "https://arxiv.org/abs/2212.03120",
    "authors": [
      "Enik\u0151 Zakar-Poly\u00e1k",
      "Marcell Nagy",
      "Roland Molontay"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2212.03475",
    "title": "PyGFI: Analyzing and Enhancing Robustness of Graph Neural Networks  Against Hardware Errors",
    "abstract": " Title: PyGFI: Analyzing and Enhancing Robustness of Graph Neural Networks  Against Hardware Errors ",
    "url": "https://arxiv.org/abs/2212.03475",
    "authors": [
      "Ruixuan Wang",
      "Fred Lin",
      "Daniel Moore",
      "Sriram Sankar",
      "Xun Jiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04679",
    "title": "Motion and Context-Aware Audio-Visual Conditioned Video Prediction",
    "abstract": " Comments: Under refinement ",
    "url": "https://arxiv.org/abs/2212.04679",
    "authors": [
      "Yating Xu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.11172",
    "title": "A recurrent CNN for online object detection on raw radar frames",
    "abstract": " Comments: 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2212.11172",
    "authors": [
      "Colin Decourt",
      "Rufin VanRullen",
      "Didier Salle",
      "Thomas Oberlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.14453",
    "title": "Learning Multimodal Data Augmentation in Feature Space",
    "abstract": " Comments: ICLR 2023. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2212.14453",
    "authors": [
      "Zichang Liu",
      "Zhiqiang Tang",
      "Xingjian Shi",
      "Aston Zhang",
      "Mu Li",
      "Anshumali Shrivastava",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14545",
    "title": "A Finite Element-Inspired Hypergraph Neural Network: Application to  Fluid Dynamics Simulations",
    "abstract": " Title: A Finite Element-Inspired Hypergraph Neural Network: Application to  Fluid Dynamics Simulations ",
    "url": "https://arxiv.org/abs/2212.14545",
    "authors": [
      "Rui Gao",
      "Indu Kant Deo",
      "Rajeev K. Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01395",
    "title": "COST of Graph Processing Using Actors",
    "abstract": " Title: COST of Graph Processing Using Actors ",
    "url": "https://arxiv.org/abs/2301.01395",
    "authors": [
      "Ronak Buch"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2301.02214",
    "title": "Automatic Sound Event Detection and Classification of Great Ape Calls  Using Neural Networks",
    "abstract": " Comments: Accepted at ICPhS 2023 (Poster) ",
    "url": "https://arxiv.org/abs/2301.02214",
    "authors": [
      "Zifan Jiang",
      "Adrian Soldati",
      "Isaac Schamberg",
      "Adriano R. Lameira",
      "Steven Moran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2301.06156",
    "title": "Least-Squares Neural Network (LSNN) Method For Linear Advection-Reaction  Equation: General Discontinuous Interface",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2301.06156",
    "authors": [
      "Zhiqiang Cai",
      "Junpyo Choi",
      "Min Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.07928",
    "title": "Hamiltonian Neural Networks with Automatic Symmetry Detection",
    "abstract": " Title: Hamiltonian Neural Networks with Automatic Symmetry Detection ",
    "url": "https://arxiv.org/abs/2301.07928",
    "authors": [
      "Eva Dierkes",
      "Christian Offen",
      "Sina Ober-Bl\u00f6baum",
      "Kathrin Fla\u00dfkamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2301.12185",
    "title": "Hybrid Cognition for Target Tracking in Cognitive Radar Networks",
    "abstract": " Comments: 34 pages, single-column, 10 figures ",
    "url": "https://arxiv.org/abs/2301.12185",
    "authors": [
      "William W. Howard",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.01259",
    "title": "Geometric Deep Learning for Autonomous Driving: Unlocking the Power of  Graph Neural Networks With CommonRoad-Geometric",
    "abstract": " Comments: Presented at IV 2023 ",
    "url": "https://arxiv.org/abs/2302.01259",
    "authors": [
      "Eivind Meyer",
      "Maurice Brenner",
      "Bowen Zhang",
      "Max Schickert",
      "Bilal Musani",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01769",
    "title": "GraphAGILE: An FPGA-based Overlay Accelerator for Low-latency GNN  Inference",
    "abstract": " Comments: 18pages ",
    "url": "https://arxiv.org/abs/2302.01769",
    "authors": [
      "Bingyi Zhang",
      "Hanqing Zeng",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2302.04614",
    "title": "SoK: A Data-driven View on Methods to Detect Reflective Amplification  DDoS Attacks Using Honeypots",
    "abstract": " Comments: camera-ready ",
    "url": "https://arxiv.org/abs/2302.04614",
    "authors": [
      "Marcin Nawrocki",
      "John Kristoff",
      "Raphael Hiesgen",
      "Chris Kanich",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.04747",
    "title": "An $O(\\log k)$-Approximation for Directed Steiner Tree in Planar Graphs",
    "abstract": " Title: An $O(\\log k)$-Approximation for Directed Steiner Tree in Planar Graphs ",
    "url": "https://arxiv.org/abs/2302.04747",
    "authors": [
      "Zachary Friggstad",
      "Ramin Mousavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.06086",
    "title": "Reliability Assurance for Deep Neural Network Architectures Against  Numerical Defects",
    "abstract": " Comments: To appear at 45th International Conference on Software Engineering (ICSE 2023), camera-ready version, tiny typo fixed ",
    "url": "https://arxiv.org/abs/2302.06086",
    "authors": [
      "Linyi Li",
      "Yuhao Zhang",
      "Luyao Ren",
      "Yingfei Xiong",
      "Tao Xie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2302.12420",
    "title": "An Iterative Classification and Semantic Segmentation Network for Old  Landslide Detection Using High-Resolution Remote Sensing Images",
    "abstract": " Title: An Iterative Classification and Semantic Segmentation Network for Old  Landslide Detection Using High-Resolution Remote Sensing Images ",
    "url": "https://arxiv.org/abs/2302.12420",
    "authors": [
      "Zili Lu",
      "Yuexing Peng",
      "Wei Li",
      "Junchuan Yu",
      "Daqing Ge",
      "Wei Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12971",
    "title": "BrainCLIP: Bridging Brain and Visual-Linguistic Representation via CLIP  for Generic Natural Visual Stimulus Decoding from fMRI",
    "abstract": " Comments: incomplete experiments ",
    "url": "https://arxiv.org/abs/2302.12971",
    "authors": [
      "Yulong Liu",
      "Yongqiang Ma",
      "Wei Zhou",
      "Guibo Zhu",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.00859",
    "title": "FuNVol: A Multi-Asset Implied Volatility Market Simulator using  Functional Principal Components and Neural SDEs",
    "abstract": " Comments: 32 pages, 13 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2303.00859",
    "authors": [
      "Vedant Choudhary",
      "Sebastian Jaimungal",
      "Maxime Bergeron"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.01194",
    "title": "UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data  Generation for Cross-Lingual Learning in Tweet Intimacy Prediction",
    "abstract": " Comments: Accepted at SemEval-2023 ",
    "url": "https://arxiv.org/abs/2303.01194",
    "authors": [
      "Andrianos Michail",
      "Stefanos Konstantinou",
      "Simon Clematide"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02384",
    "title": "Hierarchical Training of Deep Neural Networks Using Early Exiting",
    "abstract": " Comments: 11 pages, 9 figures, 1 Table ",
    "url": "https://arxiv.org/abs/2303.02384",
    "authors": [
      "Yamin Sepehri",
      "Pedram Pad",
      "Ahmet Caner Y\u00fcz\u00fcg\u00fcler",
      "Pascal Frossard",
      "L. Andrea Dunbar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.02468",
    "title": "Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for  Soft and Hard Label Prediction",
    "abstract": " Title: Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for  Soft and Hard Label Prediction ",
    "url": "https://arxiv.org/abs/2303.02468",
    "authors": [
      "Peyman Hosseini",
      "Mehran Hosseini",
      "Sana Sabah Al-Azzawi",
      "Marcus Liwicki",
      "Ignacio Castro",
      "Matthew Purver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03470",
    "title": "Partial-Information, Longitudinal Cyber Attacks on LiDAR in Autonomous  Vehicles",
    "abstract": " Title: Partial-Information, Longitudinal Cyber Attacks on LiDAR in Autonomous  Vehicles ",
    "url": "https://arxiv.org/abs/2303.03470",
    "authors": [
      "R. Spencer Hallyburton",
      "Qingzhao Zhang",
      "Z. Morley Mao",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06088",
    "title": "Improving Domain-Invariance in Self-Supervised Learning via Batch Styles  Standardization",
    "abstract": " Title: Improving Domain-Invariance in Self-Supervised Learning via Batch Styles  Standardization ",
    "url": "https://arxiv.org/abs/2303.06088",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08366",
    "title": "VENUS: A Geometrical Representation for Quantum State Visualization",
    "abstract": " Title: VENUS: A Geometrical Representation for Quantum State Visualization ",
    "url": "https://arxiv.org/abs/2303.08366",
    "authors": [
      "Shaolun Ruan",
      "Ribo Yuan",
      "Qiang Guan",
      "Yanna Lin",
      "Ying Mao",
      "Weiwen Jiang",
      "Zhepeng Wang",
      "Wei Xu",
      "Yong Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.09314",
    "title": "TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection",
    "abstract": " Comments: accepted at AAAI23 ",
    "url": "https://arxiv.org/abs/2303.09314",
    "authors": [
      "Linhao Zhang",
      "Li Jin",
      "Xian Sun",
      "Guangluan Xu",
      "Zequn Zhang",
      "Xiaoyu Li",
      "Nayu Liu",
      "Qing Liu",
      "Shiyao Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.11419",
    "title": "EPiC: Ensemble of Partial Point Clouds for Robust Classification",
    "abstract": " Title: EPiC: Ensemble of Partial Point Clouds for Robust Classification ",
    "url": "https://arxiv.org/abs/2303.11419",
    "authors": [
      "Meir Yossef Levi",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18058",
    "title": "Code Reviewer Recommendation for Architecture Violations: An Exploratory  Study",
    "abstract": " Comments: The 27th International Conference on Evaluation and Assessment in Software Engineering (EASE) ",
    "url": "https://arxiv.org/abs/2303.18058",
    "authors": [
      "Ruiyin Li",
      "Peng Liang",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.00167",
    "title": "Towards \"Anytime, Anywhere\" Community Learning and Engagement around the  Design of Public Sector AI",
    "abstract": " Title: Towards \"Anytime, Anywhere\" Community Learning and Engagement around the  Design of Public Sector AI ",
    "url": "https://arxiv.org/abs/2304.00167",
    "authors": [
      "Wesley Hanwen Deng",
      "Motahhare Eslami",
      "Kenneth Holstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.03294",
    "title": "What makes a good data augmentation for few-shot unsupervised image  anomaly detection?",
    "abstract": " Title: What makes a good data augmentation for few-shot unsupervised image  anomaly detection? ",
    "url": "https://arxiv.org/abs/2304.03294",
    "authors": [
      "Lingrui Zhang",
      "Shuheng Zhang",
      "Guoyang Xie",
      "Jiaqi Liu",
      "Hua Yan",
      "Jinbao Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03518",
    "title": "SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism  using Majority Voted Fine-Tuned Transformers",
    "abstract": " Comments: Accepted at The 17th International Workshop on Semantic Evaluation, ACL 2023 ",
    "url": "https://arxiv.org/abs/2304.03518",
    "authors": [
      "Sriya Rallabandi",
      "Sanchit Singhal",
      "Pratinav Seth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04099",
    "title": "Unsupervised Story Discovery from Continuous News Streams via Scalable  Thematic Embedding",
    "abstract": " Comments: Accepted by SIGIR'23 ",
    "url": "https://arxiv.org/abs/2304.04099",
    "authors": [
      "Susik Yoon",
      "Dongha Lee",
      "Yunyi Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04546",
    "title": "Kinship Representation Learning with Face Componential Relation",
    "abstract": " Title: Kinship Representation Learning with Face Componential Relation ",
    "url": "https://arxiv.org/abs/2304.04546",
    "authors": [
      "Weng-Tai Su",
      "Min-Hung Chen",
      "Chien-Yi Wang",
      "Shang-Hong Lai",
      "Trista Pei-Chun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04979",
    "title": "Desirable Properties of Heterogeneous Quorum Systems",
    "abstract": " Title: Desirable Properties of Heterogeneous Quorum Systems ",
    "url": "https://arxiv.org/abs/2304.04979",
    "authors": [
      "Xiao Li",
      "Eric Chan",
      "Mohsen Lesani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.05116",
    "title": "Evaluation of Differentially Constrained Motion Models for Graph-Based  Trajectory Prediction",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2304.05116",
    "authors": [
      "Theodor Westny",
      "Joel Oskarsson",
      "Bj\u00f6rn Olofsson",
      "Erik Frisk"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.07072",
    "title": "CornerFormer: Boosting Corner Representation for Fine-Grained Structured  Reconstruction",
    "abstract": " Title: CornerFormer: Boosting Corner Representation for Fine-Grained Structured  Reconstruction ",
    "url": "https://arxiv.org/abs/2304.07072",
    "authors": [
      "Hongbo Tian",
      "Yulong Li",
      "Linzhi Huang",
      "Yue Yang",
      "Xiangang Li",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.07724",
    "title": "MS-LSTM: Exploring Spatiotemporal Multiscale Representations in Video  Prediction Domain",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2206.03010 ",
    "url": "https://arxiv.org/abs/2304.07724",
    "authors": [
      "Zhifeng Ma",
      "Hao Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07928",
    "title": "Observability Blocking for Functional Privacy of Linear Dynamic Networks",
    "abstract": " Comments: Correct some references. Submitted to 2023 IEEE Conference on Decision and Control ",
    "url": "https://arxiv.org/abs/2304.07928",
    "authors": [
      "Yuan Zhang",
      "Ranbo Cheng",
      "Yuanqing Xia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.08429",
    "title": "Security and Privacy Issues for Urban Smart Traffic Infrastructure",
    "abstract": " Title: Security and Privacy Issues for Urban Smart Traffic Infrastructure ",
    "url": "https://arxiv.org/abs/2304.08429",
    "authors": [
      "Anubhab Baksi",
      "Ahmed Ibrahim Samir Khalil",
      "Anupam Chattopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.09015",
    "title": "PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict  Detection on Knowledge Graphs",
    "abstract": " Comments: Accepted by AAAI23 ",
    "url": "https://arxiv.org/abs/2304.09015",
    "authors": [
      "Jianhao Chen",
      "Junyang Ren",
      "Wentao Ding",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09462",
    "title": "Decentralized Multi-Agent Planning for Multirotors: a Fully Online and  Communication Latency Robust Approach",
    "abstract": " Title: Decentralized Multi-Agent Planning for Multirotors: a Fully Online and  Communication Latency Robust Approach ",
    "url": "https://arxiv.org/abs/2304.09462",
    "authors": [
      "Charbel Toumieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.10145",
    "title": "Can ChatGPT Reproduce Human-Generated Labels? A Study of Social  Computing Tasks",
    "abstract": " Title: Can ChatGPT Reproduce Human-Generated Labels? A Study of Social  Computing Tasks ",
    "url": "https://arxiv.org/abs/2304.10145",
    "authors": [
      "Yiming Zhu",
      "Peixian Zhang",
      "Ehsan-Ul Haq",
      "Pan Hui",
      "Gareth Tyson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.10244",
    "title": "Omni Aggregation Networks for Lightweight Image Super-Resolution",
    "abstract": " Comments: Accepted by CVPR2023. Code is available at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2304.10244",
    "authors": [
      "Hang Wang",
      "Xuanhong Chen",
      "Bingbing Ni",
      "Yutian Liu",
      "Jinfan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.10558",
    "title": "Using Z3 for Formal Modeling and Verification of FNN Global Robustness",
    "abstract": " Comments: Accepted By SEKE 2023 ",
    "url": "https://arxiv.org/abs/2304.10558",
    "authors": [
      "Yihao Zhang",
      "Zeming Wei",
      "Xiyue Zhang",
      "Meng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.10859",
    "title": "Text2Time: Transformer-based Article Time Period Prediction",
    "abstract": " Comments: 8 Pages ",
    "url": "https://arxiv.org/abs/2304.10859",
    "authors": [
      "Karthick Prasad Gunasekaran",
      "B Chase Babrich",
      "Saurabh Shirodkar",
      "Hee Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.10870",
    "title": "Ultra Sharp : Study of Single Image Super Resolution using Residual  Dense Network",
    "abstract": " Comments: 6 pages ",
    "url": "https://arxiv.org/abs/2304.10870",
    "authors": [
      "Karthick Prasad Gunasekaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.10970",
    "title": "Can GPT-4 Perform Neural Architecture Search?",
    "abstract": " Title: Can GPT-4 Perform Neural Architecture Search? ",
    "url": "https://arxiv.org/abs/2304.10970",
    "authors": [
      "Mingkai Zheng",
      "Xiu Su",
      "Shan You",
      "Fei Wang",
      "Chen Qian",
      "Chang Xu",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11116",
    "title": "Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via  Prompt Augmented by ChatGPT",
    "abstract": " Comments: 20 pages, 2 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2304.11116",
    "authors": [
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]