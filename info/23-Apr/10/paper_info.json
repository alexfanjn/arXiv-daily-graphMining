[
  {
    "id": "arXiv:2304.03288",
    "title": "VISHIEN-MAAT: Scrollytelling visualization design for explaining Siamese  Neural Network concept to non-technical users",
    "abstract": "The past decade has witnessed rapid progress in AI research since the breakthrough in deep learning. AI technology has been applied in almost every field; therefore, technical and non-technical end-users must understand these technologies to exploit them. However existing materials are designed for experts, but non-technical users need appealing materials that deliver complex ideas in easy-to-follow steps. One notable tool that fits such a profile is scrollytelling, an approach to storytelling that provides readers with a natural and rich experience at the reader's pace, along with in-depth interactive explanations of complex concepts. Hence, this work proposes a novel visualization design for creating a scrollytelling that can effectively explain an AI concept to non-technical users. As a demonstration of our design, we created a scrollytelling to explain the Siamese Neural Network for the visual similarity matching problem. Our approach helps create a visualization valuable for a short-timeline situation like a sales pitch. The results show that the visualization based on our novel design helps improve non-technical users' perception and machine learning concept knowledge acquisition compared to traditional materials like online articles. ",
    "url": "https://arxiv.org/abs/2304.03288",
    "authors": [
      "Noptanit Chotisarn",
      "Sarun Gulyanon",
      "Tianye Zhang",
      "Wei Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03294",
    "title": "What makes a good data augmentation for few-shot unsupervised image  anomaly detection?",
    "abstract": "Data augmentation is a promising technique for unsupervised anomaly detection in industrial applications, where the availability of positive samples is often limited due to factors such as commercial competition and sample collection difficulties. In this paper, how to effectively select and apply data augmentation methods for unsupervised anomaly detection is studied. The impact of various data augmentation methods on different anomaly detection algorithms is systematically investigated through experiments. The experimental results show that the performance of different industrial image anomaly detection (termed as IAD) algorithms is not significantly affected by the specific data augmentation method employed and that combining multiple data augmentation methods does not necessarily yield further improvements in the accuracy of anomaly detection, although it can achieve excellent results on specific methods. These findings provide useful guidance on selecting appropriate data augmentation methods for different requirements in IAD. ",
    "url": "https://arxiv.org/abs/2304.03294",
    "authors": [
      "Shuheng Zhang",
      "Lingrui Zhang",
      "Guoyang Xie",
      "Jiaqi Liu",
      "Hua Yan",
      "Jinbao Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03295",
    "title": "Automatic Detection of Reactions to Music via Earable Sensing",
    "abstract": "We present GrooveMeter, a novel system that automatically detects vocal and motion reactions to music via earable sensing and supports music engagement-aware applications. To this end, we use smart earbuds as sensing devices, which are already widely used for music listening, and devise reaction detection techniques by leveraging an inertial measurement unit (IMU) and a microphone on earbuds. To explore reactions in daily music-listening situations, we collect the first kind of dataset, MusicReactionSet, containing 926-minute-long IMU and audio data with 30 participants. With the dataset, we discover a set of unique challenges in detecting music listening reactions accurately and robustly using audio and motion sensing. We devise sophisticated processing pipelines to make reaction detection accurate and efficient. We present a comprehensive evaluation to examine the performance of reaction detection and system cost. It shows that GrooveMeter achieves the macro F1 scores of 0.89 for vocal reaction and 0.81 for motion reaction with leave-one-subject-out cross-validation. More importantly, GrooveMeter shows higher accuracy and robustness compared to alternative methods. We also show that our filtering approach reduces 50% or more of the energy overhead. Finally, we demonstrate the potential use cases through a case study. ",
    "url": "https://arxiv.org/abs/2304.03295",
    "authors": [
      "Euihyoek Lee",
      "Chulhong Min",
      "Jeaseung Lee",
      "Jin Yu",
      "Seungwoo Kang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03323",
    "title": "DSVAE: Interpretable Disentangled Representation for Synthetic Speech  Detection",
    "abstract": "Tools to generate high quality synthetic speech signal that is perceptually indistinguishable from speech recorded from human speakers are easily available. Several approaches have been proposed for detecting synthetic speech. Many of these approaches use deep learning methods as a black box without providing reasoning for the decisions they make. This limits the interpretability of these approaches. In this paper, we propose Disentangled Spectrogram Variational Auto Encoder (DSVAE) which is a two staged trained variational autoencoder that processes spectrograms of speech using disentangled representation learning to generate interpretable representations of a speech signal for detecting synthetic speech. DSVAE also creates an activation map to highlight the spectrogram regions that discriminate synthetic and bona fide human speech signals. We evaluated the representations obtained from DSVAE using the ASVspoof2019 dataset. Our experimental results show high accuracy (>98%) on detecting synthetic speech from 6 known and 10 out of 11 unknown speech synthesizers. We also visualize the representation obtained from DSVAE for 17 different speech synthesizers and verify that they are indeed interpretable and discriminate bona fide and synthetic speech from each of the synthesizers. ",
    "url": "https://arxiv.org/abs/2304.03323",
    "authors": [
      "Amit Kumar Singh Yadav",
      "Kratika Bhagtani",
      "Ziyue Xiang",
      "Paolo Bestagini",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03343",
    "title": "Spintronic Physical Reservoir for Autonomous Prediction and Long-Term  Household Energy Load Forecasting",
    "abstract": "In this study, we have shown autonomous long-term prediction with a spintronic physical reservoir. Due to the short-term memory property of the magnetization dynamics, non-linearity arises in the reservoir states which could be used for long-term prediction tasks using simple linear regression for online training. During the prediction stage, the output is directly fed to the input of the reservoir for autonomous prediction. We employ our proposed reservoir for the modeling of the chaotic time series such as Mackey-Glass and dynamic time-series data, such as household building energy loads. Since only the last layer of a RC needs to be trained with linear regression, it is well suited for learning in real time on edge devices. Here we show that a skyrmion based magnetic tunnel junction can potentially be used as a prototypical RC but any nanomagnetic magnetic tunnel junction with nonlinear magnetization behavior can implement such a RC. By comparing our spintronic physical RC approach with state-of-the-art energy load forecasting algorithms, such as LSTMs and RNNs, we conclude that the proposed framework presents good performance in achieving high predictions accuracy, while also requiring low memory and energy both of which are at a premium in hardware resource and power constrained edge applications. Further, the proposed approach is shown to require very small training datasets and at the same time being at least 16X energy efficient compared to the state-of-the-art sequence to sequence LSTM for accurate household load predictions. ",
    "url": "https://arxiv.org/abs/2304.03343",
    "authors": [
      "Walid Al Misba",
      "Harindra S. Mavikumbure",
      "Md Mahadi Rajib",
      "Daniel L. Marino",
      "Victor Cobilean",
      "Milos Manic",
      "Jayasimha Atulasimha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03344",
    "title": "Graph Collaborative Signals Denoising and Augmentation for  Recommendation",
    "abstract": "Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated. In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to the adjacency matrix. Our experiments demonstrate that the enhanced user-item interaction matrix with improved neighbors and lower density leads to significant benefits in graph-based recommendation. Moreover, we show that the inclusion of user-user and item-item correlations can improve recommendations for users with both abundant and insufficient interactions. The code is in \\url{https://github.com/zfan20/GraphDA}. ",
    "url": "https://arxiv.org/abs/2304.03344",
    "authors": [
      "Ziwei Fan",
      "Ke Xu",
      "Dong Zhang",
      "Hao Peng",
      "Jiawei Zhang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03351",
    "title": "Entity Graphs for Exploring Online Discourse",
    "abstract": "Vast amounts of human communication occurs online. These digital traces of natural human communication along with recent advances in natural language processing technology provide for computational analysis of these discussions. In the study of social networks the typical perspective is to view users as nodes and concepts as flowing through and among the user-nodes within the social network. In the present work we take the opposite perspective: we extract and organize massive amounts of group discussion into a concept space we call an entity graph where concepts and entities are static and human communicators move about the concept space via their conversations. Framed by this perspective we performed several experiments and comparative analysis on large volumes of online discourse from Reddit. In quantitative experiments, we found that discourse was difficult to predict, especially as the conversation carried on. We also developed an interactive tool to visually inspect conversation trails over the entity graph; although they were difficult to predict, we found that conversations, in general, tended to diverge to a vast swath of topics initially, but then tended to converge to simple and popular concepts as the conversation progressed. An application of the spreading activation function from the field of cognitive psychology also provided compelling visual narratives from the data. ",
    "url": "https://arxiv.org/abs/2304.03351",
    "authors": [
      "Nicholas Botzer",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.03365",
    "title": "Robust Decision-Focused Learning for Reward Transfer",
    "abstract": "Decision-focused (DF) model-based reinforcement learning has recently been introduced as a powerful algorithm which can focus on learning the MDP dynamics which are most relevant for obtaining high rewards. While this approach increases the performance of agents by focusing the learning towards optimizing for the reward directly, it does so by learning less accurate dynamics (from a MLE standpoint), and may thus be brittle to changes in the reward function. In this work, we develop the robust decision-focused (RDF) algorithm which leverages the non-identifiability of DF solutions to learn models which maximize expected returns while simultaneously learning models which are robust to changes in the reward function. We demonstrate on a variety of toy example and healthcare simulators that RDF significantly increases the robustness of DF to changes in the reward function, without decreasing the overall return the agent obtains. ",
    "url": "https://arxiv.org/abs/2304.03365",
    "authors": [
      "Abhishek Sharma",
      "Sonali Parbhoo",
      "Omer Gottesman",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03369",
    "title": "EGA-Depth: Efficient Guided Attention for Self-Supervised Multi-Camera  Depth Estimation",
    "abstract": "The ubiquitous multi-camera setup on modern autonomous vehicles provides an opportunity to construct surround-view depth. Existing methods, however, either perform independent monocular depth estimations on each camera or rely on computationally heavy self attention mechanisms. In this paper, we propose a novel guided attention architecture, EGA-Depth, which can improve both the efficiency and accuracy of self-supervised multi-camera depth estimation. More specifically, for each camera, we use its perspective view as the query to cross-reference its neighboring views to derive informative features for this camera view. This allows the model to perform attention only across views with considerable overlaps and avoid the costly computations of standard self-attention. Given its efficiency, EGA-Depth enables us to exploit higher-resolution visual features, leading to improved accuracy. Furthermore, EGA-Depth can incorporate more frames from previous time steps as it scales linearly w.r.t. the number of views and frames. Extensive experiments on two challenging autonomous driving benchmarks nuScenes and DDAD demonstrate the efficacy of our proposed EGA-Depth and show that it achieves the new state-of-the-art in self-supervised multi-camera depth estimation. ",
    "url": "https://arxiv.org/abs/2304.03369",
    "authors": [
      "Yunxiao Shi",
      "Hong Cai",
      "Amin Ansari",
      "Fatih Porikli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03370",
    "title": "Reliable Learning for Test-time Attacks and Distribution Shift",
    "abstract": "Machine learning algorithms are often used in environments which are not captured accurately even by the most carefully obtained training data, either due to the possibility of `adversarial' test-time attacks, or on account of `natural' distribution shift. For test-time attacks, we introduce and analyze a novel robust reliability guarantee, which requires a learner to output predictions along with a reliability radius $\\eta$, with the meaning that its prediction is guaranteed to be correct as long as the adversary has not perturbed the test point farther than a distance $\\eta$. We provide learners that are optimal in the sense that they always output the best possible reliability radius on any test point, and we characterize the reliable region, i.e. the set of points where a given reliability radius is attainable. We additionally analyze reliable learners under distribution shift, where the test points may come from an arbitrary distribution Q different from the training distribution P. For both cases, we bound the probability mass of the reliable region for several interesting examples, for linear separators under nearly log-concave and s-concave distributions, as well as for smooth boundary classifiers under smooth probability distributions. ",
    "url": "https://arxiv.org/abs/2304.03370",
    "authors": [
      "Maria-Florina Balcan",
      "Steve Hanneke",
      "Rattana Pukdee",
      "Dravyansh Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03372",
    "title": "TopNet: Transformer-based Object Placement Network for Image Compositing",
    "abstract": "We investigate the problem of automatically placing an object into a background image for image compositing. Given a background image and a segmented object, the goal is to train a model to predict plausible placements (location and scale) of the object for compositing. The quality of the composite image highly depends on the predicted location/scale. Existing works either generate candidate bounding boxes or apply sliding-window search using global representations from background and object images, which fail to model local information in background images. However, local clues in background images are important to determine the compatibility of placing the objects with certain locations/scales. In this paper, we propose to learn the correlation between object features and all local background features with a transformer module so that detailed information can be provided on all possible location/scale configurations. A sparse contrastive loss is further proposed to train our model with sparse supervision. Our new formulation generates a 3D heatmap indicating the plausibility of all location/scale combinations in one network forward pass, which is over 10 times faster than the previous sliding-window method. It also supports interactive search when users provide a pre-defined location or scale. The proposed method can be trained with explicit annotation or in a self-supervised manner using an off-the-shelf inpainting model, and it outperforms state-of-the-art methods significantly. The user study shows that the trained model generalizes well to real-world images with diverse challenging scenes and object categories. ",
    "url": "https://arxiv.org/abs/2304.03372",
    "authors": [
      "Sijie Zhu",
      "Zhe Lin",
      "Scott Cohen",
      "Jason Kuen",
      "Zhifei Zhang",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03374",
    "title": "Optimizing Neural Networks through Activation Function Discovery and  Automatic Weight Initialization",
    "abstract": "Automated machine learning (AutoML) methods improve upon existing models by optimizing various aspects of their design. While present methods focus on hyperparameters and neural network topologies, other aspects of neural network design can be optimized as well. To further the state of the art in AutoML, this dissertation introduces techniques for discovering more powerful activation functions and establishing more robust weight initialization for neural networks. These contributions improve performance, but also provide new perspectives on neural network optimization. First, the dissertation demonstrates that discovering solutions specialized to specific architectures and tasks gives better performance than reusing general approaches. Second, it shows that jointly optimizing different components of neural networks is synergistic, and results in better performance than optimizing individual components alone. Third, it demonstrates that learned representations are easier to optimize than hard-coded ones, creating further opportunities for AutoML. The dissertation thus makes concrete progress towards fully automatic machine learning in the future. ",
    "url": "https://arxiv.org/abs/2304.03374",
    "authors": [
      "Garrett Bingham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03376",
    "title": "Interpretable statistical representations of neural population dynamics  and geometry",
    "abstract": "The dynamics of neuron populations during diverse tasks often evolve on low-dimensional manifolds. However, it remains challenging to discern the contributions of geometry and dynamics for encoding relevant behavioural variables. Here, we introduce an unsupervised geometric deep learning framework for representing non-linear dynamical systems based on statistical distributions of local phase portrait features. Our method provides robust geometry-aware or geometry-agnostic representations for the unbiased comparison of dynamics based on measured trajectories. We demonstrate that our statistical representation can generalise across neural network instances to discriminate computational mechanisms, obtain interpretable embeddings of neural dynamics in a primate reaching task with geometric correspondence to hand kinematics, and develop a decoding algorithm with state-of-the-art accuracy. Our results highlight the importance of using the intrinsic manifold structure over temporal information to develop better decoding algorithms and assimilate data across experiments. ",
    "url": "https://arxiv.org/abs/2304.03376",
    "authors": [
      "Adam Gosztolai",
      "Robert L. Peach",
      "Alexis Arnaudon",
      "Mauricio Barahona",
      "Pierre Vandergheynst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2304.03378",
    "title": "Self-Supervised Video Similarity Learning",
    "abstract": "We introduce S$^2$VS, a video similarity learning approach with self-supervision. Self-Supervised Learning (SSL) is typically used to train deep models on a proxy task so as to have strong transferability on target tasks after fine-tuning. Here, in contrast to prior work, SSL is used to perform video similarity learning and address multiple retrieval and detection tasks at once with no use of labeled data. This is achieved by learning via instance-discrimination with task-tailored augmentations and the widely used InfoNCE loss together with an additional loss operating jointly on self-similarity and hard-negative similarity. We benchmark our method on tasks where video relevance is defined with varying granularity, ranging from video copies to videos depicting the same incident or event. We learn a single universal model that achieves state-of-the-art performance on all tasks, surpassing previously proposed methods that use labeled data. The code and pretrained models are publicly available at: \\url{https://github.com/gkordo/s2vs} ",
    "url": "https://arxiv.org/abs/2304.03378",
    "authors": [
      "Giorgos Kordopatis-Zilos",
      "Giorgos Tolias",
      "Christos Tzelepis",
      "Ioannis Kompatsiaris",
      "Ioannis Patras",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03382",
    "title": "Scalable Causal Discovery with Score Matching",
    "abstract": "This paper demonstrates how to discover the whole causal graph from the second derivative of the log-likelihood in observational non-linear additive Gaussian noise models. Leveraging scalable machine learning approaches to approximate the score function $\\nabla \\log p(\\mathbf{X})$, we extend the work of Rolland et al. (2022) that only recovers the topological order from the score and requires an expensive pruning step removing spurious edges among those admitted by the ordering. Our analysis leads to DAS (acronym for Discovery At Scale), a practical algorithm that reduces the complexity of the pruning by a factor proportional to the graph size. In practice, DAS achieves competitive accuracy with current state-of-the-art while being over an order of magnitude faster. Overall, our approach enables principled and scalable causal discovery, significantly lowering the compute bar. ",
    "url": "https://arxiv.org/abs/2304.03382",
    "authors": [
      "Francesco Montagna",
      "Nicoletta Noceti",
      "Lorenzo Rosasco",
      "Kun Zhang",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.03384",
    "title": "Beyond NeRF Underwater: Learning Neural Reflectance Fields for True  Color Correction of Marine Imagery",
    "abstract": "Underwater imagery often exhibits distorted coloration as a result of light-water interactions, which complicates the study of benthic environments in marine biology and geography. In this research, we propose an algorithm to restore the true color (albedo) in underwater imagery by jointly learning the effects of the medium and neural scene representations. Our approach models water effects as a combination of light attenuation with distance and backscattered light. The proposed neural scene representation is based on a neural reflectance field model, which learns albedos, normals, and volume densities of the underwater environment. We introduce a logistic regression model to separate water from the scene and apply distinct light physics during training. Our method avoids the need to estimate complex backscatter effects in water by employing several approximations, enhancing sampling efficiency and numerical stability during training. The proposed technique integrates underwater light effects into a volume rendering framework with end-to-end differentiability. Experimental results on both synthetic and real-world data demonstrate that our method effectively restores true color from underwater imagery, outperforming existing approaches in terms of color consistency. ",
    "url": "https://arxiv.org/abs/2304.03384",
    "authors": [
      "Tianyi Zhang",
      "Matthew Johnson-Roberson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.03385",
    "title": "Wide neural networks: From non-gaussian random fields at initialization  to the NTK geometry of training",
    "abstract": "Recent developments in applications of artificial neural networks with over $n=10^{14}$ parameters make it extremely important to study the large $n$ behaviour of such networks. Most works studying wide neural networks have focused on the infinite width $n \\to +\\infty$ limit of such networks and have shown that, at initialization, they correspond to Gaussian processes. In this work we will study their behavior for large, but finite $n$. Our main contributions are the following: (1) The computation of the corrections to Gaussianity in terms of an asymptotic series in $n^{-\\frac{1}{2}}$. The coefficients in this expansion are determined by the statistics of parameter initialization and by the activation function. (2) Controlling the evolution of the outputs of finite width $n$ networks, during training, by computing deviations from the limiting infinite width case (in which the network evolves through a linear flow). This improves previous estimates and yields sharper decay rates for the (finite width) NTK in terms of $n$, valid during the entire training procedure. As a corollary, we also prove that, with arbitrarily high probability, the training of sufficiently wide neural networks converges to a global minimum of the corresponding quadratic loss function. (3) Estimating how the deviations from Gaussianity evolve with training in terms of $n$. In particular, using a certain metric in the space of measures we find that, along training, the resulting measure is within $n^{-\\frac{1}{2}}(\\log n)^{1+}$ of the time dependent Gaussian process corresponding to the infinite width network (which is explicitly given by precomposing the initial Gaussian process with the linear flow corresponding to training in the infinite width limit). ",
    "url": "https://arxiv.org/abs/2304.03385",
    "authors": [
      "Lu\u00eds Carvalho",
      "Jo\u00e3o Lopes Costa",
      "Jos\u00e9 Mour\u00e3o",
      "Gon\u00e7alo Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2304.03387",
    "title": "From Social Engineering to Quantum Threats: Safeguarding User Wallets  with FailSafe",
    "abstract": "While cryptocurrencies have been rapidly gaining adoption, secure wallet interactions are still elusive for many users, which frequently leads to loss of funds. Here we propose an approach to securing interactions with cryptocurrency wallets for end-users. The approach called FailSafe consists of several defence-in-depth measures that can be applied near-term as well as a tool called qMig for aiding eventual quantum migration. ",
    "url": "https://arxiv.org/abs/2304.03387",
    "authors": [
      "Gennady Medvinsky",
      "Ben Livshits"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03388",
    "title": "EZClone: Improving DNN Model Extraction Attack via Shape Distillation  from GPU Execution Profiles",
    "abstract": "Deep Neural Networks (DNNs) have become ubiquitous due to their performance on prediction and classification problems. However, they face a variety of threats as their usage spreads. Model extraction attacks, which steal DNNs, endanger intellectual property, data privacy, and security. Previous research has shown that system-level side-channels can be used to leak the architecture of a victim DNN, exacerbating these risks. We propose two DNN architecture extraction techniques catering to various threat models. The first technique uses a malicious, dynamically linked version of PyTorch to expose a victim DNN architecture through the PyTorch profiler. The second, called EZClone, exploits aggregate (rather than time-series) GPU profiles as a side-channel to predict DNN architecture, employing a simple approach and assuming little adversary capability as compared to previous work. We investigate the effectiveness of EZClone when minimizing the complexity of the attack, when applied to pruned models, and when applied across GPUs. We find that EZClone correctly predicts DNN architectures for the entire set of PyTorch vision architectures with 100% accuracy. No other work has shown this degree of architecture prediction accuracy with the same adversarial constraints or using aggregate side-channel information. Prior work has shown that, once a DNN has been successfully cloned, further attacks such as model evasion or model inversion can be accelerated significantly. ",
    "url": "https://arxiv.org/abs/2304.03388",
    "authors": [
      "Jonah O'Brien Weiss",
      "Tiago Alves",
      "Sandip Kundu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03394",
    "title": "Deep Learning for Opinion Mining and Topic Classification of Course  Reviews",
    "abstract": "Student opinions for a course are important to educators and administrators, regardless of the type of the course or the institution. Reading and manually analyzing open-ended feedback becomes infeasible for massive volumes of comments at institution level or online forums. In this paper, we collected and pre-processed a large number of course reviews publicly available online. We applied machine learning techniques with the goal to gain insight into student sentiments and topics. Specifically, we utilized current Natural Language Processing (NLP) techniques, such as word embeddings and deep neural networks, and state-of-the-art BERT (Bidirectional Encoder Representations from Transformers), RoBERTa (Robustly optimized BERT approach) and XLNet (Generalized Auto-regression Pre-training). We performed extensive experimentation to compare these techniques versus traditional approaches. This comparative study demonstrates how to apply modern machine learning approaches for sentiment polarity extraction and topic-based classification utilizing course feedback. For sentiment polarity, the top model was RoBERTa with 95.5\\% accuracy and 84.7\\% F1-macro, while for topic classification, an SVM (Support Vector Machine) was the top classifier with 79.8\\% accuracy and 80.6\\% F1-macro. We also provided an in-depth exploration of the effect of certain hyperparameters on the model performance and discussed our observations. These findings can be used by institutions and course providers as a guide for analyzing their own course feedback using NLP models towards self-evaluation and improvement. ",
    "url": "https://arxiv.org/abs/2304.03394",
    "authors": [
      "Anna Koufakou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03400",
    "title": "RoSteALS: Robust Steganography using Autoencoder Latent Space",
    "abstract": "Data hiding such as steganography and invisible watermarking has important applications in copyright protection, privacy-preserved communication and content provenance. Existing works often fall short in either preserving image quality, or robustness against perturbations or are too complex to train. We propose RoSteALS, a practical steganography technique leveraging frozen pretrained autoencoders to free the payload embedding from learning the distribution of cover images. RoSteALS has a light-weight secret encoder of just 300k parameters, is easy to train, has perfect secret recovery performance and comparable image quality on three benchmarks. Additionally, RoSteALS can be adapted for novel cover-less steganography applications in which the cover image can be sampled from noise or conditioned on text prompts via a denoising diffusion process. Our model and code are available at \\url{https://github.com/TuBui/RoSteALS}. ",
    "url": "https://arxiv.org/abs/2304.03400",
    "authors": [
      "Tu Bui",
      "Shruti Agarwal",
      "Ning Yu",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03401",
    "title": "CAPOT: Creating Robust Dense Query Encoders using Post Training  Contrastive Alignment",
    "abstract": "The success of contextual word representations and advances in neural information retrieval have made dense vector-based retrieval a standard approach for passage and document ranking. While effective and efficient, dual-encoders are brittle to variations in query distributions and noisy queries. Data augmentation can make models more robust but introduces overhead to training set generation and requires retraining and index regeneration. We present Contrastive Alignment POst Training (CAPOT), a highly efficient finetuning method that improves model robustness without requiring index regeneration, the training set optimization, or alteration. CAPOT enables robust retrieval by freezing the document encoder while the query encoder learns to align noisy queries with their unaltered root. We evaluate CAPOT noisy variants of MSMARCO, Natural Questions, and Trivia QA passage retrieval, finding CAPOT has a similar impact as data augmentation with none of its overhead. ",
    "url": "https://arxiv.org/abs/2304.03401",
    "authors": [
      "Daniel Campos",
      "ChengXiang Zhai",
      "Alessandro Magnani"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.03406",
    "title": "Localized Region Contrast for Enhancing Self-Supervised Learning in  Medical Image Segmentation",
    "abstract": "Recent advancements in self-supervised learning have demonstrated that effective visual representations can be learned from unlabeled images. This has led to increased interest in applying self-supervised learning to the medical domain, where unlabeled images are abundant and labeled images are difficult to obtain. However, most self-supervised learning approaches are modeled as image level discriminative or generative proxy tasks, which may not capture the finer level representations necessary for dense prediction tasks like multi-organ segmentation. In this paper, we propose a novel contrastive learning framework that integrates Localized Region Contrast (LRC) to enhance existing self-supervised pre-training methods for medical image segmentation. Our approach involves identifying Super-pixels by Felzenszwalb's algorithm and performing local contrastive learning using a novel contrastive sampling loss. Through extensive experiments on three multi-organ segmentation datasets, we demonstrate that integrating LRC to an existing self-supervised method in a limited annotation setting significantly improves segmentation performance. Moreover, we show that LRC can also be applied to fully-supervised pre-training methods to further boost performance. ",
    "url": "https://arxiv.org/abs/2304.03406",
    "authors": [
      "Xiangyi Yan",
      "Junayed Naushad",
      "Chenyu You",
      "Hao Tang",
      "Shanlin Sun",
      "Kun Han",
      "Haoyu Ma",
      "James Duncan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03420",
    "title": "Toward Unsupervised 3D Point Cloud Anomaly Detection using Variational  Autoencoder",
    "abstract": "In this paper, we present an end-to-end unsupervised anomaly detection framework for 3D point clouds. To the best of our knowledge, this is the first work to tackle the anomaly detection task on a general object represented by a 3D point cloud. We propose a deep variational autoencoder-based unsupervised anomaly detection network adapted to the 3D point cloud and an anomaly score specifically for 3D point clouds. To verify the effectiveness of the model, we conducted extensive experiments on the ShapeNet dataset. Through quantitative and qualitative evaluation, we demonstrate that the proposed method outperforms the baseline method. Our code is available at https://github.com/llien30/point_cloud_anomaly_detection. ",
    "url": "https://arxiv.org/abs/2304.03420",
    "authors": [
      "Mana Masuda",
      "Ryo Hachiuma",
      "Ryo Fujii",
      "Hideo Saito",
      "Yusuke Sekikawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03427",
    "title": "Cleansing Jewel: A Neural Spelling Correction Model Built On Google  OCR-ed Tibetan Manuscripts",
    "abstract": "Scholars in the humanities rely heavily on ancient manuscripts to study history, religion, and socio-political structures in the past. Many efforts have been devoted to digitizing these precious manuscripts using OCR technology, but most manuscripts were blemished over the centuries so that an Optical Character Recognition (OCR) program cannot be expected to capture faded graphs and stains on pages. This work presents a neural spelling correction model built on Google OCR-ed Tibetan Manuscripts to auto-correct OCR-ed noisy output. This paper is divided into four sections: dataset, model architecture, training and analysis. First, we feature-engineered our raw Tibetan etext corpus into two sets of structured data frames -- a set of paired toy data and a set of paired real data. Then, we implemented a Confidence Score mechanism into the Transformer architecture to perform spelling correction tasks. According to the Loss and Character Error Rate, our Transformer + Confidence score mechanism architecture proves to be superior to Transformer, LSTM-2-LSTM and GRU-2-GRU architectures. Finally, to examine the robustness of our model, we analyzed erroneous tokens, visualized Attention and Self-Attention heatmaps in our model. ",
    "url": "https://arxiv.org/abs/2304.03427",
    "authors": [
      "Queenie Luo",
      "Yung-Sung Chuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03428",
    "title": "TinyDet: Accurate Small Object Detection in Lightweight Generic  Detectors",
    "abstract": "Small object detection requires the detection head to scan a large number of positions on image feature maps, which is extremely hard for computation- and energy-efficient lightweight generic detectors. To accurately detect small objects with limited computation, we propose a two-stage lightweight detection framework with extremely low computation complexity, termed as TinyDet. It enables high-resolution feature maps for dense anchoring to better cover small objects, proposes a sparsely-connected convolution for computation reduction, enhances the early stage features in the backbone, and addresses the feature misalignment problem for accurate small object detection. On the COCO benchmark, our TinyDet-M achieves 30.3 AP and 13.5 AP^s with only 991 MFLOPs, which is the first detector that has an AP over 30 with less than 1 GFLOPs; besides, TinyDet-S and TinyDet-L achieve promising performance under different computation limitation. ",
    "url": "https://arxiv.org/abs/2304.03428",
    "authors": [
      "Shaoyu Chen",
      "Tianheng Cheng",
      "Jiemin Fang",
      "Qian Zhang",
      "Yuan Li",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03431",
    "title": "Domain Generalization In Robust Invariant Representation",
    "abstract": "Unsupervised approaches for learning representations invariant to common transformations are used quite often for object recognition. Learning invariances makes models more robust and practical to use in real-world scenarios. Since data transformations that do not change the intrinsic properties of the object cause the majority of the complexity in recognition tasks, models that are invariant to these transformations help reduce the amount of training data required. This further increases the model's efficiency and simplifies training. In this paper, we investigate the generalization of invariant representations on out-of-distribution data and try to answer the question: Do model representations invariant to some transformations in a particular seen domain also remain invariant in previously unseen domains? Through extensive experiments, we demonstrate that the invariant model learns unstructured latent representations that are robust to distribution shifts, thus making invariance a desirable property for training in resource-constrained settings. ",
    "url": "https://arxiv.org/abs/2304.03431",
    "authors": [
      "Gauri Gupta",
      "Ritvik Kapila",
      "Keshav Gupta",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03434",
    "title": "Opinion Mining from YouTube Captions Using ChatGPT: A Case Study of  Street Interviews Polling the 2023 Turkish Elections",
    "abstract": "Opinion mining plays a critical role in understanding public sentiment and preferences, particularly in the context of political elections. Traditional polling methods, while useful, can be expensive and less scalable. Social media offers an alternative source of data for opinion mining but presents challenges such as noise, biases, and platform limitations in data collection. In this paper, we propose a novel approach for opinion mining, utilizing YouTube's auto-generated captions from public interviews as a data source, specifically focusing on the 2023 Turkish elections as a case study. We introduce an opinion mining framework using ChatGPT to mass-annotate voting intentions and motivations that represent the stance and frames prior to the election. We report that ChatGPT can predict the preferred candidate with 97\\% accuracy and identify the correct voting motivation out of 13 possible choices with 71\\% accuracy based on the data collected from 325 interviews. We conclude by discussing the robustness of our approach, accounting for factors such as captions quality, interview length, and channels. This new method will offer a less noisy and cost-effective alternative for opinion mining using social media data. ",
    "url": "https://arxiv.org/abs/2304.03434",
    "authors": [
      "Tu\u011frulcan Elmas",
      "\u0130lker G\u00fcl"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.03440",
    "title": "Supervised Contrastive Learning with Heterogeneous Similarity for  Distribution Shifts",
    "abstract": "Distribution shifts are problems where the distribution of data changes between training and testing, which can significantly degrade the performance of a model deployed in the real world. Recent studies suggest that one reason for the degradation is a type of overfitting, and that proper regularization can mitigate the degradation, especially when using highly representative models such as neural networks. In this paper, we propose a new regularization using the supervised contrastive learning to prevent such overfitting and to train models that do not degrade their performance under the distribution shifts. We extend the cosine similarity in contrastive loss to a more general similarity measure and propose to use different parameters in the measure when comparing a sample to a positive or negative example, which is analytically shown to act as a kind of margin in contrastive loss. Experiments on benchmark datasets that emulate distribution shifts, including subpopulation shift and domain generalization, demonstrate the advantage of the proposed method over existing regularization methods. ",
    "url": "https://arxiv.org/abs/2304.03440",
    "authors": [
      "Takuro Kutsuna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.03441",
    "title": "Large-Scale Analysis of New Employee Network Dynamics",
    "abstract": "The COVID-19 pandemic has accelerated digital transformations across industries, but also introduced new challenges into workplaces, including the difficulties of effectively socializing with colleagues when working remotely. This challenge is exacerbated for new employees who need to develop workplace networks from the outset. In this paper, by analyzing a large-scale telemetry dataset of more than 10,000 Microsoft employees who joined the company in the first three months of 2022, we describe how new employees interact and telecommute with their colleagues during their ``onboarding'' period. Our results reveal that although new hires are gradually expanding networks over time, there still exists significant gaps between their network statistics and those of tenured employees even after the six-month onboarding phase. We also observe that heterogeneity exists among new employees in how their networks change over time, where employees whose job tasks do not necessarily require extensive and diverse connections could be at a disadvantaged position in this onboarding process. By investigating how web-based people recommendations in organizational knowledge base facilitate new employees naturally expand their networks, we also demonstrate the potential of web-based applications for addressing the aforementioned socialization challenges. Altogether, our findings provide insights on new employee network dynamics in remote and hybrid work environments, which may help guide organizational leaders and web application developers on quantifying and improving the socialization experiences of new employees in digital workplaces. ",
    "url": "https://arxiv.org/abs/2304.03441",
    "authors": [
      "Yulin Yu",
      "Longqi Yang",
      "Si\u00e2n Lindley",
      "Mengting Wan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2304.03443",
    "title": "AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of  Drones",
    "abstract": "Safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. This paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (AMS-DRL), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. Our approach guarantees convergence by ensuring Nash Equilibrium among agents from the game-theory analysis. We evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. We also analyze how parameters such as the relative maximum speed affect navigation performance. Furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. A success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. Project website: https://github.com/NTU-UAVG/AMS-DRL-for-Pursuit-Evasion. ",
    "url": "https://arxiv.org/abs/2304.03443",
    "authors": [
      "Jiaping Xiao",
      "Mir Feroskhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03446",
    "title": "Exploring Collaborative Distributed Diffusion-Based AI-Generated Content  (AIGC) in Wireless Networks",
    "abstract": "Driven by advances in generative artificial intelligence (AI) techniques and algorithms, the widespread adoption of AI-generated content (AIGC) has emerged, allowing for the generation of diverse and high-quality content. Especially, the diffusion model-based AIGC technique has been widely used to generate content in a variety of modalities. However, the real-world implementation of AIGC models, particularly on resource-constrained devices such as mobile phones, introduces significant challenges related to energy consumption and privacy concerns. To further promote the realization of ubiquitous AIGC services, we propose a novel collaborative distributed diffusion-based AIGC framework. By capitalizing on collaboration among devices in wireless networks, the proposed framework facilitates the efficient execution of AIGC tasks, optimizing edge computation resource utilization. Furthermore, we examine the practical implementation of the denoising steps on mobile phones, the impact of the proposed approach on the wireless network-aided AIGC landscape, and the future opportunities associated with its real-world integration. The contributions of this paper not only offer a promising solution to the existing limitations of AIGC services but also pave the way for future research in device collaboration, resource optimization, and the seamless delivery of AIGC services across various devices. Our code is available at https://github.com/HongyangDu/DistributedDiffusion. ",
    "url": "https://arxiv.org/abs/2304.03446",
    "authors": [
      "Hongyang Du",
      "Ruichen Zhang",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Dong In Kim",
      "Xuemin",
      "Shen",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.03452",
    "title": "Graph Enabled Cross-Domain Knowledge Transfer",
    "abstract": "To leverage machine learning in any decision-making process, one must convert the given knowledge (for example, natural language, unstructured text) into representation vectors that can be understood and processed by machine learning model in their compatible language and data format. The frequently encountered difficulty is, however, the given knowledge is not rich or reliable enough in the first place. In such cases, one seeks to fuse side information from a separate domain to mitigate the gap between good representation learning and the scarce knowledge in the domain of interest. This approach is named Cross-Domain Knowledge Transfer. It is crucial to study the problem because of the commonality of scarce knowledge in many scenarios, from online healthcare platform analyses to financial market risk quantification, leaving an obstacle in front of us benefiting from automated decision making. From the machine learning perspective, the paradigm of semi-supervised learning takes advantage of large amount of data without ground truth and achieves impressive learning performance improvement. It is adopted in this dissertation for cross-domain knowledge transfer. (to be continued) ",
    "url": "https://arxiv.org/abs/2304.03452",
    "authors": [
      "Shibo Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03456",
    "title": "Rethinking Evaluation Protocols of Visual Representations Learned via  Self-supervised Learning",
    "abstract": "Linear probing (LP) (and $k$-NN) on the upstream dataset with labels (e.g., ImageNet) and transfer learning (TL) to various downstream datasets are commonly employed to evaluate the quality of visual representations learned via self-supervised learning (SSL). Although existing SSL methods have shown good performances under those evaluation protocols, we observe that the performances are very sensitive to the hyperparameters involved in LP and TL. We argue that this is an undesirable behavior since truly generic representations should be easily adapted to any other visual recognition task, i.e., the learned representations should be robust to the settings of LP and TL hyperparameters. In this work, we try to figure out the cause of performance sensitivity by conducting extensive experiments with state-of-the-art SSL methods. First, we find that input normalization for LP is crucial to eliminate performance variations according to the hyperparameters. Specifically, batch normalization before feeding inputs to a linear classifier considerably improves the stability of evaluation, and also resolves inconsistency of $k$-NN and LP metrics. Second, for TL, we demonstrate that a weight decay parameter in SSL significantly affects the transferability of learned representations, which cannot be identified by LP or $k$-NN evaluations on the upstream dataset. We believe that the findings of this study will be beneficial for the community by drawing attention to the shortcomings in the current SSL evaluation schemes and underscoring the need to reconsider them. ",
    "url": "https://arxiv.org/abs/2304.03456",
    "authors": [
      "Jae-Hun Lee",
      "Doyoung Yoon",
      "ByeongMoon Ji",
      "Kyungyul Kim",
      "Sangheum Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03468",
    "title": "Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs:  New Datasets and A New Method",
    "abstract": "The development of knowledge graph (KG) applications has led to a rising need for entity alignment (EA) between heterogeneous KGs that are extracted from various sources. Recently, graph neural networks (GNNs) have been widely adopted in EA tasks due to GNNs' impressive ability to capture structure information. However, we have observed that the oversimplified settings of the existing common EA datasets are distant from real-world scenarios, which obstructs a full understanding of the advancements achieved by recent methods. This phenomenon makes us ponder: Do existing GNN-based EA methods really make great progress? In this paper, to study the performance of EA methods in realistic settings, we focus on the alignment of highly heterogeneous KGs (HHKGs) (e.g., event KGs and general KGs) which are different with regard to the scale and structure, and share fewer overlapping entities. First, we sweep the unreasonable settings, and propose two new HHKG datasets that closely mimic real-world EA scenarios. Then, based on the proposed datasets, we conduct extensive experiments to evaluate previous representative EA methods, and reveal interesting findings about the progress of GNN-based EA methods. We find that the structural information becomes difficult to exploit but still valuable in aligning HHKGs. This phenomenon leads to inferior performance of existing EA methods, especially GNN-based methods. Our findings shed light on the potential problems resulting from an impulsive application of GNN-based methods as a panacea for all EA datasets. Finally, we introduce a simple but effective method: Simple-HHEA, which comprehensively utilizes entity name, structure, and temporal information. Experiment results show Simple-HHEA outperforms previous models on HHKG datasets. The datasets and source code will be available at https://anonymous.4open.science/r/Simple-HHEA-3766. ",
    "url": "https://arxiv.org/abs/2304.03468",
    "authors": [
      "Xuhui Jiang",
      "Chengjin Xu",
      "Yinghan Shen",
      "Fenglong Su",
      "Yuanzhuo Wang",
      "Fei Sun",
      "Zixuan Li",
      "Huawei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03479",
    "title": "Clique Densification in Networks",
    "abstract": "Real-world networks are rarely static. Recently, there has been increasing interest in both network growth and network densification, in which the number of edges scales superlinearly with the number of nodes. Less studied but equally important, however, are scaling laws of higher-order cliques, which can drive clustering and network redundancy. In this paper, we study how cliques grow with network size, by analyzing several empirical networks from emails to Wikipedia interactions. Our results show superlinear scaling laws whose exponents increase with clique size, in contrast to predictions from a previous model. We then show that these results are in qualitative agreement with a new model that we propose, the Local Preferential Attachment Model, where an incoming node links not only to a target node but also to its higher-degree neighbors. Our results provide new insights into how networks grow and where network redundancy occurs. ",
    "url": "https://arxiv.org/abs/2304.03479",
    "authors": [
      "Haochen Pi",
      "Keith Burghardt",
      "Allon G. Percus",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.03487",
    "title": "ParaGraph: Weighted Graph Representation for Performance Optimization of  HPC Kernels",
    "abstract": "GPU-based HPC clusters are attracting more scientific application developers due to their extensive parallelism and energy efficiency. In order to achieve portability among a variety of multi/many core architectures, a popular choice for an application developer is to utilize directive-based parallel programming models, such as OpenMP. However, even with OpenMP, the developer must choose from among many strategies for exploiting a GPU or a CPU. Recently, Machine Learning (ML) approaches have brought significant advances in the optimizations of HPC applications. To this end, several ways have been proposed to represent application characteristics for ML models. However, the available techniques fail to capture features that are crucial for exposing parallelism. In this paper, we introduce a new graph-based program representation for parallel applications that extends the Abstract Syntax Tree to represent control and data flow information. The originality of this work lies in the addition of new edges exploiting the implicit ordering and parent-child relationships in ASTs, as well as the introduction of edge weights to account for loop and condition information. We evaluate our proposed representation by training a Graph Neural Network (GNN) to predict the runtime of an OpenMP code region across CPUs and GPUs. Various transformations utilizing collapse and data transfer between the CPU and GPU are used to construct the dataset. The predicted runtime of the model is used to determine which transformation provides the best performance. Results show that our approach is indeed effective and has normalized RMSE as low as 0.004 to at most 0.01 in its runtime predictions. ",
    "url": "https://arxiv.org/abs/2304.03487",
    "authors": [
      "Ali TehraniJamsaz",
      "Alok Mishra",
      "Akash Dutta",
      "Abid M. Malik",
      "Barbara Chapman",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2304.03489",
    "title": "Deep Reinforcement Learning Based Optimal Infinite-Horizon Control of  Probabilistic Boolean Control Networks",
    "abstract": "In this paper, a deep reinforcement learning based method is proposed to obtain optimal policies for optimal infinite-horizon control of probabilistic Boolean control networks (PBCNs). Compared with the existing literatures, the proposed method is model-free, namely, the system model and the initial states needn't to be known. Meanwhile, it is suitable for large-scale PBCNs. First, we establish the connection between deep reinforcement learning and optimal infinite-horizon control, and structure the problem into the framework of the Markov decision process. Then, PBCNs are defined as large-scale or small-scale, depending on whether the memory of the action-values exceeds the RAM of the computer. Based on the newly introduced definition, Q-learning (QL) and double deep Q-network (DDQN) are applied to the optimal infinite-horizon control of small-scale and large-scale PBCNs, respectively. Meanwhile, the optimal state feedback controllers are designed. Finally, two examples are presented, which are a small-scale PBCN with 3 nodes, and a large-scale one with 28 nodes. To verify the convergence of QL and DDQN, the optimal control policy and the optimal action-values, which are obtained from both the algorithms, are compared with the ones based on a model-based method named policy iteration. Meanwhile, the performance of QL is compared with DDQN in the small-scale PBCN. ",
    "url": "https://arxiv.org/abs/2304.03489",
    "authors": [
      "Jingjie Ni",
      "Fangfei Li",
      "Zheng-Guang Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.03492",
    "title": "Multi-Layered Unseen Garments Draping Network",
    "abstract": "While recent AI-based draping networks have significantly advanced the ability to simulate the appearance of clothes worn by 3D human models, the handling of multi-layered garments remains a challenging task. This paper presents a model for draping multi-layered garments that are unseen during the training process. Our proposed framework consists of three stages: garment embedding, single-layered garment draping, and untangling. The model represents a garment independent to its topological structure by mapping it onto the $UV$ map of a human body model, allowing for the ability to handle previously unseen garments. In the single-layered garment draping phase, the model sequentially drapes all garments in each layer on the body without considering interactions between them. The untangling phase utilizes a GNN-based network to model the interaction between the garments of different layers, enabling the simulation of complex multi-layered clothing. The proposed model demonstrates strong performance on both unseen synthetic and real garment reconstruction data on a diverse range of human body shapes and poses. ",
    "url": "https://arxiv.org/abs/2304.03492",
    "authors": [
      "Dohae Lee",
      "In-Kwon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2304.03493",
    "title": "UniSeg: A Prompt-driven Universal Segmentation Model as well as A Strong  Representation Learner",
    "abstract": "The universal model emerges as a promising trend for medical image segmentation, paving up the way to build medical imaging large model (MILM). One popular strategy to build universal models is to encode each task as a one-hot vector and generate dynamic convolutional layers at the end of the decoder to extract the interested target. Although successful, it ignores the correlations among tasks and meanwhile is too late to make the model 'aware' of the ongoing task. To address both issues, we propose a prompt-driven Universal Segmentation model (UniSeg) for multi-task medical image segmentation using diverse modalities and domains. We first devise a learnable universal prompt to describe the correlations among all tasks and then convert this prompt and image features into a task-specific prompt, which is fed to the decoder as a part of its input. Thus, we make the model 'aware' of the ongoing task early and boost the task-specific training of the whole decoder. Our results indicate that the proposed UniSeg outperforms other universal models and single-task models on 11 upstream tasks. Moreover, UniSeg also beats other pre-trained models on two downstream datasets, providing the community with a high-quality pre-trained model for 3D medical image segmentation. Code and model are available at https://github.com/yeerwen/UniSeg. ",
    "url": "https://arxiv.org/abs/2304.03493",
    "authors": [
      "Yiwen Ye",
      "Yutong Xie",
      "Jianpeng Zhang",
      "Ziyang Chen",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03495",
    "title": "Devil's on the Edges: Selective Quad Attention for Scene Graph  Generation",
    "abstract": "Scene graph generation aims to construct a semantic graph structure from an image such that its nodes and edges respectively represent objects and their relationships. One of the major challenges for the task lies in the presence of distracting objects and relationships in images; contextual reasoning is strongly distracted by irrelevant objects or backgrounds and, more importantly, a vast number of irrelevant candidate relations. To tackle the issue, we propose the Selective Quad Attention Network (SQUAT) that learns to select relevant object pairs and disambiguate them via diverse contextual interactions. SQUAT consists of two main components: edge selection and quad attention. The edge selection module selects relevant object pairs, i.e., edges in the scene graph, which helps contextual reasoning, and the quad attention module then updates the edge features using both edge-to-node and edge-to-edge cross-attentions to capture contextual information between objects and object pairs. Experiments demonstrate the strong performance and robustness of SQUAT, achieving the state of the art on the Visual Genome and Open Images v6 benchmarks. ",
    "url": "https://arxiv.org/abs/2304.03495",
    "authors": [
      "Deunsol Jung",
      "Sanghyun Kim",
      "Won Hwa Kim",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03496",
    "title": "Architecture-Preserving Provable Repair of Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) are becoming increasingly important components of software, and are considered the state-of-the-art solution for a number of problems, such as image recognition. However, DNNs are far from infallible, and incorrect behavior of DNNs can have disastrous real-world consequences. This paper addresses the problem of architecture-preserving V-polytope provable repair of DNNs. A V-polytope defines a convex bounded polytope using its vertex representation. V-polytope provable repair guarantees that the repaired DNN satisfies the given specification on the infinite set of points in the given V-polytope. An architecture-preserving repair only modifies the parameters of the DNN, without modifying its architecture. The repair has the flexibility to modify multiple layers of the DNN, and runs in polynomial time. It supports DNNs with activation functions that have some linear pieces, as well as fully-connected, convolutional, pooling and residual layers. To the best our knowledge, this is the first provable repair approach that has all of these features. We implement our approach in a tool called APRNN. Using MNIST, ImageNet, and ACAS Xu DNNs, we show that it has better efficiency, scalability, and generalization compared to PRDNN and REASSURE, prior provable repair methods that are not architecture preserving. ",
    "url": "https://arxiv.org/abs/2304.03496",
    "authors": [
      "Zhe Tao",
      "Stephanie Nawas",
      "Jacqueline Mitchell",
      "Aditya V. Thakur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03501",
    "title": "Continuous Input Embedding Size Search For Recommender Systems",
    "abstract": "Latent factor models are the most popular backbones for today's recommender systems owing to their prominent performance. Latent factor models represent users and items as real-valued embedding vectors for pairwise similarity computation, and all embeddings are traditionally restricted to a uniform size that is relatively large (e.g., 256-dimensional). With the exponentially expanding user base and item catalog in contemporary e-commerce, this design is admittedly becoming memory-inefficient. To facilitate lightweight recommendation, reinforcement learning (RL) has recently opened up opportunities for identifying varying embedding sizes for different users/items. However, challenged by search efficiency and learning an optimal RL policy, existing RL-based methods are restricted to highly discrete, predefined embedding size choices. This leads to a largely overlooked potential of introducing finer granularity into embedding sizes to obtain better recommendation effectiveness under a given memory budget. In this paper, we propose continuous input embedding size search (CIESS), a novel RL-based method that operates on a continuous search space with arbitrary embedding sizes to choose from. In CIESS, we further present an innovative random walk-based exploration strategy to allow the RL policy to efficiently explore more candidate embedding sizes and converge to a better decision. CIESS is also model-agnostic and hence generalizable to a variety of latent factor RSs, whilst experiments on two real-world datasets have shown state-of-the-art performance of CIESS under different memory budgets when paired with three popular recommendation models. ",
    "url": "https://arxiv.org/abs/2304.03501",
    "authors": [
      "Yunke Qu",
      "Tong Chen",
      "Xiangyu Zhao",
      "Lizhen Cui",
      "Kai Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.03509",
    "title": "Local Rose Breeds Detection System Using Transfer Learning Techniques",
    "abstract": "Flower breed detection and giving details of that breed with the suggestion of cultivation processes and the way of taking care is important for flower cultivation, breed invention, and the flower business. Among all the local flowers in Bangladesh, the rose is one of the most popular and demanded flowers. Roses are the most desirable flower not only in Bangladesh but also throughout the world. Roses can be used for many other purposes apart from decoration. As roses have a great demand in the flower business so rose breed detection will be very essential. However, there is no remarkable work for breed detection of a particular flower unlike the classification of different flowers. In this research, we have proposed a model to detect rose breeds from images using transfer learning techniques. For such work in flowers, resources are not enough in image processing and classification, so we needed a large dataset of the massive number of images to train our model. we have used 1939 raw images of five different breeds and we have generated 9306 images for the training dataset and 388 images for the testing dataset to validate the model using augmentation. We have applied four transfer learning models in this research, which are Inception V3, ResNet50, Xception, and VGG16. Among these four models, VGG16 achieved the highest accuracy of 99%, which is an excellent outcome. Breed detection of a rose by using transfer learning methods is the first work on breed detection of a particular flower that is publicly available according to the study. ",
    "url": "https://arxiv.org/abs/2304.03509",
    "authors": [
      "Amena Begum Farha",
      "Md. Azizul Hakim",
      "Mst. Eshita Khatun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03510",
    "title": "Multispectral Imaging for Differential Face Morphing Attack Detection: A  Preliminary Study",
    "abstract": "Face morphing attack detection is emerging as an increasingly challenging problem owing to advancements in high-quality and realistic morphing attack generation. Reliable detection of morphing attacks is essential because these attacks are targeted for border control applications. This paper presents a multispectral framework for differential morphing-attack detection (D-MAD). The D-MAD methods are based on using two facial images that are captured from the ePassport (also called the reference image) and the trusted device (for example, Automatic Border Control (ABC) gates) to detect whether the face image presented in ePassport is morphed. The proposed multispectral D-MAD framework introduce a multispectral image captured as a trusted capture to capture seven different spectral bands to detect morphing attacks. Extensive experiments were conducted on the newly created datasets with 143 unique data subjects that were captured using both visible and multispectral cameras in multiple sessions. The results indicate the superior performance of the proposed multispectral framework compared to visible images. ",
    "url": "https://arxiv.org/abs/2304.03510",
    "authors": [
      "Raghavendra Ramachandra",
      "Sushma Venkatesh",
      "Naser Damer",
      "Narayan Vetrekar",
      "Rajendra Gad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03518",
    "title": "SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism  using Majority Voted Fine-Tuned Transformers",
    "abstract": "This paper describes our submission to Task 10 at SemEval 2023-Explainable Detection of Online Sexism (EDOS), divided into three subtasks. The recent rise in social media platforms has seen an increase in disproportionate levels of sexism experienced by women on social media platforms. This has made detecting and explaining online sexist content more important than ever to make social media safer and more accessible for women. Our approach consists of experimenting and finetuning BERT-based models and using a Majority Voting ensemble model that outperforms individual baseline model scores. Our system achieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319 for Task C. ",
    "url": "https://arxiv.org/abs/2304.03518",
    "authors": [
      "Sriya Rallabandi",
      "Sanchit Singhal",
      "Pratinav Seth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03519",
    "title": "Robust data-driven control for nonlinear systems using the Koopman  operator",
    "abstract": "Data-driven analysis and control of dynamical systems have gained a lot of interest in recent years. While the class of linear systems is well studied, theoretical results for nonlinear systems are still rare. In this paper, we present a data-driven controller design method for discrete-time control-affine nonlinear systems. Our approach relies on the Koopman operator, which is a linear but infinite-dimensional operator lifting the nonlinear system to a higher-dimensional space. Particularly, we derive a linear fractional representation of a lifted bilinear system representation based on measured data. Further, we restrict the lifting to finite dimensions, but account for the truncation error using a finite-gain argument. We derive a linear matrix inequality based design procedure to guarantee robust local stability for the resulting bilinear system for all error terms satisfying the finite-gain bound and, thus, also for the underlying nonlinear system. Finally, we apply the developed design method to the nonlinear Van der Pol oscillator. ",
    "url": "https://arxiv.org/abs/2304.03519",
    "authors": [
      "Robin Str\u00e4sser",
      "Julian Berberich",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.03532",
    "title": "A Mixer Layer is Worth One Graph Convolution: Unifying MLP-Mixers and  GCNs for Human Motion Prediction",
    "abstract": "The past few years has witnessed the dominance of Graph Convolutional Networks (GCNs) over human motion prediction, while their performance is still far from satisfactory. Recently, MLP-Mixers show competitive results on top of being more efficient and simple. To extract features, GCNs typically follow an aggregate-and-update paradigm, while Mixers rely on token mixing and channel mixing operations. The two research paths have been independently established in the community. In this paper, we develop a novel perspective by unifying Mixers and GCNs. We show that a mixer layer can be seen as a graph convolutional layer applied to a fully-connected graph with parameterized adjacency. Extending this theoretical finding to the practical side, we propose Meta-Mixing Network (M$^2$-Net). Assisted with a novel zero aggregation operation, our network is capable of capturing both the structure-agnostic and the structure-sensitive dependencies in a collaborative manner. Not only is it computationally efficient, but most importantly, it also achieves state-of-the-art performance. An extensive evaluation on the Human3.6M, AMASS, and 3DPW datasets shows that M$^2$-Net consistently outperforms all other approaches. We hope our work brings the community one step further towards truly predictable human motion. Our code will be publicly available. ",
    "url": "https://arxiv.org/abs/2304.03532",
    "authors": [
      "Xinshun Wang",
      "Shen Zhao",
      "Chen Chen",
      "Mengyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03535",
    "title": "CRISP: Curriculum inducing Primitive Informed Subgoal Prediction for  Hierarchical Reinforcement Learning",
    "abstract": "Hierarchical reinforcement learning is a promising approach that uses temporal abstraction to solve complex long horizon problems. However, simultaneously learning a hierarchy of policies is unstable as it is challenging to train higher-level policy when the lower-level primitive is non-stationary. In this paper, we propose a novel hierarchical algorithm by generating a curriculum of achievable subgoals for evolving lower-level primitives using reinforcement learning and imitation learning. The lower level primitive periodically performs data relabeling on a handful of expert demonstrations using our primitive informed parsing approach. We provide expressions to bound the sub-optimality of our method and develop a practical algorithm for hierarchical reinforcement learning. Since our approach uses a handful of expert demonstrations, it is suitable for most robotic control tasks. Experimental evaluation on complex maze navigation and robotic manipulation environments show that inducing hierarchical curriculum learning significantly improves sample efficiency, and results in efficient goal conditioned policies for solving temporally extended tasks. ",
    "url": "https://arxiv.org/abs/2304.03535",
    "authors": [
      "Utsav Singh",
      "Vinay P Namboodiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03537",
    "title": "Domain Adaptive Multiple Instance Learning for Instance-level Prediction  of Pathological Images",
    "abstract": "Pathological image analysis is an important process for detecting abnormalities such as cancer from cell images. However, since the image size is generally very large, the cost of providing detailed annotations is high, which makes it difficult to apply machine learning techniques. One way to improve the performance of identifying abnormalities while keeping the annotation cost low is to use only labels for each slide, or to use information from another dataset that has already been labeled. However, such weak supervisory information often does not provide sufficient performance. In this paper, we proposed a new task setting to improve the classification performance of the target dataset without increasing annotation costs. And to solve this problem, we propose a pipeline that uses multiple instance learning (MIL) and domain adaptation (DA) methods. Furthermore, in order to combine the supervisory information of both methods effectively, we propose a method to create pseudo-labels with high confidence. We conducted experiments on the pathological image dataset we created for this study and showed that the proposed method significantly improves the classification performance compared to existing methods. ",
    "url": "https://arxiv.org/abs/2304.03537",
    "authors": [
      "Shusuke Takahama",
      "Yusuke Kurose",
      "Yusuke Mukuta",
      "Hiroyuki Abe",
      "Akihiko Yoshizawa",
      "Tetsuo Ushiku",
      "Masashi Fukayama",
      "Masanobu Kitagawa",
      "Masaru Kitsuregawa",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03538",
    "title": "Adjustable Privacy using Autoencoder-based Learning Structure",
    "abstract": "Inference centers need more data to have a more comprehensive and beneficial learning model, and for this purpose, they need to collect data from data providers. On the other hand, data providers are cautious about delivering their datasets to inference centers in terms of privacy considerations. In this paper, by modifying the structure of the autoencoder, we present a method that manages the utility-privacy trade-off well. To be more precise, the data is first compressed using the encoder, then confidential and non-confidential features are separated and uncorrelated using the classifier. The confidential feature is appropriately combined with noise, and the non-confidential feature is enhanced, and at the end, data with the original data format is produced by the decoder. The proposed architecture also allows data providers to set the level of privacy required for confidential features. The proposed method has been examined for both image and categorical databases, and the results show a significant performance improvement compared to previous methods. ",
    "url": "https://arxiv.org/abs/2304.03538",
    "authors": [
      "Mohammad Ali Jamshidi",
      "Hadi Veisi",
      "Mohammad Mahdi Mojahedian",
      "Mohammad Reza Aref"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03550",
    "title": "Hierarchical Disentanglement-Alignment Network for Robust SAR Vehicle  Recognition",
    "abstract": "Due to Synthetic Aperture Radar (SAR) imaging characteristics, SAR vehicle recognition faces the problem of extracting discriminative and robust target features from a small dataset. Deep learning has shown impressive performance on the MSTAR dataset. However, data bias in a small dataset, such as background correlation, impairs the causality of these methods, i.e., discriminative features contain target and background differences. Moreover, different operating conditions of SAR lead to target signatures and background clutter variations in imaging results. However, many deep learning-based methods only verify robustness to target or background variations in the current experimental setting. In this paper, we propose a novel domain alignment framework named Hierarchical Disentanglement-Alignment Network (HDANet) to enhance features' causality and robustness. Concisely, HDANet consists of three parts: The first part uses data augmentation to generate signature variations for domain alignment. The second part disentangles the target features through a multitask-assisted mask to prevent non-causal clutter from interfering with subsequent alignment and recognition. Thirdly, a contrastive loss is employed for domain alignment to extract robust target features, and the SimSiam structure is applied to mitigate conflicts between contrastive loss and feature discrimination. Finally, the proposed method shows high robustness across MSTAR's multiple target, sensor, and environment variants. Noteworthy, we add a new scene variant to verify the robustness to target and background variations. Moreover, the saliency map and Shapley value qualitatively and quantitatively demonstrate causality. Our code is available in \\url{https://github.com/waterdisappear/SAR-ATR-HDANet}. ",
    "url": "https://arxiv.org/abs/2304.03550",
    "authors": [
      "Weijie Li",
      "Wei Yang",
      "Li Li",
      "Wenpeng Zhang",
      "Yongxiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03552",
    "title": "A physics-informed neural network framework for modeling  obstacle-related equations",
    "abstract": "Deep learning has been highly successful in some applications. Nevertheless, its use for solving partial differential equations (PDEs) has only been of recent interest with current state-of-the-art machine learning libraries, e.g., TensorFlow or PyTorch. Physics-informed neural networks (PINNs) are an attractive tool for solving partial differential equations based on sparse and noisy data. Here extend PINNs to solve obstacle-related PDEs which present a great computational challenge because they necessitate numerical methods that can yield an accurate approximation of the solution that lies above a given obstacle. The performance of the proposed PINNs is demonstrated in multiple scenarios for linear and nonlinear PDEs subject to regular and irregular obstacles. ",
    "url": "https://arxiv.org/abs/2304.03552",
    "authors": [
      "Hamid El Bahja",
      "Jan Christian Hauffen",
      "Peter Jung",
      "Bubacarr Bah",
      "Issa Karambal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.03560",
    "title": "DualRefine: Self-Supervised Depth and Pose Estimation Through Iterative  Epipolar Sampling and Refinement Toward Equilibrium",
    "abstract": "Self-supervised multi-frame depth estimation achieves high accuracy by computing matching costs of pixel correspondences between adjacent frames, injecting geometric information into the network. These pixel-correspondence candidates are computed based on the relative pose estimates between the frames. Accurate pose predictions are essential for precise matching cost computation as they influence the epipolar geometry. Furthermore, improved depth estimates can, in turn, be used to align pose estimates. Inspired by traditional structure-from-motion (SfM) principles, we propose the DualRefine model, which tightly couples depth and pose estimation through a feedback loop. Our novel update pipeline uses a deep equilibrium model framework to iteratively refine depth estimates and a hidden state of feature maps by computing local matching costs based on epipolar geometry. Importantly, we used the refined depth estimates and feature maps to compute pose updates at each step. This update in the pose estimates slowly alters the epipolar geometry during the refinement process. Experimental results on the KITTI dataset demonstrate competitive depth prediction and odometry prediction performance surpassing published self-supervised baselines. ",
    "url": "https://arxiv.org/abs/2304.03560",
    "authors": [
      "Antyanta Bangunharcana",
      "Ahmed Magd",
      "Kyung-Soo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03566",
    "title": "On the Unbounded External Archive and Population Size in  Preference-based Evolutionary Multi-objective Optimization Using a Reference  Point",
    "abstract": "Although the population size is an important parameter in evolutionary multi-objective optimization (EMO), little is known about its influence on preference-based EMO (PBEMO). The effectiveness of an unbounded external archive (UA) in PBEMO is also poorly understood, where the UA maintains all non-dominated solutions found so far. In addition, existing methods for postprocessing the UA cannot handle the decision maker's preference information. In this context, first, this paper proposes a preference-based postprocessing method for selecting representative solutions from the UA. Then, we investigate the influence of the UA and population size on the performance of PBEMO algorithms. Our results show that the performance of PBEMO algorithms (e.g., R-NSGA-II) can be significantly improved by using the UA and the proposed method. We demonstrate that a smaller population size than commonly used is effective in most PBEMO algorithms for a small budget of function evaluations, even for many objectives. We found that the size of the region of interest is a less important factor in selecting the population size of the PBEMO algorithms on real-world problems. ",
    "url": "https://arxiv.org/abs/2304.03566",
    "authors": [
      "Ryoji Tanabe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.03579",
    "title": "A lightweight Encryption Method For Privacy-Preserving in Process Mining",
    "abstract": "Novel technological achievements in the fields of business intelligence, business management and data science are based on real-time and complex virtual networks. Sharing data between a large number of organizations that leads to a system with high computational complexity is one of the considerable characteristics of the current business networks. Discovery, conformance and enhancement of the business processes are performed using the generated event logs. In this regard, one of the overlooked challenges is privacy-preserving in the field of process mining in the industry. To preserve the data-privacy with a low computational complexity structure that is a necessity for the current digital business technology, a novel lightweight encryption method based on Haar transform and a private key is proposed in this paper. We compare the proposed method with the well-known homomorphic cryptosystem and Walsh- Hadamard encryption (WHE) in terms of cryptography, computational complexity and structure vulnerability. The analyses show that the proposed method anonymizes the event logs with the lower complexity and more accuracy compared with two aforementioned cryptosystems, significantly. ",
    "url": "https://arxiv.org/abs/2304.03579",
    "authors": [
      "Mohsen Kazemian",
      "Markus Helfert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.03580",
    "title": "Language-aware Multiple Datasets Detection Pretraining for DETRs",
    "abstract": "Pretraining on large-scale datasets can boost the performance of object detectors while the annotated datasets for object detection are hard to scale up due to the high labor cost. What we possess are numerous isolated filed-specific datasets, thus, it is appealing to jointly pretrain models across aggregation of datasets to enhance data volume and diversity. In this paper, we propose a strong framework for utilizing Multiple datasets to pretrain DETR-like detectors, termed METR, without the need for manual label spaces integration. It converts the typical multi-classification in object detection into binary classification by introducing a pre-trained language model. Specifically, we design a category extraction module for extracting potential categories involved in an image and assign these categories into different queries by language embeddings. Each query is only responsible for predicting a class-specific object. Besides, to adapt our novel detection paradigm, we propose a group bipartite matching strategy that limits the ground truths to match queries assigned to the same category. Extensive experiments demonstrate that METR achieves extraordinary results on either multi-task joint training or the pretrain & finetune paradigm. Notably, our pre-trained models have high flexible transferability and increase the performance upon various DETR-like detectors on COCO val2017 benchmark. Codes will be available after this paper is published. ",
    "url": "https://arxiv.org/abs/2304.03580",
    "authors": [
      "Jing Hao",
      "Song Chen",
      "Xiaodi Wang",
      "Shumin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03586",
    "title": "Graph Attention for Automated Audio Captioning",
    "abstract": "State-of-the-art audio captioning methods typically use the encoder-decoder structure with pretrained audio neural networks (PANNs) as encoders for feature extraction. However, the convolution operation used in PANNs is limited in capturing the long-time dependencies within an audio signal, thereby leading to potential performance degradation in audio captioning. This letter presents a novel method using graph attention (GraphAC) for encoder-decoder based audio captioning. In the encoder, a graph attention module is introduced after the PANNs to learn contextual association (i.e. the dependency among the audio features over different time frames) through an adjacency graph, and a top-k mask is used to mitigate the interference from noisy nodes. The learnt contextual association leads to a more effective feature representation with feature node aggregation. As a result, the decoder can predict important semantic information about the acoustic scene and events based on the contextual associations learned from the audio signal. Experimental results show that GraphAC outperforms the state-of-the-art methods with PANNs as the encoders, thanks to the incorporation of the graph attention module into the encoder for capturing the long-time dependencies within the audio signal. The source code is available at https://github.com/LittleFlyingSheep/GraphAC. ",
    "url": "https://arxiv.org/abs/2304.03586",
    "authors": [
      "Feiyang Xiao",
      "Jian Guan",
      "Qiaoxi Zhu",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03588",
    "title": "Anomalous Sound Detection using Audio Representation with Machine ID  based Contrastive Learning Pretraining",
    "abstract": "Existing contrastive learning methods for anomalous sound detection refine the audio representation of each audio sample by using the contrast between the samples' augmentations (e.g., with time or frequency masking). However, they might be biased by the augmented data, due to the lack of physical properties of machine sound, thereby limiting the detection performance. This paper uses contrastive learning to refine audio representations for each machine ID, rather than for each audio sample. The proposed two-stage method uses contrastive learning to pretrain the audio representation model by incorporating machine ID and a self-supervised ID classifier to fine-tune the learnt model, while enhancing the relation between audio features from the same ID. Experiments show that our method outperforms the state-of-the-art methods using contrastive learning or self-supervised classification in overall anomaly detection performance and stability on DCASE 2020 Challenge Task2 dataset. ",
    "url": "https://arxiv.org/abs/2304.03588",
    "authors": [
      "Jian Guan",
      "Feiyang Xiao",
      "Youde Liu",
      "Qiaoxi Zhu",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.03602",
    "title": "Pallet Detection from Synthetic Data Using Game Engines",
    "abstract": "This research sets out to assess the viability of using game engines to generate synthetic training data for machine learning in the context of pallet segmentation. Using synthetic data has been proven in prior research to be a viable means of training neural networks and saves hours of manual labour due to the reduced need for manual image annotation. Machine vision for pallet detection can benefit from synthetic data as the industry increases the development of autonomous warehousing technologies. As per our methodology, we developed a tool capable of automatically generating large amounts of annotated training data from 3D models at pixel-perfect accuracy and a much faster rate than manual approaches. Regarding image segmentation, a Mask R-CNN pipeline was used, which achieved an AP50 of 86% for individual pallets. ",
    "url": "https://arxiv.org/abs/2304.03602",
    "authors": [
      "Jouveer Naidoo",
      "Nicholas Bates",
      "Trevor Gee",
      "Mahla Nejati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03608",
    "title": "ALIKED: A Lighter Keypoint and Descriptor Extraction Network via  Deformable Transformation",
    "abstract": "Image keypoints and descriptors play a crucial role in many visual measurement tasks. In recent years, deep neural networks have been widely used to improve the performance of keypoint and descriptor extraction. However, the conventional convolution operations do not provide the geometric invariance required for the descriptor. To address this issue, we propose the Sparse Deformable Descriptor Head (SDDH), which learns the deformable positions of supporting features for each keypoint and constructs deformable descriptors. Furthermore, SDDH extracts descriptors at sparse keypoints instead of a dense descriptor map, which enables efficient extraction of descriptors with strong expressiveness. In addition, we relax the neural reprojection error (NRE) loss from dense to sparse to train the extracted sparse descriptors. Experimental results show that the proposed network is both efficient and powerful in various visual measurement tasks, including image matching, 3D reconstruction, and visual relocalization. ",
    "url": "https://arxiv.org/abs/2304.03608",
    "authors": [
      "Xiaoming Zhao",
      "Xingming Wu",
      "Weihai Chen",
      "Peter C. Y. Chen",
      "Qingsong Xu",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03610",
    "title": "Look how they have grown: Non-destructive Leaf Detection and Size  Estimation of Tomato Plants for 3D Growth Monitoring",
    "abstract": "Smart farming is a growing field as technology advances. Plant characteristics are crucial indicators for monitoring plant growth. Research has been done to estimate characteristics like leaf area index, leaf disease, and plant height. However, few methods have been applied to non-destructive measurements of leaf size. In this paper, an automated non-destructive imaged-based measuring system is presented, which uses 2D and 3D data obtained using a Zivid 3D camera, creating 3D virtual representations (digital twins) of the tomato plants. Leaves are detected from corresponding 2D RGB images and mapped to their 3D point cloud using the detected leaf masks, which then pass the leaf point cloud to the plane fitting algorithm to extract the leaf size to provide data for growth monitoring. The performance of the measurement platform has been measured through a comprehensive trial on real-world tomato plants with quantified performance metrics compared to ground truth measurements. Three tomato leaf and height datasets (including 50+ 3D point cloud files of tomato plants) were collected and open-sourced in this project. The proposed leaf size estimation method demonstrates an RMSE value of 4.47mm and an R^2 value of 0.87. The overall measurement system (leaf detection and size estimation algorithms combine) delivers an RMSE value of 8.13mm and an R^2 value of 0.899. ",
    "url": "https://arxiv.org/abs/2304.03610",
    "authors": [
      "Yuning Xing",
      "Dexter Pham",
      "Henry Williams",
      "David Smith",
      "Ho Seok Ahn",
      "JongYoon Lim",
      "Bruce A. MacDonald",
      "Mahla Nejati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03635",
    "title": "A2J-Transformer: Anchor-to-Joint Transformer Network for 3D Interacting  Hand Pose Estimation from a Single RGB Image",
    "abstract": "3D interacting hand pose estimation from a single RGB image is a challenging task, due to serious self-occlusion and inter-occlusion towards hands, confusing similar appearance patterns between 2 hands, ill-posed joint position mapping from 2D to 3D, etc.. To address these, we propose to extend A2J-the state-of-the-art depth-based 3D single hand pose estimation method-to RGB domain under interacting hand condition. Our key idea is to equip A2J with strong local-global aware ability to well capture interacting hands' local fine details and global articulated clues among joints jointly. To this end, A2J is evolved under Transformer's non-local encoding-decoding framework to build A2J-Transformer. It holds 3 main advantages over A2J. First, self-attention across local anchor points is built to make them global spatial context aware to better capture joints' articulation clues for resisting occlusion. Secondly, each anchor point is regarded as learnable query with adaptive feature learning for facilitating pattern fitting capacity, instead of having the same local representation with the others. Last but not least, anchor point locates in 3D space instead of 2D as in A2J, to leverage 3D pose prediction. Experiments on challenging InterHand 2.6M demonstrate that, A2J-Transformer can achieve state-of-the-art model-free performance (3.38mm MPJPE advancement in 2-hand case) and can also be applied to depth domain with strong generalization. ",
    "url": "https://arxiv.org/abs/2304.03635",
    "authors": [
      "Changlong Jiang",
      "Yang Xiao",
      "Cunlin Wu",
      "Mingyang Zhang",
      "Jinghong Zheng",
      "Zhiguo Cao",
      "Joey Tianyi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03638",
    "title": "Compressed Regression over Adaptive Networks",
    "abstract": "In this work we derive the performance achievable by a network of distributed agents that solve, adaptively and in the presence of communication constraints, a regression problem. Agents employ the recently proposed ACTC (adapt-compress-then-combine) diffusion strategy, where the signals exchanged locally by neighboring agents are encoded with randomized differential compression operators. We provide a detailed characterization of the mean-square estimation error, which is shown to comprise a term related to the error that agents would achieve without communication constraints, plus a term arising from compression. The analysis reveals quantitative relationships between the compression loss and fundamental attributes of the distributed regression problem, in particular, the stochastic approximation error caused by the gradient noise and the network topology (through the Perron eigenvector). We show that knowledge of such relationships is critical to allocate optimally the communication resources across the agents, taking into account their individual attributes, such as the quality of their data or their degree of centrality in the network topology. We devise an optimized allocation strategy where the parameters necessary for the optimization can be learned online by the agents. Illustrative examples show that a significant performance improvement, as compared to a blind (i.e., uniform) resource allocation, can be achieved by optimizing the allocation by means of the provided mean-square-error formulas. ",
    "url": "https://arxiv.org/abs/2304.03638",
    "authors": [
      "Marco Carpentiero",
      "Vincenzo Matta",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.03639",
    "title": "Theoretical Conditions and Empirical Failure of Bracket Counting on Long  Sequences with Linear Recurrent Networks",
    "abstract": "Previous work has established that RNNs with an unbounded activation function have the capacity to count exactly. However, it has also been shown that RNNs are challenging to train effectively and generally do not learn exact counting behaviour. In this paper, we focus on this problem by studying the simplest possible RNN, a linear single-cell network. We conduct a theoretical analysis of linear RNNs and identify conditions for the models to exhibit exact counting behaviour. We provide a formal proof that these conditions are necessary and sufficient. We also conduct an empirical analysis using tasks involving a Dyck-1-like Balanced Bracket language under two different settings. We observe that linear RNNs generally do not meet the necessary and sufficient conditions for counting behaviour when trained with the standard approach. We investigate how varying the length of training sequences and utilising different target classes impacts model behaviour during training and the ability of linear RNN models to effectively approximate the indicator conditions. ",
    "url": "https://arxiv.org/abs/2304.03639",
    "authors": [
      "Nadine El-Naggar",
      "Pranava Madhyastha",
      "Tillman Weyde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.03640",
    "title": "FedDiSC: A Computation-efficient Federated Learning Framework for Power  Systems Disturbance and Cyber Attack Discrimination",
    "abstract": "With the growing concern about the security and privacy of smart grid systems, cyberattacks on critical power grid components, such as state estimation, have proven to be one of the top-priority cyber-related issues and have received significant attention in recent years. However, cyberattack detection in smart grids now faces new challenges, including privacy preservation and decentralized power zones with strategic data owners. To address these technical bottlenecks, this paper proposes a novel Federated Learning-based privacy-preserving and communication-efficient attack detection framework, known as FedDiSC, that enables Discrimination between power System disturbances and Cyberattacks. Specifically, we first propose a Federated Learning approach to enable Supervisory Control and Data Acquisition subsystems of decentralized power grid zones to collaboratively train an attack detection model without sharing sensitive power related data. Secondly, we put forward a representation learning-based Deep Auto-Encoder network to accurately detect power system and cybersecurity anomalies. Lastly, to adapt our proposed framework to the timeliness of real-world cyberattack detection in SGs, we leverage the use of a gradient privacy-preserving quantization scheme known as DP-SIGNSGD to improve its communication efficiency. Extensive simulations of the proposed framework on publicly available Industrial Control Systems datasets demonstrate that the proposed framework can achieve superior detection accuracy while preserving the privacy of sensitive power grid related information. Furthermore, we find that the gradient quantization scheme utilized improves communication efficiency by 40% when compared to a traditional federated learning approach without gradient quantization which suggests suitability in a real-world scenario. ",
    "url": "https://arxiv.org/abs/2304.03640",
    "authors": [
      "Muhammad Akbar Husnoo",
      "Adnan Anwar",
      "Haftu Tasew Reda",
      "Nasser Hosseinzadeh",
      "Shama Naz Islam",
      "Abdun Naser Mahmood",
      "Robin Doss"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03657",
    "title": "SCART: Simulation of Cyber Attacks for Real-Time",
    "abstract": "Real-Time systems are often implemented as reactive systems that respond to stimuli and complete tasks in a known bounded time. The development process of such systems usually involves using a cycle-accurate simulation environment and even the digital twine system that can accurately simulate the system and the environment it operates in. In addition, many real-time systems require high reliability and strive to be immune against security attacks. Thus, the development environment must support reliability-related events such as the failure of a sensor, malfunction of a subsystem, and foreseen events of Cyber security attacks. This paper presents the SCART framework - an innovative solution that aims to allow extending simulation environments of real-time systems with the capability to incorporate reliability-related events and advanced cyber security attacks, e.g., an attack on a single sensor as well as \"complex security attacks\" that aim to change the behavior of a group of sensors. We validate our system by applying the new proposed environment on control a drone's flight control system including its navigation system that uses machine learning algorithms. Such a system is very challenging since it requires many experiments that can hardly be achieved by using live systems. We showed that using SCART is very efficient, can increase the model's accuracy, and significantly reduce false-positive rates. Some of these experiments were also validated using a set of \"real drones\". ",
    "url": "https://arxiv.org/abs/2304.03657",
    "authors": [
      "Kfir Girstein",
      "Eliron Rahimi",
      "Prof. Avi Mendelson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03671",
    "title": "Contraction-Guided Adaptive Partitioning for Reachability Analysis of  Neural Network Controlled Systems",
    "abstract": "In this paper, we present a contraction-guided adaptive partitioning algorithm for improving interval-valued robust reachable set estimates in a nonlinear feedback loop with a neural network controller and disturbances. Based on an estimate of the contraction rate of over-approximated intervals, the algorithm chooses when and where to partition. Then, by leveraging a decoupling of the neural network verification step and reachability partitioning layers, the algorithm can provide accuracy improvements for little computational cost. This approach is applicable with any sufficiently accurate open-loop interval-valued reachability estimation technique and any method for bounding the input-output behavior of a neural network. Using contraction-based robustness analysis, we provide guarantees of the algorithm's performance with mixed monotone reachability. Finally, we demonstrate the algorithm's performance through several numerical simulations and compare it with existing methods in the literature. In particular, we report a sizable improvement in the accuracy of reachable set estimation in a fraction of the runtime as compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2304.03671",
    "authors": [
      "Akash Harapanahalli",
      "Saber Jafarpour",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.03691",
    "title": "Feature Mining for Encrypted Malicious Traffic Detection with Deep  Learning and Other Machine Learning Algorithms",
    "abstract": "The popularity of encryption mechanisms poses a great challenge to malicious traffic detection. The reason is traditional detection techniques cannot work without the decryption of encrypted traffic. Currently, research on encrypted malicious traffic detection without decryption has focused on feature extraction and the choice of machine learning or deep learning algorithms. In this paper, we first provide an in-depth analysis of traffic features and compare different state-of-the-art traffic feature creation approaches, while proposing a novel concept for encrypted traffic feature which is specifically designed for encrypted malicious traffic analysis. In addition, we propose a framework for encrypted malicious traffic detection. The framework is a two-layer detection framework which consists of both deep learning and traditional machine learning algorithms. Through comparative experiments, it outperforms classical deep learning and traditional machine learning algorithms, such as ResNet and Random Forest. Moreover, to provide sufficient training data for the deep learning model, we also curate a dataset composed entirely of public datasets. The composed dataset is more comprehensive than using any public dataset alone. Lastly, we discuss the future directions of this research. ",
    "url": "https://arxiv.org/abs/2304.03691",
    "authors": [
      "Zihao Wang",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03692",
    "title": "Sound Dynamic Deadlock Prediction in Linear Time",
    "abstract": "Deadlocks are one of the most notorious concurrency bugs, and significant research has focused on detecting them efficiently. Dynamic predictive analyses work by observing concurrent executions, and reason about alternative interleavings that can witness concurrency bugs. Such techniques offer scalability and sound bug reports, and have emerged as an effective approach for concurrency bug detection, such as data races. Effective dynamic deadlock prediction, however, has proven a challenging task, as no deadlock predictor currently meets the requirements of soundness, high-precision, and efficiency. In this paper, we first formally establish that this tradeoff is unavoidable, by showing that (a) sound and complete deadlock prediction is intractable, in general, and (b) even the seemingly simpler task of determining the presence of potential deadlocks, which often serve as unsound witnesses for actual predictable deadlocks, is intractable. The main contribution of this work is a new class of predictable deadlocks, called sync(hronization)-preserving deadlocks. Informally, these are deadlocks that can be predicted by reordering the observed execution while preserving the relative order of conflicting critical sections. We present two algorithms for sound deadlock prediction based on this notion. Our first algorithm SyncPDOffline detects all sync-preserving deadlocks, with running time that is linear per abstract deadlock pattern, a novel notion also introduced in this work. Our second algorithm SyncPDOnline predicts all sync-preserving deadlocks that involve two threads in a strictly online fashion, runs in overall linear time, and is better suited for a runtime monitoring setting. We implemented both our algorithms and evaluated their ability to perform offline and online deadlock-prediction on a large dataset of standard benchmarks. ",
    "url": "https://arxiv.org/abs/2304.03692",
    "authors": [
      "Umang Mathur",
      "Andreas Pavlogiannis",
      "H\u00fcnkar Can Tun\u00e7",
      "Mahesh Viswanathan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.03698",
    "title": "Deepfake Detection with Deep Learning: Convolutional Neural Networks  versus Transformers",
    "abstract": "The rapid evolvement of deepfake creation technologies is seriously threating media information trustworthiness. The consequences impacting targeted individuals and institutions can be dire. In this work, we study the evolutions of deep learning architectures, particularly CNNs and Transformers. We identified eight promising deep learning architectures, designed and developed our deepfake detection models and conducted experiments over well-established deepfake datasets. These datasets included the latest second and third generation deepfake datasets. We evaluated the effectiveness of our developed single model detectors in deepfake detection and cross datasets evaluations. We achieved 88.74%, 99.53%, 97.68%, 99.73% and 92.02% accuracy and 99.95%, 100%, 99.88%, 99.99% and 97.61% AUC, in the detection of FF++ 2020, Google DFD, Celeb-DF, Deeper Forensics and DFDC deepfakes, respectively. We also identified and showed the unique strengths of CNNs and Transformers models and analysed the observed relationships among the different deepfake datasets, to aid future developments in this area. ",
    "url": "https://arxiv.org/abs/2304.03698",
    "authors": [
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03732",
    "title": "Enabling immersive experiences in challenging network conditions",
    "abstract": "Immersive experiences, such as remote collaboration and augmented and virtual reality, require delivery of large volumes of data with consistent ultra-low latency across wireless networks in fluctuating network conditions. We describe the high-level design behind a data delivery solution that meets these requirements and provide synthetic simulations and test results running in network conditions based on real-world measurements demonstrating the efficacy of the solution. ",
    "url": "https://arxiv.org/abs/2304.03732",
    "authors": [
      "Pooja Aggarwal",
      "Michael Luby",
      "Lorenz Minder"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2304.03752",
    "title": "V3Det: Vast Vocabulary Visual Detection Dataset",
    "abstract": "Recent advances in detecting arbitrary objects in the real world are trained and evaluated on object detection datasets with a relatively restricted vocabulary. To facilitate the development of more general visual object detection, we propose V3Det, a vast vocabulary visual detection dataset with precisely annotated bounding boxes on massive images. V3Det has several appealing properties: 1) Vast Vocabulary: It contains bounding boxes of objects from 13,029 categories on real-world images, which is 10 times larger than the existing large vocabulary object detection dataset, e.g., LVIS. 2) Hierarchical Category Organization: The vast vocabulary of V3Det is organized by a hierarchical category tree which annotates the inclusion relationship among categories, encouraging the exploration of category relationships in vast and open vocabulary object detection. 3) Rich Annotations: V3Det comprises precisely annotated objects in 245k images and professional descriptions of each category written by human experts and a powerful chatbot. By offering a vast exploration space, V3Det enables extensive benchmarks on both vast and open vocabulary object detection, leading to new observations, practices, and insights for future research. It has the potential to serve as a cornerstone dataset for developing more general visual perception systems. ",
    "url": "https://arxiv.org/abs/2304.03752",
    "authors": [
      "Jiaqi Wang",
      "Pan Zhang",
      "Tao Chu",
      "Yuhang Cao",
      "Yujie Zhou",
      "Tong Wu",
      "Bin Wang",
      "Conghui He",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03754",
    "title": "Language Models are Causal Knowledge Extractors for Zero-shot Video  Question Answering",
    "abstract": "Causal Video Question Answering (CVidQA) queries not only association or temporal relations but also causal relations in a video. Existing question synthesis methods pre-trained question generation (QG) systems on reading comprehension datasets with text descriptions as inputs. However, QG models only learn to ask association questions (e.g., ``what is someone doing...'') and result in inferior performance due to the poor transfer of association knowledge to CVidQA, which focuses on causal questions like ``why is someone doing ...''. Observing this, we proposed to exploit causal knowledge to generate question-answer pairs, and proposed a novel framework, Causal Knowledge Extraction from Language Models (CaKE-LM), leveraging causal commonsense knowledge from language models to tackle CVidQA. To extract knowledge from LMs, CaKE-LM generates causal questions containing two events with one triggering another (e.g., ``score a goal'' triggers ``soccer player kicking ball'') by prompting LM with the action (soccer player kicking ball) to retrieve the intention (to score a goal). CaKE-LM significantly outperforms conventional methods by 4% to 6% of zero-shot CVidQA accuracy on NExT-QA and Causal-VidQA datasets. We also conduct comprehensive analyses and provide key findings for future research. ",
    "url": "https://arxiv.org/abs/2304.03754",
    "authors": [
      "Hung-Ting Su",
      "Yulei Niu",
      "Xudong Lin",
      "Winston H. Hsu",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03763",
    "title": "Clutter Detection and Removal in 3D Scenes with View-Consistent  Inpainting",
    "abstract": "Removing clutter from scenes is essential in many applications, ranging from privacy-concerned content filtering to data augmentation. In this work, we present an automatic system that removes clutter from 3D scenes and inpaints with coherent geometry and texture. We propose techniques for its two key components: 3D segmentation from shared properties and 3D inpainting, both of which are important porblems. The definition of 3D scene clutter (frequently-moving objects) is not well captured by commonly-studied object categories in computer vision. To tackle the lack of well-defined clutter annotations, we group noisy fine-grained labels, leverage virtual rendering, and impose an instance-level area-sensitive loss. Once clutter is removed, we inpaint geometry and texture in the resulting holes by merging inpainted RGB-D images. This requires novel voting and pruning strategies that guarantee multi-view consistency across individually inpainted images for mesh reconstruction. Experiments on ScanNet and Matterport dataset show that our method outperforms baselines for clutter segmentation and 3D inpainting, both visually and quantitatively. ",
    "url": "https://arxiv.org/abs/2304.03763",
    "authors": [
      "Fangyin Wei",
      "Thomas Funkhouser",
      "Szymon Rusinkiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03767",
    "title": "Embodied Concept Learner: Self-supervised Learning of Concepts and  Mapping through Instruction Following",
    "abstract": "Humans, even at a very early age, can learn visual concepts and understand geometry and layout through active interaction with the environment, and generalize their compositions to complete tasks described by natural languages in novel scenes. To mimic such capability, we propose Embodied Concept Learner (ECL) in an interactive 3D environment. Specifically, a robot agent can ground visual concepts, build semantic maps and plan actions to complete tasks by learning purely from human demonstrations and language instructions, without access to ground-truth semantic and depth supervisions from simulations. ECL consists of: (i) an instruction parser that translates the natural languages into executable programs; (ii) an embodied concept learner that grounds visual concepts based on language descriptions; (iii) a map constructor that estimates depth and constructs semantic maps by leveraging the learned concepts; and (iv) a program executor with deterministic policies to execute each program. ECL has several appealing benefits thanks to its modularized design. Firstly, it enables the robotic agent to learn semantics and depth unsupervisedly acting like babies, e.g., ground concepts through active interaction and perceive depth by disparities when moving forward. Secondly, ECL is fully transparent and step-by-step interpretable in long-term planning. Thirdly, ECL could be beneficial for the embodied instruction following (EIF), outperforming previous works on the ALFRED benchmark when the semantic label is not provided. Also, the learned concept can be reused for other downstream tasks, such as reasoning of object states. Project page: this http URL ",
    "url": "https://arxiv.org/abs/2304.03767",
    "authors": [
      "Mingyu Ding",
      "Yan Xu",
      "Zhenfang Chen",
      "David Daniel Cox",
      "Ping Luo",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2106.05847",
    "title": "Unfolding the multiscale structure of networks with dynamical  Ollivier-Ricci curvature",
    "abstract": "Describing networks geometrically through low-dimensional latent metric spaces has helped design efficient learning algorithms, unveil network symmetries and study dynamical network processes. However, latent space embeddings are limited to specific classes of networks because incompatible metric spaces generally result in information loss. Here, we study arbitrary networks geometrically by defining a dynamic edge curvature measuring the similarity between pairs of dynamical network processes seeded at nearby nodes. We show that the evolution of the curvature distribution exhibits gaps at characteristic timescales indicating bottleneck-edges that limit information spreading. Importantly, curvature gaps are robust to large fluctuations in node degrees, encoding communities until the phase transition of detectability, where spectral and node-clustering methods fail. Using this insight, we derive geometric modularity to find multiscale communities based on deviations from constant network curvature in generative and real-world networks, significantly outperforming most previous methods. Our work suggests using network geometry for studying and controlling the structure of and information spreading on networks. ",
    "url": "https://arxiv.org/abs/2106.05847",
    "authors": [
      "Adam Gosztolai",
      "Alexis Arnaudon"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2304.03297",
    "title": "Neural Operator Learning for Ultrasound Tomography Inversion",
    "abstract": "Neural operator learning as a means of mapping between complex function spaces has garnered significant attention in the field of computational science and engineering (CS&E). In this paper, we apply Neural operator learning to the time-of-flight ultrasound computed tomography (USCT) problem. We learn the mapping between time-of-flight (TOF) data and the heterogeneous sound speed field using a full-wave solver to generate the training data. This novel application of operator learning circumnavigates the need to solve the computationally intensive iterative inverse problem. The operator learns the non-linear mapping offline and predicts the heterogeneous sound field with a single forward pass through the model. This is the first time operator learning has been used for ultrasound tomography and is the first step in potential real-time predictions of soft tissue distribution for tumor identification in beast imaging. ",
    "url": "https://arxiv.org/abs/2304.03297",
    "authors": [
      "Haocheng Dai",
      "Michael Penwarden",
      "Robert M. Kirby",
      "Sarang Joshi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03361",
    "title": "NMR shift prediction from small data quantities",
    "abstract": "Prediction of chemical shift in NMR using machine learning methods is typically done with the maximum amount of data available to achieve the best results. In some cases, such large amounts of data are not available, e.g. for heteronuclei. We demonstrate a novel machine learning model which is able to achieve good results with comparatively low amounts of data. We show this by predicting 19F and 13C NMR chemical shifts of small molecules in specific solvents. ",
    "url": "https://arxiv.org/abs/2304.03361",
    "authors": [
      "Herman Rull",
      "Markus Fischer",
      "Stefan Kuhn"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03398",
    "title": "Quantum Conformal Prediction for Reliable Uncertainty Quantification in  Quantum Machine Learning",
    "abstract": "Quantum machine learning is a promising programming paradigm for the optimization of quantum algorithms in the current era of noisy intermediate scale quantum (NISQ) computers. A fundamental challenge in quantum machine learning is generalization, as the designer targets performance under testing conditions, while having access only to limited training data. Existing generalization analyses, while identifying important general trends and scaling laws, cannot be used to assign reliable and informative \"error bars\" to the decisions made by quantum models. In this article, we propose a general methodology that can reliably quantify the uncertainty of quantum models, irrespective of the amount of training data, of the number of shots, of the ansatz, of the training algorithm, and of the presence of quantum hardware noise. The approach, which builds on probabilistic conformal prediction, turns an arbitrary, possibly small, number of shots from a pre-trained quantum model into a set prediction, e.g., an interval, that provably contains the true target with any desired coverage level. Experimental results confirm the theoretical calibration guarantees of the proposed framework, referred to as quantum conformal prediction. ",
    "url": "https://arxiv.org/abs/2304.03398",
    "authors": [
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03408",
    "title": "Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean  Field Neural Networks",
    "abstract": "We analyze the dynamics of finite width effects in wide but finite feature learning neural networks. Unlike many prior analyses, our results, while perturbative in width, are non-perturbative in the strength of feature learning. Starting from a dynamical mean field theory (DMFT) description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\\mathcal{O}(1/\\sqrt{\\text{width}})$ fluctuations of the DMFT order parameters over random initialization of the network weights. In the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. However, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with variance that can be computed self-consistently. In two layer networks, we show how feature learning can dynamically reduce the variance of the final NTK and final network predictions. We also show how initialization variance can slow down online learning in wide but finite networks. In deeper networks, kernel variance can dramatically accumulate through subsequent layers at large feature learning strengths, but feature learning continues to improve the SNR of the feature kernels. In discrete time, we demonstrate that large learning rate phenomena such as edge of stability effects can be well captured by infinite width dynamics and that initialization variance can decrease dynamically. For CNNs trained on CIFAR-10, we empirically find significant corrections to both the bias and variance of network dynamics due to finite width. ",
    "url": "https://arxiv.org/abs/2304.03408",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03507",
    "title": "Distributional Signals for Node Classification in Graph Neural Networks",
    "abstract": "In graph neural networks (GNNs), both node features and labels are examples of graph signals, a key notion in graph signal processing (GSP). While it is common in GSP to impose signal smoothness constraints in learning and estimation tasks, it is unclear how this can be done for discrete node labels. We bridge this gap by introducing the concept of distributional graph signals. In our framework, we work with the distributions of node labels instead of their values and propose notions of smoothness and non-uniformity of such distributional graph signals. We then propose a general regularization method for GNNs that allows us to encode distributional smoothness and non-uniformity of the model output in semi-supervised node classification tasks. Numerical experiments demonstrate that our method can significantly improve the performance of most base GNN models in different problem settings. ",
    "url": "https://arxiv.org/abs/2304.03507",
    "authors": [
      "Feng Ji",
      "See Hian Lee",
      "Kai Zhao",
      "Wee Peng Tay",
      "Jielong Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03515",
    "title": "Margin-Mixup: A Method for Robust Speaker Verification in Multi-Speaker  Audio",
    "abstract": "This paper is concerned with the task of speaker verification on audio with multiple overlapping speakers. Most speaker verification systems are designed with the assumption of a single speaker being present in a given audio segment. However, in a real-world setting this assumption does not always hold. In this paper, we demonstrate that current speaker verification systems are not robust against audio with noticeable speaker overlap. To alleviate this issue, we propose margin-mixup, a simple training strategy that can easily be adopted by existing speaker verification pipelines to make the resulting speaker embeddings robust against multi-speaker audio. In contrast to other methods, margin-mixup requires no alterations to regular speaker verification architectures, while attaining better results. On our multi-speaker test set based on VoxCeleb1, the proposed margin-mixup strategy improves the EER on average with 44.4% relative to our state-of-the-art speaker verification baseline systems. ",
    "url": "https://arxiv.org/abs/2304.03515",
    "authors": [
      "Jenthe Thienpondt",
      "Nilesh Madhu",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2304.03590",
    "title": "Graphon Estimation in bipartite graphs with observable edge labels and  unobservable node labels",
    "abstract": "Many real-world data sets can be presented in the form of a matrix whose entries correspond to the interaction between two entities of different natures (number of times a web user visits a web page, a student's grade in a subject, a patient's rating of a doctor, etc.). We assume in this paper that the mentioned interaction is determined by unobservable latent variables describing each entity. Our objective is to estimate the conditional expectation of the data matrix given the unobservable variables. This is presented as a problem of estimation of a bivariate function referred to as graphon. We study the cases of piecewise constant and H\\\"older-continuous graphons. We establish finite sample risk bounds for the least squares estimator and the exponentially weighted aggregate. These bounds highlight the dependence of the estimation error on the size of the data set, the maximum intensity of the interactions, and the level of noise. As the analyzed least-squares estimator is intractable, we propose an adaptation of Lloyd's alternating minimization algorithm to compute an approximation of the least-squares estimator. Finally, we present numerical experiments in order to illustrate the empirical performance of the graphon estimator on synthetic data sets. ",
    "url": "https://arxiv.org/abs/2304.03590",
    "authors": [
      "Etienne Donier-Meroz",
      "Arnak S. Dalalyan",
      "Francis Kramarz",
      "Philippe Chon\u00e9",
      "Xavier D'Haultfoeuille"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03689",
    "title": "EPINN-NSE: Enhanced Physics-Informed Neural Networks for Solving  Navier-Stokes Equations",
    "abstract": "Fluid mechanics is a fundamental field in engineering and science. Solving the Navier-Stokes equation (NSE) is critical for understanding the behavior of fluids. However, the NSE is a complex partial differential equation that is difficult to solve, and classical numerical methods can be computationally expensive. In this paper, we present an innovative approach for solving the NSE using Physics Informed Neural Networks (PINN) and several novel techniques that improve their performance. The first model is based on an assumption that involves approximating the velocity component by employing the derivative of a stream function. This assumption serves to simplify the system and guarantees that the velocity adheres to the divergence-free equation. We also developed a second more flexible model that approximates the solution without any assumptions. The proposed models can effectively solve two-dimensional NSE. Moreover, we successfully applied the second model to solve the three-dimensional NSE. The results show that the models can efficiently and accurately solve the NSE in three dimensions. These approaches offer several advantages, including high trainability, flexibility, and efficiency. ",
    "url": "https://arxiv.org/abs/2304.03689",
    "authors": [
      "Ayoub Farkane",
      "Mounir Ghogho",
      "Mustapha Oudani",
      "Mohamed Boutayeb"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03694",
    "title": "High Accuracy Uncertainty-Aware Interatomic Force Modeling with  Equivariant Bayesian Neural Networks",
    "abstract": "Even though Bayesian neural networks offer a promising framework for modeling uncertainty, active learning and incorporating prior physical knowledge, few applications of them can be found in the context of interatomic force modeling. One of the main challenges in their application to learning interatomic forces is the lack of suitable Monte Carlo Markov chain sampling algorithms for the posterior density, as the commonly used algorithms do not converge in a practical amount of time for many of the state-of-the-art architectures. As a response to this challenge, we introduce a new Monte Carlo Markov chain sampling algorithm in this paper which can circumvent the problems of the existing sampling methods. In addition, we introduce a new stochastic neural network model based on the NequIP architecture and demonstrate that, when combined with our novel sampling algorithm, we obtain predictions with state-of-the-art accuracy as well as a good measure of uncertainty. ",
    "url": "https://arxiv.org/abs/2304.03694",
    "authors": [
      "Tim Rensmeyer",
      "Benjamin Craig",
      "Denis Kramer",
      "Oliver Niggemann"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2108.08481",
    "title": "Neural Operator: Learning Maps Between Function Spaces",
    "abstract": " Title: Neural Operator: Learning Maps Between Function Spaces ",
    "url": "https://arxiv.org/abs/2108.08481",
    "authors": [
      "Nikola Kovachki",
      "Zongyi Li",
      "Burigede Liu",
      "Kamyar Azizzadenesheli",
      "Kaushik Bhattacharya",
      "Andrew Stuart",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2110.11155",
    "title": "DeLag: Using Multi-Objective Optimization to Enhance the Detection of  Latency Degradation Patterns in Service-based Systems",
    "abstract": " Comments: Accepted for publication in IEEE Transactions on Software Engineering (TSE) ",
    "url": "https://arxiv.org/abs/2110.11155",
    "authors": [
      "Luca Traini",
      "Vittorio Cortellessa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2111.08644",
    "title": "UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection",
    "abstract": " Comments: Accepted at CVPR 2022. Paper + supplementary (15 pages, 9 figures) ",
    "url": "https://arxiv.org/abs/2111.08644",
    "authors": [
      "Andra Acsintoae",
      "Andrei Florescu",
      "Mariana-Iuliana Georgescu",
      "Tudor Mare",
      "Paul Sumedrea",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.00319",
    "title": "Object-Aware Cropping for Self-Supervised Learning",
    "abstract": " Title: Object-Aware Cropping for Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2112.00319",
    "authors": [
      "Shlok Mishra",
      "Anshul Shah",
      "Ankan Bansal",
      "Abhyuday Jagannatha",
      "Janit Anjaria",
      "Abhishek Sharma",
      "David Jacobs",
      "Dilip Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04683",
    "title": "Dynamic Flow Equilibrium of Transportation and Power Distribution  Networks Considering Flexible Traveling Choices and Voltage Quality  Improvement",
    "abstract": " Title: Dynamic Flow Equilibrium of Transportation and Power Distribution  Networks Considering Flexible Traveling Choices and Voltage Quality  Improvement ",
    "url": "https://arxiv.org/abs/2112.04683",
    "authors": [
      "Jiaqi Li",
      "Xiaoyuan Xu",
      "Zheng Yan",
      "Han Wang",
      "Yue Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.02090",
    "title": "Bayesian community detection for networks with covariates",
    "abstract": " Title: Bayesian community detection for networks with covariates ",
    "url": "https://arxiv.org/abs/2203.02090",
    "authors": [
      "Luyi Shen",
      "Arash Amini",
      "Nathaniel Josephs",
      "Lizhen Lin"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.06552",
    "title": "Neural Vector Fields for Implicit Surface Representation and Inference",
    "abstract": " Title: Neural Vector Fields for Implicit Surface Representation and Inference ",
    "url": "https://arxiv.org/abs/2204.06552",
    "authors": [
      "Edoardo Mello Rella",
      "Ajad Chhatkuli",
      "Ender Konukoglu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14354",
    "title": "Multi-Task Learning with Multi-Query Transformer for Dense Prediction",
    "abstract": " Title: Multi-Task Learning with Multi-Query Transformer for Dense Prediction ",
    "url": "https://arxiv.org/abs/2205.14354",
    "authors": [
      "Yangyang Xu",
      "Xiangtai Li",
      "Haobo Yuan",
      "Yibo Yang",
      "Lefei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.02066",
    "title": "PIDNet: A Real-time Semantic Segmentation Network Inspired by PID  Controllers",
    "abstract": " Comments: 11 pages, 9 figures; This paper will be published by CVPR2023 soon, please refer to the official version then ",
    "url": "https://arxiv.org/abs/2206.02066",
    "authors": [
      "Jiacong Xu",
      "Zixiang Xiong",
      "Shankar P. Bhattacharyya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.01398",
    "title": "Large-scale Robustness Analysis of Video Action Recognition Models",
    "abstract": " Comments: Accepted in 2023 Conference on Computer Vision and Pattern Recognition (CVPR) ",
    "url": "https://arxiv.org/abs/2207.01398",
    "authors": [
      "Madeline Chantry Schiappa",
      "Naman Biyani",
      "Prudvi Kamtam",
      "Shruti Vyas",
      "Hamid Palangi",
      "Vibhav Vineet",
      "Yogesh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.01463",
    "title": "Explicit Boundary Guided Semi-Push-Pull Contrastive Learning for  Supervised Anomaly Detection",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2207.01463",
    "authors": [
      "Xincheng Yao",
      "Ruoqi Li",
      "Jing Zhang",
      "Jun Sun",
      "Chongyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03368",
    "title": "Machine learning of percolation models using graph convolutional neural  networks",
    "abstract": " Comments: Data from unsupervised machine learning method need to be re-examined ",
    "url": "https://arxiv.org/abs/2207.03368",
    "authors": [
      "Hua Tian",
      "Lirong Zhang",
      "Youjin Deng",
      "Wanzhou Zhang"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08349",
    "title": "Retweet-BERT: Political Leaning Detection Using Language Features and  Information Diffusion on Social Networks",
    "abstract": " Comments: 11 pages, 3 figures, 4 tables. arXiv admin note: text overlap with arXiv:2103.10979 ",
    "url": "https://arxiv.org/abs/2207.08349",
    "authors": [
      "Julie Jiang",
      "Xiang Ren",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2208.12933",
    "title": "Consistency between ordering and clustering methods for graphs",
    "abstract": " Comments: 30 pages, 26 figures ",
    "url": "https://arxiv.org/abs/2208.12933",
    "authors": [
      "Tatsuro Kawamoto",
      "Masaki Ochi",
      "Teruyoshi Kobayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.05810",
    "title": "A unified model for continuous conditional video prediction",
    "abstract": " Comments: Accepted by CVPR2023 Workshop ",
    "url": "https://arxiv.org/abs/2210.05810",
    "authors": [
      "Xi Ye",
      "Guillaume-Alexandre Bilodeau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08398",
    "title": "SPIDR: SDF-based Neural Point Fields for Illumination and Deformation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2210.08398",
    "authors": [
      "Ruofan Liang",
      "Jiahao Zhang",
      "Haoda Li",
      "Chen Yang",
      "Yushi Guan",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.15446",
    "title": "LP-BFGS attack: An adversarial attack based on the Hessian with limited  pixels",
    "abstract": " Comments: 15 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2210.15446",
    "authors": [
      "Jiebao Zhang",
      "Wenhua Qian",
      "Rencan Nie",
      "Jinde Cao",
      "Dan Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12044",
    "title": "Backdoor Cleansing with Unlabeled Data",
    "abstract": " Title: Backdoor Cleansing with Unlabeled Data ",
    "url": "https://arxiv.org/abs/2211.12044",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.12952",
    "title": "Neural Shape Compiler: A Unified Framework for Transforming between  Text, Point Cloud, and Program",
    "abstract": " Comments: TMLR; project page: this https URL ",
    "url": "https://arxiv.org/abs/2212.12952",
    "authors": [
      "Tiange Luo",
      "Honglak Lee",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.04347",
    "title": "Counteracts: Testing Stereotypical Representation in Pre-trained  Language Models",
    "abstract": " Comments: WIP; to be submitted ",
    "url": "https://arxiv.org/abs/2301.04347",
    "authors": [
      "Damin Zhang",
      "Julia Rayz",
      "Romila Pradhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.07284",
    "title": "Label Inference Attack against Split Learning under Regression Setting",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2301.07284",
    "authors": [
      "Shangyu Xie",
      "Xin Yang",
      "Yuanshun Yao",
      "Tianyi Liu",
      "Taiqing Wang",
      "Jiankai Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09479",
    "title": "Modality-Agnostic Variational Compression of Implicit Neural  Representations",
    "abstract": " Title: Modality-Agnostic Variational Compression of Implicit Neural  Representations ",
    "url": "https://arxiv.org/abs/2301.09479",
    "authors": [
      "Jonathan Richard Schwarz",
      "Jihoon Tack",
      "Yee Whye Teh",
      "Jaeho Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.09588",
    "title": "A Digital Delay Model Supporting Large Adversarial Delay Variations",
    "abstract": " Title: A Digital Delay Model Supporting Large Adversarial Delay Variations ",
    "url": "https://arxiv.org/abs/2301.09588",
    "authors": [
      "Daniel \u00d6hlinger",
      "Ulrich Schmid"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2302.00064",
    "title": "Evaluating Temporal Observation-Based Causal Discovery Techniques  Applied to Road Driver Behaviour",
    "abstract": " Comments: 26 Pages = 13 Pages (Main Content) + 5 Pages (References) + 8 Pages (Appendix), 2 Figures, To be published in the Proceedings of the 2nd Conference on Causal Learning and Reasoning as part of the Journal of Machine Learning Research Workshop and Conference Proceedings series, Final submission version; Updated from initial to final submission version ",
    "url": "https://arxiv.org/abs/2302.00064",
    "authors": [
      "Rhys Howard",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.00196",
    "title": "An Axiomatic Characterization of CFMMs and Equivalence to Prediction  Markets",
    "abstract": " Title: An Axiomatic Characterization of CFMMs and Equivalence to Prediction  Markets ",
    "url": "https://arxiv.org/abs/2302.00196",
    "authors": [
      "Rafael Frongillo",
      "Maneesha Papireddygari",
      "Bo Waggoner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.09051",
    "title": "Complex QA and language models hybrid architectures, Survey",
    "abstract": " Title: Complex QA and language models hybrid architectures, Survey ",
    "url": "https://arxiv.org/abs/2302.09051",
    "authors": [
      "Xavier Daull",
      "Patrice Bellot",
      "Emmanuel Bruno",
      "Vincent Martin",
      "Elisabeth Murisasco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.10632",
    "title": "Multi-Modal Self-Supervised Learning for Recommendation",
    "abstract": " Comments: This paper has been published as a full paper at WWW 2023 ",
    "url": "https://arxiv.org/abs/2302.10632",
    "authors": [
      "Wei Wei",
      "Chao Huang",
      "Lianghao Xia",
      "Chuxu Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2302.12744",
    "title": "Anomalous NO2 emitting ship detection with TROPOMI satellite data and  machine learning",
    "abstract": " Title: Anomalous NO2 emitting ship detection with TROPOMI satellite data and  machine learning ",
    "url": "https://arxiv.org/abs/2302.12744",
    "authors": [
      "Solomiia Kurchaba",
      "Jasper van Vliet",
      "Fons J. Verbeek",
      "Cor J. Veenman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2303.02468",
    "title": "Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for  Soft and Hard Label Prediction",
    "abstract": " Title: Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for  Soft and Hard Label Prediction ",
    "url": "https://arxiv.org/abs/2303.02468",
    "authors": [
      "Peyman Hosseini",
      "Mehran Hosseini",
      "Sana Sabah Al-Azzawi",
      "Marcus Liwicki",
      "Ignacio Castro",
      "Matthew Purver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.14548",
    "title": "Viewpoint Equivariance for Multi-View 3D Object Detection",
    "abstract": " Comments: 11 pages, 4 figures; accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.14548",
    "authors": [
      "Dian Chen",
      "Jie Li",
      "Vitor Guizilini",
      "Rares Ambrus",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.15991",
    "title": "Efficient Parallel Split Learning over Resource-constrained Wireless  Edge Networks",
    "abstract": " Comments: 15 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2303.15991",
    "authors": [
      "Zheng Lin",
      "Guangyu Zhu",
      "Yiqin Deng",
      "Xianhao Chen",
      "Yue Gao",
      "Kaibin Huang",
      "Yuguang Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17066",
    "title": "Reading Strategies for Graph Visualizations that Wrap Around in Torus  Topology",
    "abstract": " Title: Reading Strategies for Graph Visualizations that Wrap Around in Torus  Topology ",
    "url": "https://arxiv.org/abs/2303.17066",
    "authors": [
      "Kun-Ting Chen",
      "Quynh Quang Ngo",
      "Kuno Kurzhals",
      "Kim Marriott",
      "Tim Dwyer",
      "Michael Sedlmair",
      "Daniel Weiskopf"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.17610",
    "title": "Ensemble weather forecast post-processing with a flexible probabilistic  neural network approach",
    "abstract": " Title: Ensemble weather forecast post-processing with a flexible probabilistic  neural network approach ",
    "url": "https://arxiv.org/abs/2303.17610",
    "authors": [
      "Peter Mlakar",
      "Janko Mer\u0161e",
      "Jana Faganeli Pucer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2304.00733",
    "title": "Unbiased Scene Graph Generation in Videos",
    "abstract": " Comments: To appear in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023 ",
    "url": "https://arxiv.org/abs/2304.00733",
    "authors": [
      "Sayak Nag",
      "Kyle Min",
      "Subarna Tripathi",
      "Amit K. Roy Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.01598",
    "title": "MM-BSN: Self-Supervised Image Denoising for Real-World with Multi-Mask  based on Blind-Spot Network",
    "abstract": " Comments: Accepted by CVPRW 2023 ",
    "url": "https://arxiv.org/abs/2304.01598",
    "authors": [
      "Dan Zhang",
      "Fangfang Zhou",
      "Yuwen Jiang",
      "Zhengming Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.02911",
    "title": "Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks",
    "abstract": " Title: Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2304.02911",
    "authors": [
      "Xuanzhe Xiao",
      "Zeng Li",
      "Chuanlong Xie",
      "Fengwei Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03093",
    "title": "Inductive Graph Unlearning",
    "abstract": " Comments: To appear in the 32nd USENIX Security Symposium, August 2023, Anaheim, CA, USA ",
    "url": "https://arxiv.org/abs/2304.03093",
    "authors": [
      "Cheng-Long Wang",
      "Mengdi Huai",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.03105",
    "title": "Geometric-aware Pretraining for Vision-centric 3D Object Detection",
    "abstract": " Comments: 15 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2304.03105",
    "authors": [
      "Linyan Huang",
      "Huijie Wang",
      "Jia Zeng",
      "Shengchuan Zhang",
      "Liujuan Cao",
      "Junchi Yan",
      "Hongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03216",
    "title": "On the Pareto Front of Multilingual Neural Machine Translation",
    "abstract": " Comments: 14 pages, 6 figures, code released at this https URL ",
    "url": "https://arxiv.org/abs/2304.03216",
    "authors": [
      "Liang Chen",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]