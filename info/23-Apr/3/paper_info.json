[
  {
    "id": "arXiv:2303.17610",
    "title": "Ensemble weather forecast post-processing with a flexible probabilistic  neural network approach",
    "abstract": "Ensemble forecast post-processing is a necessary step in producing accurate probabilistic forecasts. Conventional post-processing methods operate by estimating the parameters of a parametric distribution, frequently on a per-location or per-lead-time basis. We propose a novel, neural network-based method, which produces forecasts for all locations and lead times, jointly. To relax the distributional assumption of many post-processing methods, our approach incorporates normalizing flows as flexible parametric distribution estimators. This enables us to model varying forecast distributions in a mathematically exact way. We demonstrate the effectiveness of our method in the context of the EUPPBench benchmark, where we conduct temperature forecast post-processing for stations in a sub-region of western Europe. We show that our novel method exhibits state-of-the-art performance on the benchmark, outclassing our previous, well-performing entry. Additionally, by providing a detailed comparison of three variants of our novel post-processing method, we elucidate the reasons why our method outperforms per-lead-time-based approaches and approaches with distributional assumptions. ",
    "url": "https://arxiv.org/abs/2303.17610",
    "authors": [
      "Peter Mlakar",
      "Janko Mer\u0161e",
      "Jana Faganeli Pucer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2303.17611",
    "title": "Transformer-based Self-supervised Multimodal Representation Learning for  Wearable Emotion Recognition",
    "abstract": "Recently, wearable emotion recognition based on peripheral physiological signals has drawn massive attention due to its less invasive nature and its applicability in real-life scenarios. However, how to effectively fuse multimodal data remains a challenging problem. Moreover, traditional fully-supervised based approaches suffer from overfitting given limited labeled data. To address the above issues, we propose a novel self-supervised learning (SSL) framework for wearable emotion recognition, where efficient multimodal fusion is realized with temporal convolution-based modality-specific encoders and a transformer-based shared encoder, capturing both intra-modal and inter-modal correlations. Extensive unlabeled data is automatically assigned labels by five signal transforms, and the proposed SSL model is pre-trained with signal transformation recognition as a pretext task, allowing the extraction of generalized multimodal representations for emotion-related downstream tasks. For evaluation, the proposed SSL model was first pre-trained on a large-scale self-collected physiological dataset and the resulting encoder was subsequently frozen or fine-tuned on three public supervised emotion recognition datasets. Ultimately, our SSL-based method achieved state-of-the-art results in various emotion classification tasks. Meanwhile, the proposed model proved to be more accurate and robust compared to fully-supervised methods on low data regimes. ",
    "url": "https://arxiv.org/abs/2303.17611",
    "authors": [
      "Yujin Wu",
      "Mohamed Daoudi",
      "Ali Amad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.17616",
    "title": "Patterns Detection in Glucose Time Series by Domain Transformations and  Deep Learning",
    "abstract": "People with diabetes have to manage their blood glucose level to keep it within an appropriate range. Predicting whether future glucose values will be outside the healthy threshold is of vital importance in order to take corrective actions to avoid potential health damage. In this paper we describe our research with the aim of predicting the future behavior of blood glucose levels, so that hypoglycemic events may be anticipated. The approach of this work is the application of transformation functions on glucose time series, and their use in convolutional neural networks. We have tested our proposed method using real data from 4 different diabetes patients with promising results. ",
    "url": "https://arxiv.org/abs/2303.17616",
    "authors": [
      "J. Alvarado",
      "J. Manuel Velasco",
      "F. Ch\u00e1vez",
      "J.Ignacio Hidalgo",
      "F. Fern\u00e1ndez de Vega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2303.17646",
    "title": "XPert: Peripheral Circuit & Neural Architecture Co-search for Area and  Energy-efficient Xbar-based Computing",
    "abstract": "The hardware-efficiency and accuracy of Deep Neural Networks (DNNs) implemented on In-memory Computing (IMC) architectures primarily depend on the DNN architecture and the peripheral circuit parameters. It is therefore essential to holistically co-search the network and peripheral parameters to achieve optimal performance. To this end, we propose XPert, which co-searches network architecture in tandem with peripheral parameters such as the type and precision of analog-to-digital converters, crossbar column sharing and the layer-specific input precision using an optimization-based design space exploration. Compared to VGG16 baselines, XPert achieves 10.24x (4.7x) lower EDAP, 1.72x (1.62x) higher TOPS/W,1.93x (3x) higher TOPS/mm2 at 92.46% (56.7%) accuracy for CIFAR10 (TinyImagenet) datasets. The code for this paper is available at https://github.com/Intelligent-Computing-Lab-Yale/XPert. ",
    "url": "https://arxiv.org/abs/2303.17646",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17658",
    "title": "Establishing baselines and introducing TernaryMixOE for fine-grained  out-of-distribution detection",
    "abstract": "Machine learning models deployed in the open world may encounter observations that they were not trained to recognize, and they risk misclassifying such observations with high confidence. Therefore, it is essential that these models are able to ascertain what is in-distribution (ID) and out-of-distribution (OOD), to avoid this misclassification. In recent years, huge strides have been made in creating models that are robust to this distinction. As a result, the current state-of-the-art has reached near perfect performance on relatively coarse-grained OOD detection tasks, such as distinguishing horses from trucks, while struggling with finer-grained classification, like differentiating models of commercial aircraft. In this paper, we describe a new theoretical framework for understanding fine- and coarse-grained OOD detection, we re-conceptualize fine grained classification into a three part problem, and we propose a new baseline task for OOD models on two fine-grained hierarchical data sets, two new evaluation methods to differentiate fine- and coarse-grained OOD performance, along with a new loss function for models in this task. ",
    "url": "https://arxiv.org/abs/2303.17658",
    "authors": [
      "Noah Fleischmann",
      "Walter Bennette",
      "Nathan Inkawhich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17688",
    "title": "Learning Garment DensePose for Robust Warping in Virtual Try-On",
    "abstract": "Virtual try-on, i.e making people virtually try new garments, is an active research area in computer vision with great commercial applications. Current virtual try-on methods usually work in a two-stage pipeline. First, the garment image is warped on the person's pose using a flow estimation network. Then in the second stage, the warped garment is fused with the person image to render a new try-on image. Unfortunately, such methods are heavily dependent on the quality of the garment warping which often fails when dealing with hard poses (e.g., a person lifting or crossing arms). In this work, we propose a robust warping method for virtual try-on based on a learned garment DensePose which has a direct correspondence with the person's DensePose. Due to the lack of annotated data, we show how to leverage an off-the-shelf person DensePose model and a pretrained flow model to learn the garment DensePose in a weakly supervised manner. The garment DensePose allows a robust warping to any person's pose without any additional computation. Our method achieves the state-of-the-art equivalent on virtual try-on benchmarks and shows warping robustness on in-the-wild person images with hard poses, making it more suited for real-world virtual try-on applications. ",
    "url": "https://arxiv.org/abs/2303.17688",
    "authors": [
      "Aiyu Cui",
      "Sen He",
      "Tao Xiang",
      "Antoine Toisoul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17712",
    "title": "S-VolSDF: Sparse Multi-View Stereo Regularization of Neural Implicit  Surfaces",
    "abstract": "Neural rendering of implicit surfaces performs well in 3D vision applications. However, it requires dense input views as supervision. When only sparse input images are available, output quality drops significantly due to the shape-radiance ambiguity problem. We note that this ambiguity can be constrained when a 3D point is visible in multiple views, as is the case in multi-view stereo (MVS). We thus propose to regularize neural rendering optimization with an MVS solution. The use of an MVS probability volume and a generalized cross entropy loss leads to a noise-tolerant optimization process. In addition, neural rendering provides global consistency constraints that guide the MVS depth hypothesis sampling and thus improves MVS performance. Given only three sparse input views, experiments show that our method not only outperforms generic neural rendering models by a large margin but also significantly increases the reconstruction quality of MVS models. Project webpage: https://hao-yu-wu.github.io/s-volsdf/. ",
    "url": "https://arxiv.org/abs/2303.17712",
    "authors": [
      "Haoyu Wu",
      "Alexandros Graikos",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17720",
    "title": "Generating Adversarial Samples in Mini-Batches May Be Detrimental To  Adversarial Robustness",
    "abstract": "Neural networks have been proven to be both highly effective within computer vision, and highly vulnerable to adversarial attacks. Consequently, as the use of neural networks increases due to their unrivaled performance, so too does the threat posed by adversarial attacks. In this work, we build towards addressing the challenge of adversarial robustness by exploring the relationship between the mini-batch size used during adversarial sample generation and the strength of the adversarial samples produced. We demonstrate that an increase in mini-batch size results in a decrease in the efficacy of the samples produced, and we draw connections between these observations and the phenomenon of vanishing gradients. Next, we formulate loss functions such that adversarial sample strength is not degraded by mini-batch size. Our findings highlight a potential risk for underestimating the true (practical) strength of adversarial attacks, and a risk of overestimating a model's robustness. We share our codes to let others replicate our experiments and to facilitate further exploration of the connections between batch size and adversarial sample strength. ",
    "url": "https://arxiv.org/abs/2303.17720",
    "authors": [
      "Timothy Redgrave",
      "Colton Crum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17727",
    "title": "BOLT: An Automated Deep Learning Framework for Training and Deploying  Large-Scale Neural Networks on Commodity CPU Hardware",
    "abstract": "Efficient large-scale neural network training and inference on commodity CPU hardware is of immense practical significance in democratizing deep learning (DL) capabilities. Presently, the process of training massive models consisting of hundreds of millions to billions of parameters requires the extensive use of specialized hardware accelerators, such as GPUs, which are only accessible to a limited number of institutions with considerable financial resources. Moreover, there is often an alarming carbon footprint associated with training and deploying these models. In this paper, we address these challenges by introducing BOLT, a sparse deep learning library for training massive neural network models on standard CPU hardware. BOLT provides a flexible, high-level API for constructing models that will be familiar to users of existing popular DL frameworks. By automatically tuning specialized hyperparameters, BOLT also abstracts away the algorithmic details of sparse network training. We evaluate BOLT on a number of machine learning tasks drawn from recommendations, search, natural language processing, and personalization. We find that our proposed system achieves competitive performance with state-of-the-art techniques at a fraction of the cost and energy consumption and an order-of-magnitude faster inference time. BOLT has also been successfully deployed by multiple businesses to address critical problems, and we highlight one customer deployment case study in the field of e-commerce. ",
    "url": "https://arxiv.org/abs/2303.17727",
    "authors": [
      "Nicholas Meisburger",
      "Vihan Lakshman",
      "Benito Geordie",
      "Joshua Engels",
      "David Torres Ramos",
      "Pratik Pranav",
      "Benjamin Coleman",
      "Benjamin Meisburger",
      "Shubh Gupta",
      "Yashwanth Adunukota",
      "Tharun Medini",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17732",
    "title": "Optimal Input Gain: All You Need to Supercharge a Feed-Forward Neural  Network",
    "abstract": "Linear transformation of the inputs alters the training performance of feed-forward networks that are otherwise equivalent. However, most linear transforms are viewed as a pre-processing operation separate from the actual training. Starting from equivalent networks, it is shown that pre-processing inputs using linear transformation are equivalent to multiplying the negative gradient matrix with an autocorrelation matrix per training iteration. Second order method is proposed to find the autocorrelation matrix that maximizes learning in a given iteration. When the autocorrelation matrix is diagonal, the method optimizes input gains. This optimal input gain (OIG) approach is used to improve two first-order two-stage training algorithms, namely back-propagation (BP) and hidden weight optimization (HWO), which alternately update the input weights and solve linear equations for output weights. Results show that the proposed OIG approach greatly enhances the performance of the first-order algorithms, often allowing them to rival the popular Levenberg-Marquardt approach with far less computation. It is shown that HWO is equivalent to BP with Whitening transformation applied to the inputs. HWO effectively combines Whitening transformation with learning. Thus, OIG improved HWO could be a significant building block to more complex deep learning architectures. ",
    "url": "https://arxiv.org/abs/2303.17732",
    "authors": [
      "Chinmay Rane",
      "Kanishka Tyagi",
      "Sanjeev Malalur",
      "Yash Shinge",
      "Michael Manry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17743",
    "title": "FairGen: Towards Fair Graph Generation",
    "abstract": "There have been tremendous efforts over the past decades dedicated to the generation of realistic graphs in a variety of domains, ranging from social networks to computer networks, from gene regulatory networks to online transaction networks. Despite the remarkable success, the vast majority of these works are unsupervised in nature and are typically trained to minimize the expected graph reconstruction loss, which would result in the representation disparity issue in the generated graphs, i.e., the protected groups (often minorities) contribute less to the objective and thus suffer from systematically higher errors. In this paper, we aim to tailor graph generation to downstream mining tasks by leveraging label information and user-preferred parity constraint. In particular, we start from the investigation of representation disparity in the context of graph generative models. To mitigate the disparity, we propose a fairness-aware graph generative model named FairGen. Our model jointly trains a label-informed graph generation module and a fair representation learning module by progressively learning the behaviors of the protected and unprotected groups, from the `easy' concepts to the `hard' ones. In addition, we propose a generic context sampling strategy for graph generative models, which is proven to be capable of fairly capturing the contextual information of each group with a high probability. Experimental results on seven real-world data sets, including web-based graphs, demonstrate that FairGen (1) obtains performance on par with state-of-the-art graph generative models across six network properties, (2) mitigates the representation disparity issues in the generated graphs, and (3) substantially boosts the model performance by up to 17% in downstream tasks via data augmentation. ",
    "url": "https://arxiv.org/abs/2303.17743",
    "authors": [
      "Lecheng Zheng",
      "Dawei Zhou",
      "Hanghang Tong",
      "Jiejun Xu",
      "Yada Zhu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.17748",
    "title": "MLGCN: An Ultra Efficient Graph Convolution Neural Model For 3D Point  Cloud Analysis",
    "abstract": "The analysis of 3D point clouds has diverse applications in robotics, vision and graphics. Processing them presents specific challenges since they are naturally sparse, can vary in spatial resolution and are typically unordered. Graph-based networks to abstract features have emerged as a promising alternative to convolutional neural networks for their analysis, but these can be computationally heavy as well as memory inefficient. To address these limitations we introduce a novel Multi-level Graph Convolution Neural (MLGCN) model, which uses Graph Neural Networks (GNN) blocks to extract features from 3D point clouds at specific locality levels. Our approach employs precomputed graph KNNs, where each KNN graph is shared between GCN blocks inside a GNN block, making it both efficient and effective compared to present models. We demonstrate the efficacy of our approach on point cloud based object classification and part segmentation tasks on benchmark datasets, showing that it produces comparable results to those of state-of-the-art models while requiring up to a thousand times fewer floating-point operations (FLOPs) and having significantly reduced storage requirements. Thus, our MLGCN model could be particular relevant to point cloud based 3D shape analysis in industrial applications when computing resources are scarce. ",
    "url": "https://arxiv.org/abs/2303.17748",
    "authors": [
      "Mohammad Khodadad",
      "Morteza Rezanejad",
      "Ali Shiraee Kasmaee",
      "Kaleem Siddiqi",
      "Dirk Walther",
      "Hamidreza Mahyar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17764",
    "title": "Towards Adversarially Robust Continual Learning",
    "abstract": "Recent studies show that models trained by continual learning can achieve the comparable performances as the standard supervised learning and the learning flexibility of continual learning models enables their wide applications in the real world. Deep learning models, however, are shown to be vulnerable to adversarial attacks. Though there are many studies on the model robustness in the context of standard supervised learning, protecting continual learning from adversarial attacks has not yet been investigated. To fill in this research gap, we are the first to study adversarial robustness in continual learning and propose a novel method called \\textbf{T}ask-\\textbf{A}ware \\textbf{B}oundary \\textbf{A}ugmentation (TABA) to boost the robustness of continual learning models. With extensive experiments on CIFAR-10 and CIFAR-100, we show the efficacy of adversarial training and TABA in defending adversarial attacks. ",
    "url": "https://arxiv.org/abs/2303.17764",
    "authors": [
      "Tao Bai",
      "Chen Chen",
      "Lingjuan Lyu",
      "Jun Zhao",
      "Bihan Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17774",
    "title": "Semi-Weakly Supervised Object Kinematic Motion Prediction",
    "abstract": "Given a 3D object, kinematic motion prediction aims to identify the mobile parts as well as the corresponding motion parameters. Due to the large variations in both topological structure and geometric details of 3D objects, this remains a challenging task and the lack of large scale labeled data also constrain the performance of deep learning based approaches. In this paper, we tackle the task of object kinematic motion prediction problem in a semi-weakly supervised manner. Our key observations are two-fold. First, although 3D dataset with fully annotated motion labels is limited, there are existing datasets and methods for object part semantic segmentation at large scale. Second, semantic part segmentation and mobile part segmentation is not always consistent but it is possible to detect the mobile parts from the underlying 3D structure. Towards this end, we propose a graph neural network to learn the map between hierarchical part-level segmentation and mobile parts parameters, which are further refined based on geometric alignment. This network can be first trained on PartNet-Mobility dataset with fully labeled mobility information and then applied on PartNet dataset with fine-grained and hierarchical part-level segmentation. The network predictions yield a large scale of 3D objects with pseudo labeled mobility information and can further be used for weakly-supervised learning with pre-existing segmentation. Our experiments show there are significant performance boosts with the augmented data for previous method designed for kinematic motion prediction on 3D partial scans. ",
    "url": "https://arxiv.org/abs/2303.17774",
    "authors": [
      "Gengxin Liu",
      "Qian Sun",
      "Haibin Huang",
      "Chongyang Ma",
      "Yulan Guo",
      "Li Yi",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.17780",
    "title": "Towards Enhancing In-Context Learning for Code Generation",
    "abstract": "In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation. ICL does not require training. PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program. However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation. We refer to these studies as standard ICL. Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder. Compared to standard ICL, AceCoder has two novelties. (1) Example retrieval. It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them. (2) Guided Code Generation. It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs. The preliminary can help PTLMs understand requirements and guide the next code generation. We apply AceCoder to six PTLMs (e.g., Codex) and evaluate it on three public benchmarks using the Pass@k. Results show that AceCoder can significantly improve the performance of PTLMs on code generation. (1) In terms of Pass@1, AceCoder outperforms standard ICL by up to 79.7% and fine-tuned models by up to 171%. (2) AceCoder is effective in PTLMs with different sizes (e.g., 1B to 175B) and different languages (e.g., Python, Java, and JavaScript). (3) We investigate multiple choices of the intermediate preliminary. (4) We manually evaluate generated programs in three aspects and prove the superiority of AceCoder. (5) Finally, we discuss some insights about ICL for practitioners. ",
    "url": "https://arxiv.org/abs/2303.17780",
    "authors": [
      "Jia Li",
      "Yunfei Zhao",
      "Yongmin Li",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17783",
    "title": "SOSR: Source-Free Image Super-Resolution with Wavelet Augmentation  Transformer",
    "abstract": "Real-world images taken by different cameras with different degradation kernels often result in a cross-device domain gap in image super-resolution. A prevalent attempt to this issue is unsupervised domain adaptation (UDA) that needs to access source data. Considering privacy policies or transmission restrictions of data in many practical applications, we propose a SOurce-free image Super-Resolution framework (SOSR) to address this issue, i.e., adapt a model pre-trained on labeled source data to a target domain with only unlabeled target data. SOSR leverages the source model to generate refined pseudo-labels for teacher-student learning. To better utilize the pseudo-labels, this paper proposes a novel wavelet-based augmentation method, named Wavelet Augmentation Transformer (WAT), which can be flexibly incorporated with existing networks, to implicitly produce useful augmented data. WAT learns low-frequency information of varying levels across diverse samples, which is aggregated efficiently via deformable attention. Furthermore, an uncertainty-aware self-training mechanism is proposed to improve the accuracy of pseudo-labels, with inaccurate predictions being rectified by uncertainty estimation. To acquire better SR results and avoid overfitting pseudo-labels, several regularization losses are proposed to constrain the frequency information between target LR and SR images. Experiments show that without accessing source data, SOSR achieves superior results to the state-of-the-art UDA methods. ",
    "url": "https://arxiv.org/abs/2303.17783",
    "authors": [
      "Yuang Ai",
      "Xiaoqiang Zhou",
      "Huaibo Huang",
      "Lei Zhang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17802",
    "title": "Time-series Anomaly Detection based on Difference Subspace between  Signal Subspaces",
    "abstract": "This paper proposes a new method for anomaly detection in time-series data by incorporating the concept of difference subspace into the singular spectrum analysis (SSA). The key idea is to monitor slight temporal variations of the difference subspace between two signal subspaces corresponding to the past and present time-series data, as anomaly score. It is a natural generalization of the conventional SSA-based method which measures the minimum angle between the two signal subspaces as the degree of changes. By replacing the minimum angle with the difference subspace, our method boosts the performance while using the SSA-based framework as it can capture the whole structural difference between the two subspaces in its magnitude and direction. We demonstrate our method's effectiveness through performance evaluations on public time-series datasets. ",
    "url": "https://arxiv.org/abs/2303.17802",
    "authors": [
      "Takumi Kanai",
      "Naoya Sogi",
      "Atsuto Maki",
      "Kazuhiro Fukui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17805",
    "title": "On the Effect of Initialization: The Scaling Path of 2-Layer Neural  Networks",
    "abstract": "In supervised learning, the regularization path is sometimes used as a convenient theoretical proxy for the optimization path of gradient descent initialized with zero. In this paper, we study a modification of the regularization path for infinite-width 2-layer ReLU neural networks with non-zero initial distribution of the weights at different scales. By exploiting a link with unbalanced optimal transport theory, we show that, despite the non-convexity of the 2-layer network training, this problem admits an infinite dimensional convex counterpart. We formulate the corresponding functional optimization problem and investigate its main properties. In particular, we show that as the scale of the initialization ranges between $0$ and $+\\infty$, the associated path interpolates continuously between the so-called kernel and rich regimes. The numerical experiments confirm that, in our setting, the scaling path and the final states of the optimization path behave similarly even beyond these extreme points. ",
    "url": "https://arxiv.org/abs/2303.17805",
    "authors": [
      "Sebastian Neumayer",
      "L\u00e9na\u00efc Chizat",
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.17806",
    "title": "Neural Microfacet Fields for Inverse Rendering",
    "abstract": "We present Neural Microfacet Fields, a method for recovering materials, geometry, and environment illumination from images of a scene. Our method uses a microfacet reflectance model within a volumetric setting by treating each sample along the ray as a (potentially non-opaque) surface. Using surface-based Monte Carlo rendering in a volumetric setting enables our method to perform inverse rendering efficiently by combining decades of research in surface-based light transport with recent advances in volume rendering for view synthesis. Our approach outperforms prior work in inverse rendering, capturing high fidelity geometry and high frequency illumination details; its novel view synthesis results are on par with state-of-the-art methods that do not recover illumination or materials. ",
    "url": "https://arxiv.org/abs/2303.17806",
    "authors": [
      "Alexander Mai",
      "Dor Verbin",
      "Falko Kuester",
      "Sara Fridovich-Keil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2303.17835",
    "title": "Improved Difference Images for Change Detection Classifiers in SAR  Imagery Using Deep Learning",
    "abstract": "Satellite-based Synthetic Aperture Radar (SAR) images can be used as a source of remote sensed imagery regardless of cloud cover and day-night cycle. However, the speckle noise and varying image acquisition conditions pose a challenge for change detection classifiers. This paper proposes a new method of improving SAR image processing to produce higher quality difference images for the classification algorithms. The method is built on a neural network-based mapping transformation function that produces artificial SAR images from a location in the requested acquisition conditions. The inputs for the model are: previous SAR images from the location, imaging angle information from the SAR images, digital elevation model, and weather conditions. The method was tested with data from a location in North-East Finland by using Sentinel-1 SAR images from European Space Agency, weather data from Finnish Meteorological Institute, and a digital elevation model from National Land Survey of Finland. In order to verify the method, changes to the SAR images were simulated, and the performance of the proposed method was measured using experimentation where it gave substantial improvements to performance when compared to a more conventional method of creating difference images. ",
    "url": "https://arxiv.org/abs/2303.17835",
    "authors": [
      "Janne Alatalo",
      "Tuomo Sipola",
      "Mika Rantonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.17839",
    "title": "Learning Procedure-aware Video Representation from Instructional Videos  and Their Narrations",
    "abstract": "The abundance of instructional videos and their narrations over the Internet offers an exciting avenue for understanding procedural activities. In this work, we propose to learn video representation that encodes both action steps and their temporal ordering, based on a large-scale dataset of web instructional videos and their narrations, without using human annotations. Our method jointly learns a video representation to encode individual step concepts, and a deep probabilistic model to capture both temporal dependencies and immense individual variations in the step ordering. We empirically demonstrate that learning temporal ordering not only enables new capabilities for procedure reasoning, but also reinforces the recognition of individual steps. Our model significantly advances the state-of-the-art results on step classification (+2.8% / +3.3% on COIN / EPIC-Kitchens) and step forecasting (+7.4% on COIN). Moreover, our model attains promising results in zero-shot inference for step classification and forecasting, as well as in predicting diverse and plausible steps for incomplete procedures. Our code is available at https://github.com/facebookresearch/ProcedureVRL. ",
    "url": "https://arxiv.org/abs/2303.17839",
    "authors": [
      "Yiwu Zhong",
      "Licheng Yu",
      "Yang Bai",
      "Shangwen Li",
      "Xueting Yan",
      "Yin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2303.17842",
    "title": "Shepherding Slots to Objects: Towards Stable and Robust Object-Centric  Learning",
    "abstract": "Object-centric learning (OCL) aspires general and compositional understanding of scenes by representing a scene as a collection of object-centric representations. OCL has also been extended to multi-view image and video datasets to apply various data-driven inductive biases by utilizing geometric or temporal information in the multi-image data. Single-view images carry less information about how to disentangle a given scene than videos or multi-view images do. Hence, owing to the difficulty of applying inductive biases, OCL for single-view images remains challenging, resulting in inconsistent learning of object-centric representation. To this end, we introduce a novel OCL framework for single-view images, SLot Attention via SHepherding (SLASH), which consists of two simple-yet-effective modules on top of Slot Attention. The new modules, Attention Refining Kernel (ARK) and Intermediate Point Predictor and Encoder (IPPE), respectively, prevent slots from being distracted by the background noise and indicate locations for slots to focus on to facilitate learning of object-centric representation. We also propose a weak semi-supervision approach for OCL, whilst our proposed framework can be used without any assistant annotation during the inference. Experiments show that our proposed method enables consistent learning of object-centric representation and achieves strong performance across four datasets. Code is available at \\url{https://github.com/object-understanding/SLASH}. ",
    "url": "https://arxiv.org/abs/2303.17842",
    "authors": [
      "Jinwoo Kim",
      "Janghyuk Choi",
      "Ho-Jin Choi",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17845",
    "title": "WSense: A Robust Feature Learning Module for Lightweight Human Activity  Recognition",
    "abstract": "In recent times, various modules such as squeeze-and-excitation, and others have been proposed to improve the quality of features learned from wearable sensor signals. However, these modules often cause the number of parameters to be large, which is not suitable for building lightweight human activity recognition models which can be easily deployed on end devices. In this research, we propose a feature learning module, termed WSense, which uses two 1D CNN and global max pooling layers to extract similar quality features from wearable sensor data while ignoring the difference in activity recognition models caused by the size of the sliding window. Experiments were carried out using CNN and ConvLSTM feature learning pipelines on a dataset obtained with a single accelerometer (WISDM) and another obtained using the fusion of accelerometers, gyroscopes, and magnetometers (PAMAP2) under various sliding window sizes. A total of nine hundred sixty (960) experiments were conducted to validate the WSense module against baselines and existing methods on the two datasets. The results showed that the WSense module aided pipelines in learning similar quality features and outperformed the baselines and existing models with a minimal and uniform model size across all sliding window segmentations. The code is available at https://github.com/AOige/WSense. ",
    "url": "https://arxiv.org/abs/2303.17845",
    "authors": [
      "Ayokunle Olalekan Ige",
      "Mohd Halim Mohd Noor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17849",
    "title": "On R\u00e9nyi Differential Privacy in Statistics-Based Synthetic Data  Generation",
    "abstract": "Privacy protection with synthetic data generation often uses differentially private statistics and model parameters to quantitatively express theoretical security. However, these methods do not take into account privacy protection due to the randomness of data generation. In this paper, we theoretically evaluate R\\'{e}nyi differential privacy of the randomness in data generation of a synthetic data generation method that uses the mean vector and the covariance matrix of an original dataset. Specifically, for a fixed $\\alpha > 1$, we show the condition of $\\varepsilon$ such that the synthetic data generation satisfies $(\\alpha, \\varepsilon)$-R\\'{e}nyi differential privacy under a bounded neighboring condition and an unbounded neighboring condition, respectively. In particular, under the unbounded condition, when the size of the original dataset and synthetic datase is 10 million, the mechanism satisfies $(4, 0.576)$-R\\'{e}nyi differential privacy. We also show that when we translate it into the traditional $(\\varepsilon, \\delta)$-differential privacy, the mechanism satisfies $(4.00, 10^{-10})$-differential privacy. ",
    "url": "https://arxiv.org/abs/2303.17849",
    "authors": [
      "Takayuki Miura",
      "Toshiki Shibahara",
      "Masanobu Kii",
      "Atsunori Ichikawa",
      "Juko Yamamoto",
      "Koji Chida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.17859",
    "title": "MapFormer: Boosting Change Detection by Using Pre-change Information",
    "abstract": "Change detection in remote sensing imagery is essential for a variety of applications such as urban planning, disaster management, and climate research. However, existing methods for identifying semantically changed areas overlook the availability of semantic information in the form of existing maps describing features of the earth's surface. In this paper, we leverage this information for change detection in bi-temporal images. We show that the simple integration of the additional information via concatenation of latent representations suffices to significantly outperform state-of-the-art change detection methods. Motivated by this observation, we propose the new task of Conditional Change Detection, where pre-change semantic information is used as input next to bi-temporal images. To fully exploit the extra information, we propose MapFormer, a novel architecture based on a multi-modal feature fusion module that allows for feature processing conditioned on the available semantic information. We further employ a supervised, cross-modal contrastive loss to guide the learning of visual representations. Our approach outperforms existing change detection methods by an absolute 11.7% and 18.4% in terms of binary change IoU on DynamicEarthNet and HRSCD, respectively. Furthermore, we demonstrate the robustness of our approach to the quality of the pre-change semantic information and the absence pre-change imagery. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2303.17859",
    "authors": [
      "Maximilian Bernhard",
      "Niklas Strau\u00df",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17878",
    "title": "Fused Depthwise Tiling for Memory Optimization in TinyML Deep Neural  Network Inference",
    "abstract": "Memory optimization for deep neural network (DNN) inference gains high relevance with the emergence of TinyML, which refers to the deployment of DNN inference tasks on tiny, low-power microcontrollers. Applications such as audio keyword detection or radar-based gesture recognition are heavily constrained by the limited memory on such tiny devices because DNN inference requires large intermediate run-time buffers to store activations and other intermediate data, which leads to high memory usage. In this paper, we propose a new Fused Depthwise Tiling (FDT) method for the memory optimization of DNNs, which, compared to existing tiling methods, reduces memory usage without inducing any run time overhead. FDT applies to a larger variety of network layers than existing tiling methods that focus on convolutions. It improves TinyML memory optimization significantly by reducing memory of models where this was not possible before and additionally providing alternative design points for models that show high run time overhead with existing methods. In order to identify the best tiling configuration, an end-to-end flow with a new path discovery method is proposed, which applies FDT and existing tiling methods in a fully automated way, including the scheduling of the operations and planning of the layout of buffers in memory. Out of seven evaluated models, FDT achieved significant memory reduction for two models by 76.2% and 18.1% where existing tiling methods could not be applied. Two other models showed a significant run time overhead with existing methods and FDT provided alternative design points with no overhead but reduced memory savings. ",
    "url": "https://arxiv.org/abs/2303.17878",
    "authors": [
      "Rafael Stahl",
      "Daniel Mueller-Gritschneder",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17882",
    "title": "Visual Anomaly Detection via Dual-Attention Transformer and  Discriminative Flow",
    "abstract": "In this paper, we introduce the novel state-of-the-art Dual-attention Transformer and Discriminative Flow (DADF) framework for visual anomaly detection. Based on only normal knowledge, visual anomaly detection has wide applications in industrial scenarios and has attracted significant attention. However, most existing methods fail to meet the requirements. In contrast, the proposed DTDF presents a new paradigm: it firstly leverages a pre-trained network to acquire multi-scale prior embeddings, followed by the development of a vision Transformer with dual attention mechanisms, namely self-attention and memorial-attention, to achieve two-level reconstruction for prior embeddings with the sequential and normality association. Additionally, we propose using normalizing flow to establish discriminative likelihood for the joint distribution of prior and reconstructions at each scale. The DADF achieves 98.3/98.4 of image/pixel AUROC on Mvtec AD; 83.7 of image AUROC and 67.4 of pixel sPRO on Mvtec LOCO AD benchmarks, demonstrating the effectiveness of our proposed approach. ",
    "url": "https://arxiv.org/abs/2303.17882",
    "authors": [
      "Haiming Yao",
      "Wei Luo",
      "Wenyong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17892",
    "title": "Interval Logic Tensor Networks",
    "abstract": "In this paper, we introduce Interval Real Logic (IRL), a two-sorted logic that interprets knowledge such as sequential properties (traces) and event properties using sequences of real-featured data. We interpret connectives using fuzzy logic, event durations using trapezoidal fuzzy intervals, and fuzzy temporal relations using relationships between the intervals' areas. We propose Interval Logic Tensor Networks (ILTN), a neuro-symbolic system that learns by propagating gradients through IRL. In order to support effective learning, ILTN defines smoothened versions of the fuzzy intervals and temporal relations of IRL using softplus activations. We show that ILTN can successfully leverage knowledge expressed in IRL in synthetic tasks that require reasoning about events to predict their fuzzy durations. Our results show that the system is capable of making events compliant with background temporal knowledge. ",
    "url": "https://arxiv.org/abs/2303.17892",
    "authors": [
      "Samy Badreddine",
      "Gianluca Apriceno",
      "Andrea Passerini",
      "Luciano Serafini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17895",
    "title": "EA-BEV: Edge-aware Bird' s-Eye-View Projector for 3D Object Detection",
    "abstract": "In recent years, great progress has been made in the Lift-Splat-Shot-based (LSS-based) 3D object detection method, which converts features of 2D camera view and 3D lidar view to Bird's-Eye-View (BEV) for feature fusion. However, inaccurate depth estimation (e.g. the 'depth jump' problem) is an obstacle to develop LSS-based methods. To alleviate the 'depth jump' problem, we proposed Edge-Aware Bird's-Eye-View (EA-BEV) projector. By coupling proposed edge-aware depth fusion module and depth estimate module, the proposed EA-BEV projector solves the problem and enforces refined supervision on depth. Besides, we propose sparse depth supervision and gradient edge depth supervision, for constraining learning on global depth and local marginal depth information. Our EA-BEV projector is a plug-and-play module for any LSS-based 3D object detection models, and effectively improves the baseline performance. We demonstrate the effectiveness on the nuScenes benchmark. On the nuScenes 3D object detection validation dataset, our proposed EA-BEV projector can boost several state-of-the-art LLS-based baselines on nuScenes 3D object detection benchmark and nuScenes BEV map segmentation benchmark with negligible increment of inference time. ",
    "url": "https://arxiv.org/abs/2303.17895",
    "authors": [
      "Haotian",
      "Fanyi",
      "Wang",
      "Jingwen",
      "Laifeng",
      "Tianpeng",
      "Feng",
      "Zhaokai",
      "Zhang",
      "Wangzhi",
      "Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17900",
    "title": "Procedural Generation of Complex Roundabouts for Autonomous Vehicle  Testing",
    "abstract": "High-definition roads are an essential component of realistic driving scenario simulation for autonomous vehicle testing. Roundabouts are one of the key road segments that have not been thoroughly investigated. Based on the geometric constraints of the nearby road structure, this work presents a novel method for procedurally building roundabouts. The suggested method can result in roundabout lanes that are not perfectly circular and resemble real-world roundabouts by allowing approaching roadways to be connected to a roundabout at any angle. One can easily incorporate the roundabout in their HD road generation process or use the standalone roundabouts in scenario-based testing of autonomous driving. ",
    "url": "https://arxiv.org/abs/2303.17900",
    "authors": [
      "Zarif Ikram",
      "Golam Md Muktadir",
      "Jim Whitehead"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17910",
    "title": "Selective Knowledge Distillation for Non-Autoregressive Neural Machine  Translation",
    "abstract": "Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks. However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research. In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn. In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance. Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances. Further analysis shows that distilling only 5% of the raw translations can help an NAT outperform its counterpart trained on raw data by about 2.4 BLEU. ",
    "url": "https://arxiv.org/abs/2303.17910",
    "authors": [
      "Min Liu",
      "Yu Bao",
      "Chengqi Zhao",
      "Shujian Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.17921",
    "title": "IC-FPS: Instance-Centroid Faster Point Sampling Module for 3D Point-base  Object Detection",
    "abstract": "3D object detection is one of the most important tasks in autonomous driving and robotics. Our research focuses on tackling low efficiency issue of point-based methods on large-scale point clouds. Existing point-based methods adopt farthest point sampling (FPS) strategy for downsampling, which is computationally expensive in terms of inference time and memory consumption when the number of point cloud increases. In order to improve efficiency, we propose a novel Instance-Centroid Faster Point Sampling Module (IC-FPS) , which effectively replaces the first Set Abstraction (SA) layer that is extremely tedious. IC-FPS module is comprised of two methods, local feature diffusion based background point filter (LFDBF) and Centroid-Instance Sampling Strategy (CISS). LFDBF is constructed to exclude most invalid background points, while CISS substitutes FPS strategy by fast sampling centroids and instance points. IC-FPS module can be inserted to almost every point-based models. Extensive experiments on multiple public benchmarks have demonstrated the superiority of IC-FPS. On Waymo dataset, the proposed module significantly improves performance of baseline model and accelerates inference speed by 3.8 times. For the first time, real-time detection of point-based models in large-scale point cloud scenario is realized. ",
    "url": "https://arxiv.org/abs/2303.17921",
    "authors": [
      "Hu Haotian",
      "Wang Fanyi",
      "Su Jingwen",
      "Gao Shiyu",
      "Zhang Zhiwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17923",
    "title": "Potential degradation of transportation network efficiency due to route  recommendations",
    "abstract": "In this work, we propose a road traffic model to assess the effects of real-time route recommendations on the traffic flow between an origin and a destination connected by two possible routes. We suppose that this origin-destination pair is subject to a constant demand flow and that a certain fraction of the users constituting this demand has access to a navigation application (app). The model aims to investigate potential drawbacks, at the global level, of the usage of navigation apps. After a comprehensive stability analysis, we show that an excessive use of navigation apps can degrade of the network efficiency, which may take the form of a decrease of performance measures or of the failure to satisfy the user demand. ",
    "url": "https://arxiv.org/abs/2303.17923",
    "authors": [
      "Tommaso Toso",
      "Alain Y. Kibangou",
      "Paolo Frasca"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2303.17925",
    "title": "Beyond Multilayer Perceptrons: Investigating Complex Topologies in  Neural Networks",
    "abstract": "In this study, we explore the impact of network topology on the approximation capabilities of artificial neural networks (ANNs), with a particular focus on complex topologies. We propose a novel methodology for constructing complex ANNs based on various topologies, including Barab\\'asi-Albert, Erd\\H{o}s-R\\'enyi, Watts-Strogatz, and multilayer perceptrons (MLPs). The constructed networks are evaluated on synthetic datasets generated from manifold learning generators, with varying levels of task difficulty and noise. Our findings reveal that complex topologies lead to superior performance in high-difficulty regimes compared to traditional MLPs. This performance advantage is attributed to the ability of complex networks to exploit the compositionality of the underlying target function. However, this benefit comes at the cost of increased forward-pass computation time and reduced robustness to graph damage. Additionally, we investigate the relationship between various topological attributes and model performance. Our analysis shows that no single attribute can account for the observed performance differences, suggesting that the influence of network topology on approximation capabilities may be more intricate than a simple correlation with individual topological attributes. Our study sheds light on the potential of complex topologies for enhancing the performance of ANNs and provides a foundation for future research exploring the interplay between multiple topological attributes and their impact on model performance. ",
    "url": "https://arxiv.org/abs/2303.17925",
    "authors": [
      "Tommaso Boccato",
      "Matteo Ferrante",
      "Andrea Duggento",
      "Nicola Toschi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17927",
    "title": "Cross-Cultural Transfer Learning for Chinese Offensive Language  Detection",
    "abstract": "Detecting offensive language is a challenging task. Generalizing across different cultures and languages becomes even more challenging: besides lexical, syntactic and semantic differences, pragmatic aspects such as cultural norms and sensitivities, which are particularly relevant in this context, vary greatly. In this paper, we target Chinese offensive language detection and aim to investigate the impact of transfer learning using offensive language detection data from different cultural backgrounds, specifically Korean and English. We find that culture-specific biases in what is considered offensive negatively impact the transferability of language models (LMs) and that LMs trained on diverse cultural data are sensitive to different features in Chinese offensive language detection. In a few-shot learning scenario, however, our study shows promising prospects for non-English offensive language detection with limited resources. Our findings highlight the importance of cross-cultural transfer learning in improving offensive language detection and promoting inclusive digital spaces. ",
    "url": "https://arxiv.org/abs/2303.17927",
    "authors": [
      "Li Zhou",
      "Laura Cabello",
      "Yong Cao",
      "Daniel Hershcovich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.17937",
    "title": "STFAR: Improving Object Detection Robustness at Test-Time by  Self-Training with Feature Alignment Regularization",
    "abstract": "Domain adaptation helps generalizing object detection models to target domain data with distribution shift. It is often achieved by adapting with access to the whole target domain data. In a more realistic scenario, target distribution is often unpredictable until inference stage. This motivates us to explore adapting an object detection model at test-time, a.k.a. test-time adaptation (TTA). In this work, we approach test-time adaptive object detection (TTAOD) from two perspective. First, we adopt a self-training paradigm to generate pseudo labeled objects with an exponential moving average model. The pseudo labels are further used to supervise adapting source domain model. As self-training is prone to incorrect pseudo labels, we further incorporate aligning feature distributions at two output levels as regularizations to self-training. To validate the performance on TTAOD, we create benchmarks based on three standard object detection datasets and adapt generic TTA methods to object detection task. Extensive evaluations suggest our proposed method sets the state-of-the-art on test-time adaptive object detection task. ",
    "url": "https://arxiv.org/abs/2303.17937",
    "authors": [
      "Yijin Chen",
      "Xun Xu",
      "Yongyi Su",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17946",
    "title": "Social Honeypot for Humans: Luring People through Self-managed Instagram  Pages",
    "abstract": "Social Honeypots are tools deployed in Online Social Networks (OSN) to attract malevolent activities performed by spammers and bots. To this end, their content is designed to be of maximum interest to malicious users. However, by choosing an appropriate content topic, this attractive mechanism could be extended to any OSN users, rather than only luring malicious actors. As a result, honeypots can be used to attract individuals interested in a wide range of topics, from sports and hobbies to more sensitive subjects like political views and conspiracies. With all these individuals gathered in one place, honeypot owners can conduct many analyses, from social to marketing studies. In this work, we introduce a novel concept of social honeypot for attracting OSN users interested in a generic target topic. We propose a framework based on fully-automated content generation strategies and engagement plans to mimic legit Instagram pages. To validate our framework, we created 21 self-managed social honeypots (i.e., pages) on Instagram, covering three topics, four content generation strategies, and three engaging plans. In nine weeks, our honeypots gathered a total of 753 followers, 5387 comments, and 15739 likes. These results demonstrate the validity of our approach, and through statistical analysis, we examine the characteristics of effective social honeypots. ",
    "url": "https://arxiv.org/abs/2303.17946",
    "authors": [
      "Sara Bardi",
      "Mauro Conti",
      "Luca Pajola",
      "Pier Paolo Tricomi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.17949",
    "title": "Unsupervised Anomaly Detection and Localization of Machine Audio: A  GAN-based Approach",
    "abstract": "Automatic detection of machine anomaly remains challenging for machine learning. We believe the capability of generative adversarial network (GAN) suits the need of machine audio anomaly detection, yet rarely has this been investigated by previous work. In this paper, we propose AEGAN-AD, a totally unsupervised approach in which the generator (also an autoencoder) is trained to reconstruct input spectrograms. It is pointed out that the denoising nature of reconstruction deprecates its capacity. Thus, the discriminator is redesigned to aid the generator during both training stage and detection stage. The performance of AEGAN-AD on the dataset of DCASE 2022 Challenge TASK 2 demonstrates the state-of-the-art result on five machine types. A novel anomaly localization method is also investigated. Source code available at: www.github.com/jianganbai/AEGAN-AD ",
    "url": "https://arxiv.org/abs/2303.17949",
    "authors": [
      "Anbai Jiang",
      "Wei-Qiang Zhang",
      "Yufeng Deng",
      "Pingyi Fan",
      "Jia Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.17954",
    "title": "DARKSIDE: A Heterogeneous RISC-V Compute Cluster for Extreme-Edge  On-Chip DNN Inference and Training",
    "abstract": "On-chip DNN inference and training at the Extreme-Edge (TinyML) impose strict latency, throughput, accuracy and flexibility requirements. Heterogeneous clusters are promising solutions to meet the challenge, combining the flexibility of DSP-enhanced cores with the performance and energy boost of dedicated accelerators. We present DARKSIDE, a System-on-Chip with a heterogeneous cluster of 8 RISC-V cores enhanced with 2-b to 32-b mixed-precision integer arithmetic. To boost performance and efficiency on key compute-intensive Deep Neural Network (DNN) kernels, the cluster is enriched with three digital accelerators: a specialized engine for low-data-reuse depthwise convolution kernels (up to 30 MAC/cycle); a minimal overhead datamover to marshal 1-b to 32-b data on-the-fly; a 16-b floating point Tensor Product Engine (TPE) for tiled matrix-multiplication acceleration. DARKSIDE is implemented in 65nm CMOS technology. The cluster achieves a peak integer performance of 65 GOPS and a peak efficiency of 835 GOPS/W when working on 2-b integer DNN kernels. When targeting floating-point tensor operations, the TPE provides up to 18.2 GFLOPS of performance or 300 GFLOPS/W of efficiency - enough to enable on-chip floating-point training at competitive speed coupled with ultra-low power quantized inference. ",
    "url": "https://arxiv.org/abs/2303.17954",
    "authors": [
      "Angelo Garofalo",
      "Yvan Tortorella",
      "Matteo Perotti",
      "Luca Valente",
      "Alessandro Nadalini",
      "Luca Benini",
      "Davide Rossi",
      "Francesco Conti"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2303.17966",
    "title": "HD-GCN:A Hybrid Diffusion Graph Convolutional Network",
    "abstract": "The information diffusion performance of GCN and its variant models is limited by the adjacency matrix, which can lower their performance. Therefore, we introduce a new framework for graph convolutional networks called Hybrid Diffusion-based Graph Convolutional Network (HD-GCN) to address the limitations of information diffusion caused by the adjacency matrix. In the HD-GCN framework, we initially utilize diffusion maps to facilitate the diffusion of information among nodes that are adjacent to each other in the feature space. This allows for the diffusion of information between similar points that may not have an adjacent relationship. Next, we utilize graph convolution to further propagate information among adjacent nodes after the diffusion maps, thereby enabling the spread of information among similar nodes that are adjacent in the graph. Finally, we employ the diffusion distances obtained through the use of diffusion maps to regularize and constrain the predicted labels of training nodes. This regularization method is then applied to the HD-GCN training, resulting in a smoother classification surface. The model proposed in this paper effectively overcomes the limitations of information diffusion imposed only by the adjacency matrix. HD-GCN utilizes hybrid diffusion by combining information diffusion between neighborhood nodes in the feature space and adjacent nodes in the adjacency matrix. This method allows for more comprehensive information propagation among nodes, resulting in improved model performance. We evaluated the performance of DM-GCN on three well-known citation network datasets and the results showed that the proposed framework is more effective than several graph-based semi-supervised learning methods. ",
    "url": "https://arxiv.org/abs/2303.17966",
    "authors": [
      "Zhi Yang",
      "Kang Li",
      "Haitao Gan",
      "Zhongwei Huang",
      "Ming Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17989",
    "title": "Unsupervised crack detection on complex stone masonry surfaces",
    "abstract": "Computer vision for detecting building pathologies has interested researchers for quite some time. Vision-based crack detection is a non-destructive assessment technique, which can be useful especially for Cultural Heritage (CH) where strict regulations apply and, even simple, interventions are not permitted. Recently, shallow and deep machine learning architectures applied on various types of imagery are gaining ground. In this article a crack detection methodology for stone masonry walls is presented. In the proposed approach, crack detection is approached as an unsupervised anomaly detection problem on RGB (Red Green Blue) image patches. Towards this direction, some of the most popular state of the art CNN (Convolutional Neural Network) architectures are deployed and modified to binary classify the images or image patches by predicting a specific class for the tested imagery; 'Crack' or 'No crack', and detect and localize those cracks on the RGB imagery with high accuracy. Testing of the model was performed on various test sites and random images retrieved from the internet and collected by the authors and results suggested the high performance of specific networks compared to the rest, considering also the small numbers of epochs required for training. Those results met the accuracy delivered by more complex and computationally heavy approaches, requiring a large amount of data for training. Source code is available on GitHub https://github.com/pagraf/Crack-detection while datasets are available on Zenodo https://doi.org/10.5281/zenodo.6516913 . ",
    "url": "https://arxiv.org/abs/2303.17989",
    "authors": [
      "Panagiotis Agrafiotis",
      "Anastastios Doulamis",
      "Andreas Georgopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17995",
    "title": "Neural Network Entropy (NNetEn): EEG Signals and Chaotic Time Series  Separation by Entropy Features, Python Package for NNetEn Calculation",
    "abstract": "Entropy measures are effective features for time series classification problems. Traditional entropy measures, such as Shannon entropy, use probability distribution function. However, for the effective separation of time series, new entropy estimation methods are required to characterize the chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn) is based on the classification of special datasets (MNIST-10 and SARS-CoV-2-RBV1) in relation to the entropy of the time series recorded in the reservoir of the LogNNet neural network. NNetEn estimates the chaotic dynamics of time series in an original way. Based on the NNetEn algorithm, we propose two new classification metrics: R2 Efficiency and Pearson Efficiency. The efficiency of NNetEn is verified on separation of two chaotic time series of sine mapping using dispersion analysis (ANOVA). For two close dynamic time series (r = 1.1918 and r = 1.2243), the F-ratio has reached the value of 124 and reflects high efficiency of the introduced method in classification problems. The EEG signal classification for healthy persons and patients with Alzheimer disease illustrates the practical application of the NNetEn features. Our computations demonstrate the synergistic effect of increasing classification accuracy when applying traditional entropy measures and the NNetEn concept conjointly. An implementation of the algorithms in Python is presented. ",
    "url": "https://arxiv.org/abs/2303.17995",
    "authors": [
      "Andrei Velichko",
      "Maksim Belyaev",
      "Yuriy Izotov",
      "Murugappan Murugappan",
      "Hanif Heidari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2303.18011",
    "title": "Exploiting Multilingualism in Low-resource Neural Machine Translation  via Adversarial Learning",
    "abstract": "Generative Adversarial Networks (GAN) offer a promising approach for Neural Machine Translation (NMT). However, feeding multiple morphologically languages into a single model during training reduces the NMT's performance. In GAN, similar to bilingual models, multilingual NMT only considers one reference translation for each sentence during model training. This single reference translation limits the GAN model from learning sufficient information about the source sentence representation. Thus, in this article, we propose Denoising Adversarial Auto-encoder-based Sentence Interpolation (DAASI) approach to perform sentence interpolation by learning the intermediate latent representation of the source and target sentences of multilingual language pairs. Apart from latent representation, we also use the Wasserstein-GAN approach for the multilingual NMT model by incorporating the model generated sentences of multiple languages for reward computation. This computed reward optimizes the performance of the GAN-based multilingual model in an effective manner. We demonstrate the experiments on low-resource language pairs and find that our approach outperforms the existing state-of-the-art approaches for multilingual NMT with a performance gain of up to 4 BLEU points. Moreover, we use our trained model on zero-shot language pairs under an unsupervised scenario and show the robustness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2303.18011",
    "authors": [
      "Amit Kumar",
      "Ajay Pratap",
      "Anil Kumar Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.18019",
    "title": "Live image-based neurosurgical guidance and roadmap generation using  unsupervised embedding",
    "abstract": "Advanced minimally invasive neurosurgery navigation relies mainly on Magnetic Resonance Imaging (MRI) guidance. MRI guidance, however, only provides pre-operative information in the majority of the cases. Once the surgery begins, the value of this guidance diminishes to some extent because of the anatomical changes due to surgery. Guidance with live image feedback coming directly from the surgical device, e.g., endoscope, can complement MRI-based navigation or be an alternative if MRI guidance is not feasible. With this motivation, we present a method for live image-only guidance leveraging a large data set of annotated neurosurgical videos.First, we report the performance of a deep learning-based object detection method, YOLO, on detecting anatomical structures in neurosurgical images. Second, we present a method for generating neurosurgical roadmaps using unsupervised embedding without assuming exact anatomical matches between patients, presence of an extensive anatomical atlas, or the need for simultaneous localization and mapping. A generated roadmap encodes the common anatomical paths taken in surgeries in the training set. At inference, the roadmap can be used to map a surgeon's current location using live image feedback on the path to provide guidance by being able to predict which structures should appear going forward or backward, much like a mapping application. Even though the embedding is not supervised by position information, we show that it is correlated to the location inside the brain and on the surgical path. We trained and evaluated the proposed method with a data set of 166 transsphenoidal adenomectomy procedures. ",
    "url": "https://arxiv.org/abs/2303.18019",
    "authors": [
      "Gary Sarwin",
      "Alessandro Carretta",
      "Victor Staartjes",
      "Matteo Zoli",
      "Diego Mazzatenta",
      "Luca Regli",
      "Carlo Serra",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.18037",
    "title": "Traffic Sign Recognition Dataset and Data Augmentation",
    "abstract": "Although there are many datasets for traffic sign classification, there are few datasets collected for traffic sign recognition and few of them obtain enough instances especially for training a model with the deep learning method. The deep learning method is almost the only way to train a model for real-world usage that covers various highly similar classes compared with the traditional way such as through color, shape, etc. Also, for some certain sign classes, their sign meanings were destined to can't get enough instances in the dataset. To solve this problem, we purpose a unique data augmentation method for the traffic sign recognition dataset that takes advantage of the standard of the traffic sign. We called it TSR dataset augmentation. We based on the benchmark Tsinghua-Tencent 100K (TT100K) dataset to verify the unique data augmentation method. we performed the method on four main iteration version datasets based on the TT100K dataset and the experimental results showed our method is efficacious. The iteration version datasets based on TT100K, data augmentation method source code and the training results introduced in this paper are publicly available. ",
    "url": "https://arxiv.org/abs/2303.18037",
    "authors": [
      "Jingzhan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18044",
    "title": "Long-Short Temporal Co-Teaching for Weakly Supervised Video Anomaly  Detection",
    "abstract": "Weakly supervised video anomaly detection (WS-VAD) is a challenging problem that aims to learn VAD models only with video-level annotations. In this work, we propose a Long-Short Temporal Co-teaching (LSTC) method to address the WS-VAD problem. It constructs two tubelet-based spatio-temporal transformer networks to learn from short- and long-term video clips respectively. Each network is trained with respect to a multiple instance learning (MIL)-based ranking loss, together with a cross-entropy loss when clip-level pseudo labels are available. A co-teaching strategy is adopted to train the two networks. That is, clip-level pseudo labels generated from each network are used to supervise the other one at the next training round, and the two networks are learned alternatively and iteratively. Our proposed method is able to better deal with the anomalies with varying durations as well as subtle anomalies. Extensive experiments on three public datasets demonstrate that our method outperforms state-of-the-art WS-VAD methods. ",
    "url": "https://arxiv.org/abs/2303.18044",
    "authors": [
      "Shengyang Sun",
      "Xiaojin Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.18049",
    "title": "No Place to Hide: Dual Deep Interaction Channel Network for Fake News  Detection based on Data Augmentation",
    "abstract": "Online Social Network (OSN) has become a hotbed of fake news due to the low cost of information dissemination. Although the existing methods have made many attempts in news content and propagation structure, the detection of fake news is still facing two challenges: one is how to mine the unique key features and evolution patterns, and the other is how to tackle the problem of small samples to build the high-performance model. Different from popular methods which take full advantage of the propagation topology structure, in this paper, we propose a novel framework for fake news detection from perspectives of semantic, emotion and data enhancement, which excavates the emotional evolution patterns of news participants during the propagation process, and a dual deep interaction channel network of semantic and emotion is designed to obtain a more comprehensive and fine-grained news representation with the consideration of comments. Meanwhile, the framework introduces a data enhancement module to obtain more labeled data with high quality based on confidence which further improves the performance of the classification model. Experiments show that the proposed approach outperforms the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2303.18049",
    "authors": [
      "Biwei Cao",
      "Lulu Hua",
      "Jiuxin Cao",
      "Jie Gui",
      "Bo Liu",
      "James Tin-Yau Kwok"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.18051",
    "title": "Synergistic Graph Fusion via Encoder Embedding",
    "abstract": "In this paper, we introduce a novel approach to multi-graph embedding called graph fusion encoder embedding. The method is designed to work with multiple graphs that share a common vertex set. Under the supervised learning setting, we show that the resulting embedding exhibits a surprising yet highly desirable \"synergistic effect\": for sufficiently large vertex size, the vertex classification accuracy always benefits from additional graphs. We provide a mathematical proof of this effect under the stochastic block model, and identify the necessary and sufficient condition for asymptotically perfect classification. The simulations and real data experiments confirm the superiority of the proposed method, which consistently outperforms recent benchmark methods in classification. ",
    "url": "https://arxiv.org/abs/2303.18051",
    "authors": [
      "Cencheng Shen",
      "Carey E. Priebe",
      "Jonathan Larson",
      "Ha Trinh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.18055",
    "title": "Deep neural operator for learning transient response of interpenetrating  phase composites subject to dynamic loading",
    "abstract": "Additive manufacturing has been recognized as an industrial technological revolution for manufacturing, which allows fabrication of materials with complex three-dimensional (3D) structures directly from computer-aided design models. The mechanical properties of interpenetrating phase composites (IPCs), especially response to dynamic loading, highly depend on their 3D structures. In general, for each specified structural design, it could take hours or days to perform either finite element analysis (FEA) or experiments to test the mechanical response of IPCs to a given dynamic load. To accelerate the physics-based prediction of mechanical properties of IPCs for various structural designs, we employ a deep neural operator (DNO) to learn the transient response of IPCs under dynamic loading as surrogate of physics-based FEA models. We consider a 3D IPC beam formed by two metals with a ratio of Young's modulus of 2.7, wherein random blocks of constituent materials are used to demonstrate the generality and robustness of the DNO model. To obtain FEA results of IPC properties, 5,000 random time-dependent strain loads generated by a Gaussian process kennel are applied to the 3D IPC beam, and the reaction forces and stress fields inside the IPC beam under various loading are collected. Subsequently, the DNO model is trained using an incremental learning method with sequence-to-sequence training implemented in JAX, leading to a 100X speedup compared to widely used vanilla deep operator network models. After an offline training, the DNO model can act as surrogate of physics-based FEA to predict the transient mechanical response in terms of reaction force and stress distribution of the IPCs to various strain loads in one second at an accuracy of 98%. Also, the learned operator is able to provide extended prediction of the IPC beam subject to longer random strain loads at a reasonably well accuracy. ",
    "url": "https://arxiv.org/abs/2303.18055",
    "authors": [
      "Minglei Lu",
      "Ali Mohammadi",
      "Zhaoxu Meng",
      "Xuhui Meng",
      "Gang Li",
      "Zhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2303.18058",
    "title": "Code Reviewer Recommendation for Architecture Violations: An Exploratory  Study",
    "abstract": "Code review is a common practice in software development and often conducted before code changes are merged into the code repository. A number of approaches for automatically recommending appropriate reviewers have been proposed to match such code changes to pertinent reviewers. However, such approaches are generic, i.e., they do not focus on specific types of issues during code reviews. In this paper, we propose an approach that focuses on architecture violations, one of the most critical type of issues identified during code review. Specifically, we aim at automating the recommendation of code reviewers, who are potentially qualified to review architecture violations, based on reviews of code changes. To this end, we selected three common similarity detection methods to measure the file path similarity of code commits and the semantic similarity of review comments. We conducted a series of experiments on finding the appropriate reviewers through evaluating and comparing these similarity detection methods in separate and combined ways with the baseline reviewer recommendation approach, RevFinder. The results show that the common similarity detection methods can produce acceptable performance scores and achieve a better performance than RevFinder. The sampling techniques used in recommending code reviewers can impact the performance of reviewer recommendation approaches. We also discuss the potential implications of our findings for both researchers and practitioners. ",
    "url": "https://arxiv.org/abs/2303.18058",
    "authors": [
      "Ruiyin Li",
      "Peng Liang",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.18059",
    "title": "Inferring networks from time series: a neural approach",
    "abstract": "Network structures underlie the dynamics of many complex phenomena, from gene regulation and foodwebs to power grids and social media. Yet, as they often cannot be observed directly, their connectivities must be inferred from observations of their emergent dynamics. In this work we present a powerful and fast computational method to infer large network adjacency matrices from time series data using a neural network. Using a neural network provides uncertainty quantification on the prediction in a manner that reflects both the non-convexity of the inference problem as well as the noise on the data. This is useful since network inference problems are typically underdetermined, and a feature that has hitherto been lacking from network inference methods. We demonstrate our method's capabilities by inferring line failure locations in the British power grid from observations of its response to a power cut. Since the problem is underdetermined, many classical statistical tools (e.g. regression) will not be straightforwardly applicable. Our method, in contrast, provides probability densities on each edge, allowing the use of hypothesis testing to make meaningful probabilistic statements about the location of the power cut. We also demonstrate our method's ability to learn an entire cost matrix for a non-linear model from a dataset of economic activity in Greater London. Our method outperforms OLS regression on noisy data in terms of both speed and prediction accuracy, and scales as $N^2$ where OLS is cubic. Since our technique is not specifically engineered for network inference, it represents a general parameter estimation scheme that is applicable to any parameter dimension. ",
    "url": "https://arxiv.org/abs/2303.18059",
    "authors": [
      "Thomas Gaskin",
      "Grigorios A. Pavliotis",
      "Mark Girolami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.18083",
    "title": "Analysis and Comparison of Two-Level KFAC Methods for Training Deep  Neural Networks",
    "abstract": "As a second-order method, the Natural Gradient Descent (NGD) has the ability to accelerate training of neural networks. However, due to the prohibitive computational and memory costs of computing and inverting the Fisher Information Matrix (FIM), efficient approximations are necessary to make NGD scalable to Deep Neural Networks (DNNs). Many such approximations have been attempted. The most sophisticated of these is KFAC, which approximates the FIM as a block-diagonal matrix, where each block corresponds to a layer of the neural network. By doing so, KFAC ignores the interactions between different layers. In this work, we investigate the interest of restoring some low-frequency interactions between the layers by means of two-level methods. Inspired from domain decomposition, several two-level corrections to KFAC using different coarse spaces are proposed and assessed. The obtained results show that incorporating the layer interactions in this fashion does not really improve the performance of KFAC. This suggests that it is safe to discard the off-diagonal blocks of the FIM, since the block-diagonal approach is sufficiently robust, accurate and economical in computation time. ",
    "url": "https://arxiv.org/abs/2303.18083",
    "authors": [
      "Abdoulaye Koroko",
      "Ani Anciaux-Sedrakian",
      "Ibtihel Ben Gharbia",
      "Val\u00e9rie Gar\u00e8s",
      "Mounir Haddou",
      "Quang Huy Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.18094",
    "title": "Robust LSTM-based Vehicle Velocity Observer for Regular and Near-limits  Applications",
    "abstract": "Accurate velocity estimation is key to vehicle control. While the literature describes how model-based and learning-based observers are able to estimate a vehicle's velocity in normal driving conditions, the challenge remains to estimate the velocity in near-limits maneuvers while using only conventional in-car sensors. In this paper, we introduce a novel neural network architecture based on Long Short-Term Memory (LSTM) networks to accurately estimate the vehicle's velocity in different driving conditions, including maneuvers at the limits of handling. The approach has been tested on real vehicle data and it provides more accurate estimations than state-of-the-art model-based and learning-based methods, for both regular and near-limits driving scenarios. Our approach is robust since the performance of the state-of-the-art observers deteriorates with higher dynamics, while our method adapts to different maneuvers, providing accurate estimations even at the vehicle's limits of handling. ",
    "url": "https://arxiv.org/abs/2303.18094",
    "authors": [
      "Agapius Bou Ghosn",
      "Marcus Nolte",
      "Philip Polack",
      "Arnaud de La Fortelle",
      "Markus Maurer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2303.18101",
    "title": "INoD: Injected Noise Discriminator for Self-Supervised Representation  Learning in Agricultural Fields",
    "abstract": "Perception datasets for agriculture are limited both in quantity and diversity which hinders effective training of supervised learning approaches. Self-supervised learning techniques alleviate this problem, however, existing methods are not optimized for dense prediction tasks in agriculture domains which results in degraded performance. In this work, we address this limitation with our proposed Injected Noise Discriminator (INoD) which exploits principles of feature replacement and dataset discrimination for self-supervised representation learning. INoD interleaves feature maps from two disjoint datasets during their convolutional encoding and predicts the dataset affiliation of the resultant feature map as a pretext task. Our approach enables the network to learn unequivocal representations of objects seen in one dataset while observing them in conjunction with similar features from the disjoint dataset. This allows the network to reason about higher-level semantics of the entailed objects, thus improving its performance on various downstream tasks. Additionally, we introduce the novel Fraunhofer Potato 2022 dataset consisting of over 16,800 images for object detection in potato fields. Extensive evaluations of our proposed INoD pretraining strategy for the tasks of object detection, semantic segmentation, and instance segmentation on the Sugar Beets 2016 and our potato dataset demonstrate that it achieves state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2303.18101",
    "authors": [
      "Julia Hindel",
      "Nikhil Gosala",
      "Kevin Bregler",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.18104",
    "title": "Status Updating under Partial Battery Knowledge in Energy Harvesting IoT  Networks",
    "abstract": "We study status updating under inexact knowledge about the battery levels of the energy harvesting sensors in an IoT network, where users make on-demand requests to a cache-enabled edge node to send updates about various random processes monitored by the sensors. To serve the request(s), the edge node either commands the corresponding sensor to send an update or uses the aged data from the cache. We find a control policy that minimizes the average on-demand AoI subject to per-slot energy harvesting constraints under partial battery knowledge at the edge node. Namely, the edge node is informed about sensors' battery levels only via received status updates, leading to uncertainty about the battery levels for the decision-making. We model the problem as a POMDP which is then reformulated as an equivalent belief-MDP. The belief-MDP in its original form is difficult to solve due to the infinite belief space. However, by exploiting a specific pattern in the evolution of beliefs, we truncate the belief space and develop a dynamic programming algorithm to obtain an optimal policy. Moreover, we address a multi-sensor setup under a transmission limitation for which we develop an asymptotically optimal algorithm. Simulation results assess the performance of the proposed methods. ",
    "url": "https://arxiv.org/abs/2303.18104",
    "authors": [
      "Mohammad Hatami",
      "Markus Leinonen",
      "Marian Codreanu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.18106",
    "title": "Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy  Protection Using Self-supervised Learning and Minimal Labels",
    "abstract": "Endoscopic video recordings are widely used in minimally invasive robot-assisted surgery, but when the endoscope is outside the patient's body, it can capture irrelevant segments that may contain sensitive information. To address this, we propose a framework that accurately detects out-of-body frames in surgical videos by leveraging self-supervision with minimal data labels. We use a massive amount of unlabeled endoscopic images to learn meaningful representations in a self-supervised manner. Our approach, which involves pre-training on an auxiliary task and fine-tuning with limited supervision, outperforms previous methods for detecting out-of-body frames in surgical videos captured from da Vinci X and Xi surgical systems. The average F1 scores range from 96.00 to 98.02. Remarkably, using only 5% of the training labels, our approach still maintains an average F1 score performance above 97, outperforming fully-supervised methods with 95% fewer labels. These results demonstrate the potential of our framework to facilitate the safe handling of surgical video recordings and enhance data privacy protection in minimally invasive surgery. ",
    "url": "https://arxiv.org/abs/2303.18106",
    "authors": [
      "Ziheng Wang",
      "Conor Perreault",
      "Xi Liu",
      "Anthony Jarc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.18131",
    "title": "AdvCheck: Characterizing Adversarial Examples via Local Gradient  Checking",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples, which may lead to catastrophe in security-critical domains. Numerous detection methods are proposed to characterize the feature uniqueness of adversarial examples, or to distinguish DNN's behavior activated by the adversarial examples. Detections based on features cannot handle adversarial examples with large perturbations. Besides, they require a large amount of specific adversarial examples. Another mainstream, model-based detections, which characterize input properties by model behaviors, suffer from heavy computation cost. To address the issues, we introduce the concept of local gradient, and reveal that adversarial examples have a quite larger bound of local gradient than the benign ones. Inspired by the observation, we leverage local gradient for detecting adversarial examples, and propose a general framework AdvCheck. Specifically, by calculating the local gradient from a few benign examples and noise-added misclassified examples to train a detector, adversarial examples and even misclassified natural inputs can be precisely distinguished from benign ones. Through extensive experiments, we have validated the AdvCheck's superior performance to the state-of-the-art (SOTA) baselines, with detection rate ($\\sim \\times 1.2$) on general adversarial attacks and ($\\sim \\times 1.4$) on misclassified natural inputs on average, with average 1/500 time cost. We also provide interpretable results for successful detection. ",
    "url": "https://arxiv.org/abs/2303.18131",
    "authors": [
      "Ruoxi Chen",
      "Haibo Jin",
      "Jinyin Chen",
      "Haibin Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18132",
    "title": "A Desynchronization-Based Countermeasure Against Side-Channel Analysis  of Neural Networks",
    "abstract": "Model extraction attacks have been widely applied, which can normally be used to recover confidential parameters of neural networks for multiple layers. Recently, side-channel analysis of neural networks allows parameter extraction even for networks with several multiple deep layers with high effectiveness. It is therefore of interest to implement a certain level of protection against these attacks. In this paper, we propose a desynchronization-based countermeasure that makes the timing analysis of activation functions harder. We analyze the timing properties of several activation functions and design the desynchronization in a way that the dependency on the input and the activation type is hidden. We experimentally verify the effectiveness of the countermeasure on a 32-bit ARM Cortex-M4 microcontroller and employ a t-test to show the side-channel information leakage. The overhead ultimately depends on the number of neurons in the fully-connected layer, for example, in the case of 4096 neurons in VGG-19, the overheads are between 2.8% and 11%. ",
    "url": "https://arxiv.org/abs/2303.18132",
    "authors": [
      "Jakub Breier",
      "Dirmanto Jap",
      "Xiaolu Hou",
      "Shivam Bhasin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18136",
    "title": "Machine-learned Adversarial Attacks against Fault Prediction Systems in  Smart Electrical Grids",
    "abstract": "In smart electrical grids, fault detection tasks may have a high impact on society due to their economic and critical implications. In the recent years, numerous smart grid applications, such as defect detection and load forecasting, have embraced data-driven methodologies. The purpose of this study is to investigate the challenges associated with the security of machine learning (ML) applications in the smart grid scenario. Indeed, the robustness and security of these data-driven algorithms have not been extensively studied in relation to all power grid applications. We demonstrate first that the deep neural network method used in the smart grid is susceptible to adversarial perturbation. Then, we highlight how studies on fault localization and type classification illustrate the weaknesses of present ML algorithms in smart grids to various adversarial attacks ",
    "url": "https://arxiv.org/abs/2303.18136",
    "authors": [
      "Carmelo Ardito",
      "Yashar Deldjoo",
      "Tommaso Di Noia",
      "Eugenio Di Sciascio",
      "Fatemeh Nazary",
      "Giovanni Servedio"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18138",
    "title": "BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection",
    "abstract": "As various forms of fraud proliferate on Ethereum, it is imperative to safeguard against these malicious activities to protect susceptible users from being victimized. While current studies solely rely on graph-based fraud detection approaches, it is argued that they may not be well-suited for dealing with highly repetitive, skew-distributed and heterogeneous Ethereum transactions. To address these challenges, we propose BERT4ETH, a universal pre-trained Transformer encoder that serves as an account representation extractor for detecting various fraud behaviors on Ethereum. BERT4ETH features the superior modeling capability of Transformer to capture the dynamic sequential patterns inherent in Ethereum transactions, and addresses the challenges of pre-training a BERT model for Ethereum with three practical and effective strategies, namely repetitiveness reduction, skew alleviation and heterogeneity modeling. Our empirical evaluation demonstrates that BERT4ETH outperforms state-of-the-art methods with significant enhancements in terms of the phishing account detection and de-anonymization tasks. The code for BERT4ETH is available at: https://github.com/git-disl/BERT4ETH. ",
    "url": "https://arxiv.org/abs/2303.18138",
    "authors": [
      "Sihao Hu",
      "Zhen Zhang",
      "Bingqiao Luo",
      "Shengliang Lu",
      "Bingsheng He",
      "Ling Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18154",
    "title": "Direct Data-Driven Computation of Polytopic Robust Control Invariant  Sets and State-Feedback Controllers",
    "abstract": "This paper presents a direct data-driven approach for computing robust control invariant (RCI) sets and their associated state-feedback control laws. The proposed method utilizes a single state-input trajectory generated from the system, to compute a polytopic RCI set with a desired complexity and an invariance-inducing feedback controller, without the need to identify a model of the system. The problem is formulated in terms of a set of sufficient LMI conditions that are then combined in a semi-definite program to maximize the volume of the RCI set while respecting the state and input constraints. We demonstrate through a numerical case study that the proposed data-driven approach can generate RCI sets that are of comparable size to those obtained by a model-based method in which exact knowledge of the system matrices is assumed. Under the assumption of persistency of excitation of the data, the proposed algorithm guarantees robust invariance even with a small number of data samples. Overall, the direct data-driven approach presented in this paper offers a reliable and efficient counterpart to the model-based methods for RCI set computation and state-feedback controller design. ",
    "url": "https://arxiv.org/abs/2303.18154",
    "authors": [
      "Manas Mejari",
      "Ankit Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.18157",
    "title": "MAGNNETO: A Graph Neural Network-based Multi-Agent system for Traffic  Engineering",
    "abstract": "Current trends in networking propose the use of Machine Learning (ML) for a wide variety of network optimization tasks. As such, many efforts have been made to produce ML-based solutions for Traffic Engineering (TE), which is a fundamental problem in ISP networks. Nowadays, state-of-the-art TE optimizers rely on traditional optimization techniques, such as Local search, Constraint Programming, or Linear programming. In this paper, we present MAGNNETO, a distributed ML-based framework that leverages Multi-Agent Reinforcement Learning and Graph Neural Networks for distributed TE optimization. MAGNNETO deploys a set of agents across the network that learn and communicate in a distributed fashion via message exchanges between neighboring agents. Particularly, we apply this framework to optimize link weights in OSPF, with the goal of minimizing network congestion. In our evaluation, we compare MAGNNETO against several state-of-the-art TE optimizers in more than 75 topologies (up to 153 nodes and 354 links), including realistic traffic loads. Our experimental results show that, thanks to its distributed nature, MAGNNETO achieves comparable performance to state-of-the-art TE optimizers with significantly lower execution times. Moreover, our ML-based solution demonstrates a strong generalization capability to successfully operate in new networks unseen during training. ",
    "url": "https://arxiv.org/abs/2303.18157",
    "authors": [
      "Guillermo Bern\u00e1rdez",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Albert L\u00f3pez",
      "Xiang Shi",
      "Shihan Xiao",
      "Xiangle Cheng",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.18164",
    "title": "Single Image Depth Prediction Made Better: A Multivariate Gaussian Take",
    "abstract": "Neural-network-based single image depth prediction (SIDP) is a challenging task where the goal is to predict the scene's per-pixel depth at test time. Since the problem, by definition, is ill-posed, the fundamental goal is to come up with an approach that can reliably model the scene depth from a set of training examples. In the pursuit of perfect depth estimation, most existing state-of-the-art learning techniques predict a single scalar depth value per-pixel. Yet, it is well-known that the trained model has accuracy limits and can predict imprecise depth. Therefore, an SIDP approach must be mindful of the expected depth variations in the model's prediction at test time. Accordingly, we introduce an approach that performs continuous modeling of per-pixel depth, where we can predict and reason about the per-pixel depth and its distribution. To this end, we model per-pixel scene depth using a multivariate Gaussian distribution. Moreover, contrary to the existing uncertainty modeling methods -- in the same spirit, where per-pixel depth is assumed to be independent, we introduce per-pixel covariance modeling that encodes its depth dependency w.r.t all the scene points. Unfortunately, per-pixel depth covariance modeling leads to a computationally expensive continuous loss function, which we solve efficiently using the learned low-rank approximation of the overall covariance matrix. Notably, when tested on benchmark datasets such as KITTI, NYU, and SUN-RGB-D, the SIDP model obtained by optimizing our loss function shows state-of-the-art results. Our method's accuracy (named MG) is among the top on the KITTI depth-prediction benchmark leaderboard. ",
    "url": "https://arxiv.org/abs/2303.18164",
    "authors": [
      "Ce Liu",
      "Suryansh Kumar",
      "Shuhang Gu",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.18174",
    "title": "Diff-ID: An Explainable Identity Difference Quantification Framework for  DeepFake Detection",
    "abstract": "Despite the fact that DeepFake forgery detection algorithms have achieved impressive performance on known manipulations, they often face disastrous performance degradation when generalized to an unseen manipulation. Some recent works show improvement in generalization but rely on features fragile to image distortions such as compression. To this end, we propose Diff-ID, a concise and effective approach that explains and measures the identity loss induced by facial manipulations. When testing on an image of a specific person, Diff-ID utilizes an authentic image of that person as a reference and aligns them to the same identity-insensitive attribute feature space by applying a face-swapping generator. We then visualize the identity loss between the test and the reference image from the image differences of the aligned pairs, and design a custom metric to quantify the identity loss. The metric is then proved to be effective in distinguishing the forgery images from the real ones. Extensive experiments show that our approach achieves high detection performance on DeepFake images and state-of-the-art generalization ability to unknown forgery methods, while also being robust to image distortions. ",
    "url": "https://arxiv.org/abs/2303.18174",
    "authors": [
      "Chuer Yu",
      "Xuhong Zhang",
      "Yuxuan Duan",
      "Senbo Yan",
      "Zonghui Wang",
      "Yang Xiang",
      "Shouling Ji",
      "Wenzhi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.18178",
    "title": "Robust and IP-Protecting Vertical Federated Learning against Unexpected  Quitting of Parties",
    "abstract": "Vertical federated learning (VFL) enables a service provider (i.e., active party) who owns labeled features to collaborate with passive parties who possess auxiliary features to improve model performance. Existing VFL approaches, however, have two major vulnerabilities when passive parties unexpectedly quit in the deployment phase of VFL - severe performance degradation and intellectual property (IP) leakage of the active party's labels. In this paper, we propose \\textbf{Party-wise Dropout} to improve the VFL model's robustness against the unexpected exit of passive parties and a defense method called \\textbf{DIMIP} to protect the active party's IP in the deployment phase. We evaluate our proposed methods on multiple datasets against different inference attacks. The results show that Party-wise Dropout effectively maintains model performance after the passive party quits, and DIMIP successfully disguises label information from the passive party's feature extractor, thereby mitigating IP leakage. ",
    "url": "https://arxiv.org/abs/2303.18178",
    "authors": [
      "Jingwei Sun",
      "Zhixu Du",
      "Anna Dai",
      "Saleh Baghersalimi",
      "Alireza Amirshahi",
      "David Atienza",
      "Yiran Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18186",
    "title": "Adaptive Model Prediction Control-Based Multi-Terrain Trajectory  Tracking Framework for Mobile Spherical Robots",
    "abstract": "Owing to uncertainties in both kinematics and dynamics, the current trajectory tracking framework for mobile robots like spherical robots cannot function effectively on multiple terrains, especially uneven and unknown ones. Since this is a prerequisite for robots to execute tasks in the wild, we enhance our previous hierarchical trajectory tracking framework to handle this issue. First, a modified adaptive RBF neural network (RBFNN) is proposed to represent all uncertainties in kinodynamics. Then the Lyapunov function is utilized to design its adaptive law, and a variable step-size algorithm is employed in the weights update procedure to accelerate convergence and improve stability. Hence, a new adaptive model prediction control-based instruction planner (VAN-MPC) is proposed. Without modifying the bottom controllers, we finally develop the multi-terrain trajectory tracking framework by employing the new instruction planner VAN-MPC. The practical experiments demonstrate its effectiveness and robustness. ",
    "url": "https://arxiv.org/abs/2303.18186",
    "authors": [
      "Yifan Liu",
      "Tao Hu",
      "Xiaoqing Guan",
      "Yixu Wang",
      "Bixuan Zhang",
      "You Wang",
      "Guang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.18187",
    "title": "Learning Spiking Neural Systems with the Event-Driven Forward-Forward  Process",
    "abstract": "We develop a novel credit assignment algorithm for information processing with spiking neurons without requiring feedback synapses. Specifically, we propose an event-driven generalization of the forward-forward and the predictive forward-forward learning processes for a spiking neural system that iteratively processes sensory input over a stimulus window. As a result, the recurrent circuit computes the membrane potential of each neuron in each layer as a function of local bottom-up, top-down, and lateral signals, facilitating a dynamic, layer-wise parallel form of neural computation. Unlike spiking neural coding, which relies on feedback synapses to adjust neural electrical activity, our model operates purely online and forward in time, offering a promising way to learn distributed representations of sensory data patterns with temporal spike signals. Notably, our experimental results on several pattern datasets demonstrate that the even-driven forward-forward (ED-FF) framework works well for training a dynamic recurrent spiking system capable of both classification and reconstruction. ",
    "url": "https://arxiv.org/abs/2303.18187",
    "authors": [
      "Alexander Ororbia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18191",
    "title": "Detecting Backdoors During the Inference Stage Based on Corruption  Robustness Consistency",
    "abstract": "Deep neural networks are proven to be vulnerable to backdoor attacks. Detecting the trigger samples during the inference stage, i.e., the test-time trigger sample detection, can prevent the backdoor from being triggered. However, existing detection methods often require the defenders to have high accessibility to victim models, extra clean data, or knowledge about the appearance of backdoor triggers, limiting their practicality. In this paper, we propose the test-time corruption robustness consistency evaluation (TeCo), a novel test-time trigger sample detection method that only needs the hard-label outputs of the victim models without any extra information. Our journey begins with the intriguing observation that the backdoor-infected models have similar performance across different image corruptions for the clean images, but perform discrepantly for the trigger samples. Based on this phenomenon, we design TeCo to evaluate test-time robustness consistency by calculating the deviation of severity that leads to predictions' transition across different corruptions. Extensive experiments demonstrate that compared with state-of-the-art defenses, which even require either certain information about the trigger types or accessibility of clean data, TeCo outperforms them on different backdoor attacks, datasets, and model architectures, enjoying a higher AUROC by 10% and 5 times of stability. ",
    "url": "https://arxiv.org/abs/2303.18191",
    "authors": [
      "Xiaogeng Liu",
      "Minghui Li",
      "Haoyu Wang",
      "Shengshan Hu",
      "Dengpan Ye",
      "Hai Jin",
      "Libing Wu",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18200",
    "title": "PADME-SoSci: A Platform for Analytics and Distributed Machine Learning  for the Social Sciences",
    "abstract": "Data privacy and ownership are significant in social data science, raising legal and ethical concerns. Sharing and analyzing data is difficult when different parties own different parts of it. An approach to this challenge is to apply de-identification or anonymization techniques to the data before collecting it for analysis. However, this can reduce data utility and increase the risk of re-identification. To address these limitations, we present PADME, a distributed analytics tool that federates model implementation and training. PADME uses a federated approach where the model is implemented and deployed by all parties and visits each data location incrementally for training. This enables the analysis of data across locations while still allowing the model to be trained as if all data were in a single location. Training the model on data in its original location preserves data ownership. Furthermore, the results are not provided until the analysis is completed on all data locations to ensure privacy and avoid bias in the results. ",
    "url": "https://arxiv.org/abs/2303.18200",
    "authors": [
      "Zeyd Boukhers",
      "Arnim Bleier",
      "Yeliz Ucer Yediel",
      "Mio Hienstorfer-Heitmann",
      "Mehrshad Jaberansaryand Adamantios Koumpisand Oya Beyan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18201",
    "title": "TPMCF: Temporal QoS Prediction using Multi-Source Collaborative Features",
    "abstract": "Recently, with the rapid deployment of service APIs, personalized service recommendations have played a paramount role in the growth of the e-commerce industry. Quality-of-Service (QoS) parameters determining the service performance, often used for recommendation, fluctuate over time. Thus, the QoS prediction is essential to identify a suitable service among functionally equivalent services over time. The contemporary temporal QoS prediction methods hardly achieved the desired accuracy due to various limitations, such as the inability to handle data sparsity and outliers and capture higher-order temporal relationships among user-service interactions. Even though some recent recurrent neural-network-based architectures can model temporal relationships among QoS data, prediction accuracy degrades due to the absence of other features (e.g., collaborative features) to comprehend the relationship among the user-service interactions. This paper addresses the above challenges and proposes a scalable strategy for Temporal QoS Prediction using Multi-source Collaborative-Features (TPMCF), achieving high prediction accuracy and faster responsiveness. TPMCF combines the collaborative-features of users/services by exploiting user-service relationship with the spatio-temporal auto-extracted features by employing graph convolution and transformer encoder with multi-head self-attention. We validated our proposed method on WS-DREAM-2 datasets. Extensive experiments showed TPMCF outperformed major state-of-the-art approaches regarding prediction accuracy while ensuring high scalability and reasonably faster responsiveness. ",
    "url": "https://arxiv.org/abs/2303.18201",
    "authors": [
      "Suraj Kumar",
      "Soumi Chattopadhyay",
      "Chandranath Adak"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18205",
    "title": "SimTS: Rethinking Contrastive Representation Learning for Time Series  Forecasting",
    "abstract": "Contrastive learning methods have shown an impressive ability to learn meaningful representations for image or time series classification. However, these methods are less effective for time series forecasting, as optimization of instance discrimination is not directly applicable to predicting the future state from the history context. Moreover, the construction of positive and negative pairs in current technologies strongly relies on specific time series characteristics, restricting their generalization across diverse types of time series data. To address these limitations, we propose SimTS, a simple representation learning approach for improving time series forecasting by learning to predict the future from the past in the latent space. SimTS does not rely on negative pairs or specific assumptions about the characteristics of the particular time series. Our extensive experiments on several benchmark time series forecasting datasets show that SimTS achieves competitive performance compared to existing contrastive learning methods. Furthermore, we show the shortcomings of the current contrastive learning framework used for time series forecasting through a detailed ablation study. Overall, our work suggests that SimTS is a promising alternative to other contrastive learning approaches for time series forecasting. ",
    "url": "https://arxiv.org/abs/2303.18205",
    "authors": [
      "Xiaochen Zheng",
      "Xingyu Chen",
      "Manuel Sch\u00fcrch",
      "Amina Mollaysa",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18219",
    "title": "SemHint-MD: Learning from Noisy Semantic Labels for Self-Supervised  Monocular Depth Estimation",
    "abstract": "Without ground truth supervision, self-supervised depth estimation can be trapped in a local minimum due to the gradient-locality issue of the photometric loss. In this paper, we present a framework to enhance depth by leveraging semantic segmentation to guide the network to jump out of the local minimum. Prior works have proposed to share encoders between these two tasks or explicitly align them based on priors like the consistency between edges in the depth and segmentation maps. Yet, these methods usually require ground truth or high-quality pseudo labels, which may not be easily accessible in real-world applications. In contrast, we investigate self-supervised depth estimation along with a segmentation branch that is supervised with noisy labels provided by models pre-trained with limited data. We extend parameter sharing from the encoder to the decoder and study the influence of different numbers of shared decoder parameters on model performance. Also, we propose to use cross-task information to refine current depth and segmentation predictions to generate pseudo-depth and semantic labels for training. The advantages of the proposed method are demonstrated through extensive experiments on the KITTI benchmark and a downstream task for endoscopic tissue deformation tracking. ",
    "url": "https://arxiv.org/abs/2303.18219",
    "authors": [
      "Shan Lin",
      "Yuheng Zhi",
      "Michael C. Yip"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17671",
    "title": "Neural signature kernels as infinite-width-depth-limits of controlled  ResNets",
    "abstract": "Motivated by the paradigm of reservoir computing, we consider randomly initialized controlled ResNets defined as Euler-discretizations of neural controlled differential equations (Neural CDEs). We show that in the infinite-width-then-depth limit and under proper scaling, these architectures converge weakly to Gaussian processes indexed on some spaces of continuous paths and with kernels satisfying certain partial differential equations (PDEs) varying according to the choice of activation function. In the special case where the activation is the identity, we show that the equation reduces to a linear PDE and the limiting kernel agrees with the signature kernel of Salvi et al. (2021). In this setting, we also show that the width-depth limits commute. We name this new family of limiting kernels neural signature kernels. Finally, we show that in the infinite-depth regime, finite-width controlled ResNets converge in distribution to Neural CDEs with random vector fields which, depending on whether the weights are shared across layers, are either time-independent and Gaussian or behave like a matrix-valued Brownian motion. ",
    "url": "https://arxiv.org/abs/2303.17671",
    "authors": [
      "Nicola Muca Cirone",
      "Maud Lemercier",
      "Cristopher Salvi"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2303.17765",
    "title": "Learning from Similar Linear Representations: Adaptivity, Minimaxity,  and Robustness",
    "abstract": "Representation multi-task learning (MTL) and transfer learning (TL) have achieved tremendous success in practice. However, the theoretical understanding of these methods is still lacking. Most existing theoretical works focus on cases where all tasks share the same representation, and claim that MTL and TL almost always improve performance. However, as the number of tasks grow, assuming all tasks share the same representation is unrealistic. Also, this does not always match empirical findings, which suggest that a shared representation may not necessarily improve single-task or target-only learning performance. In this paper, we aim to understand how to learn from tasks with \\textit{similar but not exactly the same} linear representations, while dealing with outlier tasks. We propose two algorithms that are \\textit{adaptive} to the similarity structure and \\textit{robust} to outlier tasks under both MTL and TL settings. Our algorithms outperform single-task or target-only learning when representations across tasks are sufficiently similar and the fraction of outlier tasks is small. Furthermore, they always perform no worse than single-task learning or target-only learning, even when the representations are dissimilar. We provide information-theoretic lower bounds to show that our algorithms are nearly \\textit{minimax} optimal in a large regime. ",
    "url": "https://arxiv.org/abs/2303.17765",
    "authors": [
      "Ye Tian",
      "Yuqi Gu",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17823",
    "title": "An interpretable neural network-based non-proportional odds model for  ordinal regression with continuous response",
    "abstract": "This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately. ",
    "url": "https://arxiv.org/abs/2303.17823",
    "authors": [
      "Akifumi Okuno",
      "Kazuharu Harada"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.17941",
    "title": "Comparing Adversarial and Supervised Learning for Organs at Risk  Segmentation in CT images",
    "abstract": "Organ at Risk (OAR) segmentation from CT scans is a key component of the radiotherapy treatment workflow. In recent years, deep learning techniques have shown remarkable potential in automating this process. In this paper, we investigate the performance of Generative Adversarial Networks (GANs) compared to supervised learning approaches for segmenting OARs from CT images. We propose three GAN-based models with identical generator architectures but different discriminator networks. These models are compared with well-established CNN models, such as SE-ResUnet and DeepLabV3, using the StructSeg dataset, which consists of 50 annotated CT scans containing contours of six OARs. Our work aims to provide insight into the advantages and disadvantages of adversarial training in the context of OAR segmentation. The results are very promising and show that the proposed GAN-based approaches are similar or superior to their CNN-based counterparts, particularly when segmenting more challenging target organs. ",
    "url": "https://arxiv.org/abs/2303.17941",
    "authors": [
      "Leonardo Crespi",
      "Mattia Portanti",
      "Daniele Loiacono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18001",
    "title": "You Only Train Once: Learning a General Anomaly Enhancement Network with  Random Masks for Hyperspectral Anomaly Detection",
    "abstract": "In this paper, we introduce a new approach to address the challenge of generalization in hyperspectral anomaly detection (AD). Our method eliminates the need for adjusting parameters or retraining on new test scenes as required by most existing methods. Employing an image-level training paradigm, we achieve a general anomaly enhancement network for hyperspectral AD that only needs to be trained once. Trained on a set of anomaly-free hyperspectral images with random masks, our network can learn the spatial context characteristics between anomalies and background in an unsupervised way. Additionally, a plug-and-play model selection module is proposed to search for a spatial-spectral transform domain that is more suitable for AD task than the original data. To establish a unified benchmark to comprehensively evaluate our method and existing methods, we develop a large-scale hyperspectral AD dataset (HAD100) that includes 100 real test scenes with diverse anomaly targets. In comparison experiments, we combine our network with a parameter-free detector and achieve the optimal balance between detection accuracy and inference speed among state-of-the-art AD methods. Experimental results also show that our method still achieves competitive performance when the training and test set are captured by different sensor devices. Our code is available at https://github.com/ZhaoxuLi123/AETNet. ",
    "url": "https://arxiv.org/abs/2303.18001",
    "authors": [
      "Zhaoxu Li",
      "Yingqian Wang",
      "Chao Xiao",
      "Qiang Ling",
      "Zaiping Lin",
      "Wei An"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.18017",
    "title": "Rapid prediction of lab-grown tissue properties using deep learning",
    "abstract": "The interactions between cells and the extracellular matrix are vital for the self-organisation of tissues. In this paper we present proof-of-concept to use machine learning tools to predict the role of this mechanobiology in the self-organisation of cell-laden hydrogels grown in tethered moulds. We develop a process for the automated generation of mould designs with and without key symmetries. We create a large training set with $N=6500$ cases by running detailed biophysical simulations of cell-matrix interactions using the contractile network dipole orientation (CONDOR) model for the self-organisation of cellular hydrogels within these moulds. These are used to train an implementation of the \\texttt{pix2pix} deep learning model, reserving $740$ cases that were unseen in the training of the neural network for training and validation. Comparison between the predictions of the machine learning technique and the reserved predictions from the biophysical algorithm show that the machine learning algorithm makes excellent predictions. The machine learning algorithm is significantly faster than the biophysical method, opening the possibility of very high throughput rational design of moulds for pharmaceutical testing, regenerative medicine and fundamental studies of biology. Future extensions for scaffolds and 3D bioprinting will open additional applications. ",
    "url": "https://arxiv.org/abs/2303.18017",
    "authors": [
      "Allison E. Andrews",
      "Hugh Dickinson",
      "James P. Hague"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.18061",
    "title": "Multi-User Data Detection in Massive MIMO with 1-Bit ADCs",
    "abstract": "We provide new analytical results on the uplink data detection in massive multiple-input multiple-output systems with 1-bit analog-to-digital converters. The statistical properties of the soft-estimated symbols (i.e., after linear combining and prior to the data detection process) have been previously characterized only for a single user equipment (UE) and uncorrelated Rayleigh fading. In this paper, we consider a multi-UE setting with correlated Rayleigh fading, where the soft-estimated symbols are obtained by means of maximum ratio combining based on imperfectly estimated channels. We derive a closed-form expression of the expected value of the soft-estimated symbols, which allows to understand the impact of the specific data symbols transmitted by the interfering UEs. Building on this result, we design efficient data detection strategies based on the minimum distance criterion, which are compared in terms of symbol error rate and complexity. ",
    "url": "https://arxiv.org/abs/2303.18061",
    "authors": [
      "Amin Radbord",
      "Italo Atzeni",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2303.18066",
    "title": "Finite Elements with Switched Detection for Direct Optimal Control of  Nonsmooth Systems with Set-Valued Step Functions",
    "abstract": "This paper extends the Finite Elements with Switch Detection (FESD) method [Nurkanovi\\'c et al., 2022] to optimal control problems with nonsmooth systems involving set-valued step functions. Logical relations and common nonsmooth functions within a dynamical system can be expressed using linear and nonlinear expressions of the components of the step function. A prominent subclass of these systems are Filippov systems. The set-valued step function can be expressed by the solution map of a linear program, and using its KKT conditions allows one to transform the initial system into an equivalent dynamic complementarity system (DCS). Standard Runge-Kutta (RK) methods applied to DCS have only first-order accuracy. The FESD discretization makes the step sizes degrees of freedom and adds further constraints that ensure exact switch detection to recover the high-accuracy properties that RK methods have for smooth ODEs. All methods and examples in this paper are implemented in the open-source software package NOSNOC. ",
    "url": "https://arxiv.org/abs/2303.18066",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Jonathan Frey",
      "Anton Pozharskiy",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.18211",
    "title": "Simple Sorting Criteria Help Find the Causal Order in Additive Noise  Models",
    "abstract": "Additive Noise Models (ANM) encode a popular functional assumption that enables learning causal structure from observational data. Due to a lack of real-world data meeting the assumptions, synthetic ANM data are often used to evaluate causal discovery algorithms. Reisach et al. (2021) show that, for common simulation parameters, a variable ordering by increasing variance is closely aligned with a causal order and introduce var-sortability to quantify the alignment. Here, we show that not only variance, but also the fraction of a variable's variance explained by all others, as captured by the coefficient of determination $R^2$, tends to increase along the causal order. Simple baseline algorithms can use $R^2$-sortability to match the performance of established methods. Since $R^2$-sortability is invariant under data rescaling, these algorithms perform equally well on standardized or rescaled data, addressing a key limitation of algorithms exploiting var-sortability. We characterize and empirically assess $R^2$-sortability for different simulation parameters. We show that all simulation parameters can affect $R^2$-sortability and must be chosen deliberately to control the difficulty of the causal discovery task and the real-world plausibility of the simulated data. We provide an implementation of the sortability measures and sortability-based algorithms in our library CausalDisco (https://github.com/CausalDisco/CausalDisco). ",
    "url": "https://arxiv.org/abs/2303.18211",
    "authors": [
      "Alexander G. Reisach",
      "Myriam Tami",
      "Christof Seiler",
      "Antoine Chambaz",
      "Sebastian Weichwald"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1902.09037",
    "title": "Adaptive Estimators Show Information Compression in Deep Neural Networks",
    "abstract": " Comments: Accepted as a poster presentation at ICLR 2019 and reviewed on OpenReview (available at this https URL). Pages: 11. Figures: 9 ",
    "url": "https://arxiv.org/abs/1902.09037",
    "authors": [
      "Ivan Chelombiev",
      "Conor Houghton",
      "Cian O'Donnell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.03825",
    "title": "Optimal training of integer-valued neural networks with mixed integer  programming",
    "abstract": " Title: Optimal training of integer-valued neural networks with mixed integer  programming ",
    "url": "https://arxiv.org/abs/2009.03825",
    "authors": [
      "T\u00f3mas Thorbjarnarson",
      "Neil Yorke-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.03176",
    "title": "Feature Representation in Deep Metric Embeddings",
    "abstract": " Title: Feature Representation in Deep Metric Embeddings ",
    "url": "https://arxiv.org/abs/2102.03176",
    "authors": [
      "Ryan Furlong",
      "Vincent O'Brien",
      "James Garland",
      "Daniel Palacios-Alonso",
      "Francisco Dominguez-Mateos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.04794",
    "title": "Packet-Level Adversarial Network Traffic Crafting using Sequence  Generative Adversarial Networks",
    "abstract": " Comments: The authors agreed to withdraw the manuscript due to privacy reason ",
    "url": "https://arxiv.org/abs/2103.04794",
    "authors": [
      "Qiumei Cheng",
      "Shiying Zhou",
      "Yi Shen",
      "Dezhang Kong",
      "Chunming Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.03084",
    "title": "Transferring Knowledge Distillation for Multilingual Social Event  Detection",
    "abstract": " Comments: We withdrew this paper from TPAMI due to the long review cycle. Recently we have restudied our methods and some new great results are discovered ",
    "url": "https://arxiv.org/abs/2108.03084",
    "authors": [
      "Jiaqian Ren",
      "Hao Peng",
      "Lei Jiang",
      "Jia Wu",
      "Yongxin Tong",
      "Lihong Wang",
      "Xu Bai",
      "Bo Wang",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06861",
    "title": "Quantus: An Explainable AI Toolkit for Responsible Evaluation of Neural  Network Explanations and Beyond",
    "abstract": " Comments: 4 pages, 1 figure, 1 table ",
    "url": "https://arxiv.org/abs/2202.06861",
    "authors": [
      "Anna Hedstr\u00f6m",
      "Leander Weber",
      "Dilyara Bareeva",
      "Franz Motzkus",
      "Wojciech Samek",
      "Sebastian Lapuschkin",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.15752",
    "title": "Information Consumption and Boundary Spanning in Decentralized Online  Social Networks: the case of Mastodon Users",
    "abstract": " Comments: Preprint of article published with Online Social Networks and Media, vol. 30:100220, June 2022. Elsevier ",
    "url": "https://arxiv.org/abs/2203.15752",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2204.03245",
    "title": "HIT-UAV: A high-altitude infrared thermal dataset for Unmanned Aerial  Vehicle-based object detection",
    "abstract": " Title: HIT-UAV: A high-altitude infrared thermal dataset for Unmanned Aerial  Vehicle-based object detection ",
    "url": "https://arxiv.org/abs/2204.03245",
    "authors": [
      "Jiashun Suo",
      "Tianyi Wang",
      "Xingzhou Zhang",
      "Haiyang Chen",
      "Wei Zhou",
      "Weisong Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05184",
    "title": "Domain Adversarial Graph Convolutional Network Based on RSSI and  Crowdsensing for Indoor Localization",
    "abstract": " Comments: IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2204.05184",
    "authors": [
      "Mingxin Zhang",
      "Zipei Fan",
      "Ryosuke Shibasaki",
      "Xuan Song"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.08208",
    "title": "Unsupervised Medical Image Translation with Adversarial Diffusion Models",
    "abstract": " Comments: M. Ozbey and O. Dalmaz contributed equally to this study ",
    "url": "https://arxiv.org/abs/2207.08208",
    "authors": [
      "Muzaffer \u00d6zbey",
      "Onat Dalmaz",
      "Salman UH Dar",
      "Hasan A Bedel",
      "\u015eaban \u00d6zturk",
      "Alper G\u00fcng\u00f6r",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10435",
    "title": "Human Trajectory Prediction via Neural Social Physics",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2207.10435",
    "authors": [
      "Jiangbei Yue",
      "Dinesh Manocha",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.14682",
    "title": "Towards Unconstrained Audio Splicing Detection and Localization with  Neural Networks",
    "abstract": " Comments: Accepted at MMFORWILD 2022, ICPR Workshops - Code: this https URL ",
    "url": "https://arxiv.org/abs/2207.14682",
    "authors": [
      "Denise Moussa",
      "Germans Hirsch",
      "Christian Riess"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.01194",
    "title": "CLONeR: Camera-Lidar Fusion for Occupancy Grid-aided Neural  Representations",
    "abstract": " Comments: first two authors equally contributed ",
    "url": "https://arxiv.org/abs/2209.01194",
    "authors": [
      "Alexandra Carlson",
      "Manikandasriram Srinivasan Ramanagopal",
      "Nathan Tseng",
      "Matthew Johnson-Roberson",
      "Ram Vasudevan",
      "Katherine A. Skinner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.01701",
    "title": "Concatenated Classic and Neural (CCN) Codes: ConcatenatedAE",
    "abstract": " Comments: 6 pages, IEEE WCNC 2023 ",
    "url": "https://arxiv.org/abs/2209.01701",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Rick Fritschek",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.03147",
    "title": "Network Intrusion Detection with Limited Labeled Data Using  Self-supervision",
    "abstract": " Title: Network Intrusion Detection with Limited Labeled Data Using  Self-supervision ",
    "url": "https://arxiv.org/abs/2209.03147",
    "authors": [
      "S. Lotfi",
      "M. Modirrousta",
      "S. Shashaani",
      "M. Aliyari Shoorehdeli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.06015",
    "title": "Black-box Dataset Ownership Verification via Backdoor Watermarking",
    "abstract": " Comments: This paper is accepted by IEEE TIFS. 15 pages. The preliminary short version of this paper was posted on arXiv (arXiv:2010.05821) and presented in a non-archival NeurIPS Workshop (2020) ",
    "url": "https://arxiv.org/abs/2209.06015",
    "authors": [
      "Yiming Li",
      "Mingyan Zhu",
      "Xue Yang",
      "Yong Jiang",
      "Tao Wei",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12054",
    "title": "Towards Global Neural Network Abstractions with Locally-Exact  Reconstruction",
    "abstract": " Comments: Under submission to the Neural Networks Journal (revised version). Sections 2, 4.7, 5.4, Appendix A and B have been added ",
    "url": "https://arxiv.org/abs/2210.12054",
    "authors": [
      "Edoardo Manino",
      "Iury Bessa",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.16539",
    "title": "Exploiting prompt learning with pre-trained language models for  Alzheimer's Disease detection",
    "abstract": " Comments: Accepted ICASSP 2023 (will update with IEEE vision later) ",
    "url": "https://arxiv.org/abs/2210.16539",
    "authors": [
      "Yi Wang",
      "Jiajun Deng",
      "Tianzi Wang",
      "Bo Zheng",
      "Shoukang Hu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.17101",
    "title": "Unrolled Graph Learning for Multi-Agent Collaboration",
    "abstract": " Title: Unrolled Graph Learning for Multi-Agent Collaboration ",
    "url": "https://arxiv.org/abs/2210.17101",
    "authors": [
      "Enpei Zhang",
      "Shuo Tang",
      "Xiaowen Dong",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.03329",
    "title": "Implicit Graphon Neural Representation",
    "abstract": " Comments: 3 figures ",
    "url": "https://arxiv.org/abs/2211.03329",
    "authors": [
      "Xinyue Xia",
      "Gal Mishne",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.04674",
    "title": "Lipschitz Continuous Algorithms for Graph Problems",
    "abstract": " Title: Lipschitz Continuous Algorithms for Graph Problems ",
    "url": "https://arxiv.org/abs/2211.04674",
    "authors": [
      "Soh Kumabe",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.08447",
    "title": "SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic  Specialisation for Chinese Sexism Detection in Social Media",
    "abstract": " Comments: accepted at ICWSM 2023 ",
    "url": "https://arxiv.org/abs/2211.08447",
    "authors": [
      "Aiqi Jiang",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.11417",
    "title": "DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular  Automata",
    "abstract": " Comments: Link to the demo: this https URL ",
    "url": "https://arxiv.org/abs/2211.11417",
    "authors": [
      "Ehsan Pajouheshgar",
      "Yitao Xu",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12277",
    "title": "Semantic Guided Level-Category Hybrid Prediction Network for  Hierarchical Image Classification",
    "abstract": " Title: Semantic Guided Level-Category Hybrid Prediction Network for  Hierarchical Image Classification ",
    "url": "https://arxiv.org/abs/2211.12277",
    "authors": [
      "Peng Wang",
      "Jingzhou Chen",
      "Yuntao Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.13551",
    "title": "SfM-TTR: Using Structure from Motion for Test-Time Refinement of  Single-View Depth Networks",
    "abstract": " Title: SfM-TTR: Using Structure from Motion for Test-Time Refinement of  Single-View Depth Networks ",
    "url": "https://arxiv.org/abs/2211.13551",
    "authors": [
      "Sergio Izquierdo",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16630",
    "title": "DINER: Depth-aware Image-based NEural Radiance fields",
    "abstract": " Comments: Website: this https URL ; Video: this https URL&t=1s ",
    "url": "https://arxiv.org/abs/2211.16630",
    "authors": [
      "Malte Prinzler",
      "Otmar Hilliges",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01611",
    "title": "CoP: Factual Inconsistency Detection by Controlling the Preference",
    "abstract": " Comments: Accepted to AAAI2023 regular paper ",
    "url": "https://arxiv.org/abs/2212.01611",
    "authors": [
      "Shuaijie She",
      "Xiang Geng",
      "Shujian Huang",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.05936",
    "title": "Encoder-Decoder Network with Guided Transmission Map: Architecture",
    "abstract": " Comments: 3 pages, 2 figures, ASPAI 2022 ",
    "url": "https://arxiv.org/abs/2212.05936",
    "authors": [
      "Le-Anh Tran",
      "Dong-Chul Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.06370",
    "title": "Dual Accuracy-Quality-Driven Neural Network for Prediction Interval  Generation",
    "abstract": " Comments: Submitted to IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2212.06370",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00437",
    "title": "Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced  Data",
    "abstract": " Comments: 93 pages, 20 figures, 4 tables. Hien Dang and Tho Tran contributed equally to this work ",
    "url": "https://arxiv.org/abs/2301.00437",
    "authors": [
      "Hien Dang",
      "Tho Tran",
      "Stanley Osher",
      "Hung Tran-The",
      "Nhat Ho",
      "Tan Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.00794",
    "title": "STEPs: Self-Supervised Key Step Extraction from Unlabeled Procedural  Videos",
    "abstract": " Title: STEPs: Self-Supervised Key Step Extraction from Unlabeled Procedural  Videos ",
    "url": "https://arxiv.org/abs/2301.00794",
    "authors": [
      "Anshul Shah",
      "Benjamin Lundell",
      "Harpreet Sawhney",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04535",
    "title": "Few-shot Learning for Cross-Target Stance Detection by Aggregating  Multimodal Embeddings",
    "abstract": " Comments: To appear in IEEE Transactions on Computational Social Systems ",
    "url": "https://arxiv.org/abs/2301.04535",
    "authors": [
      "Parisa Jamadi Khiabani",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.08243",
    "title": "Self-Supervised Learning from Images with a Joint-Embedding Predictive  Architecture",
    "abstract": " Comments: 2023 IEEE/CVF International Conference on Computer Vision ",
    "url": "https://arxiv.org/abs/2301.08243",
    "authors": [
      "Mahmoud Assran",
      "Quentin Duval",
      "Ishan Misra",
      "Piotr Bojanowski",
      "Pascal Vincent",
      "Michael Rabbat",
      "Yann LeCun",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.08859",
    "title": "Logical Message Passing Networks with One-hop Inference on Atomic  Formulas",
    "abstract": " Comments: Accepted by ICLR 2023. 20 pages, 4 figures, and 9 tables. Our implementation can be found at this https URL update v3: typo fix. update v2: add code repository ",
    "url": "https://arxiv.org/abs/2301.08859",
    "authors": [
      "Zihao Wang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2301.12456",
    "title": "Towards Verifying the Geometric Robustness of Large-scale Neural  Networks",
    "abstract": " Title: Towards Verifying the Geometric Robustness of Large-scale Neural  Networks ",
    "url": "https://arxiv.org/abs/2301.12456",
    "authors": [
      "Fu Wang",
      "Peipei Xu",
      "Wenjie Ruan",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02790",
    "title": "Perception Datasets for Anomaly Detection in Autonomous Driving: A  Survey",
    "abstract": " Comments: Accepted for publication at IV 2023 ",
    "url": "https://arxiv.org/abs/2302.02790",
    "authors": [
      "Daniel Bogdoll",
      "Svenja Uhlemeyer",
      "Kamil Kowol",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06859",
    "title": "Learning Distortion Invariant Representation for Image Restoration from  A Causality Perspective",
    "abstract": " Comments: Accepted by CVPR2023 ",
    "url": "https://arxiv.org/abs/2303.06859",
    "authors": [
      "Xin Li",
      "Bingchen Li",
      "Xin Jin",
      "Cuiling Lan",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.09483",
    "title": "Achieving a Better Stability-Plasticity Trade-off via Auxiliary Networks  in Continual Learning",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.09483",
    "authors": [
      "Sanghwan Kim",
      "Lorenzo Noci",
      "Antonio Orvieto",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16066",
    "title": "Neural Collapse Inspired Federated Learning with Non-iid Data",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.16066",
    "authors": [
      "Chenxi Huang",
      "Liang Xie",
      "Yibo Yang",
      "Wenxiao Wang",
      "Binbin Lin",
      "Deng Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16166",
    "title": "Reproducibility is Nothing without Correctness: The Importance of  Testing Code in NLP",
    "abstract": " Title: Reproducibility is Nothing without Correctness: The Importance of  Testing Code in NLP ",
    "url": "https://arxiv.org/abs/2303.16166",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Andrea Pilzer",
      "Matteo Negri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16904",
    "title": "Severity classification of ground-glass opacity via 2-D convolutional  neural network and lung CT scans: a 3-day exploration",
    "abstract": " Title: Severity classification of ground-glass opacity via 2-D convolutional  neural network and lung CT scans: a 3-day exploration ",
    "url": "https://arxiv.org/abs/2303.16904",
    "authors": [
      "Lisa Y.W. Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17001",
    "title": "The G-invariant graph Laplacian",
    "abstract": " Title: The G-invariant graph Laplacian ",
    "url": "https://arxiv.org/abs/2303.17001",
    "authors": [
      "Eitan Rosen",
      "Xiuyuan Cheng",
      "Yoel Shkolnisky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.17597",
    "title": "Robo3D: Towards Robust and Reliable 3D Perception against Corruptions",
    "abstract": " Comments: 33 pages, 26 figures, 26 tables; code at this https URL project page at this https URL ",
    "url": "https://arxiv.org/abs/2303.17597",
    "authors": [
      "Lingdong Kong",
      "Youquan Liu",
      "Xin Li",
      "Runnan Chen",
      "Wenwei Zhang",
      "Jiawei Ren",
      "Liang Pan",
      "Kai Chen",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  }
]