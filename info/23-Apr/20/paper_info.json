[
  {
    "id": "arXiv:2304.09184",
    "title": "Frequency Enhanced Hybrid Attention Network for Sequential  Recommendation",
    "abstract": "The self-attention mechanism, which equips with a strong capability of modeling long-range dependencies, is one of the extensively used techniques in the sequential recommendation field. However, many recent studies represent that current self-attention based models are low-pass filters and are inadequate to capture high-frequency information. Furthermore, since the items in the user behaviors are intertwined with each other, these models are incomplete to distinguish the inherent periodicity obscured in the time domain. In this work, we shift the perspective to the frequency domain, and propose a novel Frequency Enhanced Hybrid Attention Network for Sequential Recommendation, namely FEARec. In this model, we firstly improve the original time domain self-attention in the frequency domain with a ramp structure to make both low-frequency and high-frequency information could be explicitly learned in our approach. Moreover, we additionally design a similar attention mechanism via auto-correlation in the frequency domain to capture the periodic characteristics and fuse the time and frequency level attention in a union model. Finally, both contrastive learning and frequency regularization are utilized to ensure that multiple views are aligned in both the time domain and frequency domain. Extensive experiments conducted on four widely used benchmark datasets demonstrate that the proposed model performs significantly better than the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2304.09184",
    "authors": [
      "Xinyu Du",
      "Huanhuan Yuan",
      "Pengpeng Zhao",
      "Fuzhen Zhuang",
      "Guanfeng Liu",
      "Yanchi Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.09214",
    "title": "SO(2) and O(2) Equivariance in Image Recognition with  Bessel-Convolutional Neural Networks",
    "abstract": "For many years, it has been shown how much exploiting equivariances can be beneficial when solving image analysis tasks. For example, the superiority of convolutional neural networks (CNNs) compared to dense networks mainly comes from an elegant exploitation of the translation equivariance. Patterns can appear at arbitrary positions and convolutions take this into account to achieve translation invariant operations through weight sharing. Nevertheless, images often involve other symmetries that can also be exploited. It is the case of rotations and reflections that have drawn particular attention and led to the development of multiple equivariant CNN architectures. Among all these methods, Bessel-convolutional neural networks (B-CNNs) exploit a particular decomposition based on Bessel functions to modify the key operation between images and filters and make it by design equivariant to all the continuous set of planar rotations. In this work, the mathematical developments of B-CNNs are presented along with several improvements, including the incorporation of reflection and multi-scale equivariances. Extensive study is carried out to assess the performances of B-CNNs compared to other methods. Finally, we emphasize the theoretical advantages of B-CNNs by giving more insights and in-depth mathematical details. ",
    "url": "https://arxiv.org/abs/2304.09214",
    "authors": [
      "Valentin Delchevalerie",
      "Alexandre Mayer",
      "Adrien Bibal",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09221",
    "title": "Convergence of stochastic gradient descent under a local Lajasiewicz  condition for deep neural networks",
    "abstract": "We extend the global convergence result of Chatterjee \\cite{chatterjee2022convergence} by considering the stochastic gradient descent (SGD) for non-convex objective functions. With minimal additional assumptions that can be realized by finitely wide neural networks, we prove that if we initialize inside a local region where the \\L{}ajasiewicz condition holds, with a positive probability, the stochastic gradient iterates converge to a global minimum inside this region. A key component of our proof is to ensure that the whole trajectories of SGD stay inside the local region with a positive probability. For that, we assume the SGD noise scales with the objective function, which is called machine learning noise and achievable in many real examples. Furthermore, we provide a negative argument to show why using the boundedness of noise with Robbins-Monro type step sizes is not enough to keep the key component valid. ",
    "url": "https://arxiv.org/abs/2304.09221",
    "authors": [
      "Jing An",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09234",
    "title": "Capacity Allocation and Pricing of High Occupancy Toll Lane Systems with  Heterogeneous Travelers",
    "abstract": "In this article, we study the optimal design of High Occupancy Toll (HOT) lanes. In our setup, the traffic authority determines the road capacity allocation between HOT lanes and ordinary lanes, as well as the toll price charged for travelers who use the HOT lanes but do not meet the high-occupancy eligibility criteria. We build a game-theoretic model to analyze the decisions made by travelers with heterogeneous values of time and carpool disutilities, who choose between paying or forming carpools to take the HOT lanes, or taking the ordinary lanes. Travelers' payoffs depend on the congestion cost of the lane that they take, the payment and the carpool disutilities. We provide a complete characterization of travelers' equilibrium strategies and resulting travel times for any capacity allocation and toll price. We also calibrate our model on the California Interstate highway 880 and compute the optimal capacity allocation and toll design. ",
    "url": "https://arxiv.org/abs/2304.09234",
    "authors": [
      "Haripriya Pulyassary",
      "Ruifan Yang",
      "Zhanhao Zhang",
      "Manxi Wu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.09243",
    "title": "Evaluation of a Canonical Image Representation for Sidescan Sonar",
    "abstract": "Acoustic sensors play an important role in autonomous underwater vehicles (AUVs). Sidescan sonar (SSS) detects a wide range and provides photo-realistic images in high resolution. However, SSS projects the 3D seafloor to 2D images, which are distorted by the AUV's altitude, target's range and sensor's resolution. As a result, the same physical area can show significant visual differences in SSS images from different survey lines, causing difficulties in tasks such as pixel correspondence and template matching. In this paper, a canonical transformation method consisting of intensity correction and slant range correction is proposed to decrease the above distortion. The intensity correction includes beam pattern correction and incident angle correction using three different Lambertian laws (cos, cos2, cot), whereas the slant range correction removes the nadir zone and projects the position of SSS elements into equally horizontally spaced, view-point independent bins. The proposed method is evaluated on real data collected by a HUGIN AUV, with manually-annotated pixel correspondence as ground truth reference. Experimental results on patch pairs compare similarity measures and keypoint descriptor matching. The results show that the canonical transformation can improve the patch similarity, as well as SIFT descriptor matching accuracy in different images where the same physical area was ensonified. ",
    "url": "https://arxiv.org/abs/2304.09243",
    "authors": [
      "Weiqi Xu",
      "Li Ling",
      "Yiping Xie",
      "Jun Zhang",
      "John Folkesson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.09245",
    "title": "Early Detection of Parkinson's Disease using Motor Symptoms and Machine  Learning",
    "abstract": "Parkinson's disease (PD) has been found to affect 1 out of every 1000 people, being more inclined towards the population above 60 years. Leveraging wearable-systems to find accurate biomarkers for diagnosis has become the need of the hour, especially for a neurodegenerative condition like Parkinson's. This work aims at focusing on early-occurring, common symptoms, such as motor and gait related parameters to arrive at a quantitative analysis on the feasibility of an economical and a robust wearable device. A subset of the Parkinson's Progression Markers Initiative (PPMI), PPMI Gait dataset has been utilised for feature-selection after a thorough analysis with various Machine Learning algorithms. Identified influential features has then been used to test real-time data for early detection of Parkinson Syndrome, with a model accuracy of 91.9% ",
    "url": "https://arxiv.org/abs/2304.09245",
    "authors": [
      "Poojaa C",
      "John Sahaya Rani Alex"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2304.09246",
    "title": "Real-Time Helmet Violation Detection Using YOLOv5 and Ensemble Learning",
    "abstract": "The proper enforcement of motorcycle helmet regulations is crucial for ensuring the safety of motorbike passengers and riders, as roadway cyclists and passengers are not likely to abide by these regulations if no proper enforcement systems are instituted. This paper presents the development and evaluation of a real-time YOLOv5 Deep Learning (DL) model for detecting riders and passengers on motorbikes, identifying whether the detected person is wearing a helmet. We trained the model on 100 videos recorded at 10 fps, each for 20 seconds. Our study demonstrated the applicability of DL models to accurately detect helmet regulation violators even in challenging lighting and weather conditions. We employed several data augmentation techniques in the study to ensure the training data is diverse enough to help build a robust model. The proposed model was tested on 100 test videos and produced an mAP score of 0.5267, ranking 11th on the AI City Track 5 public leaderboard. The use of deep learning techniques for image classification tasks, such as identifying helmet-wearing riders, has enormous potential for improving road safety. The study shows the potential of deep learning models for application in smart cities and enforcing traffic regulations and can be deployed in real-time for city-wide monitoring. ",
    "url": "https://arxiv.org/abs/2304.09246",
    "authors": [
      "Geoffery Agorku",
      "Divine Agbobli",
      "Vuban Chowdhury",
      "Kwadwo Amankwah-Nkyi",
      "Adedolapo Ogungbire",
      "Portia Ankamah Lartey",
      "Armstrong Aboah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09248",
    "title": "Fine-Tuning YOLOv5 with Genetic Algorithm For Helmet Violation Detection",
    "abstract": "The present study addresses the issue of non-compliance with helmet laws and the potential danger to both motorcycle riders and passengers. Despite the well-established advantages of helmet usage, compliance remains a formidable challenge in many regions of the world, with various factors contributing to the issue. To mitigate this concern, real-time monitoring and enforcement of helmet laws have been advocated as a plausible solution. However, previous attempts at real-time helmet violation detection have been limited by their inability to operate in real-time. To remedy this issue, the current paper proposes a real-time helmet violation detection system utilizing a single-stage object detection model called YOLOv5. The model was trained on the 2023 NVIDIA AI City Challenge Track 5 dataset and employed genetic algorithms in selecting the optimal hyperparameters for training the model. Furthermore, data augmentation techniques such as flip, and rotation were implemented to improve model performance. The efficacy of the model was assessed using mean average precision (mAP). Our developed model achieved an mAP score of 0.5377 on the experimental test data which won 10th place on the public leaderboard. The proposed approach represents a noteworthy breakthrough in the field and holds the potential to significantly improve motorcycle safety. ",
    "url": "https://arxiv.org/abs/2304.09248",
    "authors": [
      "Elham Soltanikazemi",
      "Armstrong Aboah",
      "Elizabeth Arthur",
      "Bijaya Kumar Hatuwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09258",
    "title": "Heterogeneous Integration of In-Memory Analog Computing Architectures  with Tensor Processing Units",
    "abstract": "Tensor processing units (TPUs), specialized hardware accelerators for machine learning tasks, have shown significant performance improvements when executing convolutional layers in convolutional neural networks (CNNs). However, they struggle to maintain the same efficiency in fully connected (FC) layers, leading to suboptimal hardware utilization. In-memory analog computing (IMAC) architectures, on the other hand, have demonstrated notable speedup in executing FC layers. This paper introduces a novel, heterogeneous, mixed-signal, and mixed-precision architecture that integrates an IMAC unit with an edge TPU to enhance mobile CNN performance. To leverage the strengths of TPUs for convolutional layers and IMAC circuits for dense layers, we propose a unified learning algorithm that incorporates mixed-precision training techniques to mitigate potential accuracy drops when deploying models on the TPU-IMAC architecture. The simulations demonstrate that the TPU-IMAC configuration achieves up to $2.59\\times$ performance improvements, and $88\\%$ memory reductions compared to conventional TPU architectures for various CNN models while maintaining comparable accuracy. The TPU-IMAC architecture shows potential for various applications where energy efficiency and high performance are essential, such as edge computing and real-time processing in mobile devices. The unified training algorithm and the integration of IMAC and TPU architectures contribute to the potential impact of this research on the broader machine learning landscape. ",
    "url": "https://arxiv.org/abs/2304.09258",
    "authors": [
      "Mohammed E. Elbtity",
      "Brendan Reidy",
      "Md Hasibul Amin",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09276",
    "title": "A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of  computing and functional programming",
    "abstract": "Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with complex structures, we use the Lambda Calculus ({\\lambda}-Calculus), a simple, but Turing-Complete mathematical formalism, which serves as the basis for modern functional programming languages and is at the heart of computability theory. We will introduce the use of integrated neural learning and lambda calculi formalization. Finally, we explore execution of a program in {\\lambda}-Calculus is based on reductions, we will show that it is enough to learn how to perform these reductions so that we can execute any program. Keywords: Machine Learning, Lambda Calculus, Neurosymbolic AI, Neural Networks, Transformer Model, Sequence-to-Sequence Models, Computational Models ",
    "url": "https://arxiv.org/abs/2304.09276",
    "authors": [
      "Jo\u00e3o Flach",
      "Luis C. Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.09287",
    "title": "Integrity and Junkiness Failure Handling for Embedding-based Retrieval:  A Case Study in Social Network Search",
    "abstract": "Embedding based retrieval has seen its usage in a variety of search applications like e-commerce, social networking search etc. While the approach has demonstrated its efficacy in tasks like semantic matching and contextual search, it is plagued by the problem of uncontrollable relevance. In this paper, we conduct an analysis of embedding-based retrieval launched in early 2021 on our social network search engine, and define two main categories of failures introduced by it, integrity and junkiness. The former refers to issues such as hate speech and offensive content that can severely harm user experience, while the latter includes irrelevant results like fuzzy text matching or language mismatches. Efficient methods during model inference are further proposed to resolve the issue, including indexing treatments and targeted user cohort treatments, etc. Though being simple, we show the methods have good offline NDCG and online A/B tests metrics gain in practice. We analyze the reasons for the improvements, pointing out that our methods are only preliminary attempts to this important but challenging problem. We put forward potential future directions to explore. ",
    "url": "https://arxiv.org/abs/2304.09287",
    "authors": [
      "Wenping Wang",
      "Yunxi Guo",
      "Chiyao Shen",
      "Shuai Ding",
      "Guangdeng Liao",
      "Hao Fu",
      "Pramodh Karanth Prabhakar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09290",
    "title": "Towards Spatio-temporal Sea Surface Temperature Forecasting via Static  and Dynamic Learnable Personalized Graph Convolution Network",
    "abstract": "Sea surface temperature (SST) is uniquely important to the Earth's atmosphere since its dynamics are a major force in shaping local and global climate and profoundly affect our ecosystems. Accurate forecasting of SST brings significant economic and social implications, for example, better preparation for extreme weather such as severe droughts or tropical cyclones months ahead. However, such a task faces unique challenges due to the intrinsic complexity and uncertainty of ocean systems. Recently, deep learning techniques, such as graphical neural networks (GNN), have been applied to address this task. Even though these methods have some success, they frequently have serious drawbacks when it comes to investigating dynamic spatiotemporal dependencies between signals. To solve this problem, this paper proposes a novel static and dynamic learnable personalized graph convolution network (SD-LPGC). Specifically, two graph learning layers are first constructed to respectively model the stable long-term and short-term evolutionary patterns hidden in the multivariate SST signals. Then, a learnable personalized convolution layer is designed to fuse this information. Our experiments on real SST datasets demonstrate the state-of-the-art performances of the proposed approach on the forecasting task. ",
    "url": "https://arxiv.org/abs/2304.09290",
    "authors": [
      "Xiaohan Li",
      "Gaowei Zhang",
      "Kai Huang",
      "Zhaofeng He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2304.09302",
    "title": "CabiNet: Scaling Neural Collision Detection for Object Rearrangement  with Procedural Scene Generation",
    "abstract": "We address the important problem of generalizing robotic rearrangement to clutter without any explicit object models. We first generate over 650K cluttered scenes - orders of magnitude more than prior work - in diverse everyday environments, such as cabinets and shelves. We render synthetic partial point clouds from this data and use it to train our CabiNet model architecture. CabiNet is a collision model that accepts object and scene point clouds, captured from a single-view depth observation, and predicts collisions for SE(3) object poses in the scene. Our representation has a fast inference speed of 7 microseconds per query with nearly 20% higher performance than baseline approaches in challenging environments. We use this collision model in conjunction with a Model Predictive Path Integral (MPPI) planner to generate collision-free trajectories for picking and placing in clutter. CabiNet also predicts waypoints, computed from the scene's signed distance field (SDF), that allows the robot to navigate tight spaces during rearrangement. This improves rearrangement performance by nearly 35% compared to baselines. We systematically evaluate our approach, procedurally generate simulated experiments, and demonstrate that our approach directly transfers to the real world, despite training exclusively in simulation. Robot experiment demos in completely unknown scenes and objects can be found at this http https://cabinet-object-rearrangement.github.io ",
    "url": "https://arxiv.org/abs/2304.09302",
    "authors": [
      "Adithyavairavan Murali",
      "Arsalan Mousavian",
      "Clemens Eppner",
      "Adam Fishman",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09313",
    "title": "Application of genetic algorithm to load balancing in networks with a  homogeneous traffic flow",
    "abstract": "The concept of extended cloud requires efficient network infrastructure to support ecosystems reaching form the edge to the cloud(s). Standard approaches to network load balancing deliver static solutions that are insufficient for the extended clouds, where network loads change often. To address this issue, a genetic algorithm based load optimizer is proposed and implemented. Next, its performance is experimentally evaluated and it is shown that it outperforms other existing solutions. ",
    "url": "https://arxiv.org/abs/2304.09313",
    "authors": [
      "Marek Bolanowski",
      "Alicja Gerka",
      "Andrzej Paszkiewicz",
      "Maria Ganzha",
      "Marcin Paprzycki"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.09344",
    "title": "BioThings Explorer: a query engine for a federated knowledge graph of  biomedical APIs",
    "abstract": "Knowledge graphs are an increasingly common data structure for representing biomedical information. These knowledge graphs can easily represent heterogeneous types of information, and many algorithms and tools exist for querying and analyzing graphs. Biomedical knowledge graphs have been used in a variety of applications, including drug repurposing, identification of drug targets, prediction of drug side effects, and clinical decision support. Typically, knowledge graphs are constructed by centralization and integration of data from multiple disparate sources. Here, we describe BioThings Explorer, an application that can query a virtual, federated knowledge graph derived from the aggregated information in a network of biomedical web services. BioThings Explorer leverages semantically precise annotations of the inputs and outputs for each resource, and automates the chaining of web service calls to execute multi-step graph queries. Because there is no large, centralized knowledge graph to maintain, BioThing Explorer is distributed as a lightweight application that dynamically retrieves information at query time. More information can be found at https://explorer.biothings.io, and code is available at https://github.com/biothings/biothings_explorer. ",
    "url": "https://arxiv.org/abs/2304.09344",
    "authors": [
      "Jackson Callaghan",
      "Colleen H. Xu",
      "Jiwen Xin",
      "Marco Alvarado Cano",
      "Anders Riutta",
      "Eric Zhou",
      "Rohan Juneja",
      "Yao Yao",
      "Madhumita Narayan",
      "Kristina Hanspers",
      "Ayushi Agrawal",
      "Alexander R. Pico",
      "Chunlei Wu",
      "Andrew I. Su"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2304.09351",
    "title": "Machine Vision System for Early-stage Apple Flowers and Flower Clusters  Detection for Precision Thinning and Pollination",
    "abstract": "Early-stage identification of fruit flowers that are in both opened and unopened condition in an orchard environment is significant information to perform crop load management operations such as flower thinning and pollination using automated and robotic platforms. These operations are important in tree-fruit agriculture to enhance fruit quality, manage crop load, and enhance the overall profit. The recent development in agricultural automation suggests that this can be done using robotics which includes machine vision technology. In this article, we proposed a vision system that detects early-stage flowers in an unstructured orchard environment using YOLOv5 object detection algorithm. For the robotics implementation, the position of a cluster of the flower blossom is important to navigate the robot and the end effector. The centroid of individual flowers (both open and unopen) was identified and associated with flower clusters via K-means clustering. The accuracy of the opened and unopened flower detection is achieved up to mAP of 81.9% in commercial orchard images. ",
    "url": "https://arxiv.org/abs/2304.09351",
    "authors": [
      "Salik Ram Khanal",
      "Ranjan Sapkota",
      "Dawood Ahmed",
      "Uddhav Bhattarai",
      "Manoj Karkee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09355",
    "title": "To Compress or Not to Compress -- Self-Supervised Learning and  Information Theory: A Review",
    "abstract": "Deep neural networks have demonstrated remarkable performance in supervised learning tasks but require large amounts of labeled data. Self-supervised learning offers an alternative paradigm, enabling the model to learn from data without explicit labels. Information theory has been instrumental in understanding and optimizing deep neural networks. Specifically, the information bottleneck principle has been applied to optimize the trade-off between compression and relevant information preservation in supervised settings. However, the optimal information objective in self-supervised learning remains unclear. In this paper, we review various approaches to self-supervised learning from an information-theoretic standpoint and present a unified framework that formalizes the \\textit{self-supervised information-theoretic learning problem}. We integrate existing research into a coherent framework, examine recent self-supervised methods, and identify research opportunities and challenges. Moreover, we discuss empirical measurement of information-theoretic quantities and their estimators. This paper offers a comprehensive review of the intersection between information theory, self-supervised learning, and deep neural networks. ",
    "url": "https://arxiv.org/abs/2304.09355",
    "authors": [
      "Ravid Shwartz-Ziv",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.09358",
    "title": "Investigating the Nature of 3D Generalization in Deep Neural Networks",
    "abstract": "Visual object recognition systems need to generalize from a set of 2D training views to novel views. The question of how the human visual system can generalize to novel views has been studied and modeled in psychology, computer vision, and neuroscience. Modern deep learning architectures for object recognition generalize well to novel views, but the mechanisms are not well understood. In this paper, we characterize the ability of common deep learning architectures to generalize to novel views. We formulate this as a supervised classification task where labels correspond to unique 3D objects and examples correspond to 2D views of the objects at different 3D orientations. We consider three common models of generalization to novel views: (i) full 3D generalization, (ii) pure 2D matching, and (iii) matching based on a linear combination of views. We find that deep models generalize well to novel views, but they do so in a way that differs from all these existing models. Extrapolation to views beyond the range covered by views in the training set is limited, and extrapolation to novel rotation axes is even more limited, implying that the networks do not infer full 3D structure, nor use linear interpolation. Yet, generalization is far superior to pure 2D matching. These findings help with designing datasets with 2D views required to achieve 3D generalization. Code to reproduce our experiments is publicly available: https://github.com/shoaibahmed/investigating_3d_generalization.git ",
    "url": "https://arxiv.org/abs/2304.09358",
    "authors": [
      "Shoaib Ahmed Siddiqui",
      "David Krueger",
      "Thomas Breuel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09367",
    "title": "Graph Neural Network-Based Anomaly Detection for River Network Systems",
    "abstract": "Water is the lifeblood of river networks, and its quality plays a crucial role in sustaining both aquatic ecosystems and human societies. Real-time monitoring of water quality is increasingly reliant on in-situ sensor technology. Anomaly detection is crucial for identifying erroneous patterns in sensor data, but can be a challenging task due to the complexity and variability of the data, even under normal conditions. This paper presents a solution to the challenging task of anomaly detection for river network sensor data, which is essential for the accurate and continuous monitoring of water quality. We use a graph neural network model, the recently proposed Graph Deviation Network (GDN), which employs graph attention-based forecasting to capture the complex spatio-temporal relationships between sensors. We propose an alternate anomaly threshold criteria for the model, GDN+, based on the learned graph. To evaluate the model's efficacy, we introduce new benchmarking simulation experiments with highly-sophisticated dependency structures and subsequence anomalies of various types. We further examine the strengths and weaknesses of this baseline approach, GDN, in comparison to other benchmarking methods on complex real-world river network data. Findings suggest that GDN+ outperforms the baseline approach in high-dimensional data, while also providing improved interpretability. We also introduce software called gnnad. ",
    "url": "https://arxiv.org/abs/2304.09367",
    "authors": [
      "Katie Buchhorn",
      "Edgar Santos-Fernandez",
      "Kerrie Mengersen",
      "Robert Salomone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2304.09376",
    "title": "Physical Knowledge Enhanced Deep Neural Network for Sea Surface  Temperature Prediction",
    "abstract": "Traditionally, numerical models have been deployed in oceanography studies to simulate ocean dynamics by representing physical equations. However, many factors pertaining to ocean dynamics seem to be ill-defined. We argue that transferring physical knowledge from observed data could further improve the accuracy of numerical models when predicting Sea Surface Temperature (SST). Recently, the advances in earth observation technologies have yielded a monumental growth of data. Consequently, it is imperative to explore ways in which to improve and supplement numerical models utilizing the ever-increasing amounts of historical observational data. To this end, we introduce a method for SST prediction that transfers physical knowledge from historical observations to numerical models. Specifically, we use a combination of an encoder and a generative adversarial network (GAN) to capture physical knowledge from the observed data. The numerical model data is then fed into the pre-trained model to generate physics-enhanced data, which can then be used for SST prediction. Experimental results demonstrate that the proposed method considerably enhances SST prediction performance when compared to several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2304.09376",
    "authors": [
      "Yuxin Meng",
      "Feng Gao",
      "Eric Rigall",
      "Ran Dong",
      "Junyu Dong",
      "Qian Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.09384",
    "title": "SP-BatikGAN: An Efficient Generative Adversarial Network for Symmetric  Pattern Generation",
    "abstract": "Following the contention of AI arts, our research focuses on bringing AI for all, particularly for artists, to create AI arts with limited data and settings. We are interested in geometrically symmetric pattern generation, which appears on many artworks such as Portuguese, Moroccan tiles, and Batik, a cultural heritage in Southeast Asia. Symmetric pattern generation is a complex problem, with prior research creating too-specific models for certain patterns only. We provide publicly, the first-ever 1,216 high-quality symmetric patterns straight from design files for this task. We then formulate symmetric pattern enforcement (SPE) loss to leverage underlying symmetric-based structures that exist on current image distributions. Our SPE improves and accelerates training on any GAN configuration, and, with efficient attention, SP-BatikGAN compared to FastGAN, the state-of-the-art GAN for limited setting, improves the FID score from 110.11 to 90.76, an 18% decrease, and model diversity recall score from 0.047 to 0.204, a 334% increase. ",
    "url": "https://arxiv.org/abs/2304.09384",
    "authors": [
      "Chrystian",
      "Wahyono"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.09388",
    "title": "An Empirical Study of Leveraging Knowledge Distillation for Compressing  Multilingual Neural Machine Translation Models",
    "abstract": "Knowledge distillation (KD) is a well-known method for compressing neural models. However, works focusing on distilling knowledge from large multilingual neural machine translation (MNMT) models into smaller ones are practically nonexistent, despite the popularity and superiority of MNMT. This paper bridges this gap by presenting an empirical investigation of knowledge distillation for compressing MNMT models. We take Indic to English translation as a case study and demonstrate that commonly used language-agnostic and language-aware KD approaches yield models that are 4-5x smaller but also suffer from performance drops of up to 3.5 BLEU. To mitigate this, we then experiment with design considerations such as shallower versus deeper models, heavy parameter sharing, multi-stage training, and adapters. We observe that deeper compact models tend to be as good as shallower non-compact ones, and that fine-tuning a distilled model on a High-Quality subset slightly boosts translation quality. Overall, we conclude that compressing MNMT models via KD is challenging, indicating immense scope for further research. ",
    "url": "https://arxiv.org/abs/2304.09388",
    "authors": [
      "Varun Gumma",
      "Raj Dabre",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09391",
    "title": "Inferring High-level Geographical Concepts via Knowledge Graph and  Multi-scale Data Integration: A Case Study of C-shaped Building Pattern  Recognition",
    "abstract": "Effective building pattern recognition is critical for understanding urban form, automating map generalization, and visualizing 3D city models. Most existing studies use object-independent methods based on visual perception rules and proximity graph models to extract patterns. However, because human vision is a part-based system, pattern recognition may require decomposing shapes into parts or grouping them into clusters. Existing methods may not recognize all visually aware patterns, and the proximity graph model can be inefficient. To improve efficiency and effectiveness, we integrate multi-scale data using a knowledge graph, focusing on the recognition of C-shaped building patterns. First, we use a property graph to represent the relationships between buildings within and across different scales involved in C-shaped building pattern recognition. Next, we store this knowledge graph in a graph database and convert the rules for C-shaped pattern recognition and enrichment into query conditions. Finally, we recognize and enrich C-shaped building patterns using rule-based reasoning in the built knowledge graph. We verify the effectiveness of our method using multi-scale data with three levels of detail (LODs) collected from the Gaode Map. Our results show that our method achieves a higher recall rate of 26.4% for LOD1, 20.0% for LOD2, and 9.1% for LOD3 compared to existing approaches. We also achieve recognition efficiency improvements of 0.91, 1.37, and 9.35 times, respectively. ",
    "url": "https://arxiv.org/abs/2304.09391",
    "authors": [
      "Zhiwei Wei",
      "Yi Xiao",
      "Wenjia Xu",
      "Mi Shu",
      "Lu Cheng",
      "Yang Wang",
      "Chunbo Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09402",
    "title": "MixPro: Simple yet Effective Data Augmentation for Prompt-based Learning",
    "abstract": "Prompt-based learning reformulates downstream tasks as cloze problems by combining the original input with a template. This technique is particularly useful in few-shot learning, where a model is trained on a limited amount of data. However, the limited templates and text used in few-shot prompt-based learning still leave significant room for performance improvement. Additionally, existing methods using model ensembles can constrain the model efficiency. To address these issues, we propose an augmentation method called MixPro, which augments both the vanilla input text and the templates through token-level, sentence-level, and epoch-level Mixup strategies. We conduct experiments on five few-shot datasets, and the results show that MixPro outperforms other augmentation baselines, improving model performance by an average of 5.08% compared to before augmentation. ",
    "url": "https://arxiv.org/abs/2304.09402",
    "authors": [
      "Bohan Li",
      "Longxu Dou",
      "Yutai Hou",
      "Yunlong Feng",
      "Honglin Mu",
      "Wanxiang Che"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09403",
    "title": "Wavelets Beat Monkeys at Adversarial Robustness",
    "abstract": "Research on improving the robustness of neural networks to adversarial noise - imperceptible malicious perturbations of the data - has received significant attention. The currently uncontested state-of-the-art defense to obtain robust deep neural networks is Adversarial Training (AT), but it consumes significantly more resources compared to standard training and trades off accuracy for robustness. An inspiring recent work [Dapello et al.] aims to bring neurobiological tools to the question: How can we develop Neural Nets that robustly generalize like human vision? [Dapello et al.] design a network structure with a neural hidden first layer that mimics the primate primary visual cortex (V1), followed by a back-end structure adapted from current CNN vision models. It seems to achieve non-trivial adversarial robustness on standard vision benchmarks when tested on small perturbations. Here we revisit this biologically inspired work, and ask whether a principled parameter-free representation with inspiration from physics is able to achieve the same goal. We discover that the wavelet scattering transform can replace the complex V1-cortex and simple uniform Gaussian noise can take the role of neural stochasticity, to achieve adversarial robustness. In extensive experiments on the CIFAR-10 benchmark with adaptive adversarial attacks we show that: 1) Robustness of VOneBlock architectures is relatively weak (though non-zero) when the strength of the adversarial attack radius is set to commonly used benchmarks. 2) Replacing the front-end VOneBlock by an off-the-shelf parameter-free Scatternet followed by simple uniform Gaussian noise can achieve much more substantial adversarial robustness without adversarial training. Our work shows how physically inspired structures yield new insights into robustness that were previously only thought possible by meticulously mimicking the human cortex. ",
    "url": "https://arxiv.org/abs/2304.09403",
    "authors": [
      "Jingtong Su",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09406",
    "title": "How to Do Things with Deep Learning Code",
    "abstract": "The premise of this article is that a basic understanding of the composition and functioning of large language models is critically urgent. To that end, we extract a representational map of OpenAI's GPT-2 with what we articulate as two classes of deep learning code, that which pertains to the model and that which underwrites applications built around the model. We then verify this map through case studies of two popular GPT-2 applications: the text adventure game, AI Dungeon, and the language art project, This Word Does Not Exist. Such an exercise allows us to test the potential of Critical Code Studies when the object of study is deep learning code and to demonstrate the validity of code as an analytical focus for researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies. More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems, and by extension works toward demystifying some of the auratic mystery of \"AI.\" What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities-indeed, understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems. ",
    "url": "https://arxiv.org/abs/2304.09406",
    "authors": [
      "Minh Hua",
      "Rita Raley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.09414",
    "title": "On the Effectiveness of Image Manipulation Detection in the Age of  Social Media",
    "abstract": "Image manipulation detection algorithms designed to identify local anomalies often rely on the manipulated regions being ``sufficiently'' different from the rest of the non-tampered regions in the image. However, such anomalies might not be easily identifiable in high-quality manipulations, and their use is often based on the assumption that certain image phenomena are associated with the use of specific editing tools. This makes the task of manipulation detection hard in and of itself, with state-of-the-art detectors only being able to detect a limited number of manipulation types. More importantly, in cases where the anomaly assumption does not hold, the detection of false positives in otherwise non-manipulated images becomes a serious problem. To understand the current state of manipulation detection, we present an in-depth analysis of deep learning-based and learning-free methods, assessing their performance on different benchmark datasets containing tampered and non-tampered samples. We provide a comprehensive study of their suitability for detecting different manipulations as well as their robustness when presented with non-tampered data. Furthermore, we propose a novel deep learning-based pre-processing technique that accentuates the anomalies present in manipulated regions to make them more identifiable by a variety of manipulation detection methods. To this end, we introduce an anomaly enhancement loss that, when used with a residual architecture, improves the performance of different detection algorithms with a minimal introduction of false positives on the non-manipulated data. Lastly, we introduce an open-source manipulation detection toolkit comprising a number of standard detection algorithms. ",
    "url": "https://arxiv.org/abs/2304.09414",
    "authors": [
      "Rosaura G. VidalMata",
      "Priscila Saboia",
      "Daniel Moreira",
      "Grant Jensen",
      "Jason Schlessman",
      "Walter J. Scheirer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09421",
    "title": "TieFake: Title-Text Similarity and Emotion-Aware Fake News Detection",
    "abstract": "Fake news detection aims to detect fake news widely spreading on social media platforms, which can negatively influence the public and the government. Many approaches have been developed to exploit relevant information from news images, text, or videos. However, these methods may suffer from the following limitations: (1) ignore the inherent emotional information of the news, which could be beneficial since it contains the subjective intentions of the authors; (2) pay little attention to the relation (similarity) between the title and textual information in news articles, which often use irrelevant title to attract reader' attention. To this end, we propose a novel Title-Text similarity and emotion-aware Fake news detection (TieFake) method by jointly modeling the multi-modal context information and the author sentiment in a unified framework. Specifically, we respectively employ BERT and ResNeSt to learn the representations for text and images, and utilize publisher emotion extractor to capture the author's subjective emotion in the news content. We also propose a scale-dot product attention mechanism to capture the similarity between title features and textual features. Experiments are conducted on two publicly available multi-modal datasets, and the results demonstrate that our proposed method can significantly improve the performance of fake news detection. Our code is available at https://github.com/UESTC-GQJ/TieFake. ",
    "url": "https://arxiv.org/abs/2304.09421",
    "authors": [
      "Quanjiang Guo",
      "Zhao Kang",
      "Ling Tian",
      "Zhouguo Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.09424",
    "title": "Loss minimization yields multicalibration for large neural networks",
    "abstract": "Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as \"fairness comes for free from optimizing neural networks\". ",
    "url": "https://arxiv.org/abs/2304.09424",
    "authors": [
      "Jaros\u0142aw B\u0142asiok",
      "Parikshit Gopalan",
      "Lunjia Hu",
      "Adam Tauman Kalai",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09431",
    "title": "Martingale Posterior Neural Processes",
    "abstract": "A Neural Process (NP) estimates a stochastic process implicitly defined with neural networks given a stream of data, rather than pre-specifying priors already known, such as Gaussian processes. An ideal NP would learn everything from data without any inductive biases, but in practice, we often restrict the class of stochastic processes for the ease of estimation. One such restriction is the use of a finite-dimensional latent variable accounting for the uncertainty in the functions drawn from NPs. Some recent works show that this can be improved with more \"data-driven\" source of uncertainty such as bootstrapping. In this work, we take a different approach based on the martingale posterior, a recently developed alternative to Bayesian inference. For the martingale posterior, instead of specifying prior-likelihood pairs, a predictive distribution for future data is specified. Under specific conditions on the predictive distribution, it can be shown that the uncertainty in the generated future data actually corresponds to the uncertainty of the implicitly defined Bayesian posteriors. Based on this result, instead of assuming any form of the latent variables, we equip a NP with a predictive distribution implicitly defined with neural networks and use the corresponding martingale posteriors as the source of uncertainty. The resulting model, which we name as Martingale Posterior Neural Process (MPNP), is demonstrated to outperform baselines on various tasks. ",
    "url": "https://arxiv.org/abs/2304.09431",
    "authors": [
      "Hyungi Lee",
      "Eunggu Yun",
      "Giung Nam",
      "Edwin Fong",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09433",
    "title": "Language Models Enable Simple Systems for Generating Structured Views of  Heterogeneous Data Lakes",
    "abstract": "A long standing goal of the data management community is to develop general, automated systems that ingest semi-structured documents and output queryable tables without human effort or domain specific customization. Given the sheer variety of potential documents, state-of-the art systems make simplifying assumptions and use domain specific training. In this work, we ask whether we can maintain generality by using large language models (LLMs). LLMs, which are pretrained on broad data, can perform diverse downstream tasks simply conditioned on natural language task descriptions. We propose and evaluate EVAPORATE, a simple, prototype system powered by LLMs. We identify two fundamentally different strategies for implementing this system: prompt the LLM to directly extract values from documents or prompt the LLM to synthesize code that performs the extraction. Our evaluations show a cost-quality tradeoff between these two approaches. Code synthesis is cheap, but far less accurate than directly processing each document with the LLM. To improve quality while maintaining low cost, we propose an extended code synthesis implementation, EVAPORATE-CODE+, which achieves better quality than direct extraction. Our key insight is to generate many candidate functions and ensemble their extractions using weak supervision. EVAPORATE-CODE+ not only outperforms the state-of-the art systems, but does so using a sublinear pass over the documents with the LLM. This equates to a 110x reduction in the number of tokens the LLM needs to process, averaged across 16 real-world evaluation settings of 10k documents each. ",
    "url": "https://arxiv.org/abs/2304.09433",
    "authors": [
      "Simran Arora",
      "Brandon Yang",
      "Sabri Eyuboglu",
      "Avanika Narayan",
      "Andrew Hojel",
      "Immanuel Trummer",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.09439",
    "title": "Local object crop collision network for efficient simulation of  non-convex objects in GPU-based simulators",
    "abstract": "Our goal is to develop an efficient contact detection algorithm for large-scale GPU-based simulation of non-convex objects. Current GPU-based simulators such as IsaacGym and Brax must trade-off speed with fidelity, generality, or both when simulating non-convex objects. Their main issue lies in contact detection (CD): existing CD algorithms, such as Gilbert-Johnson-Keerthi (GJK), must trade off their computational speed with accuracy which becomes expensive as the number of collisions among non-convex objects increases. We propose a data-driven approach for CD, whose accuracy depends only on the quality and quantity of offline dataset rather than online computation time. Unlike GJK, our method inherently has a uniform computational flow, which facilitates efficient GPU usage based on advanced compilers such as XLA (Accelerated Linear Algebra). Further, we offer a data-efficient solution by learning the patterns of colliding local crop object shapes, rather than global object shapes which are harder to learn. We demonstrate our approach improves the efficiency of existing CD methods by a factor of 5-10 for non-convex objects with comparable accuracy. Using the previous work on contact resolution for a neural-network-based contact detector, we integrate our CD algorithm into the open-source GPU-based simulator, Brax, and show that we can improve the efficiency over IsaacGym and generality over standard Brax. We highly recommend the videos of our simulator included in the supplementary materials. ",
    "url": "https://arxiv.org/abs/2304.09439",
    "authors": [
      "Dongwon Son",
      "Beomjoon Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09444",
    "title": "Rank-Based Learning and Local Model Based Evolutionary Algorithm for  High-Dimensional Expensive Multi-Objective Problems",
    "abstract": "Surrogate-assisted evolutionary algorithms have been widely developed to solve complex and computationally expensive multi-objective optimization problems in recent years. However, when dealing with high-dimensional optimization problems, the performance of these surrogate-assisted multi-objective evolutionary algorithms deteriorate drastically. In this work, a novel Classifier-assisted rank-based learning and Local Model based multi-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional expensive multi-objective optimization problems. The proposed algorithm consists of three parts: classifier-assisted rank-based learning, hypervolume-based non-dominated search, and local search in the relatively sparse objective space. Specifically, a probabilistic neural network is built as classifier to divide the offspring into a number of ranks. The offspring in different ranks uses rank-based learning strategy to generate more promising and informative candidates for real function evaluations. Then, radial basis function networks are built as surrogates to approximate the objective functions. After searching non-dominated solutions assisted by the surrogate model, the candidates with higher hypervolume improvement are selected for real evaluations. Subsequently, in order to maintain the diversity of solutions, the most uncertain sample point from the non-dominated solutions measured by the crowding distance is selected as the guided parent to further infill in the uncertain region of the front. The experimental results of benchmark problems and a real-world application on geothermal reservoir heat extraction optimization demonstrate that the proposed algorithm shows superior performance compared with the state-of-the-art surrogate-assisted multi-objective evolutionary algorithms. The source code for this work is available at https://github.com/JellyChen7/CLMEA. ",
    "url": "https://arxiv.org/abs/2304.09444",
    "authors": [
      "Guodong Chen",
      "Jiu Jimmy Jiao",
      "Xiaoming Xue",
      "Xin Luo",
      "Zhongzheng Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09446",
    "title": "Density-Insensitive Unsupervised Domain Adaption on 3D Object Detection",
    "abstract": "3D object detection from point clouds is crucial in safety-critical autonomous driving. Although many works have made great efforts and achieved significant progress on this task, most of them suffer from expensive annotation cost and poor transferability to unknown data due to the domain gap. Recently, few works attempt to tackle the domain gap in objects, but still fail to adapt to the gap of varying beam-densities between two domains, which is critical to mitigate the characteristic differences of the LiDAR collectors. To this end, we make the attempt to propose a density-insensitive domain adaption framework to address the density-induced domain gap. In particular, we first introduce Random Beam Re-Sampling (RBRS) to enhance the robustness of 3D detectors trained on the source domain to the varying beam-density. Then, we take this pre-trained detector as the backbone model, and feed the unlabeled target domain data into our newly designed task-specific teacher-student framework for predicting its high-quality pseudo labels. To further adapt the property of density-insensitivity into the target domain, we feed the teacher and student branches with the same sample of different densities, and propose an Object Graph Alignment (OGA) module to construct two object-graphs between the two branches for enforcing the consistency in both the attribute and relation of cross-density objects. Experimental results on three widely adopted 3D object detection datasets demonstrate that our proposed domain adaption method outperforms the state-of-the-art methods, especially over varying-density data. Code is available at https://github.com/WoodwindHu/DTS}{https://github.com/WoodwindHu/DTS. ",
    "url": "https://arxiv.org/abs/2304.09446",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09453",
    "title": "Network Pruning Spaces",
    "abstract": "Network pruning techniques, including weight pruning and filter pruning, reveal that most state-of-the-art neural networks can be accelerated without a significant performance drop. This work focuses on filter pruning which enables accelerated inference with any off-the-shelf deep learning library and hardware. We propose the concept of \\emph{network pruning spaces} that parametrize populations of subnetwork architectures. Based on this concept, we explore the structure aspect of subnetworks that result in minimal loss of accuracy in different pruning regimes and arrive at a series of observations by comparing subnetwork distributions. We conjecture through empirical studies that there exists an optimal FLOPs-to-parameter-bucket ratio related to the design of original network in a pruning regime. Statistically, the structure of a winning subnetwork guarantees an approximately optimal ratio in this regime. Upon our conjectures, we further refine the initial pruning space to reduce the cost of searching a good subnetwork architecture. Our experimental results on ImageNet show that the subnetwork we found is superior to those from the state-of-the-art pruning methods under comparable FLOPs. ",
    "url": "https://arxiv.org/abs/2304.09453",
    "authors": [
      "Xuanyu He",
      "Yu-I Yang",
      "Ran Song",
      "Jiachen Pu",
      "Conggang Hu",
      "Feijun Jiang",
      "Wei Zhang",
      "Huanghao Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09462",
    "title": "Decentralized Multi-Agent Planning for Multirotors:a Fully online and  Communication Latency Robust Approach",
    "abstract": "There are many industrial, commercial and social applications for multi-agent planning for multirotors such as autonomous agriculture, infrastructure inspection and search and rescue. Thus, improving on the state-of-the-art of multi-agent planning to make it a viable real-world solution is of great benefit. In this work, we propose a new method for multi-agent planning in a static environment that improves our previous work by making it fully online as well as robust to communication latency. The proposed framework generates a global path and a Safe Corridor to avoid static obstacles in an online fashion (generated offline in our previous work). It then generates a time-aware Safe Corridor which takes into account the future positions of other agents to avoid intra-agent collisions. The time-aware Safe Corridor is given with a local reference trajectory to an MIQP (Mixed-Integer Quadratic Problem)/MPC (Model Predictive Control) solver that outputs a safe and optimal trajectory. The planning frequency is adapted to account for communication delays. The proposed method is fully online, real-time, decentralized, and synchronous. It is compared to 3 recent state-of-the-art methods in simulations. It outperforms all methods in robustness and safety as well as flight time. It also outperforms the only other state-of-the-art latency robust method in computation time. ",
    "url": "https://arxiv.org/abs/2304.09462",
    "authors": [
      "Charbel Toumieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.09469",
    "title": "Baybayin Character Instance Detection",
    "abstract": "The Philippine Government recently passed the \"National Writing System Act,\" which promotes using Baybayin in Philippine texts. In support of this effort to promote the use of Baybayin, we present a computer vision system which can aid individuals who cannot easily read Baybayin script. In this paper, we survey the existing methods of identifying Baybayin scripts using computer vision and machine learning techniques and discuss their capabilities and limitations. Further, we propose a Baybayin Optical Character Instance Segmentation and Classification model using state-of-the-art Convolutional Neural Networks (CNNs) that detect Baybayin character instances in an image then outputs the Latin alphabet counterparts of each character instance in the image. Most existing systems are limited to character-level image classification and often misclassify or not natively support characters with diacritics. In addition, these existing models often have specific input requirements that limit it to classifying Baybayin text in a controlled setting, such as limitations in clarity and contrast, among others. To our knowledge, our proposed method is the first end-to-end character instance detection model for Baybayin, achieving a mAP50 score of 93.30%, mAP50-95 score of 80.50%, and F1-Score of 84.84%. ",
    "url": "https://arxiv.org/abs/2304.09469",
    "authors": [
      "Adriel Isaiah V. Amoguis",
      "Gian Joseph B. Madrid",
      "Benito Miguel D. Flores IV",
      "Macario O. Cordel II"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09477",
    "title": "Towards Co-Creative Generative Adversarial Networks for Fashion  Designers",
    "abstract": "Originating from the premise that Generative Adversarial Networks (GANs) enrich creative processes rather than diluting them, we describe an ongoing PhD project that proposes to study GANs in a co-creative context. By asking How can GANs be applied in co-creation, and in doing so, how can they contribute to fashion design processes? the project sets out to investigate co-creative GAN applications and further develop them for the specific application area of fashion design. We do so by drawing on the field of mixed-initiative co-creation. Combined with the technical insight into GANs' functioning, we aim to understand how their algorithmic properties translate into interactive interfaces for co-creation and propose new interactions. ",
    "url": "https://arxiv.org/abs/2304.09477",
    "authors": [
      "Imke Grabe",
      "Jichen Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.09486",
    "title": "Security and Privacy Problems in Voice Assistant Applications: A Survey",
    "abstract": "Voice assistant applications have become omniscient nowadays. Two models that provide the two most important functions for real-life applications (i.e., Google Home, Amazon Alexa, Siri, etc.) are Automatic Speech Recognition (ASR) models and Speaker Identification (SI) models. According to recent studies, security and privacy threats have also emerged with the rapid development of the Internet of Things (IoT). The security issues researched include attack techniques toward machine learning models and other hardware components widely used in voice assistant applications. The privacy issues include technical-wise information stealing and policy-wise privacy breaches. The voice assistant application takes a steadily growing market share every year, but their privacy and security issues never stopped causing huge economic losses and endangering users' personal sensitive information. Thus, it is important to have a comprehensive survey to outline the categorization of the current research regarding the security and privacy problems of voice assistant applications. This paper concludes and assesses five kinds of security attacks and three types of privacy threats in the papers published in the top-tier conferences of cyber security and voice domain. ",
    "url": "https://arxiv.org/abs/2304.09486",
    "authors": [
      "Jingjin Li",
      "Chao chen",
      "Lei Pan",
      "Mostafa Rahimi Azghadi",
      "Hossein Ghodosi",
      "Jun Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.09490",
    "title": "Neural Network Quantisation for Faster Homomorphic Encryption",
    "abstract": "Homomorphic encryption (HE) enables calculating on encrypted data, which makes it possible to perform privacypreserving neural network inference. One disadvantage of this technique is that it is several orders of magnitudes slower than calculation on unencrypted data. Neural networks are commonly trained using floating-point, while most homomorphic encryption libraries calculate on integers, thus requiring a quantisation of the neural network. A straightforward approach would be to quantise to large integer sizes (e.g. 32 bit) to avoid large quantisation errors. In this work, we reduce the integer sizes of the networks, using quantisation-aware training, to allow more efficient computations. For the targeted MNIST architecture proposed by Badawi et al., we reduce the integer sizes by 33% without significant loss of accuracy, while for the CIFAR architecture, we can reduce the integer sizes by 43%. Implementing the resulting networks under the BFV homomorphic encryption scheme using SEAL, we could reduce the execution time of an MNIST neural network by 80% and by 40% for a CIFAR neural network. ",
    "url": "https://arxiv.org/abs/2304.09490",
    "authors": [
      "Wouter Legiest",
      "Jan-Pieter D'Anvers",
      "Furkan Turan",
      "Michiel Van Beirendonck",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.09493",
    "title": "Emotion fusion for mental illness detection from social media: A survey",
    "abstract": "Mental illnesses are one of the most prevalent public health problems worldwide, which negatively influence people's lives and society's health. With the increasing popularity of social media, there has been a growing research interest in the early detection of mental illness by analysing user-generated posts on social media. According to the correlation between emotions and mental illness, leveraging and fusing emotion information has developed into a valuable research topic. In this article, we provide a comprehensive survey of approaches to mental illness detection in social media that incorporate emotion fusion. We begin by reviewing different fusion strategies, along with their advantages and disadvantages. Subsequently, we discuss the major challenges faced by researchers working in this area, including issues surrounding the availability and quality of datasets, the performance of algorithms and interpretability. We additionally suggest some potential directions for future research. ",
    "url": "https://arxiv.org/abs/2304.09493",
    "authors": [
      "Tianlin Zhang",
      "Kailai Yang",
      "Shaoxiong Ji",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09498",
    "title": "Learning Robust Visual-Semantic Embedding for Generalizable Person  Re-identification",
    "abstract": "Generalizable person re-identification (Re-ID) is a very hot research topic in machine learning and computer vision, which plays a significant role in realistic scenarios due to its various applications in public security and video surveillance. However, previous methods mainly focus on the visual representation learning, while neglect to explore the potential of semantic features during training, which easily leads to poor generalization capability when adapted to the new domain. In this paper, we propose a Multi-Modal Equivalent Transformer called MMET for more robust visual-semantic embedding learning on visual, textual and visual-textual tasks respectively. To further enhance the robust feature learning in the context of transformer, a dynamic masking mechanism called Masked Multimodal Modeling strategy (MMM) is introduced to mask both the image patches and the text tokens, which can jointly works on multimodal or unimodal data and significantly boost the performance of generalizable person Re-ID. Extensive experiments on benchmark datasets demonstrate the competitive performance of our method over previous approaches. We hope this method could advance the research towards visual-semantic representation learning. Our source code is also publicly available at https://github.com/JeremyXSC/MMET. ",
    "url": "https://arxiv.org/abs/2304.09498",
    "authors": [
      "Suncheng Xiang",
      "Jingsheng Gao",
      "Mengyuan Guan",
      "Jiacheng Ruan",
      "Chengfeng Zhou",
      "Ting Liu",
      "Dahong Qian",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09499",
    "title": "The Responsibility Problem in Neural Networks with Unordered Targets",
    "abstract": "We discuss the discontinuities that arise when mapping unordered objects to neural network outputs of fixed permutation, referred to as the responsibility problem. Prior work has proved the existence of the issue by identifying a single discontinuity. Here, we show that discontinuities under such models are uncountably infinite, motivating further research into neural networks for unordered data. ",
    "url": "https://arxiv.org/abs/2304.09499",
    "authors": [
      "Ben Hayes",
      "Charalampos Saitis",
      "Gy\u00f6rgy Fazekas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.09500",
    "title": "Biologically inspired structure learning with reverse knowledge  distillation for spiking neural networks",
    "abstract": "Spiking neural networks (SNNs) have superb characteristics in sensory information recognition tasks due to their biological plausibility. However, the performance of some current spiking-based models is limited by their structures which means either fully connected or too-deep structures bring too much redundancy. This redundancy from both connection and neurons is one of the key factors hindering the practical application of SNNs. Although Some pruning methods were proposed to tackle this problem, they normally ignored the fact the neural topology in the human brain could be adjusted dynamically. Inspired by this, this paper proposed an evolutionary-based structure construction method for constructing more reasonable SNNs. By integrating the knowledge distillation and connection pruning method, the synaptic connections in SNNs can be optimized dynamically to reach an optimal state. As a result, the structure of SNNs could not only absorb knowledge from the teacher model but also search for deep but sparse network topology. Experimental results on CIFAR100 and DVS-Gesture show that the proposed structure learning method can get pretty well performance while reducing the connection redundancy. The proposed method explores a novel dynamical way for structure learning from scratch in SNNs which could build a bridge to close the gap between deep learning and bio-inspired neural dynamics. ",
    "url": "https://arxiv.org/abs/2304.09500",
    "authors": [
      "Qi Xu",
      "Yaxin Li",
      "Xuanye Fang",
      "Jiangrong Shen",
      "Jian K. Liu",
      "Huajin Tang",
      "Gang Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09512",
    "title": "Community Detection Using Revised Medoid-Shift Based on KNN",
    "abstract": "Community detection becomes an important problem with the booming of social networks. As an excellent clustering algorithm, Mean-Shift can not be applied directly to community detection, since Mean-Shift can only handle data with coordinates, while the data in the community detection problem is mostly represented by a graph that can be treated as data with a distance matrix (or similarity matrix). Fortunately, a new clustering algorithm called Medoid-Shift is proposed. The Medoid-Shift algorithm preserves the benefits of Mean-Shift and can be applied to problems based on distance matrix, such as community detection. One drawback of the Medoid-Shift algorithm is that there may be no data points within the neighborhood region defined by a distance parameter. To deal with the community detection problem better, a new algorithm called Revised Medoid-Shift (RMS) in this work is thus proposed. During the process of finding the next medoid, the RMS algorithm is based on a neighborhood defined by KNN, while the original Medoid-Shift is based on a neighborhood defined by a distance parameter. Since the neighborhood defined by KNN is more stable than the one defined by the distance parameter in terms of the number of data points within the neighborhood, the RMS algorithm may converge more smoothly. In the RMS method, each of the data points is shifted towards a medoid within the neighborhood defined by KNN. After the iterative process of shifting, each of the data point converges into a cluster center, and the data points converging into the same center are grouped into the same cluster. ",
    "url": "https://arxiv.org/abs/2304.09512",
    "authors": [
      "Jie Hou",
      "Jiakang Li",
      "Xiaokang Peng",
      "Wei Ke",
      "Yonggang Lu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09513",
    "title": "NetGPT: Generative Pretrained Transformer for Network Traffic",
    "abstract": "Pretrained models for network traffic can utilize large-scale raw data to learn the essential characteristics of network traffic, and generate distinguishable results for input traffic without considering specific downstream tasks. Effective pretrained models can significantly optimize the training efficiency and effectiveness of downstream tasks, such as traffic classification, attack detection, resource scheduling, protocol analysis, and traffic generation. Despite the great success of pretraining in natural language processing, there is no work in the network field. Considering the diverse demands and characteristics of network traffic and network tasks, it is non-trivial to build a pretrained model for network traffic and we face various challenges, especially the heterogeneous headers and payloads in the multi-pattern network traffic and the different dependencies for contexts of diverse downstream network tasks. To tackle these challenges, in this paper, we make the first attempt to provide a generative pretrained model for both traffic understanding and generation tasks. We propose the multi-pattern network traffic modeling to construct unified text inputs and support both traffic understanding and generation tasks. We further optimize the adaptation effect of the pretrained model to diversified tasks by shuffling header fields, segmenting packets in flows, and incorporating diverse task labels with prompts. Expensive experiments demonstrate the effectiveness of our NetGPT in a range of traffic understanding and generation tasks, and outperform state-of-the-art baselines by a wide margin. ",
    "url": "https://arxiv.org/abs/2304.09513",
    "authors": [
      "Xuying Meng",
      "Chungang Lin",
      "Yequan Wang",
      "Yujun Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09515",
    "title": "Secure Split Learning against Property Inference, Data Reconstruction,  and Feature Space Hijacking Attacks",
    "abstract": "Split learning of deep neural networks (SplitNN) has provided a promising solution to learning jointly for the mutual interest of a guest and a host, which may come from different backgrounds, holding features partitioned vertically. However, SplitNN creates a new attack surface for the adversarial participant, holding back its practical use in the real world. By investigating the adversarial effects of highly threatening attacks, including property inference, data reconstruction, and feature hijacking attacks, we identify the underlying vulnerability of SplitNN and propose a countermeasure. To prevent potential threats and ensure the learning guarantees of SplitNN, we design a privacy-preserving tunnel for information exchange between the guest and the host. The intuition is to perturb the propagation of knowledge in each direction with a controllable unified solution. To this end, we propose a new activation function named R3eLU, transferring private smashed data and partial loss into randomized responses in forward and backward propagations, respectively. We give the first attempt to secure split learning against three threatening attacks and present a fine-grained privacy budget allocation scheme. The analysis proves that our privacy-preserving SplitNN solution provides a tight privacy budget, while the experimental results show that our solution performs better than existing solutions in most cases and achieves a good tradeoff between defense and model usability. ",
    "url": "https://arxiv.org/abs/2304.09515",
    "authors": [
      "Yunlong Mao",
      "Zexi Xin",
      "Zhenyu Li",
      "Jue Hong",
      "Qingyou Yang",
      "Sheng Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.09528",
    "title": "Network Algebraization and Port Relationship for  Power-Electronic-Dominated Power Systems",
    "abstract": "Different from the quasi-static network in the traditional power system, the dynamic network in the power-electronic-dominated power system should be considered due to rapid response of converters' controls. In this paper, a nonlinear differential-algebraic model framework is established with algebraic equations for dynamic electrical networks and differential equations for the (source) nodes, by generalizing the Kron reduction. The internal and terminal voltages of source nodes including converters are chosen as ports of nodes and networks. Correspondingly, the impact of dynamic network becomes clear, namely, it serves as a voltage divider and generates the terminal voltage based on the internal voltage of the sources instantaneously, even when the dynamics of inductance are included. With this simplest model, the roles of both nodes and the network become apparent.Simulations verify the proposed model framework in the modified 9-bus system. ",
    "url": "https://arxiv.org/abs/2304.09528",
    "authors": [
      "Rui Ma",
      "Xiaowen Yang",
      "Meng Zhan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.09530",
    "title": "SelfAct: Personalized Activity Recognition based on Self-Supervised and  Active Learning",
    "abstract": "Supervised Deep Learning (DL) models are currently the leading approach for sensor-based Human Activity Recognition (HAR) on wearable and mobile devices. However, training them requires large amounts of labeled data whose collection is often time-consuming, expensive, and error-prone. At the same time, due to the intra- and inter-variability of activity execution, activity models should be personalized for each user. In this work, we propose SelfAct: a novel framework for HAR combining self-supervised and active learning to mitigate these problems. SelfAct leverages a large pool of unlabeled data collected from many users to pre-train through self-supervision a DL model, with the goal of learning a meaningful and efficient latent representation of sensor data. The resulting pre-trained model can be locally used by new users, which will fine-tune it thanks to a novel unsupervised active learning strategy. Our experiments on two publicly available HAR datasets demonstrate that SelfAct achieves results that are close to or even better than the ones of fully supervised approaches with a small number of active learning queries. ",
    "url": "https://arxiv.org/abs/2304.09530",
    "authors": [
      "Luca Arrotta",
      "Gabriele Civitarese",
      "Samuele Valente",
      "Claudio Bettini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.09534",
    "title": "Realistic Data Enrichment for Robust Image Segmentation in  Histopathology",
    "abstract": "Poor performance of quantitative analysis in histopathological Whole Slide Images (WSI) has been a significant obstacle in clinical practice. Annotating large-scale WSIs manually is a demanding and time-consuming task, unlikely to yield the expected results when used for fully supervised learning systems. Rarely observed disease patterns and large differences in object scales are difficult to model through conventional patient intake. Prior methods either fall back to direct disease classification, which only requires learning a few factors per image, or report on average image segmentation performance, which is highly biased towards majority observations. Geometric image augmentation is commonly used to improve robustness for average case predictions and to enrich limited datasets. So far no method provided sampling of a realistic posterior distribution to improve stability, e.g. for the segmentation of imbalanced objects within images. Therefore, we propose a new approach, based on diffusion models, which can enrich an imbalanced dataset with plausible examples from underrepresented groups by conditioning on segmentation maps. Our method can simply expand limited clinical datasets making them suitable to train machine learning pipelines, and provides an interpretable and human-controllable way of generating histopathology images that are indistinguishable from real ones to human experts. We validate our findings on two datasets, one from the public domain and one from a Kidney Transplant study. ",
    "url": "https://arxiv.org/abs/2304.09534",
    "authors": [
      "Sarah Cechnicka",
      "James Ball",
      "Callum Arthurs",
      "Candice Roufosse",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09536",
    "title": "Decadal Temperature Prediction via Chaotic Behavior Tracking",
    "abstract": "Decadal temperature prediction provides crucial information for quantifying the expected effects of future climate changes and thus informs strategic planning and decision-making in various domains. However, such long-term predictions are extremely challenging, due to the chaotic nature of temperature variations. Moreover, the usefulness of existing simulation-based and machine learning-based methods for this task is limited because initial simulation or prediction errors increase exponentially over time. To address this challenging task, we devise a novel prediction method involving an information tracking mechanism that aims to track and adapt to changes in temperature dynamics during the prediction phase by providing probabilistic feedback on the prediction error of the next step based on the current prediction. We integrate this information tracking mechanism, which can be considered as a model calibrator, into the objective function of our method to obtain the corrections needed to avoid error accumulation. Our results show the ability of our method to accurately predict global land-surface temperatures over a decadal range. Furthermore, we demonstrate that our results are meaningful in a real-world context: the temperatures predicted using our method are consistent with and can be used to explain the well-known teleconnections within and between different continents. ",
    "url": "https://arxiv.org/abs/2304.09536",
    "authors": [
      "Jinfu Ren",
      "Yang Liu",
      "Jiming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.09540",
    "title": "Learning Hierarchically-Structured Concepts II: Overlapping Concepts,  and Networks With Feedback",
    "abstract": "We continue our study from Lynch and Mallmann-Trenn (Neural Networks, 2021), of how concepts that have hierarchical structure might be represented in brain-like neural networks, how these representations might be used to recognize the concepts, and how these representations might be learned. In Lynch and Mallmann-Trenn (Neural Networks, 2021), we considered simple tree-structured concepts and feed-forward layered networks. Here we extend the model in two ways: we allow limited overlap between children of different concepts, and we allow networks to include feedback edges. For these more general cases, we describe and analyze algorithms for recognition and algorithms for learning. ",
    "url": "https://arxiv.org/abs/2304.09540",
    "authors": [
      "Nancy Lynch",
      "Frederik Mallmann-Trenn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2304.09547",
    "title": "Graph Exploration for Effective Multi-agent Q-Learning",
    "abstract": "This paper proposes an exploration technique for multi-agent reinforcement learning (MARL) with graph-based communication among agents. We assume the individual rewards received by the agents are independent of the actions by the other agents, while their policies are coupled. In the proposed framework, neighbouring agents collaborate to estimate the uncertainty about the state-action space in order to execute more efficient explorative behaviour. Different from existing works, the proposed algorithm does not require counting mechanisms and can be applied to continuous-state environments without requiring complex conversion techniques. Moreover, the proposed scheme allows agents to communicate in a fully decentralized manner with minimal information exchange. And for continuous-state scenarios, each agent needs to exchange only a single parameter vector. The performance of the algorithm is verified with theoretical results for discrete-state scenarios and with experiments for continuous ones. ",
    "url": "https://arxiv.org/abs/2304.09547",
    "authors": [
      "Ainur Zhaikhan",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2304.09563",
    "title": "On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model,  Data, and Training",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims at automatically inferring the specific sentiment polarities toward certain aspects of products or services behind the social media texts or reviews, which has been a fundamental application to the real-world society. Since the early 2010s, ABSA has achieved extraordinarily high accuracy with various deep neural models. However, existing ABSA models with strong in-house performances may fail to generalize to some challenging cases where the contexts are variable, i.e., low robustness to real-world environments. In this study, we propose to enhance the ABSA robustness by systematically rethinking the bottlenecks from all possible angles, including model, data, and training. First, we strengthen the current best-robust syntax-aware models by further incorporating the rich external syntactic dependencies and the labels with aspect simultaneously with a universal-syntax graph convolutional network. In the corpus perspective, we propose to automatically induce high-quality synthetic training data with various types, allowing models to learn sufficient inductive bias for better robustness. Last, we based on the rich pseudo data perform adversarial training to enhance the resistance to the context perturbation and meanwhile employ contrastive learning to reinforce the representations of instances with contrastive sentiments. Extensive robustness evaluations are conducted. The results demonstrate that our enhanced syntax-aware model achieves better robustness performances than all the state-of-the-art baselines. By additionally incorporating our synthetic corpus, the robust testing results are pushed with around 10% accuracy, which are then further improved by installing the advanced training strategies. In-depth analyses are presented for revealing the factors influencing the ABSA robustness. ",
    "url": "https://arxiv.org/abs/2304.09563",
    "authors": [
      "Hao Fei",
      "Tat-Seng Chua",
      "Chenliang Li",
      "Donghong Ji",
      "Meishan Zhang",
      "Yafeng Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.09575",
    "title": "Approximate non-linear model predictive control with safety-augmented  neural networks",
    "abstract": "Model predictive control (MPC) achieves stability and constraint satisfaction for general nonlinear systems, but requires computationally expensive online optimization. This paper studies approximations of such MPC controllers via neural networks (NNs) to achieve fast online evaluation. We propose safety augmentation that yields deterministic guarantees for convergence and constraint satisfaction despite approximation inaccuracies. We approximate the entire input sequence of the MPC with NNs, which allows us to verify online if it is a feasible solution to the MPC problem. We replace the NN solution by a safe candidate based on standard MPC techniques whenever it is infeasible or has worse cost. Our method requires a single evaluation of the NN and forward integration of the input sequence online, which is fast to compute on resource-constrained systems. The proposed control framework is illustrated on three non-linear MPC benchmarks of different complexity, demonstrating computational speedups orders of magnitudes higher than online optimization. In the examples, we achieve deterministic safety through the safety-augmented NNs, where naive NN implementation fails. ",
    "url": "https://arxiv.org/abs/2304.09575",
    "authors": [
      "Henrik Hose",
      "Johannes K\u00f6hler",
      "Melanie N. Zeilinger",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.09584",
    "title": "DynamicRead: Exploring Robust Gaze Interaction Methods for Reading on  Handheld Mobile Devices under Dynamic Conditions",
    "abstract": "Enabling gaze interaction in real-time on handheld mobile devices has attracted significant attention in recent years. An increasing number of research projects have focused on sophisticated appearance-based deep learning models to enhance the precision of gaze estimation on smartphones. This inspires important research questions, including how the gaze can be used in a real-time application, and what type of gaze interaction methods are preferable under dynamic conditions in terms of both user acceptance and delivering reliable performance. To address these questions, we design four types of gaze scrolling techniques: three explicit technique based on Gaze Gesture, Dwell time, and Pursuit; and one implicit technique based on reading speed to support touch-free, page-scrolling on a reading application. We conduct a 20-participant user study under both sitting and walking settings and our results reveal that Gaze Gesture and Dwell time-based interfaces are more robust while walking and Gaze Gesture has achieved consistently good scores on usability while not causing high cognitive workload. ",
    "url": "https://arxiv.org/abs/2304.09584",
    "authors": [
      "Yaxiong Lei",
      "Yuheng Wang",
      "Tyler Caslin",
      "Alexander Wisowaty",
      "Xu Zhu",
      "Mohamed Khamis",
      "Juan Ye"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.09588",
    "title": "DADFNet: Dual Attention and Dual Frequency-Guided Dehazing Network for  Video-Empowered Intelligent Transportation",
    "abstract": "Visual surveillance technology is an indispensable functional component of advanced traffic management systems. It has been applied to perform traffic supervision tasks, such as object detection, tracking and recognition. However, adverse weather conditions, e.g., fog, haze and mist, pose severe challenges for video-based transportation surveillance. To eliminate the influences of adverse weather conditions, we propose a dual attention and dual frequency-guided dehazing network (termed DADFNet) for real-time visibility enhancement. It consists of a dual attention module (DAM) and a high-low frequency-guided sub-net (HLFN) to jointly consider the attention and frequency mapping to guide haze-free scene reconstruction. Extensive experiments on both synthetic and real-world images demonstrate the superiority of DADFNet over state-of-the-art methods in terms of visibility enhancement and improvement in detection accuracy. Furthermore, DADFNet only takes $6.3$ ms to process a 1,920 * 1,080 image on the 2080 Ti GPU, making it highly efficient for deployment in intelligent transportation systems. ",
    "url": "https://arxiv.org/abs/2304.09588",
    "authors": [
      "Yu Guo",
      "Ryan Wen Liu",
      "Jiangtian Nie",
      "Lingjuan Lyu",
      "Zehui Xiong",
      "Jiawen Kang",
      "Han Yu",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09590",
    "title": "Parallel Neural Networks in Golang",
    "abstract": "This paper describes the design and implementation of parallel neural networks (PNNs) with the novel programming language Golang. We follow in our approach the classical Single-Program Multiple-Data (SPMD) model where a PNN is composed of several sequential neural networks, which are trained with a proportional share of the training dataset. We used for this purpose the MNIST dataset, which contains binary images of handwritten digits. Our analysis focusses on different activation functions and optimizations in the form of stochastic gradients and initialization of weights and biases. We conduct a thorough performance analysis, where network configurations and different performance factors are analyzed and interpreted. Golang and its inherent parallelization support proved very well for parallel neural network simulation by considerable decreased processing times compared to sequential variants. ",
    "url": "https://arxiv.org/abs/2304.09590",
    "authors": [
      "Daniela Kalwarowskyj",
      "Erich Schikuta"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.09595",
    "title": "AdapterGNN: Efficient Delta Tuning Improves Generalization Ability in  Graph Neural Networks",
    "abstract": "Fine-tuning pre-trained models has recently yielded remarkable performance gains in graph neural networks (GNNs). In addition to pre-training techniques, inspired by the latest work in the natural language fields, more recent work has shifted towards applying effective fine-tuning approaches, such as parameter-efficient tuning (delta tuning). However, given the substantial differences between GNNs and transformer-based models, applying such approaches directly to GNNs proved to be less effective. In this paper, we present a comprehensive comparison of delta tuning techniques for GNNs and propose a novel delta tuning method specifically designed for GNNs, called AdapterGNN. AdapterGNN preserves the knowledge of the large pre-trained model and leverages highly expressive adapters for GNNs, which can adapt to downstream tasks effectively with only a few parameters, while also improving the model's generalization ability on the downstream tasks. Extensive experiments show that AdapterGNN achieves higher evaluation performance (outperforming full fine-tuning by 1.4% and 5.5% in the chemistry and biology domains respectively, with only 5% of its parameters tuned) and lower generalization gaps compared to full fine-tuning. Moreover, we empirically show that a larger GNN model can have a worse generalization ability, which differs from the trend observed in large language models. We have also provided a theoretical justification for delta tuning can improve the generalization ability of GNNs by applying generalization bounds. ",
    "url": "https://arxiv.org/abs/2304.09595",
    "authors": [
      "Shengrui Li",
      "Xueting Han",
      "Jing Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09599",
    "title": "LEA: Beyond Evolutionary Algorithms via Learned Optimization Strategy",
    "abstract": "Evolutionary algorithms (EAs) have emerged as a powerful framework for expensive black-box optimization. Obtaining better solutions with less computational cost is essential and challenging for black-box optimization. The most critical obstacle is figuring out how to effectively use the target task information to form an efficient optimization strategy. However, current methods are weak due to the poor representation of the optimization strategy and the inefficient interaction between the optimization strategy and the target task. To overcome the above limitations, we design a learned EA (LEA) to realize the move from hand-designed optimization strategies to learned optimization strategies, including not only hyperparameters but also update rules. Unlike traditional EAs, LEA has high adaptability to the target task and can obtain better solutions with less computational cost. LEA is also able to effectively utilize the low-fidelity information of the target task to form an efficient optimization strategy. The experimental results on one synthetic case, CEC 2013, and two real-world cases show the advantages of learned optimization strategies over human-designed baselines. In addition, LEA is friendly to the acceleration provided by Graphics Processing Units and runs 102 times faster than unaccelerated EA when evolving 32 populations, each containing 6400 individuals. ",
    "url": "https://arxiv.org/abs/2304.09599",
    "authors": [
      "Kai Wu",
      "Penghui Liu",
      "Jing Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09609",
    "title": "MMDR: A Result Feature Fusion Object Detection Approach for Autonomous  System",
    "abstract": "Object detection has been extensively utilized in autonomous systems in recent years, encompassing both 2D and 3D object detection. Recent research in this field has primarily centered around multimodal approaches for addressing this issue.In this paper, a multimodal fusion approach based on result feature-level fusion is proposed. This method utilizes the outcome features generated from single modality sources, and fuses them for downstream tasks.Based on this method, a new post-fusing network is proposed for multimodal object detection, which leverages the single modality outcomes as features. The proposed approach, called Multi-Modal Detector based on Result features (MMDR), is designed to work for both 2D and 3D object detection tasks. Compared to previous multimodal models, the proposed approach in this paper performs feature fusion at a later stage, enabling better representation of the deep-level features of single modality sources. Additionally, the MMDR model incorporates shallow global features during the feature fusion stage, endowing the model with the ability to perceive background information and the overall input, thereby avoiding issues such as missed detections. ",
    "url": "https://arxiv.org/abs/2304.09609",
    "authors": [
      "Wendong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09623",
    "title": "CHATTY: Coupled Holistic Adversarial Transport Terms with Yield for  Unsupervised Domain Adaptation",
    "abstract": "We propose a new technique called CHATTY: Coupled Holistic Adversarial Transport Terms with Yield for Unsupervised Domain Adaptation. Adversarial training is commonly used for learning domain-invariant representations by reversing the gradients from a domain discriminator head to train the feature extractor layers of a neural network. We propose significant modifications to the adversarial head, its training objective, and the classifier head. With the aim of reducing class confusion, we introduce a sub-network which displaces the classifier outputs of the source and target domain samples in a learnable manner. We control this movement using a novel transport loss that spreads class clusters away from each other and makes it easier for the classifier to find the decision boundaries for both the source and target domains. The results of adding this new loss to a careful selection of previously proposed losses leads to improvement in UDA results compared to the previous state-of-the-art methods on benchmark datasets. We show the importance of the proposed loss term using ablation studies and visualization of the movement of target domain sample in representation space. ",
    "url": "https://arxiv.org/abs/2304.09623",
    "authors": [
      "Chirag P",
      "Mukta Wagle",
      "Ravi Kant Gupta",
      "Pranav Jeevan P",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.09646",
    "title": "Resource Allocation in the RIS Assisted SCMA Cellular Network Coexisting  with D2D Communications",
    "abstract": "The cellular network coexisting with device-to-device (D2D) communications has been studied extensively. Reconfigurable intelligent surface (RIS) and non-orthogonal multiple access (NOMA) are promising technologies for the evolution of 5G, 6G and beyond. Besides, sparse code multiple access (SCMA) is considered suitable for next-generation wireless network in code-domain NOMA. In this paper, we consider the RIS-aided uplink SCMA cellular network simultaneously with D2D users. We formulate the optimization problem which aims to maximize the cellular sum-rate by jointly designing D2D users resource block (RB) association, the transmitted power for both cellular users and D2D users, and the phase shifts at the RIS. The power limitation and users communication requirements are considered. The problem is non-convex, and it is challenging to solve it directly. To handle this optimization problem, we propose an efficient iterative algorithm based on block coordinate descent (BCD) method. The original problem is decoupled into three subproblems to solve separately. Simulation results demonstrate that the proposed scheme can significantly improve the sum-rate performance over various schemes. ",
    "url": "https://arxiv.org/abs/2304.09646",
    "authors": [
      "Yukai Liu",
      "Wen Chen",
      "Kunlun Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.09653",
    "title": "ReelFramer: Co-creating News Reels on Social Media with Generative AI",
    "abstract": "Short videos on social media are a prime way many young people find and consume content. News outlets would like to reach audiences through news reels, but currently struggle to translate traditional journalistic formats into the short, entertaining videos that match the style of the platform. There are many ways to frame a reel-style narrative around a news story, and selecting one is a challenge. Different news stories call for different framings, and require a different trade-off between entertainment and information. We present a system called ReelFramer that uses text and image generation to help journalists explore multiple narrative framings for a story, then generate scripts, character boards and storyboards they can edit and iterate on. A user study of five graduate students in journalism-related fields found the system greatly eased the burden of transforming a written story into a reel, and that exploring framings to find the right one was a rewarding process. ",
    "url": "https://arxiv.org/abs/2304.09653",
    "authors": [
      "Sitong Wang",
      "Samia Menon",
      "Tao Long",
      "Keren Henderson",
      "Dingzeyu Li",
      "Kevin Crowston",
      "Mark Hansen",
      "Jeffrey V. Nickerson",
      "Lydia B. Chilton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09654",
    "title": "Uniform Generation of Temporal Graphs with Given Degrees",
    "abstract": "Uniform sampling from the set $\\mathcal{G}(\\mathbf{d})$ of graphs with a given degree-sequence $\\mathbf{d} = (d_1, \\dots, d_n) \\in \\mathbb N^n$ is a classical problem in the study of random graphs. We consider an analogue for temporal graphs in which the edges are labeled with integer timestamps. The input to this generation problem is a tuple $\\mathbf{D} = (\\mathbf{d}, T) \\in \\mathbb N^n \\times \\mathbb N_{>0}$ and the task is to output a uniform random sample from the set $\\mathcal{G}(\\mathbf{D})$ of temporal graphs with degree-sequence $\\mathbf{d}$ and timestamps in the interval $[1, T]$. By allowing repeated edges with distinct timestamps, $\\mathcal{G}(\\mathbf{D})$ can be non-empty even if $\\mathcal{G}(\\mathbf{d})$ is, and as a consequence, existing algorithms are difficult to apply. We describe an algorithm for this generation problem which runs in expected time $O(M)$ if $\\Delta^{2+\\epsilon} = O(M)$ for some constant $\\epsilon > 0$ and $T - \\Delta = \\Omega(T)$ where $M = \\sum_i d_i$ and $\\Delta = \\max_i d_i$. Our algorithm applies the switching method of McKay and Wormald $[1]$ to temporal graphs: we first generate a random temporal multigraph and then remove self-loops and duplicated edges with switching operations which rewire the edges in a degree-preserving manner. ",
    "url": "https://arxiv.org/abs/2304.09654",
    "authors": [
      "Daniel Allendorf"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2304.09655",
    "title": "How Secure is Code Generated by ChatGPT?",
    "abstract": "In recent years, large language models have been responsible for great advances in the field of artificial intelligence (AI). ChatGPT in particular, an AI chatbot developed and recently released by OpenAI, has taken the field to the next level. The conversational model is able not only to process human-like text, but also to translate natural language into code. However, the safety of programs generated by ChatGPT should not be overlooked. In this paper, we perform an experiment to address this issue. Specifically, we ask ChatGPT to generate a number of program and evaluate the security of the resulting source code. We further investigate whether ChatGPT can be prodded to improve the security by appropriate prompts, and discuss the ethical aspects of using AI to generate code. Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks. ",
    "url": "https://arxiv.org/abs/2304.09655",
    "authors": [
      "Rapha\u00ebl Khoury",
      "Anderson R. Avila",
      "Jacob Brunelle",
      "Baba Mamadou Camara"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.09664",
    "title": "On countings and enumerations of block-parallel automata networks",
    "abstract": "When we focus on finite dynamical systems from both the computability/complexity and the modelling standpoints, automata networks seem to be a particularly appropriate mathematical model on which theory shall be developed. In this paper, automata networks are finite collections of entities (the automata), each automaton having its own set of possible states, which interact with each other over discrete time, interactions being defined as local functions allowing the automata to change their state according to the states of their neighbourhoods. The studies on this model of computation have underlined the very importance of the way (i.e. the schedule) according to which the automata update their states, namely the update modes which can be deterministic, periodic, fair, or not. Indeed, a given network may admit numerous underlying dynamics, these latter depending highly on the update modes under which we let the former evolve. In this paper, we pay attention to a new kind of deterministic, periodic and fair update mode family introduced recently in a modelling framework, called the block-parallel update modes by duality with the well-known and studied block-sequential update modes. More precisely, in the general context of automata networks, this work aims at presenting what distinguish block-parallel update modes from block-sequential ones, and at counting and enumerating them: in absolute terms, by keeping only representatives leading to distinct dynamics, and by keeping only representatives giving rise to distinct isomorphic limit dynamics. Put together, this paper constitutes a first theoretical analysis of these update modes and their impact on automata networks dynamics. ",
    "url": "https://arxiv.org/abs/2304.09664",
    "authors": [
      "K\u00e9vin Perrot",
      "Sylvain Sen\u00e9",
      "L\u00e9ah Tapin"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2304.09670",
    "title": "CMID: A Unified Self-Supervised Learning Framework for Remote Sensing  Image Understanding",
    "abstract": "Self-supervised learning (SSL) has gained widespread attention in the remote sensing (RS) and earth observation (EO) communities owing to its ability to learn task-agnostic representations without human-annotated labels. Nevertheless, most existing RS SSL methods are limited to learning either global semantic separable or local spatial perceptible representations. We argue that this learning strategy is suboptimal in the realm of RS, since the required representations for different RS downstream tasks are often varied and complex. In this study, we proposed a unified SSL framework that is better suited for RS images representation learning. The proposed SSL framework, Contrastive Mask Image Distillation (CMID), is capable of learning representations with both global semantic separability and local spatial perceptibility by combining contrastive learning (CL) with masked image modeling (MIM) in a self-distillation way. Furthermore, our CMID learning framework is architecture-agnostic, which is compatible with both convolutional neural networks (CNN) and vision transformers (ViT), allowing CMID to be easily adapted to a variety of deep learning (DL) applications for RS understanding. Comprehensive experiments have been carried out on four downstream tasks (i.e. scene classification, semantic segmentation, object-detection, and change detection) and the results show that models pre-trained using CMID achieve better performance than other state-of-the-art SSL methods on multiple downstream tasks. The code and pre-trained models will be made available at https://github.com/NJU-LHRS/official-CMID to facilitate SSL research and speed up the development of RS images DL applications. ",
    "url": "https://arxiv.org/abs/2304.09670",
    "authors": [
      "Dilxat Muhtar",
      "Xueliang Zhang",
      "Pengfeng Xiao",
      "Zhenshi Li",
      "Feng Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09677",
    "title": "Reference-guided Controllable Inpainting of Neural Radiance Fields",
    "abstract": "The popularity of Neural Radiance Fields (NeRFs) for view synthesis has led to a desire for NeRF editing tools. Here, we focus on inpainting regions in a view-consistent and controllable manner. In addition to the typical NeRF inputs and masks delineating the unwanted region in each view, we require only a single inpainted view of the scene, i.e., a reference view. We use monocular depth estimators to back-project the inpainted view to the correct 3D positions. Then, via a novel rendering technique, a bilateral solver can construct view-dependent effects in non-reference views, making the inpainted region appear consistent from any view. For non-reference disoccluded regions, which cannot be supervised by the single reference view, we devise a method based on image inpainters to guide both the geometry and appearance. Our approach shows superior performance to NeRF inpainting baselines, with the additional advantage that a user can control the generated scene via a single inpainted image. Project page: https://ashmrz.github.io/reference-guided-3d ",
    "url": "https://arxiv.org/abs/2304.09677",
    "authors": [
      "Ashkan Mirzaei",
      "Tristan Aumentado-Armstrong",
      "Marcus A. Brubaker",
      "Jonathan Kelly",
      "Alex Levinshtein",
      "Konstantinos G. Derpanis",
      "Igor Gilitschenski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09694",
    "title": "CrossFusion: Interleaving Cross-modal Complementation for  Noise-resistant 3D Object Detection",
    "abstract": "The combination of LiDAR and camera modalities is proven to be necessary and typical for 3D object detection according to recent studies. Existing fusion strategies tend to overly rely on the LiDAR modal in essence, which exploits the abundant semantics from the camera sensor insufficiently. However, existing methods cannot rely on information from other modalities because the corruption of LiDAR features results in a large domain gap. Following this, we propose CrossFusion, a more robust and noise-resistant scheme that makes full use of the camera and LiDAR features with the designed cross-modal complementation strategy. Extensive experiments we conducted show that our method not only outperforms the state-of-the-art methods under the setting without introducing an extra depth estimation network but also demonstrates our model's noise resistance without re-training for the specific malfunction scenarios by increasing 5.2\\% mAP and 2.4\\% NDS. ",
    "url": "https://arxiv.org/abs/2304.09694",
    "authors": [
      "Yang Yang",
      "Weijie Ma",
      "Hao Chen",
      "Linlin Ou",
      "Xinyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09695",
    "title": "Big-Little Adaptive Neural Networks on Low-Power Near-Subthreshold  Processors",
    "abstract": "This paper investigates the energy savings that near-subthreshold processors can obtain in edge AI applications and proposes strategies to improve them while maintaining the accuracy of the application. The selected processors deploy adaptive voltage scaling techniques in which the frequency and voltage levels of the processor core are determined at the run-time. In these systems, embedded RAM and flash memory size is typically limited to less than 1 megabyte to save power. This limited memory imposes restrictions on the complexity of the neural networks model that can be mapped to these devices and the required trade-offs between accuracy and battery life. To address these issues, we propose and evaluate alternative 'big-little' neural network strategies to improve battery life while maintaining prediction accuracy. The strategies are applied to a human activity recognition application selected as a demonstrator that shows that compared to the original network, the best configurations obtain an energy reduction measured at 80% while maintaining the original level of inference accuracy. ",
    "url": "https://arxiv.org/abs/2304.09695",
    "authors": [
      "Zichao Shen",
      "Neil Howard",
      "Jose Nunez-Yanez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2304.09711",
    "title": "Grooming Connectivity Intents in IP-Optical Networks Using Directed  Acyclic Graphs",
    "abstract": "During the last few years, there have been concentrated efforts toward intent-driven networking. While relying upon Software-Defined Networking (SDN), Intent-Based Networking (IBN) pushes the frontiers of efficient networking by decoupling the intentions of a network operator (i.e., what is desired to be done) from the implementation (i.e., how is it achieved). The advantages of such a paradigm have long been argued and include, but are not limited to, the reduction of human errors, reduced expertise requirements among operator personnel, and faster business plan adaptation. In previous work, we have shown how incorporating IBN in multi-domain networks can have a significantly positive impact as it can enable decentralized operation, accountability, and confidentiality. The pillar of our previous contribution is the compilation of intents using system-generated intent trees. In this work, we extend the architecture to enable grooming among the user intents. Therefore, separate intents can now end up using the same network resources. While this makes the intent system reasonably more complex, it indisputably improves resource allocation. To represent the intent relationships of the newly enhanced architecture, we use Directed Acyclic Graphs (DAGs). Furthermore, we appropriately adapt an advanced established technique from the literature to solve the Routing, Modulation, and Spectrum Assignment (RMSA) problem for the intent compilation. We demonstrate a realistic scenario in which we evaluate our architecture and the intent compilation strategy. Our current approach successfully consolidates the advantages of having an intent-driven architecture and, at the same time, flexibly choosing among advanced resource allocation techniques. ",
    "url": "https://arxiv.org/abs/2304.09711",
    "authors": [
      "Filippos Christou",
      "Andreas Kirst\u00e4dter"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.09720",
    "title": "Genetic Algorithm Based Combinatorial Optimization for the Optimal  Design of Water Distribution Network of Gurudeniya Service Zone, Sri Lanka",
    "abstract": "This paper brings an in detail Genetic Algorithm (GA) based combinatorial optimization method used for the optimal design of the water distribution network (WDN) of Gurudeniya Service Zone, Sri Lanka. Genetic Algorithm (GA) mimics the survival of the fittest principle of nature to develop a search process. Methodology employs fuzzy combinations of pipe diameters to check their suitability to be considered as the cost effective optimal design solutions. Furthermore, the hydraulic constraints were implicitly evaluated within the GA itself in its aim to reaching the global optimum solution. Upon analysis, the results of this approach delivered agreeable design outputs. In addition, the comparison made between the results obtained by a previous study inspired by the Honey Bee Mating Optimization (HBMO) Algorithm and results obtained by the GA based approach, proves competency of GA for the optimal design of water distribution network in Gurudeniya Service Zone, Sri Lanka. ",
    "url": "https://arxiv.org/abs/2304.09720",
    "authors": [
      "K. H. M. R. N. Senavirathna",
      "C. K. Walgampaya"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.09721",
    "title": "Improved Active Fire Detection using Operational U-Nets",
    "abstract": "As a consequence of global warming and climate change, the risk and extent of wildfires have been increasing in many areas worldwide. Warmer temperatures and drier conditions can cause quickly spreading fires and make them harder to control; therefore, early detection and accurate locating of active fires are crucial in environmental monitoring. Using satellite imagery to monitor and detect active fires has been critical for managing forests and public land. Many traditional statistical-based methods and more recent deep-learning techniques have been proposed for active fire detection. In this study, we propose a novel approach called Operational U-Nets for the improved early detection of active fires. The proposed approach utilizes Self-Organized Operational Neural Network (Self-ONN) layers in a compact U-Net architecture. The preliminary experimental results demonstrate that Operational U-Nets not only achieve superior detection performance but can also significantly reduce computational complexity. ",
    "url": "https://arxiv.org/abs/2304.09721",
    "authors": [
      "Ozer Can Devecioglu",
      "Mete Ahishali",
      "Fahad Sohrab",
      "Turker Ince",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.09759",
    "title": "Amplifying Sine Unit: An Oscillatory Activation Function for Deep Neural  Networks to Recover Nonlinear Oscillations Efficiently",
    "abstract": "Many industrial and real life problems exhibit highly nonlinear periodic behaviors and the conventional methods may fall short of finding their analytical or closed form solutions. Such problems demand some cutting edge computational tools with increased functionality and reduced cost. Recently, deep neural networks have gained massive research interest due to their ability to handle large data and universality to learn complex functions. In this work, we put forward a methodology based on deep neural networks with responsive layers structure to deal nonlinear oscillations in microelectromechanical systems. We incorporated some oscillatory and non oscillatory activation functions such as growing cosine unit known as GCU, Sine, Mish and Tanh in our designed network to have a comprehensive analysis on their performance for highly nonlinear and vibrational problems. Integrating oscillatory activation functions with deep neural networks definitely outperform in predicting the periodic patterns of underlying systems. To support oscillatory actuation for nonlinear systems, we have proposed a novel oscillatory activation function called Amplifying Sine Unit denoted as ASU which is more efficient than GCU for complex vibratory systems such as microelectromechanical systems. Experimental results show that the designed network with our proposed activation function ASU is more reliable and robust to handle the challenges posed by nonlinearity and oscillations. To validate the proposed methodology, outputs of our networks are being compared with the results from Livermore solver for ordinary differential equation called LSODA. Further, graphical illustrations of incurred errors are also being presented in the work. ",
    "url": "https://arxiv.org/abs/2304.09759",
    "authors": [
      "Jamshaid Ul Rahman",
      "Faiza Makhdoom",
      "Dianchen Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2304.09761",
    "title": "An innovative Deep Learning Based Approach for Accurate Agricultural  Crop Price Prediction",
    "abstract": "Accurate prediction of agricultural crop prices is a crucial input for decision-making by various stakeholders in agriculture: farmers, consumers, retailers, wholesalers, and the Government. These decisions have significant implications including, most importantly, the economic well-being of the farmers. In this paper, our objective is to accurately predict crop prices using historical price information, climate conditions, soil type, location, and other key determinants of crop prices. This is a technically challenging problem, which has been attempted before. In this paper, we propose an innovative deep learning based approach to achieve increased accuracy in price prediction. The proposed approach uses graph neural networks (GNNs) in conjunction with a standard convolutional neural network (CNN) model to exploit geospatial dependencies in prices. Our approach works well with noisy legacy data and produces a performance that is at least 20% better than the results available in the literature. We are able to predict prices up to 30 days ahead. We choose two vegetables, potato (stable price behavior) and tomato (volatile price behavior) and work with noisy public data available from Indian agricultural markets. ",
    "url": "https://arxiv.org/abs/2304.09761",
    "authors": [
      "Mayank Ratan Bhardwaj",
      "Jaydeep Pawar",
      "Abhijnya Bhat",
      "Deepanshu",
      "Inavamsi Enaganti",
      "Kartik Sagar",
      "Y. Narahari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2304.09764",
    "title": "An End-to-End Vehicle Trajcetory Prediction Framework",
    "abstract": "Anticipating the motion of neighboring vehicles is crucial for autonomous driving, especially on congested highways where even slight motion variations can result in catastrophic collisions. An accurate prediction of a future trajectory does not just rely on the previous trajectory, but also, more importantly, a simulation of the complex interactions between other vehicles nearby. Most state-of-the-art networks built to tackle the problem assume readily available past trajectory points, hence lacking a full end-to-end pipeline with direct video-to-output mechanism. In this article, we thus propose a novel end-to-end architecture that takes raw video inputs and outputs future trajectory predictions. It first extracts and tracks the 3D location of the nearby vehicles via multi-head attention-based regression networks as well as non-linear optimization. This provides the past trajectory points which then feeds into the trajectory prediction algorithm consisting of an attention-based LSTM encoder-decoder architecture, which allows it to model the complicated interdependence between the vehicles and make an accurate prediction of the future trajectory points of the surrounding vehicles. The proposed model is evaluated on the large-scale BLVD dataset, and has also been implemented on CARLA. The experimental results demonstrate that our approach outperforms various state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2304.09764",
    "authors": [
      "Fuad Hasan",
      "Hailong Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09774",
    "title": "Nearly Work-Efficient Parallel DFS in Undirected Graphs",
    "abstract": "We present the first parallel depth-first search algorithm for undirected graphs that has near-linear work and sublinear depth. Concretely, in any $n$-node $m$-edge undirected graph, our algorithm computes a DFS in $\\tilde{O}(\\sqrt{n})$ depth and using $\\tilde{O}(m+n)$ work. All prior work either required $\\Omega(n)$ depth, and thus were essentially sequential, or needed a high $poly(n)$ work and thus were far from being work-efficient. ",
    "url": "https://arxiv.org/abs/2304.09774",
    "authors": [
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Jiahao Qu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.09785",
    "title": "Post-Training Quantization for Object Detection",
    "abstract": "Efficient inference for object detection networks is a major challenge on edge devices. Post-Training Quantization (PTQ), which transforms a full-precision model into low bit-width directly, is an effective and convenient approach to reduce model inference complexity. But it suffers severe accuracy drop when applied to complex tasks such as object detection. PTQ optimizes the quantization parameters by different metrics to minimize the perturbation of quantization. The p-norm distance of feature maps before and after quantization, Lp, is widely used as the metric to evaluate perturbation. For the specialty of object detection network, we observe that the parameter p in Lp metric will significantly influence its quantization performance. We indicate that using a fixed hyper-parameter p does not achieve optimal quantization performance. To mitigate this problem, we propose a framework, DetPTQ, to assign different p values for quantizing different layers using an Object Detection Output Loss (ODOL), which represents the task loss of object detection. DetPTQ employs the ODOL-based adaptive Lp metric to select the optimal quantization parameters. Experiments show that our DetPTQ outperforms the state-of-the-art PTQ methods by a significant margin on both 2D and 3D object detectors. For example, we achieve 31.1/31.7(quantization/full-precision) mAP on RetinaNet-ResNet18 with 4-bit weight and 4-bit activation. ",
    "url": "https://arxiv.org/abs/2304.09785",
    "authors": [
      "Lin Niu",
      "Jiawei Liu",
      "Zhihang Yuan",
      "Dawei Yang",
      "Xinggang Wang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09788",
    "title": "Advances on Concept Drift Detection in Regression Tasks using Social  Networks Theory",
    "abstract": "Mining data streams is one of the main studies in machine learning area due to its application in many knowledge areas. One of the major challenges on mining data streams is concept drift, which requires the learner to discard the current concept and adapt to a new one. Ensemble-based drift detection algorithms have been used successfully to the classification task but usually maintain a fixed size ensemble of learners running the risk of needlessly spending processing time and memory. In this paper we present improvements to the Scale-free Network Regressor (SFNR), a dynamic ensemble-based method for regression that employs social networks theory. In order to detect concept drifts SFNR uses the Adaptive Window (ADWIN) algorithm. Results show improvements in accuracy, especially in concept drift situations and better performance compared to other state-of-the-art algorithms in both real and synthetic data. ",
    "url": "https://arxiv.org/abs/2304.09788",
    "authors": [
      "Jean Paul Barddal",
      "Heitor Murilo Gomes",
      "Fabr\u00edcio Enembreck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09789",
    "title": "Automatic Interaction and Activity Recognition from Videos of Human  Manual Demonstrations with Application to Anomaly Detection",
    "abstract": "This paper presents a new method to describe spatio-temporal relations between objects and hands, to recognize both interactions and activities within video demonstrations of manual tasks. The approach exploits Scene Graphs to extract key interaction features from image sequences, encoding at the same time motion patterns and context. Additionally, the method introduces an event-based automatic video segmentation and clustering, which allows to group similar events, detecting also on the fly if a monitored activity is executed correctly. The effectiveness of the approach was demonstrated in two multi-subject experiments, showing the ability to recognize and cluster hand-object and object-object interactions without prior knowledge of the activity, as well as matching the same activity performed by different subjects. ",
    "url": "https://arxiv.org/abs/2304.09789",
    "authors": [
      "Elena Merlo",
      "Marta Lagomarsino",
      "Edoardo Lamon",
      "Arash Ajoudani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.09801",
    "title": "MetaBEV: Solving Sensor Failures for BEV Detection and Map Segmentation",
    "abstract": "Perception systems in modern autonomous driving vehicles typically take inputs from complementary multi-modal sensors, e.g., LiDAR and cameras. However, in real-world applications, sensor corruptions and failures lead to inferior performances, thus compromising autonomous safety. In this paper, we propose a robust framework, called MetaBEV, to address extreme real-world environments involving overall six sensor corruptions and two extreme sensor-missing situations. In MetaBEV, signals from multiple sensors are first processed by modal-specific encoders. Subsequently, a set of dense BEV queries are initialized, termed meta-BEV. These queries are then processed iteratively by a BEV-Evolving decoder, which selectively aggregates deep features from either LiDAR, cameras, or both modalities. The updated BEV representations are further leveraged for multiple 3D prediction tasks. Additionally, we introduce a new M2oE structure to alleviate the performance drop on distinct tasks in multi-task joint learning. Finally, MetaBEV is evaluated on the nuScenes dataset with 3D object detection and BEV map segmentation tasks. Experiments show MetaBEV outperforms prior arts by a large margin on both full and corrupted modalities. For instance, when the LiDAR signal is missing, MetaBEV improves 35.5% detection NDS and 17.7% segmentation mIoU upon the vanilla BEVFusion model; and when the camera signal is absent, MetaBEV still achieves 69.2% NDS and 53.7% mIoU, which is even higher than previous works that perform on full-modalities. Moreover, MetaBEV performs fairly against previous methods in both canonical perception and multi-task learning settings, refreshing state-of-the-art nuScenes BEV map segmentation with 70.4% mIoU. ",
    "url": "https://arxiv.org/abs/2304.09801",
    "authors": [
      "Chongjian Ge",
      "Junsong Chen",
      "Enze Xie",
      "Zhongdao Wang",
      "Lanqing Hong",
      "Huchuan Lu",
      "Zhenguo Li",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09802",
    "title": "Generalization and Estimation Error Bounds for Model-based Neural  Networks",
    "abstract": "Model-based neural networks provide unparalleled performance for various tasks, such as sparse coding and compressed sensing problems. Due to the strong connection with the sensing model, these networks are interpretable and inherit prior structure of the problem. In practice, model-based neural networks exhibit higher generalization capability compared to ReLU neural networks. However, this phenomenon was not addressed theoretically. Here, we leverage complexity measures including the global and local Rademacher complexities, in order to provide upper bounds on the generalization and estimation errors of model-based networks. We show that the generalization abilities of model-based networks for sparse recovery outperform those of regular ReLU networks, and derive practical design rules that allow to construct model-based networks with guaranteed high generalization. We demonstrate through a series of experiments that our theoretical insights shed light on a few behaviours experienced in practice, including the fact that ISTA and ADMM networks exhibit higher generalization abilities (especially for small number of training samples), compared to ReLU networks. ",
    "url": "https://arxiv.org/abs/2304.09802",
    "authors": [
      "Avner Shultzman",
      "Eyar Azar",
      "Miguel R. D. Rodrigues",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09811",
    "title": "Analytic Network Traffic Prediction Based on User Behavior Modeling",
    "abstract": "This paper proposes an interpretable user-behavior-based (UBB) network traffic prediction (NTP) method. Based on user behavior, a weekly traffic demand profile can be naturally sorted into three categories, i.e., weekday, Saturday, and Sunday. For each category, the traffic pattern is divided into three components which are mainly generated in three time periods, i.e., morning, afternoon, and evening. Each component is modeled as a normal-distributed signal. Numerical results indicate the UBB NTP method matches the practical wireless traffic demand very well. Compared with existing methods, the proposed UBB NTP method improves the computational efficiency and increases the predictive accuracy. ",
    "url": "https://arxiv.org/abs/2304.09811",
    "authors": [
      "Liangzhi Wang",
      "Jiliang Zhang",
      "Zitian Zhang",
      "Jie Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.09820",
    "title": "A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain  Text Classification",
    "abstract": "Cross-domain text classification aims to adapt models to a target domain that lacks labeled data. It leverages or reuses rich labeled data from the different but related source domain(s) and unlabeled data from the target domain. To this end, previous work focuses on either extracting domain-invariant features or task-agnostic features, ignoring domain-aware features that may be present in the target domain and could be useful for the downstream task. In this paper, we propose a two-stage framework for cross-domain text classification. In the first stage, we finetune the model with mask language modeling (MLM) and labeled data from the source domain. In the second stage, we further fine-tune the model with self-supervised distillation (SSD) and unlabeled data from the target domain. We evaluate its performance on a public cross-domain text classification benchmark and the experiment results show that our method achieves new state-of-the-art results for both single-source domain adaptations (94.17% $\\uparrow$1.03%) and multi-source domain adaptations (95.09% $\\uparrow$1.34%). ",
    "url": "https://arxiv.org/abs/2304.09820",
    "authors": [
      "Yunlong Feng",
      "Bohan Li",
      "Libo Qin",
      "Xiao Xu",
      "Wanxiang Che"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09835",
    "title": "Towards transparent and robust data-driven wind turbine power curve  models",
    "abstract": "Wind turbine power curve models translate ambient conditions into turbine power output. They are essential for energy yield prediction and turbine performance monitoring. In recent years, data-driven machine learning methods have outperformed parametric, physics-informed approaches. However, they are often criticised for being opaque \"black boxes\" which raises concerns regarding their robustness in non-stationary environments, such as faced by wind turbines. We, therefore, introduce an explainable artificial intelligence (XAI) framework to investigate and validate strategies learned by data-driven power curve models from operational SCADA data. It combines domain-specific considerations with Shapley Values and the latest findings from XAI for regression. Our results suggest, that learned strategies can be better indicators for model robustness than validation or test set errors. Moreover, we observe that highly complex, state-of-the-art ML models are prone to learn physically implausible strategies. Consequently, we compare several measures to ensure physically reasonable model behaviour. Lastly, we propose the utilization of XAI in the context of wind turbine performance monitoring, by disentangling environmental and technical effects that cause deviations from an expected turbine output. We hope, our work can guide domain experts towards training and selecting more transparent and robust data-driven wind turbine power curve models. ",
    "url": "https://arxiv.org/abs/2304.09835",
    "authors": [
      "Simon Letzgus",
      "Klaus-Robert M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.09837",
    "title": "Points of non-linearity of functions generated by random neural networks",
    "abstract": "We consider functions from the real numbers to the real numbers, output by a neural network with 1 hidden activation layer, arbitrary width, and ReLU activation function. We assume that the parameters of the neural network are chosen uniformly at random with respect to various probability distributions, and compute the expected distribution of the points of non-linearity. We use these results to explain why the network may be biased towards outputting functions with simpler geometry, and why certain functions with low information-theoretic complexity are nonetheless hard for a neural network to approximate. ",
    "url": "https://arxiv.org/abs/2304.09837",
    "authors": [
      "David Holmes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2304.09850",
    "title": "Patching Neural Barrier Functions Using Hamilton-Jacobi Reachability",
    "abstract": "Learning-based control algorithms have led to major advances in robotics at the cost of decreased safety guarantees. Recently, neural networks have also been used to characterize safety through the use of barrier functions for complex nonlinear systems. Learned barrier functions approximately encode and enforce a desired safety constraint through a value function, but do not provide any formal guarantees. In this paper, we propose a local dynamic programming (DP) based approach to \"patch\" an almost-safe learned barrier at potentially unsafe points in the state space. This algorithm, HJ-Patch, obtains a novel barrier that provides formal safety guarantees, yet retains the global structure of the learned barrier. Our local DP based reachability algorithm, HJ-Patch, updates the barrier function \"minimally\" at points that both (a) neighbor the barrier safety boundary and (b) do not satisfy the safety condition. We view this as a key step to bridging the gap between learning-based barrier functions and Hamilton-Jacobi reachability analysis, providing a framework for further integration of these approaches. We demonstrate that for well-trained barriers we reduce the computational load by 2 orders of magnitude with respect to standard DP-based reachability, and demonstrate scalability to a 6-dimensional system, which is at the limit of standard DP-based reachability. ",
    "url": "https://arxiv.org/abs/2304.09850",
    "authors": [
      "Sander Tonkens",
      "Alex Toofanian",
      "Zhizhen Qin",
      "Sicun Gao",
      "Sylvia Herbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.09855",
    "title": "Generalized Analytical Estimation of Sensitivity Matrices in Unbalanced  Distribution Networks",
    "abstract": "Fast and accurate estimation of sensitivity matrices is significant for the enhancement of distribution system modeling and automation. Analytical estimations have mainly focused on voltage magnitude sensitivity to active/reactive power injections for unbalance networks with Wye-connected loads and neglecting DERs' smart inverter functionality. Hence, this paper enhances the scope of analytical estimation of sensitivity matrices for unbalanced networks with 1-phase, 2-phase, and 3-phase Delta/Wye-connected loads, DERs with smart inverter functionality, and substation/line step-voltage regulators (SVR). A composite bus model comprising of DER, Delta- and Wye-connected load is proposed to represent a generic distribution bus, which can be simplified to load, PV, or voltage-controlled bus as required. The proposed matrix-based analytical method consolidates voltage magnitude and angle sensitivity to active/reactive power injection and tap-position of all SVRs into a single algorithm. Extensive case studies on IEEE networks show the accuracy and wide scope of the proposed algorithm compared to the existing benchmark method. ",
    "url": "https://arxiv.org/abs/2304.09855",
    "authors": [
      "Salish Maharjan",
      "Rui Cheng",
      "Zhaoyu Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.09310",
    "title": "The Adaptive $\u03c4$-Lasso: Its Robustness and Oracle Properties",
    "abstract": "This paper introduces a new regularized version of the robust $\\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the performance of the adaptive $\\tau$-Lasso estimator with that of other competing regularized estimators in terms of prediction and variable selection accuracy in the presence of contamination within the response vector/regression matrix and additive heavy-tailed noise. We observe from our simulations that the class of $\\tau$-Lasso estimators exhibits robustness and reliable performance in both contaminated and uncontaminated data settings, achieving the best or close-to-best for many scenarios, except for oracle estimators. However, it is worth noting that no particular estimator uniformly dominates others. We also validate our findings on robustness properties through simulation experiments. ",
    "url": "https://arxiv.org/abs/2304.09310",
    "authors": [
      "Emadaldin Mozafari-Majd",
      "Visa Koivunen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.09373",
    "title": "Multi-scale Adaptive Fusion Network for Hyperspectral Image Denoising",
    "abstract": "Removing the noise and improving the visual quality of hyperspectral images (HSIs) is challenging in academia and industry. Great efforts have been made to leverage local, global or spectral context information for HSI denoising. However, existing methods still have limitations in feature interaction exploitation among multiple scales and rich spectral structure preservation. In view of this, we propose a novel solution to investigate the HSI denoising using a Multi-scale Adaptive Fusion Network (MAFNet), which can learn the complex nonlinear mapping between clean and noisy HSI. Two key components contribute to improving the hyperspectral image denoising: A progressively multiscale information aggregation network and a co-attention fusion module. Specifically, we first generate a set of multiscale images and feed them into a coarse-fusion network to exploit the contextual texture correlation. Thereafter, a fine fusion network is followed to exchange the information across the parallel multiscale subnetworks. Furthermore, we design a co-attention fusion module to adaptively emphasize informative features from different scales, and thereby enhance the discriminative learning capability for denoising. Extensive experiments on synthetic and real HSI datasets demonstrate that the proposed MAFNet has achieved better denoising performance than other state-of-the-art techniques. Our codes are available at \\verb'https://github.com/summitgao/MAFNet'. ",
    "url": "https://arxiv.org/abs/2304.09373",
    "authors": [
      "Haodong Pan",
      "Feng Gao",
      "Junyu Dong",
      "Qian Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09466",
    "title": "MAMAF-Net: Motion-Aware and Multi-Attention Fusion Network for Stroke  Diagnosis",
    "abstract": "Stroke is a major cause of mortality and disability worldwide from which one in four people are in danger of incurring in their lifetime. The pre-hospital stroke assessment plays a vital role in identifying stroke patients accurately to accelerate further examination and treatment in hospitals. Accordingly, the National Institutes of Health Stroke Scale (NIHSS), Cincinnati Pre-hospital Stroke Scale (CPSS) and Face Arm Speed Time (F.A.S.T.) are globally known tests for stroke assessment. However, the validity of these tests is skeptical in the absence of neurologists. Therefore, in this study, we propose a motion-aware and multi-attention fusion network (MAMAF-Net) that can detect stroke from multimodal examination videos. Contrary to other studies on stroke detection from video analysis, our study for the first time proposes an end-to-end solution from multiple video recordings of each subject with a dataset encapsulating stroke, transient ischemic attack (TIA), and healthy controls. The proposed MAMAF-Net consists of motion-aware modules to sense the mobility of patients, attention modules to fuse the multi-input video data, and 3D convolutional layers to perform diagnosis from the attention-based extracted features. Experimental results over the collected StrokeDATA dataset show that the proposed MAMAF-Net achieves a successful detection of stroke with 93.62% sensitivity and 95.33% AUC score. ",
    "url": "https://arxiv.org/abs/2304.09466",
    "authors": [
      "Aysen Degerli",
      "Pekka Jakala",
      "Juha Pajula",
      "Miguel Bordallo Lopez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09507",
    "title": "Self-supervised Image Denoising with Downsampled Invariance Loss and  Conditional Blind-Spot Network",
    "abstract": "There have been many image denoisers using deep neural networks, which outperform conventional model-based methods by large margins. Recently, self-supervised methods have attracted attention because constructing a large real noise dataset for supervised training is an enormous burden. The most representative self-supervised denoisers are based on blind-spot networks, which exclude the receptive field's center pixel. However, excluding any input pixel is abandoning some information, especially when the input pixel at the corresponding output position is excluded. In addition, a standard blind-spot network fails to reduce real camera noise due to the pixel-wise correlation of noise, though it successfully removes independently distributed synthetic noise. Hence, to realize a more practical denoiser, we propose a novel self-supervised training framework that can remove real noise. For this, we derive the theoretic upper bound of a supervised loss where the network is guided by the downsampled blinded output. Also, we design a conditional blind-spot network (C-BSN), which selectively controls the blindness of the network to use the center pixel information. Furthermore, we exploit a random subsampler to decorrelate noise spatially, making the C-BSN free of visual artifacts that were often seen in downsample-based methods. Extensive experiments show that the proposed C-BSN achieves state-of-the-art performance on real-world datasets as a self-supervised denoiser and shows qualitatively pleasing results without any post-processing or refinement. ",
    "url": "https://arxiv.org/abs/2304.09507",
    "authors": [
      "Yeong Il Jang",
      "Keuntek Lee",
      "Gu Yong Park",
      "Seyun Kim",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09552",
    "title": "Denoising Cosine Similarity: A Theory-Driven Approach for Efficient  Representation Learning",
    "abstract": "Representation learning has been increasing its impact on the research and practice of machine learning, since it enables to learn representations that can apply to various downstream tasks efficiently. However, recent works pay little attention to the fact that real-world datasets used during the stage of representation learning are commonly contaminated by noise, which can degrade the quality of learned representations. This paper tackles the problem to learn robust representations against noise in a raw dataset. To this end, inspired by recent works on denoising and the success of the cosine-similarity-based objective functions in representation learning, we propose the denoising Cosine-Similarity (dCS) loss. The dCS loss is a modified cosine-similarity loss and incorporates a denoising property, which is supported by both our theoretical and empirical findings. To make the dCS loss implementable, we also construct the estimators of the dCS loss with statistical guarantees. Finally, we empirically show the efficiency of the dCS loss over the baseline objective functions in vision and speech domains. ",
    "url": "https://arxiv.org/abs/2304.09552",
    "authors": [
      "Takumi Nakagawa",
      "Yutaro Sanada",
      "Hiroki Waida",
      "Yuhui Zhang",
      "Yuichiro Wada",
      "K\u014dsaku Takanashi",
      "Tomonori Yamada",
      "Takafumi Kanamori"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09576",
    "title": "Leveraging the two timescale regime to demonstrate convergence of neural  networks",
    "abstract": "We study the training dynamics of shallow neural networks, in a two-timescale regime in which the stepsizes for the inner layer are much smaller than those for the outer layer. In this regime, we prove convergence of the gradient flow to a global optimum of the non-convex optimization problem in a simple univariate setting. The number of neurons need not be asymptotically large for our result to hold, distinguishing our result from popular recent approaches such as the neural tangent kernel or mean-field regimes. Experimental illustration is provided, showing that the stochastic gradient descent behaves according to our description of the gradient flow and thus converges to a global optimum in the two-timescale regime, but can fail outside of this regime. ",
    "url": "https://arxiv.org/abs/2304.09576",
    "authors": [
      "Pierre Marion",
      "Rapha\u00ebl Berthier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09620",
    "title": "DCELANM-Net:Medical Image Segmentation based on Dual Channel Efficient  Layer Aggregation Network with Learner",
    "abstract": "The DCELANM-Net structure, which this article offers, is a model that ingeniously combines a Dual Channel Efficient Layer Aggregation Network (DCELAN) and a Micro Masked Autoencoder (Micro-MAE). On the one hand, for the DCELAN, the features are more effectively fitted by deepening the network structure; the deeper network can successfully learn and fuse the features, which can more accurately locate the local feature information; and the utilization of each layer of channels is more effectively improved by widening the network structure and residual connections. We adopted Micro-MAE as the learner of the model. In addition to being straightforward in its methodology, it also offers a self-supervised learning method, which has the benefit of being incredibly scaleable for the model. ",
    "url": "https://arxiv.org/abs/2304.09620",
    "authors": [
      "Chengzhun Lu",
      "Zhangrun Xia",
      "Krzysztof Przystupa",
      "Orest Kochan",
      "Jun Su"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09679",
    "title": "Sparse graphs without long induced paths",
    "abstract": "Graphs of bounded degeneracy are known to contain induced paths of order $\\Omega(\\log \\log n)$ when they contain a path of order $n$, as proved by Ne\\v{s}et\\v{r}il and Ossona de Mendez (2012). In 2016 Esperet, Lemoine, and Maffray conjectured that this bound could be improved to $\\Omega((\\log n)^c)$ for some constant $c>0$ depending on the degeneracy. We disprove this conjecture by constructing, for arbitrarily large values of $n$, a graph that is 2-degenerate, has a path of order $n$, and where all induced paths have order $O((\\log \\log n)^2)$. We also show that the graphs we construct have linearly bounded coloring numbers. ",
    "url": "https://arxiv.org/abs/2304.09679",
    "authors": [
      "Oscar Defrain",
      "Jean-Florent Raymond"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.09701",
    "title": "On the complexity of Dominating Set for graphs with fixed diameter",
    "abstract": "A set $S\\subseteq V$ of a graph $G=(V,E)$ is a dominating set if each vertex has a neighbor in $S$ or belongs to $S$. Dominating Set is the problem of deciding, given a graph $G$ and an integer $k\\geq 1$, if $G$ has a dominating set of size at most $k$. It is well known that this problem is $\\mathsf{NP}$-complete even for claw-free graphs. We give a complexity dichotomy for Dominating Set for the class of claw-free graphs with diameter $d$. We show that the problem is $\\mathsf{NP}$-complete for every fixed $d\\ge 3$ and polynomial time solvable for $d\\le 2$. To prove the case $d=2$, we show that Minimum Maximal Matching can be solved in polynomial time for $2K_2$-free graphs. ",
    "url": "https://arxiv.org/abs/2304.09701",
    "authors": [
      "Valentin Bouquet",
      "Fran\u00e7ois Delbot",
      "Christophe Picouleau",
      "St\u00e9phane Rovedakis"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.09750",
    "title": "Application of Tensor Neural Networks to Pricing Bermudan Swaptions",
    "abstract": "The Cheyette model is a quasi-Gaussian volatility interest rate model widely used to price interest rate derivatives such as European and Bermudan Swaptions for which Monte Carlo simulation has become the industry standard. In low dimensions, these approaches provide accurate and robust prices for European Swaptions but, even in this computationally simple setting, they are known to underestimate the value of Bermudan Swaptions when using the state variables as regressors. This is mainly due to the use of a finite number of predetermined basis functions in the regression. Moreover, in high-dimensional settings, these approaches succumb to the Curse of Dimensionality. To address these issues, Deep-learning techniques have been used to solve the backward Stochastic Differential Equation associated with the value process for European and Bermudan Swaptions; however, these methods are constrained by training time and memory. To overcome these limitations, we propose leveraging Tensor Neural Networks as they can provide significant parameter savings while attaining the same accuracy as classical Dense Neural Networks. In this paper we rigorously benchmark the performance of Tensor Neural Networks and Dense Neural Networks for pricing European and Bermudan Swaptions, and we show that Tensor Neural Networks can be trained faster than Dense Neural Networks and provide more accurate and robust prices than their Dense counterparts. ",
    "url": "https://arxiv.org/abs/2304.09750",
    "authors": [
      "Raj G. Patel",
      "Tomas Dominguez",
      "Mohammad Dib",
      "Samuel Palmer",
      "Andrea Cadarso",
      "Fernando De Lope Contreras",
      "Abdelkader Ratnani",
      "Francisco Gomez Casanova",
      "Senaida Hern\u00e1ndez-Santana",
      "\u00c1lvaro D\u00edaz-Fern\u00e1ndez",
      "Eva Andr\u00e9s",
      "Jorge Luis-Hita",
      "Escol\u00e1stico S\u00e1nchez-Mart\u00ednez",
      "Samuel Mugel",
      "Roman Orus"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2304.09783",
    "title": "Application of attention-based Siamese composite neural network in  medical image recognition",
    "abstract": "Medical image recognition often faces the problem of insufficient data in practical applications. Image recognition and processing under few-shot conditions will produce overfitting, low recognition accuracy, low reliability and insufficient robustness. It is often the case that the difference of characteristics is subtle, and the recognition is affected by perspectives, background, occlusion and other factors, which increases the difficulty of recognition. Furthermore, in fine-grained images, the few-shot problem leads to insufficient useful feature information in the images. Considering the characteristics of few-shot and fine-grained image recognition, this study has established a recognition model based on attention and Siamese neural network. Aiming at the problem of few-shot samples, a Siamese neural network suitable for classification model is proposed. The Attention-Based neural network is used as the main network to improve the classification effect. Covid- 19 lung samples have been selected for testing the model. The results show that the less the number of image samples are, the more obvious the advantage shows than the ordinary neural network. ",
    "url": "https://arxiv.org/abs/2304.09783",
    "authors": [
      "Zihao Huang",
      "Xia Chen",
      "Yue Wang",
      "Weixing Xin",
      "Xingtong Lin",
      "Huizhen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2002.06653",
    "title": "Directed Graph Hashing",
    "abstract": " Comments: To be submitted to Algorithmica. Earlier version of paper presented at 51st Southeastern International Conference on Combinatorics, Graph Theory & Computing but was not published in conference proceedings ",
    "url": "https://arxiv.org/abs/2002.06653",
    "authors": [
      "Caleb Helbling"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2003.06267",
    "title": "Causal Unfoldings and Disjunctive Causes",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1607.03747 ",
    "url": "https://arxiv.org/abs/2003.06267",
    "authors": [
      "Marc de Visme",
      "Glynn Winskel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2010.06154",
    "title": "An Analysis of Robustness of Non-Lipschitz Networks",
    "abstract": " Comments: To appear in Journal of Machine Learning Research (JMLR) ",
    "url": "https://arxiv.org/abs/2010.06154",
    "authors": [
      "Maria-Florina Balcan",
      "Avrim Blum",
      "Dravyansh Sharma",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.07217",
    "title": "Influential Rank: A New Perspective of Post-training for Robust Model  against Noisy Labels",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2106.07217",
    "authors": [
      "Seulki Park",
      "Hwanjun Song",
      "Daeho Um",
      "Dae Ung Jo",
      "Sangdoo Yun",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.06126",
    "title": "Control of Dual-Sourcing Inventory Systems using Recurrent Neural  Networks",
    "abstract": " Comments: 54 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2201.06126",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Thomas Asikis",
      "Ioannis Fragkos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2204.03740",
    "title": "Successes and critical failures of neural networks in capturing  human-like speech recognition",
    "abstract": " Title: Successes and critical failures of neural networks in capturing  human-like speech recognition ",
    "url": "https://arxiv.org/abs/2204.03740",
    "authors": [
      "Federico Adolfi",
      "Jeffrey S. Bowers",
      "David Poeppel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2205.11331",
    "title": "Networked Sensing with AI-Empowered Interference Management: Exploiting  Macro-Diversity and Array Gain in Perceptive Mobile Networks",
    "abstract": " Title: Networked Sensing with AI-Empowered Interference Management: Exploiting  Macro-Diversity and Array Gain in Perceptive Mobile Networks ",
    "url": "https://arxiv.org/abs/2205.11331",
    "authors": [
      "Lei Xie",
      "Shenghui Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.00052",
    "title": "CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming  Language Models",
    "abstract": " Comments: AAAI Conference on Artificial Intelligence (AAAI) 2023 ",
    "url": "https://arxiv.org/abs/2206.00052",
    "authors": [
      "Akshita Jha",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03799",
    "title": "Dyna-DM: Dynamic Object-aware Self-supervised Monocular Depth Maps",
    "abstract": " Title: Dyna-DM: Dynamic Object-aware Self-supervised Monocular Depth Maps ",
    "url": "https://arxiv.org/abs/2206.03799",
    "authors": [
      "Kieran Saunders",
      "George Vogiatzis",
      "Luis J. Manso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.04011",
    "title": "Robust Semantic Communications with Masked VQ-VAE Enabled Codebook",
    "abstract": " Comments: 16 pages, 11 figures. arXiv admin note: text overlap with arXiv:2202.03338 ",
    "url": "https://arxiv.org/abs/2206.04011",
    "authors": [
      "Qiyu Hu",
      "Guangyi Zhang",
      "Zhijin Qin",
      "Yunlong Cai",
      "Guanding Yu",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.09326",
    "title": "Toward Robust Manufacturing Scheduling: Stochastic Job-Shop Scheduling",
    "abstract": " Title: Toward Robust Manufacturing Scheduling: Stochastic Job-Shop Scheduling ",
    "url": "https://arxiv.org/abs/2206.09326",
    "authors": [
      "Mikhail A. Bragin",
      "Matthew E. Wilhelm",
      "Nanpeng Yu",
      "Matthew D. Stuber"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2207.01450",
    "title": "Discourse-Aware Graph Networks for Textual Logical Reasoning",
    "abstract": " Title: Discourse-Aware Graph Networks for Textual Logical Reasoning ",
    "url": "https://arxiv.org/abs/2207.01450",
    "authors": [
      "Yinya Huang",
      "Lemao Liu",
      "Kun Xu",
      "Meng Fang",
      "Liang Lin",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03578",
    "title": "Code Translation with Compiler Representations",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2207.03578",
    "authors": [
      "Marc Szafraniec",
      "Baptiste Roziere",
      "Hugh Leather",
      "Francois Charton",
      "Patrick Labatut",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05072",
    "title": "An On-demand Photonic Ising Machine with Simplified Hamiltonian  Calculation by Phase-encoding and Intensity Detection",
    "abstract": " Title: An On-demand Photonic Ising Machine with Simplified Hamiltonian  Calculation by Phase-encoding and Intensity Detection ",
    "url": "https://arxiv.org/abs/2207.05072",
    "authors": [
      "Jiayi Ouyang",
      "Yuxuan Liao",
      "Zhiyao Ma",
      "Deyang Kong",
      "Xue Feng",
      "Xiang Zhang",
      "Xiaowen Dong",
      "Kaiyu Cui",
      "Fang Liu",
      "Wei Zhang",
      "Yidong Huang"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2207.08409",
    "title": "TokenMix: Rethinking Image Mixing for Data Augmentation in Vision  Transformers",
    "abstract": " Comments: ECCV 2022; Code: this https URL ",
    "url": "https://arxiv.org/abs/2207.08409",
    "authors": [
      "Jihao Liu",
      "Boxiao Liu",
      "Hang Zhou",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10367",
    "title": "EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless  Machine Learning Integration",
    "abstract": " Comments: 6 pages, 1 figure, 1 table. Published in Elsevier SoftwareX ",
    "url": "https://arxiv.org/abs/2207.10367",
    "authors": [
      "Moshe Sipper",
      "Tomer Halperin",
      "Itai Tzruia",
      "Achiya Elyasaf"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06948",
    "title": "An Automated Process for 2D and 3D Finite Element Overclosure and Gap  Adjustment using Radial Basis Function Networks",
    "abstract": " Comments: 26 Pages, 5 Figures, 2 Tables ",
    "url": "https://arxiv.org/abs/2209.06948",
    "authors": [
      "Thor E. Andreassen",
      "Donald R. Hume",
      "Landon D. Hamilton",
      "Sean E. Higinbotham",
      "Kevin B. Shelburne"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.06386",
    "title": "Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper  Directly-Trained Spiking Neural Networks",
    "abstract": " Comments: Accepted by the Thirty-First International Joint Conference on Artificial Intelligence (IJCAI-22) ",
    "url": "https://arxiv.org/abs/2210.06386",
    "authors": [
      "Lang Feng",
      "Qianhui Liu",
      "Huajin Tang",
      "De Ma",
      "Gang Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06466",
    "title": "Prompt Generation Networks for Input-based Adaptation of Frozen Vision  Transformers",
    "abstract": " Comments: Tech report, 12 pages. Code: this https URL ",
    "url": "https://arxiv.org/abs/2210.06466",
    "authors": [
      "Jochem Loedeman",
      "Maarten C. Stol",
      "Tengda Han",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09721",
    "title": "An incremental input-to-state stability condition for a generic class of  recurrent neural networks",
    "abstract": " Title: An incremental input-to-state stability condition for a generic class of  recurrent neural networks ",
    "url": "https://arxiv.org/abs/2210.09721",
    "authors": [
      "William D'Amico",
      "Alessio La Bella",
      "Marcello Farina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.13605",
    "title": "GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online  Action Prediction",
    "abstract": " Comments: Accepted to WACV 2023 ",
    "url": "https://arxiv.org/abs/2210.13605",
    "authors": [
      "Samrudhdhi B Rangrej",
      "Kevin J Liang",
      "Tal Hassner",
      "James J Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.17495",
    "title": "Automated Code Extraction from Discussion Board Text Dataset",
    "abstract": " Comments: LaTeX; typos corrected at page 6 ",
    "url": "https://arxiv.org/abs/2210.17495",
    "authors": [
      "Sina Mahdipour Saravani",
      "Sadaf Ghaffari",
      "Yanye Luther",
      "James Folkestad",
      "Marcia Moraes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.00608",
    "title": "ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds",
    "abstract": " Title: ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds ",
    "url": "https://arxiv.org/abs/2211.00608",
    "authors": [
      "Taha Entesari",
      "Sina Sharifi",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11191",
    "title": "Correlative Preference Transfer with Hierarchical Hypergraph Network for  Multi-Domain Recommendation",
    "abstract": " Comments: Accepted by WWW 2023 research track. The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2211.11191",
    "authors": [
      "Zixuan Xu",
      "Penghui Wei",
      "Shaoguo Liu",
      "Weimin Zhang",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.16960",
    "title": "BASiS: Batch Aligned Spectral Embedding Space",
    "abstract": " Comments: 14 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2211.16960",
    "authors": [
      "Or Streicher",
      "Ido Cohen",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.02703",
    "title": "RUPNet: Residual upsampling network for real-time polyp segmentation",
    "abstract": " Comments: Accepted SPIE Medical Imaging 2023 ",
    "url": "https://arxiv.org/abs/2301.02703",
    "authors": [
      "Nikhil Kumar Tomar",
      "Ulas Bagci",
      "Debesh Jha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04956",
    "title": "Graph Laplacian for Semi-Supervised Learning",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2301.04956",
    "authors": [
      "Or Streicher",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.03654",
    "title": "A Privacy-Preserving Hybrid Federated Learning Framework for Financial  Crime Detection",
    "abstract": " Comments: PETs prize challenge version ",
    "url": "https://arxiv.org/abs/2302.03654",
    "authors": [
      "Haobo Zhang",
      "Junyuan Hong",
      "Fan Dong",
      "Steve Drew",
      "Liangjie Xue",
      "Jiayu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04544",
    "title": "GMConv: Modulating Effective Receptive Fields for Convolutional Kernels",
    "abstract": " Comments: 10 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.04544",
    "authors": [
      "Qi Chen",
      "Chao Li",
      "Jia Ning",
      "Stephen Lin",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.08274",
    "title": "Robust Human Motion Forecasting using Transformer-based Model",
    "abstract": " Comments: This paper has been already accepted to the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022) ",
    "url": "https://arxiv.org/abs/2302.08274",
    "authors": [
      "Esteve Valls Mascaro",
      "Shuo Ma",
      "Hyemin Ahn",
      "Dongheui Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08767",
    "title": "Highly Personalized Text Embedding for Image Manipulation by Stable  Diffusion",
    "abstract": " Title: Highly Personalized Text Embedding for Image Manipulation by Stable  Diffusion ",
    "url": "https://arxiv.org/abs/2303.08767",
    "authors": [
      "Inhwa Han",
      "Serin Yang",
      "Taesung Kwon",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16628",
    "title": "DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object  Detection and Tracking",
    "abstract": " Title: DORT: Modeling Dynamic Objects in Recurrent for Multi-Camera 3D Object  Detection and Tracking ",
    "url": "https://arxiv.org/abs/2303.16628",
    "authors": [
      "Qing Lian",
      "Tai Wang",
      "Dahua Lin",
      "Jiangmiao Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.00215",
    "title": "Inductive Relation Prediction from Relational Paths and Context with  Hierarchical Transformers",
    "abstract": " Comments: Accepted by ICASSP 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2304.00215",
    "authors": [
      "Jiaang Li",
      "Quan Wang",
      "Zhendong Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.02451",
    "title": "Adaptive Data Augmentation for Contrastive Learning",
    "abstract": " Comments: Accepted by ICASSP 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2304.02451",
    "authors": [
      "Yuhan Zhang",
      "He Zhu",
      "Shan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04455",
    "title": "Bayesian optimization for sparse neural networks with trainable  activation functions",
    "abstract": " Title: Bayesian optimization for sparse neural networks with trainable  activation functions ",
    "url": "https://arxiv.org/abs/2304.04455",
    "authors": [
      "Mohamed Fakhfakh",
      "Lotfi Chaari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2304.05055",
    "title": "A Comprehensive Survey on Deep Graph Representation Learning",
    "abstract": " Title: A Comprehensive Survey on Deep Graph Representation Learning ",
    "url": "https://arxiv.org/abs/2304.05055",
    "authors": [
      "Wei Ju",
      "Zheng Fang",
      "Yiyang Gu",
      "Zequn Liu",
      "Qingqing Long",
      "Ziyue Qiao",
      "Yifang Qin",
      "Jianhao Shen",
      "Fang Sun",
      "Zhiping Xiao",
      "Junwei Yang",
      "Jingyang Yuan",
      "Yusheng Zhao",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.06326",
    "title": "Understanding Overfitting in Adversarial Training via Kernel Regression",
    "abstract": " Title: Understanding Overfitting in Adversarial Training via Kernel Regression ",
    "url": "https://arxiv.org/abs/2304.06326",
    "authors": [
      "Teng Zhang",
      "Kang Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2304.06930",
    "title": "Self-Supervised Scene Dynamic Recovery from Rolling Shutter Images and  Events",
    "abstract": " Title: Self-Supervised Scene Dynamic Recovery from Rolling Shutter Images and  Events ",
    "url": "https://arxiv.org/abs/2304.06930",
    "authors": [
      "Yangguang Wang",
      "Xiang Zhang",
      "Mingyuan Lin",
      "Lei Yu",
      "Boxin Shi",
      "Wen Yang",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07655",
    "title": "EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking  Neural Networks",
    "abstract": " Comments: This article has been withdrawn due to an internal dispute ",
    "url": "https://arxiv.org/abs/2304.07655",
    "authors": [
      "Xi Chen",
      "Siwei Mai",
      "Konstantinos Michmizos"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.07907",
    "title": "Analyzing Activity and Suspension Patterns of Twitter Bots Attacking  Turkish Twitter Trends by a Longitudinal Dataset",
    "abstract": " Comments: Accepted to Cyber Social Threats (CySoc) 2023 colocated with WebConf23 ",
    "url": "https://arxiv.org/abs/2304.07907",
    "authors": [
      "Tu\u011frulcan Elmas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.08767",
    "title": "Masked Language Model Based Textual Adversarial Example Detection",
    "abstract": " Comments: 13 pages,3 figures ",
    "url": "https://arxiv.org/abs/2304.08767",
    "authors": [
      "Xiaomei Zhang",
      "Zhaoxi Zhang",
      "Qi Zhong",
      "Xufei Zheng",
      "Yanjun Zhang",
      "Shengshan Hu",
      "Leo Yu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08799",
    "title": "Self-Supervised 3D Action Representation Learning with Skeleton Cloud  Colorization",
    "abstract": " Comments: This work is an extension of our ICCV 2021 paper [arXiv:2108.01959] this https URL ",
    "url": "https://arxiv.org/abs/2304.08799",
    "authors": [
      "Siyuan Yang",
      "Jun Liu",
      "Shijian Lu",
      "Er Meng Hwa",
      "Yongjian Hu",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08805",
    "title": "Implicit representation priors meet Riemannian geometry for Bayesian  robotic grasping",
    "abstract": " Comments: 4 pages, 5 figures, submitted to the workshop Geometric Representations at ICRA 2023 ",
    "url": "https://arxiv.org/abs/2304.08805",
    "authors": [
      "Norman Marlier",
      "Julien Gustin",
      "Olivier Br\u00fcls",
      "Gilles Louppe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.08996",
    "title": "Energy-Efficient Design of STAR-RIS Aided MIMO-NOMA Networks",
    "abstract": " Title: Energy-Efficient Design of STAR-RIS Aided MIMO-NOMA Networks ",
    "url": "https://arxiv.org/abs/2304.08996",
    "authors": [
      "Fang Fang",
      "Bibo Wu",
      "Shu Fu",
      "Zhiguo Ding",
      "Xianbin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2304.09010",
    "title": "CF-VAE: Causal Disentangled Representation Learning with VAE and Causal  Flows",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.09010",
    "authors": [
      "Di Fan",
      "Yannian Kou",
      "Chuanhou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  }
]