[
  {
    "id": "arXiv:2301.11929",
    "title": "Training Full Spike Neural Networks via Auxiliary Accumulation Pathway",
    "abstract": "Due to the binary spike signals making converting the traditional high-power multiply-accumulation (MAC) into a low-power accumulation (AC) available, the brain-inspired Spiking Neural Networks (SNNs) are gaining more and more attention. However, the binary spike propagation of the Full-Spike Neural Networks (FSNN) with limited time steps is prone to significant information loss. To improve performance, several state-of-the-art SNN models trained from scratch inevitably bring many non-spike operations. The non-spike operations cause additional computational consumption and may not be deployed on some neuromorphic hardware where only spike operation is allowed. To train a large-scale FSNN with high performance, this paper proposes a novel Dual-Stream Training (DST) method which adds a detachable Auxiliary Accumulation Pathway (AAP) to the full spiking residual networks. The accumulation in AAP could compensate for the information loss during the forward and backward of full spike propagation, and facilitate the training of the FSNN. In the test phase, the AAP could be removed and only the FSNN remained. This not only keeps the lower energy consumption but also makes our model easy to deploy. Moreover, for some cases where the non-spike operations are available, the APP could also be retained in test inference and improve feature discrimination by introducing a little non-spike consumption. Extensive experiments on ImageNet, DVS Gesture, and CIFAR10-DVS datasets demonstrate the effectiveness of DST. ",
    "url": "https://arxiv.org/abs/2301.11929",
    "authors": [
      "Guangyao Chen",
      "Peixi Peng",
      "Guoqi Li",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11956",
    "title": "On the Connection Between MPNN and Graph Transformer",
    "abstract": "Graph Transformer (GT) recently has emerged as a new paradigm of graph learning algorithms, outperforming the previously popular Message Passing Neural Network (MPNN) on multiple benchmarks. Previous work (Kim et al., 2022) shows that with proper position embedding, GT can approximate MPNN arbitrarily well, implying that GT is at least as powerful as MPNN. In this paper, we study the inverse connection and show that MPNN with virtual node (VN), a commonly used heuristic with little theoretical understanding, is powerful enough to arbitrarily approximate the self-attention layer of GT. In particular, we first show that if we consider one type of linear transformer, the so-called Performer/Linear Transformer (Choromanski et al., 2020; Katharopoulos et al., 2020), then MPNN + VN with only O(1) depth and O(1) width can approximate a self-attention layer in Performer/Linear Transformer. Next, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN with O(n^d) width and O(1) depth can approximate the self-attention layer arbitrarily well, where d is the input feature dimension. Lastly, under some assumptions, we provide an explicit construction of MPNN + VN with O(1) width and O(n) depth approximating the self-attention layer in GT arbitrarily well. On the empirical side, we demonstrate that 1) MPNN + VN is a surprisingly strong baseline, outperforming GT on the recently proposed Long Range Graph Benchmark (LRGB) dataset, 2) our MPNN + VN improves over early implementation on a wide range of OGB datasets and 3) MPNN + VN outperforms Linear Transformer and MPNN on the climate modeling task. ",
    "url": "https://arxiv.org/abs/2301.11956",
    "authors": [
      "Chen Cai",
      "Truong Son Hy",
      "Rose Yu",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11964",
    "title": "Adversarial Networks and Machine Learning for File Classification",
    "abstract": "Correctly identifying the type of file under examination is a critical part of a forensic investigation. The file type alone suggests the embedded content, such as a picture, video, manuscript, spreadsheet, etc. In cases where a system owner might desire to keep their files inaccessible or file type concealed, we propose using an adversarially-trained machine learning neural network to determine a file's true type even if the extension or file header is obfuscated to complicate its discovery. Our semi-supervised generative adversarial network (SGAN) achieved 97.6% accuracy in classifying files across 11 different types. We also compared our network against a traditional standalone neural network and three other machine learning algorithms. The adversarially-trained network proved to be the most precise file classifier especially in scenarios with few supervised samples available. Our implementation of a file classifier using an SGAN is implemented on GitHub (https://ksaintg.github.io/SGAN-File-Classier). ",
    "url": "https://arxiv.org/abs/2301.11964",
    "authors": [
      "Ken St. Germain",
      "Josh Angichiodo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11972",
    "title": "Using Social Cues to Recognize Task Failures for HRI: A Review of  Current Research and Future Directions",
    "abstract": "Robots that carry out tasks and interact in complex environments will inevitably commit errors. Error detection is thus an important ability for robots to master, to work in an efficient and productive way. People leverage social cues from others around them to recognize and repair their own mistakes. With advances in computing and AI, it is increasingly possible for robots to achieve a similar error detection capability. In this work, we review current literature around the topic of how social cues can be used to recognize task failures for human-robot interaction (HRI). This literature review unites insights from behavioral science, human-robot interaction, and machine learning, to focus on three areas: 1) social cues for error detection (from behavioral science), 2) recognizing task failures in robots (from HRI), and 3) approaches for autonomous detection of HRI task failures based on social cues (from machine learning). We propose a taxonomy of error detection based on self-awareness and social feedback. Finally, we leave recommendations for HRI researchers and practitioners interested in developing robots that detect (physical) task errors using social cues from bystanders. ",
    "url": "https://arxiv.org/abs/2301.11972",
    "authors": [
      "Alexandra Bremers",
      "Alexandria Pabst",
      "Maria Teresa Parreira",
      "Wendy Ju"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.11986",
    "title": "FRA: A novel Face Representation Augmentation algorithm for face  recognition",
    "abstract": "A low amount of training data for many state-of-the-art deep learning-based Face Recognition (FR) systems causes a marked deterioration in their performance. Although a considerable amount of research has addressed this issue by inventing new data augmentation techniques, using either input space transformations or Generative Adversarial Networks (GAN) for feature space augmentations, these techniques have yet to satisfy expectations. In this paper, we propose a novel method, named the Face Representation Augmentation (FRA) algorithm, for augmenting face datasets. To the best of our knowledge, FRA is the first method that shifts its focus towards manipulating the face embeddings generated by any face representation learning algorithm in order to generate new embeddings representing the same identity and facial emotion but with an altered posture. Extensive experiments conducted in this study convince the efficacy of our methodology and its power to provide noiseless, completely new facial representations to improve the training procedure of any FR algorithm. Therefore, FRA is able to help the recent state-of-the-art FR methods by providing more data for training FR systems. The proposed method, using experiments conducted on the Karolinska Directed Emotional Faces (KDEF) dataset, improves the identity classification accuracies by 9.52 %, 10.04 %, and 16.60 %, in comparison with the base models of MagFace, ArcFace, and CosFace, respectively. ",
    "url": "https://arxiv.org/abs/2301.11986",
    "authors": [
      "Soroush Hashemifar",
      "Abdolreza Marefat",
      "Javad Hassannataj Joloudari",
      "Hamid Hassanpour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11988",
    "title": "Energy-Efficient Distributed Algorithms for Synchronous Networks",
    "abstract": "We study the design of energy-efficient algorithms for the LOCAL and CONGEST models. Specifically, as a measure of complexity, we consider the maximum, taken over all the edges, or over all the nodes, of the number of rounds at which an edge, or a node, is active in the algorithm. We first show that every Turing-computable problem has a CONGEST algorithm with constant node-activation complexity, and therefore constant edge-activation complexity as well. That is, every node (resp., edge) is active in sending (resp., transmitting) messages for only $O(1)$ rounds during the whole execution of the algorithm. In other words, every Turing-computable problem can be solved by an algorithm consuming the least possible energy. In the LOCAL model, the same holds obviously, but with the additional feature that the algorithm runs in $O(\\mbox{poly}(n))$ rounds in $n$-node networks. However, we show that insisting on algorithms running in $O(\\mbox{poly}(n))$ rounds in the CONGEST model comes with a severe cost in terms of energy. Namely, there are problems requiring $\\Omega(\\mbox{poly}(n))$ edge-activations (and thus $\\Omega(\\mbox{poly}(n))$ node-activations as well) in the CONGEST model whenever solved by algorithms bounded to run in $O(\\mbox{poly}(n))$ rounds. Finally, we demonstrate the existence of a sharp separation between the edge-activation complexity and the node-activation complexity in the CONGEST model, for algorithms bounded to run in $O(\\mbox{poly}(n))$ rounds. Specifically, under this constraint, there is a problem with $O(1)$ edge-activation complexity but $\\tilde{\\Omega}(n^{1/4})$ node-activation complexity. ",
    "url": "https://arxiv.org/abs/2301.11988",
    "authors": [
      "Pierre Fraigniaud",
      "Pedro Montealegre",
      "Ivan Rapaport",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.11990",
    "title": "Alignment with human representations supports robust few-shot learning",
    "abstract": "Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well. ",
    "url": "https://arxiv.org/abs/2301.11990",
    "authors": [
      "Ilia Sucholutsky",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11998",
    "title": "Augmented Reality's Potential for Identifying and Mitigating Home  Privacy Leaks",
    "abstract": "Users face various privacy risks in smart homes, yet there are limited ways for them to learn about the details of such risks, such as the data practices of smart home devices and their data flow. In this paper, we present Privacy Plumber, a system that enables a user to inspect and explore the privacy \"leaks\" in their home using an augmented reality tool. Privacy Plumber allows the user to learn and understand the volume of data leaving the home and how that data may affect a user's privacy -- in the same physical context as the devices in question, because we visualize the privacy leaks with augmented reality. Privacy Plumber uses ARP spoofing to gather aggregate network traffic information and presents it through an overlay on top of the device in an smartphone app. The increased transparency aims to help the user make privacy decisions and mend potential privacy leaks, such as instruct Privacy Plumber on what devices to block, on what schedule (i.e., turn off Alexa when sleeping), etc. Our initial user study with six participants demonstrates participants' increased awareness of privacy leaks in smart devices, which further contributes to their privacy decisions (e.g., which devices to block). ",
    "url": "https://arxiv.org/abs/2301.11998",
    "authors": [
      "Stefany Cruz",
      "Logan Danek",
      "Shinan Liu",
      "Christopher Kraemer",
      "Zixin Wang",
      "Nick Feamster",
      "Danny Yuxing Huang",
      "Yaxing Yao",
      "Josiah Hester"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12001",
    "title": "Vertex-based reachability analysis for verifying ReLU deep neural  networks",
    "abstract": "Neural networks achieved high performance over different tasks, i.e. image identification, voice recognition and other applications. Despite their success, these models are still vulnerable regarding small perturbations, which can be used to craft the so-called adversarial examples. Different approaches have been proposed to circumvent their vulnerability, including formal verification systems, which employ a variety of techniques, including reachability, optimization and search procedures, to verify that the model satisfies some property. In this paper we propose three novel reachability algorithms for verifying deep neural networks with ReLU activations. The first and third algorithms compute an over-approximation for the reachable set, whereas the second one computes the exact reachable set. Differently from previously proposed approaches, our algorithms take as input a V-polytope. Our experiments on the ACAS Xu problem show that the Exact Polytope Network Mapping (EPNM) reachability algorithm proposed in this work surpass the state-of-the-art results from the literature, specially in relation to other reachability methods. ",
    "url": "https://arxiv.org/abs/2301.12001",
    "authors": [
      "Jo\u00e3o Zago",
      "Eduardo Camponogara",
      "Eric Antonelo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12006",
    "title": "Improved knowledge distillation by utilizing backward pass knowledge in  neural networks",
    "abstract": "Knowledge distillation (KD) is one of the prominent techniques for model compression. In this method, the knowledge of a large network (teacher) is distilled into a model (student) with usually significantly fewer parameters. KD tries to better-match the output of the student model to that of the teacher model based on the knowledge extracts from the forward pass of the teacher network. Although conventional KD is effective for matching the two networks over the given data points, there is no guarantee that these models would match in other areas for which we do not have enough training samples. In this work, we address that problem by generating new auxiliary training samples based on extracting knowledge from the backward pass of the teacher in the areas where the student diverges greatly from the teacher. We compute the difference between the teacher and the student and generate new data samples that maximize the divergence. This is done by perturbing data samples in the direction of the gradient of the difference between the student and the teacher. Augmenting the training set by adding this auxiliary improves the performance of KD significantly and leads to a closer match between the student and the teacher. Using this approach, when data samples come from a discrete domain, such as applications of natural language processing (NLP) and language understanding, is not trivial. However, we show how this technique can be used successfully in such applications. We evaluated the performance of our method on various tasks in computer vision and NLP domains and got promising results. ",
    "url": "https://arxiv.org/abs/2301.12006",
    "authors": [
      "Aref Jafari",
      "Mehdi Rezagholizadeh",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12012",
    "title": "In-Distribution Barrier Functions: Self-Supervised Policy Filters that  Avoid Out-of-Distribution States",
    "abstract": "Learning-based control approaches have shown great promise in performing complex tasks directly from high-dimensional perception data for real robotic systems. Nonetheless, the learned controllers can behave unexpectedly if the trajectories of the system divert from the training data distribution, which can compromise safety. In this work, we propose a control filter that wraps any reference policy and effectively encourages the system to stay in-distribution with respect to offline-collected safe demonstrations. Our methodology is inspired by Control Barrier Functions (CBFs), which are model-based tools from the nonlinear control literature that can be used to construct minimally invasive safe policy filters. While existing methods based on CBFs require a known low-dimensional state representation, our proposed approach is directly applicable to systems that rely solely on high-dimensional visual observations by learning in a latent state-space. We demonstrate that our method is effective for two different visuomotor control tasks in simulation environments, including both top-down and egocentric view settings. ",
    "url": "https://arxiv.org/abs/2301.12012",
    "authors": [
      "Fernando Casta\u00f1eda",
      "Haruki Nishimura",
      "Rowan McAllister",
      "Koushil Sreenath",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12013",
    "title": "Cybersecurity Threat Hunting and Vulnerability Analysis Using a Neo4j  Graph Database of Open Source Intelligence",
    "abstract": "Open source intelligence is a powerful tool for cybersecurity analysts to gather information both for analysis of discovered vulnerabilities and for detecting novel cybersecurity threats and exploits. However the scale of information that is relevant for information security on the internet is always increasing, and is intractable for analysts to parse comprehensively. Therefore methods of condensing the available open source intelligence, and automatically developing connections between disparate sources of information, is incredibly valuable. In this research, we present a system which constructs a Neo4j graph database formed by shared connections between open source intelligence text including blogs, cybersecurity bulletins, news sites, antivirus scans, social media posts (e.g., Reddit and Twitter), and threat reports. These connections are comprised of possible indicators of compromise (e.g., IP addresses, domains, hashes, email addresses, phone numbers), information on known exploits and techniques (e.g., CVEs and MITRE ATT&CK Technique ID's), and potential sources of information on cybersecurity exploits such as twitter usernames. The construction of the database of potential IoCs is detailed, including the addition of machine learning and metadata which can be used for filtering of the data for a specific domain (for example a specific natural language) when needed. Examples of utilizing the graph database for querying connections between known malicious IoCs and open source intelligence documents, including threat reports, are shown. We show that this type of relationship querying can allow for more effective use of open source intelligence for threat hunting, malware family clustering, and vulnerability analysis. ",
    "url": "https://arxiv.org/abs/2301.12013",
    "authors": [
      "Elijah Pelofske",
      "Lorie M. Liebrock",
      "Vincent Urias"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12022",
    "title": "Epsilon-Identifiability of Causal Quantities",
    "abstract": "Identifying the effects of causes and causes of effects is vital in virtually every scientific field. Often, however, the needed probabilities may not be fully identifiable from the data sources available. This paper shows how partial identifiability is still possible for several probabilities of causation. We term this epsilon-identifiability and demonstrate its usefulness in cases where the behavior of certain subpopulations can be restricted to within some narrow bounds. In particular, we show how unidentifiable causal effects and counterfactual probabilities can be narrowly bounded when such allowances are made. Often those allowances are easily measured and reasonably assumed. Finally, epsilon-identifiability is applied to the unit selection problem. ",
    "url": "https://arxiv.org/abs/2301.12022",
    "authors": [
      "Ang Li",
      "Scott Mueller",
      "Judea Pearl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2301.12025",
    "title": "Cross-Architectural Positive Pairs improve the effectiveness of  Self-Supervised Learning",
    "abstract": "Existing self-supervised techniques have extreme computational requirements and suffer a substantial drop in performance with a reduction in batch size or pretraining epochs. This paper presents Cross Architectural - Self Supervision (CASS), a novel self-supervised learning approach that leverages Transformer and CNN simultaneously. Compared to the existing state-of-the-art self-supervised learning approaches, we empirically show that CASS-trained CNNs and Transformers across four diverse datasets gained an average of 3.8% with 1% labeled data, 5.9% with 10% labeled data, and 10.13% with 100% labeled data while taking 69% less time. We also show that CASS is much more robust to changes in batch size and training epochs than existing state-of-the-art self-supervised learning approaches. We have open-sourced our code at https://github.com/pranavsinghps1/CASS. ",
    "url": "https://arxiv.org/abs/2301.12025",
    "authors": [
      "Pranav Singh",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12033",
    "title": "Norm-based Generalization Bounds for Compositionally Sparse Neural  Networks",
    "abstract": "In this paper, we investigate the Rademacher complexity of deep sparse neural networks, where each neuron receives a small number of inputs. We prove generalization bounds for multilayered sparse ReLU neural networks, including convolutional neural networks. These bounds differ from previous ones, as they consider the norms of the convolutional filters instead of the norms of the associated Toeplitz matrices, independently of weight sharing between neurons. As we show theoretically, these bounds may be orders of magnitude better than standard norm-based generalization bounds and empirically, they are almost non-vacuous in estimating generalization in various simple classification problems. Taken together, these results suggest that compositional sparsity of the underlying target function is critical to the success of deep neural networks. ",
    "url": "https://arxiv.org/abs/2301.12033",
    "authors": [
      "Tomer Galanti",
      "Mengjia Xu",
      "Liane Galanti",
      "Tomaso Poggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12036",
    "title": "Analyzing Robustness of the Deep Reinforcement Learning Algorithm in  Ramp Metering Applications Considering False Data Injection Attack and  Defense",
    "abstract": "Decades of practices of ramp metering, by controlling downstream volume and smoothing the interweaving traffic, have proved that ramp metering can decrease total travel time, mitigate shockwaves, decrease rear-end collisions, reduce pollution, etc. Besides traditional methods like ALIENA algorithms, Deep Reinforcement Learning algorithms have been established recently to build finer control on ramp metering. However, those Deep Learning models may be venerable to adversarial attacks. Thus, it is important to investigate the robustness of those models under False Data Injection adversarial attack. Furthermore, algorithms capable of detecting anomaly data from clean data are the key to safeguard Deep Learning algorithm. In this study, an online algorithm that can distinguish adversarial data from clean data are tested. Results found that in most cases anomaly data can be distinguished from clean data, although their difference is too small to be manually distinguished by humans. In practice, whenever adversarial/hazardous data is detected, the system can fall back to a fixed control program, and experts should investigate the detectors status or security protocols afterwards before real damages happen. ",
    "url": "https://arxiv.org/abs/2301.12036",
    "authors": [
      "Diyi Liu",
      "Lanmin Liu",
      "Lee D Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2301.12046",
    "title": "Semantic Adversarial Attacks on Face Recognition through Significant  Attributes",
    "abstract": "Face recognition is known to be vulnerable to adversarial face images. Existing works craft face adversarial images by indiscriminately changing a single attribute without being aware of the intrinsic attributes of the images. To this end, we propose a new Semantic Adversarial Attack called SAA-StarGAN that tampers with the significant facial attributes for each image. We predict the most significant attributes by applying the cosine similarity or probability score. The probability score method is based on training a Face Verification model for an attribute prediction task to obtain a class probability score for each attribute. The prediction process will help craft adversarial face images more easily and efficiently, as well as improve the adversarial transferability. Then, we change the most significant facial attributes, with either one or more of the facial attributes for impersonation and dodging attacks in white-box and black-box settings. Experimental results show that our method could generate diverse and realistic adversarial face images meanwhile avoid affecting human perception of the face recognition. SAA-StarGAN achieves an 80.5% attack success rate against black-box models, outperforming existing methods by 35.5% under the impersonation attack. Concerning the black-box setting, SAA-StarGAN achieves high attack success rates on various models. The experiments confirm that predicting the most important attributes significantly affects the success of adversarial attacks in both white-box and black-box settings and could enhance the transferability of the crafted adversarial examples. ",
    "url": "https://arxiv.org/abs/2301.12046",
    "authors": [
      "Yasmeen M. Khedr",
      "Yifeng Xiong",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12048",
    "title": "Making Reconstruction-based Method Great Again for Video Anomaly  Detection",
    "abstract": "Anomaly detection in videos is a significant yet challenging problem. Previous approaches based on deep neural networks employ either reconstruction-based or prediction-based approaches. Nevertheless, existing reconstruction-based methods 1) rely on old-fashioned convolutional autoencoders and are poor at modeling temporal dependency; 2) are prone to overfit the training samples, leading to indistinguishable reconstruction errors of normal and abnormal frames during the inference phase. To address such issues, firstly, we get inspiration from transformer and propose ${\\textbf S}$patio-${\\textbf T}$emporal ${\\textbf A}$uto-${\\textbf T}$rans-${\\textbf E}$ncoder, dubbed as $\\textbf{STATE}$, as a new autoencoder model for enhanced consecutive frame reconstruction. Our STATE is equipped with a specifically designed learnable convolutional attention module for efficient temporal learning and reasoning. Secondly, we put forward a novel reconstruction-based input perturbation technique during testing to further differentiate anomalous frames. With the same perturbation magnitude, the testing reconstruction error of the normal frames lowers more than that of the abnormal frames, which contributes to mitigating the overfitting problem of reconstruction. Owing to the high relevance of the frame abnormality and the objects in the frame, we conduct object-level reconstruction using both the raw frame and the corresponding optical flow patches. Finally, the anomaly score is designed based on the combination of the raw and motion reconstruction errors using perturbed inputs. Extensive experiments on benchmark video anomaly detection datasets demonstrate that our approach outperforms previous reconstruction-based methods by a notable margin, and achieves state-of-the-art anomaly detection performance consistently. The code is available at https://github.com/wyzjack/MRMGA4VAD. ",
    "url": "https://arxiv.org/abs/2301.12048",
    "authors": [
      "Yizhou Wang",
      "Can Qin",
      "Yue Bai",
      "Yi Xu",
      "Xu Ma",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.12054",
    "title": "Adversarial Learning Networks: Source-free Unsupervised Domain  Incremental Learning",
    "abstract": "This work presents an approach for incrementally updating deep neural network (DNN) models in a non-stationary environment. DNN models are sensitive to changes in input data distribution, which limits their application to problem settings with stationary input datasets. In a non-stationary environment, updating a DNN model requires parameter re-training or model fine-tuning. We propose an unsupervised source-free method to update DNN classification models. The contributions of this work are two-fold. First, we use trainable Gaussian prototypes to generate representative samples for future iterations; second, using unsupervised domain adaptation, we incrementally adapt the existing model using unlabelled data. Unlike existing methods, our approach can update a DNN model incrementally for non-stationary source and target tasks without storing past training data. We evaluated our work on incremental sentiment prediction and incremental disease prediction applications and compared our approach to state-of-the-art continual learning, domain adaptation, and ensemble learning methods. Our results show that our approach achieved improved performance compared to existing incremental learning methods. We observe minimal forgetting of past knowledge over many iterations, which can help us develop unsupervised self-learning systems. ",
    "url": "https://arxiv.org/abs/2301.12054",
    "authors": [
      "Abhinit Kumar Ambastha",
      "Leong Tze Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12057",
    "title": "Object Preserving Siamese Network for Single Object Tracking on Point  Clouds",
    "abstract": "Obviously, the object is the key factor of the 3D single object tracking (SOT) task. However, previous Siamese-based trackers overlook the negative effects brought by randomly dropped object points during backbone sampling, which hinder trackers to predict accurate bounding boxes (BBoxes). Exploring an approach that seeks to maximize the preservation of object points and their object-aware features is of particular significance. Motivated by this, we propose an Object Preserving Siamese Network (OPSNet), which can significantly maintain object integrity and boost tracking performance. Firstly, the object highlighting module enhances the object-aware features and extracts discriminative features from template and search area. Then, the object-preserved sampling selects object candidates to obtain object-preserved search area seeds and drop the background points that contribute less to tracking. Finally, the object localization network precisely locates 3D BBoxes based on the object-preserved search area seeds. Extensive experiments demonstrate our method outperforms the state-of-the-art performance (9.4% and 2.5% success gain on KITTI and Waymo Open Dataset respectively). ",
    "url": "https://arxiv.org/abs/2301.12057",
    "authors": [
      "Kaijie Zhao",
      "Haitao Zhao",
      "Zhongze Wang",
      "Jingchao Peng",
      "Zhengwei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12058",
    "title": "Aerial Image Object Detection With Vision Transformer Detector (ViTDet)",
    "abstract": "The past few years have seen an increased interest in aerial image object detection due to its critical value to large-scale geo-scientific research like environmental studies, urban planning, and intelligence monitoring. However, the task is very challenging due to the birds-eye view perspective, complex backgrounds, large and various image sizes, different appearances of objects, and the scarcity of well-annotated datasets. Recent advances in computer vision have shown promise tackling the challenge. Specifically, Vision Transformer Detector (ViTDet) was proposed to extract multi-scale features for object detection. The empirical study shows that ViTDet's simple design achieves good performance on natural scene images and can be easily embedded into any detector architecture. To date, ViTDet's potential benefit to challenging aerial image object detection has not been explored. Therefore, in our study, 25 experiments were carried out to evaluate the effectiveness of ViTDet for aerial image object detection on three well-known datasets: Airbus Aircraft, RarePlanes, and Dataset of Object DeTection in Aerial images (DOTA). Our results show that ViTDet can consistently outperform its convolutional neural network counterparts on horizontal bounding box (HBB) object detection by a large margin (up to 17% on average precision) and that it achieves the competitive performance for oriented bounding box (OBB) object detection. Our results also establish a baseline for future research. ",
    "url": "https://arxiv.org/abs/2301.12058",
    "authors": [
      "Liya Wang",
      "Alex Tien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12063",
    "title": "HAT-GAE: Self-Supervised Graph Auto-encoders with Hierarchical Adaptive  Masking and Trainable Corruption",
    "abstract": "Self-supervised auto-encoders have emerged as a successful framework for representation learning in computer vision and natural language processing in recent years, However, their application to graph data has been met with limited performance due to the non-Euclidean and complex structure of graphs in comparison to images or text, as well as the limitations of conventional auto-encoder architectures. In this paper, we investigate factors impacting the performance of auto-encoders on graph data and propose a novel auto-encoder model for graph representation learning. Our model incorporates a hierarchical adaptive masking mechanism to incrementally increase the difficulty of training in order to mimic the process of human cognitive learning, and a trainable corruption scheme to enhance the robustness of learned representations. Through extensive experimentation on ten benchmark datasets, we demonstrate the superiority of our proposed method over state-of-the-art graph representation learning models. ",
    "url": "https://arxiv.org/abs/2301.12063",
    "authors": [
      "Chengyu Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12068",
    "title": "Physics-Inspired Protein Encoder Pre-Training via Siamese  Sequence-Structure Diffusion Trajectory Prediction",
    "abstract": "Pre-training methods on proteins are recently gaining interest, leveraging either protein sequences or structures, while modeling their joint energy landscape is largely unexplored. In this work, inspired by the success of denoising diffusion models, we propose the DiffPreT approach to pre-train a protein encoder by sequence-structure multimodal diffusion modeling. DiffPreT guides the encoder to recover the native protein sequences and structures from the perturbed ones along the multimodal diffusion trajectory, which acquires the joint distribution of sequences and structures. Considering the essential protein conformational variations, we enhance DiffPreT by a physics-inspired method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the correlation between different conformers of a protein. SiamDiff attains this goal by maximizing the mutual information between representations of diffusion trajectories of structurally-correlated conformers. We study the effectiveness of DiffPreT and SiamDiff on both atom- and residue-level structure-based protein understanding tasks. Experimental results show that the performance of DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new state-of-the-art performance, considering the mean ranks on all tasks. The source code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2301.12068",
    "authors": [
      "Zuobai Zhang",
      "Minghao Xu",
      "Aur\u00e9lie Lozano",
      "Vijil Chenthamarakshan",
      "Payel Das",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12073",
    "title": "Towards Equitable Representation in Text-to-Image Synthesis Models with  the Cross-Cultural Understanding Benchmark (CCUB) Dataset",
    "abstract": "It has been shown that accurate representation in media improves the well-being of the people who consume it. By contrast, inaccurate representations can negatively affect viewers and lead to harmful perceptions of other cultures. To achieve inclusive representation in generated images, we propose a culturally-aware priming approach for text-to-image synthesis using a small but culturally curated dataset that we collected, known here as Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias prevalent in giant datasets. Our proposed approach is comprised of two fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs, and (2) Adding semantic context via automated prompt engineering using the fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware text data. CCUB dataset is curated and our approach is evaluated by people who have a personal relationship with that particular culture. Our experiments indicate that priming using both text and image is effective in improving the cultural relevance and decreasing the offensiveness of generated images while maintaining quality. ",
    "url": "https://arxiv.org/abs/2301.12073",
    "authors": [
      "Zhixuan Liu",
      "Youeun Shin",
      "Beverley-Claire Okogwu",
      "Youngsik Yun",
      "Lia Coleman",
      "Peter Schaldenbrand",
      "Jihie Kim",
      "Jean Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12082",
    "title": "Pushing the Limits of Fewshot Anomaly Detection in Industry Vision:  Graphcore",
    "abstract": "In the area of fewshot anomaly detection (FSAD), efficient visual feature plays an essential role in memory bank M-based methods. However, these methods do not account for the relationship between the visual feature and its rotated visual feature, drastically limiting the anomaly detection performance. To push the limits, we reveal that rotation-invariant feature property has a significant impact in industrial-based FSAD. Specifically, we utilize graph representation in FSAD and provide a novel visual isometric invariant feature (VIIF) as anomaly measurement feature. As a result, VIIF can robustly improve the anomaly discriminating ability and can further reduce the size of redundant features stored in M by a large amount. Besides, we provide a novel model GraphCore via VIIFs that can fast implement unsupervised FSAD training and can improve the performance of anomaly detection. A comprehensive evaluation is provided for comparing GraphCore and other SOTA anomaly detection models under our proposed fewshot anomaly detection setting, which shows GraphCore can increase average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%, 22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively. ",
    "url": "https://arxiv.org/abs/2301.12082",
    "authors": [
      "Guoyang Xie",
      "Jingbao Wang",
      "Jiaqi Liu",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12092",
    "title": "The Benefits of Vulnerability Discovery and Bug Bounty Programs: Case  Studies of Chromium and Firefox",
    "abstract": "Recently, bug-bounty programs have gained popularity and become a significant part of the security culture of many organizations. Bug-bounty programs enable organizations to enhance their security posture by harnessing the diverse expertise of crowds of external security experts (i.e., bug hunters). However, quantifying the benefits of bug-bounty programs remains elusive, which presents a significant challenge for managing them. Previous studies focused on measuring their benefits in terms of the number of vulnerabilities reported or based on properties of the reported vulnerabilities, such as severity or exploitability. Importantly, beyond these inherent properties, the value of a report also depends on the probability that the vulnerability would be discovered by a threat actor before an internal expert could discover and patch it. In this paper, we present a data-driven study of the Chromium and Firefox vulnerability-reward programs. First, we estimate the difficulty of discovering a vulnerability using the probability of rediscovery as a novel metric. Our findings show that vulnerability discovery and patching provide clear benefits by making it difficult for threat actors to find vulnerabilities; however, we also identify opportunities for improvement, such as incentivizing bug hunters to focus more on development releases. Second, we compare the types of vulnerabilities that are discovered internally vs. externally and those that are exploited by threat actors. We observe significant differences between vulnerabilities found by external bug hunters, internal security teams, and external threat actors, which indicates that bug-bounty programs provide an important benefit by complementing the expertise of internal teams, but also that external hunters should be incentivized more to focus on the types of vulnerabilities that are likely to be exploited by threat actors. ",
    "url": "https://arxiv.org/abs/2301.12092",
    "authors": [
      "Soodeh Atefi",
      "Amutheezan Sivagnanam",
      "Afiya Ayman",
      "Jens Grossklags",
      "Aron Laszka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12097",
    "title": "Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal  Recommendation",
    "abstract": "User interaction data in recommender systems is a form of dyadic relation that reflects the preferences of users with items. Learning the representations of these two discrete sets of objects, users and items, is critical for recommendation. Recent multimodal recommendation models leveraging multimodal features (e.g., images and text descriptions) have been demonstrated to be effective in improving recommendation accuracy. However, state-of-the-art models enhance the dyadic relations between users and items by considering either user-user or item-item relations, leaving the high-order relations of the other side (i.e., users or items) unexplored. Furthermore, we experimentally reveal that the current multimodality fusion methods in the state-of-the-art models may degrade their recommendation performance. That is, without tainting the model architectures, these models can achieve even better recommendation accuracy with uni-modal information. On top of the finding, we propose a model that enhances the dyadic relations by learning Dual RepresentAtions of both users and items via constructing homogeneous Graphs for multimOdal recommeNdation. We name our model as DRAGON. Specifically, DRAGON constructs the user-user graph based on the commonly interacted items and the item-item graph from item multimodal features. It then utilizes graph learning on both the user-item heterogeneous graph and the homogeneous graphs (user-user and item-item) to obtain the dual representations of users and items. To capture information from each modality, DRAGON employs a simple yet effective fusion method, attentive concatenation, to derive the representations of users and items. Extensive experiments on three public datasets and seven baselines show that DRAGON can outperform the strongest baseline by 22.03% on average. Various ablation studies are conducted on DRAGON to validate its effectiveness. ",
    "url": "https://arxiv.org/abs/2301.12097",
    "authors": [
      "Hongyu Zhou",
      "Xin Zhou",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.12100",
    "title": "Reachability Analysis of Neural Network Control Systems",
    "abstract": "Neural network controllers (NNCs) have shown great promise in autonomous and cyber-physical systems. Despite the various verification approaches for neural networks, the safety analysis of NNCs remains an open problem. Existing verification approaches for neural network control systems (NNCSs) either can only work on a limited type of activation functions, or result in non-trivial over-approximation errors with time evolving. This paper proposes a verification framework for NNCS based on Lipschitzian optimisation, called DeepNNC. We first prove the Lipschitz continuity of closed-loop NNCSs by unrolling and eliminating the loops. We then reveal the working principles of applying Lipschitzian optimisation on NNCS verification and illustrate it by verifying an adaptive cruise control model. Compared to state-of-the-art verification approaches, DeepNNC shows superior performance in terms of efficiency and accuracy over a wide range of NNCs. We also provide a case study to demonstrate the capability of DeepNNC to handle a real-world, practical, and complex system. Our tool \\textbf{DeepNNC} is available at \\url{https://github.com/TrustAI/DeepNNC}. ",
    "url": "https://arxiv.org/abs/2301.12100",
    "authors": [
      "Chi Zhang",
      "Wenjie Ruan",
      "Peipei Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12104",
    "title": "Unbiased and Efficient Self-Supervised Incremental Contrastive Learning",
    "abstract": "Contrastive Learning (CL) has been proved to be a powerful self-supervised approach for a wide range of domains, including computer vision and graph representation learning. However, the incremental learning issue of CL has rarely been studied, which brings the limitation in applying it to real-world applications. Contrastive learning identifies the samples with the negative ones from the noise distribution that changes in the incremental scenarios. Therefore, only fitting the change of data without noise distribution causes bias, and directly retraining results in low efficiency. To bridge this research gap, we propose a self-supervised Incremental Contrastive Learning (ICL) framework consisting of (i) a novel Incremental InfoNCE (NCE-II) loss function by estimating the change of noise distribution for old data to guarantee no bias with respect to the retraining, (ii) a meta-optimization with deep reinforced Learning Rate Learning (LRL) mechanism which can adaptively learn the learning rate according to the status of the training processes and achieve fast convergence which is critical for incremental learning. Theoretically, the proposed ICL is equivalent to retraining, which is based on solid mathematical derivation. In practice, extensive experiments in different domains demonstrate that, without retraining a new model, ICL achieves up to 16.7x training speedup and 16.8x faster convergence with competitive results. ",
    "url": "https://arxiv.org/abs/2301.12104",
    "authors": [
      "Cheng Ji",
      "Jianxin Li",
      "Hao Peng",
      "Jia Wu",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Phillip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12118",
    "title": "Physics-informed Neural Network: The Effect of Reparameterization in  Solving Differential Equations",
    "abstract": "Differential equations are used to model and predict the behaviour of complex systems in a wide range of fields, and the ability to solve them is an important asset for understanding and predicting the behaviour of these systems. Complicated physics mostly involves difficult differential equations, which are hard to solve analytically. In recent years, physics-informed neural networks have been shown to perform very well in solving systems with various differential equations. The main ways to approximate differential equations are through penalty function and reparameterization. Most researchers use penalty functions rather than reparameterization due to the complexity of implementing reparameterization. In this study, we quantitatively compare physics-informed neural network models with and without reparameterization using the approximation error. The performance of reparameterization is demonstrated based on two benchmark mechanical engineering problems, a one-dimensional bar problem and a two-dimensional bending beam problem. Our results show that when dealing with complex differential equations, applying reparameterization results in a lower approximation error. ",
    "url": "https://arxiv.org/abs/2301.12118",
    "authors": [
      "Siddharth Nand",
      "Yuecheng Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12148",
    "title": "Quality Indicators for Preference-based Evolutionary Multi-objective  Optimization Using a Reference Point: A Review and Analysis",
    "abstract": "Some quality indicators have been proposed for benchmarking preference-based evolutionary multi-objective optimization algorithms using a reference point. Although a systematic review and analysis of the quality indicators are helpful for both benchmarking and practical decision-making, neither has been conducted. In this context, first, this paper reviews existing regions of interest and quality indicators for preference-based evolutionary multi-objective optimization using the reference point. We point out that each quality indicator was designed for a different region of interest. Then, this paper investigates the properties of the quality indicators. We demonstrate that an achievement scalarizing function value is not always consistent with the distance from a solution to the reference point in the objective space. We observe that the regions of interest can be significantly different depending on the position of the reference point and the shape of the Pareto front. We identify undesirable properties of some quality indicators. We also show that the ranking of preference-based evolutionary multi-objective optimization algorithms significantly depends on the choice of quality indicators. ",
    "url": "https://arxiv.org/abs/2301.12148",
    "authors": [
      "Ryoji Tanabe",
      "Ke Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.12149",
    "title": "POSTER V2: A simpler and stronger facial expression recognition network",
    "abstract": "Facial expression recognition (FER) plays an important role in a variety of real-world applications such as human-computer interaction. POSTER V1 achieves the state-of-the-art (SOTA) performance in FER by effectively combining facial landmark and image features through two-stream pyramid cross-fusion design. However, the architecture of POSTER V1 is undoubtedly complex. It causes expensive computational costs. In order to relieve the computational pressure of POSTER V1, in this paper, we propose POSTER V2. It improves POSTER V1 in three directions: cross-fusion, two-stream, and multi-scale feature extraction. In cross-fusion, we use window-based cross-attention mechanism replacing vanilla cross-attention mechanism. We remove the image-to-landmark branch in the two-stream design. For multi-scale feature extraction, POSTER V2 combines images with landmark's multi-scale features to replace POSTER V1's pyramid design. Extensive experiments on several standard datasets show that our POSTER V2 achieves the SOTA FER performance with the minimum computational cost. For example, POSTER V2 reached 92.21\\% on RAF-DB, 67.49\\% on AffectNet (7 cls) and 63.77\\% on AffectNet (8 cls), respectively, using only 8.4G floating point operations (FLOPs) and 43.7M parameters (Param). This demonstrates the effectiveness of our improvements. The code and models are available at ~\\url{https://github.com/Talented-Q/POSTER_V2}. ",
    "url": "https://arxiv.org/abs/2301.12149",
    "authors": [
      "Jiawei Mao",
      "Rui Xu",
      "Xuesong Yin",
      "Yuanqi Chang",
      "Binling Nie",
      "Aibin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12151",
    "title": "Selecting Models based on the Risk of Damage Caused by Adversarial  Attacks",
    "abstract": "Regulation, legal liabilities, and societal concerns challenge the adoption of AI in safety and security-critical applications. One of the key concerns is that adversaries can cause harm by manipulating model predictions without being detected. Regulation hence demands an assessment of the risk of damage caused by adversaries. Yet, there is no method to translate this high-level demand into actionable metrics that quantify the risk of damage. In this article, we propose a method to model and statistically estimate the probability of damage arising from adversarial attacks. We show that our proposed estimator is statistically consistent and unbiased. In experiments, we demonstrate that the estimation results of our method have a clear and actionable interpretation and outperform conventional metrics. We then show how operators can use the estimation results to reliably select the model with the lowest risk. ",
    "url": "https://arxiv.org/abs/2301.12151",
    "authors": [
      "Jona Klemenc",
      "Holger Trittenbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12159",
    "title": "ClusterFuG: Clustering Fully connected Graphs by Multicut",
    "abstract": "We propose a graph clustering formulation based on multicut (a.k.a. weighted correlation clustering) on the complete graph. Our formulation does not need specification of the graph topology as in the original sparse formulation of multicut, making our approach simpler and potentially better performing. In contrast to unweighted correlation clustering we allow for a more expressive weighted cost structure. In dense multicut, the clustering objective is given in a factorized form as inner products of node feature vectors. This allows for an efficient formulation and inference in contrast to multicut/weighted correlation clustering, which has at least quadratic representation and computation complexity when working on the complete graph. We show how to rewrite classical greedy algorithms for multicut in our dense setting and how to modify them for greater efficiency and solution quality. In particular, our algorithms scale to graphs with tens of thousands of nodes. Empirical evidence on instance segmentation on Cityscapes and clustering of ImageNet datasets shows the merits of our approach. ",
    "url": "https://arxiv.org/abs/2301.12159",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12166",
    "title": "Heterogeneous Datasets for Federated Survival Analysis Simulation",
    "abstract": "Survival analysis studies time-modeling techniques for an event of interest occurring for a population. Survival analysis found widespread applications in healthcare, engineering, and social sciences. However, the data needed to train survival models are often distributed, incomplete, censored, and confidential. In this context, federated learning can be exploited to tremendously improve the quality of the models trained on distributed data while preserving user privacy. However, federated survival analysis is still in its early development, and there is no common benchmarking dataset to test federated survival models. This work proposes a novel technique for constructing realistic heterogeneous datasets by starting from existing non-federated datasets in a reproducible way. Specifically, we provide two novel dataset-splitting algorithms based on the Dirichlet distribution to assign each data sample to a carefully chosen client: quantity-skewed splitting and label-skewed splitting. Furthermore, these algorithms allow for obtaining different levels of heterogeneity by changing a single hyperparameter. Finally, numerical experiments provide a quantitative evaluation of the heterogeneity level using log-rank tests and a qualitative analysis of the generated splits. The implementation of the proposed methods is publicly available in favor of reproducibility and to encourage common practices to simulate federated environments for survival analysis. ",
    "url": "https://arxiv.org/abs/2301.12166",
    "authors": [
      "Alberto Archetti",
      "Eugenio Lomurno",
      "Francesco Lattari",
      "Andr\u00e9 Martin",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12168",
    "title": "Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks  via Aggregated Early Exits",
    "abstract": "Today, artificial neural networks are the state of the art for solving a variety of complex tasks, especially in image classification. Such architectures consist of a sequence of stacked layers with the aim of extracting useful information and having it processed by a classifier to make accurate predictions. However, intermediate information within such models is often left unused. In other cases, such as in edge computing contexts, these architectures are divided into multiple partitions that are made functional by including early exits, i.e. intermediate classifiers, with the goal of reducing the computational and temporal load without extremely compromising the accuracy of the classifications. In this paper, we present Anticipate, Ensemble and Prune (AEP), a new training technique based on weighted ensembles of early exits, which aims at exploiting the information in the structure of networks to maximise their performance. Through a comprehensive set of experiments, we show how the use of this approach can yield average accuracy improvements of up to 15% over traditional training. In its hybrid-weighted configuration, AEP's internal pruning operation also allows reducing the number of parameters by up to 41%, lowering the number of multiplications and additions by 18% and the latency time to make inference by 16%. By using AEP, it is also possible to learn weights that allow early exits to achieve better accuracy values than those obtained from single-output reference models. ",
    "url": "https://arxiv.org/abs/2301.12168",
    "authors": [
      "Simone Sarti",
      "Eugenio Lomurno",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12175",
    "title": "Bio-inspired Autonomous Exploration Policies with CNN-based Object  Detection on Nano-drones",
    "abstract": "Nano-sized drones, with palm-sized form factor, are gaining relevance in the Internet-of-Things ecosystem. Achieving a high degree of autonomy for complex multi-objective missions (e.g., safe flight, exploration, object detection) is extremely challenging for the onboard chip-set due to tight size, payload (<10g), and power envelope constraints, which strictly limit both memory and computation. Our work addresses this complex problem by combining bio-inspired navigation policies, which rely on time-of-flight distance sensor data, with a vision-based convolutional neural network (CNN) for object detection. Our field-proven nano-drone is equipped with two microcontroller units (MCUs), a single-core ARM Cortex-M4 (STM32) for safe navigation and exploration policies, and a parallel ultra-low power octa-core RISC-V (GAP8) for onboard CNN inference, with a power envelope of just 134mW, including image sensors and external memories. The object detection task achieves a mean average precision of 50% (at 1.6 frame/s) on an in-field collected dataset. We compare four bio-inspired exploration policies and identify a pseudo-random policy to achieve the highest coverage area of 83% in a ~36m^2 unknown room in a 3 minutes flight. By combining the detection CNN and the exploration policy, we show an average detection rate of 90% on six target objects in a never-seen-before environment. ",
    "url": "https://arxiv.org/abs/2301.12175",
    "authors": [
      "Lorenzo Lamberti",
      "Luca Bompani",
      "Victor Javier Kartsch",
      "Manuele Rusci",
      "Daniele Palossi",
      "Luca Benini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12185",
    "title": "Hybrid Cognition for Target Tracking in Cognitive Radar Networks",
    "abstract": "This work investigates online learning techniques for a cognitive radar network utilizing feedback from a central coordinator. The available spectrum is divided into channels, and each radar node must transmit in one channel per time step. The network attempts to optimize radar tracking accuracy by learning the optimal channel selection for spectrum sharing and radar performance. Since the presence of primary users appears as interference, the approach also improves spectrum sharing performance. Importantly, each part of the network acts as an online learner, observing the environment to inform future actions. We show that in interference-limited spectrum, where the signal-to-interference-plus-noise ratio can vary across channels and nodes, a cognitive radar network is able to use information from the central coordinator in order to reduce the amount of time necessary to learn the optimal channel selection. We also show that even limited use of a central coordinator can eliminate collisions, which occur when two nodes select the same channel. We provide several reward functions which capture different aspects of the dynamic radar scenario and describe the online machine learning algorithms which are applicable to this structure. In addition, we study varying levels of feedback, where central coordinator update rates vary. We compare our algorithms against baselines and demonstrate dramatic improvements in convergence time over the prior art. A network using hybrid cognition is able to use a minimal amount of feedback to achieve much faster convergence times and therefore lower tracking error. ",
    "url": "https://arxiv.org/abs/2301.12185",
    "authors": [
      "William W. Howard",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12189",
    "title": "Deciphering the Projection Head: Representation Evaluation  Self-supervised Learning",
    "abstract": "Self-supervised learning (SSL) aims to learn intrinsic features without labels. Despite the diverse architectures of SSL methods, the projection head always plays an important role in improving the performance of the downstream task. In this work, we systematically investigate the role of the projection head in SSL. Specifically, the projection head targets the uniformity part of SSL, which pushes the dissimilar samples away from each other, thus enabling the encoder to focus on extracting semantic features. Based on this understanding, we propose a Representation Evaluation Design (RED) in SSL models in which a shortcut connection between the representation and the projection vectors is built. Extensive experiments with different architectures, including SimCLR, MoCo-V2, and SimSiam, on various datasets, demonstrate that the representation evaluation design can consistently improve the baseline models in the downstream tasks. The learned representation from the RED-SSL models shows superior robustness to unseen augmentations and out-of-distribution data. ",
    "url": "https://arxiv.org/abs/2301.12189",
    "authors": [
      "Jiajun Ma",
      "Tianyang Hu",
      "Wenjia Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12204",
    "title": "Privacy and Bias Analysis of Disclosure Avoidance Systems",
    "abstract": "Disclosure avoidance (DA) systems are used to safeguard the confidentiality of data while allowing it to be analyzed and disseminated for analytic purposes. These methods, e.g., cell suppression, swapping, and k-anonymity, are commonly applied and may have significant societal and economic implications. However, a formal analysis of their privacy and bias guarantees has been lacking. This paper presents a framework that addresses this gap: it proposes differentially private versions of these mechanisms and derives their privacy bounds. In addition, the paper compares their performance with traditional differential privacy mechanisms in terms of accuracy and fairness on US Census data release and classification tasks. The results show that, contrary to popular beliefs, traditional differential privacy techniques may be superior in terms of accuracy and fairness to differential private counterparts of widely used DA mechanisms. ",
    "url": "https://arxiv.org/abs/2301.12204",
    "authors": [
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck",
      "Saswat Das",
      "Christine Task"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2301.12210",
    "title": "Neural Temporal Point Process for Forecasting Higher Order and  Directional Interactions",
    "abstract": "Real-world systems are made of interacting entities that evolve with time. Creating models that can forecast interactions by learning the dynamics of entities is an important problem in numerous fields. Earlier works used dynamic graph models to achieve this. However, real-world interactions are more complex than pairwise, as they involve more than two entities, and many of these higher-order interactions have directional components. Examples of these can be seen in communication networks such as email exchanges that involve a sender, and multiple recipients, citation networks, where authors draw upon the work of others, and so on. In this paper, we solve the problem of higher-order directed interaction forecasting by proposing a deep neural network-based model \\textit{Directed HyperNode Temporal Point Process} for directed hyperedge event forecasting, as hyperedge provides native framework for modeling relationships among the variable number of nodes. Our proposed technique reduces the search space of possible candidate hyperedges by first forecasting the nodes at which events will be observed, based on which it generates candidate hyperedges. To demonstrate the efficiency of our model, we curated four datasets and conducted an extensive empirical study. We believe that this is the first work that solves the problem of forecasting higher-order directional interactions. ",
    "url": "https://arxiv.org/abs/2301.12210",
    "authors": [
      "Tony Gracious",
      "Arman Gupta",
      "Ambedkar Dukkipati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12217",
    "title": "Semantic Parsing for Conversational Question Answering over Knowledge  Graphs",
    "abstract": "In this paper, we are interested in developing semantic parsers which understand natural language questions embedded in a conversation with a user and ground them to formal queries over definitions in a general purpose knowledge graph (KG) with very large vocabularies (covering thousands of concept names and relations, and millions of entities). To this end, we develop a dataset where user questions are annotated with Sparql parses and system answers correspond to execution results thereof. We present two different semantic parsing approaches and highlight the challenges of the task: dealing with large vocabularies, modelling conversation context, predicting queries with multiple entities, and generalising to new questions at test time. We hope our dataset will serve as useful testbed for the development of conversational semantic parsers. Our dataset and models are released at https://github.com/EdinburghNLP/SPICE. ",
    "url": "https://arxiv.org/abs/2301.12217",
    "authors": [
      "Laura Perez-Beltrachini",
      "Parag Jain",
      "Emilio Monti",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12219",
    "title": "Towards Accurate Acne Detection via Decoupled Sequential Detection Head",
    "abstract": "Accurate acne detection plays a crucial role in acquiring precise diagnosis and conducting proper therapy. However, the ambiguous boundaries and arbitrary dimensions of acne lesions severely limit the performance of existing methods. In this paper, we address these challenges via a novel Decoupled Sequential Detection Head (DSDH), which can be easily adopted by mainstream two-stage detectors. DSDH brings two simple but effective improvements to acne detection. Firstly, the offset and scaling tasks are explicitly introduced, and their incompatibility is settled by our task-decouple mechanism, which improves the capability of predicting the location and size of acne lesions. Second, we propose the task-sequence mechanism, and execute offset and scaling sequentially to gain a more comprehensive insight into the dimensions of acne lesions. In addition, we build a high-quality acne detection dataset named ACNE-DET to verify the effectiveness of DSDH. Experiments on ACNE-DET and the public benchmark ACNE04 show that our method outperforms the state-of-the-art methods by significant margins. Our code and dataset are publicly available at (temporarily anonymous). ",
    "url": "https://arxiv.org/abs/2301.12219",
    "authors": [
      "Xin Wei",
      "Lei Zhang",
      "Jianwei Zhang",
      "Junyou Wang",
      "Wenjie Liu",
      "Jiaqi Li",
      "Xian Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12226",
    "title": "Causal Influence Maximization in Hypergraph",
    "abstract": "Influence Maximization (IM) is the task of selecting a fixed number of seed nodes in a given network to maximize dissemination benefits. Although the research for efficient algorithms has been dedicated recently, it is usually neglected to further explore the graph structure and the objective function inherently. With this motivation, we take the first attempt on the hypergraph-based IM with a novel causal objective. We consider the case that each hypergraph node carries specific attributes with Individual Treatment Effect (ITE), namely the change of potential outcomes before/after infections in a causal inference perspective. In many scenarios, the sum of ITEs of the infected is a more reasonable objective for influence spread, whereas it is difficult to achieve via current IM algorithms. In this paper, we introduce a new algorithm called \\textbf{CauIM}. We first recover the ITE of each node with observational data and then conduct a weighted greedy algorithm to maximize the sum of ITEs of the infected. Theoretically, we mainly present the generalized lower bound of influence spread beyond the well-known $(1-\\frac{1}{e})$ optimal guarantee and provide the robustness analysis. Empirically, in real-world experiments, we demonstrate the effectiveness and robustness of \\textbf{CauIM}. It outperforms the previous IM and randomized methods significantly. ",
    "url": "https://arxiv.org/abs/2301.12226",
    "authors": [
      "Xinyan Su",
      "Zhiheng Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12230",
    "title": "Continual Graph Learning: A Survey",
    "abstract": "Research on continual learning (CL) mainly focuses on data represented in the Euclidean space, while research on graph-structured data is scarce. Furthermore, most graph learning models are tailored for static graphs. However, graphs usually evolve continually in the real world. Catastrophic forgetting also emerges in graph learning models when being trained incrementally. This leads to the need to develop robust, effective and efficient continual graph learning approaches. Continual graph learning (CGL) is an emerging area aiming to realize continual learning on graph-structured data. This survey is written to shed light on this emerging area. It introduces the basic concepts of CGL and highlights two unique challenges brought by graphs. Then it reviews and categorizes recent state-of-the-art approaches, analyzing their strategies to tackle the unique challenges in CGL. Besides, it discusses the main concerns in each family of CGL methods, offering potential solutions. Finally, it explores the open issues and potential applications of CGL. ",
    "url": "https://arxiv.org/abs/2301.12230",
    "authors": [
      "Qiao Yuan",
      "Sheng-Uei Guan",
      "Pin Ni",
      "Tianlun Luo",
      "Ka Lok Man",
      "Prudence Wong",
      "Victor Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12235",
    "title": "Vulnerabilities and Attacks on CAN-Based 3D Printing/Additive  Manufacturing",
    "abstract": "Recent advancements in 3D-printing/additive manufacturing has brought forth a new interest in the use of Controller Area Network (CAN) for multi-module, plug-and-play bus support for their embedded systems. CAN systems provide a variety of benefits that can outweigh typical conventional wire-loom protocols in many categories. However, implementation of CAN also brings forth vulnerabilities provided by its spoofable, destination-encoded shared communication bus. These vulnerabilities result in undetectable fault injection, packet manipulation, unauthorized packet logging/sniffing, and more. They also provide attackers the capability to manipulate all sensor information, commands, and create unsafe operating conditions using only a single compromised node on the CAN network (bypassing all root-of-trust in the modules). Thus, malicious hardware requires only a connection to the bus for access to all traffic. In this paper, we discuss the effects of repurposed CAN-based attacks capable of manipulating sensor data, overriding systems, and injecting dangerous commands on the Controller Area Network using various entry methods. As a case study, we also showed a spoofing attack on critical data modules within a commercial 3D printer. ",
    "url": "https://arxiv.org/abs/2301.12235",
    "authors": [
      "Tyler Cultice",
      "Himanshu Thapliyal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12277",
    "title": "Node Injection for Class-specific Network Poisoning",
    "abstract": "Graph Neural Networks (GNNs) are powerful in learning rich network representations that aid the performance of downstream tasks. However, recent studies showed that GNNs are vulnerable to adversarial attacks involving node injection and network perturbation. Among these, node injection attacks are more practical as they don't require manipulation in the existing network and can be performed more realistically. In this paper, we propose a novel problem statement - a class-specific poison attack on graphs in which the attacker aims to misclassify specific nodes in the target class into a different class using node injection. Additionally, nodes are injected in such a way that they camouflage as benign nodes. We propose NICKI, a novel attacking strategy that utilizes an optimization-based approach to sabotage the performance of GNN-based node classifiers. NICKI works in two phases - it first learns the node representation and then generates the features and edges of the injected nodes. Extensive experiments and ablation studies on four benchmark networks show that NICKI is consistently better than four baseline attacking strategies for misclassifying nodes in the target class. We also show that the injected nodes are properly camouflaged as benign, thus making the poisoned graph indistinguishable from its clean version w.r.t various topological properties. ",
    "url": "https://arxiv.org/abs/2301.12277",
    "authors": [
      "Ansh Kumar Sharma",
      "Rahul Kukreja",
      "Mayank Kharbanda",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12288",
    "title": "Context-Aware Differential Privacy for Language Modeling",
    "abstract": "The remarkable ability of language models (LMs) has also brought challenges at the interface of AI and security. A critical challenge pertains to how much information these models retain and leak about the training data. This is particularly urgent as the typical development of LMs relies on huge, often highly sensitive data, such as emails and chat logs. To contrast this shortcoming, this paper introduces Context-Aware Differentially Private Language Model (CADP-LM) , a privacy-preserving LM framework that relies on two key insights: First, it utilizes the notion of \\emph{context} to define and audit the potentially sensitive information. Second, it adopts the notion of Differential Privacy to protect sensitive information and characterize the privacy leakage. A unique characteristic of CADP-LM is its ability to target the protection of sensitive sentences and contexts only, providing a highly accurate private model. Experiments on a variety of datasets and settings demonstrate these strengths of CADP-LM. ",
    "url": "https://arxiv.org/abs/2301.12288",
    "authors": [
      "My H. Dinh",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12292",
    "title": "Zero-shot causal learning",
    "abstract": "Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. However, most existing causal methods cannot generalize to predicting the effects of previously unseen interventions (e.g., a newly invented drug), because they require data for individuals who received the intervention. Here, we consider zero-shot causal learning: predicting the personalized effects of novel, previously unseen interventions. To tackle this problem, we propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. Rather than training a separate model for each intervention, CaML trains as a single meta-model across thousands of tasks, each constructed by sampling an intervention and individuals who either did or did not receive it. By leveraging both intervention information (e.g., a drug's attributes) and individual features (e.g., a patient's history), CaML is able to predict the personalized effects of unseen interventions. Experimental results on real world datasets in large-scale medical claims and cell-line perturbations demonstrate the effectiveness of our approach. Most strikingly, CaML zero-shot predictions outperform even strong baselines which have direct access to data of considered target interventions. ",
    "url": "https://arxiv.org/abs/2301.12292",
    "authors": [
      "Hamed Nilforoshan",
      "Michael Moor",
      "Yusuf Roohani",
      "Yining Chen",
      "Anja \u0160urina",
      "Michihiro Yasunaga",
      "Sara Oblak",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.12303",
    "title": "Presence of informal language, such as emoticons, hashtags, and slang,  impact the performance of sentiment analysis models on social media text?",
    "abstract": "This study aimed to investigate the influence of the presence of informal language, such as emoticons and slang, on the performance of sentiment analysis models applied to social media text. A convolutional neural network (CNN) model was developed and trained on three datasets: a sarcasm dataset, a sentiment dataset, and an emoticon dataset. The model architecture was held constant for all experiments and the model was trained on 80% of the data and tested on 20%. The results revealed that the model achieved an accuracy of 96.47% on the sarcasm dataset, with the lowest accuracy for class 1. On the sentiment dataset, the model achieved an accuracy of 95.28%. The amalgamation of sarcasm and sentiment datasets improved the accuracy of the model to 95.1%, and the addition of emoticon dataset has a slight positive impact on the accuracy of the model to 95.37%. The study suggests that the presence of informal language has a restricted impact on the performance of sentiment analysis models applied to social media text. However, the inclusion of emoticon data to the model can enhance the accuracy slightly. ",
    "url": "https://arxiv.org/abs/2301.12303",
    "authors": [
      "Aadil Gani Ganie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12309",
    "title": "On the Lipschitz Constant of Deep Networks and Double Descent",
    "abstract": "Existing bounds on the generalization error of deep networks assume some form of smooth or bounded dependence on the input variable, falling short of investigating the mechanisms controlling such factors in practice. In this work, we present an extensive experimental study of the empirical Lipschitz constant of deep networks undergoing double descent, and highlight non-monotonic trends strongly correlating with the test error. Building a connection between parameter-space and input-space gradients for SGD around a critical point, we isolate two important factors -- namely loss landscape curvature and distance of parameters from initialization -- respectively controlling optimization dynamics around a critical point and bounding model function complexity, even beyond the training data. Our study presents novels insights on implicit regularization via overparameterization, and effective model complexity for networks trained in practice. ",
    "url": "https://arxiv.org/abs/2301.12309",
    "authors": [
      "Matteo Gamba",
      "Hossein Azizpour",
      "M\u00e5rten Bj\u00f6rkman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12312",
    "title": "Accelerating Graph Analytics on a Reconfigurable Architecture with a  Data-Indirect Prefetcher",
    "abstract": "The irregular nature of memory accesses of graph workloads makes their performance poor on modern computing platforms. On manycore reconfigurable architectures (MRAs), in particular, even state-of-the-art graph prefetchers do not work well (only 3% speedup), since they are designed for traditional CPUs. This is because caches in MRAs are typically not large enough to host a large quantity of prefetched data, and many employs shared caches that such prefetchers simply do not support. This paper studies the design of a data prefetcher for an MRA called Transmuter. The prefetcher is built on top of Prodigy, the current best-performing data prefetcher for CPUs. The key design elements that adapt the prefetcher to the MRA include fused prefetcher status handling registers and a prefetch handshake protocol to support run-time reconfiguration, in addition, a redesign of the cache structure in Transmuter. An evaluation of popular graph workloads shows that synergistic integration of these architectures outperforms a baseline without prefetcher by 1.27x on average and by as much as 2.72x on some workloads. ",
    "url": "https://arxiv.org/abs/2301.12312",
    "authors": [
      "Yichen Yang",
      "Jingtao Li",
      "Nishil Talati",
      "Subhankar Pal",
      "Siying Feng",
      "Chaitali Chakrabarti",
      "Trevor Mudge",
      "Ronald Dreslinski"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2301.12313",
    "title": "Adapting Neural Link Predictors for Complex Query Answering",
    "abstract": "Answering complex queries on incomplete knowledge graphs is a challenging task where a model needs to answer complex logical queries in the presence of missing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022) showed that neural link predictors could also be used for answering complex queries: their Continuous Query Decomposition (CQD) method works by decomposing complex queries into atomic sub-queries, answers them using neural link predictors and aggregates their scores via t-norms for ranking the answers to each complex query. However, CQD does not handle negations and only uses the training signal from atomic training queries: neural link prediction scores are not calibrated to interact together via fuzzy logic t-norms during complex query answering. In this work, we propose to address this problem by training a parameter-efficient score adaptation model to re-calibrate neural link prediction scores: this new component is trained on complex queries by back-propagating through the complex query-answering process. Our method, CQD$^{A}$, produces significantly more accurate results than current state-of-the-art methods, improving from $34.4$ to $35.1$ Mean Reciprocal Rank values averaged across all datasets and query types while using $\\leq 35\\%$ of the available training query types. We further show that CQD$^{A}$ is data-efficient, achieving competitive results with only $1\\%$ of the training data, and robust in out-of-domain evaluations. ",
    "url": "https://arxiv.org/abs/2301.12313",
    "authors": [
      "Erik Arakelyan",
      "Pasquale Minervini",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.12318",
    "title": "Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering",
    "abstract": "Most existing methods to detect backdoored machine learning (ML) models take one of the two approaches: trigger inversion (aka. reverse engineer) and weight analysis (aka. model diagnosis). In particular, the gradient-based trigger inversion is considered to be among the most effective backdoor detection techniques, as evidenced by the TrojAI competition, Trojan Detection Challenge and backdoorBench. However, little has been done to understand why this technique works so well and, more importantly, whether it raises the bar to the backdoor attack. In this paper, we report the first attempt to answer this question by analyzing the change rate of the backdoored model around its trigger-carrying inputs. Our study shows that existing attacks tend to inject the backdoor characterized by a low change rate around trigger-carrying inputs, which are easy to capture by gradient-based trigger inversion. In the meantime, we found that the low change rate is not necessary for a backdoor attack to succeed: we design a new attack enhancement called \\textit{Gradient Shaping} (GRASP), which follows the opposite direction of adversarial training to reduce the change rate of a backdoored model with regard to the trigger, without undermining its backdoor effect. Also, we provide a theoretic analysis to explain the effectiveness of this new technique and the fundamental weakness of gradient-based trigger inversion. Finally, we perform both theoretical and experimental analysis, showing that the GRASP enhancement does not reduce the effectiveness of the stealthy attacks against the backdoor detection methods based on weight analysis, as well as other backdoor mitigation methods without using detection. ",
    "url": "https://arxiv.org/abs/2301.12318",
    "authors": [
      "Rui Zhu",
      "Di Tang",
      "Siyuan Tang",
      "Guanhong Tao",
      "Shiqing Ma",
      "Xiaofeng Wang",
      "Haixu Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12321",
    "title": "Neural Relation Graph for Identifying Problematic Data",
    "abstract": "Diagnosing and cleaning datasets are crucial for building robust machine learning systems. However, identifying problems within large-scale datasets with real-world distributions is difficult due to the presence of complex issues, such as label errors or under-representation of certain types. In this paper, we propose a novel approach for identifying problematic data by utilizing a largely ignored source of information: a relational structure of data in the feature-embedded space. We develop an efficient algorithm for detecting label errors and outlier data points based on the relational graph structure of the dataset. We further introduce a visualization tool for contextualizing data points, which can serve as an effective tool for interactively diagnosing datasets. We evaluate label error and out-of-distribution detection performances on large-scale image and language domain tasks, including ImageNet and GLUE benchmarks, and demonstrate the effectiveness of our approach for debugging datasets and building robust machine learning systems. ",
    "url": "https://arxiv.org/abs/2301.12321",
    "authors": [
      "Jang-Hyun Kim",
      "Sangdoo Yun",
      "Hyun Oh Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12343",
    "title": "Achieving Timestamp Prediction While Recognizing with Non-Autoregressive  End-to-End ASR Model",
    "abstract": "Conventional ASR systems use frame-level phoneme posterior to conduct force-alignment~(FA) and provide timestamps, while end-to-end ASR systems especially AED based ones are short of such ability. This paper proposes to perform timestamp prediction~(TP) while recognizing by utilizing continuous integrate-and-fire~(CIF) mechanism in non-autoregressive ASR model - Paraformer. Foucing on the fire place bias issue of CIF, we conduct post-processing strategies including fire-delay and silence insertion. Besides, we propose to use scaled-CIF to smooth the weights of CIF output, which is proved beneficial for both ASR and TP task. Accumulated averaging shift~(AAS) and diarization error rate~(DER) are adopted to measure the quality of timestamps and we compare these metrics of proposed system and conventional hybrid force-alignment system. The experiment results over manually-marked timestamps testset show that the proposed optimization methods significantly improve the accuracy of CIF timestamps, reducing 66.7\\% and 82.1\\% of AAS and DER respectively. Comparing to Kaldi force-alignment trained with the same data, optimized CIF timestamps achieved 12.3\\% relative AAS reduction. ",
    "url": "https://arxiv.org/abs/2301.12343",
    "authors": [
      "Xian Shi",
      "Yanni Chen",
      "Shiliang Zhang",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.12348",
    "title": "Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps",
    "abstract": "The privacy of personal information has received significant attention in mobile software. Although previous researchers have designed some methods to identify the conflict between app behavior and privacy policies, little is known about investigating regulation requirements for third-party libraries (TPLs). The regulators enacted multiple regulations to regulate the usage of personal information for TPLs (e.g., the \"California Consumer Privacy Act\" requires businesses clearly notify consumers if they share consumers' data with third parties or not). However, it remains challenging to analyze the legality of TPLs due to three reasons: 1) TPLs are mainly published on public repositoriesinstead of app market (e.g., Google play). The public repositories do not perform privacy compliance analysis for each TPL. 2) TPLs only provide independent functions or function sequences. They cannot run independently, which limits the application of performing dynamic analysis. 3) Since not all the functions of TPLs are related to user privacy, we must locate the functions of TPLs that access/process personal information before performing privacy compliance analysis. To overcome the above challenges, in this paper, we propose an automated system named ATPChecker to analyze whether the Android TPLs meet privacy-related regulations or not. Our findings remind developers to be mindful of TPL usage when developing apps or writing privacy policies to avoid violating regulations ",
    "url": "https://arxiv.org/abs/2301.12348",
    "authors": [
      "Zhao Kaifa",
      "Zhan Xian Zhan",
      "Yu Le",
      "Zhou Shiyao",
      "Zhou Hao",
      "LuoXiapu Luo",
      "Wang Haoyu",
      "Liu Yepang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12349",
    "title": "Encoding Node Diffusion Competence and Role Significance for Network  Dismantling",
    "abstract": "Percolation theory shows that removing a small fraction of critical nodes can lead to the disintegration of a large network into many disconnected tiny subnetworks. The network dismantling task focuses on how to efficiently select the least such critical nodes. Most existing approaches focus on measuring nodes' importance from either functional or topological viewpoint. Different from theirs, we argue that nodes' importance can be measured from both of the two complementary aspects: The functional importance can be based on the nodes' competence in relaying network information; While the topological importance can be measured from nodes' regional structural patterns. In this paper, we propose an unsupervised learning framework for network dismantling, called DCRS, which encodes and fuses both node diffusion competence and role significance. Specifically, we propose a graph diffusion neural network which emulates information diffusion for competence encoding; We divide nodes with similar egonet structural patterns into a few roles, and construct a role graph on which to encode node role significance. The DCRS converts and fuses the two encodings to output a final ranking score for selecting critical nodes. Experiments on both real-world networks and synthetic networks demonstrate that our scheme significantly outperforms the state-of-the-art competitors for its mostly requiring much fewer nodes to dismantle a network. ",
    "url": "https://arxiv.org/abs/2301.12349",
    "authors": [
      "Jiazheng Zhang",
      "Bang Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12351",
    "title": "On the Opportunity of Causal Deep Generative Models: A Survey and Future  Directions",
    "abstract": "Deep generative models have gained popularity in recent years due to their ability to accurately replicate inherent empirical distributions and yield novel samples. In particular, certain advances are proposed wherein the model engenders data examples following specified attributes. Nevertheless, several challenges still exist and are to be overcome, i.e., difficulty in extrapolating out-of-sample data and insufficient learning of disentangled representations. Structural causal models (SCMs), on the other hand, encapsulate the causal factors that govern a generative process and characterize a generative model based on causal relationships, providing crucial insights for addressing the current obstacles in deep generative models. In this paper, we present a comprehensive survey of Causal deep Generative Models (CGMs), which combine SCMs and deep generative models in a way that boosts several trustworthy properties such as robustness, fairness, and interpretability. We provide an overview of the recent advances in CGMs, categorize them based on generative types, and discuss how causality is introduced into the family of deep generative models. We also explore potential avenues for future research in this field. ",
    "url": "https://arxiv.org/abs/2301.12351",
    "authors": [
      "Guanglin Zhou",
      "Lina Yao",
      "Xiwei Xu",
      "Chen Wang",
      "Liming Zhu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12352",
    "title": "Maximal Cliques on Multi-Frame Proposal Graph for Unsupervised Video  Object Segmentation",
    "abstract": "Unsupervised Video Object Segmentation (UVOS) aims at discovering objects and tracking them through videos. For accurate UVOS, we observe if one can locate precise segment proposals on key frames, subsequent processes are much simpler. Hence, we propose to reason about key frame proposals using a graph built with the object probability masks initially generated from multiple frames around the key frame and then propagated to the key frame. On this graph, we compute maximal cliques, with each clique representing one candidate object. By making multiple proposals in the clique to vote for the key frame proposal, we obtain refined key frame proposals that could be better than any of the single-frame proposals. A semi-supervised VOS algorithm subsequently tracks these key frame proposals to the entire video. Our algorithm is modular and hence can be used with any instance segmentation and semi-supervised VOS algorithm. We achieve state-of-the-art performance on the DAVIS-2017 validation and test-dev dataset. On the related problem of video instance segmentation, our method shows competitive performance with the previous best algorithm that requires joint training with the VOS algorithm. ",
    "url": "https://arxiv.org/abs/2301.12352",
    "authors": [
      "Jialin Yuan",
      "Jay Patravali",
      "Hung Nguyen",
      "Chanho Kim",
      "Li Fuxin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12353",
    "title": "On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU  Network",
    "abstract": "This paper studies the expressive power of deep neural networks from the perspective of function compositions. We show that repeated compositions of a single fixed-size ReLU network can produce super expressive power. In particular, we prove by construction that $\\mathcal{L}_2\\circ \\boldsymbol{g}^{\\circ r}\\circ \\boldsymbol{\\mathcal{L}}_1$ can approximate $1$-Lipschitz continuous functions on $[0,1]^d$ with an error $\\mathcal{O}(r^{-1/d})$, where $\\boldsymbol{g}$ is realized by a fixed-size ReLU network, $\\boldsymbol{\\mathcal{L}}_1$ and $\\mathcal{L}_2$ are two affine linear maps matching the dimensions, and $\\boldsymbol{g}^{\\circ r}$ means the $r$-times composition of $\\boldsymbol{g}$. Furthermore, we extend such a result to generic continuous functions on $[0,1]^d$ with the approximation error characterized by the modulus of continuity. Our results reveal that a continuous-depth network generated via a dynamical system has good approximation power even if its dynamics function is time-independent and realized by a fixed-size ReLU network. ",
    "url": "https://arxiv.org/abs/2301.12353",
    "authors": [
      "Shijun Zhang",
      "Jianfeng Lu",
      "Hongkai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12355",
    "title": "Semantics-enhanced Temporal Graph Networks for Content Caching and  Energy Saving",
    "abstract": "The enormous amount of network equipment and users implies a tremendous growth of Internet traffic for multimedia services. To mitigate the traffic pressure, architectures with in-network storage are proposed to cache popular content at nodes in close proximity to users to shorten the backhaul links. Meanwhile, the reduction of transmission distance also contributes to the energy saving. However, due to limited storage, only a fraction of the content can be cached, while caching the most popular content is cost-effective. Correspondingly, it becomes essential to devise an effective popularity prediction method. In this regard, existing efforts adopt dynamic graph neural network (DGNN) models, but it remains challenging to tackle sparse datasets. In this paper, we first propose a reformative temporal graph network, which is named STGN, that utilizes extra semantic messages to enhance the temporal and structural learning of a DGNN model, since the consideration of semantics can help establish implicit paths within the sparse interaction graph and hence improve the prediction performance. Furthermore, we propose a user-specific attention mechanism to fine-grainedly aggregate various semantics. Finally, extensive simulations verify the superiority of our STGN models and demonstrate their high potential in energy-saving. ",
    "url": "https://arxiv.org/abs/2301.12355",
    "authors": [
      "Jianhang Zhu",
      "Rongpeng Li",
      "Xianfu Chen",
      "Shiwen Mao",
      "Jianjun Wu",
      "Zhifeng Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12356",
    "title": "Exploiting High Performance Spiking Neural Networks with Efficient  Spiking Patterns",
    "abstract": "Spiking Neural Networks (SNNs) use discrete spike sequences to transmit information, which significantly mimics the information transmission of the brain. Although this binarized form of representation dramatically enhances the energy efficiency and robustness of SNNs, it also leaves a large gap between the performance of SNNs and Artificial Neural Networks based on real values. There are many different spike patterns in the brain, and the dynamic synergy of these spike patterns greatly enriches the representation capability. Inspired by spike patterns in biological neurons, this paper introduces the dynamic Burst pattern and designs the Leaky Integrate and Fire or Burst (LIFB) neuron that can make a trade-off between short-time performance and dynamic temporal performance from the perspective of network information capacity. LIFB neuron exhibits three modes, resting, Regular spike, and Burst spike. The burst density of the neuron can be adaptively adjusted, which significantly enriches the characterization capability. We also propose a decoupling method that can losslessly decouple LIFB neurons into equivalent LIF neurons, which demonstrates that LIFB neurons can be efficiently implemented on neuromorphic hardware. We conducted experiments on the static datasets CIFAR10, CIFAR100, and ImageNet, which showed that we greatly improved the performance of the SNNs while significantly reducing the network latency. We also conducted experiments on neuromorphic datasets DVS-CIFAR10 and NCALTECH101 and showed that we achieved state-of-the-art with a small network structure. ",
    "url": "https://arxiv.org/abs/2301.12356",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12360",
    "title": "ADL-ID: Adversarial Disentanglement Learning for Wireless Device  Fingerprinting Temporal Domain Adaptation",
    "abstract": "As the journey of 5G standardization is coming to an end, academia and industry have already begun to consider the sixth-generation (6G) wireless networks, with an aim to meet the service demands for the next decade. Deep learning-based RF fingerprinting (DL-RFFP) has recently been recognized as a potential solution for enabling key wireless network applications and services, such as spectrum policy enforcement and network access control. The state-of-the-art DL-RFFP frameworks suffer from a significant performance drop when tested with data drawn from a domain that is different from that used for training data. In this paper, we propose ADL-ID, an unsupervised domain adaption framework that is based on adversarial disentanglement representation to address the temporal domain adaptation for the RFFP task. Our framework has been evaluated on real LoRa and WiFi datasets and showed about 24% improvement in accuracy when compared to the baseline CNN network on short-term temporal adaptation. It also improves the classification accuracy by up to 9% on long-term temporal adaptation. Furthermore, we release a 5-day, 2.1TB, large-scale WiFi 802.11b dataset collected from 50 Pycom devices to support the research community efforts in developing and validating robust RFFP methods. ",
    "url": "https://arxiv.org/abs/2301.12360",
    "authors": [
      "Abdurrahman Elmaghbub",
      "Bechir Hamdaoui",
      "Weng-Keen Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12379",
    "title": "FedConceptEM: Robust Federated Learning Under Diverse Distribution  Shifts",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that protects privacy by keeping client data on edge devices. However, optimizing FL in practice can be challenging due to the diversity and heterogeneity of the learning system. Recent research efforts have aimed to improve the optimization of FL with distribution shifts, but it is still an open problem how to train FL models when multiple types of distribution shifts, i.e., feature distribution skew, label distribution skew, and concept shift occur simultaneously. To address this challenge, we propose a novel algorithm framework, FedConceptEM, for handling diverse distribution shifts in FL. FedConceptEM automatically assigns clients with concept shifts to different models, avoiding the performance drop caused by these shifts. At the same time, clients without concept shifts, even with feature or label skew, are assigned to the same model, improving the robustness of the trained models. Extensive experiments demonstrate that FedConceptEM outperforms other state-of-the-art cluster-based FL methods by a significant margin. ",
    "url": "https://arxiv.org/abs/2301.12379",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12389",
    "title": "On Learning Necessary and Sufficient Causal Graphs",
    "abstract": "The causal revolution has spurred interest in understanding complex relationships in various fields. Most existing methods aim to discover causal relationships among all variables in a large-scale complex graph. However, in practice, only a small number of variables in the graph are relevant for the outcomes of interest. As a result, causal estimation with the full causal graph -- especially given limited data -- could lead to many falsely discovered, spurious variables that may be highly correlated with but have no causal impact on the target outcome. In this paper, we propose to learn a class of necessary and sufficient causal graphs (NSCG) that only contains causally relevant variables for an outcome of interest, which we term causal features. The key idea is to utilize probabilities of causation to systematically evaluate the importance of features in the causal graph, allowing us to identify a subgraph that is relevant to the outcome of interest. To learn NSCG from data, we develop a score-based necessary and sufficient causal structural learning (NSCSL) algorithm, by establishing theoretical relationships between probabilities of causation and causal effects of features. Across empirical studies of simulated and real data, we show that the proposed NSCSL algorithm outperforms existing algorithms and can reveal important yeast genes for target heritable traits of interest. ",
    "url": "https://arxiv.org/abs/2301.12389",
    "authors": [
      "Hengrui Cai",
      "Yixin Wang",
      "Michael Jordan",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12390",
    "title": "Enhancing Efficiency in Parallel Louvain Algorithm for Community  Detection",
    "abstract": "Community detection is a key aspect of network analysis, as it allows for the identification of groups and patterns within a network. With the ever-increasing size of networks, it is crucial to have fast algorithms to analyze them efficiently. It is a modularity-based greedy algorithm that divides a network into disconnected communities better over several iterations. Even in big, dense networks, it is renowned for establishing high-quality communities. However it can be at least a factor of ten slower than community discovery techniques that rely on label-propagation, which are generally extremely fast but obtain communities of lower quality. The researchers have suggested a number of methods for parallelizing and improving the Louvain algorithm. To decide which strategy is generally the best fit and which parameter values produce the highest performance without compromising community quality, it is critical to assess the performance and accuracy of these existing approaches. As we implement the single-threaded and multi-threaded versions of the static Louvain algorithm in this report, we carefully examine the method's specifics, make the required tweaks and optimizations, and determine the right parameter values. The tolerance between each pass can be changed to adjust the method's performance. With an initial tolerance of 0.01 and a tolerance decline factor of 10, an asynchronous version of the algorithm produced the best results. Generally speaking, according to our findings, the approach is not well suited for shared-memory parallelism; however, one potential workaround is to break the graph into manageable chunks that can be independently executed and then merged back together. ",
    "url": "https://arxiv.org/abs/2301.12390",
    "authors": [
      "Subhajit Sahu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.12398",
    "title": "Permanence based Hidden Community and Graph Recovery in Social Networks",
    "abstract": "Due to the recent development of data analysis techniques, technologies for detecting communities through information expressed in social networks have been developed. Although it has several advantages, including the ability to effectively share recommended items through an estimated community, it may cause personal privacy issues. Therefore, recently, the problem of hiding the real community well is being studied at the same time. As an example, Mittal \\etal, proposed an algorithm called NEURAL that can hide this community well based on a metric called permanence. Based on this, in this study, we propose a Reverse NEURAL (R-NEURAL) algorithm that restores the community as well as the original graph structure using permanence. The proposed algorithm includes a method for well restoring not only the community hidden by the NEURAL algorithm but also the original graph structure modified by recovered edges. We conduct experiments on real-world graphs and found that the proposed algorithm recovers well the hidden community as well as the graph structure. ",
    "url": "https://arxiv.org/abs/2301.12398",
    "authors": [
      "Jaeyoung Choi",
      "Wooseok Sim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12400",
    "title": "HeroNet: A Hybrid Retrieval-Generation Network for Conversational Bots",
    "abstract": "Using natural language, Conversational Bot offers unprecedented ways to many challenges in areas such as information searching, item recommendation, and question answering. Existing bots are usually developed through retrieval-based or generative-based approaches, yet both of them have their own advantages and disadvantages. To assemble this two approaches, we propose a hybrid retrieval-generation network (HeroNet) with the three-fold ideas: 1). To produce high-quality sentence representations, HeroNet performs multi-task learning on two subtasks: Similar Queries Discovery and Query-Response Matching. Specifically, the retrieval performance is improved while the model size is reduced by training two lightweight, task-specific adapter modules that share only one underlying T5-Encoder model. 2). By introducing adversarial training, HeroNet is able to solve both retrieval\\&generation tasks simultaneously while maximizing performance of each other. 3). The retrieval results are used as prior knowledge to improve the generation performance while the generative result are scored by the discriminator and their scores are integrated into the generator's cross-entropy loss function. The experimental results on a open dataset demonstrate the effectiveness of the HeroNet and our code is available at https://github.com/TempHero/HeroNet.git ",
    "url": "https://arxiv.org/abs/2301.12400",
    "authors": [
      "Bolin Zhang",
      "Yunzhe Xu",
      "Zhiying Tu",
      "Dianhui Chu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12402",
    "title": "Decision-Making Context Interaction Network for Click-Through Rate  Prediction",
    "abstract": "Click-through rate (CTR) prediction is crucial in recommendation and online advertising systems. Existing methods usually model user behaviors, while ignoring the informative context which influences the user to make a click decision, e.g., click pages and pre-ranking candidates that inform inferences about user interests, leading to suboptimal performance. In this paper, we propose a Decision-Making Context Interaction Network (DCIN), which deploys a carefully designed Context Interaction Unit (CIU) to learn decision-making contexts and thus benefits CTR prediction. In addition, the relationship between different decision-making context sources is explored by the proposed Adaptive Interest Aggregation Unit (AIAU) to improve CTR prediction further. In the experiments on public and industrial datasets, DCIN significantly outperforms the state-of-the-art methods. Notably, the model has obtained the improvement of CTR+2.9%/CPM+2.1%/GMV+1.5% for online A/B testing and served the main traffic of Meituan Waimai advertising system. ",
    "url": "https://arxiv.org/abs/2301.12402",
    "authors": [
      "Xiang Li",
      "Shuwei Chen",
      "Jian Dong",
      "Jin Zhang",
      "Yongkang Wang",
      "Xingxing Wang",
      "Dong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12412",
    "title": "Contextual Causal Bayesian Optimisation",
    "abstract": "Causal Bayesian optimisation (CaBO) combines causality with Bayesian optimisation (BO) and shows that there are situations where the optimal reward is not achievable if causal knowledge is ignored. While CaBO exploits causal relations to determine the set of controllable variables to intervene on, it does not exploit purely observational variables and marginalises them. We show that, in general, utilising a subset of observational variables as a context to choose the values of interventional variables leads to lower cumulative regrets. We propose a general framework of contextual causal Bayesian optimisation that efficiently searches through combinations of controlled and contextual variables, known as policy scopes, and identifies the one yielding the optimum. We highlight the difficulties arising from the application of the causal acquisition function currently used in CaBO to select the policy scope in contextual settings and propose a multi-armed bandits based selection mechanism. We analytically show that well-established methods, such as contextual BO (CoBO) or CaBO, are not able to achieve the optimum in some cases, and empirically show that the proposed method achieves sub-linear regret in various environments and under different configurations. ",
    "url": "https://arxiv.org/abs/2301.12412",
    "authors": [
      "Vahan Arsenyan",
      "Antoine Grosnit",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12444",
    "title": "Exploring Attention Map Reuse for Efficient Transformer Neural Networks",
    "abstract": "Transformer-based deep neural networks have achieved great success in various sequence applications due to their powerful ability to model long-range dependency. The key module of Transformer is self-attention (SA) which extracts features from the entire sequence regardless of the distance between positions. Although SA helps Transformer performs particularly well on long-range tasks, SA requires quadratic computation and memory complexity with the input sequence length. Recently, attention map reuse, which groups multiple SA layers to share one attention map, has been proposed and achieved significant speedup for speech recognition models. In this paper, we provide a comprehensive study on attention map reuse focusing on its ability to accelerate inference. We compare the method with other SA compression techniques and conduct a breakdown analysis of its advantages for a long sequence. We demonstrate the effectiveness of attention map reuse by measuring the latency on both CPU and GPU platforms. ",
    "url": "https://arxiv.org/abs/2301.12444",
    "authors": [
      "Kyuhong Shim",
      "Jungwook Choi",
      "Wonyong Sung"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12453",
    "title": "Boosting Automated Patch Correctness Prediction via Pre-trained Language  Model",
    "abstract": "Automated program repair (APR) aims to fix software bugs automatically without human debugging efforts and plays a crucial role in software development and maintenance. Despite the recent significant progress, APR is still challenged by a long-standing overfitting problem (i.e., the generated patch is plausible but overfitting). Various techniques have thus been proposed to address the overfitting problem. Among them, leveraging deep learning approaches to predict patch correctness is emerging along with the available large-scale patch benchmarks recently. However, existing learning-based techniques mainly rely on manually-designed code features, which can be extremely costly and challenging to construct in practice. In this paper, we propose APPT, a pre-trained model-based automated patch correctness assessment technique, which treats the source code as token sequences without extra overhead to design hand-crafted features. In particular, APPT adopts a pre-trained model as the encoder stack, followed by an LSTM stack and a deep learning classifier. Although our idea is general and can be built on various pre-trained models, we implemente APPT based on the BERT model. We conduct an extensive experiment on 1,183 Defects4J patches and the results show that APPT achieves prediction accuracy of 79.0% and recall of 81.3%, outperforming the state-of-the-art technique CACHE by 3.6% and 4.8%. Our additional investigation on 49,694 real-world patches shows that APPT achieves the optimum performance (exceeding 99% in five common metrics for assessing patch classification techniques) compared with existing representation learning techniques. We also prove that adopting code pre-trained models can further provide substantial advancement (e.g., GraphCodeBERT-based APPT improves BERT-based APPT by 3.0% and 2.6% in precision and recall, respectively), highlighting the generalizability of APPT. ",
    "url": "https://arxiv.org/abs/2301.12453",
    "authors": [
      "Quanjun Zhang",
      "Chunrong Fang",
      "Weisong Sun",
      "Yan Liu",
      "Tieke He",
      "Xiaodong Hao",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.12456",
    "title": "Towards Verifying the Geometric Robustness of Large-scale Neural  Networks",
    "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial geometric transformation. This paper aims to verify the robustness of large-scale DNNs against the combination of multiple geometric transformations with a provable guarantee. Given a set of transformations (e.g., rotation, scaling, etc.), we develop GeoRobust, a black-box robustness analyser built upon a novel global optimisation strategy, for locating the worst-case combination of transformations that affect and even alter a network's output. GeoRobust can provide provable guarantees on finding the worst-case combination based on recent advances in Lipschitzian theory. Due to its black-box nature, GeoRobust can be deployed on large-scale DNNs regardless of their architectures, activation functions, and the number of neurons. In practice, GeoRobust can locate the worst-case geometric transformation with high precision for the ResNet50 model on ImageNet in a few seconds on average. We examined 18 ImageNet classifiers, including the ResNet family and vision transformers, and found a positive correlation between the geometric robustness of the networks and the parameter numbers. We also observe that increasing the depth of DNN is more beneficial than increasing its width in terms of improving its geometric robustness. Our tool GeoRobust is available at https://github.com/TrustAI/GeoRobust. ",
    "url": "https://arxiv.org/abs/2301.12456",
    "authors": [
      "Fu Wang",
      "Peipei Xu",
      "Wenjie Ruan",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12457",
    "title": "EvoX: A Distributed GPU-accelerated Library towards Scalable  Evolutionary Computation",
    "abstract": "During the past decades, evolutionary computation (EC) has demonstrated promising potential in solving various complex optimization problems of relatively small scales. Nowadays, however, ongoing developments in modern science and engineering are bringing increasingly grave challenges to the conventional EC paradigm in terms of scalability. As problem scales increase, on the one hand, the encoding spaces (i.e., dimensions of the decision vectors) are intrinsically larger; on the other hand, EC algorithms often require growing numbers of function evaluations (and probably larger population sizes as well) to work properly. To meet such emerging challenges, not only does it require delicate algorithm designs, but more importantly, a high-performance computing framework is indispensable. Hence, we develop a distributed GPU-accelerated algorithm library -- EvoX. First, we propose a generalized workflow for implementing general EC algorithms. Second, we design a scalable computing framework for running EC algorithms on distributed GPU devices. Third, we provide user-friendly interfaces to both researchers and practitioners for benchmark studies as well as extended real-world applications. Empirically, we assess the promising scalability of EvoX via a series of benchmark experiments with problem dimensions/population sizes up to millions. Moreover, we demonstrate the easy usability of EvoX by applying it to solving reinforcement learning tasks on OpenAI Gym. To the best of our knowledge, this is the first library supporting distributed GPU computing in the EC literature. The code of EvoX is available at https://github.com/EMI-Group/EvoX. ",
    "url": "https://arxiv.org/abs/2301.12457",
    "authors": [
      "Beichen Huang",
      "Ran Cheng",
      "Yaochu Jin",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.12458",
    "title": "Self-supervised Semi-implicit Graph Variational Auto-encoders with  Masking",
    "abstract": "Generative graph self-supervised learning (SSL) aims to learn node representations by reconstructing the input graph data. However, most existing methods focus on unsupervised learning tasks only and very few work has shown its superiority over the state-of-the-art graph contrastive learning (GCL) models, especially on the classification task. While a very recent model has been proposed to bridge the gap, its performance on unsupervised learning tasks is still unknown. In this paper, to comprehensively enhance the performance of generative graph SSL against other GCL models on both unsupervised and supervised learning tasks, we propose the SeeGera model, which is based on the family of self-supervised variational graph auto-encoder (VGAE). Specifically, SeeGera adopts the semi-implicit variational inference framework, a hierarchical variational framework, and mainly focuses on feature reconstruction and structure/feature masking. On the one hand, SeeGera co-embeds both nodes and features in the encoder and reconstructs both links and features in the decoder. Since feature embeddings contain rich semantic information on features, they can be combined with node embeddings to provide fine-grained knowledge for feature reconstruction. On the other hand, SeeGera adds an additional layer for structure/feature masking to the hierarchical variational framework, which boosts the model generalizability. We conduct extensive experiments comparing SeeGera with 9 other state-of-the-art competitors. Our results show that SeeGera can compare favorably against other state-of-the-art GCL methods in a variety of unsupervised and supervised learning tasks. ",
    "url": "https://arxiv.org/abs/2301.12458",
    "authors": [
      "Xiang Li",
      "Tiandi Ye",
      "Caihua Shan",
      "Dongsheng Li",
      "Ming Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12471",
    "title": "Maximising Weather Forecasting Accuracy through the Utilisation of Graph  Neural Networks and Dynamic GNNs",
    "abstract": "Weather forecasting is an essential task to tackle global climate change. Weather forecasting requires the analysis of multivariate data generated by heterogeneous meteorological sensors. These sensors comprise of ground-based sensors, radiosonde, and sensors mounted on satellites, etc., To analyze the data generated by these sensors we use Graph Neural Networks (GNNs) based weather forecasting model. GNNs are graph learning-based models which show strong empirical performance in many machine learning approaches. In this research, we investigate the performance of weather forecasting using GNNs and traditional Machine learning-based models. ",
    "url": "https://arxiv.org/abs/2301.12471",
    "authors": [
      "Gaganpreet Singh",
      "Surya Durbha",
      "Shreelakshmi C R"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12473",
    "title": "Large Language Models for Biomedical Causal Graph Construction",
    "abstract": "Automatic causal graph construction is of high importance in medical research. They have many applications, such as clinical trial criteria design, where identification of confounding variables is a crucial step. The quality bar for clinical applications is high, and the lack of public corpora is a barrier for such studies. Large language models (LLMs) have demonstrated impressive capabilities in natural language processing and understanding, so applying such models in clinical settings is an attractive direction, especially in clinical applications with complex relations between entities, such as diseases, symptoms and treatments. Whereas, relation extraction has already been studied using LLMs, here we present an end-to-end machine learning solution of causal relationship analysis between aforementioned entities using EMR notes. Additionally, in comparison to other studies, we demonstrate extensive evaluation of the method. ",
    "url": "https://arxiv.org/abs/2301.12473",
    "authors": [
      "Vahan Arsenyan",
      "Davit Shahnazaryan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12477",
    "title": "StriderNET: A Graph Reinforcement Learning Approach to Optimize Atomic  Structures on Rough Energy Landscapes",
    "abstract": "Optimization of atomic structures presents a challenging problem, due to their highly rough and non-convex energy landscape, with wide applications in the fields of drug design, materials discovery, and mechanics. Here, we present a graph reinforcement learning approach, StriderNET, that learns a policy to displace the atoms towards low energy configurations. We evaluate the performance of StriderNET on three complex atomic systems, namely, binary Lennard-Jones particles, calcium silicate hydrates gel, and disordered silicon. We show that StriderNET outperforms all classical optimization algorithms and enables the discovery of a lower energy minimum. In addition, StriderNET exhibits a higher rate of reaching minima with energies, as confirmed by the average over multiple realizations. Finally, we show that StriderNET exhibits inductivity to unseen system sizes that are an order of magnitude different from the training system. ",
    "url": "https://arxiv.org/abs/2301.12477",
    "authors": [
      "Vaibhav Bihani",
      "Sahil Manchanda",
      "Srikanth Sastry",
      "Sayan Ranu",
      "N.M. Anoop Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12487",
    "title": "Mitigating Adversarial Effects of False Data Injection Attacks in Power  Grid",
    "abstract": "Deep Neural Networks have proven to be highly accurate at a variety of tasks in recent years. The benefits of Deep Neural Networks have also been embraced in power grids to detect False Data Injection Attacks (FDIA) while conducting critical tasks like state estimation. However, the vulnerabilities of DNNs along with the distinct infrastructure of cyber-physical-system (CPS) can favor the attackers to bypass the detection mechanism. Moreover, the divergent nature of CPS engenders limitations to the conventional defense mechanisms for False Data Injection Attacks. In this paper, we propose a DNN framework with additional layer which utilizes randomization to mitigate the adversarial effect by padding the inputs. The primary advantage of our method is when deployed to a DNN model it has trivial impact on the models performance even with larger padding sizes. We demonstrate the favorable outcome of the framework through simulation using the IEEE 14-bus, 30-bus, 118-bus and 300-bus systems. Furthermore to justify the framework we select attack techniques that generate subtle adversarial examples that can bypass the detection mechanism effortlessly. ",
    "url": "https://arxiv.org/abs/2301.12487",
    "authors": [
      "Farhin Farhad Riya",
      "Shahinul Hoque",
      "Jinyuan Stella Sun",
      "Jiangnan Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12493",
    "title": "Graph Mixer Networks",
    "abstract": "In recent years, the attention mechanism has demonstrated superior performance in various tasks, leading to the emergence of GAT and Graph Transformer models that utilize this mechanism to extract relational information from graph-structured data. However, the high computational cost associated with the Transformer block, as seen in Vision Transformers, has motivated the development of alternative architectures such as MLP-Mixers, which have been shown to improve performance in image tasks while reducing the computational cost. Despite the effectiveness of Transformers in graph-based tasks, their computational efficiency remains a concern. The logic behind MLP-Mixers, which addresses this issue in image tasks, has the potential to be applied to graph-structured data as well. In this paper, we propose the Graph Mixer Network (GMN), also referred to as Graph Nasreddin Nets (GNasNets), a framework that incorporates the principles of MLP-Mixers for graph-structured data. Using a PNA model with multiple aggregators as the foundation, our proposed GMN has demonstrated improved performance compared to Graph Transformers. The source code is available publicly at https://github.com/asarigun/GraphMixerNetworks. ",
    "url": "https://arxiv.org/abs/2301.12493",
    "authors": [
      "Ahmet Sar\u0131g\u00fcn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12515",
    "title": "LiDAR-CS Dataset: LiDAR Point Cloud Dataset with Cross-Sensors for 3D  Object Detection",
    "abstract": "LiDAR devices are widely used in autonomous driving scenarios and researches on 3D point cloud achieve remarkable progress over the past years. However, deep learning-based methods heavily rely on the annotation data and often face the domain generalization problem. Unlike 2D images whose domains are usually related to the texture information, the feature extracted from the 3D point cloud is affected by the distribution of the points. Due to the lack of a 3D domain adaptation benchmark, the common practice is to train the model on one benchmark (e.g, Waymo) and evaluate it on another dataset (e.g. KITTI). However, in this setting, there are two types of domain gaps, the scenarios domain, and sensors domain, making the evaluation and analysis complicated and difficult. To handle this situation, we propose LiDAR Dataset with Cross-Sensors (LiDAR-CS Dataset), which contains large-scale annotated LiDAR point cloud under 6 groups of different sensors but with same corresponding scenarios, captured from hybrid realistic LiDAR simulator. As far as we know, LiDAR-CS Dataset is the first dataset focused on the sensor (e.g., the points distribution) domain gaps for 3D object detection in real traffic. Furthermore, we evaluate and analyze the performance with several baseline detectors on the LiDAR-CS benchmark and show its applications. ",
    "url": "https://arxiv.org/abs/2301.12515",
    "authors": [
      "Jin Fang",
      "Dingfu Zhou",
      "Jingjing Zhao",
      "Chulin Tang",
      "Cheng-Zhong Xu",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12519",
    "title": "3D Object Detection in LiDAR Point Clouds using Graph Neural Networks",
    "abstract": "LiDAR (Light Detection and Ranging) is an advanced active remote sensing technique working on the principle of time of travel (ToT) for capturing highly accurate 3D information of the surroundings. LiDAR has gained wide attention in research and development with the LiDAR industry expected to reach 2.8 billion $ by 2025. Although the LiDAR dataset is of rich density and high spatial resolution, it is challenging to process LiDAR data due to its inherent 3D geometry and massive volume. But such a high-resolution dataset possesses immense potential in many applications and has great potential in 3D object detection and recognition. In this research we propose Graph Neural Network (GNN) based framework to learn and identify the objects in the 3D LiDAR point clouds. GNNs are class of deep learning which learns the patterns and objects based on the principle of graph learning which have shown success in various 3D computer vision tasks. ",
    "url": "https://arxiv.org/abs/2301.12519",
    "authors": [
      "Shreelakshmi C R",
      "Surya S. Durbha",
      "Gaganpreet Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12530",
    "title": "G-Rank: Unsupervised Continuous Learn-to-Rank for Edge Devices in a P2P  Network",
    "abstract": "Ranking algorithms in traditional search engines are powered by enormous training data sets that are meticulously engineered and curated by a centralized entity. Decentralized peer-to-peer (p2p) networks such as torrenting applications and Web3 protocols deliberately eschew centralized databases and computational architectures when designing services and features. As such, robust search-and-rank algorithms designed for such domains must be engineered specifically for decentralized networks, and must be lightweight enough to operate on consumer-grade personal devices such as a smartphone or laptop computer. We introduce G-Rank, an unsupervised ranking algorithm designed exclusively for decentralized networks. We demonstrate that accurate, relevant ranking results can be achieved in fully decentralized networks without any centralized data aggregation, feature engineering, or model training. Furthermore, we show that such results are obtainable with minimal data preprocessing and computational overhead, and can still return highly relevant results even when a user's device is disconnected from the network. G-Rank is highly modular in design, is not limited to categorical data, and can be implemented in a variety of domains with minimal modification. The results herein show that unsupervised ranking models designed for decentralized p2p networks are not only viable, but worthy of further research. ",
    "url": "https://arxiv.org/abs/2301.12530",
    "authors": [
      "Andrew Gold",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12535",
    "title": "Concurrent Shuffle Differential Privacy Under Continual Observation",
    "abstract": "We introduce the concurrent shuffle model of differential privacy. In this model we have multiple concurrent shufflers permuting messages from different, possibly overlapping, batches of users. Similarly to the standard (single) shuffle model, the privacy requirement is that the concatenation of all shuffled messages should be differentially private. We study the private continual summation problem (a.k.a. the counter problem) and show that the concurrent shuffle model allows for significantly improved error compared to a standard (single) shuffle model. Specifically, we give a summation algorithm with error $\\tilde{O}(n^{1/(2k+1)})$ with $k$ concurrent shufflers on a sequence of length $n$. Furthermore, we prove that this bound is tight for any $k$, even if the algorithm can choose the sizes of the batches adaptively. For $k=\\log n$ shufflers, the resulting error is polylogarithmic, much better than $\\tilde{\\Theta}(n^{1/3})$ which we show is the smallest possible with a single shuffler. We use our online summation algorithm to get algorithms with improved regret bounds for the contextual linear bandit problem. In particular we get optimal $\\tilde{O}(\\sqrt{n})$ regret with $k= \\tilde{\\Omega}(\\log n)$ concurrent shufflers. ",
    "url": "https://arxiv.org/abs/2301.12535",
    "authors": [
      "Jay Tenenbaum",
      "Haim Kaplan",
      "Yishay Mansour",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12541",
    "title": "Supervised and Contrastive Self-Supervised In-Domain Representation  Learning for Dense Prediction Problems in Remote Sensing",
    "abstract": "In recent years Convolutional neural networks (CNN) have made significant progress in computer vision. These advancements have been applied to other areas, such as remote sensing and have shown satisfactory results. However, the lack of large labeled datasets and the inherent complexity of remote sensing problems have made it difficult to train deep CNNs for dense prediction problems. To solve this issue, ImageNet pretrained weights have been used as a starting point in various dense predictions tasks. Although this type of transfer learning has led to improvements, the domain difference between natural and remote sensing images has also limited the performance of deep CNNs. On the other hand, self-supervised learning methods for learning visual representations from large unlabeled images have grown substantially over the past two years. Accordingly, in this paper we have explored the effectiveness of in-domain representations in both supervised and self-supervised forms to solve the domain difference between remote sensing and the ImageNet dataset. The obtained weights from remote sensing images are utilized as initial weights for solving semantic segmentation and object detection tasks and state-of-the-art results are obtained. For self-supervised pre-training, we have utilized the SimSiam algorithm as it is simple and does not need huge computational resources. One of the most influential factors in acquiring general visual representations from remote sensing images is the pre-training dataset. To examine the effect of the pre-training dataset, equal-sized remote sensing datasets are used for pre-training. Our results have demonstrated that using datasets with a high spatial resolution for self-supervised representation learning leads to high performance in downstream tasks. ",
    "url": "https://arxiv.org/abs/2301.12541",
    "authors": [
      "Ali Ghanbarzade",
      "Dr. Hossein Soleimani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12549",
    "title": "Scaling in Depth: Unlocking Robustness Certification on ImageNet",
    "abstract": "Notwithstanding the promise of Lipschitz-based approaches to \\emph{deterministically} train and certify robust deep networks, the state-of-the-art results only make successful use of feed-forward Convolutional Networks (ConvNets) on low-dimensional data, e.g. CIFAR-10. Because ConvNets often suffer from vanishing gradients when going deep, large-scale datasets with many classes, e.g., ImageNet, have remained out of practical reach. This paper investigates ways to scale up certifiably robust training to Residual Networks (ResNets). First, we introduce the \\emph{Linear ResNet} (LiResNet) architecture, which utilizes a new residual block designed to facilitate \\emph{tighter} Lipschitz bounds compared to a conventional residual block. Second, we introduce Efficient Margin MAximization (EMMA), a loss function that stabilizes robust training by simultaneously penalizing worst-case adversarial examples from \\emph{all} classes. Combining LiResNet and EMMA, we achieve new \\emph{state-of-the-art} robust accuracy on CIFAR-10/100 and Tiny-ImageNet under $\\ell_2$-norm-bounded perturbations. Moreover, for the first time, we are able to scale up deterministic robustness guarantees to ImageNet, bringing hope to the possibility of applying deterministic certification to real-world applications. ",
    "url": "https://arxiv.org/abs/2301.12549",
    "authors": [
      "Kai Hu",
      "Andy Zou",
      "Zifan Wang",
      "Klas Leino",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12562",
    "title": "Simplifying Subgraph Representation Learning for Scalable Link  Prediction",
    "abstract": "Link prediction on graphs is a fundamental problem in graph representation learning. Subgraph representation learning approaches (SGRLs), by transforming link prediction to graph classification on the subgraphs around the target links, have advanced the learning capability of Graph Neural Networks (GNNs) for link prediction. Despite their state-of-the-art performance, SGRLs are computationally expensive, and not scalable to large-scale graphs due to their expensive subgraph-level operations for each target link. To unlock the scalability of SGRLs, we propose a new class of SGRLs, that we call Scalable Simplified SGRL (S3GRL). Aimed at faster training and inference, S3GRL simplifies the message passing and aggregation operations in each link's subgraph. S3GRL, as a scalability framework, flexibly accommodates various subgraph sampling strategies and diffusion operators to emulate computationally-expensive SGRLs. We further propose and empirically study multiple instances of S3GRL. Our extensive experiments demonstrate that the proposed S3GRL models scale up SGRLs without any significant performance compromise (even with considerable gains in some cases), while offering substantially lower computational footprints (e.g., multi-fold inference and training speedup). ",
    "url": "https://arxiv.org/abs/2301.12562",
    "authors": [
      "Paul Louis",
      "Shweta Ann Jacob",
      "Amirali Salehi-Abari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12563",
    "title": "Multi-Priority Graph Sparsification",
    "abstract": "A \\emph{sparsification} of a given graph $G$ is a sparser graph (typically a subgraph) which aims to approximate or preserve some property of $G$. Examples of sparsifications include but are not limited to spanning trees, Steiner trees, spanners, emulators, and distance preservers. Each vertex has the same priority in all of these problems. However, real-world graphs typically assign different ``priorities'' or ``levels'' to different vertices, in which higher-priority vertices require higher-quality connectivity between them. Multi-priority variants of the Steiner tree problem have been studied in prior literature but this generalization is much less studied for other sparsification problems. In this paper, we define a generalized multi-priority problem and present a rounding-up approach that can be used for a variety of graph sparsifications. Our analysis provides a systematic way to compute approximate solutions to multi-priority variants of a wide range of graph sparsification problems given access to a single-priority subroutine. ",
    "url": "https://arxiv.org/abs/2301.12563",
    "authors": [
      "Reyan Ahmed",
      "Keaton Hamm",
      "Stephen Kobourov",
      "Mohammad Javad Latifi Jebelli",
      "Faryad Darabi Sahneh",
      "Richard Spence"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.12576",
    "title": "Uncovering Adversarial Risks of Test-Time Adaptation",
    "abstract": "Recently, test-time adaptation (TTA) has been proposed as a promising solution for addressing distribution shifts. It allows a base model to adapt to an unforeseen distribution during inference by leveraging the information from the batch of (unlabeled) test data. However, we uncover a novel security vulnerability of TTA based on the insight that predictions on benign samples can be impacted by malicious samples in the same batch. To exploit this vulnerability, we propose Distribution Invading Attack (DIA), which injects a small fraction of malicious data into the test batch. DIA causes models using TTA to misclassify benign and unperturbed test data, providing an entirely new capability for adversaries that is infeasible in canonical machine learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness of our attack on multiple benchmarks across six TTA methods. In response, we investigate two countermeasures to robustify the existing insecure TTA implementations, following the principle of \"security by design\". Together, we hope our findings can make the community aware of the utility-security tradeoffs in deploying TTA and provide valuable insights for developing robust TTA approaches. ",
    "url": "https://arxiv.org/abs/2301.12576",
    "authors": [
      "Tong Wu",
      "Feiran Jia",
      "Xiangyu Qi",
      "Jiachen T. Wang",
      "Vikash Sehwag",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12593",
    "title": "Risk-Averse Model Uncertainty for Distributionally Robust Safe  Reinforcement Learning",
    "abstract": "Many real-world domains require safe decision making in the presence of uncertainty. In this work, we propose a deep reinforcement learning framework for approaching this important problem. We consider a risk-averse perspective towards model uncertainty through the use of coherent distortion risk measures, and we show that our formulation is equivalent to a distributionally robust safe reinforcement learning problem with robustness guarantees on performance and safety. We propose an efficient implementation that only requires access to a single training environment, and we demonstrate that our framework produces robust, safe performance on a variety of continuous control tasks with safety constraints in the Real-World Reinforcement Learning Suite. ",
    "url": "https://arxiv.org/abs/2301.12593",
    "authors": [
      "James Queeney",
      "Mouhacine Benosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12594",
    "title": "A theory of continuous generative flow networks",
    "abstract": "Generative flow networks (GFlowNets) are amortized variational inference algorithms that are trained to sample from unnormalized target distributions over compositional objects. A key limitation of GFlowNets until this time has been that they are restricted to discrete spaces. We present a theory for generalized GFlowNets, which encompasses both existing discrete GFlowNets and ones with continuous or hybrid state spaces, and perform experiments with two goals in mind. First, we illustrate critical points of the theory and the importance of various assumptions. Second, we empirically demonstrate how observations about discrete GFlowNets transfer to the continuous case and show strong results compared to non-GFlowNet baselines on several previously studied tasks. This work greatly widens the perspectives for the application of GFlowNets in probabilistic inference and various modeling settings. ",
    "url": "https://arxiv.org/abs/2301.12594",
    "authors": [
      "Salem Lahlou",
      "Tristan Deleu",
      "Pablo Lemos",
      "Dinghuai Zhang",
      "Alexandra Volokhova",
      "Alex Hern\u00e1ndez-Garc\u00eda",
      "L\u00e9na N\u00e9hale Ezzine",
      "Yoshua Bengio",
      "Nikolay Malkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12595",
    "title": "Adversarial Attacks on Adversarial Bandits",
    "abstract": "We study a security threat to adversarial multi-armed bandits, in which an attacker perturbs the loss or reward signal to control the behavior of the victim bandit player. We show that the attacker is able to mislead any no-regret adversarial bandit algorithm into selecting a suboptimal target arm in every but sublinear (T-o(T)) number of rounds, while incurring only sublinear (o(T)) cumulative attack cost. This result implies critical security concern in real-world bandit-based systems, e.g., in online recommendation, an attacker might be able to hijack the recommender system and promote a desired product. Our proposed attack algorithms require knowledge of only the regret rate, thus are agnostic to the concrete bandit algorithm employed by the victim player. We also derived a theoretical lower bound on the cumulative attack cost that any victim-agnostic attack algorithm must incur. The lower bound matches the upper bound achieved by our attack, which shows that our attack is asymptotically optimal. ",
    "url": "https://arxiv.org/abs/2301.12595",
    "authors": [
      "Yuzhe Ma",
      "Zhijin Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12603",
    "title": "Do We Really Need Graph Neural Networks for Traffic Forecasting?",
    "abstract": "Spatio-temporal graph neural networks (STGNN) have become the most popular solution to traffic forecasting. While successful, they rely on the message passing scheme of GNNs to establish spatial dependencies between nodes, and thus inevitably inherit GNNs' notorious inefficiency. Given these facts, in this paper, we propose an embarrassingly simple yet remarkably effective spatio-temporal learning approach, entitled SimST. Specifically, SimST approximates the efficacies of GNNs by two spatial learning techniques, which respectively model local and global spatial correlations. Moreover, SimST can be used alongside various temporal models and involves a tailored training strategy. We conduct experiments on five traffic benchmarks to assess the capability of SimST in terms of efficiency and effectiveness. Empirical results show that SimST improves the prediction throughput by up to 39 times compared to more sophisticated STGNNs while attaining comparable performance, which indicates that GNNs are not the only option for spatial modeling in traffic forecasting. ",
    "url": "https://arxiv.org/abs/2301.12603",
    "authors": [
      "Xu Liu",
      "Yuxuan Liang",
      "Chao Huang",
      "Hengchang Hu",
      "Yushi Cao",
      "Bryan Hooi",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12605",
    "title": "Traffic Prediction in Cellular Networks using Graph Neural Networks",
    "abstract": "Cellular networks are ubiquitous entities that provide major means of communication all over the world. One major challenge in cellular networks is a dynamic change in the number of users and their usage of telecommunication service which results in overloading at certain base stations. One class of solution to deal with this overloading issue is the deployment of drones that can act as temporary base stations and offload the traffic from the overloaded base station. There are two main challenges in the development of this solution. Firstly, the drone is expected to be present around the base station where an overload would occur in the future thus requiring a prediction of traffic overload. Secondly, drones are highly constrained in their resources and can only fly for a few minutes. If the affected base station is really far, drones can never reach there. This requires the initial placement of drones in sectors where overloading can occur thus again requiring a traffic forecast but at a different spatial scale. It must be noted that the spatial extent of the region that the problem poses and the extremely limited power resources available to the drone pose a great challenge that is hard to overcome without deploying the drones in strategic positions to reduce the time to fly to the required high-demand zone. Moreover, since drone fly at a finite speed, it is important that a predictive solution that can forecast traffic surges is adopted so that drones are available to offload the overload before it actually happens. Both these goals require analysis and forecast of cellular network traffic which is the main goal of this project ",
    "url": "https://arxiv.org/abs/2301.12605",
    "authors": [
      "Maryam Khalid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12630",
    "title": "Maximal co-occurrence nonoverlapping sequential rule mining",
    "abstract": "The aim of sequential pattern mining (SPM) is to discover potentially useful information from a given se-quence. Although various SPM methods have been investigated, most of these focus on mining all of the patterns. However, users sometimes want to mine patterns with the same specific prefix pattern, called co-occurrence pattern. Since sequential rule mining can make better use of the results of SPM, and obtain better recommendation performance, this paper addresses the issue of maximal co-occurrence nonoverlapping sequential rule (MCoR) mining and proposes the MCoR-Miner algo-rithm. To improve the efficiency of support calculation, MCoR-Miner employs depth-first search and backtracking strategies equipped with an indexing mechanism to avoid the use of sequential searching. To obviate useless support calculations for some sequences, MCoR-Miner adopts a filtering strategy to prune the sequences without the prefix pattern. To reduce the number of candidate patterns, MCoR-Miner applies the frequent item and binomial enumeration tree strategies. To avoid searching for the maximal rules through brute force, MCoR-Miner uses a screening strategy. To validate the per-formance of MCoR-Miner, eleven competitive algorithms were conducted on eight sequences. Our experimental results showed that MCoR-Miner outperformed other competitive algorithms, and yielded better recommendation performance than frequent co-occurrence pattern mining. All algorithms and datasets can be downloaded from https://github.com/wuc567/Pattern-Mining/tree/master/MCoR-Miner. ",
    "url": "https://arxiv.org/abs/2301.12630",
    "authors": [
      "Yan Li",
      "Chang Zhang",
      "Jie Li",
      "Wei Song",
      "Zhenlian Qi",
      "Youxi Wu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2301.12643",
    "title": "Adversarial Style Augmentation for Domain Generalization",
    "abstract": "It is well-known that the performance of well-trained deep neural networks may degrade significantly when they are applied to data with even slightly shifted distributions. Recent studies have shown that introducing certain perturbation on feature statistics (\\eg, mean and standard deviation) during training can enhance the cross-domain generalization ability. Existing methods typically conduct such perturbation by utilizing the feature statistics within a mini-batch, limiting their representation capability. Inspired by the domain generalization objective, we introduce a novel Adversarial Style Augmentation (ASA) method, which explores broader style spaces by generating more effective statistics perturbation via adversarial training. Specifically, we first search for the most sensitive direction and intensity for statistics perturbation by maximizing the task loss. By updating the model against the adversarial statistics perturbation during training, we allow the model to explore the worst-case domain and hence improve its generalization performance. To facilitate the application of ASA, we design a simple yet effective module, namely AdvStyle, which instantiates the ASA method in a plug-and-play manner. We justify the efficacy of AdvStyle on tasks of cross-domain classification and instance retrieval. It achieves higher mean accuracy and lower performance fluctuation. Especially, our method significantly outperforms its competitors on the PACS dataset under the single source generalization setting, \\eg, boosting the classification accuracy from 61.2\\% to 67.1\\% with a ResNet50 backbone. Our code will be available at \\url{https://github.com/YBZh/AdvStyle}. ",
    "url": "https://arxiv.org/abs/2301.12643",
    "authors": [
      "Yabin Zhang",
      "Bin Deng",
      "Ruihuang Li",
      "Kui Jia",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12667",
    "title": "NeSyFOLD: A System for Generating Logic-based Explanations from  Convolutional Neural Networks",
    "abstract": "We present a novel neurosymbolic system called NeSyFOLD that classifies images while providing a logic-based explanation of the classification. NeSyFOLD's training process is as follows: (i) We first pre-train a CNN on the input image dataset and extract activations of the last layer filters as binary values; (ii) Next, we use the FOLD-SE-M rule-based machine learning algorithm to generate a logic program that can classify an image -- represented as a vector of binary activations corresponding to each filter -- while producing a logical explanation. The rules generated by the FOLD-SE-M algorithm have filter numbers as predicates. We use a novel algorithm that we have devised for automatically mapping the CNN filters to semantic concepts in the images. This mapping is used to replace predicate names (filter numbers) in the rule-set with corresponding semantic concept labels. The resulting rule-set is highly interpretable, and can be intuitively understood by humans. We compare our NeSyFOLD system with the ERIC system that uses a decision-tree like algorithm to obtain the rules. Our system has the following advantages over ERIC: (i) NeSyFOLD generates smaller rule-sets without compromising on the accuracy and fidelity; (ii) NeSyFOLD generates the mapping of filter numbers to semantic labels automatically. ",
    "url": "https://arxiv.org/abs/2301.12667",
    "authors": [
      "Parth Padalkar",
      "Huaduo Wang",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12678",
    "title": "The Meta Distribution of SINR in UAV-Assisted Cellular Networks",
    "abstract": "Mounting compact and lightweight base stations on unmanned aerial vehicles (UAVs) is a cost-effective and flexible solution to provide seamless coverage on the existing terrestrial networks. While the coverage probability in UAV-assisted cellular networks has been widely investigated, it provides only the first-order statistic of signal-to-interference-plus-noise ratio (SINR). In this paper, to analyze high-order statistics of SINR and characterize the disparity among individual links, we provide a meta distribution (MD)-based analytical framework for UAV-assisted cellular networks, in which the probabilistic line-of-sight channel and realistic antenna pattern are taken into account for air-to-ground transmissions. To accurately characterize the interference from UAVs, we relax the widely applied uniform off-boresight angle (OBA) assumption and derive the exact distribution of OBA. Using stochastic geometry, for both steerable and vertical antenna scenarios, we obtain mathematical expressions for the moments of condition success probability, the SINR MD, and the mean local delay. Moreover, we study the asymptotic behavior of the moments as network density approaches infinity. Numerical results validate the tightness of the theoretical results and show that the uniform OBA assumption underestimates the network performance, especially in the regime of moderate altitude of UAV. We also show that when UAVs are equipped with steerable antennas, the network coverage and user fairness can be optimized simultaneously by carefully adjusting the UAV parameters. ",
    "url": "https://arxiv.org/abs/2301.12678",
    "authors": [
      "Minwei Shi",
      "Kai Yang",
      "Dusit Niyato",
      "Hang Yuan",
      "He Zhou",
      "Zhan Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.12680",
    "title": "Feature-Space Bayesian Adversarial Learning Improved Malware Detector  Robustness",
    "abstract": "We present a new algorithm to train a robust malware detector. Modern malware detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional. This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness. We prove that our learning method bounds the difference between the adversarial risk and empirical risk explaining the improved robustness. We show that adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples. ",
    "url": "https://arxiv.org/abs/2301.12680",
    "authors": [
      "Bao Gia Doan",
      "Shuiqiao Yang",
      "Paul Montague",
      "Olivier De Vel",
      "Tamas Abraham",
      "Seyit Camtepe",
      "Salil S. Kanhere",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12698",
    "title": "Robust Meta Learning for Image based tasks",
    "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we learn an optimal model in training data, it could have better generalization performance in testing tasks. However, learning such a model is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel robust meta-learning method, which is more robust to the image-based testing tasks which is unknown and has distribution shifts with training tasks. Our robust meta-learning method can provide robust optimal models even when data from each distribution are scarce. In experiments, we demonstrate that our algorithm not only has better generalization performance but also robust to different unknown testing tasks. ",
    "url": "https://arxiv.org/abs/2301.12698",
    "authors": [
      "Penghao Jiang",
      "Xin Ke",
      "ZiFeng Wang",
      "Chunxi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12699",
    "title": "KG-BERTScore: Incorporating Knowledge Graph into BERTScore for  Reference-Free Machine Translation Evaluation",
    "abstract": "BERTScore is an effective and robust automatic metric for referencebased machine translation evaluation. In this paper, we incorporate multilingual knowledge graph into BERTScore and propose a metric named KG-BERTScore, which linearly combines the results of BERTScore and bilingual named entity matching for reference-free machine translation evaluation. From the experimental results on WMT19 QE as a metric without references shared tasks, our metric KG-BERTScore gets higher overall correlation with human judgements than the current state-of-the-art metrics for reference-free machine translation evaluation.1 Moreover, the pre-trained multilingual model used by KG-BERTScore and the parameter for linear combination are also studied in this paper. ",
    "url": "https://arxiv.org/abs/2301.12699",
    "authors": [
      "Zhanglin Wu",
      "Min Zhang",
      "Ming Zhu",
      "Yinglu Li",
      "Ting Zhu",
      "Hao Yang",
      "Song Peng",
      "Ying Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12715",
    "title": "Fine-Tuning Deteriorates General Textual Out-of-Distribution Detection  by Distorting Task-Agnostic Features",
    "abstract": "Detecting out-of-distribution (OOD) inputs is crucial for the safe deployment of natural language processing (NLP) models. Though existing methods, especially those based on the statistics in the feature space of fine-tuned pre-trained language models (PLMs), are claimed to be effective, their effectiveness on different types of distribution shifts remains underexplored. In this work, we take the first step to comprehensively evaluate the mainstream textual OOD detection methods for detecting semantic and non-semantic shifts. We find that: (1) no existing method behaves well in both settings; (2) fine-tuning PLMs on in-distribution data benefits detecting semantic shifts but severely deteriorates detecting non-semantic shifts, which can be attributed to the distortion of task-agnostic features. To alleviate the issue, we present a simple yet effective general OOD score named GNOME that integrates the confidence scores derived from the task-agnostic and task-specific representations. Experiments show that GNOME works well in both semantic and non-semantic shift scenarios, and further brings significant improvement on two cross-task benchmarks where both kinds of shifts simultaneously take place. Our code is available at https://github.com/lancopku/GNOME. ",
    "url": "https://arxiv.org/abs/2301.12715",
    "authors": [
      "Sishuo Chen",
      "Wenkai Yang",
      "Xiaohan Bi",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12717",
    "title": "Automatic Intersection Management in Mixed Traffic Using Reinforcement  Learning and Graph Neural Networks",
    "abstract": "Connected automated driving has the potential to significantly improve urban traffic efficiency, e.g., by alleviating issues due to occlusion. Cooperative behavior planning can be employed to jointly optimize the motion of multiple vehicles. Most existing approaches to automatic intersection management, however, only consider fully automated traffic. In practice, mixed traffic, i.e., the simultaneous road usage by automated and human-driven vehicles, will be prevalent. The present work proposes to leverage reinforcement learning and a graph-based scene representation for cooperative multi-agent planning. We build upon our previous works that showed the applicability of such machine learning methods to fully automated traffic. The scene representation is extended for mixed traffic and considers uncertainty in the human drivers' intentions. In the simulation-based evaluation, we model measurement uncertainties through noise processes that are tuned using real-world data. The paper evaluates the proposed method against an enhanced first in - first out scheme, our baseline for mixed traffic management. With increasing share of automated vehicles, the learned planner significantly increases the vehicle throughput and reduces the delay due to interaction. Non-automated vehicles benefit virtually alike. ",
    "url": "https://arxiv.org/abs/2301.12717",
    "authors": [
      "Marvin Klimke",
      "Benjamin V\u00f6lz",
      "Michael Buchholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12721",
    "title": "Robust Attributed Graph Alignment via Joint Structure Learning and  Optimal Transport",
    "abstract": "Graph alignment, which aims at identifying corresponding entities across multiple networks, has been widely applied in various domains. As the graphs to be aligned are usually constructed from different sources, the inconsistency issues of structures and features between two graphs are ubiquitous in real-world applications. Most existing methods follow the ``embed-then-cross-compare'' paradigm, which computes node embeddings in each graph and then processes node correspondences based on cross-graph embedding comparison. However, we find these methods are unstable and sub-optimal when structure or feature inconsistency appears. To this end, we propose SLOTAlign, an unsupervised graph alignment framework that jointly performs Structure Learning and Optimal Transport Alignment. We convert graph alignment to an optimal transport problem between two intra-graph matrices without the requirement of cross-graph comparison. We further incorporate multi-view structure learning to enhance graph representation power and reduce the effect of structure and feature inconsistency inherited across graphs. Moreover, an alternating scheme based algorithm has been developed to address the joint optimization problem in SLOTAlign, and the provable convergence result is also established. Finally, we conduct extensive experiments on six unsupervised graph alignment datasets and the DBP15K knowledge graph (KG) alignment benchmark dataset. The proposed SLOTAlign shows superior performance and strongest robustness over seven unsupervised graph alignment methods and five specialized KG alignment methods. ",
    "url": "https://arxiv.org/abs/2301.12721",
    "authors": [
      "Jianheng Tang",
      "Weiqi Zhang",
      "Jiajin Li",
      "Kangfei Zhao",
      "Fugee Tsung",
      "Jia Li"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12723",
    "title": "Measuring robustness of dynamical systems. Relating time and space to  length and precision",
    "abstract": "Verification of discrete time or continuous time dynamical systems over the reals is known to be undecidable. It is however known that undecidability does not hold for various classes of systems: if robustness is defined as the fact that reachability relation is stable under infinitesimal perturbation, then their reachability relation is decidable. In other words, undecidability implies sensitivity under infinitesimal perturbation, a property usually not expected in systems considered in practice, and hence can be seen (somehow informally) as an artefact of the theory, that always assumes exactness. In a similar vein, it is known that, while undecidability holds for logical formulas over the reals, it does not hold when considering delta-undecidability: one must determine whether a property is true, or $\\delta$-far from being true. We first extend the previous statements to a theory for general (discrete time, continuous-time, and even hybrid) dynamical systems, and we relate the two approaches. We also relate robustness to some geometric properties of reachability relation. But mainly, when a system is robust, it then makes sense to quantify at which level of perturbation. We prove that assuming robustness to polynomial perturbations on precision leads to reachability verifiable in complexity class PSPACE, and even to a characterization of this complexity class. We prove that assuming robustness to polynomial perturbations on time or length of trajectories leads to similar statements, but with PTIME. It has been recently unexpectedly shown that the length of a solution of a polynomial ordinary differential equation corresponds to a time of computation: PTIME corresponds to solutions of polynomial differential equations of polynomial length. Our results argue that the answer is given by precision: space corresponds to the involved precision. ",
    "url": "https://arxiv.org/abs/2301.12723",
    "authors": [
      "Manon Blanc",
      "Olivier Bournez"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2301.12730",
    "title": "General Covariance Data Augmentation for Neural PDE Solvers",
    "abstract": "The growing body of research shows how to replace classical partial differential equation (PDE) integrators with neural networks. The popular strategy is to generate the input-output pairs with a PDE solver, train the neural network in the regression setting, and use the trained model as a cheap surrogate for the solver. The bottleneck in this scheme is the number of expensive queries of a PDE solver needed to generate the dataset. To alleviate the problem, we propose a computationally cheap augmentation strategy based on general covariance and simple random coordinate transformations. Our approach relies on the fact that physical laws are independent of the coordinate choice, so the change in the coordinate system preserves the type of a parametric PDE and only changes PDE's data (e.g., initial conditions, diffusion coefficient). For tried neural networks and partial differential equations, proposed augmentation improves test error by 23% on average. The worst observed result is a 17% increase in test error for multilayer perceptron, and the best case is a 80% decrease for dilated residual network. ",
    "url": "https://arxiv.org/abs/2301.12730",
    "authors": [
      "Vladimir Fanaskov",
      "Tianchi Yu",
      "Alexander Rudikov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.12744",
    "title": "PointSmile: Point Self-supervised Learning via Curriculum Mutual  Information",
    "abstract": "Self-supervised learning is attracting wide attention in point cloud processing. However, it is still not well-solved to gain discriminative and transferable features of point clouds for efficient training on downstream tasks, due to their natural sparsity and irregularity. We propose PointSmile, a reconstruction-free self-supervised learning paradigm by maximizing curriculum mutual information (CMI) across the replicas of point cloud objects. From the perspective of how-and-what-to-learn, PointSmile is designed to imitate human curriculum learning, i.e., starting with an easy curriculum and gradually increasing the difficulty of that curriculum. To solve \"how-to-learn\", we introduce curriculum data augmentation (CDA) of point clouds. CDA encourages PointSmile to learn from easy samples to hard ones, such that the latent space can be dynamically affected to create better embeddings. To solve \"what-to-learn\", we propose to maximize both feature- and class-wise CMI, for better extracting discriminative features of point clouds. Unlike most of existing methods, PointSmile does not require a pretext task, nor does it require cross-modal data to yield rich latent representations. We demonstrate the effectiveness and robustness of PointSmile in downstream tasks including object classification and segmentation. Extensive results show that our PointSmile outperforms existing self-supervised methods, and compares favorably with popular fully-supervised methods on various standard architectures. ",
    "url": "https://arxiv.org/abs/2301.12744",
    "authors": [
      "Xin Li",
      "Mingqiang Wei",
      "Songcan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12762",
    "title": "Causality-based CTR Prediction using Graph Neural Networks",
    "abstract": "As a prevalent problem in online advertising, CTR prediction has attracted plentiful attention from both academia and industry. Recent studies have been reported to establish CTR prediction models in the graph neural networks (GNNs) framework. However, most of GNNs-based models handle feature interactions in a complete graph, while ignoring causal relationships among features, which results in a huge drop in the performance on out-of-distribution data. This paper is dedicated to developing a causality-based CTR prediction model in the GNNs framework (Causal-GNN) integrating representations of feature graph, user graph and ad graph in the context of online advertising. In our model, a structured representation learning method (GraphFwFM) is designed to capture high-order representations on feature graph based on causal discovery among field features in gated graph neural networks (GGNNs), and GraphSAGE is employed to obtain graph representations of users and ads. Experiments conducted on three public datasets demonstrate the superiority of Causal-GNN in AUC and Logloss and the effectiveness of GraphFwFM in capturing high-order representations on causal feature graph. ",
    "url": "https://arxiv.org/abs/2301.12762",
    "authors": [
      "Panyu Zhai",
      "Yanwu Yang",
      "Chunjie Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12766",
    "title": "GPS-Spoofing Attack Detection Mechanism for UAV Swarms",
    "abstract": "Recently autonomous and semi-autonomous Unmanned Aerial Vehicle (UAV) swarms started to receive a lot of research interest and demand from various civil application fields. However, for successful mission execution, UAV swarms require Global navigation satellite system signals and in particular, Global Positioning System (GPS) signals for navigation. Unfortunately, civil GPS signals are unencrypted and unauthenticated, which facilitates the execution of GPS spoofing attacks. During these attacks, adversaries mimic the authentic GPS signal and broadcast it to the targeted UAV in order to change its course, and force it to land or crash. In this study, we propose a GPS spoofing detection mechanism capable of detecting single-transmitter and multi-transmitter GPS spoofing attacks to prevent the outcomes mentioned above. Our detection mechanism is based on comparing the distance between each two swarm members calculated from their GPS coordinates to the distance acquired from Impulse Radio Ultra-Wideband ranging between the same swarm members. If the difference in distances is larger than a chosen threshold the GPS spoofing attack is declared detected. ",
    "url": "https://arxiv.org/abs/2301.12766",
    "authors": [
      "Pavlo Mykytyn",
      "Marcin Brzozowski",
      "Zoya Dyka",
      "Peter Langendoerfer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12778",
    "title": "A Comprehensive Investigation of Feature and Model Importance in Android  Malware Detection",
    "abstract": "The popularity and relative openness of Android means it is a popular target for malware. Over the years, various studies have found that machine learning models can effectively discriminate malware from benign applications. However, as the operating system evolves, so does malware, bringing into question the findings of these previous studies, many of which used small, outdated, and often imbalanced datasets. In this paper, we reimplement 16 representative past works and evaluate them on a balanced, relevant and up-to-date dataset comprising 124,000 Android applications. We also carry out new experiments designed to fill holes in existing knowledge, and use our findings to identify the most effective features and models to use for Android malware detection within a contemporary environment. Our results suggest that accuracies of up to 96.8% can be achieved using static features alone, with a further 1% achievable using more expensive dynamic analysis approaches. We find the best models to be random forests built from API call usage and TCP network traffic features. ",
    "url": "https://arxiv.org/abs/2301.12778",
    "authors": [
      "Ali Muzaffar",
      "Hani Ragab Hassen",
      "Hind Zantout",
      "Michael A Lones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.12783",
    "title": "The Leafed Induced Subtree in chordal and bounded treewidth graphs",
    "abstract": "In the Fully Leafed Induced Subtrees, one is given a graph $G$ and two integers $a$ and $b$ and the question is to find an induced subtree of $G$ with $a$ vertices and at least $b$ leaves. This problem is known to be NP-complete even when the input graph is $4$-regular. Polynomial algorithms are known when the input graph is restricted to be a tree or series-parallel. In this paper we generalize these results by providing an FPT algorithm parameterized by treewidth. We also provide a polynomial algorithm when the input graph is restricted to be a chordal graph. ",
    "url": "https://arxiv.org/abs/2301.12783",
    "authors": [
      "Julien Baste"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.12798",
    "title": "TrFedDis: Trusted Federated Disentangling Network for Non-IID Domain  Feature",
    "abstract": "Federated learning (FL), as an effective decentralized distributed learning approach, enables multiple institutions to jointly train a model without sharing their local data. However, the domain feature shift caused by different acquisition devices/clients substantially degrades the performance of the FL model. Furthermore, most existing FL approaches aim to improve accuracy without considering reliability (e.g., confidence or uncertainty). The predictions are thus unreliable when deployed in safety-critical applications. Therefore, aiming at improving the performance of FL in non-Domain feature issues while enabling the model more reliable. In this paper, we propose a novel trusted federated disentangling network, termed TrFedDis, which utilizes feature disentangling to enable the ability to capture the global domain-invariant cross-client representation and preserve local client-specific feature learning. Meanwhile, to effectively integrate the decoupled features, an uncertainty-aware decision fusion is also introduced to guide the network for dynamically integrating the decoupled features at the evidence level, while producing a reliable prediction with an estimated uncertainty. To the best of our knowledge, our proposed TrFedDis is the first work to develop an FL approach based on evidential uncertainty combined with feature disentangling, which enhances the performance and reliability of FL in non-IID domain features. Extensive experimental results show that our proposed TrFedDis provides outstanding performance with a high degree of reliability as compared to other state-of-the-art FL approaches. ",
    "url": "https://arxiv.org/abs/2301.12798",
    "authors": [
      "Meng Wang",
      "Kai Yu",
      "Chun-Mei Feng",
      "Yiming Qian",
      "Ke Zou",
      "Lianyu Wang",
      "Rick Siow Mong Goh",
      "Xinxing Xu",
      "Yong Liu",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12799",
    "title": "Eye Image-based Algorithms to Estimate Percentage Closure of Eye and  Saccadic Ratio for Alertness Detection",
    "abstract": "The current research work has developed two novel algorithms for image-based measurement of Percentage Closure of Eyes-PERCLOS and Saccadic Ratio-SR. The PERCLOS is estimated by correlation filter-based technique. An innovative combination of gray scale and Near Infrared sensitive camera with passive NIR illuminator helps to achieve higher accuracy than the existing art. Two novel techniques have been developed for the detection of iris centre and eye corners. We propose an index called Form Factor to find the iris position. The saccadic velocity profile can be estimated from the temporal information of the iris positions using standard tracking algorithm such as Extended Kalman filter. Experimental results indicate that the estimation of both SR and PERCLOS can predict the level of alertness of an operator from onset of diminished alertness to fatigue. ",
    "url": "https://arxiv.org/abs/2301.12799",
    "authors": [
      "Supratim Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.12805",
    "title": "EDSA-Ensemble: an Event Detection Sentiment Analysis Ensemble  Architecture",
    "abstract": "As global digitization continues to grow, technology becomes more affordable and easier to use, and social media platforms thrive, becoming the new means of spreading information and news. Communities are built around sharing and discussing current events. Within these communities, users are enabled to share their opinions about each event. Using Sentiment Analysis to understand the polarity of each message belonging to an event, as well as the entire event, can help to better understand the general and individual feelings of significant trends and the dynamics on online social networks. In this context, we propose a new ensemble architecture, EDSA-Ensemble (Event Detection Sentiment Analysis Ensemble), that uses Event Detection and Sentiment Analysis to improve the detection of the polarity for current events from Social Media. For Event Detection, we use techniques based on Information Diffusion taking into account both the time span and the topics. To detect the polarity of each event, we preprocess the text and employ several Machine and Deep Learning models to create an ensemble model. The preprocessing step includes several word representation models, i.e., raw frequency, TFIDF, Word2Vec, and Transformers. The proposed EDSA-Ensemble architecture improves the event sentiment classification over the individual Machine and Deep Learning models. ",
    "url": "https://arxiv.org/abs/2301.12805",
    "authors": [
      "Alexandru Petrescu",
      "Ciprian-Octavian Truic\u0103",
      "Elena-Simona Apostol",
      "Adrian Paschke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12809",
    "title": "The Hidden Power of Pure 16-bit Floating-Point Neural Networks",
    "abstract": "Lowering the precision of neural networks from the prevalent 32-bit precision has long been considered harmful to performance, despite the gain in space and time. Many works propose various techniques to implement half-precision neural networks, but none study pure 16-bit settings. This paper investigates the unexpected performance gain of pure 16-bit neural networks over the 32-bit networks in classification tasks. We present extensive experimental results that favorably compare various 16-bit neural networks' performance to those of the 32-bit models. In addition, a theoretical analysis of the efficiency of 16-bit models is provided, which is coupled with empirical evidence to back it up. Finally, we discuss situations in which low-precision training is indeed detrimental. ",
    "url": "https://arxiv.org/abs/2301.12809",
    "authors": [
      "Juyoung Yun",
      "Byungkon Kang",
      "Zhoulai Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2301.12827",
    "title": "YOLO-based Object Detection in Industry 4.0 Fischertechnik Model  Environment",
    "abstract": "In this paper we extensively explore the suitability of YOLO architectures to monitor the process flow across a Fischertechnik industry 4.0 application. Specifically, different YOLO architectures in terms of size and complexity design along with different prior-shapes assignment strategies are adopted. To simulate the real world factory environment, we prepared a rich dataset augmented with different distortions that highly enhance and in some cases degrade our image qualities. The degradation is performed to account for environmental variations and enhancements opt to compensate the color correlations that we face while preparing our dataset. The analysis of our conducted experiments shows the effectiveness of the presented approach evaluated using different measures along with the training and validation strategies that we tailored to tackle the unavoidable color correlations that the problem at hand inherits by nature. ",
    "url": "https://arxiv.org/abs/2301.12827",
    "authors": [
      "Slavomira Schneidereit",
      "Ashkan Mansouri Yarahmadi",
      "Toni Schneidereit",
      "Michael Breu\u00df",
      "Marc Gebauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12831",
    "title": "M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing  System",
    "abstract": "Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this paper, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to overcome the issues above. The innovation of this work mainly lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three pervasively available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy. The model outputs three predictions from the vision, acoustic, and fusion heads, enabling a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M3FAS under various challenging experimental settings. ",
    "url": "https://arxiv.org/abs/2301.12831",
    "authors": [
      "Chenqi Kong",
      "Kexin Zheng",
      "Yibing Liu",
      "Shiqi Wang",
      "Anderson Rocha",
      "Haoliang Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12832",
    "title": "Deep networks for system identification: a Survey",
    "abstract": "Deep learning is a topic of considerable current interest. The availability of massive data collections and powerful software resources has led to an impressive amount of results in many application areas that reveal essential but hidden properties of the observations. System identification learns mathematical descriptions of dynamic systems from input-output data and can thus benefit from the advances of deep neural networks to enrich the possible range of models to choose from. For this reason, we provide a survey of deep learning from a system identification perspective. We cover a wide spectrum of topics to enable researchers to understand the methods, providing rigorous practical and theoretical insights into the benefits and challenges of using them. The main aim of the identified model is to predict new data from previous observations. This can be achieved with different deep learning based modelling techniques and we discuss architectures commonly adopted in the literature, like feedforward, convolutional, and recurrent networks. Their parameters have to be estimated from past data trying to optimize the prediction performance. For this purpose, we discuss a specific set of first-order optimization tools that is emerged as efficient. The survey then draws connections to the well-studied area of kernel-based methods. They control the data fit by regularization terms that penalize models not in line with prior assumptions. We illustrate how to cast them in deep architectures to obtain deep kernel-based methods. The success of deep learning also resulted in surprising empirical observations, like the counter-intuitive behaviour of models with many parameters. We discuss the role of overparameterized models, including their connection to kernels, as well as implicit regularization mechanisms which affect generalization, specifically the interesting phenomena of benign overfitting ... ",
    "url": "https://arxiv.org/abs/2301.12832",
    "authors": [
      "Gianluigi Pillonetto",
      "Aleksandr Aravkin",
      "Daniel Gedon",
      "Lennart Ljung",
      "Ant\u00f4nio H. Ribeiro",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12847",
    "title": "Finding the Law: Enhancing Statutory Article Retrieval via Graph Neural  Networks",
    "abstract": "Statutory article retrieval (SAR), the task of retrieving statute law articles relevant to a legal question, is a promising application of legal text processing. In particular, high-quality SAR systems can improve the work efficiency of legal professionals and provide basic legal assistance to citizens in need at no cost. Unlike traditional ad-hoc information retrieval, where each document is considered a complete source of information, SAR deals with texts whose full sense depends on complementary information from the topological organization of statute law. While existing works ignore these domain-specific dependencies, we propose a novel graph-augmented dense statute retriever (G-DSR) model that incorporates the structure of legislation via a graph neural network to improve dense retrieval performance. Experimental results show that our approach outperforms strong retrieval baselines on a real-world expert-annotated SAR dataset. ",
    "url": "https://arxiv.org/abs/2301.12847",
    "authors": [
      "Antoine Louis",
      "Gijs van Dijck",
      "Gerasimos Spanakis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12868",
    "title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained  Language Model: An Empirical Study on Codex",
    "abstract": "Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advancements in few-shot language models trained on code have demonstrated superior performance in generating these representations compared to traditional unimodal language models, which are trained on downstream tasks. Despite these advancements, existing fine-tuned neural semantic parsers are susceptible to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a large prompt-based language model of code, \\codex. Our results demonstrate that the state-of-the-art (SOTA) code-language models are vulnerable to carefully crafted adversarial examples. To address this challenge, we propose methods for improving robustness without the need for significant amounts of labeled data or heavy computational resources. ",
    "url": "https://arxiv.org/abs/2301.12868",
    "authors": [
      "Terry Yue Zhuo",
      "Zhuang Li",
      "Yujin Huang",
      "Yuan-Fang Li",
      "Weiqing Wang",
      "Gholamreza Haffari",
      "Fatemeh Shiri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12873",
    "title": "Approximating DTW with a convolutional neural network on EEG data",
    "abstract": "Dynamic Time Wrapping (DTW) is a widely used algorithm for measuring similarities between two time series. It is especially valuable in a wide variety of applications, such as clustering, anomaly detection, classification, or video segmentation, where the time-series have different timescales, are irregularly sampled, or are shifted. However, it is not prone to be considered as a loss function in an end-to-end learning framework because of its non-differentiability and its quadratic temporal complexity. While differentiable variants of DTW have been introduced by the community, they still present some drawbacks: computing the distance is still expensive and this similarity tends to blur some differences in the time-series. In this paper, we propose a fast and differentiable approximation of DTW by comparing two architectures: the first one for learning an embedding in which the Euclidean distance mimics the DTW, and the second one for directly predicting the DTW output using regression. We build the former by training a siamese neural network to regress the DTW value between two time-series. Depending on the nature of the activation function, this approximation naturally supports differentiation, and it is efficient to compute. We show, in a time-series retrieval context on EEG datasets, that our methods achieve at least the same level of accuracy as other DTW main approximations with higher computational efficiency. We also show that it can be used to learn in an end-to-end setting on long time series by proposing generative models of EEGs. ",
    "url": "https://arxiv.org/abs/2301.12873",
    "authors": [
      "Hugo Lerogeron",
      "Romain Picot-Clemente",
      "Alain Rakotomamonjy",
      "Laurent Heutte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12874",
    "title": "Extremal Domain Translation with Neural Optimal Transport",
    "abstract": "We propose the extremal transport (ET) which is a mathematical formalization of the theoretically best possible unpaired translation between a pair of domains w.r.t. the given similarity function. Inspired by the recent advances in neural optimal transport (OT), we propose a scalable algorithm to approximate ET maps as a limit of partial OT maps. We test our algorithm on toy examples and on the unpaired image-to-image translation task. ",
    "url": "https://arxiv.org/abs/2301.12874",
    "authors": [
      "Milena Gazdieva",
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12885",
    "title": "SplitGNN: Splitting GNN for Node Classification with Heterogeneous  Attention",
    "abstract": "With the frequent happening of privacy leakage and the enactment of privacy laws across different countries, data owners are reluctant to directly share their raw data and labels with any other party. In reality, a lot of these raw data are stored in the graph database, especially for finance. For collaboratively building graph neural networks(GNNs), federated learning(FL) may not be an ideal choice for the vertically partitioned setting where privacy and efficiency are the main concerns. Moreover, almost all the existing federated GNNs are mainly designed for homogeneous graphs, which simplify various types of relations as the same type, thus largely limits their performance. We bridge this gap by proposing a split learning-based GNN(SplitGNN), where this model is divided into two sub-models: the local GNN model includes all the private data related computation to generate local node embeddings, whereas the global model calculates global embeddings by aggregating all the participants' local embeddings. Our SplitGNN allows the isolated heterogeneous neighborhood to be collaboratively utilized. To better capture representations, we propose a novel Heterogeneous Attention(HAT) algorithm and use both node-based and path-based attention mechanisms to learn various types of nodes and edges with multi-hop relation features. We demonstrate the effectiveness of our SplitGNN on node classification tasks for two standard public datasets and the real-world dataset. Extensive experimental results validate that our proposed SplitGNN significantly outperforms the state-of-the-art(SOTA) methods. ",
    "url": "https://arxiv.org/abs/2301.12885",
    "authors": [
      "Xiaolong Xu",
      "Lingjuan Lyu",
      "Yihong Dong",
      "Yicheng Lu",
      "Weiqiang Wang",
      "Hong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12893",
    "title": "Formalizing Piecewise Affine Activation Functions of Neural Networks in  Coq",
    "abstract": "Verification of neural networks relies on activation functions being piecewise affine (pwa) -- enabling an encoding of the verification problem for theorem provers. In this paper, we present the first formalization of pwa activation functions for an interactive theorem prover tailored to verifying neural networks within Coq using the library Coquelicot for real analysis. As a proof-of-concept, we construct the popular pwa activation function ReLU. We integrate our formalization into a Coq model of neural networks, and devise a verified transformation from a neural network N to a pwa function representing N by composing pwa functions that we construct for each layer. This representation enables encodings for proof automation, e.g. Coq's tactic lra -- a decision procedure for linear real arithmetic. Further, our formalization paves the way for integrating Coq in frameworks of neural network verification as a fallback prover when automated proving fails. ",
    "url": "https://arxiv.org/abs/2301.12893",
    "authors": [
      "Andrei Aleksandrov",
      "Kim V\u00f6llinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12896",
    "title": "Identifying Adversarially Attackable and Robust Samples",
    "abstract": "This work proposes a novel perspective on adversarial attacks by introducing the concept of sample attackability and robustness. Adversarial attacks insert small, imperceptible perturbations to the input that cause large, undesired changes to the output of deep learning models. Despite extensive research on generating adversarial attacks and building defense systems, there has been limited research on understanding adversarial attacks from an input-data perspective. We propose a deep-learning-based method for detecting the most attackable and robust samples in an unseen dataset for an unseen target model. The proposed method is based on a neural network architecture that takes as input a sample and outputs a measure of attackability or robustness. The proposed method is evaluated using a range of different models and different attack methods, and the results demonstrate its effectiveness in detecting the samples that are most likely to be affected by adversarial attacks. Understanding sample attackability can have important implications for future work in sample-selection tasks. For example in active learning, the acquisition function can be designed to select the most attackable samples, or in adversarial training, only the most attackable samples are selected for augmentation. ",
    "url": "https://arxiv.org/abs/2301.12896",
    "authors": [
      "Vyas Raina",
      "Mark Gales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12904",
    "title": "Long Short-Term Memory Neural Network for Temperature Prediction in  Laser Powder Bed Additive Manufacturing",
    "abstract": "In context of laser powder bed fusion (L-PBF), it is known that the properties of the final fabricated product highly depend on the temperature distribution and its gradient over the manufacturing plate. In this paper, we propose a novel means to predict the temperature gradient distributions during the printing process by making use of neural networks. This is realized by employing heat maps produced by an optimized printing protocol simulation and used for training a specifically tailored recurrent neural network in terms of a long short-term memory architecture. The aim of this is to avoid extreme and inhomogeneous temperature distribution that may occur across the plate in the course of the printing process. In order to train the neural network, we adopt a well-engineered simulation and unsupervised learning framework. To maintain a minimized average thermal gradient across the plate, a cost function is introduced as the core criteria, which is inspired and optimized by considering the well-known traveling salesman problem (TSP). As time evolves the unsupervised printing process governed by TSP produces a history of temperature heat maps that maintain minimized average thermal gradient. All in one, we propose an intelligent printing tool that provides control over the substantial printing process components for L-PBF, i.e.\\ optimal nozzle trajectory deployment as well as online temperature prediction for controlling printing quality. ",
    "url": "https://arxiv.org/abs/2301.12904",
    "authors": [
      "Ashkan Mansouri Yarahmadi",
      "Michael Breu\u00df",
      "Carsten Hartmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12906",
    "title": "Curvature Filtrations for Graph Generative Model Evaluation",
    "abstract": "Graph generative model evaluation necessitates understanding differences between graphs on the distributional level. This entails being able to harness salient attributes of graphs in an efficient manner. Curvature constitutes one such property of graphs, and has recently started to prove useful in characterising graphs. Its expressive properties, stability, and practical utility in model evaluation remain largely unexplored, however. We combine graph curvature descriptors with cutting-edge methods from topological data analysis to obtain robust, expressive descriptors for evaluating graph generative models. ",
    "url": "https://arxiv.org/abs/2301.12906",
    "authors": [
      "Joshua Southern",
      "Jeremy Wayland",
      "Michael Bronstein",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12909",
    "title": "Dirichlet-Neumann Waveform Relaxation Algorithm for Time Fractional  Diffusion Equation in Heterogeneous Media",
    "abstract": "In this article, we have studied the convergence behavior of the Dirichlet-Neumann waveform relaxation algorithms for time-fractional sub-diffusion and diffusion wave equations in 1D \\& 2D for regular domains, where the dimensionless diffusion coefficient takes different constant values in different subdomains. From numerical experiments, we first capture the optimal relaxation parameters. Using these optimal relaxation parameters, our analysis estimates the rate of change of the convergence behavior against the fractional order and time. We have performed our analysis in multiple subdomain cases for both in 1D \\& 2D. ",
    "url": "https://arxiv.org/abs/2301.12909",
    "authors": [
      "Soura Sana",
      "Bankim C. Mandal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.12912",
    "title": "A PBPO+ Graph Rewriting Tutorial",
    "abstract": "We provide a tutorial introduction to the algebraic graph rewriting formalism PBPO+. We show how PBPO+ can be obtained by composing a few simple building blocks, and model the reduction rules for binary decision diagrams as an example. Along the way, we comment on how alternative design decisions lead to related formalisms in the literature, such as DPO. We close with a detailed comparison with Bauderon's double pullback approach. ",
    "url": "https://arxiv.org/abs/2301.12912",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2301.12913",
    "title": "Rational verification and checking for Nash and subgame-perfect  equilibria in graph games",
    "abstract": "We study two natural problems about rational behaviors in multiplayer non-zero-sum sequential infinite duration games played on graphs: checking problems, that consist in deciding whether a strategy profile, defined by a Mealy machine, is rational; and rational verification, that consists in deciding whether all the rational answers to a given strategy satisfy some specification. We give the complexities of those problems for two major concepts of rationality: Nash equilibria and subgame-perfect equilibria, and for five major classes of payoff functions: parity, mean-payoff, quantitative reachability, energy, and discounted-sum. ",
    "url": "https://arxiv.org/abs/2301.12913",
    "authors": [
      "L\u00e9onard Brice",
      "Jean-Fran\u00e7ois Raskin",
      "Marie van den Bogaard"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2301.12914",
    "title": "PromptMix: Text-to-image diffusion models enhance the performance of  lightweight networks",
    "abstract": "Many deep learning tasks require annotations that are too time consuming for human operators, resulting in small dataset sizes. This is especially true for dense regression problems such as crowd counting which requires the location of every person in the image to be annotated. Techniques such as data augmentation and synthetic data generation based on simulations can help in such cases. In this paper, we introduce PromptMix, a method for artificially boosting the size of existing datasets, that can be used to improve the performance of lightweight networks. First, synthetic images are generated in an end-to-end data-driven manner, where text prompts are extracted from existing datasets via an image captioning deep network, and subsequently introduced to text-to-image diffusion models. The generated images are then annotated using one or more high-performing deep networks, and mixed with the real dataset for training the lightweight network. By extensive experiments on five datasets and two tasks, we show that PromptMix can significantly increase the performance of lightweight networks by up to 26%. ",
    "url": "https://arxiv.org/abs/2301.12914",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12926",
    "title": "Asymmetry and condition number of an elliptic-parabolic system for  biological network formation",
    "abstract": "We present results of numerical simulations of the tensor-valued elliptic-parabolic PDE model for biological network formation. The numerical method is based on a non-linear finite difference scheme on a uniform Cartesian grid in a 2D domain. The focus is on the impact of different discretization methods and choices of regularization parameters on the symmetry of the numerical solution. In particular, we show that using the symmetric alternating-direction implicit (ADI) method for time discretization helps preserve the symmetry of the solution, compared to the (nonsymmetric) ADI method. Moreover, we study the effect of regularization by isotropic background permeability $r>0$, showing that increased condition number of the elliptic problem due to decreasing value of $r$ leads to loss of symmetry. Finally, we perform numerical error analysis of our method in Wasserstein distance. ",
    "url": "https://arxiv.org/abs/2301.12926",
    "authors": [
      "Clarissa Astuto",
      "Daniele Boffi",
      "Jan Haskovec",
      "Peter Markowich",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.12929",
    "title": "Can Persistent Homology provide an efficient alternative for Evaluation  of Knowledge Graph Completion Methods?",
    "abstract": "In this paper we present a novel method, $\\textit{Knowledge Persistence}$ ($\\mathcal{KP}$), for faster evaluation of Knowledge Graph (KG) completion approaches. Current ranking-based evaluation is quadratic in the size of the KG, leading to long evaluation times and consequently a high carbon footprint. $\\mathcal{KP}$ addresses this by representing the topology of the KG completion methods through the lens of topological data analysis, concretely using persistent homology. The characteristics of persistent homology allow $\\mathcal{KP}$ to evaluate the quality of the KG completion looking only at a fraction of the data. Experimental results on standard datasets show that the proposed metric is highly correlated with ranking metrics (Hits@N, MR, MRR). Performance evaluation shows that $\\mathcal{KP}$ is computationally efficient: In some cases, the evaluation time (validation+test) of a KG completion method has been reduced from 18 hours (using Hits@10) to 27 seconds (using $\\mathcal{KP}$), and on average (across methods & data) reduces the evaluation time (validation+test) by $\\approx$ $\\textbf{99.96}\\%$. ",
    "url": "https://arxiv.org/abs/2301.12929",
    "authors": [
      "Anson Bastos",
      "Kuldeep Singh",
      "Abhishek Nadgeri",
      "Johannes Hoffart",
      "Toyotaro Suzumura",
      "Manish Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2301.12942",
    "title": "Refined Regret for Adversarial MDPs with Linear Function Approximation",
    "abstract": "We consider learning in an adversarial Markov Decision Process (MDP) where the loss functions can change arbitrarily over $K$ episodes and the state space can be arbitrarily large. We assume that the Q-function of any policy is linear in some known features, that is, a linear function approximation exists. The best existing regret upper bound for this setting (Luo et al., 2021) is of order $\\tilde{\\mathcal O}(K^{2/3})$ (omitting all other dependencies), given access to a simulator. This paper provides two algorithms that improve the regret to $\\tilde{\\mathcal O}(\\sqrt K)$ in the same setting. Our first algorithm makes use of a refined analysis of the Follow-the-Regularized-Leader (FTRL) algorithm with the log-barrier regularizer. This analysis allows the loss estimators to be arbitrarily negative and might be of independent interest. Our second algorithm develops a magnitude-reduced loss estimator, further removing the polynomial dependency on the number of actions in the first algorithm and leading to the optimal regret bound (up to logarithmic terms and dependency on the horizon). Moreover, we also extend the first algorithm to simulator-free linear MDPs, which achieves $\\tilde{\\mathcal O}(K^{8/9})$ regret and greatly improves over the best existing bound $\\tilde{\\mathcal O}(K^{14/15})$. This algorithm relies on a better alternative to the Matrix Geometric Resampling procedure by Neu & Olkhovskaya (2020), which could again be of independent interest. ",
    "url": "https://arxiv.org/abs/2301.12942",
    "authors": [
      "Yan Dai",
      "Haipeng Luo",
      "Chen-Yu Wei",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12951",
    "title": "On the Interaction between Node Fairness and Edge Privacy in Graph  Neural Networks",
    "abstract": "Due to the emergence of graph neural networks (GNNs) and their widespread implementation in real-world scenarios, the fairness and privacy of GNNs have attracted considerable interest since they are two essential social concerns in the era of building trustworthy GNNs. Existing studies have respectively explored the fairness and privacy of GNNs and exhibited that both fairness and privacy are at the cost of GNN performance. However, the interaction between them is yet to be explored and understood. In this paper, we investigate the interaction between the fairness of a GNN and its privacy for the first time. We empirically identify that edge privacy risks increase when the individual fairness of nodes is improved. Next, we present the intuition behind such a trade-off and employ the influence function and Pearson correlation to measure it theoretically. To take the performance, fairness, and privacy of GNNs into account simultaneously, we propose implementing fairness-aware reweighting and privacy-aware graph structure perturbation modules in a retraining mechanism. Experimental results demonstrate that our method is effective in implementing GNN fairness with limited performance cost and restricted privacy risks. ",
    "url": "https://arxiv.org/abs/2301.12951",
    "authors": [
      "He Zhang",
      "Xingliang Yuan",
      "Quoc Viet Hung Nguyen",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2301.12959",
    "title": "GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis",
    "abstract": "Synthesizing high-fidelity complex images from text is challenging. Based on large pretraining, the autoregressive and diffusion models can synthesize photo-realistic images. Although these large models have shown notable progress, there remain three flaws. 1) These models require tremendous training data and parameters to achieve good performance. 2) The multi-step generation design slows the image synthesis process heavily. 3) The synthesized visual features are difficult to control and require delicately designed prompts. To enable high-quality, efficient, fast, and controllable text-to-image synthesis, we propose Generative Adversarial CLIPs, namely GALIP. GALIP leverages the powerful pretrained CLIP model both in the discriminator and generator. Specifically, we propose a CLIP-based discriminator. The complex scene understanding ability of CLIP enables the discriminator to accurately assess the image quality. Furthermore, we propose a CLIP-empowered generator that induces the visual concepts from CLIP through bridge features and prompts. The CLIP-integrated generator and discriminator boost training efficiency, and as a result, our model only requires about 3% training data and 6% learnable parameters, achieving comparable results to large pretrained autoregressive and diffusion models. Moreover, our model achieves 120 times faster synthesis speed and inherits the smooth latent space from GAN. The extensive experimental results demonstrate the excellent performance of our GALIP. Code is available at https://github.com/tobran/GALIP. ",
    "url": "https://arxiv.org/abs/2301.12959",
    "authors": [
      "Ming Tao",
      "Bing-Kun Bao",
      "Hao Tang",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12968",
    "title": "Improving Adversarial Transferability with Scheduled Step Size and Dual  Example",
    "abstract": "Deep neural networks are widely known to be vulnerable to adversarial examples, especially showing significantly poor performance on adversarial examples generated under the white-box setting. However, most white-box attack methods rely heavily on the target model and quickly get stuck in local optima, resulting in poor adversarial transferability. The momentum-based methods and their variants are proposed to escape the local optima for better transferability. In this work, we notice that the transferability of adversarial examples generated by the iterative fast gradient sign method (I-FGSM) exhibits a decreasing trend when increasing the number of iterations. Motivated by this finding, we argue that the information of adversarial perturbations near the benign sample, especially the direction, benefits more on the transferability. Thus, we propose a novel strategy, which uses the Scheduled step size and the Dual example (SD), to fully utilize the adversarial information near the benign sample. Our proposed strategy can be easily integrated with existing adversarial attack methods for better adversarial transferability. Empirical evaluations on the standard ImageNet dataset demonstrate that our proposed method can significantly enhance the transferability of existing adversarial attacks. ",
    "url": "https://arxiv.org/abs/2301.12968",
    "authors": [
      "Zeliang Zhang",
      "Peihan Liu",
      "Xiaosen Wang",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12972",
    "title": "MRNet: Multiple-Input Receptive Field Network for Large-Scale Point  Cloud Segmentation",
    "abstract": "The size of the input receptive field is one of the most critical aspects in the semantic segmentation of the point cloud, yet it is one of the most overlooked parameters. This paper presents the multiple-input receptive field processing semantic segmentation network MRNet. The fundamental philosophy of our design is to overcome the size of the input receptive field dilemma. In particular, the input receptive field's size significantly impacts the performance of different sizes of objects. To overcome this, we introduce a parallel processing network with connection modules between the parallel streams. Our ablation studies show the effectiveness of implemented modules. Also, we set the new state-of-art performance on the large-scale point cloud dataset SensatUrban. ",
    "url": "https://arxiv.org/abs/2301.12972",
    "authors": [
      "Sunghwan Yoo",
      "Yeongjeong Jeong",
      "Maryam Jameela",
      "Gunho Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12984",
    "title": "ContCommRTD: A Distributed Content-based Misinformation-aware Community  Detection System for Real-Time Disaster Reporting",
    "abstract": "Real-time social media data can provide useful information on evolving hazards. Alongside traditional methods of disaster detection, the integration of social media data can considerably enhance disaster management. In this paper, we investigate the problem of detecting geolocation-content communities on Twitter and propose a novel distributed system that provides in near real-time information on hazard-related events and their evolution. We show that content-based community analysis leads to better and faster dissemination of reports on hazards. Our distributed disaster reporting system analyzes the social relationship among worldwide geolocated tweets, and applies topic modeling to group tweets by topics. Considering for each tweet the following information: user, timestamp, geolocation, retweets, and replies, we create a publisher-subscriber distribution model for topics. We use content similarity and the proximity of nodes to create a new model for geolocation-content based communities. Users can subscribe to different topics in specific geographical areas or worldwide and receive real-time reports regarding these topics. As misinformation can lead to increase damage if propagated in hazards related tweets, we propose a new deep learning model to detect fake news. The misinformed tweets are then removed from display. We also show empirically the scalability capabilities of the proposed system. ",
    "url": "https://arxiv.org/abs/2301.12984",
    "authors": [
      "Elena-Simona Apostol",
      "Ciprian-Octavian Truic\u0103",
      "Adrian Paschke"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.12988",
    "title": "Graph Neural Network Framework for Security Assessment Informed by  Topological Measures",
    "abstract": "In the power system, security assessment (SA) plays a pivotal role in determining the safe operation in a normal situation and some contingencies scenarios. Electrical variables as input variables of the model are mainly considered to indicate the power system operation as secure or insecure, according to the reliability criteria for contingency scenarios. In this approach, the features are in grid format data, where the relation between features and any knowledge of network topology is absent. Moreover, the traditional and common models, such as neural networks (NN), are not applicable if the input variables are in the graph format structure. Therefore, this paper examines the security analysis in the graph neural network (GNN) framework such that the GNN model incorporates the network connection and node's neighbors' influence for the assessment. Here the input features are separated graphs representing different network conditions in electrical and structural statuses. Topological characteristics defined by network centrality measures are added in the feature vector representing the structural properties of the network. The proposed model is simulated in the IEEE 118-Bus system for the voltage static security assessment (SSA). The performance indices validate the efficiency of the GNN-based model compared to the traditional NN model denoting that the information enclosed in graph data boosts the classifier performance since the GNN model benefits the neighbors' features. Moreover, outperforming of GNN-based model is determined when robustness and sensitivity analyzes are carried out. The proposed method is not limited to a specific task and can be extended for other security assessments with different critical variables, such as dynamic analysis and frequency criteria, respectively. ",
    "url": "https://arxiv.org/abs/2301.12988",
    "authors": [
      "Mojtaba Dezvarei",
      "Kevin Tomsovic",
      "Jinyuan Stella Sun",
      "Seddik M. Djouadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12993",
    "title": "Benchmarking Robustness to Adversarial Image Obfuscations",
    "abstract": "Automated content filtering and moderation is an important tool that allows online platforms to build striving user communities that facilitate cooperation and prevent abuse. Unfortunately, resourceful actors try to bypass automated filters in a bid to post content that violate platform policies and codes of conduct. To reach this goal, these malicious actors may obfuscate policy violating images (e.g. overlay harmful images by carefully selected benign images or visual patterns) to prevent machine learning models from reaching the correct decision. In this paper, we invite researchers to tackle this specific issue and present a new image benchmark. This benchmark, based on ImageNet, simulates the type of obfuscations created by malicious actors. It goes beyond ImageNet-$\\textrm{C}$ and ImageNet-$\\bar{\\textrm{C}}$ by proposing general, drastic, adversarial modifications that preserve the original content intent. It aims to tackle a more common adversarial threat than the one considered by $\\ell_p$-norm bounded adversaries. We evaluate 33 pretrained models on the benchmark and train models with different augmentations, architectures and training methods on subsets of the obfuscations to measure generalization. We hope this benchmark will encourage researchers to test their models and methods and try to find new approaches that are more robust to these obfuscations. ",
    "url": "https://arxiv.org/abs/2301.12993",
    "authors": [
      "Florian Stimberg",
      "Ayan Chakrabarti",
      "Chun-Ta Lu",
      "Hussein Hazimeh",
      "Otilia Stretcu",
      "Wei Qiao",
      "Yintao Liu",
      "Merve Kaya",
      "Cyrus Rashtchian",
      "Ariel Fuxman",
      "Mehmet Tek",
      "Sven Gowal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12995",
    "title": "FedFA: Federated Feature Augmentation",
    "abstract": "Federated learning is a distributed paradigm that allows multiple parties to collaboratively train deep models without exchanging the raw data. However, the data distribution among clients is naturally non-i.i.d., which leads to severe degradation of the learnt model. The primary goal of this paper is to develop a robust federated learning algorithm to address feature shift in clients' samples, which can be caused by various factors, e.g., acquisition differences in medical imaging. To reach this goal, we propose FedFA to tackle federated learning from a distinct perspective of federated feature augmentation. FedFA is based on a major insight that each client's data distribution can be characterized by statistics (i.e., mean and standard deviation) of latent features; and it is likely to manipulate these local statistics globally, i.e., based on information in the entire federation, to let clients have a better sense of the underlying distribution and therefore alleviate local data bias. Based on this insight, we propose to augment each local feature statistic probabilistically based on a normal distribution, whose mean is the original statistic and variance quantifies the augmentation scope. Key to our approach is the determination of a meaningful Gaussian variance, which is accomplished by taking into account not only biased data of each individual client, but also underlying feature statistics characterized by all participating clients. We offer both theoretical and empirical justifications to verify the effectiveness of FedFA. Our code is available at https://github.com/tfzhou/FedFA. ",
    "url": "https://arxiv.org/abs/2301.12995",
    "authors": [
      "Tianfei Zhou",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13012",
    "title": "Key Feature Replacement of In-Distribution Samples for  Out-of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection can be used in deep learning-based applications to reject outlier samples from being unreliably classified by deep neural networks. Learning to classify between OOD and in-distribution samples is difficult because data comprising the former is extremely diverse. It has been observed that an auxiliary OOD dataset is most effective in training a \"rejection\" network when its samples are semantically similar to in-distribution images. We first deduce that OOD images are perceived by a deep neural network to be semantically similar to in-distribution samples when they share a common background, as deep networks are observed to incorrectly classify such images with high confidence. We then propose a simple yet effective Key In-distribution feature Replacement BY inpainting (KIRBY) procedure that constructs a surrogate OOD dataset by replacing class-discriminative features of in-distribution samples with marginal background features. The procedure can be implemented using off-the-shelf vision algorithms, where each step within the algorithm is shown to make the surrogate data increasingly similar to in-distribution data. Design choices in each step are studied extensively, and an exhaustive comparison with state-of-the-art algorithms demonstrates KIRBY's competitiveness on various benchmarks. ",
    "url": "https://arxiv.org/abs/2301.13012",
    "authors": [
      "Jaeyoung Kim",
      "Seo Taek Kong",
      "Dongbin Na",
      "Kyu-Hwan Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13014",
    "title": "Attribute-Guided Multi-Level Attention Network for Fine-Grained Fashion  Retrieval",
    "abstract": "This paper proposes an attribute-guided multi-level attention network (AG-MLAN) to learn fine-grained fashion similarity. AG-MLAN is able to make a more accurate attribute positioning and capture more discriminative features under the guidance of the specified attribute. Specifically, the AG-MLAN contains two branches, branch 1 aims to force the model to recognize different attributes, while branch 2 aims to learn multiple attribute-specific embedding spaces for measuring the fine-grained similarity. We first improve the Convolutional Neural Network (CNN) backbone to extract hierarchical feature representations, then the extracted feature representations are passed into branch 1 for attribute classification and branch 2 for multi-level feature extraction. In branch 2, we first propose a multi-level attention module to extract a more discriminative representation under the guidance of a specific attribute. Then, we adopt a masked embedding module to learn attribute-aware embedding. Finally, the AG-MLAN is trained with a weighted loss of the classification loss in branch 1 and the triplet loss of the masked embedding features in branch 2 to further improve the accuracy in attribute location. Extensive experiments on the DeepFashion, FashionAI, and Zappos50k datasets show the effectiveness of AG-MLAN for fine-grained fashion similarity learning and its potential for attribute-guided retrieval tasks. The proposed AG-MLAN outperforms the state-of-the-art methods in the fine-grained fashion similarity retrieval task. ",
    "url": "https://arxiv.org/abs/2301.13014",
    "authors": [
      "Ling Xiao",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13021",
    "title": "Robust DPG Fortin operators",
    "abstract": "At the fully discrete setting, stability of the discontinuous Petrov--Galerkin (DPG) method with optimal test functions requires local test spaces that ensure the existence of Fortin operators. We construct such operators for $H^1$ and $\\boldsymbol{H}(\\mathrm{div})$ on simplices in any space dimension and arbitrary polynomial degree. The resulting test spaces are smaller than previously analyzed cases. For parameter-dependent norms, we achieve uniform boundedness by the inclusion of exponential layers. As an example, we consider a canonical DPG setting for reaction-dominated diffusion. Our test spaces guarantee uniform stability and quasi-optimal convergence of the scheme. We present numerical experiments that illustrate the loss of stability and error control by the residual for small diffusion coefficient when using standard polynomial test spaces, whereas we observe uniform stability and error control with our construction. ",
    "url": "https://arxiv.org/abs/2301.13021",
    "authors": [
      "Thomas F\u00fchrer",
      "Norbert Heuer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.13028",
    "title": "On the Efficacy of Metrics to Describe Adversarial Attacks",
    "abstract": "Adversarial defenses are naturally evaluated on their ability to tolerate adversarial attacks. To test defenses, diverse adversarial attacks are crafted, that are usually described in terms of their evading capability and the L0, L1, L2, and Linf norms. We question if the evading capability and L-norms are the most effective information to claim that defenses have been tested against a representative attack set. To this extent, we select image quality metrics from the state of the art and search correlations between image perturbation and detectability. We observe that computing L-norms alone is rarely the preferable solution. We observe a strong correlation between the identified metrics computed on an adversarial image and the output of a detector on such an image, to the extent that they can predict the response of a detector with approximately 0.94 accuracy. Further, we observe that metrics can classify attacks based on similar perturbations and similar detectability. This suggests a possible review of the approach to evaluate detectors, where additional metrics are included to assure that a representative attack dataset is selected. ",
    "url": "https://arxiv.org/abs/2301.13028",
    "authors": [
      "Tommaso Puccetti",
      "Tommaso Zoppi",
      "Andrea Ceccarelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13031",
    "title": "BSSAD: Towards A Novel Bayesian State-Space Approach for Anomaly  Detection in Multivariate Time Series",
    "abstract": "Detecting anomalies in multivariate time series(MTS) data plays an important role in many domains. The abnormal values could indicate events, medical abnormalities,cyber-attacks, or faulty devices which if left undetected could lead to significant loss of resources, capital, or human lives. In this paper, we propose a novel and innovative approach to anomaly detection called Bayesian State-Space Anomaly Detection(BSSAD). The BSSAD consists of two modules: the neural network module and the Bayesian state-space module. The design of our approach combines the strength of Bayesian state-space algorithms in predicting the next state and the effectiveness of recurrent neural networks and autoencoders in understanding the relationship between the data to achieve high accuracy in detecting anomalies. The modular design of our approach allows flexibility in implementation with the option of changing the parameters of the Bayesian state-space models or swap-ping neural network algorithms to achieve different levels of performance. In particular, we focus on using Bayesian state-space models of particle filters and ensemble Kalman filters. We conducted extensive experiments on five different datasets. The experimental results show the superior performance of our model over baselines, achieving an F1-score greater than 0.95. In addition, we also propose using a metric called MatthewCorrelation Coefficient (MCC) to obtain more comprehensive information about the accuracy of anomaly detection. ",
    "url": "https://arxiv.org/abs/2301.13031",
    "authors": [
      "Usman Anjum",
      "Samuel Lin",
      "Justin Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13039",
    "title": "Representation biases in sentence transformers",
    "abstract": "Variants of the BERT architecture specialised for producing full-sentence representations often achieve better performance on downstream tasks than sentence embeddings extracted from vanilla BERT. However, there is still little understanding of what properties of inputs determine the properties of such representations. In this study, we construct several sets of sentences with pre-defined lexical and syntactic structures and show that SOTA sentence transformers have a strong nominal-participant-set bias: cosine similarities between pairs of sentences are more strongly determined by the overlap in the set of their noun participants than by having the same predicates, lengthy nominal modifiers, or adjuncts. At the same time, the precise syntactic-thematic functions of the participants are largely irrelevant. ",
    "url": "https://arxiv.org/abs/2301.13039",
    "authors": [
      "Dmitry Nikolaev",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.13060",
    "title": "Zero-One Laws of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are de facto standard deep learning architectures for machine learning on graphs. This has led to a large body of work analyzing the capabilities and limitations of these models, particularly pertaining to their representation and extrapolation capacity. We offer a novel theoretical perspective on the representation and extrapolation capacity of GNNs, by answering the question: how do GNNs behave as the number of graph nodes become very large? Under mild assumptions, we show that when we draw graphs of increasing size from the Erd\\H{o}s-R\\'enyi model, the probability that such graphs are mapped to a particular output by a class of GNN classifiers tends to either zero or to one. This class includes the popular graph convolutional network architecture. The result establishes 'zero-one laws' for these GNNs, and analogously to other convergence laws, entails theoretical limitations on their capacity. We empirically verify our results, observing that the theoretical asymptotic limits are evident already on relatively small graphs. ",
    "url": "https://arxiv.org/abs/2301.13060",
    "authors": [
      "Sam Adam-Day",
      "Theodor Mihai Iliant",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13066",
    "title": "A Human Word Association based model for topic detection in social  networks",
    "abstract": "With the widespread use of social networks, detecting the topics discussed in these networks has become a significant challenge. The current works are mainly based on frequent pattern mining or semantic relations, and the language structure is not considered. The meaning of language structural methods is to discover the relationship between words and how humans understand them. Therefore, this paper uses the Concept of the Imitation of the Mental Ability of Word Association to propose a topic detection framework in social networks. This framework is based on the Human Word Association method. The performance of this method is evaluated on the FA-CUP dataset. It is a benchmark dataset in the field of topic detection. The results show that the proposed method is a good improvement compared to other methods, based on the Topic-recall and the keyword F1 measure. Also, most of the previous works in the field of topic detection are limited to the English language, and the Persian language, especially microblogs written in this language, is considered a low-resource language. Therefore, a data set of Telegram posts in the Farsi language has been collected. Applying the proposed method to this dataset also shows that this method works better than other topic detection methods. ",
    "url": "https://arxiv.org/abs/2301.13066",
    "authors": [
      "Mehrdad Ranjbar Khadivi",
      "Shahin Akbarpour",
      "Mohammad-Reza Feizi-Derakhshi",
      "Babak Anari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13067",
    "title": "Fuzzy Presheaves are Quasitoposes and Consequences in Graph Rewriting",
    "abstract": "Quasitoposes have proven to be an interesting framework for many graph rewriting formalisms. Since presheaves categories are toposes and fuzzy sets are quasitoposes, we prove that the combination of both, fuzzy presheaves, are also quasitoposes. This question was recently conjectured more specifically for fuzzy graphs and is now therefore proven. This entails that many fuzzy presheaves of interest can be used for graph rewriting. ",
    "url": "https://arxiv.org/abs/2301.13067",
    "authors": [
      "Alo\u00efs Rosset",
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2301.13081",
    "title": "STAIR: Learning Sparse Text and Image Representation in Grounded Tokens",
    "abstract": "Image and text retrieval is one of the foundational tasks in the vision and language domain with multiple real-world applications. State-of-the-art approaches, e.g. CLIP, ALIGN, represent images and texts as dense embeddings and calculate the similarity in the dense embedding space as the matching score. On the other hand, sparse semantic features like bag-of-words models are more interpretable, but believed to suffer from inferior accuracy than dense representations. In this work, we show that it is possible to build a sparse semantic representation that is as powerful as, or even better than, dense presentations. We extend the CLIP model and build a sparse text and image representation (STAIR), where the image and text are mapped to a sparse token space. Each token in the space is a (sub-)word in the vocabulary, which is not only interpretable but also easy to integrate with existing information retrieval systems. STAIR model significantly outperforms a CLIP model with +$4.9\\%$ and +$4.3\\%$ absolute Recall@1 improvement on COCO-5k text$\\rightarrow$image and image$\\rightarrow$text retrieval respectively. It also achieved better performance on both of ImageNet zero-shot and linear probing compared to CLIP. ",
    "url": "https://arxiv.org/abs/2301.13081",
    "authors": [
      "Chen Chen",
      "Bowen Zhang",
      "Liangliang Cao",
      "Jiguang Shen",
      "Tom Gunter",
      "Albin Madappally Jose",
      "Alexander Toshev",
      "Jonathon Shlens",
      "Ruoming Pang",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13083",
    "title": "Communication Drives the Emergence of Language Universals in Neural  Agents: Evidence from the Word-order/Case-marking Trade-off",
    "abstract": "Artificial learners often behave differently from human learners in the context of neural agent-based simulations of language emergence and change. The lack of appropriate cognitive biases in these learners is one of the prevailing explanations. However, it has also been proposed that more naturalistic settings of language learning and use could lead to more human-like results. In this work, we investigate the latter account focusing on the word-order/case-marking trade-off, a widely attested language universal which has proven particularly difficult to simulate. We propose a new Neural-agent Language Learning and Communication framework (NeLLCom) where pairs of speaking and listening agents first learn a given miniature language through supervised learning, and then optimize it for communication via reinforcement learning. Following closely the setup of earlier human experiments, we succeed in replicating the trade-off with the new framework without hard-coding any learning bias in the agents. We see this as an essential step towards the investigation of language universals with neural learners. ",
    "url": "https://arxiv.org/abs/2301.13083",
    "authors": [
      "Yuchen Lian",
      "Arianna Bisazza",
      "Tessa Verhoef"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13091",
    "title": "Optimal Approximation Complexity of High-Dimensional Functions with  Neural Networks",
    "abstract": "We investigate properties of neural networks that use both ReLU and $x^2$ as activation functions and build upon previous results to show that both analytic functions and functions in Sobolev spaces can be approximated by such networks of constant depth to arbitrary accuracy, demonstrating optimal order approximation rates across all nonlinear approximators, including standard ReLU networks. We then show how to leverage low local dimensionality in some contexts to overcome the curse of dimensionality, obtaining approximation rates that are optimal for unknown lower-dimensional subspaces. ",
    "url": "https://arxiv.org/abs/2301.13091",
    "authors": [
      "Vincent P.H. Goverse",
      "Jad Hamdan",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.13096",
    "title": "Anchor-Based Adversarially Robust Zero-Shot Learning Driven by Language",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks. We consider adversarial defense in the case of zero-shot image classification setting, which has rarely been explored because both adversarial defense and zero-shot learning are challenging. We propose LAAT, a novel Language-driven, Anchor-based Adversarial Training strategy, to improve the adversarial robustness in a zero-shot setting. LAAT uses a text encoder to obtain fixed anchors (normalized feature embeddings) of each category, then uses these anchors to perform adversarial training. The text encoder has the property that semantically similar categories can be mapped to neighboring anchors in the feature space. By leveraging this property, LAAT can make the image model adversarially robust on novel categories without any extra examples. Experimental results show that our method achieves impressive zero-shot adversarial performance, even surpassing the previous state-of-the-art adversarially robust one-shot methods in most attacking settings. When models are trained with LAAT on large datasets like ImageNet-1K, they can have substantial zero-shot adversarial robustness across several downstream datasets. ",
    "url": "https://arxiv.org/abs/2301.13096",
    "authors": [
      "Xiao Li",
      "Wei Zhang",
      "Yining Liu",
      "Zhanhao Hu",
      "Bo Zhang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13122",
    "title": "Towards Adversarial Realism and Robust Learning for IoT Intrusion  Detection and Classification",
    "abstract": "The Internet of Things (IoT) faces tremendous security challenges. Machine learning models can be used to tackle the growing number of cyber-attack variations targeting IoT systems, but the increasing threat posed by adversarial attacks restates the need for reliable defense strategies. This work describes the types of constraints required for an adversarial cyber-attack example to be realistic and proposes a methodology for a trustworthy adversarial robustness analysis with a realistic adversarial evasion attack vector. The proposed methodology was used to evaluate three supervised algorithms, Random Forest (RF), Extreme Gradient Boosting (XGB), and Light Gradient Boosting Machine (LGBM), and one unsupervised algorithm, Isolation Forest (IFOR). Constrained adversarial examples were generated with the Adaptative Perturbation Pattern Method (A2PM), and evasion attacks were performed against models created with regular and adversarial training. Even though RF was the least affected in binary classification, XGB consistently achieved the highest accuracy in multi-class classification. The obtained results evidence the inherent susceptibility of tree-based algorithms and ensembles to adversarial evasion attacks and demonstrates the benefits of adversarial training and a security by design approach for a more robust IoT network intrusion detection. ",
    "url": "https://arxiv.org/abs/2301.13122",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Isabel Pra\u00e7a",
      "Eva Maia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13142",
    "title": "Self-Compressing Neural Networks",
    "abstract": "This work focuses on reducing neural network size, which is a major driver of neural network execution time, power consumption, bandwidth, and memory footprint. A key challenge is to reduce size in a manner that can be exploit-ed readily for efficient training and inference without the need for specialized hardware. We propose Self-Compression: a simple, general method that simultaneously achieves two goals: (1) removing redundant weights, and (2) reducing the number of bits required to represent the remaining weights. This is achieved using a generalized loss function to minimize overall network size. In our ex-periments we demonstrate floating point accuracy with as few as 3% of the bits and 18% of the weights remaining in the network. ",
    "url": "https://arxiv.org/abs/2301.13142",
    "authors": [
      "Szabolcs Cs\u00e9falvay",
      "James Imber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13145",
    "title": "Accurate and efficient multiscale simulation of a heterogeneous elastic  beam via computation on small sparse patches",
    "abstract": "Modern `smart' materials have complex microscale structure, often with unknown macroscale closure. The Equation-Free Patch Scheme empowers us to non-intrusively, efficiently, and accurately simulate over large scales through computations on only small well-separated patches of the microscale system. Here the microscale system is a solid beam of random heterogeneous elasticity. The continuing challenge is to compute the given physics on just the microscale patches, and couple the patches across un-simulated macroscale space, in order to establish efficiency, accuracy, consistency, and stability on the macroscale. Dynamical systems theory supports the scheme. This research program is to develop a systematic non-intrusive approach, both computationally and analytically proven, to model and compute accurately macroscale system levels of general complex physical and engineering systems. ",
    "url": "https://arxiv.org/abs/2301.13145",
    "authors": [
      "A.J. Roberts",
      "Thien Tran-Duc",
      "J.E. Bunder",
      "Yannis Kevrekidis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2301.13146",
    "title": "Enhancing Neural Network Differential Equation Solvers",
    "abstract": "We motivate the use of neural networks for the construction of numerical solutions to differential equations. We prove that there exists a feed-forward neural network that can arbitrarily minimise an objective function that is zero at the solution of Poisson's equation, allowing us to guarantee that neural network solution estimates can get arbitrarily close to the exact solutions. We also show how these estimates can be appreciably enhanced through various strategies, in particular through the construction of error correction networks, for which we propose a general method. We conclude by providing numerical experiments that attest to the validity of all such strategies for variants of Poisson's equation. ",
    "url": "https://arxiv.org/abs/2301.13146",
    "authors": [
      "Matthew J. H. Wright"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13154",
    "title": "Protein Representation Learning via Knowledge Enhanced Primary Structure  Modeling",
    "abstract": "Protein representation learning has primarily benefited from the remarkable development of language models (LMs). Accordingly, pre-trained protein models also suffer from a problem in LMs: a lack of factual knowledge. The recent solution models the relationships between protein and associated knowledge terms as the knowledge encoding objective. However, it fails to explore the relationships at a more granular level, i.e., the token level. To mitigate this, we propose Knowledge-exploited Auto-encoder for Protein (KeAP), which performs token-level knowledge graph exploration for protein representation learning. In practice, non-masked amino acids iteratively query the associated knowledge tokens to extract and integrate helpful information for restoring masked amino acids via attention. We show that KeAP can consistently outperform the previous counterpart on 9 representative downstream applications, sometimes surpassing it by large margins. These results suggest that KeAP provides an alternative yet effective way to perform knowledge enhanced protein representation learning. ",
    "url": "https://arxiv.org/abs/2301.13154",
    "authors": [
      "Hong-Yu Zhou",
      "Yunxiang Fu",
      "Zhicheng Zhang",
      "Cheng Bian",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.13155",
    "title": "Advancing Radiograph Representation Learning with Masked Record Modeling",
    "abstract": "Modern studies in radiograph representation learning rely on either self-supervision to encode invariant semantics or associated radiology reports to incorporate medical expertise, while the complementarity between them is barely noticed. To explore this, we formulate the self- and report-completion as two complementary objectives and present a unified framework based on masked record modeling (MRM). In practice, MRM reconstructs masked image patches and masked report tokens following a multi-task scheme to learn knowledge-enhanced semantic representations. With MRM pre-training, we obtain pre-trained models that can be well transferred to various radiography tasks. Specifically, we find that MRM offers superior performance in label-efficient fine-tuning. For instance, MRM achieves 88.5% mean AUC on CheXpert using 1% labeled data, outperforming previous R$^2$L methods with 100% labels. On NIH ChestX-ray, MRM outperforms the best performing counterpart by about 3% under small labeling ratios. Besides, MRM surpasses self- and report-supervised pre-training in identifying the pneumonia type and the pneumothorax area, sometimes by large margins. ",
    "url": "https://arxiv.org/abs/2301.13155",
    "authors": [
      "Hong-Yu Zhou",
      "Chenyu Lian",
      "Liansheng Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13159",
    "title": "Spectral properties of the Laplacian of temporal networks following a  constant block Jacobi model",
    "abstract": "We study the behavior of the eigenvectors associated with the smallest eigenvalues of the Laplacian matrix of temporal networks. We consider the multilayer representation of temporal networks, i.e. a set of networks linked through ordinal interconnected layers. We analyze the Laplacian matrix, known as supra-Laplacian, constructed through the supra-adjacency matrix associated with the multilayer formulation of temporal networks, using a constant block Jacobi model which has closed-form solution. To do this, we assume that the inter-layer weights are perturbations of the Kronecker sum of the separate adjacency matrices forming the temporal network. Thus we investigate the properties of the eigenvectors associated with the smallest eigenvalues (close to zero) of the supra-Laplacian matrix. Using arguments of perturbation theory, we show that these eigenvectors can be approximated by linear combinations of the zero eigenvectors of the individual time layers. This finding is crucial in reconsidering and generalizing the role of the Fielder vector in supra-Laplacian matrices. ",
    "url": "https://arxiv.org/abs/2301.13159",
    "authors": [
      "Zhana Kuncheva",
      "Ognyan Kounchev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.13187",
    "title": "Weighted flow diffusion for local graph clustering with node attributes:  an algorithm and statistical guarantees",
    "abstract": "Local graph clustering methods aim to detect small clusters in very large graphs without the need to process the whole graph. They are fundamental and scalable tools for a wide range of tasks such as local community detection, node ranking and node embedding. While prior work on local graph clustering mainly focuses on graphs without node attributes, modern real-world graph datasets typically come with node attributes that provide valuable additional information. We present a simple local graph clustering algorithm for graphs with node attributes, based on the idea of diffusing mass locally in the graph while accounting for both structural and attribute proximities. Using high-dimensional concentration results, we provide statistical guarantees on the performance of the algorithm for the recovery of a target cluster with a single seed node. We give conditions under which a target cluster generated from a fairly general contextual random graph model, which includes both the stochastic block model and the planted cluster model as special cases, can be fully recovered with bounded false positives. Empirically, we validate all theoretical claims using synthetic data, and we show that incorporating node attributes leads to superior local clustering performances using real-world graph datasets. ",
    "url": "https://arxiv.org/abs/2301.13187",
    "authors": [
      "Shenghao Yang",
      "Kimon Fountoulakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.13199",
    "title": "Streaming Anomaly Detection",
    "abstract": "Anomaly detection is critical for finding suspicious behavior in innumerable systems. We need to detect anomalies in real-time, i.e. determine if an incoming entity is anomalous or not, as soon as we receive it, to minimize the effects of malicious activities and start recovery as soon as possible. Therefore, online algorithms that can detect anomalies in a streaming manner are essential. We first propose MIDAS which uses a count-min sketch to detect anomalous edges in dynamic graphs in an online manner, using constant time and memory. We then propose two variants, MIDAS-R which incorporates temporal and spatial relations, and MIDAS-F which aims to filter away anomalous edges to prevent them from negatively affecting the internal data structures. We then extend the count-min sketch to a Higher-Order sketch to capture complex relations in graph data, and to reduce detecting suspicious dense subgraph problem to finding a dense submatrix in constant time. Using this sketch, we propose four streaming methods to detect edge and subgraph anomalies. Next, we broaden the graph setting to multi-aspect data. We propose MStream which detects explainable anomalies in multi-aspect data streams. We further propose MStream-PCA, MStream-IB, and MStream-AE to incorporate correlation between features. Finally, we consider multi-dimensional data streams with concept drift and propose MemStream. MemStream leverages the power of a denoising autoencoder to learn representations and a memory module to learn the dynamically changing trend in data without the need for labels. We prove a theoretical bound on the size of memory for effective drift handling. In addition, we allow quick retraining when the arriving stream becomes sufficiently different from the training data. Furthermore, MemStream makes use of two architecture design choices to be robust to memory poisoning. ",
    "url": "https://arxiv.org/abs/2301.13199",
    "authors": [
      "Siddharth Bhatia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11936",
    "title": "Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks  with Quantum Computation",
    "abstract": "Ridgelet transform has been a fundamental mathematical tool in the theoretical studies of neural networks. However, the practical applicability of ridgelet transform to conducting learning tasks was limited since its numerical implementation by conventional classical computation requires an exponential runtime $\\exp(O(D))$ as data dimension $D$ increases. To address this problem, we develop a quantum ridgelet transform (QRT), which implements the ridgelet transform of a quantum state within a linear runtime $O(D)$ of quantum computation. As an application, we also show that one can use QRT as a fundamental subroutine for quantum machine learning (QML) to efficiently find a sparse trainable subnetwork of large shallow wide neural networks without conducting large-scale optimization of the original network. This application discovers an efficient way in this regime to demonstrate the lottery ticket hypothesis on finding such a sparse trainable neural network. These results open an avenue of QML for accelerating learning tasks with commonly used classical neural networks. ",
    "url": "https://arxiv.org/abs/2301.11936",
    "authors": [
      "Hayata Yamasaki",
      "Sathyawageeswar Subramanian",
      "Satoshi Hayakawa",
      "Sho Sonoda"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11955",
    "title": "Statistical whitening of neural populations with gain-modulating  interneurons",
    "abstract": "Statistical whitening transformations play a fundamental role in many computational systems, and may also play an important role in biological sensory systems. Individual neurons appear to rapidly and reversibly alter their input-output gains, approximately normalizing the variance of their responses. Populations of neurons appear to regulate their joint responses, reducing correlations between neural activities. It is natural to see whitening as the objective that guides these behaviors, but the mechanism for such joint changes is unknown, and direct adjustment of synaptic interactions would seem to be both too slow, and insufficiently reversible. Motivated by the extensive neuroscience literature on rapid gain modulation, we propose a recurrent network architecture in which joint whitening is achieved through modulation of gains within the circuit. Specifically, we derive an online statistical whitening algorithm that regulates the joint second-order statistics of a multi-dimensional input by adjusting the marginal variances of an overcomplete set of interneuron projections. The gains of these interneurons are adjusted individually, using only local signals, and feed back onto the primary neurons. The network converges to a state in which the responses of the primary neurons are whitened. We demonstrate through simulations that the behavior of the network is robust to poor conditioning or noise when the gains are sign-constrained, and can be generalized to achieve a form of local whitening in convolutional populations, such as those found throughout the visual or auditory system. ",
    "url": "https://arxiv.org/abs/2301.11955",
    "authors": [
      "Lyndon R. Duong",
      "David Lipshutz",
      "David J. Heeger",
      "Dmitri B. Chklovskii",
      "Eero P. Simoncelli"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.11965",
    "title": "The persistent homology of genealogical networks",
    "abstract": "Genealogical networks (i.e. family trees) are of growing interest, with the largest known data sets now including well over one billion individuals. Interest in family history also supports an 8.5 billion dollar industry whose size is projected to double within 7 years (FutureWise report HC1137). Yet little mathematical attention has been paid to the complex network properties of genealogical networks, especially at large scales. The structure of genealogical networks is of particular interest due to the practice of forming unions, e.g. marriages, that are typically well outside one's immediate family. In most other networks, including other social networks, no equivalent restriction exists on the distance at which relationships form. To study the effect this has on genealogical networks we use persistent homology to identify and compare the structure of 101 genealogical and 31 other social networks. Specifically, we introduce the notion of a network's persistence curve, which encodes the network's set of persistence intervals. We find that the persistence curves of genealogical networks have a distinct structure when compared to other social networks. This difference in structure also extends to subnetworks of genealogical and social networks suggesting that, even with incomplete data, persistent homology can be used to meaningfully analyze genealogical networks. Here we also describe how concepts from genealogical networks, such as common ancestor cycles, are represented using persistent homology. We expect that persistent homology tools will become increasingly important in genealogical exploration as popular interest in ancestry research continues to expand. ",
    "url": "https://arxiv.org/abs/2301.11965",
    "authors": [
      "Zachary M. Boyd",
      "Nick Callor",
      "Taylor Gledhill",
      "Abigail Jenkins",
      "Robert Snellman",
      "Benjamin Z. Webb",
      "Raelynn Wonnacott"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Discrete Mathematics (cs.DM)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2301.11982",
    "title": "Strategy evolution on dynamic networks",
    "abstract": "Models of strategy evolution on static networks help us understanding how population structure can promote the spread of traits like cooperation. One key mechanism is the formation of altruistic spatial clusters, where neighbors of a cooperative individual are likely to reciprocate, which protects prosocial traits from exploitation. But most real-world interactions are ephemeral and subject to exogenous restructuring, resulting in dynamic social networks. Strategic behavior on dynamic networks is difficult to study, and much less is known about the resulting evolutionary dynamics. Here, we provide an analytical treatment of cooperation on dynamic networks, allowing for arbitrary spatial and temporal heterogeneity. We show that transitions among network structures can favor the spread of cooperation, even if each individual social network would inhibit cooperation when static. Furthermore, we show that spatial heterogeneity tends to inhibit cooperation while temporal heterogeneity tends to promote it. Dynamic networks can therefore have profound effects on the evolution of prosocial traits, even in cases where individuals have no agency over network structure. ",
    "url": "https://arxiv.org/abs/2301.11982",
    "authors": [
      "Qi Su",
      "Alex McAvoy",
      "Joshua B. Plotkin"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2301.12098",
    "title": "Turbulence control in plane Couette flow using low-dimensional neural  ODE-based models and deep reinforcement learning",
    "abstract": "The high dimensionality and complex dynamics of turbulent flows remain an obstacle to the discovery and implementation of control strategies. Deep reinforcement learning (RL) is a promising avenue for overcoming these obstacles, but requires a training phase in which the RL agent iteratively interacts with the flow environment to learn a control policy, which can be prohibitively expensive when the environment involves slow experiments or large-scale simulations. We overcome this challenge using a framework we call \"DManD-RL\" (data-driven manifold dynamics-RL), which generates a data-driven low-dimensional model of our system that we use for RL training. With this approach, we seek to minimize drag in a direct numerical simulation (DNS) of a turbulent minimal flow unit of plane Couette flow at Re=400 using two slot jets on one wall. We obtain, from DNS data with $\\mathcal{O}(10^5)$ degrees of freedom, a 25-dimensional DManD model of the dynamics by combining an autoencoder and neural ordinary differential equation. Using this model as the environment, we train an RL control agent, yielding a 440-fold speedup over training on the DNS, with equivalent control performance. The agent learns a policy that laminarizes 84% of unseen DNS test trajectories within 900 time units, significantly outperforming classical opposition control (58%), despite the actuation authority being much more restricted. The agent often achieves laminarization through a counterintuitive strategy that drives the formation of two low-speed streaks, with a spanwise wavelength that is too small to be self-sustaining. The agent demonstrates the same performance when we limit observations to wall shear rate. ",
    "url": "https://arxiv.org/abs/2301.12098",
    "authors": [
      "Alec J. Linot",
      "Kevin Zeng",
      "Michael D. Graham"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12176",
    "title": "Neural Gas Network Image Features and Segmentation for Brain Tumor  Detection Using Magnetic Resonance Imaging Data",
    "abstract": "Accurate detection of brain tumors could save lots of lives and increasing the accuracy of this binary classification even as much as a few percent has high importance. Neural Gas Networks (NGN) is a fast, unsupervised algorithm that could be used in data clustering, image pattern recognition, and image segmentation. In this research, we used the metaheuristic Firefly Algorithm (FA) for image contrast enhancement as pre-processing and NGN weights for feature extraction and segmentation of Magnetic Resonance Imaging (MRI) data on two brain tumor datasets from the Kaggle platform. Also, tumor classification is conducted by Support Vector Machine (SVM) classification algorithms and compared with a deep learning technique plus other features in train and test phases. Additionally, NGN tumor segmentation is evaluated by famous performance metrics such as Accuracy, F-measure, Jaccard, and more versus ground truth data and compared with traditional segmentation techniques. The proposed method is fast and precise in both tasks of tumor classification and segmentation compared with other methods. A classification accuracy of 95.14 % and segmentation accuracy of 0.977 is achieved by the proposed method. ",
    "url": "https://arxiv.org/abs/2301.12176",
    "authors": [
      "S. Muhammad Hossein Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12232",
    "title": "Tackling Stackelberg Network Interdiction against a Boundedly Rational  Adversary",
    "abstract": "This work studies Stackelberg network interdiction games -- an important class of games in which a defender first allocates (randomized) defense resources to a set of critical nodes on a graph while an adversary chooses its path to attack these nodes accordingly. We consider a boundedly rational adversary in which the adversary's response model is based on a dynamic form of classic logit-based discrete choice models. We show that the problem of finding an optimal interdiction strategy for the defender in the rational setting is NP-hard. The resulting optimization is in fact non-convex and additionally, involves complex terms that sum over exponentially many paths. We tackle these computational challenges by presenting new efficient approximation algorithms with bounded solution guarantees. First, we address the exponentially-many-path challenge by proposing a polynomial-time dynamic programming-based formulation. We then show that the gradient of the non-convex objective can also be computed in polynomial time, which allows us to use a gradient-based method to solve the problem efficiently. Second, we identify a restricted problem that is convex and hence gradient-based methods find the global optimal solution for this restricted problem. We further identify mild conditions under which this restricted problem provides a bounded approximation for the original problem. ",
    "url": "https://arxiv.org/abs/2301.12232",
    "authors": [
      "Tien Mai",
      "Avinandan Bose",
      "Arunesh Sinha",
      "Thanh H. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2301.12258",
    "title": "Cross-domain Neural Pitch and Periodicity Estimation",
    "abstract": "Pitch is a foundational aspect of our perception of audio signals. Pitch contours are commonly used to analyze speech and music signals and as input features for many audio tasks, including music transcription, singing voice synthesis, and prosody editing. In this paper, we describe a set of techniques for improving the accuracy of state-of-the-art neural pitch and periodicity estimators. We also introduce a novel entropy-based method for extracting periodicity and per-frame voiced-unvoiced classifications from statistical inference-based pitch estimators (e.g., neural networks), and show how to train a neural pitch estimator to simultaneously handle speech and music without performance degradation. While neural pitch trackers have historically been significantly slower than signal processing based pitch trackers, our estimator implementations approach the speed of state-of-the-art DSP-based pitch estimators on a standard CPU, but with significantly more accurate pitch and periodicity estimation. Our experiments show that an accurate, cross-domain pitch and periodicity estimator written in PyTorch with a hopsize of ten milliseconds can run 11.2x faster than real-time on a Intel i9-9820X 10-core 3.30 GHz CPU or 408x faster than real-time on a NVIDIA GeForce RTX 3090 GPU without hardware optimization. We release all of our code and models as Pitch-Estimating Neural Networks (penn), an open-source, pip-installable Python module for training, evaluating, and performing inference with pitch- and periodicity-estimating neural networks. The code for penn is available at https://github.com/interactiveaudiolab/penn. ",
    "url": "https://arxiv.org/abs/2301.12258",
    "authors": [
      "Max Morrison",
      "Caedon Hsieh",
      "Nathan Pruyne",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2301.12383",
    "title": "On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs",
    "abstract": "Heterogeneity and comorbidity are two interwoven challenges associated with various healthcare problems that greatly hampered research on developing effective treatment and understanding of the underlying neurobiological mechanism. Very few studies have been conducted to investigate heterogeneous causal effects (HCEs) in graphical contexts due to the lack of statistical methods. To characterize this heterogeneity, we first conceptualize heterogeneous causal graphs (HCGs) by generalizing the causal graphical model with confounder-based interactions and multiple mediators. Such confounders with an interaction with the treatment are known as moderators. This allows us to flexibly produce HCGs given different moderators and explicitly characterize HCEs from the treatment or potential mediators on the outcome. We establish the theoretical forms of HCEs and derive their properties at the individual level in both linear and nonlinear models. An interactive structural learning is developed to estimate the complex HCGs and HCEs with confidence intervals provided. Our method is empirically justified by extensive simulations and its practical usefulness is illustrated by exploring causality among psychiatric disorders for trauma survivors. ",
    "url": "https://arxiv.org/abs/2301.12383",
    "authors": [
      "Richard A Watson",
      "Hengrui Cai",
      "Xinming An",
      "Samuel McLean",
      "Rui Song"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12455",
    "title": "Axiomatic Quantum Field Theory in Discrete Spacetime via Multiway Causal  Structure: The Case of Entanglement Entropies",
    "abstract": "The causal set and Wolfram model approaches to discrete quantum gravity both permit the formulation of a manifestly covariant notion of entanglement entropy for quantum fields. In the causal set case, this is given by a construction (due to Sorkin and Johnston) of a 2-point correlation function for a Gaussian scalar field from causal set Feynman propagators and Pauli-Jordan functions, from which an eigendecomposition, and hence an entanglement entropy, can be computed. In the Wolfram model case, it is given instead in terms of the Fubini-Study metric on branchial graphs, whose tensor product structure is inherited functorially from that of finite-dimensional Hilbert spaces. In both cases, the entanglement entropies in question are most naturally defined over an extended spacetime region (hence the manifest covariance), in contrast to the generically non-covariant definitions over single spacelike hypersurfaces common to most continuum quantum field theories. In this article, we show how an axiomatic field theory for a free, massless scalar field (obeying the appropriate bosonic commutation relations) may be rigorously constructed over multiway causal graphs: a combinatorial structure sufficiently general as to encompass both causal sets and Wolfram model evolutions as special cases. We proceed to show numerically that the entanglement entropies computed using both the Sorkin-Johnston approach and the branchial graph approach are monotonically related for a large class of Wolfram model evolution rules. We also prove a special case of this monotonic relationship using a recent geometrical entanglement monotone proposed by Cocchiarella et al. ",
    "url": "https://arxiv.org/abs/2301.12455",
    "authors": [
      "Jonathan Gorard",
      "Julia Dannemann-Freitag"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.12581",
    "title": "Intrinsic Bayesian Optimisation on Complex Constrained Domain",
    "abstract": "Motivated by the success of Bayesian optimisation algorithms in the Euclidean space, we propose a novel approach to construct Intrinsic Bayesian optimisation (In-BO) on manifolds with a primary focus on complex constrained domains or irregular-shaped spaces arising as submanifolds of R2, R3 and beyond. Data may be collected in a spatial domain but restricted to a complex or intricately structured region corresponding to a geographic feature, such as lakes. Traditional Bayesian Optimisation (Tra-BO) defined with a Radial basis function (RBF) kernel cannot accommodate these complex constrained conditions. The In-BO uses the Sparse Intrinsic Gaussian Processes (SIn-GP) surrogate model to take into account the geometric structure of the manifold. SInGPs are constructed using the heat kernel of the manifold which is estimated as the transition density of the Brownian Motion on manifolds. The efficiency of In-BO is demonstrated through simulation studies on a U-shaped domain, a Bitten torus, and a real dataset from the Aral sea. Its performance is compared to that of traditional BO, which is defined in Euclidean space. ",
    "url": "https://arxiv.org/abs/2301.12581",
    "authors": [
      "Yuan Liu",
      "Mu Niu",
      "Claire Miller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12636",
    "title": "Exploring Image Augmentations for Siamese Representation Learning with  Chest X-Rays",
    "abstract": "Image augmentations are quintessential for effective visual representation learning across self-supervised learning techniques. While augmentation strategies for natural imaging have been studied extensively, medical images are vastly different from their natural counterparts. Thus, it is unknown whether common augmentation strategies employed in Siamese representation learning generalize to medical images and to what extent. To address this challenge, in this study, we systematically assess the effect of various augmentations on the quality and robustness of the learned representations. We train and evaluate Siamese Networks for abnormality detection on chest X-Rays across three large datasets (MIMIC-CXR, CheXpert and VinDR-CXR). We investigate the efficacy of the learned representations through experiments involving linear probing, fine-tuning, zero-shot transfer, and data efficiency. Finally, we identify a set of augmentations that yield robust representations that generalize well to both out-of-distribution data and diseases, while outperforming supervised baselines using just zero-shot transfer and linear probes by up to 20%. ",
    "url": "https://arxiv.org/abs/2301.12636",
    "authors": [
      "Rogier van der Sluijs",
      "Nandita Bhaskhar",
      "Daniel Rubin",
      "Curtis Langlotz",
      "Akshay Chaudhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12651",
    "title": "Complex Critical Points of Deep Linear Neural Networks",
    "abstract": "We extend the work of Mehta, Chen, Tang, and Hauenstein on computing the complex critical points of the loss function of deep linear neutral networks when the activation function is the identity function. For networks with a single hidden layer trained on a single data point we give an improved bound on the number of complex critical points of the loss function. We show that for any number of hidden layers complex critical points with zero coordinates arise in certain patterns which we completely classify for networks with one hidden layer. We report our results of computational experiments with varying network architectures defining small deep linear networks using HomotopyContinuation.jl. ",
    "url": "https://arxiv.org/abs/2301.12651",
    "authors": [
      "Ayush Bharadwaj",
      "Serkan Ho\u015ften"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12684",
    "title": "Attack Impact Evaluation for Stochastic Control Systems through Alarm  Flag State Augmentation",
    "abstract": "This note addresses the problem of evaluating the impact of an attack on discrete-time nonlinear stochastic control systems. The problem is formulated as an optimal control problem with a joint chance constraint that forces the adversary to avoid detection throughout a given time period. Due to the joint constraint, the optimal control policy depends not only on the current state, but also on the entire history, leading to an explosion of the search space and making the problem generally intractable. However, we discover that the current state and whether an alarm has been triggered, or not, is sufficient for specifying the optimal decision at each time step. This information, which we refer to as the alarm flag, can be added to the state space to create an equivalent optimal control problem that can be solved with existing numerical approaches using a Markov policy. Additionally, we note that the formulation results in a policy that does not avoid detection once an alarm has been triggered. We extend the formulation to handle multi-alarm avoidance policies for more reasonable attack impact evaluations, and show that the idea of augmenting the state space with an alarm flag is valid in this extended formulation as well. ",
    "url": "https://arxiv.org/abs/2301.12684",
    "authors": [
      "Hampei Sasahara",
      "Takashi Tanaka",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12743",
    "title": "Mexican violence displaces people, discourages international migration,  and shrinks highway network connections",
    "abstract": "This paper estimates the impact of violence on domestic and international migration in Mexico during 2005-2020. Unlike earlier studies, we use network analysis to quantify changes in the degree of interconnectedness among all municipalities in Mexico and with the US, breaking it down by origin-destination pairs. To identify the impact of violence on the changes of the migration network, we use instrumental variables. We exploit the exogenous variation in heroin street prices in the US, local prices of corn in Mexico, and differences in which regions received more Chinese immigrant communities during the 1930s, members of which introduced opium cultivation and drug smuggling networks in Mexico. These instruments help us identify the areas with a current presence of drug trafficking organizations and facing increases in violence. We show that municipalities that experience rises in homicide rates continue to attract immigrants within the country, but they face a larger rise in domestic emigration. The violence also discourages the return migration of Mexicans from the US and non-transit international emigration. Consistent with our findings, areas affected by violence also experience a long-term reduction in vehicle trips made in the highway network connecting them with the rest of the country. ",
    "url": "https://arxiv.org/abs/2301.12743",
    "authors": [
      "Michele Coscia",
      "Roxana Guti\u00e9rrez-Romero"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.12814",
    "title": "Complexity of Gaussian boson sampling with tensor networks",
    "abstract": "Gaussian boson sampling, a computational model that is widely believed to admit quantum supremacy, has already been experimentally demonstrated to surpasses the classical simulation capabilities of even with the most powerful supercomputers today. However, whether the current approach limited by photon loss and noise in such experiments prescribes a scalable path to quantum advantage is an open question. For example, random circuit sampling with constant noise per gate was recently shown not to be a scalable approach to achieve quantum supremacy, although simulating intermediate scale systems is still difficult. To understand the effect of photon loss on the scability of Gaussian boson sampling, we use a tensor network algorithm with $U(1)$ symmetry to examine the asymptotic operator entanglement entropy scaling, which relates to the simulation complexity. We develop a custom-built algorithm that significantly reduces the computational time with state-of-the-art hardware accelerators, enabling simulations of much larger systems. With this capability, we observe, for Gaussian boson sampling, the crucial $N_\\text{out}\\propto\\sqrt{N}$ scaling of the number of surviving photons in the number of input photons that marks the boundary between efficient and inefficient classical simulation. We further theoretically show that this should be general for other input states. ",
    "url": "https://arxiv.org/abs/2301.12814",
    "authors": [
      "Minzhao Liu",
      "Changhun Oh",
      "Junyu Liu",
      "Liang Jiang",
      "Yuri Alexeev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.12892",
    "title": "Quantifying and maximizing the information flux in recurrent neural  networks",
    "abstract": "Free-running Recurrent Neural Networks (RNNs), especially probabilistic models, generate an ongoing information flux that can be quantified with the mutual information $I\\left[\\vec{x}(t),\\vec{x}(t\\!+\\!1)\\right]$ between subsequent system states $\\vec{x}$. Although, former studies have shown that $I$ depends on the statistics of the network's connection weights, it is unclear (1) how to maximize $I$ systematically and (2) how to quantify the flux in large systems where computing the mutual information becomes intractable. Here, we address these questions using Boltzmann machines as model systems. We find that in networks with moderately strong connections, the mutual information $I$ is approximately a monotonic transformation of the root-mean-square averaged Pearson correlations between neuron-pairs, a quantity that can be efficiently computed even in large systems. Furthermore, evolutionary maximization of $I\\left[\\vec{x}(t),\\vec{x}(t\\!+\\!1)\\right]$ reveals a general design principle for the weight matrices enabling the systematic construction of systems with a high spontaneous information flux. Finally, we simultaneously maximize information flux and the mean period length of cyclic attractors in the state space of these dynamical networks. Our results are potentially useful for the construction of RNNs that serve as short-time memories or pattern generators. ",
    "url": "https://arxiv.org/abs/2301.12892",
    "authors": [
      "Claus Metzner",
      "Marius E. Yamakou",
      "Dennis Voelkl",
      "Achim Schilling",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.12939",
    "title": "Data-driven soiling detection in PV modules",
    "abstract": "Soiling is the accumulation of dirt in solar panels which leads to a decreasing trend in solar energy yield and may be the cause of vast revenue losses. The effect of soiling can be reduced by washing the panels, which is, however, a procedure of non-negligible cost. Moreover, soiling monitoring systems are often unreliable or very costly. We study the problem of estimating the soiling ratio in photo-voltaic (PV) modules, i.e., the ratio of the real power output to the power output that would be produced if solar panels were clean. A key advantage of our algorithms is that they estimate soiling, without needing to train on labelled data, i.e., periods of explicitly monitoring the soiling in each park, and without relying on generic analytical formulas which do not take into account the peculiarities of each installation. We consider as input a time series comprising a minimum set of measurements, that are available to most PV park operators. Our experimental evaluation shows that we significantly outperform current state-of-the-art methods for estimating soiling ratio. ",
    "url": "https://arxiv.org/abs/2301.12939",
    "authors": [
      "Alexandros Kalimeris",
      "Ioannis Psarros",
      "Giorgos Giannopoulos",
      "Manolis Terrovitis",
      "George Papastefanatos",
      "Gregory Kotsis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12973",
    "title": "Robust Precoding via Characteristic Functions for VSAT to  Multi-Satellite Uplink Transmission",
    "abstract": "The uplink from a very small aperture terminal (VSAT) towards multiple satellites is considered, in this paper. VSATs can be equipped with multiple antennas, allowing parallel transmission to multiple satellites. A low-complexity precoder based on imperfect positional information of the satellites is presented. The probability distribution of the position uncertainty and the statistics of the channel elements are related by the characteristic function of the position uncertainty. This knowledge is included in the precoder design to maximize the mean signal-to-leakage-and-noise ratio (SLNR) at the satellites. Furthermore, the performance w.r.t. the inter-satellite distance is numerically evaluated. It is shown that the proposed approach achieves the capacity for perfect position knowledge and sufficiently large inter-satellite distances. In case of imperfect position knowledge, the performance degradation of the robust precoder is relatively small. ",
    "url": "https://arxiv.org/abs/2301.12973",
    "authors": [
      "Maik R\u00f6per",
      "Bho Matthiesen",
      "Dirk W\u00fcbben",
      "Petar Popovski",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.12985",
    "title": "Integrating Earth Observation Data into Causal Inference: Challenges and  Opportunities",
    "abstract": "Observational studies require adjustment for confounding factors that are correlated with both the treatment and outcome. In the setting where the observed variables are tabular quantities such as average income in a neighborhood, tools have been developed for addressing such confounding. However, in many parts of the developing world, features about local communities may be scarce. In this context, satellite imagery can play an important role, serving as a proxy for the confounding variables otherwise unobserved. In this paper, we study confounder adjustment in this non-tabular setting, where patterns or objects found in satellite images contribute to the confounder bias. Using the evaluation of anti-poverty aid programs in Africa as our running example, we formalize the challenge of performing causal adjustment with such unstructured data -- what conditions are sufficient to identify causal effects, how to perform estimation, and how to quantify the ways in which certain aspects of the unstructured image object are most predictive of the treatment decision. Via simulation, we also explore the sensitivity of satellite image-based observational inference to image resolution and to misspecification of the image-associated confounder. Finally, we apply these tools in estimating the effect of anti-poverty interventions in African communities from satellite imagery. ",
    "url": "https://arxiv.org/abs/2301.12985",
    "authors": [
      "Connor T. Jerzak",
      "Fredrik Johansson",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.13099",
    "title": "Prediction of Customer Churn in Banking Industry",
    "abstract": "With the growing competition in banking industry, banks are required to follow customer retention strategies while they are trying to increase their market share by acquiring new customers. This study compares the performance of six supervised classification techniques to suggest an efficient model to predict customer churn in banking industry, given 10 demographic and personal attributes from 10000 customers of European banks. The effect of feature selection, class imbalance, and outliers will be discussed for ANN and random forest as the two competing models. As shown, unlike random forest, ANN does not reveal any serious concern regarding overfitting and is also robust to noise. Therefore, ANN structure with five nodes in a single hidden layer is recognized as the best performing classifier. ",
    "url": "https://arxiv.org/abs/2301.13099",
    "authors": [
      "Sina Esmaeilpour Charandabi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2301.13151",
    "title": "Convolutional Neural Network-Based Automatic Classification of  Colorectal and Prostate Tumor Biopsies Using Multispectral Imagery: System  Development Study",
    "abstract": "Colorectal and prostate cancers are the most common types of cancer in men worldwide. To diagnose colorectal and prostate cancer, a pathologist performs a histological analysis on needle biopsy samples. This manual process is time-consuming and error-prone, resulting in high intra and interobserver variability, which affects diagnosis reliability. This study aims to develop an automatic computerized system for diagnosing colorectal and prostate tumors by using images of biopsy samples to reduce time and diagnosis error rates associated with human analysis. We propose a CNN model for classifying colorectal and prostate tumors from multispectral images of biopsy samples. The key idea was to remove the last block of the convolutional layers and halve the number of filters per layer. Our results showed excellent performance, with an average test accuracy of 99.8% and 99.5% for the prostate and colorectal data sets, respectively. The system showed excellent performance when compared with pretrained CNNs and other classification methods, as it avoids the preprocessing phase while using a single CNN model for classification. Overall, the proposed CNN architecture was globally the best-performing system for classifying colorectal and prostate tumor images. The proposed CNN was detailed and compared with previously trained network models used as feature extractors. These CNNs were also compared with other classification techniques. As opposed to pretrained CNNs and other classification approaches, the proposed CNN yielded excellent results. The computational complexity of the CNNs was also investigated, it was shown that the proposed CNN is better at classifying images than pretrained networks because it does not require preprocessing. Thus, the overall analysis was that the proposed CNN architecture was globally the best-performing system for classifying colorectal and prostate tumor images. ",
    "url": "https://arxiv.org/abs/2301.13151",
    "authors": [
      "Remy Peyret",
      "Duaa alSaeed",
      "Fouad Khelifi",
      "Nadia Al-Ghreimil",
      "Heyam Al-Baity",
      "Ahmed Bouridane"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.13175",
    "title": "Cops and robbers on $P_5$-free graphs",
    "abstract": "We prove that every connected $P_5$-free graph has cop number at most two, solving a conjecture of Sivaraman. In order to do so, we first prove that every connected $P_5$-free graph $G$ with independence number at least three contains a three-vertex induced path with vertices $a \\hbox{-} b \\hbox{-} c$ in order, such that every neighbour of $c$ is also adjacent to one of $a,b$. ",
    "url": "https://arxiv.org/abs/2301.13175",
    "authors": [
      "Maria Chudnovsky",
      "Sergey Norin",
      "Paul Seymour",
      "J\u00e9r\u00e9mie Turcotte"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.13192",
    "title": "Robust empirical risk minimization via Newton's method",
    "abstract": "We study a variant of Newton's method for empirical risk minimization, where at each iteration of the optimization algorithm, we replace the gradient and Hessian of the objective function by robust estimators taken from existing literature on robust mean estimation for multivariate data. After proving a general theorem about the convergence of successive iterates to a small ball around the population-level minimizer, we study consequences of our theory in generalized linear models, when data are generated from Huber's epsilon-contamination model and/or heavy-tailed distributions. We also propose an algorithm for obtaining robust Newton directions based on the conjugate gradient method, which may be more appropriate for high-dimensional settings, and provide conjectures about the convergence of the resulting algorithm. Compared to the robust gradient descent algorithm proposed by Prasad et al. (2020), our algorithm enjoys the faster rates of convergence for successive iterates often achieved by second-order algorithms for convex problems, i.e., quadratic convergence in a neighborhood of the optimum, with a stepsize that may be chosen adaptively via backtracking linesearch. ",
    "url": "https://arxiv.org/abs/2301.13192",
    "authors": [
      "Eirini Ioannou",
      "Muni Sreenivas Pydi",
      "Po-Ling Loh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.05409",
    "title": "Solving high-dimensional Hamilton-Jacobi-Bellman PDEs using neural  networks: perspectives from the theory of controlled diffusions and measures  on path space",
    "abstract": " Title: Solving high-dimensional Hamilton-Jacobi-Bellman PDEs using neural  networks: perspectives from the theory of controlled diffusions and measures  on path space ",
    "url": "https://arxiv.org/abs/2005.05409",
    "authors": [
      "Nikolas N\u00fcsken",
      "Lorenz Richter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.08427",
    "title": "How Powerful are Shallow Neural Networks with Bandlimited Random  Weights?",
    "abstract": " Title: How Powerful are Shallow Neural Networks with Bandlimited Random  Weights? ",
    "url": "https://arxiv.org/abs/2008.08427",
    "authors": [
      "Ming Li",
      "Sho Sonoda",
      "Feilong Cao",
      "Yu Guang Wang",
      "Jiye Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2009.11038",
    "title": "The cost of coordination can exceed the benefit of collaboration in  performing complex tasks",
    "abstract": " Comments: in Press in Collective Intelligence. Please cite the published version using the DOI below ",
    "url": "https://arxiv.org/abs/2009.11038",
    "authors": [
      "Vince J. Straub",
      "Milena Tsvetkova",
      "Taha Yasseri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2103.13676",
    "title": "JDSR-GAN: Constructing An Efficient Joint Learning Network for Masked  Face Super-Resolution",
    "abstract": " Comments: IEEE Transactions on Multimedia, 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2103.13676",
    "authors": [
      "Guangwei Gao",
      "Lei Tang",
      "Fei Wu",
      "Huimin Lu",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2104.02922",
    "title": "Sparse Oblique Decision Trees: A Tool to Understand and Manipulate  Neural Net Features",
    "abstract": " Comments: Appears in Data Mining and Knowledge Discovery (2023), Special Issue on Explainable and Interpretable Machine Learning and Data Mining ",
    "url": "https://arxiv.org/abs/2104.02922",
    "authors": [
      "Suryabhan Singh Hada",
      "Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n",
      "Arman Zharmagambetov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.03138",
    "title": "Destroying Multicolored Paths and Cycles in Edge-Colored Graphs",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2104.03138",
    "authors": [
      "Nils Jakob Eckstein",
      "Niels Gr\u00fcttemeier",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2105.02519",
    "title": "Uncovering the socioeconomic structure of spatial and social  interactions in cities",
    "abstract": " Comments: 9 pages, 4 figures + Appendix ",
    "url": "https://arxiv.org/abs/2105.02519",
    "authors": [
      "Maxime Lenormand",
      "Horacio Samaniego"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2105.08086",
    "title": "Neural Error Mitigation of Near-Term Quantum Simulations",
    "abstract": " Comments: 20 pages, 4 main figures, 7 supplementary figures, 1 supplementary table ",
    "url": "https://arxiv.org/abs/2105.08086",
    "authors": [
      "Elizabeth R. Bennewitz",
      "Florian Hopfmueller",
      "Bohdan Kulchytskyy",
      "Juan Carrasquilla",
      "Pooya Ronagh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.08793",
    "title": "Masked Contrastive Learning for Anomaly Detection",
    "abstract": " Comments: Accepted to IJCAI 2021 ",
    "url": "https://arxiv.org/abs/2105.08793",
    "authors": [
      "Hyunsoo Cho",
      "Jinseok Seol",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.12882",
    "title": "MAVFI: An End-to-End Fault Analysis Framework with Anomaly Detection and  Recovery for Micro Aerial Vehicles",
    "abstract": " Comments: 6 pages, 9 figures; The first two authors have equal contributions; Accepted as a conference paper in DATE 2023 ",
    "url": "https://arxiv.org/abs/2105.12882",
    "authors": [
      "Yu-Shun Hsiao",
      "Zishen Wan",
      "Tianyu Jia",
      "Radhika Ghosal",
      "Abdulrahman Mahmoud",
      "Arijit Raychowdhury",
      "David Brooks",
      "Gu-Yeon Wei",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.00393",
    "title": "Relational Reasoning Networks",
    "abstract": " Title: Relational Reasoning Networks ",
    "url": "https://arxiv.org/abs/2106.00393",
    "authors": [
      "Giuseppe Marra",
      "Michelangelo Diligenti",
      "Francesco Giannini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.02978",
    "title": "Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks",
    "abstract": " Title: Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2106.02978",
    "authors": [
      "Qin Ding",
      "Cho-Jui Hsieh",
      "James Sharpnack"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.03767",
    "title": "Discrete-time Temporal Network Embedding via Implicit Hierarchical  Learning in Hyperbolic Space",
    "abstract": " Comments: KDD2021; V2: fixed some typos ",
    "url": "https://arxiv.org/abs/2107.03767",
    "authors": [
      "Menglin Yang",
      "Min Zhou",
      "Marcus Kalander",
      "Zengfeng Huang",
      "Irwin King"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.11245",
    "title": "Evolutionary Foundation for Heterogeneity in Risk Aversion",
    "abstract": " Title: Evolutionary Foundation for Heterogeneity in Risk Aversion ",
    "url": "https://arxiv.org/abs/2110.11245",
    "authors": [
      "Yuval Heller",
      "Ilan Nehama"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2110.15501",
    "title": "Doubly Robust Interval Estimation for Optimal Policy Evaluation in  Online Learning",
    "abstract": " Title: Doubly Robust Interval Estimation for Optimal Policy Evaluation in  Online Learning ",
    "url": "https://arxiv.org/abs/2110.15501",
    "authors": [
      "Ye Shen",
      "Hengrui Cai",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2111.10447",
    "title": "DyFormer: A Scalable Dynamic Graph Transformer with Provable Benefits on  Generalization Ability",
    "abstract": " Title: DyFormer: A Scalable Dynamic Graph Transformer with Provable Benefits on  Generalization Ability ",
    "url": "https://arxiv.org/abs/2111.10447",
    "authors": [
      "Weilin Cong",
      "Yanhong Wu",
      "Yuandong Tian",
      "Mengting Gu",
      "Yinglong Xia",
      "Chun-cheng Jason Chen",
      "Mehrdad Mahdavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.13850",
    "title": "Temporal Context Mining for Learned Video Compression",
    "abstract": " Title: Temporal Context Mining for Learned Video Compression ",
    "url": "https://arxiv.org/abs/2111.13850",
    "authors": [
      "Xihua Sheng",
      "Jiahao Li",
      "Bin Li",
      "Li Li",
      "Dong Liu",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.05755",
    "title": "Information Prebuilt Recurrent Reconstruction Network for Video  Super-Resolution",
    "abstract": " Comments: 12 pages,9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2112.05755",
    "authors": [
      "Ming Yu",
      "Shuyun Wang",
      "Cuihong Xue",
      "Yingchun Guo",
      "Gang Yan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01130",
    "title": "Reusing Verification Assertions as Security Checkers for Hardware Trojan  Detection",
    "abstract": " Comments: 6 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2201.01130",
    "authors": [
      "Mohammad Eslami",
      "Tara Ghasempouri",
      "Samuel Pagliarini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2201.04452",
    "title": "Machine-learning-aided Massive Hybrid Analog and Digital MIMO DOA  Estimation for Future Wireless Networks",
    "abstract": " Title: Machine-learning-aided Massive Hybrid Analog and Digital MIMO DOA  Estimation for Future Wireless Networks ",
    "url": "https://arxiv.org/abs/2201.04452",
    "authors": [
      "Feng Shu",
      "Yiwen Chen",
      "Xichao Zhan",
      "Wenlong Cai",
      "Mengxing Huang",
      "Qijuan Jie",
      "Yifang Li",
      "Baihua Shi",
      "Jiangzhou Wang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2203.06125",
    "title": "Protein Representation Learning by Geometric Structure Pretraining",
    "abstract": " Title: Protein Representation Learning by Geometric Structure Pretraining ",
    "url": "https://arxiv.org/abs/2203.06125",
    "authors": [
      "Zuobai Zhang",
      "Minghao Xu",
      "Arian Jamasb",
      "Vijil Chenthamarakshan",
      "Aurelie Lozano",
      "Payel Das",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.10583",
    "title": "Should Users Trust Their Android Devices? A Scoring System for Assessing  Security and Privacy Risks of Pre-Installed Applications",
    "abstract": " Comments: 16 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2203.10583",
    "authors": [
      "Abdullah Ozbay",
      "Kemal Bicakci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.05177",
    "title": "The PartialSpoof Database and Countermeasures for the Detection of Short  Fake Speech Segments Embedded in an Utterance",
    "abstract": " Comments: Published in IEEE/ACM Transactions on Audio, Speech, and Language Processing (DOI: 10.1109/TASLP.2022.3233236) ",
    "url": "https://arxiv.org/abs/2204.05177",
    "authors": [
      "Lin Zhang",
      "Xin Wang",
      "Erica Cooper",
      "Nicholas Evans",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.08696",
    "title": "CTCNet: A CNN-Transformer Cooperation Network for Face Image  Super-Resolution",
    "abstract": " Comments: 13 pages, 12 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2204.08696",
    "authors": [
      "Guangwei Gao",
      "Zixiang Xu",
      "Juncheng Li",
      "Jian Yang",
      "Tieyong Zeng",
      "Guo-Jun Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.12489",
    "title": "Sound Localization by Self-Supervised Time Delay Estimation",
    "abstract": " Comments: ECCV 2022 ",
    "url": "https://arxiv.org/abs/2204.12489",
    "authors": [
      "Ziyang Chen",
      "David F. Fouhey",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.00305",
    "title": "AdapterBias: Parameter-efficient Token-dependent Representation Shift  for Adapters in NLP Tasks",
    "abstract": " Comments: Findings of NAACL 2022 ",
    "url": "https://arxiv.org/abs/2205.00305",
    "authors": [
      "Chin-Lun Fu",
      "Zih-Ching Chen",
      "Yun-Ru Lee",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.04309",
    "title": "Characterizing Positionality in Games of Infinite Duration over Infinite  Graphs",
    "abstract": " Comments: 51 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2205.04309",
    "authors": [
      "Pierre Ohlmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2205.09683",
    "title": "Dexterous Robotic Manipulation using Deep Reinforcement Learning and  Knowledge Transfer for Complex Sparse Reward-based Tasks",
    "abstract": " Comments: This paper has been summited to Expert Systems: the Journal of Knowledge Engineering for reviewing. arXiv admin note: text overlap with arXiv:2109.15233 ",
    "url": "https://arxiv.org/abs/2205.09683",
    "authors": [
      "Qiang Wang",
      "Francisco Roldan Sanchez",
      "Robert McCarthy",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Noel O'Connor",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Stefan Bauer",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11796",
    "title": "G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection",
    "abstract": " Comments: 24 pages, 6 figures, 10 tables, the code has been open sourced at this https URL ",
    "url": "https://arxiv.org/abs/2205.11796",
    "authors": [
      "Liping Hou",
      "Ke Lu",
      "Xue Yang",
      "Yuqiu Li",
      "Jian Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13578",
    "title": "Dynamic Network Reconfiguration for Entropy Maximization using Deep  Reinforcement Learning",
    "abstract": " Comments: 10 pages, 6 figures, 1 appendix ",
    "url": "https://arxiv.org/abs/2205.13578",
    "authors": [
      "Christoffel Doorman",
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2205.15680",
    "title": "Simulation-Based Inference with Waldo: Confidence Regions by Leveraging  Prediction Algorithms or Posterior Estimators for Inverse Problems",
    "abstract": " Comments: 15 pages, 10 figures, code available at this https URL ",
    "url": "https://arxiv.org/abs/2205.15680",
    "authors": [
      "Luca Masserano",
      "Tommaso Dorigo",
      "Rafael Izbicki",
      "Mikael Kuusela",
      "Ann B. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00553",
    "title": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms  for Neural Networks",
    "abstract": " Title: FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms  for Neural Networks ",
    "url": "https://arxiv.org/abs/2206.00553",
    "authors": [
      "Kiarash Mohammadi",
      "Aishwarya Sivaraman",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2206.00566",
    "title": "The Fully Convolutional Transformer for Medical Image Segmentation",
    "abstract": " Title: The Fully Convolutional Transformer for Medical Image Segmentation ",
    "url": "https://arxiv.org/abs/2206.00566",
    "authors": [
      "Athanasios Tragakis",
      "Chaitanya Kaul",
      "Roderick Murray-Smith",
      "Dirk Husmeier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.05794",
    "title": "SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks",
    "abstract": " Title: SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks ",
    "url": "https://arxiv.org/abs/2206.05794",
    "authors": [
      "Tomer Galanti",
      "Zachary S. Siegel",
      "Aparna Gupte",
      "Tomaso Poggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.06089",
    "title": "Graph Neural Networks Intersect Probabilistic Graphical Models: A Survey",
    "abstract": " Title: Graph Neural Networks Intersect Probabilistic Graphical Models: A Survey ",
    "url": "https://arxiv.org/abs/2206.06089",
    "authors": [
      "Chenqing Hua",
      "Sitao Luan",
      "Qian Zhang",
      "Jie Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.06669",
    "title": "Walking Under the Ladder Logic: PLC-VBS, a PLC Control Logic  Vulnerability Discovery Tool",
    "abstract": " Title: Walking Under the Ladder Logic: PLC-VBS, a PLC Control Logic  Vulnerability Discovery Tool ",
    "url": "https://arxiv.org/abs/2206.06669",
    "authors": [
      "Sam Maesschalck",
      "Alexander Staves",
      "Richard Derbyshire",
      "Benjamin Green",
      "David Hutchison"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.07081",
    "title": "Applications of Generative Adversarial Networks in Neuroimaging and  Clinical Neuroscience",
    "abstract": " Title: Applications of Generative Adversarial Networks in Neuroimaging and  Clinical Neuroscience ",
    "url": "https://arxiv.org/abs/2206.07081",
    "authors": [
      "Rongguang Wang",
      "Vishnu Bashyam",
      "Zhijian Yang",
      "Fanyang Yu",
      "Vasiliki Tassopoulou",
      "Sai Spandana Chintapalli",
      "Ioanna Skampardoni",
      "Lasya P. Sreepada",
      "Dushyant Sahoo",
      "Konstantina Nikita",
      "Ahmed Abdulkadir",
      "Junhao Wen",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2207.01524",
    "title": "Variational Neural Networks",
    "abstract": " Comments: 5 pages, 3 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2207.01524",
    "authors": [
      "Illia Oleksiienko",
      "Dat Thanh Tran",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.02891",
    "title": "Don't overfit the history -- Recursive time series data augmentation",
    "abstract": " Comments: Accepted to ICLR 2023 Resubmitted here due to major change in proofs following conference submission ",
    "url": "https://arxiv.org/abs/2207.02891",
    "authors": [
      "Amine Mohamed Aboussalah",
      "Min-Jae Kwon",
      "Raj G Patel",
      "Cheng Chi",
      "Chi-Guhn Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.07774",
    "title": "BDPC: Controlling Application Delay in 6TiSCH networks for the  Industrial Internet of Things",
    "abstract": " Comments: This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2207.07774",
    "authors": [
      "Lucas Aimaretto",
      "Diego Dujovne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.13243",
    "title": "Toward Transparent AI: A Survey on Interpreting the Inner Structures of  Deep Neural Networks",
    "abstract": " Title: Toward Transparent AI: A Survey on Interpreting the Inner Structures of  Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2207.13243",
    "authors": [
      "Tilman R\u00e4uker",
      "Anson Ho",
      "Stephen Casper",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07012",
    "title": "MM-GNN: Mix-Moment Graph Neural Network towards Modeling Neighborhood  Feature Distribution",
    "abstract": " Comments: accepted by WSDM2023 ",
    "url": "https://arxiv.org/abs/2208.07012",
    "authors": [
      "Wendong Bi",
      "Lun Du",
      "Qiang Fu",
      "Yanlin Wang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.07628",
    "title": "FALCON: Faithful Neural Semantic Entailment over ALC Ontologies",
    "abstract": " Title: FALCON: Faithful Neural Semantic Entailment over ALC Ontologies ",
    "url": "https://arxiv.org/abs/2208.07628",
    "authors": [
      "Zhenwei Tang",
      "Tilman Hinnerichs",
      "Xi Peng",
      "Xiangliang Zhang",
      "Robert Hoehndorf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2208.10630",
    "title": "Fault Current-Constrained Optimal Power Flow on Unbalanced Distribution  Networks",
    "abstract": " Comments: 5 pages. 1 figure. 3 tables ",
    "url": "https://arxiv.org/abs/2208.10630",
    "authors": [
      "Jose E. Tabarez",
      "Arthur K. Barnes",
      "Adam Mate",
      "Russell W. Bent"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.10925",
    "title": "Vox-Surf: Voxel-based Implicit Surface Representation",
    "abstract": " Title: Vox-Surf: Voxel-based Implicit Surface Representation ",
    "url": "https://arxiv.org/abs/2208.10925",
    "authors": [
      "Hai Li",
      "Xingrui Yang",
      "Hongjia Zhai",
      "Yuqian Liu",
      "Hujun Bao",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.13764",
    "title": "Temporal Label Smoothing for Early Event Prediction",
    "abstract": " Title: Temporal Label Smoothing for Early Event Prediction ",
    "url": "https://arxiv.org/abs/2208.13764",
    "authors": [
      "Hugo Y\u00e8che",
      "Aliz\u00e9e Pace",
      "Gunnar R\u00e4tsch",
      "Rita Kuznetsova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.02111",
    "title": "Discovering Block Structure in Networks",
    "abstract": " Title: Discovering Block Structure in Networks ",
    "url": "https://arxiv.org/abs/2209.02111",
    "authors": [
      "Rudy Arthur"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.05299",
    "title": "Deep Convolutional Pooling Transformer for Deepfake Detection",
    "abstract": " Comments: 13 pages for peer review ",
    "url": "https://arxiv.org/abs/2209.05299",
    "authors": [
      "Tianyi Wang",
      "Harry Cheng",
      "Kam Pui Chow",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08639",
    "title": "Distributionally robust trading strategies for renewable energy  producers",
    "abstract": " Title: Distributionally robust trading strategies for renewable energy  producers ",
    "url": "https://arxiv.org/abs/2209.08639",
    "authors": [
      "Pierre Pinson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.09699",
    "title": "PADLoC: LiDAR-Based Deep Loop Closure Detection and Registration Using  Panoptic Attention",
    "abstract": " Title: PADLoC: LiDAR-Based Deep Loop Closure Detection and Registration Using  Panoptic Attention ",
    "url": "https://arxiv.org/abs/2209.09699",
    "authors": [
      "Jos\u00e9 Arce",
      "Niclas V\u00f6disch",
      "Daniele Cattaneo",
      "Wolfram Burgard",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.10866",
    "title": "A One-shot Framework for Distributed Clustered Learning in Heterogeneous  Environments",
    "abstract": " Title: A One-shot Framework for Distributed Clustered Learning in Heterogeneous  Environments ",
    "url": "https://arxiv.org/abs/2209.10866",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15190",
    "title": "Neural Integral Equations",
    "abstract": " Comments: 11 + 21 pages, 16 figures and 9 tables. Comments are welcome! v3: Exposition improved to make the article more self-contained, and several references on the theory of integral equations have been added. Codes will be made public after the peer-review process ",
    "url": "https://arxiv.org/abs/2209.15190",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Josue Ortega Caro",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.00737",
    "title": "FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients",
    "abstract": " Title: FedDig: Robust Federated Learning Using Data Digest to Represent Absent  Clients ",
    "url": "https://arxiv.org/abs/2210.00737",
    "authors": [
      "Chih-Fan Hsu",
      "Ming-Ching Chang",
      "Wei-Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01376",
    "title": "Improved High-Probability Regret for Adversarial Bandits with  Time-Varying Feedback Graphs",
    "abstract": " Title: Improved High-Probability Regret for Adversarial Bandits with  Time-Varying Feedback Graphs ",
    "url": "https://arxiv.org/abs/2210.01376",
    "authors": [
      "Haipeng Luo",
      "Hanghang Tong",
      "Mengxiao Zhang",
      "Yuheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.03292",
    "title": "Unsupervised Semantic Representation Learning of Scientific Literature  Based on Graph Attention Mechanism and Maximum Mutual Information",
    "abstract": " Title: Unsupervised Semantic Representation Learning of Scientific Literature  Based on Graph Attention Mechanism and Maximum Mutual Information ",
    "url": "https://arxiv.org/abs/2210.03292",
    "authors": [
      "Hongrui Gao",
      "Yawen Li",
      "Meiyu Liang",
      "Zeli Guan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.06175",
    "title": "Exploring Efficient-tuning Methods in Self-supervised Speech Models",
    "abstract": " Comments: SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.06175",
    "authors": [
      "Zih-Ching Chen",
      "Chin-Lun Fu",
      "Chih-Ying Liu",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.13148",
    "title": "Transformers over Directed Acyclic Graphs",
    "abstract": " Title: Transformers over Directed Acyclic Graphs ",
    "url": "https://arxiv.org/abs/2210.13148",
    "authors": [
      "Yuankai Luo",
      "Veronika Thost"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15045",
    "title": "Optimal Patrolling Strategies for Trees and Complete Networks",
    "abstract": " Title: Optimal Patrolling Strategies for Trees and Complete Networks ",
    "url": "https://arxiv.org/abs/2210.15045",
    "authors": [
      "Thuy Bui",
      "Thomas Lidbetter"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.15824",
    "title": "Improving the Modality Representation with Multi-View Contrastive  Learning for Multimodal Sentiment Analysis",
    "abstract": " Title: Improving the Modality Representation with Multi-View Contrastive  Learning for Multimodal Sentiment Analysis ",
    "url": "https://arxiv.org/abs/2210.15824",
    "authors": [
      "Peipei Liu",
      "Xin Zheng",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.17406",
    "title": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "abstract": " Title: Emergent Linguistic Structures in Neural Networks are Fragile ",
    "url": "https://arxiv.org/abs/2210.17406",
    "authors": [
      "Emanuele La Malfa",
      "Matthew Wicker",
      "Marta Kiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.02922",
    "title": "Beyond Hawkes: Neural Multi-event Forecasting on Spatio-temporal Point  Processes",
    "abstract": " Comments: Submitted to ICML2023 ",
    "url": "https://arxiv.org/abs/2211.02922",
    "authors": [
      "Negar Erfanian",
      "Santiago Segarra",
      "Maarten de Hoop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.03846",
    "title": "FED-CD: Federated Causal Discovery from Interventional and Observational  Data",
    "abstract": " Title: FED-CD: Federated Causal Discovery from Interventional and Observational  Data ",
    "url": "https://arxiv.org/abs/2211.03846",
    "authors": [
      "Amin Abyaneh",
      "Nino Scherrer",
      "Patrick Schwab",
      "Stefan Bauer",
      "Bernhard Sch\u00f6lkopf",
      "Arash Mehrjou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.08227",
    "title": "Perona: Robust Infrastructure Fingerprinting for Resource-Efficient Big  Data Analytics",
    "abstract": " Comments: 8 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2211.08227",
    "authors": [
      "Dominik Scheinert",
      "Soeren Becker",
      "Jonathan Bader",
      "Lauritz Thamsen",
      "Jonathan Will",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.09887",
    "title": "Microstructural parameter estimation using spherical convolutional  neural networks",
    "abstract": " Title: Microstructural parameter estimation using spherical convolutional  neural networks ",
    "url": "https://arxiv.org/abs/2211.09887",
    "authors": [
      "Leevi Kerkel\u00e4",
      "Kiran Seunarine",
      "Filip Szczepankiewicz",
      "Chris A. Clark"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2211.09945",
    "title": "SparseVLR: A Framework for Verified Locally Robust Sparse Neural  Networks Search",
    "abstract": " Comments: 17 pages, 9 tables, 7 figures ",
    "url": "https://arxiv.org/abs/2211.09945",
    "authors": [
      "Sawinder Kaur",
      "Asif Salekin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.11378",
    "title": "Learning on tree architectures outperforms a convolutional feedforward  network",
    "abstract": " Comments: 21 pages, 4 figures, 2 table ",
    "url": "https://arxiv.org/abs/2211.11378",
    "authors": [
      "Yuval Meir",
      "Itamar Ben-Noam",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15081",
    "title": "Flip Initial Features: Generalization of Neural Networks Under Sparse  Features for Semi-supervised Node Classification",
    "abstract": " Title: Flip Initial Features: Generalization of Neural Networks Under Sparse  Features for Semi-supervised Node Classification ",
    "url": "https://arxiv.org/abs/2211.15081",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": " Comments: To appear in AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.01117",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.04546",
    "title": "A Dependable Hybrid Machine Learning Model for Network Intrusion  Detection",
    "abstract": " Comments: Accepted in the Journal of Information Security and Applications (Scopus, Web of Science (SCIE) Journal, Quartile: Q1, Site Score: 7.6, Impact Factor: 4.96) on 7 December 2022 ",
    "url": "https://arxiv.org/abs/2212.04546",
    "authors": [
      "Md. Alamin Talukder",
      "Khondokar Fida Hasan",
      "Md. Manowarul Islam",
      "Md Ashraf Uddin",
      "Arnisha Akhter",
      "Mohammad Abu Yousuf",
      "Fares Alharbi",
      "Mohammad Ali Moni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04632",
    "title": "Category-Level 6D Object Pose Estimation with Flexible Vector-Based  Rotation Representation",
    "abstract": " Comments: revised from CVPR2021 paper FS-NET. arXiv admin note: substantial text overlap with arXiv:2103.07054 ",
    "url": "https://arxiv.org/abs/2212.04632",
    "authors": [
      "Wei Chen",
      "Xi Jia",
      "Zhongqun Zhang",
      "Hyung Jin Chang",
      "Linlin Shen",
      "Jinming Duan",
      "Ales Leonardis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07425",
    "title": "Robust and Explainable Identification of Logical Fallacies in Natural  Language Arguments",
    "abstract": " Comments: Added more discussion to the Results section ",
    "url": "https://arxiv.org/abs/2212.07425",
    "authors": [
      "Zhivar Sourati",
      "Vishnu Priya Prasanna Venkatesh",
      "Darshan Deshpande",
      "Himanshu Rawlani",
      "Filip Ilievski",
      "H\u00f4ng-\u00c2n Sandlin",
      "Alain Mermoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.08479",
    "title": "Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR  Imaging",
    "abstract": " Title: Neural Implicit k-Space for Binning-free Non-Cartesian Cardiac MR  Imaging ",
    "url": "https://arxiv.org/abs/2212.08479",
    "authors": [
      "Wenqi Huang",
      "Hongwei Li",
      "Jiazhen Pan",
      "Gastao Cruz",
      "Daniel Rueckert",
      "Kerstin Hammernik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.08665",
    "title": "Hard Sample Aware Network for Contrastive Deep Graph Clustering",
    "abstract": " Comments: add appendix ",
    "url": "https://arxiv.org/abs/2212.08665",
    "authors": [
      "Yue Liu",
      "Xihong Yang",
      "Sihang Zhou",
      "Xinwang Liu",
      "Zhen Wang",
      "Ke Liang",
      "Wenxuan Tu",
      "Liang Li",
      "Jingcan Duan",
      "Cancan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09637",
    "title": "A Sequential Concept Drift Detection Method for On-Device Learning on  Low-End Edge Devices",
    "abstract": " Comments: Fig.4 is replaced with a better one ",
    "url": "https://arxiv.org/abs/2212.09637",
    "authors": [
      "Takeya Yamada",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.09877",
    "title": "LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer",
    "abstract": " Title: LayoutDETR: Detection Transformer Is a Good Multimodal Layout Designer ",
    "url": "https://arxiv.org/abs/2212.09877",
    "authors": [
      "Ning Yu",
      "Chia-Chih Chen",
      "Zeyuan Chen",
      "Rui Meng",
      "Gang Wu",
      "Paul Josel",
      "Juan Carlos Niebles",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.10426",
    "title": "Deep Riemannian Networks for EEG Decoding",
    "abstract": " Comments: 26 pages, 15 Figures ",
    "url": "https://arxiv.org/abs/2212.10426",
    "authors": [
      "Daniel Wilson",
      "Robin Tibor Schirrmeister",
      "Lukas Alexander Wilhelm Gemein",
      "Tonio Ball"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.14365",
    "title": "INO: Invariant Neural Operators for Learning Complex Physical Systems  with Momentum Conservation",
    "abstract": " Title: INO: Invariant Neural Operators for Learning Complex Physical Systems  with Momentum Conservation ",
    "url": "https://arxiv.org/abs/2212.14365",
    "authors": [
      "Ning Liu",
      "Yue Yu",
      "Huaiqian You",
      "Neeraj Tatikola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.14580",
    "title": "Heterogeneous Synthetic Learner for Panel Data",
    "abstract": " Title: Heterogeneous Synthetic Learner for Panel Data ",
    "url": "https://arxiv.org/abs/2212.14580",
    "authors": [
      "Ye Shen",
      "Runzhe Wan",
      "Hengrui Cai",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.00327",
    "title": "Convergence and Generalization of Wide Neural Networks with Large Bias",
    "abstract": " Title: Convergence and Generalization of Wide Neural Networks with Large Bias ",
    "url": "https://arxiv.org/abs/2301.00327",
    "authors": [
      "Hongru Yang",
      "Ziyu Jiang",
      "Ruizhe Zhang",
      "Zhangyang Wang",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00437",
    "title": "Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced  Data",
    "abstract": " Comments: 87 pages, 12 figures, 4 tables. Hien Dang and Tho Tran and Tan Nguyen contributed equally to this work ",
    "url": "https://arxiv.org/abs/2301.00437",
    "authors": [
      "Hien Dang",
      "Tho Tran",
      "Tan Nguyen",
      "Stanley Osher",
      "Hung Tran-The",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.02647",
    "title": "Universal adaptive optics for microscopy through embedded neural network  control",
    "abstract": " Comments: 27 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2301.02647",
    "authors": [
      "Qi Hu",
      "Martin Hailstone",
      "Jingyu Wang",
      "Matthew Wincott",
      "Danail Stoychev",
      "Huriye Atilgan",
      "Dalia Gala",
      "Tai Chaiamarit",
      "Richard M. Parton",
      "Jacopo Antonello",
      "Adam M. Packer",
      "Ilan Davis",
      "Martin J. Booth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2301.05104",
    "title": "Learning Compiler Pass Orders using Coreset and Normalized Value  Prediction",
    "abstract": " Title: Learning Compiler Pass Orders using Coreset and Normalized Value  Prediction ",
    "url": "https://arxiv.org/abs/2301.05104",
    "authors": [
      "Youwei Liang",
      "Kevin Stone",
      "Ali Shameli",
      "Chris Cummins",
      "Mostafa Elhoushi",
      "Jiadong Guo",
      "Benoit Steiner",
      "Xiaomeng Yang",
      "Pengtao Xie",
      "Hugh Leather",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05711",
    "title": "OA-BEV: Bringing Object Awareness to Bird's-Eye-View Representation for  Multi-Camera 3D Object Detection",
    "abstract": " Title: OA-BEV: Bringing Object Awareness to Bird's-Eye-View Representation for  Multi-Camera 3D Object Detection ",
    "url": "https://arxiv.org/abs/2301.05711",
    "authors": [
      "Xiaomeng Chu",
      "Jiajun Deng",
      "Yuan Zhao",
      "Jianmin Ji",
      "Yu Zhang",
      "Houqiang Li",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06646",
    "title": "Async-HFL: Efficient and Robust Asynchronous Federated Learning in  Hierarchical IoT Networks",
    "abstract": " Comments: To appear in IoTDI'23. Copyright may transfer without notice ",
    "url": "https://arxiv.org/abs/2301.06646",
    "authors": [
      "Xiaofan Yu",
      "Ludmila Cherkasova",
      "Harsh Vardhan",
      "Quanling Zhao",
      "Emily Ekaireb",
      "Xiyuan Zhang",
      "Arya Mazumdar",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2301.06732",
    "title": "Coronal Hole Analysis and Prediction using Computer Vision and LSTM  Neural Network",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2301.06732",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ]
  },
  {
    "id": "arXiv:2301.06957",
    "title": "FewSOME: Few Shot Anomaly Detection",
    "abstract": " Title: FewSOME: Few Shot Anomaly Detection ",
    "url": "https://arxiv.org/abs/2301.06957",
    "authors": [
      "Niamh Belton",
      "Misgina Tsighe Hagos",
      "Aonghus Lawlor",
      "Kathleen M. Curran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.07191",
    "title": "A Note on the Simplex-Tree Construction of the Vietoris-Rips Complex",
    "abstract": " Comments: 5 pages ",
    "url": "https://arxiv.org/abs/2301.07191",
    "authors": [
      "Antonio Rieser"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2301.08130",
    "title": "A Cohesive Distillation Architecture for Neural Language Models",
    "abstract": " Comments: Master thesis, 93 pages ",
    "url": "https://arxiv.org/abs/2301.08130",
    "authors": [
      "Jan Philip Wahle"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.08861",
    "title": "Data-Driven Distributionally Robust Scheduling of Community Integrated  Energy Systems with Uncertain Renewable Generations Considering Integrated  Demand Response",
    "abstract": " Comments: Accepted by Applied Energy ",
    "url": "https://arxiv.org/abs/2301.08861",
    "authors": [
      "Yang Li",
      "Meng Han",
      "Mohammad Shahidehpour",
      "Jiazheng Li",
      "Chao Long"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.08881",
    "title": "Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL  Robustness",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2301.08881",
    "authors": [
      "Shuaichen Chang",
      "Jun Wang",
      "Mingwen Dong",
      "Lin Pan",
      "Henghui Zhu",
      "Alexander Hanbo Li",
      "Wuwei Lan",
      "Sheng Zhang",
      "Jiarong Jiang",
      "Joseph Lilien",
      "Steve Ash",
      "William Yang Wang",
      "Zhiguo Wang",
      "Vittorio Castelli",
      "Patrick Ng",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.08883",
    "title": "Versatile Neural Processes for Learning Implicit Neural Representations",
    "abstract": " Comments: Accepted by ICLR2023 ",
    "url": "https://arxiv.org/abs/2301.08883",
    "authors": [
      "Zongyu Guo",
      "Cuiling Lan",
      "Zhizheng Zhang",
      "Yan Lu",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.09507",
    "title": "Characterizing Polarization in Social Networks using the Signed  Relational Latent Distance Model",
    "abstract": " Comments: Preprint version - Accepted for the proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS) 2023 ",
    "url": "https://arxiv.org/abs/2301.09507",
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir \u00c7elikkanat",
      "Louis Boucherie",
      "Christian Djurhuus",
      "Felix Burmester",
      "Daniel Mathias Holmelund",
      "Monika Frolcov\u00e1",
      "Morten M\u00f8rup"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.10616",
    "title": "Prediction of COVID-19 by Its Variants using Multivariate Data-driven  Deep Learning Models",
    "abstract": " Title: Prediction of COVID-19 by Its Variants using Multivariate Data-driven  Deep Learning Models ",
    "url": "https://arxiv.org/abs/2301.10616",
    "authors": [
      "Akhmad Dimitri Baihaqi",
      "Novanto Yudistira",
      "Edy Santoso"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10896",
    "title": "Causal Reasoning of Entities and Events in Procedural Texts",
    "abstract": " Comments: Accepted to Findings of EACL 2023 ",
    "url": "https://arxiv.org/abs/2301.10896",
    "authors": [
      "Li Zhang",
      "Hainiu Xu",
      "Yue Yang",
      "Shuyan Zhou",
      "Weiqiu You",
      "Manni Arora",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.10960",
    "title": "Visiting Distant Neighbors in Graph Convolutional Networks",
    "abstract": " Title: Visiting Distant Neighbors in Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2301.10960",
    "authors": [
      "Alireza Hashemi",
      "Hernan Makse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.10964",
    "title": "Interaction-level Membership Inference Attack Against Federated  Recommender Systems",
    "abstract": " Comments: This paper has been accepted by The Web Conference (WWW) 2023 ",
    "url": "https://arxiv.org/abs/2301.10964",
    "authors": [
      "Wei Yuan",
      "Chaoqun Yang",
      "Quoc Viet Hung Nguyen",
      "Lizhen Cui",
      "Tieke He",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.11004",
    "title": "NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media",
    "abstract": " Comments: Will improve the work further ",
    "url": "https://arxiv.org/abs/2301.11004",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Usman Naseem",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11189",
    "title": "Improving Statistical Fidelity for Neural Image Compression with  Implicit Local Likelihood Models",
    "abstract": " Comments: 16 pages, 10 figures, reduced PDF size ",
    "url": "https://arxiv.org/abs/2301.11189",
    "authors": [
      "Matthew J. Muckley",
      "Alaaeldin El-Nouby",
      "Karen Ullrich",
      "Herv\u00e9 J\u00e9gou",
      "Jakob Verbeek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.11197",
    "title": "Causal Graph Discovery from Self and Mutually Exciting Time Series",
    "abstract": " Comments: This is an updated version of our previous workshop paper; instead of posting it as a new submission, we update the previous arxiv preprint arXiv:2106.02600 . Also, the previous workshop paper can be found in the \"past version\" using the above arXiv link ",
    "url": "https://arxiv.org/abs/2301.11197",
    "authors": [
      "Song Wei",
      "Yao Xie",
      "Christopher S. Josef",
      "Rishikesan Kamaleswaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.11443",
    "title": "Limitless stability for Graph Convolutional Networks",
    "abstract": " Title: Limitless stability for Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2301.11443",
    "authors": [
      "Christian Koke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2301.11546",
    "title": "Adapting Step-size: A Unified Perspective to Analyze and Improve  Gradient-based Methods for Adversarial Attacks",
    "abstract": " Title: Adapting Step-size: A Unified Perspective to Analyze and Improve  Gradient-based Methods for Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2301.11546",
    "authors": [
      "Wei Tao",
      "Lei Bao",
      "Sheng Long",
      "Gaowei Wu",
      "Qing Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11660",
    "title": "Probing Out-of-Distribution Robustness of Language Models with  Parameter-Efficient Transfer Learning",
    "abstract": " Comments: WIP ",
    "url": "https://arxiv.org/abs/2301.11660",
    "authors": [
      "Hyunsoo Cho",
      "Choonghyun Park",
      "Junyeop Kim",
      "Hyuhng Joon Kim",
      "Kang Min Yoo",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11661",
    "title": "A Denoising Diffusion Model for Fluid Field Prediction",
    "abstract": " Title: A Denoising Diffusion Model for Fluid Field Prediction ",
    "url": "https://arxiv.org/abs/2301.11661",
    "authors": [
      "Gefan Yang",
      "Stefan Sommer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2301.11806",
    "title": "PCV: A Point Cloud-Based Network Verifier",
    "abstract": " Comments: 11 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2301.11806",
    "authors": [
      "Arup Kumar Sarker",
      "Farzana Yasmin Ahmad",
      "Matthew B. Dwyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.11849",
    "title": "Complexity of equilibria in binary public goods games on undirected  graphs",
    "abstract": " Comments: Added reference to concurrent work arXiv:2301.11580 ",
    "url": "https://arxiv.org/abs/2301.11849",
    "authors": [
      "Max Klimm",
      "Maximilian J. Stahlberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ]
  }
]