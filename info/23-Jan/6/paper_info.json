[
  {
    "id": "arXiv:2301.01801",
    "title": "Network Utility Maximization with Unknown Utility Functions: A  Distributed, Data-Driven Bilevel Optimization Approach",
    "abstract": "Fair resource allocation is one of the most important topics in communication networks. Existing solutions almost exclusively assume each user utility function is known and concave. This paper seeks to answer the following question: how to allocate resources when utility functions are unknown, even to the users? This answer has become increasingly important in the next-generation AI-aware communication networks where the user utilities are complex and their closed-forms are hard to obtain. In this paper, we provide a new solution using a distributed and data-driven bilevel optimization approach, where the lower level is a distributed network utility maximization (NUM) algorithm with concave surrogate utility functions, and the upper level is a data-driven learning algorithm to find the best surrogate utility functions that maximize the sum of true network utility. The proposed algorithm learns from data samples (utility values or gradient values) to autotune the surrogate utility functions to maximize the true network utility, so works for unknown utility functions. For the general network, we establish the nonasymptotic convergence rate of the proposed algorithm with nonconcave utility functions. The simulations validate our theoretical results and demonstrate the great effectiveness of the proposed method in a real-world network. ",
    "url": "https://arxiv.org/abs/2301.01801",
    "authors": [
      "Kaiyi Ji",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.01802",
    "title": "MonoEdge: Monocular 3D Object Detection Using Local Perspectives",
    "abstract": "We propose a novel approach for monocular 3D object detection by leveraging local perspective effects of each object. While the global perspective effect shown as size and position variations has been exploited for monocular 3D detection extensively, the local perspectives has long been overlooked. We design a local perspective module to regress a newly defined variable named keyedge-ratios as the parameterization of the local shape distortion to account for the local perspective, and derive the object depth and yaw angle from it. Theoretically, this module does not rely on the pixel-wise size or position in the image of the objects, therefore independent of the camera intrinsic parameters. By plugging this module in existing monocular 3D object detection frameworks, we incorporate the local perspective distortion with global perspective effect for monocular 3D reasoning, and we demonstrate the effectiveness and superior performance over strong baseline methods in multiple datasets. ",
    "url": "https://arxiv.org/abs/2301.01802",
    "authors": [
      "Minghan Zhu",
      "Lingting Ge",
      "Panqu Wang",
      "Huei Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.01815",
    "title": "Multi-Task Learning for Budbreak Prediction",
    "abstract": "Grapevine budbreak is a key phenological stage of seasonal development, which serves as a signal for the onset of active growth. This is also when grape plants are most vulnerable to damage from freezing temperatures. Hence, it is important for winegrowers to anticipate the day of budbreak occurrence to protect their vineyards from late spring frost events. This work investigates deep learning for budbreak prediction using data collected for multiple grape cultivars. While some cultivars have over 30 seasons of data others have as little as 4 seasons, which can adversely impact prediction accuracy. To address this issue, we investigate multi-task learning, which combines data across all cultivars to make predictions for individual cultivars. Our main result shows that several variants of multi-task learning are all able to significantly improve prediction accuracy compared to learning for each cultivar independently. ",
    "url": "https://arxiv.org/abs/2301.01815",
    "authors": [
      "Aseem Saxena",
      "Paola Pesantez-Cabrera",
      "Rohan Ballapragada",
      "Markus Keller",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01817",
    "title": "Evaluation of Induced Expert Knowledge in Causal Structure Learning by  NOTEARS",
    "abstract": "Causal modeling provides us with powerful counterfactual reasoning and interventional mechanism to generate predictions and reason under various what-if scenarios. However, causal discovery using observation data remains a nontrivial task due to unobserved confounding factors, finite sampling, and changes in the data distribution. These can lead to spurious cause-effect relationships. To mitigate these challenges in practice, researchers augment causal learning with known causal relations. The goal of the paper is to study the impact of expert knowledge on causal relations in the form of additional constraints used in the formulation of the nonparametric NOTEARS. We provide a comprehensive set of comparative analyses of biasing the model using different types of knowledge. We found that (i) knowledge that corrects the mistakes of the NOTEARS model can lead to statistically significant improvements, (ii) constraints on active edges have a larger positive impact on causal discovery than inactive edges, and surprisingly, (iii) the induced knowledge does not correct on average more incorrect active and/or inactive edges than expected. We also demonstrate the behavior of the model and the effectiveness of domain knowledge on a real-world dataset. ",
    "url": "https://arxiv.org/abs/2301.01817",
    "authors": [
      "Jawad Chowdhury",
      "Rezaur Rashid",
      "Gabriel Terejanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.01824",
    "title": "Privacy and Efficiency of Communications in Federated Split Learning",
    "abstract": "Everyday, large amounts of sensitive data \\sai{is} distributed across mobile phones, wearable devices, and other sensors. Traditionally, these enormous datasets have been processed on a single system, with complex models being trained to make valuable predictions. Distributed machine learning techniques such as Federated and Split Learning have recently been developed to protect user \\sai{data and} privacy better while ensuring high performance. Both of these distributed learning architectures have advantages and disadvantages. In this paper, we examine these tradeoffs and suggest a new hybrid Federated Split Learning architecture that combines the efficiency and privacy benefits of both. Our evaluation demonstrates how our hybrid Federated Split Learning approach can lower the amount of processing power required by each client running a distributed learning system, reduce training and inference time while keeping a similar accuracy. We also discuss the resiliency of our approach to deep learning privacy inference attacks and compare our solution to other recently proposed benchmarks. ",
    "url": "https://arxiv.org/abs/2301.01824",
    "authors": [
      "Zongshun Zhang",
      "Andrea Pinto",
      "Valeria Turina",
      "Flavio Esposito",
      "Ibrahim Matta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.01832",
    "title": "Availability Adversarial Attack and Countermeasures for Deep  Learning-based Load Forecasting",
    "abstract": "The forecast of electrical loads is essential for the planning and operation of the power system. Recently, advances in deep learning have enabled more accurate forecasts. However, deep neural networks are prone to adversarial attacks. Although most of the literature focuses on integrity-based attacks, this paper proposes availability-based adversarial attacks, which can be more easily implemented by attackers. For each forecast instance, the availability attack position is optimally solved by mixed-integer reformulation of the artificial neural network. To tackle this attack, an adversarial training algorithm is proposed. In simulation, a realistic load forecasting dataset is considered and the attack performance is compared to the integrity-based attack. Meanwhile, the adversarial training algorithm is shown to significantly improve robustness against availability attacks. All codes are available at https://github.com/xuwkk/AAA_Load_Forecast. ",
    "url": "https://arxiv.org/abs/2301.01832",
    "authors": [
      "Wangkun Xu",
      "Fei Teng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.01849",
    "title": "NODAGS-Flow: Nonlinear Cyclic Causal Structure Learning",
    "abstract": "Learning causal relationships between variables is a well-studied problem in statistics, with many important applications in science. However, modeling real-world systems remain challenging, as most existing algorithms assume that the underlying causal graph is acyclic. While this is a convenient framework for developing theoretical developments about causal reasoning and inference, the underlying modeling assumption is likely to be violated in real systems, because feedback loops are common (e.g., in biological systems). Although a few methods search for cyclic causal models, they usually rely on some form of linearity, which is also limiting, or lack a clear underlying probabilistic model. In this work, we propose a novel framework for learning nonlinear cyclic causal graphical models from interventional data, called NODAGS-Flow. We perform inference via direct likelihood optimization, employing techniques from residual normalizing flows for likelihood estimation. Through synthetic experiments and an application to single-cell high-content perturbation screening data, we show significant performance improvements with our approach compared to state-of-the-art methods with respect to structure recovery and predictive performance. ",
    "url": "https://arxiv.org/abs/2301.01849",
    "authors": [
      "Muralikrishnna G. Sethuraman",
      "Romain Lopez",
      "Rahul Mohan",
      "Faramarz Fekri",
      "Tommaso Biancalani",
      "Jan-Christian H\u00fctter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.01867",
    "title": "Unsupervised High Impedance Fault Detection Using Autoencoder and  Principal Component Analysis",
    "abstract": "Detection of high impedance faults (HIF) has been one of the biggest challenges in the power distribution network. The low current magnitude and diverse characteristics of HIFs make them difficult to be detected by over-current relays. Recently, data-driven methods based on machine learning models are gaining popularity in HIF detection due to their capability to learn complex patterns from data. Most machine learning-based detection methods adopt supervised learning techniques to distinguish HIFs from normal load conditions by performing classifications, which rely on a large amount of data collected during HIF. However, measurements of HIF are difficult to acquire in the real world. As a result, the reliability and generalization of the classification methods are limited when the load profiles and faults are not present in the training data. Consequently, this paper proposes an unsupervised HIF detection framework using the autoencoder and principal component analysis-based monitoring techniques. The proposed fault detection method detects the HIF by monitoring the changes in correlation structure within the current waveforms that are different from the normal loads. The performance of the proposed HIF detection method is tested using real data collected from a 4.16 kV distribution system and compared with results from a commercially available solution for HIF detection. The numerical results demonstrate that the proposed method outperforms the commercially available HIF detection technique while maintaining high security by not falsely detecting during load conditions. ",
    "url": "https://arxiv.org/abs/2301.01867",
    "authors": [
      "Yingxiang Liu",
      "Mohammad Razeghi-Jahromi",
      "James Stoupis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.01877",
    "title": "When Cyber Aggression Prediction Meets BERT on Social Media",
    "abstract": "Increasingly, cyber aggression becomes the prevalent phenomenon that erodes the social media environment. However, due to subjective and expense, the traditional self-reporting questionnaire is hard to be employed in the current cyber area. In this study, we put forward the prediction model for cyber aggression based on the cutting-edge deep learning algorithm. Building on 320 active Weibo users' social media activities, we construct basic, dynamic, and content features. We elaborate cyber aggression on three dimensions: social exclusion, malicious humour, and guilt induction. We then build the prediction model combined with pretrained BERT model. The empirical evidence shows outperformance and supports a stronger prediction with the BERT model than traditional machine learning models without extra pretrained information. This study offers a solid theoretical model for cyber aggression prediction. Furthermore, this study contributes to cyber aggression behaviors' probing and social media platforms' organization. ",
    "url": "https://arxiv.org/abs/2301.01877",
    "authors": [
      "Zhenkun Zhou",
      "Mengli Yu",
      "Yuxin He",
      "Xingyu Peng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.01905",
    "title": "FireFly: A High-Throughput and Reconfigurable Hardware Accelerator for  Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) have been widely used due to their strong biological interpretability and high energy efficiency. With the introduction of the backpropagation algorithm and surrogate gradient, the structure of spiking neural networks has become more complex, and the performance gap with artificial neural networks has gradually decreased. However, most SNN hardware implementations for field-programmable gate arrays (FPGAs) cannot meet arithmetic or memory efficiency requirements, which significantly restricts the development of SNNs. They do not delve into the arithmetic operations between the binary spikes and synaptic weights or assume unlimited on-chip RAM resources by using overly expensive devices on small tasks. To improve arithmetic efficiency, we analyze the neural dynamics of spiking neurons, generalize the SNN arithmetic operation to the multiplex-accumulate operation, and propose a high-performance implementation of such operation by utilizing the DSP48E2 hard block in Xilinx Ultrascale FPGAs. To improve memory efficiency, we design a memory system to enable efficient synaptic weights and membrane voltage memory access with reasonable on-chip RAM consumption. Combining the above two improvements, we propose an FPGA accelerator that can process spikes generated by the firing neuron on-the-fly (FireFly). FireFly is implemented on several FPGA edge devices with limited resources but still guarantees a peak performance of 5.53TSOP/s at 300MHz. As a lightweight accelerator, FireFly achieves the highest computational density efficiency compared with existing research using large FPGA devices. ",
    "url": "https://arxiv.org/abs/2301.01905",
    "authors": [
      "Jindong Li",
      "Guobin Shen",
      "Dongcheng Zhao",
      "Qian Zhang",
      "Zeng Yi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2301.01917",
    "title": "Small Moving Object Detection Algorithm Based on Motion Information",
    "abstract": "A Samll Moving Object Detection algorithm Based on Motion Information (SMOD-BMI) was proposed to detect small moving objects with low Signal-to-Noise Ratio (SNR). Firstly, To capture suspicious moving objects, a ConvLSTM-SCM-PAN model structure was designed, in which the Convolutional Long and Short Time Memory (ConvLSTM) network fused temporal and spatial information, the Selective Concatenate Module (SCM) was selected to solve the problem of channel unbalance during feature fusion, and the Path Aggregation Network (PAN) located the suspicious moving objects. Then, an object tracking algorithm is used to track suspicious moving objects and calculate their Motion Range (MR). At the same time, according to the moving speed of the suspicious moving objects, the size of their MR is adjusted adaptively (To be specific, if the objects move slowly, we expand their MR according their speed to ensure the contextual environment information) to obtain their Adaptive Candidate Motion Range (ACMR), so as to ensure that the SNR of the moving object is improved while the necessary context information is retained adaptively. Finally, a LightWeight SCM U-Shape Net (LW-SCM-USN) based on ACMR with a SCM module is designed to classify and locate small moving objects accurately and quickly. In this paper, the moving bird in surveillance video is used as the experimental dataset to verify the performance of the algorithm. The experimental results show that the proposed small moving object detection method based on motion information can effectively reduce the missing rate and false detection rate, and its performance is better than the existing moving small object detection method of SOTA. ",
    "url": "https://arxiv.org/abs/2301.01917",
    "authors": [
      "Ziwei Sun",
      "Zexi Hua",
      "Hengcao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01918",
    "title": "Plant species richness prediction from DESIS hyperspectral data: A  comparison study on feature extraction procedures and regression models",
    "abstract": "The diversity of terrestrial vascular plants plays a key role in maintaining the stability and productivity of ecosystems. Monitoring species compositional diversity across large spatial scales is challenging and time consuming. The advanced spectral and spatial specification of the recently launched DESIS (the DLR Earth Sensing Imaging Spectrometer) instrument provides a unique opportunity to test the potential for monitoring plant species diversity with spaceborne hyperspectral data. This study provides a quantitative assessment on the ability of DESIS hyperspectral data for predicting plant species richness in two different habitat types in southeast Australia. Spectral features were first extracted from the DESIS spectra, then regressed against on-ground estimates of plant species richness, with a two-fold cross validation scheme to assess the predictive performance. We tested and compared the effectiveness of Principal Component Analysis (PCA), Canonical Correlation Analysis (CCA), and Partial Least Squares analysis (PLS) for feature extraction, and Kernel Ridge Regression (KRR), Gaussian Process Regression (GPR), Random Forest Regression (RFR) for species richness prediction. The best prediction results were r=0.76 and RMSE=5.89 for the Southern Tablelands region, and r=0.68 and RMSE=5.95 for the Snowy Mountains region. Relative importance analysis for the DESIS spectral bands showed that the red-edge, red, and blue spectral regions were more important for predicting plant species richness than the green bands and the near-infrared bands beyond red-edge. We also found that the DESIS hyperspectral data performed better than Sentinel-2 multispectral data in the prediction of plant species richness. Our results provide a quantitative reference for future studies exploring the potential of spaceborne hyperspectral data for plant biodiversity mapping. ",
    "url": "https://arxiv.org/abs/2301.01918",
    "authors": [
      "Yiqing Guo",
      "Karel Mokany",
      "Cindy Ong",
      "Peyman Moghadam",
      "Simon Ferrier",
      "Shaun R. Levick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2301.01931",
    "title": "Reduced Deep Convolutional Activation Features (R-DeCAF) in  Histopathology Images to Improve the Classification Performance for Breast  Cancer Diagnosis",
    "abstract": "Breast cancer is the second most common cancer among women worldwide. Diagnosis of breast cancer by the pathologists is a time-consuming procedure and subjective. Computer aided diagnosis frameworks are utilized to relieve pathologist workload by classifying the data automatically, in which deep convolutional neural networks (CNNs) are effective solutions. The features extracted from activation layer of pre-trained CNNs are called deep convolutional activation features (DeCAF). In this paper, we have analyzed that all DeCAF features are not necessarily led to a higher accuracy in the classification task and dimension reduction plays an important role. Therefore, different dimension reduction methods are applied to achieve an effective combination of features by capturing the essence of DeCAF features. To this purpose, we have proposed reduced deep convolutional activation features (R-DeCAF). In this framework, pre-trained CNNs such as AlexNet, VGG-16 and VGG-19 are utilized in transfer learning mode as feature extractors. DeCAF features are extracted from the first fully connected layer of the mentioned CNNs and support vector machine has been used for binary classification. Among linear and nonlinear dimensionality reduction algorithms, linear approaches such as principal component analysis (PCA) represent a better combination among deep features and lead to a higher accuracy in the classification task using small number of features considering specific amount of cumulative explained variance (CEV) of features. The proposed method is validated using experimental BreakHis dataset. Comprehensive results show improvement in the classification accuracy up to 4.3% with less computational time. Best achieved accuracy is 91.13% for 400x data with feature vector size (FVS) of 23 and CEV equals to 0.15 using pre-trained AlexNet as feature extractor and PCA as feature reduction algorithm. ",
    "url": "https://arxiv.org/abs/2301.01931",
    "authors": [
      "Bahareh Morovati",
      "Reza Lashgari",
      "Mojtaba Hajihasani",
      "Hasti Shabani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.01932",
    "title": "PA-GM: Position-Aware Learning of Embedding Networks for Deep Graph  Matching",
    "abstract": "Graph matching can be formalized as a combinatorial optimization problem, where there are corresponding relationships between pairs of nodes that can be represented as edges. This problem becomes challenging when there are potential ambiguities present due to nodes and edges with high similarity, and there is a need to find accurate results for similar content matching. In this paper, we introduce a novel end-to-end neural network that can map the linear assignment problem into a high-dimensional space augmented with node-level relative position information, which is crucial for improving the method's performance for similar content matching. Our model constructs the anchor set for the relative position of nodes and then aggregates the feature information of the target node and each anchor node based on a measure of relative position. It then learns the node feature representation by integrating the topological structure and the relative position information, thus realizing the linear assignment between the two graphs. To verify the effectiveness and generalizability of our method, we conduct graph matching experiments, including cross-category matching, on different real-world datasets. Comparisons with different baselines demonstrate the superiority of our method. Our source code is available under https://github.com/anonymous. ",
    "url": "https://arxiv.org/abs/2301.01932",
    "authors": [
      "Dongdong Chen",
      "Yuxing Dai",
      "Lichi Zhang",
      "Zhihong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.01947",
    "title": "StitchNet: Composing Neural Networks from Pre-Trained Fragments",
    "abstract": "We propose StitchNet, a novel neural network creation paradigm that stitches together fragments (one or more consecutive network layers) from multiple pre-trained neural networks. StitchNet allows the creation of high-performing neural networks without the large compute and data requirements needed under traditional model creation processes via backpropagation training. We leverage Centered Kernel Alignment (CKA) as a compatibility measure to efficiently guide the selection of these fragments in composing a network for a given task tailored to specific accuracy needs and computing resource constraints. We then show that these fragments can be stitched together to create neural networks with comparable accuracy to traditionally trained networks at a fraction of computing resource and data requirements. Finally, we explore a novel on-the-fly personalized model creation and inference application enabled by this new paradigm. ",
    "url": "https://arxiv.org/abs/2301.01947",
    "authors": [
      "Surat Teerapittayanon",
      "Marcus Comiter",
      "Brad McDanel",
      "H.T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01949",
    "title": "SPRING: Situated Conversation Agent Pretrained with Multimodal Questions  from Incremental Layout Graph",
    "abstract": "Existing multimodal conversation agents have shown impressive abilities to locate absolute positions or retrieve attributes in simple scenarios, but they fail to perform well when complex relative positions and information alignments are involved, which poses a bottleneck in response quality. In this paper, we propose a Situated Conversation Agent Petrained with Multimodal Questions from INcremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios. Specifically, we design two types of Multimodal Question Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during pretraining are generated from novel Incremental Layout Graphs (ILG). QA pair difficulty labels automatically annotated by ILG are used to promote MQA-based Curriculum Learning. Experimental results verify the SPRING's effectiveness, showing that it significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets. ",
    "url": "https://arxiv.org/abs/2301.01949",
    "authors": [
      "Yuxing Long",
      "Binyuan Hui",
      "Fulong Ye",
      "Yanyang Li",
      "Zhuoxin Han",
      "Caixia Yuan",
      "Yongbin Li",
      "Xiaojie Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.01967",
    "title": "A Survey of Code-switching: Linguistic and Social Perspectives for  Language Technologies",
    "abstract": "The analysis of data in which multiple languages are represented has gained popularity among computational linguists in recent years. So far, much of this research focuses mainly on the improvement of computational methods and largely ignores linguistic and social aspects of C-S discussed across a wide range of languages within the long-established literature in linguistics. To fill this gap, we offer a survey of code-switching (C-S) covering the literature in linguistics with a reflection on the key issues in language technologies. From the linguistic perspective, we provide an overview of structural and functional patterns of C-S focusing on the literature from European and Indian contexts as highly multilingual areas. From the language technologies perspective, we discuss how massive language models fail to represent diverse C-S types due to lack of appropriate training data, lack of robust evaluation benchmarks for C-S (across multilingual situations and types of C-S) and lack of end-to-end systems that cover sociolinguistic aspects of C-S as well. Our survey will be a step towards an outcome of mutual benefit for computational scientists and linguists with a shared interest in multilingualism and C-S. ",
    "url": "https://arxiv.org/abs/2301.01967",
    "authors": [
      "A.Seza Do\u011fru\u00f6z",
      "Sunayana Sitaram",
      "Barbara E. Bullock",
      "Almeida Jacqueline Toribio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.01970",
    "title": "CAT: LoCalization and IdentificAtion Cascade Detection Transformer for  Open-World Object Detection",
    "abstract": "Open-world object detection (OWOD), as a more general and challenging goal, requires the model trained from data on known objects to detect both known and unknown objects and incrementally learn to identify these unknown objects. The existing works which employ standard detection framework and fixed pseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion of detecting unknown objects substantially reduces the model's ability to detect known ones. (ii) The PLM does not adequately utilize the priori knowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee that the model is trained in the right direction. We observe that humans subconsciously prefer to focus on all foreground objects and then identify each one in detail, rather than localize and identify a single object simultaneously, for alleviating the confusion. This motivates us to propose a novel solution called CAT: LoCalization and IdentificAtion Cascade Detection Transformer which decouples the detection process via the shared decoder in the cascade decoding way. In the meanwhile, we propose the self-adaptive pseudo-labelling mechanism which combines the model-driven with input-driven PLM and self-adaptively generates robust pseudo-labels for unknown objects, significantly improving the ability of CAT to retrieve unknown objects. Comprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL VOC, show that our model outperforms the state-of-the-art in terms of all metrics in the task of OWOD, incremental object detection (IOD) and open-set detection. ",
    "url": "https://arxiv.org/abs/2301.01970",
    "authors": [
      "Shuailei Ma",
      "Yuefeng Wang",
      "Jiaqi Fan",
      "Ying Wei",
      "Thomas H. Li",
      "Hongli Liu",
      "Fanbing Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01984",
    "title": "The Evolutionary Computation Methods No One Should Use",
    "abstract": "The center-bias (or zero-bias) operator has recently been identified as one of the problems plaguing the benchmarking of evolutionary computation methods. This operator lets the methods that utilize it easily optimize functions that have their respective optima in the center of the feasible set. In this paper, we describe a simple procedure that can be used to identify methods that incorporate a center-bias operator and use it to investigate 90 evolutionary computation methods that were published between 1987 and 2022. We show that more than half (47 out of the 90) of the considered methods have the center-bias problem. We also show that the center-bias is a relatively new phenomenon (with the first identified method being from 2012), but its inclusion has become extremely prevalent in the last few years. Lastly, we briefly discuss the possible root causes of this issue. ",
    "url": "https://arxiv.org/abs/2301.01984",
    "authors": [
      "Jakub Kudela"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.01987",
    "title": "Energy Efficient Semantic Communication over Wireless Networks with Rate  Splitting",
    "abstract": "In this paper, the problem of wireless resource allocation and semantic information extraction for energy efficient semantic communications over wireless networks with rate splitting is investigated. In the considered model, a base station (BS) first extracts semantic information from its large-scale data, and then transmits the small-sized semantic information to each user which recovers the original data based on its local common knowledge. At the BS side, the probability graph is used to extract multi-level semantic information. In the downlink transmission, a rate splitting scheme is adopted, while the private small-sized semantic information is transmitted through private message and the common knowledge is transmitted through common message. Due to limited wireless resource, both computation energy and transmission energy are considered. This joint computation and communication problem is formulated as an optimization problem aiming to minimize the total communication and computation energy consumption of the network under computation, latency, and transmit power constraints. To solve this problem, an alternating algorithm is proposed where the closed-form solutions for semantic information extraction ratio and computation frequency are obtained at each step. Numerical results verify the effectiveness of the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2301.01987",
    "authors": [
      "Zhaohui Yang",
      "Mingzhe Chen",
      "Zhaoyang Zhang",
      "Chongwen Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.02009",
    "title": "Learning by Sorting: Self-supervised Learning with Group Ordering  Constraints",
    "abstract": "Contrastive learning has become a prominent ingredient in learning representations from unlabeled data. However, existing methods primarily consider pairwise relations. This paper proposes a new approach towards self-supervised contrastive learning based on Group Ordering Constraints (GroCo). The GroCo loss leverages the idea of comparing groups of positive and negative images instead of pairs of images. Building on the recent success of differentiable sorting algorithms, group ordering constraints enforce that the distances of all positive samples (a positive group) are smaller than the distances of all negative images (a negative group); thus, enforcing positive samples to gather around an anchor. This leads to a more holistic optimization of the local neighborhoods. We evaluate the proposed setting on a suite of competitive self-supervised learning benchmarks and show that our method is not only competitive to current methods in the case of linear probing but also leads to higher consistency in local representations, as can be seen from a significantly improved k-NN performance across all benchmarks. ",
    "url": "https://arxiv.org/abs/2301.02009",
    "authors": [
      "Nina Shvetsova",
      "Felix Petersen",
      "Anna Kukleva",
      "Bernt Schiele",
      "Hilde Kuehne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02031",
    "title": "DLGSANet: Lightweight Dynamic Local and Global Self-Attention Networks  for Image Super-Resolution",
    "abstract": "We propose an effective lightweight dynamic local and global self-attention network (DLGSANet) to solve image super-resolution. Our method explores the properties of Transformers while having low computational costs. Motivated by the network designs of Transformers, we develop a simple yet effective multi-head dynamic local self-attention (MHDLSA) module to extract local features efficiently. In addition, we note that existing Transformers usually explore all similarities of the tokens between the queries and keys for the feature aggregation. However, not all the tokens from the queries are relevant to those in keys, using all the similarities does not effectively facilitate the high-resolution image reconstruction. To overcome this problem, we develop a sparse global self-attention (SparseGSA) module to select the most useful similarity values so that the most useful global features can be better utilized for the high-resolution image reconstruction. We develop a hybrid dynamic-Transformer block(HDTB) that integrates the MHDLSA and SparseGSA for both local and global feature exploration. To ease the network training, we formulate the HDTBs into a residual hybrid dynamic-Transformer group (RHDTG). By embedding the RHDTGs into an end-to-end trainable network, we show that our proposed method has fewer network parameters and lower computational costs while achieving competitive performance against state-of-the-art ones in terms of accuracy. More information is available at https://neonleexiang.github.io/DLGSANet/ ",
    "url": "https://arxiv.org/abs/2301.02031",
    "authors": [
      "Xiang Li",
      "Jinshan Pan",
      "Jinhui Tang",
      "Jiangxin Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02039",
    "title": "Randomized Message-Interception Smoothing: Gray-box Certificates for  Graph Neural Networks",
    "abstract": "Randomized smoothing is one of the most promising frameworks for certifying the adversarial robustness of machine learning models, including Graph Neural Networks (GNNs). Yet, existing randomized smoothing certificates for GNNs are overly pessimistic since they treat the model as a black box, ignoring the underlying architecture. To remedy this, we propose novel gray-box certificates that exploit the message-passing principle of GNNs: We randomly intercept messages and carefully analyze the probability that messages from adversarially controlled nodes reach their target nodes. Compared to existing certificates, we certify robustness to much stronger adversaries that control entire nodes in the graph and can arbitrarily manipulate node features. Our certificates provide stronger guarantees for attacks at larger distances, as messages from farther-away nodes are more likely to get intercepted. We demonstrate the effectiveness of our method on various models and datasets. Since our gray-box certificates consider the underlying graph structure, we can significantly improve certifiable robustness by applying graph sparsification. ",
    "url": "https://arxiv.org/abs/2301.02039",
    "authors": [
      "Yan Scholten",
      "Jan Schuchardt",
      "Simon Geisler",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02079",
    "title": "Explain to Me: Towards Understanding Privacy Decisions",
    "abstract": "Privacy assistants help users manage their privacy online. Their tasks could vary from detecting privacy violations to recommending sharing actions for content that the user intends to share. Recent work on these tasks are promising and show that privacy assistants can successfully tackle them. However, for such privacy assistants to be employed by users, it is important that these assistants can explain their decisions to users. Accordingly, this paper develops a methodology to create explanations of privacy. The methodology is based on identifying important topics in a domain of interest, providing explanation schemes for decisions, and generating them automatically. We apply our proposed methodology on a real-world privacy data set, which contains images labeled as private or public to explain the labels. We evaluate our approach on a user study that depicts what factors are influential for users to find explanations useful. ",
    "url": "https://arxiv.org/abs/2301.02079",
    "authors": [
      "Gonul Ayci",
      "P\u0131nar Yolum",
      "Arzucan \u00d6zg\u00fcr",
      "Murat \u015eensoy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.02099",
    "title": "Learning Goal-Conditioned Policies Offline with Self-Supervised Reward  Shaping",
    "abstract": "Developing agents that can execute multiple skills by learning from pre-collected datasets is an important problem in robotics, where online interaction with the environment is extremely time-consuming. Moreover, manually designing reward functions for every single desired skill is prohibitive. Prior works targeted these challenges by learning goal-conditioned policies from offline datasets without manually specified rewards, through hindsight relabelling. These methods suffer from the issue of sparsity of rewards, and fail at long-horizon tasks. In this work, we propose a novel self-supervised learning phase on the pre-collected dataset to understand the structure and the dynamics of the model, and shape a dense reward function for learning policies offline. We evaluate our method on three continuous control tasks, and show that our model significantly outperforms existing approaches, especially on tasks that involve long-term planning. ",
    "url": "https://arxiv.org/abs/2301.02099",
    "authors": [
      "Lina Mezghani",
      "Sainbayar Sukhbaatar",
      "Piotr Bojanowski",
      "Alessandro Lazaric",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02111",
    "title": "Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers",
    "abstract": "We introduce a language modeling approach for text to speech synthesis (TTS). Specifically, we train a neural codec language model (called Vall-E) using discrete codes derived from an off-the-shelf neural audio codec model, and regard TTS as a conditional language modeling task rather than continuous signal regression as in previous work. During the pre-training stage, we scale up the TTS training data to 60K hours of English speech which is hundreds of times larger than existing systems. Vall-E emerges in-context learning capabilities and can be used to synthesize high-quality personalized speech with only a 3-second enrolled recording of an unseen speaker as an acoustic prompt. Experiment results show that Vall-E significantly outperforms the state-of-the-art zero-shot TTS system in terms of speech naturalness and speaker similarity. In addition, we find Vall-E could preserve the speaker's emotion and acoustic environment of the acoustic prompt in synthesis. See https://aka.ms/valle for demos of our work. ",
    "url": "https://arxiv.org/abs/2301.02111",
    "authors": [
      "Chengyi Wang",
      "Sanyuan Chen",
      "Yu Wu",
      "Ziqiang Zhang",
      "Long Zhou",
      "Shujie Liu",
      "Zhuo Chen",
      "Yanqing Liu",
      "Huaming Wang",
      "Jinyu Li",
      "Lei He",
      "Sheng Zhao",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.02120",
    "title": "Reprogramming Pretrained Language Models for Protein Sequence  Representation Learning",
    "abstract": "Machine Learning-guided solutions for protein learning tasks have made significant headway in recent years. However, success in scientific discovery tasks is limited by the accessibility of well-defined and labeled in-domain data. To tackle the low-data constraint, recent adaptions of deep learning models pretrained on millions of protein sequences have shown promise; however, the construction of such domain-specific large-scale model is computationally expensive. Here, we propose Representation Learning via Dictionary Learning (R2DL), an end-to-end representation learning framework in which we reprogram deep models for alternate-domain tasks that can perform well on protein property prediction with significantly fewer training samples. R2DL reprograms a pretrained English language model to learn the embeddings of protein sequences, by learning a sparse linear mapping between English and protein sequence vocabulary embeddings. Our model can attain better accuracy and significantly improve the data efficiency by up to $10^5$ times over the baselines set by pretrained and standard supervised methods. To this end, we reprogram an off-the-shelf pre-trained English language transformer and benchmark it on a set of protein physicochemical prediction tasks (secondary structure, stability, homology, stability) as well as on a biomedically relevant set of protein function prediction tasks (antimicrobial, toxicity, antibody affinity). ",
    "url": "https://arxiv.org/abs/2301.02120",
    "authors": [
      "Ria Vinod",
      "Pin-Yu Chen",
      "Payel Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2301.02126",
    "title": "CRADL: Contrastive Representations for Unsupervised Anomaly Detection  and Localization",
    "abstract": "Unsupervised anomaly detection in medical imaging aims to detect and localize arbitrary anomalies without requiring annotated anomalous data during training. Often, this is achieved by learning a data distribution of normal samples and detecting anomalies as regions in the image which deviate from this distribution. Most current state-of-the-art methods use latent variable generative models operating directly on the images. However, generative models have been shown to mostly capture low-level features, s.a. pixel-intensities, instead of rich semantic features, which also applies to their representations. We circumvent this problem by proposing CRADL whose core idea is to model the distribution of normal samples directly in the low-dimensional representation space of an encoder trained with a contrastive pretext-task. By utilizing the representations of contrastive learning, we aim to fix the over-fixation on low-level features and learn more semantic-rich representations. Our experiments on anomaly detection and localization tasks using three distinct evaluation datasets show that 1) contrastive representations are superior to representations of generative latent variable models and 2) the CRADL framework shows competitive or superior performance to state-of-the-art. ",
    "url": "https://arxiv.org/abs/2301.02126",
    "authors": [
      "Carsten T. L\u00fcth",
      "David Zimmerer",
      "Gregor Koehler",
      "Paul F. Jaeger",
      "Fabian Isensee",
      "Jens Petersen",
      "Klaus H. Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02129",
    "title": "Algorithms and Complexity for Computing Nash Equilibria in Adversarial  Team Games",
    "abstract": "Adversarial team games model multiplayer strategic interactions in which a team of identically-interested players is competing against an adversarial player in a zero-sum game. Such games capture many well-studied settings in game theory, such as congestion games, but go well-beyond to environments wherein the cooperation of one team -- in the absence of explicit communication -- is obstructed by competing entities; the latter setting remains poorly understood despite its numerous applications. Since the seminal work of Von Stengel and Koller (GEB `97), different solution concepts have received attention from an algorithmic standpoint. Yet, the complexity of the standard Nash equilibrium has remained open. In this paper, we settle this question by showing that computing a Nash equilibrium in adversarial team games belongs to the class continuous local search (CLS), thereby establishing CLS-completeness by virtue of the recent CLS-hardness result of Rubinstein and Babichenko (STOC `21) in potential games. To do so, we leverage linear programming duality to prove that any $\\epsilon$-approximate stationary strategy for the team can be extended in polynomial time to an $O(\\epsilon)$-approximate Nash equilibrium, where the $O(\\cdot)$ notation suppresses polynomial factors in the description of the game. As a consequence, we show that the Moreau envelop of a suitable best response function acts as a potential under certain natural gradient-based dynamics. ",
    "url": "https://arxiv.org/abs/2301.02129",
    "authors": [
      "Ioannis Anagnostides",
      "Fivos Kalogiannis",
      "Ioannis Panageas",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
      "Stephen McAleer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.02145",
    "title": "Domain Generalization via Ensemble Stacking for Face Presentation Attack  Detection",
    "abstract": "Face presentation attack detection (PAD) plays a pivotal role in securing face recognition systems against spoofing attacks. Although great progress has been made in designing face PAD methods, developing a model that can generalize well to an unseen test domain remains a significant challenge. Moreover, due to different types of spoofing attacks, creating a dataset with a sufficient number of samples for training deep neural networks is a laborious task. This work addresses these challenges by creating synthetic data and introducing a deep learning-based unified framework for improving the generalization ability of the face PAD. In particular, synthetic data is generated by proposing a video distillation technique that blends a spatiotemporal warped image with a still image based on alpha compositing. Since the proposed synthetic samples can be generated by increasing different alpha weights, we train multiple classifiers by taking the advantage of a specific type of ensemble learning known as a stacked ensemble, where each such classifier becomes an expert in its own domain but a non-expert to others. Motivated by this, a meta-classifier is employed to learn from these experts collaboratively so that when developing an ensemble, they can leverage complementary information from each other to better tackle or be more useful for an unseen target domain. Experimental results using half total error rates (HTERs) on four PAD databases CASIA-MFSD (6.97 %), Replay-Attack (33.49%), MSU-MFSD (4.02%), and OULU-NPU (10.91%)) demonstrate the robustness of the method and open up new possibilities for advancing presentation attack detection using ensemble learning with large-scale synthetic data. ",
    "url": "https://arxiv.org/abs/2301.02145",
    "authors": [
      "Usman Muhammad",
      "Djamila Romaissa Beddiar",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02152",
    "title": "L-HYDRA: Multi-Head Physics-Informed Neural Networks",
    "abstract": "We introduce multi-head neural networks (MH-NNs) to physics-informed machine learning, which is a type of neural networks (NNs) with all nonlinear hidden layers as the body and multiple linear output layers as multi-head. Hence, we construct multi-head physics-informed neural networks (MH-PINNs) as a potent tool for multi-task learning (MTL), generative modeling, and few-shot learning for diverse problems in scientific machine learning (SciML). MH-PINNs connect multiple functions/tasks via a shared body as the basis functions as well as a shared distribution for the head. The former is accomplished by solving multiple tasks with MH-PINNs with each head independently corresponding to each task, while the latter by employing normalizing flows (NFs) for density estimate and generative modeling. To this end, our method is a two-stage method, and both stages can be tackled with standard deep learning tools of NNs, enabling easy implementation in practice. MH-PINNs can be used for various purposes, such as approximating stochastic processes, solving multiple tasks synergistically, providing informative prior knowledge for downstream few-shot learning tasks such as meta-learning and transfer learning, learning representative basis functions, and uncertainty quantification. We demonstrate the effectiveness of MH-PINNs in five benchmarks, investigating also the possibility of synergistic learning in regression analysis. We name the open-source code \"Lernaean Hydra\" (L-HYDRA), since this mythical creature possessed many heads for performing important multiple tasks, as in the proposed method. ",
    "url": "https://arxiv.org/abs/2301.02152",
    "authors": [
      "Zongren Zou",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.02195",
    "title": "Towards Autoformalization of Mathematics and Code Correctness:  Experiments with Elementary Proofs",
    "abstract": "The ever-growing complexity of mathematical proofs makes their manual verification by mathematicians very cognitively demanding. Autoformalization seeks to address this by translating proofs written in natural language into a formal representation that is computer-verifiable via interactive theorem provers. In this paper, we introduce a semantic parsing approach, based on the Universal Transformer architecture, that translates elementary mathematical proofs into an equivalent formalization in the language of the Coq interactive theorem prover. The same architecture is also trained to translate simple imperative code decorated with Hoare triples into formally verifiable proofs of correctness in Coq. Experiments on a limited domain of artificial and human-written proofs show that the models generalize well to intermediate lengths not seen during training and variations in natural language. ",
    "url": "https://arxiv.org/abs/2301.02195",
    "authors": [
      "Garett Cunningham",
      "Razvan C. Bunescu",
      "David Juedes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2301.02239",
    "title": "Robust Dynamic Radiance Fields",
    "abstract": "Dynamic radiance field reconstruction methods aim to model the time-varying structure and appearance of a dynamic scene. Existing methods, however, assume that accurate camera poses can be reliably estimated by Structure from Motion (SfM) algorithms. These methods, thus, are unreliable as SfM algorithms often fail or produce erroneous poses on challenging videos with highly dynamic objects, poorly textured surfaces, and rotating camera motion. We address this robustness issue by jointly estimating the static and dynamic radiance fields along with the camera parameters (poses and focal length). We demonstrate the robustness of our approach via extensive quantitative and qualitative experiments. Our results show favorable performance over the state-of-the-art dynamic view synthesis methods. ",
    "url": "https://arxiv.org/abs/2301.02239",
    "authors": [
      "Yu-Lun Liu",
      "Chen Gao",
      "Andreas Meuleman",
      "Hung-Yu Tseng",
      "Ayush Saraf",
      "Changil Kim",
      "Yung-Yu Chuang",
      "Johannes Kopf",
      "Jia-Bin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01850",
    "title": "Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural  Network",
    "abstract": "We propose to integrate weapon system features (such as weapon system manufacturer, deployment time and location, storage time and location, etc.) into a parameterized Cox-Weibull reliability model via a neural network, like DeepSurv, to improve predictive maintenance. In parallel, we develop an alternative Bayesian model by parameterizing the Weibull parameters with a neural network and employing dropout methods such as Monte-Carlo (MC)-dropout for comparative purposes. Due to data collection procedures in weapon system testing we employ a novel interval-censored log-likelihood which incorporates Monte-Carlo Markov Chain (MCMC) sampling of the Weibull parameters during gradient descent optimization. We compare classification metrics such as receiver operator curve (ROC), area under the curve (AUC), and F scores and show that our model generally outperforms traditional powerful models such as XGBoost as well as the current standard conditional Weibull probability density estimation model. ",
    "url": "https://arxiv.org/abs/2301.01850",
    "authors": [
      "Michael Potter",
      "Benny Cheng"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2301.01885",
    "title": "Enhancement attacks in biomedical machine learning",
    "abstract": "The prevalence of machine learning in biomedical research is rapidly growing, yet the trustworthiness of such research is often overlooked. While some previous works have investigated the ability of adversarial attacks to degrade model performance in medical imaging, the ability to falsely improve performance via recently-developed \"enhancement attacks\" may be a greater threat to biomedical machine learning. In the spirit of developing attacks to better understand trustworthiness, we developed three techniques to drastically enhance prediction performance of classifiers with minimal changes to features, including the enhancement of 1) within-dataset predictions, 2) a particular method over another, and 3) cross-dataset generalization. Our within-dataset enhancement framework falsely improved classifiers' accuracy from 50% to almost 100% while maintaining high feature similarities between original and enhanced data (Pearson's r's>0.99). Similarly, the method-specific enhancement framework was effective in falsely improving the performance of one method over another. For example, a simple neural network outperformed LR by 50% on our enhanced dataset, although no performance differences were present in the original dataset. Crucially, the original and enhanced data were still similar (r=0.95). Finally, we demonstrated that enhancement is not specific to within-dataset predictions but can also be adapted to enhance the generalization accuracy of one dataset to another by up to 38%. Overall, our results suggest that more robust data sharing and provenance tracking pipelines are necessary to maintain data integrity in biomedical machine learning research. ",
    "url": "https://arxiv.org/abs/2301.01885",
    "authors": [
      "Matthew Rosenblatt",
      "Javid Dadashkarimi",
      "Dustin Scheinost"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2301.01911",
    "title": "TractGraphCNN: anatomically informed graph CNN for classification using  diffusion MRI tractography",
    "abstract": "The structure and variability of the brain's connections can be investigated via prediction of non-imaging phenotypes using neural networks. However, known neuroanatomical relationships between input features are generally ignored in network design. We propose TractGraphCNN, a novel, anatomically informed graph CNN framework for machine learning tasks using diffusion MRI tractography. An EdgeConv module aggregates features from anatomically similar white matter connections indicated by graph edges, and an attention module enables interpretation of predictive white matter tracts. Results in a sex prediction testbed task demonstrate strong performance of TractGraphCNN in two large datasets (HCP and ABCD). Graphs informed by white matter geometry demonstrate higher performance than graphs informed by gray matter connectivity. Overall, the bilateral cingulum and left middle longitudinal fasciculus are consistently highly predictive of sex. This work shows the potential of incorporating anatomical information, especially known anatomical similarities between input features, to guide convolutions in neural networks. ",
    "url": "https://arxiv.org/abs/2301.01911",
    "authors": [
      "Yuqian Chen",
      "Fan Zhang",
      "Leo R. Zekelman",
      "Tengfei Xue",
      "Chaoyi Zhang",
      "Yang Song",
      "Nikos Makris",
      "Yogesh Rathi",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.01958",
    "title": "Interaction graphs of isomorphic automata networks I: complete digraph  and minimum in-degree",
    "abstract": "An automata network with $n$ components over a finite alphabet $Q$ of size $q$ is a discrete dynamical system described by the successive iterations of a function $f:Q^n\\to Q^n$. In most applications, the main parameter is the interaction graph of $f$: the digraph with vertex set $[n]$ that contains an arc from $j$ to $i$ if $f_i$ depends on input $j$. What can be said on the set $\\mathbb{G}(f)$ of the interaction graphs of the automata networks isomorphic to $f$? It seems that this simple question has never been studied. Here, we report some basic facts. First, we prove that if $n\\geq 5$ or $q\\geq 3$ and $f$ is neither the identity nor constant, then $\\mathbb{G}(f)$ always contains the complete digraph $K_n$, with $n^2$ arcs. Then, we prove that $\\mathbb{G}(f)$ always contains a digraph whose minimum in-degree is bounded as a function of $q$. Hence, if $n$ is large with respect to $q$, then $\\mathbb{G}(f)$ cannot only contain $K_n$. However, we prove that $\\mathbb{G}(f)$ can contain only dense digraphs, with at least $\\lfloor n^2/4 \\rfloor$ arcs. ",
    "url": "https://arxiv.org/abs/2301.01958",
    "authors": [
      "Florian Bridoux",
      "K\u00e9vin Perrot",
      "Aymeric Picard Marchetto",
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2301.02033",
    "title": "Physics-informed self-supervised deep learning reconstruction for  accelerated first-pass perfusion cardiac MRI",
    "abstract": "First-pass perfusion cardiac magnetic resonance (FPP-CMR) is becoming an essential non-invasive imaging method for detecting deficits of myocardial blood flow, allowing the assessment of coronary heart disease. Nevertheless, acquisitions suffer from relatively low spatial resolution and limited heart coverage. Compressed sensing (CS) methods have been proposed to accelerate FPP-CMR and achieve higher spatial resolution. However, the long reconstruction times have limited the widespread clinical use of CS in FPP-CMR. Deep learning techniques based on supervised learning have emerged as alternatives for speeding up reconstructions. However, these approaches require fully sampled data for training, which is not possible to obtain, particularly high-resolution FPP-CMR images. Here, we propose a physics-informed self-supervised deep learning FPP-CMR reconstruction approach for accelerating FPP-CMR scans and hence facilitate high spatial resolution imaging. The proposed method provides high-quality FPP-CMR images from 10x undersampled data without using fully sampled reference data. ",
    "url": "https://arxiv.org/abs/2301.02033",
    "authors": [
      "Elena Mart\u00edn-Gonz\u00e1lez",
      "Ebraham Alskaf",
      "Amedeo Chiribiri",
      "Pablo Casaseca-de-la-Higuera",
      "Carlos Alberola-L\u00f3pez",
      "Rita G Nunes",
      "Teresa M Correia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2301.02133",
    "title": "A note on highly connected $K_{2,\\ell}$-minor free graphs",
    "abstract": "We show that every $3$-connected $K_{2,\\ell}$-minor free graph with minimum degree at least $4$ has maximum degree at most $7\\ell$. As a consequence, we show that every 3-connected $K_{2,\\ell}$-minor free graph with minimum degree at least $5$ and no twins of degree $5$ has bounded size. Our proofs use Steiner trees and nested cuts; in particular, they do not rely on Ding's characterization of $K_{2,\\ell}$-minor free graphs. ",
    "url": "https://arxiv.org/abs/2301.02133",
    "authors": [
      "Nicolas Bousquet",
      "Th\u00e9o Pierron",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.02166",
    "title": "Identification of lung nodules CT scan using YOLOv5 based on convolution  neural network",
    "abstract": "Purpose: The lung nodules localization in CT scan images is the most difficult task due to the complexity of the arbitrariness of shape, size, and texture of lung nodules. This is a challenge to be faced when coming to developing different solutions to improve detection systems. the deep learning approach showed promising results by using convolutional neural network (CNN), especially for image recognition and it's one of the most used algorithm in computer vision. Approach: we use (CNN) building blocks based on YOLOv5 (you only look once) to learn the features representations for nodule detection labels, in this paper, we introduce a method for detecting lung cancer localization. Chest X-rays and low-dose computed tomography are also possible screening methods, When it comes to recognizing nodules in radiography, computer-aided diagnostic (CAD) system based on (CNN) have demonstrated their worth. One-stage detector YOLOv5 trained on 280 annotated CT SCAN from a public dataset LIDC-IDRI based on segmented pulmonary nodules. Results: we analyze the predictions performance of the lung nodule locations, and demarcates the relevant CT scan regions. In lung nodule localization the accuracy is measured as mean average precision (mAP). the mAP takes into account how well the bounding boxes are fitting the labels as well as how accurate the predicted classes for those bounding boxes, the accuracy we got 92.27%. Conclusion: this study was to identify the nodule that were developing in the lungs of the participants. It was difficult to find information on lung nodules in medical literature. ",
    "url": "https://arxiv.org/abs/2301.02166",
    "authors": [
      "Haytham Al Ewaidat",
      "Youness El Brag"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02178",
    "title": "Sum Labelling Graphs of Maximum Degree Two",
    "abstract": "The concept of sum labelling was introduced in 1990 by Harary. A graph is a sum graph if its vertices can be labelled by distinct positive integers in such a way that two vertices are connected by an edge if and only if the sum of their labels is the label of another vertex in the graph. It is easy to see that every sum graph has at least one isolated vertex, and every graph can be made a sum graph by adding at most $n^2$ isolated vertices to it. The minimum number of isolated vertices that need to be added to a graph to make it a sum graph is called the sum number of the graph. The sum number of several prominent graph classes (e.g., cycles, trees, complete graphs) is already well known. We examine the effect of taking the disjoint union of graphs on the sum number. In particular, we provide a complete characterization of the sum number of graphs of maximum degree two, since every such graph is the disjoint union of paths and cycles. ",
    "url": "https://arxiv.org/abs/2301.02178",
    "authors": [
      "Henning Fernau",
      "Kshitij Gajjar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.02181",
    "title": "A Critical Appraisal of Data Augmentation Methods for Imaging-Based  Medical Diagnosis Applications",
    "abstract": "Current data augmentation techniques and transformations are well suited for improving the size and quality of natural image datasets but are not yet optimized for medical imaging. We hypothesize that sub-optimal data augmentations can easily distort or occlude medical images, leading to false positives or negatives during patient diagnosis, prediction, or therapy/surgery evaluation. In our experimental results, we found that utilizing commonly used intensity-based data augmentation distorts the MRI scans and leads to texture information loss, thus negatively affecting the overall performance of classification. Additionally, we observed that commonly used data augmentation methods cannot be used with a plug-and-play approach in medical imaging, and requires manual tuning and adjustment. ",
    "url": "https://arxiv.org/abs/2301.02181",
    "authors": [
      "Tara M. Pattilachan",
      "Ugur Demir",
      "Elif Keles",
      "Debesh Jha",
      "Derk Klatte",
      "Megan Engels",
      "Sanne Hoogenboom",
      "Candice Bolan",
      "Michael Wallace",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02214",
    "title": "Automatic Sound Event Detection and Classification of Great Ape Calls  Using Neural Networks",
    "abstract": "We present a novel approach to automatically detect and classify great ape calls from continuous raw audio recordings collected during field research. Our method leverages deep pretrained and sequential neural networks, including wav2vec 2.0 and LSTM, and is validated on three data sets from three different great ape lineages (orangutans, chimpanzees, and bonobos). The recordings were collected by different researchers and include different annotation schemes, which our pipeline preprocesses and trains in a uniform fashion. Our results for call detection and classification attain high accuracy. Our method is aimed to be generalizable to other animal species, and more generally, sound event detection tasks. To foster future research, we make our pipeline and methods publicly available. ",
    "url": "https://arxiv.org/abs/2301.02214",
    "authors": [
      "Zifan Jiang",
      "Adrian Soldati",
      "Isaac Schamberg",
      "Adriano R. Lameira",
      "Steven Moran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2301.02220",
    "title": "Value Enhancement of Reinforcement Learning via Efficient and Robust  Trust Region Optimization",
    "abstract": "Reinforcement learning (RL) is a powerful machine learning technique that enables an intelligent agent to learn an optimal policy that maximizes the cumulative rewards in sequential decision making. Most of methods in the existing literature are developed in \\textit{online} settings where the data are easy to collect or simulate. Motivated by high stake domains such as mobile health studies with limited and pre-collected data, in this paper, we study \\textit{offline} reinforcement learning methods. To efficiently use these datasets for policy optimization, we propose a novel value enhancement method to improve the performance of a given initial policy computed by existing state-of-the-art RL algorithms. Specifically, when the initial policy is not consistent, our method will output a policy whose value is no worse and often better than that of the initial policy. When the initial policy is consistent, under some mild conditions, our method will yield a policy whose value converges to the optimal one at a faster rate than the initial policy, achieving the desired ``value enhancement\" property. The proposed method is generally applicable to any parametrized policy that belongs to certain pre-specified function class (e.g., deep neural networks). Extensive numerical studies are conducted to demonstrate the superior performance of our method. ",
    "url": "https://arxiv.org/abs/2301.02220",
    "authors": [
      "Chengchun Shi",
      "Zhengling Qi",
      "Jianing Wang",
      "Fan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1912.12148",
    "title": "DADA: Driver Attention Prediction in Driving Accident Scenarios",
    "abstract": " Comments: published by IEEE Transactions on Intelligent Transportation Systems ",
    "url": "https://arxiv.org/abs/1912.12148",
    "authors": [
      "Jianwu Fang",
      "Dingxin Yan",
      "Jiahuan Qiao",
      "Jianru Xue",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2003.06267",
    "title": "Causal Unfoldings and Disjunctive Causes",
    "abstract": " Comments: 30 pages, no figures, submitted for publication in the special issue of the Journal Logical Methods in Computer Science devoted to the best contributions of CALCO 2019. arXiv admin note: text overlap with arXiv:1607.03747 ",
    "url": "https://arxiv.org/abs/2003.06267",
    "authors": [
      "Marc de Visme",
      "Glynn Winskel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2006.04746",
    "title": "FREDE: Anytime Graph Embeddings",
    "abstract": " Comments: As appeared in VLDB 14 ",
    "url": "https://arxiv.org/abs/2006.04746",
    "authors": [
      "Anton Tsitsulin",
      "Marina Munkhoeva",
      "Davide Mottin",
      "Panagiotis Karras",
      "Ivan Oseledets",
      "Emmanuel M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2008.11943",
    "title": "The Complexity of Network Satisfaction Problems for Symmetric Relation  Algebras with a Flexible Atom",
    "abstract": " Comments: 32 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2008.11943",
    "authors": [
      "Manuel Bodirsky",
      "Simon Kn\u00e4uer"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Rings and Algebras (math.RA)"
    ]
  },
  {
    "id": "arXiv:2106.00561",
    "title": "A General Framework for Learning-Based Distributionally Robust MPC of  Markov Jump Systems",
    "abstract": " Comments: Revised version ",
    "url": "https://arxiv.org/abs/2106.00561",
    "authors": [
      "Mathijs Schuurmans",
      "Panagiotis Patrinos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.02248",
    "title": "A comparison of LSTM and GRU networks for learning symbolic sequences",
    "abstract": " Title: A comparison of LSTM and GRU networks for learning symbolic sequences ",
    "url": "https://arxiv.org/abs/2107.02248",
    "authors": [
      "Roberto Cahuantzi",
      "Xinye Chen",
      "Stefan G\u00fcttel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2107.03083",
    "title": "Wireless Network Scheduling with Discrete Propagation Delays: Theorems  and Algorithms",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2107.03083",
    "authors": [
      "Shenghao Yang",
      "Jun Ma",
      "Yanxiao Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2111.09278",
    "title": "Differentially Private Federated Learning on Heterogeneous Data",
    "abstract": " Title: Differentially Private Federated Learning on Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2111.09278",
    "authors": [
      "Maxence Noble",
      "Aur\u00e9lien Bellet",
      "Aymeric Dieuleveut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2202.02429",
    "title": "Verifying Inverse Model Neural Networks",
    "abstract": " Comments: Reformatted and fixed typos ",
    "url": "https://arxiv.org/abs/2202.02429",
    "authors": [
      "Chelsea Sidrane",
      "Sydney Katz",
      "Anthony Corso",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2202.07201",
    "title": "Holistic Adversarial Robustness of Deep Learning Models",
    "abstract": " Comments: survey paper on holistic adversarial robustness for deep learning; published at AAAI 2023 Senior Member Presentation Track ",
    "url": "https://arxiv.org/abs/2202.07201",
    "authors": [
      "Pin-Yu Chen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.09795",
    "title": "Accountable Javascript Code Delivery",
    "abstract": " Title: Accountable Javascript Code Delivery ",
    "url": "https://arxiv.org/abs/2202.09795",
    "authors": [
      "Ilkan Esiyok",
      "Pascal Berrang",
      "Katriel Cohn-Gordon",
      "Robert Kuennemann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2203.00907",
    "title": "Split Semantic Detection in Sandplay Images",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2203.00907",
    "authors": [
      "Xiaokun Feng",
      "Xiaotang Chen",
      "Jian Jia",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.01881",
    "title": "Understanding Representation Quality in Self-Supervised Models",
    "abstract": " Title: Understanding Representation Quality in Self-Supervised Models ",
    "url": "https://arxiv.org/abs/2203.01881",
    "authors": [
      "Neha Kalibhat",
      "Kanika Narang",
      "Hamed Firooz",
      "Maziar Sanjabi",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01969",
    "title": "Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and  no Retraining",
    "abstract": " Comments: MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2203.01969",
    "authors": [
      "Benjamin Billot",
      "Magdamo Colin",
      "Sean E. Arnold",
      "Sudeshna Das",
      "Juan. E. Iglesias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.14550",
    "title": "CenterLoc3D: Monocular 3D Vehicle Localization Network for Roadside  Surveillance Cameras",
    "abstract": " Comments: 33 pages, 15 figures. v3. This work has been published on Complex & Intelligent Systems, link: this https URL ",
    "url": "https://arxiv.org/abs/2203.14550",
    "authors": [
      "Tang Xinyao",
      "Wang Wei",
      "Song Huansheng",
      "Zhao Chunhui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09829",
    "title": "Capturing cross-session neural population variability through  self-supervised identification of consistent neuron ensembles",
    "abstract": " Title: Capturing cross-session neural population variability through  self-supervised identification of consistent neuron ensembles ",
    "url": "https://arxiv.org/abs/2205.09829",
    "authors": [
      "Justin Jude",
      "Matthew G. Perich",
      "Lee E. Miller",
      "Matthias H. Hennig"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13209",
    "title": "Sym-NCO: Leveraging Symmetricity for Neural Combinatorial Optimization",
    "abstract": " Comments: 23 pages, 8 figures, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13209",
    "authors": [
      "Minsu Kim",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.13983",
    "title": "Quantum Augmented Dual Attack",
    "abstract": " Comments: Error in the code of the previous version and updates to the estimates in the paper ",
    "url": "https://arxiv.org/abs/2205.13983",
    "authors": [
      "Martin R. Albrecht",
      "Yixin Shen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2206.05694",
    "title": "RL-GA: A Reinforcement Learning-Based Genetic Algorithm for  Electromagnetic Detection Satellite Scheduling Problem",
    "abstract": " Comments: 29 pages, 9 figures, Accepted by Swarm and Evolutionary Computation ",
    "url": "https://arxiv.org/abs/2206.05694",
    "authors": [
      "Yanjie Song",
      "Luona Wei",
      "Qing Yang",
      "Jian Wu",
      "Lining Xing",
      "Yingwu Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.07459",
    "title": "READ: Aggregating Reconstruction Error into Out-of-distribution  Detection",
    "abstract": " Comments: Accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2206.07459",
    "authors": [
      "Wenyu Jiang",
      "Yuxin Ge",
      "Hao Cheng",
      "Mingcai Chen",
      "Shuai Feng",
      "Chongjun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.06956",
    "title": "Cover and Hitting Times of Hyperbolic Random Graphs",
    "abstract": " Comments: 50 pages, 4 figures. Appeared in Proceedings of RANDOM 2022 ",
    "url": "https://arxiv.org/abs/2207.06956",
    "authors": [
      "Marcos Kiwi",
      "Markus Schepers",
      "John Sylvester"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2207.08489",
    "title": "Neural Distributed Image Compression with Cross-Attention Feature  Alignment",
    "abstract": " Comments: 16 pages, 15 figures, presented in WACV 2023 ",
    "url": "https://arxiv.org/abs/2207.08489",
    "authors": [
      "Nitish Mital",
      "Ezgi Ozyilkan",
      "Ali Garjani",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.13895",
    "title": "Generative Hypergraph Models and Spectral Embedding",
    "abstract": " Title: Generative Hypergraph Models and Spectral Embedding ",
    "url": "https://arxiv.org/abs/2207.13895",
    "authors": [
      "Xue Gong",
      "Desmond J. Higham",
      "Konstantinos Zygalakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Physics and Society (physics.soc-ph)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2209.02032",
    "title": "Robust machine learning segmentation for large-scale analysis of  heterogeneous clinical brain MRI datasets",
    "abstract": " Comments: under review, extension of MICCAI 2022 paper ",
    "url": "https://arxiv.org/abs/2209.02032",
    "authors": [
      "Benjamin Billot",
      "Colin Magdamo",
      "You Cheng",
      "Steven E. Arnold",
      "Sudeshna Das",
      "Juan. E. Iglesias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10585",
    "title": "Grape Cold Hardiness Prediction via Multi-Task Learning",
    "abstract": " Comments: 6 pages, 2 figures, accepted at IAAI-23 ",
    "url": "https://arxiv.org/abs/2209.10585",
    "authors": [
      "Aseem Saxena",
      "Paola Pesantez-Cabrera",
      "Rohan Ballapragada",
      "Kin-Ho Lam",
      "Markus Keller",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11785",
    "title": "Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search",
    "abstract": " Title: Tiered Pruning for Efficient Differentialble Inference-Aware Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2209.11785",
    "authors": [
      "S\u0142awomir Kierat",
      "Mateusz Sieniawski",
      "Denys Fridman",
      "Chen-Han Yu",
      "Szymon Migacz",
      "Pawe\u0142 Morkisz",
      "Alex-Fit Florea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.14084",
    "title": "Global Weighted Tensor Nuclear Norm for Tensor Robust Principal  Component Analysis",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2209.14084",
    "authors": [
      "Libin Wang",
      "Yulong Wang",
      "Shiyuan Wang",
      "Youheng Liu",
      "Yutao Hu",
      "Longlong Chen",
      "Hong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00898",
    "title": "Robust $Q$-learning Algorithm for Markov Decision Processes under  Wasserstein Uncertainty",
    "abstract": " Title: Robust $Q$-learning Algorithm for Markov Decision Processes under  Wasserstein Uncertainty ",
    "url": "https://arxiv.org/abs/2210.00898",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.09028",
    "title": "Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2",
    "abstract": " Title: Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2 ",
    "url": "https://arxiv.org/abs/2210.09028",
    "authors": [
      "Pier Paolo Tricomi",
      "Lisa Facciolo",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11201",
    "title": "Robust Imitation via Mirror Descent Inverse Reinforcement Learning",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.11201",
    "authors": [
      "Dong-Sig Han",
      "Hyunseo Kim",
      "Hyundo Lee",
      "Je-Hwan Ryu",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.13014",
    "title": "Sarcasm Detection Framework Using Context, Emotion and Sentiment  Features",
    "abstract": " Title: Sarcasm Detection Framework Using Context, Emotion and Sentiment  Features ",
    "url": "https://arxiv.org/abs/2211.13014",
    "authors": [
      "Oxana Vitman",
      "Yevhen Kostiuk",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.03998",
    "title": "Minimizing Age of Information in Spatially Distributed Random Access  Wireless Networks",
    "abstract": " Comments: Accepted to IEEE INFOCOM 2023 ",
    "url": "https://arxiv.org/abs/2212.03998",
    "authors": [
      "Nicholas Jones",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.08756",
    "title": "Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization",
    "abstract": " Title: Multi-Scales Data Augmentation Approach In Natural Language Inference  For Artifacts Mitigation And Pre-Trained Model Optimization ",
    "url": "https://arxiv.org/abs/2212.08756",
    "authors": [
      "Zhenyuan Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2212.09993",
    "title": "Are Deep Neural Networks SMARTer than Second Graders?",
    "abstract": " Title: Are Deep Neural Networks SMARTer than Second Graders? ",
    "url": "https://arxiv.org/abs/2212.09993",
    "authors": [
      "Anoop Cherian",
      "Kuan-Chuan Peng",
      "Suhas Lohit",
      "Kevin Smith",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10730",
    "title": "Real-time Path Planning of Driver-less Mining Trains with Time-dependent  Physical Constraints",
    "abstract": " Title: Real-time Path Planning of Driver-less Mining Trains with Time-dependent  Physical Constraints ",
    "url": "https://arxiv.org/abs/2212.10730",
    "authors": [
      "Xiaojiang Ren",
      "Hui Guo",
      "Changxin Gao",
      "Sheng Kai",
      "Guoqiang Mao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.13726",
    "title": "A Clustering-guided Contrastive Fusion for Multi-view Representation  Learning",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2212.13726",
    "authors": [
      "Guanzhou Ke",
      "Guoqing Chao",
      "Xiaoli Wang",
      "Chenyang Xu",
      "Chang Xu",
      "Yongqi Zhu",
      "Yang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00335",
    "title": "Theoretical Characterization of How Neural Network Pruning Affects its  Generalization",
    "abstract": " Title: Theoretical Characterization of How Neural Network Pruning Affects its  Generalization ",
    "url": "https://arxiv.org/abs/2301.00335",
    "authors": [
      "Hongru Yang",
      "Yingbin Liang",
      "Xiaojie Guo",
      "Lingfei Wu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00391",
    "title": "PiPAD: Pipelined and Parallel Dynamic GNN Training on GPUs",
    "abstract": " Comments: To appear at PPoPP 2023: 28th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming ",
    "url": "https://arxiv.org/abs/2301.00391",
    "authors": [
      "Chunyang Wang",
      "Desen Sun",
      "Yuebin Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.00802",
    "title": "G-CEALS: Gaussian Cluster Embedding in Autoencoder Latent Space for  Tabular Data Representation",
    "abstract": " Title: G-CEALS: Gaussian Cluster Embedding in Autoencoder Latent Space for  Tabular Data Representation ",
    "url": "https://arxiv.org/abs/2301.00802",
    "authors": [
      "Manar D. Samad",
      "Sakib Abrar",
      "Mohammad Bataineh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.01495",
    "title": "Beckman Defense",
    "abstract": " Title: Beckman Defense ",
    "url": "https://arxiv.org/abs/2301.01495",
    "authors": [
      "A. V. Subramanyam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]