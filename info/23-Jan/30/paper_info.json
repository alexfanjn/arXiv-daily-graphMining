[
  {
    "id": "arXiv:2301.11336",
    "title": "Causal Structural Learning from Time Series: A Convex Optimization  Approach",
    "abstract": "Structural learning, which aims to learn directed acyclic graphs (DAGs) from observational data, is foundational to causal reasoning and scientific discovery. Recent advancements formulate structural learning into a continuous optimization problem; however, DAG learning remains a highly non-convex problem, and there has not been much work on leveraging well-developed convex optimization techniques for causal structural learning. We fill this gap by proposing a data-adaptive linear approach for causal structural learning from time series data, which can be conveniently cast into a convex optimization problem using a recently developed monotone operator variational inequality (VI) formulation. Furthermore, we establish non-asymptotic recovery guarantee of the VI-based approach and show the superior performance of our proposed method on structure recovery over existing methods via extensive numerical experiments. ",
    "url": "https://arxiv.org/abs/2301.11336",
    "authors": [
      "Song Wei",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.11342",
    "title": "A Robust Optimisation Perspective on Counterexample-Guided Repair of  Neural Networks",
    "abstract": "Counterexample-guided repair aims at creating neural networks with mathematical safety guarantees, facilitating the application of neural networks in safety-critical domains. However, whether counterexample-guided repair is guaranteed to terminate remains an open question. We approach this question by showing that counterexample-guided repair can be viewed as a robust optimisation algorithm. While termination guarantees for neural network repair itself remain beyond our reach, we prove termination for more restrained machine learning models and disprove termination in a general setting. We empirically study the practical implications of our theoretical results, demonstrating the suitability of common verifiers and falsifiers for repair despite a disadvantageous theoretical result. Additionally, we use our theoretical insights to devise a novel algorithm for repairing linear regression models, surpassing existing approaches. ",
    "url": "https://arxiv.org/abs/2301.11342",
    "authors": [
      "David Boetius",
      "Stefan Leue",
      "Tobias Sutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.11351",
    "title": "Estimating Causal Effects using a Multi-task Deep Ensemble",
    "abstract": "Over the past few decades, a number of methods have been proposed for causal effect estimation, yet few have been demonstrated to be effective in handling data with complex structures, such as images. To fill this gap, we propose a Causal Multi-task Deep Ensemble (CMDE) framework to learn both shared and group-specific information from the study population and prove its equivalence to a multi-task Gaussian process (GP) with coregionalization kernel a priori. Compared to multi-task GP, CMDE efficiently handles high-dimensional and multi-modal covariates and provides pointwise uncertainty estimates of causal effects. We evaluate our method across various types of datasets and tasks and find that CMDE outperforms state-of-the-art methods on a majority of these tasks. ",
    "url": "https://arxiv.org/abs/2301.11351",
    "authors": [
      "Ziyang Jiang",
      "Zhuoran Hou",
      "Yiling Liu",
      "Yiman Ren",
      "Keyu Li",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11368",
    "title": "Coincident Learning for Unsupervised Anomaly Detection",
    "abstract": "Anomaly detection is an important task for complex systems (e.g., industrial facilities, manufacturing, large-scale science experiments), where failures in a sub-system can lead to low yield, faulty products, or even damage to components. While complex systems often have a wealth of data, labeled anomalies are typically rare (or even nonexistent) and expensive to acquire. In this paper, we introduce a new method, called CoAD, for training anomaly detection models on unlabeled data, based on the expectation that anomalous behavior in one sub-system will produce coincident anomalies in downstream sub-systems and products. Given data split into two streams $s$ and $q$ (i.e., subsystem diagnostics and final product quality), we define an unsupervised metric, $\\hat{F}_\\beta$, out of analogy to the supervised classification $F_\\beta$ statistic, which quantifies the performance of the independent anomaly detection algorithms on s and q based on their coincidence rate. We demonstrate our method in four cases: a synthetic time-series data set, a synthetic imaging data set generated from MNIST, a metal milling data set, and a data set taken from a particle accelerator. ",
    "url": "https://arxiv.org/abs/2301.11368",
    "authors": [
      "Ryan Humble",
      "Zhe Zhang",
      "Finn O'Shea",
      "Eric Darve",
      "Daniel Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11374",
    "title": "Policy Optimization with Robustness Certificates",
    "abstract": "We present a policy optimization framework in which the learned policy comes with a machine-checkable certificate of adversarial robustness. Our approach, called CAROL, learns a model of the environment. In each learning iteration, it uses the current version of this model and an external abstract interpreter to construct a differentiable signal for provable robustness. This signal is used to guide policy learning, and the abstract interpretation used to construct it directly leads to the robustness certificate returned at convergence. We give a theoretical analysis that bounds the worst-case accumulative reward of CAROL. We also experimentally evaluate CAROL on four MuJoCo environments. On these tasks, which involve continuous state and action spaces, CAROL learns certified policies that have performance comparable to the (non-certified) policies learned using state-of-the-art robust RL methods. ",
    "url": "https://arxiv.org/abs/2301.11374",
    "authors": [
      "Chenxi Yang",
      "Greg Anderson",
      "Swarat Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11375",
    "title": "Neural networks learn to magnify areas near decision boundaries",
    "abstract": "We study how training molds the Riemannian geometry induced by neural network feature maps. At infinite width, neural networks with random parameters induce highly symmetric metrics on input space. Feature learning in networks trained to perform classification tasks magnifies local areas along decision boundaries. These changes are consistent with previously proposed geometric approaches for hand-tuning of kernel methods to improve generalization. ",
    "url": "https://arxiv.org/abs/2301.11375",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Sheng Yang",
      "Julian A. Rubinfien",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11378",
    "title": "MG-GNN: Multigrid Graph Neural Networks for Learning Multilevel Domain  Decomposition Methods",
    "abstract": "Domain decomposition methods (DDMs) are popular solvers for discretized systems of partial differential equations (PDEs), with one-level and multilevel variants. These solvers rely on several algorithmic and mathematical parameters, prescribing overlap, subdomain boundary conditions, and other properties of the DDM. While some work has been done on optimizing these parameters, it has mostly focused on the one-level setting or special cases such as structured-grid discretizations with regular subdomain construction. In this paper, we propose multigrid graph neural networks (MG-GNN), a novel GNN architecture for learning optimized parameters in two-level DDMs\\@. We train MG-GNN using a new unsupervised loss function, enabling effective training on small problems that yields robust performance on unstructured grids that are orders of magnitude larger than those in the training set. We show that MG-GNN outperforms popular hierarchical graph network architectures for this optimization and that our proposed loss function is critical to achieving this improved performance. ",
    "url": "https://arxiv.org/abs/2301.11378",
    "authors": [
      "Ali Taghibakhshi",
      "Nicolas Nytko",
      "Tareq Uz Zaman",
      "Scott MacLachlan",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2301.11386",
    "title": "Task formulation for Extracting Social Determinants of Health from  Clinical Narratives",
    "abstract": "Objective: The 2022 n2c2 NLP Challenge posed identification of social determinants of health (SDOH) in clinical narratives. We present three systems that we developed for the Challenge and discuss the distinctive task formulation used in each of the three systems. Materials and Methods: The first system identifies target pieces of information independently using machine learning classifiers. The second system uses a large language model (LLM) to extract complete structured outputs per document. The third system extracts candidate phrases using machine learning and identifies target relations with hand-crafted rules. Results: The three systems achieved F1 scores of 0.884, 0.831, and 0.663 in the Subtask A of the Challenge, which are ranked third, seventh, and eighth among the 15 participating teams. The review of the extraction results from our systems reveals characteristics of each approach and those of the SODH extraction task. Discussion: Phrases and relations annotated in the task is unique and diverse, not conforming to the conventional event extraction task. These annotations are difficult to model with limited training data. The system that extracts information independently, ignoring the annotated relations, achieves the highest F1 score. Meanwhile, LLM with its versatile capability achieves the high F1 score, while respecting the annotated relations. The rule-based system tackling relation extraction obtains the low F1 score, while it is the most explainable approach. Conclusion: The F1 scores of the three systems vary in this challenge setting, but each approach has advantages and disadvantages in a practical application. The selection of the approach depends not only on the F1 score but also on the requirements in the application. ",
    "url": "https://arxiv.org/abs/2301.11386",
    "authors": [
      "Manabu Torii",
      "Ian M. Finn",
      "Son Doan",
      "Paul Wang",
      "Elly W. Yang",
      "Daniel S. Zisook"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11389",
    "title": "A Symbolic Emulator for Shuffle Synthesis on the NVIDIA PTX Code",
    "abstract": "Various kinds of applications take advantage of GPUs through automation tools that attempt to automatically exploit the available performance of the GPU's parallel architecture. Directive-based programming models, such as OpenACC, are one such method that easily enables parallel computing by just adhering code annotations to code loops. Such abstract models, however, often prevent programmers from making additional low-level optimizations to take advantage of the advanced architectural features of GPUs because the actual generated computation is hidden from the application developer. This paper describes and implements a novel flexible optimization technique that operates by inserting a code emulator phase to the tail-end of the compilation pipeline. Our tool emulates the generated code using symbolic analysis by substituting dynamic information and thus allowing for further low-level code optimizations to be applied. We implement our tool to support both CUDA and OpenACC directives as the frontend of the compilation pipeline, thus enabling low-level GPU optimizations for OpenACC that were not previously possible. We demonstrate the capabilities of our tool by automating warp-level shuffle instructions that are difficult to use by even advanced GPU programmers. Lastly, evaluating our tool with a benchmark suite and complex application code, we provide a detailed study to assess the benefits of shuffle instructions across four generations of GPU architectures. ",
    "url": "https://arxiv.org/abs/2301.11389",
    "authors": [
      "Kazuaki Matsumura",
      "Simon Garcia De Gonzalo",
      "Antonio J. Pe\u00f1a"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.11408",
    "title": "DBGDGM: Dynamic Brain Graph Deep Generative Model",
    "abstract": "Graphs are a natural representation of brain activity derived from functional magnetic imaging (fMRI) data. It is well known that clusters of anatomical brain regions, known as functional connectivity networks (FCNs), encode temporal relationships which can serve as useful biomarkers for understanding brain function and dysfunction. Previous works, however, ignore the temporal dynamics of the brain and focus on static graphs. In this paper, we propose a dynamic brain graph deep generative model (DBGDGM) which simultaneously clusters brain regions into temporally evolving communities and learns dynamic unsupervised node embeddings. Specifically, DBGDGM represents brain graph nodes as embeddings sampled from a distribution over communities that evolve over time. We parameterise this community distribution using neural networks that learn from subject and node embeddings as well as past community assignments. Experiments demonstrate DBGDGM outperforms baselines in graph generation, dynamic link prediction, and is comparable for graph classification. Finally, an analysis of the learnt community distributions reveals overlap with known FCNs reported in neuroscience literature. ",
    "url": "https://arxiv.org/abs/2301.11408",
    "authors": [
      "Alexander Campbell",
      "Simeon Spasov",
      "Nicola Toschi",
      "Pietro Lio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11418",
    "title": "Parkinson gait modelling from an anomaly deep representation",
    "abstract": "Parkinson's Disease is associated with gait movement disorders, such as postural instability, stiffness, and tremors. Today, some approaches implemented learning representations to quantify kinematic patterns during locomotion, supporting clinical procedures such as diagnosis and treatment planning. These approaches assumes a large amount of stratified and labeled data to optimize discriminative representations. Nonetheless, these considerations may restrict the operability of approaches in real scenarios during clinical practice. This work introduces a self-supervised generative representation, under the pretext of video reconstruction and anomaly detection framework. This architecture is trained following a one-class weakly supervised learning to avoid inter-class variance and approach the multiple relationships that represent locomotion. For validation 14 PD patients and 23 control subjects were recorded, and trained with the control population only, achieving an AUC of 86.9%, homoscedasticity level of 80% and shapeness level of 70% in the classification task considering its generalization. ",
    "url": "https://arxiv.org/abs/2301.11418",
    "authors": [
      "Edgar Rangel",
      "Fabio Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.11419",
    "title": "Efficiently predicting high resolution mass spectra with graph neural  networks",
    "abstract": "Identifying a small molecule from its mass spectrum is the primary open problem in computational metabolomics. This is typically cast as information retrieval: an unknown spectrum is matched against spectra predicted computationally from a large database of chemical structures. However, current approaches to spectrum prediction model the output space in ways that force a tradeoff between capturing high resolution mass information and tractable learning. We resolve this tradeoff by casting spectrum prediction as a mapping from an input molecular graph to a probability distribution over molecular formulas. We discover that a large corpus of mass spectra can be closely approximated using a fixed vocabulary constituting only 2% of all observed formulas. This enables efficient spectrum prediction using an architecture similar to graph classification - GrAFF-MS - achieving significantly lower prediction error and orders-of-magnitude faster runtime than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2301.11419",
    "authors": [
      "Michael Murphy",
      "Stefanie Jegelka",
      "Ernest Fraenkel",
      "Tobias Kind",
      "David Healey",
      "Thomas Butler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2301.11431",
    "title": "Semidefinite Relaxations for Robust Multiview Triangulation",
    "abstract": "We propose the first convex relaxation for multiview triangulation that is robust to both noise and outliers. To this end, we extend existing semidefinite relaxation approaches to loss functions that include a truncated least squares cost to account for outliers. We propose two formulations, one based on epipolar constraints and one based on the fractional reprojection equations. The first is lower dimensional and remains tight under moderate noise and outlier levels, while the second is higher dimensional and therefore slower but remains tight even under extreme noise and outlier levels. We demonstrate through extensive experiments that the proposed approach allows us to compute provably optimal reconstructions and that empirically the relaxations remain tight even under significant noise and a large percentage of outliers. ",
    "url": "https://arxiv.org/abs/2301.11431",
    "authors": [
      "Linus H\u00e4renstam-Nielsen",
      "Niclas Zeller",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.11440",
    "title": "Secure synchronization of artificial neural networks used to correct  errors in quantum cryptography",
    "abstract": "Quantum cryptography can provide a very high level of data security. However, a big challenge of this technique is errors in quantum channels. Therefore, error correction methods must be applied in real implementations. An example is error correction based on artificial neural networks. This paper considers the practical aspects of this recently proposed method and analyzes elements which influence security and efficiency. The synchronization process based on mutual learning processes is analyzed in detail. The results allowed us to determine the impact of various parameters. Additionally, the paper describes the recommended number of iterations for different structures of artificial neural networks and various error rates. All this aims to support users in choosing a suitable configuration of neural networks used to correct errors in a secure and efficient way. ",
    "url": "https://arxiv.org/abs/2301.11440",
    "authors": [
      "Marcin Niemiec",
      "Tymoteusz Widlarz",
      "Miralem Mehic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11443",
    "title": "Limitless stability for Graph Convolutional Networks",
    "abstract": "This work establishes rigorous, novel and widely applicable stability guarantees and transferability bounds for graph convolutional networks -- without reference to any underlying limit object or statistical distribution. Crucially, utilized graph-shift operators (GSOs) are not necessarily assumed to be normal, allowing for the treatment of networks on both directed- and for the first time also undirected graphs. Stability to node-level perturbations is related to an 'adequate (spectral) covering' property of the filters in each layer. Stability to edge-level perturbations is related to Lipschitz constants and newly introduced semi-norms of filters. Results on stability to topological perturbations are obtained through recently developed mathematical-physics based tools. As an important and novel example, it is showcased that graph convolutional networks are stable under graph-coarse-graining procedures (replacing strongly-connected sub-graphs by single nodes) precisely if the GSO is the graph Laplacian and filters are regular at infinity. These new theoretical results are supported by corresponding numerical investigations. ",
    "url": "https://arxiv.org/abs/2301.11443",
    "authors": [
      "Christian Koke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2301.11445",
    "title": "3DShape2VecSet: A 3D Shape Representation for Neural Fields and  Generative Diffusion Models",
    "abstract": "We introduce 3DShape2VecSet, a novel shape representation for neural fields designed for generative diffusion models. Our shape representation can encode 3D shapes given as surface models or point clouds, and represents them as neural fields. The concept of neural fields has previously been combined with a global latent vector, a regular grid of latent vectors, or an irregular grid of latent vectors. Our new representation encodes neural fields on top of a set of vectors. We draw from multiple concepts, such as the radial basis function representation and the cross attention and self-attention function, to design a learnable representation that is especially suitable for processing with transformers. Our results show improved performance in 3D shape encoding and 3D shape generative modeling tasks. We demonstrate a wide variety of generative applications: unconditioned generation, category-conditioned generation, text-conditioned generation, point-cloud completion, and image-conditioned generation. ",
    "url": "https://arxiv.org/abs/2301.11445",
    "authors": [
      "Biao Zhang",
      "Jiapeng Tang",
      "Matthias Niessner",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.11447",
    "title": "Personalised Federated Learning On Heterogeneous Feature Spaces",
    "abstract": "Most personalised federated learning (FL) approaches assume that raw data of all clients are defined in a common subspace i.e. all clients store their data according to the same schema. For real-world applications, this assumption is restrictive as clients, having their own systems to collect and then store data, may use heterogeneous data representations. We aim at filling this gap. To this end, we propose a general framework coined FLIC that maps client's data onto a common feature space via local embedding functions. The common feature space is learnt in a federated manner using Wasserstein barycenters while the local embedding functions are trained on each client via distribution alignment. We integrate this distribution alignement mechanism into a federated learning approach and provide the algorithmics of FLIC. We compare its performances against FL benchmarks involving heterogeneous input features spaces. In addition, we provide theoretical insights supporting the relevance of our methodology. ",
    "url": "https://arxiv.org/abs/2301.11447",
    "authors": [
      "Alain Rakotomamonjy",
      "Maxime Vono",
      "Hamlet Jesse Medina Ruiz",
      "Liva Ralaivola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11456",
    "title": "Graph Scattering beyond Wavelet Shackles",
    "abstract": "This work develops a flexible and mathematically sound framework for the design and analysis of graph scattering networks with variable branching ratios and generic functional calculus filters. Spectrally-agnostic stability guarantees for node- and graph-level perturbations are derived; the vertex-set non-preserving case is treated by utilizing recently developed mathematical-physics based tools. Energy propagation through the network layers is investigated and related to truncation stability. New methods of graph-level feature aggregation are introduced and stability of the resulting composite scattering architectures is established. Finally, scattering transforms are extended to edge- and higher order tensorial input. Theoretical results are complemented by numerical investigations: Suitably chosen cattering networks conforming to the developed theory perform better than traditional graph-wavelet based scattering approaches in social network graph classification tasks and significantly outperform other graph-based learning approaches to regression of quantum-chemical energies on QM7. ",
    "url": "https://arxiv.org/abs/2301.11456",
    "authors": [
      "Christian Koke",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11457",
    "title": "Attacking Important Pixels for Anchor-free Detectors",
    "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks: subtle perturbation can completely change the prediction result. Existing adversarial attacks on object detection focus on attacking anchor-based detectors, which may not work well for anchor-free detectors. In this paper, we propose the first adversarial attack dedicated to anchor-free detectors. It is a category-wise attack that attacks important pixels of all instances of a category simultaneously. Our attack manifests in two forms, sparse category-wise attack (SCA) and dense category-wise attack (DCA), that minimize the $L_0$ and $L_\\infty$ norm-based perturbations, respectively. For DCA, we present three variants, DCA-G, DCA-L, and DCA-S, that select a global region, a local region, and a semantic region, respectively, to attack. Our experiments on large-scale benchmark datasets including PascalVOC, MS-COCO, and MS-COCO Keypoints indicate that our proposed methods achieve state-of-the-art attack performance and transferability on both object detection and human pose estimation tasks. ",
    "url": "https://arxiv.org/abs/2301.11457",
    "authors": [
      "Yunxu Xie",
      "Shu Hu",
      "Xin Wang",
      "Quanyu Liao",
      "Bin Zhu",
      "Xi Wu",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11459",
    "title": "Neural-Symbolic Inference for Robust Autoregressive Graph Parsing via  Compositional Uncertainty Quantification",
    "abstract": "Pre-trained seq2seq models excel at graph semantic parsing with rich annotated data, but generalize worse to out-of-distribution (OOD) and long-tail examples. In comparison, symbolic parsers under-perform on population-level metrics, but exhibit unique strength in OOD and tail generalization. In this work, we study compositionality-aware approach to neural-symbolic inference informed by model confidence, performing fine-grained neural-symbolic reasoning at subgraph level (i.e., nodes and edges) and precisely targeting subgraph components with high uncertainty in the neural parser. As a result, the method combines the distinct strength of the neural and symbolic approaches in capturing different aspects of the graph prediction, leading to well-rounded generalization performance both across domains and in the tail. We empirically investigate the approach in the English Resource Grammar (ERG) parsing problem on a diverse suite of standard in-domain and seven OOD corpora. Our approach leads to 35.26% and 35.60% error reduction in aggregated Smatch score over neural and symbolic approaches respectively, and 14% absolute accuracy gain in key tail linguistic categories over the neural model, outperforming prior state-of-art methods that do not account for compositionality or uncertainty. ",
    "url": "https://arxiv.org/abs/2301.11459",
    "authors": [
      "Zi Lin",
      "Jeremiah Liu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11462",
    "title": "How poor is the stimulus? Evaluating hierarchical generalization in  neural networks trained on child-directed speech",
    "abstract": "When acquiring syntax, children consistently choose hierarchical rules over competing non-hierarchical possibilities. Is this preference due to a learning bias for hierarchical structure, or due to more general biases that interact with hierarchical cues in children's linguistic input? We explore these possibilities by training LSTMs and Transformers - two types of neural networks without a hierarchical bias - on data similar in quantity and content to children's linguistic input: text from the CHILDES corpus. We then evaluate what these models have learned about English yes/no questions, a phenomenon for which hierarchical structure is crucial. We find that, though they perform well at capturing the surface statistics of child-directed speech (as measured by perplexity), both model types generalize in a way more consistent with an incorrect linear rule than the correct hierarchical rule. These results suggest that human-like generalization from text alone requires stronger biases than the general sequence-processing biases of standard neural network architectures. ",
    "url": "https://arxiv.org/abs/2301.11462",
    "authors": [
      "Aditya Yedetore",
      "Tal Linzen",
      "Robert Frank",
      "R. Thomas McCoy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11463",
    "title": "Nik Defense: An Artificial Intelligence Based Defense Mechanism against  Selfish Mining in Bitcoin",
    "abstract": "The Bitcoin cryptocurrency has received much attention recently. In the network of Bitcoin, transactions are recorded in a ledger. In this network, the process of recording transactions depends on some nodes called miners that execute a protocol known as mining protocol. One of the significant aspects of mining protocol is incentive compatibility. However, literature has shown that Bitcoin mining's protocol is not incentive-compatible. Some nodes with high computational power can obtain more revenue than their fair share by adopting a type of attack called the selfish mining attack. In this paper, we propose an artificial intelligence-based defense against selfish mining attacks by applying the theory of learning automata. The proposed defense mechanism ignores private blocks by assigning weight based on block discovery time and changes current Bitcoin's fork resolving policy by evaluating branches' height difference in a self-adaptive manner utilizing learning automata. To the best of our knowledge, the proposed protocol is the literature's first learning-based defense mechanism. Simulation results have shown the superiority of the proposed mechanism against tie-breaking mechanism, which is a well-known defense. The simulation results have shown that the suggested defense mechanism increases the profit threshold up to 40\\% and decreases the revenue of selfish attackers. ",
    "url": "https://arxiv.org/abs/2301.11463",
    "authors": [
      "Ali Nikhalat Jahromi",
      "Ali Mohammad Saghiri",
      "Mohammad Reza Meybodi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11471",
    "title": "Multi-channel Medium Access Control Protocols for Wireless Networks  within Computing Packages",
    "abstract": "Wireless communications at the chip scale emerge as a interesting complement to traditional wire-based approaches thanks to their low latency, inherent broadcast nature, and capacity to bypass pin constraints. However, as current trends push towards massive and bandwidth-hungry processor architectures, there is a need for wireless chip-scale networks that exploit and share as many channels as possible. In this context, this work addresses the issue of channel sharing by exploring the design space of multi-channel Medium Access Control (MAC) protocols for chip-scale networks. Distinct channel assignment strategies for both random access and token passing are presented and evaluated under realistic traffic patterns. It is shown that, even with the improvements enabled by the multiple channels, both protocols maintain their intrinsic advantages and disadvantages. ",
    "url": "https://arxiv.org/abs/2301.11471",
    "authors": [
      "Bernat Oll\u00e9",
      "Pau Talarn",
      "Albert Cabellos-Aparicio",
      "Filip Lemic",
      "Eduard Alarc\u00f3n",
      "Sergi Abadal"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2301.11490",
    "title": "Neural Episodic Control with State Abstraction",
    "abstract": "Existing Deep Reinforcement Learning (DRL) algorithms suffer from sample inefficiency. Generally, episodic control-based approaches are solutions that leverage highly-rewarded past experiences to improve sample efficiency of DRL algorithms. However, previous episodic control-based approaches fail to utilize the latent information from the historical behaviors (e.g., state transitions, topological similarities, etc.) and lack scalability during DRL training. This work introduces Neural Episodic Control with State Abstraction (NECSA), a simple but effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state evaluation, and a multi-step state analysis. We evaluate our approach to the MuJoCo and Atari tasks in OpenAI gym domains. The experimental results indicate that NECSA achieves higher sample efficiency than the state-of-the-art episodic control-based approaches. Our data and code are available at the project website\\footnote{\\url{https://sites.google.com/view/drl-necsa}}. ",
    "url": "https://arxiv.org/abs/2301.11490",
    "authors": [
      "Zhuo Li",
      "Derui Zhu",
      "Yujing Hu",
      "Xiaofei Xie",
      "Lei Ma",
      "Yan Zheng",
      "Yan Song",
      "Yingfeng Chen",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.11494",
    "title": "Learning Vortex Dynamics for Fluid Inference and Prediction",
    "abstract": "We propose a novel machine learning method based on differentiable vortex particles to infer and predict fluid dynamics from a single video. The key design of our system is a particle-based latent space to encapsulate the hidden, Lagrangian vortical evolution underpinning the observable, Eulerian flow phenomena. We devise a novel differentiable vortex particle system in conjunction with their learnable, vortex-to-velocity dynamics mapping to effectively capture and represent the complex flow features in a reduced space. We further design an end-to-end training pipeline to directly learn and synthesize simulators from data, that can reliably deliver future video rollouts based on limited observation. The value of our method is twofold: first, our learned simulator enables the inference of hidden physics quantities (e.g. velocity field) purely from visual observation, to be used for motion analysis; secondly, it also supports future prediction, constructing the input video's sequel along with its future dynamics evolution. We demonstrate our method's efficacy by comparing quantitatively and qualitatively with a range of existing methods on both synthetic and real-world videos, displaying improved data correspondence, visual plausibility, and physical integrity. ",
    "url": "https://arxiv.org/abs/2301.11494",
    "authors": [
      "Yitong Deng",
      "Hong-Xing Yu",
      "Jiajun Wu",
      "Bo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.11495",
    "title": "Skeleton-based Action Recognition through Contrasting Two-Stream  Spatial-Temporal Networks",
    "abstract": "For pursuing accurate skeleton-based action recognition, most prior methods use the strategy of combining Graph Convolution Networks (GCNs) with attention-based methods in a serial way. However, they regard the human skeleton as a complete graph, resulting in less variations between different actions (e.g., the connection between the elbow and head in action ``clapping hands''). For this, we propose a novel Contrastive GCN-Transformer Network (ConGT) which fuses the spatial and temporal modules in a parallel way. The ConGT involves two parallel streams: Spatial-Temporal Graph Convolution stream (STG) and Spatial-Temporal Transformer stream (STT). The STG is designed to obtain action representations maintaining the natural topology structure of the human skeleton. The STT is devised to acquire action representations containing the global relationships among joints. Since the action representations produced from these two streams contain different characteristics, and each of them knows little information of the other, we introduce the contrastive learning paradigm to guide their output representations of the same sample to be as close as possible in a self-supervised manner. Through the contrastive learning, they can learn information from each other to enrich the action features by maximizing the mutual information between the two types of action representations. To further improve action recognition accuracy, we introduce the Cyclical Focal Loss (CFL) which can focus on confident training samples in early training epochs, with an increasing focus on hard samples during the middle epochs. We conduct experiments on three benchmark datasets, which demonstrate that our model achieves state-of-the-art performance in action recognition. ",
    "url": "https://arxiv.org/abs/2301.11495",
    "authors": [
      "Chen Pang",
      "Xuequan Lu",
      "Lei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11499",
    "title": "Dual-View Selective Instance Segmentation Network for Unstained Live  Adherent Cells in Differential Interference Contrast Images",
    "abstract": "Despite recent advances in data-independent and deep-learning algorithms, unstained live adherent cell instance segmentation remains a long-standing challenge in cell image processing. Adherent cells' inherent visual characteristics, such as low contrast structures, fading edges, and irregular morphology, have made it difficult to distinguish from one another, even by human experts, let alone computational methods. In this study, we developed a novel deep-learning algorithm called dual-view selective instance segmentation network (DVSISN) for segmenting unstained adherent cells in differential interference contrast (DIC) images. First, we used a dual-view segmentation (DVS) method with pairs of original and rotated images to predict the bounding box and its corresponding mask for each cell instance. Second, we used a mask selection (MS) method to filter the cell instances predicted by the DVS to keep masks closest to the ground truth only. The developed algorithm was trained and validated on our dataset containing 520 images and 12198 cells. Experimental results demonstrate that our algorithm achieves an AP_segm of 0.555, which remarkably overtakes a benchmark by a margin of 23.6%. This study's success opens up a new possibility of using rotated images as input for better prediction in cell images. ",
    "url": "https://arxiv.org/abs/2301.11499",
    "authors": [
      "Fei Pan",
      "Yutong Wu",
      "Kangning Cui",
      "Shuxun Chen",
      "Yanfang Li",
      "Yaofang Liu",
      "Adnan Shakoor",
      "Han Zhao",
      "Beijia Lu",
      "Shaohua Zhi",
      "Raymond Chan",
      "Dong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11508",
    "title": "Theme-driven Keyphrase Extraction from Social Media on Opioid Recovery",
    "abstract": "An emerging trend on social media platforms is their use as safe spaces for peer support. Particularly in healthcare, where many medical conditions contain harsh stigmas, social media has become a stigma-free way to engage in dialogues regarding symptoms, treatments, and personal experiences. Many existing works have employed NLP algorithms to facilitate quantitative analysis of health trends. Notably absent from existing works are keyphrase extraction (KE) models for social health posts-a task crucial to discovering emerging public health trends. This paper presents a novel, theme-driven KE dataset, SuboxoPhrase, and a qualitative annotation scheme with an overarching goal of extracting targeted clinically-relevant keyphrases. To the best of our knowledge, this is the first study to design a KE schema for social media healthcare texts. To demonstrate the value of this approach, this study analyzes Reddit posts regarding medications for opioid use disorder, a paramount health concern worldwide. Additionally, we benchmark ten off-the-shelf KE models on our new dataset, demonstrating the unique extraction challenges in modeling user-generated health texts. The proposed theme-driven KE approach lays the foundation of future work on efficient, large-scale analysis of social health texts, allowing researchers to surface useful public health trends, patterns, and knowledge gaps. ",
    "url": "https://arxiv.org/abs/2301.11508",
    "authors": [
      "William Romano",
      "Omar Sharif",
      "Madhusudan Basak",
      "Joseph Gatto",
      "Sarah Preum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11513",
    "title": "CellMix: A General Instance Relationship based Method for Data  Augmentation Towards Pathology Image Analysis",
    "abstract": "Pathology image analysis crucially relies on the availability and quality of annotated pathological samples, which are very difficult to collect and need lots of human effort. To address this issue, beyond traditional preprocess data augmentation methods, mixing-based approaches are effective and practical. However, previous mixing-based data augmentation methods do not thoroughly explore the essential characteristics of pathology images, including the local specificity, global distribution, and inner/outer-sample instance relationship. To further understand the pathology characteristics and make up effective pseudo samples, we propose the CellMix framework with a novel distribution-based in-place shuffle strategy. We split the images into patches with respect to the granularity of pathology instances and do the shuffle process across the same batch. In this way, we generate new samples while keeping the absolute relationship of pathology instances intact. Furthermore, to deal with the perturbations and distribution-based noise, we devise a loss-drive strategy inspired by curriculum learning during the training process, making the model fit the augmented data adaptively. It is worth mentioning that we are the first to explore data augmentation techniques in the pathology image field. Experiments show SOTA results on 7 different datasets. We conclude that this novel instance relationship-based strategy can shed light on general data augmentation for pathology image analysis. The code is available at https://github.com/sagizty/CellMix. ",
    "url": "https://arxiv.org/abs/2301.11513",
    "authors": [
      "Tianyi Zhang",
      "Zhiling Yan",
      "Chunhui Li",
      "Nan Ying",
      "Yanli Lei",
      "Yunlu Feng",
      "Yu Zhao",
      "Guanglei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11514",
    "title": "Deep Visual Anomaly Detection in Industrial Manufacturing: A Survey",
    "abstract": "The recent rapid development of deep learning has laid a milestone in visual anomaly detection (VAD). In this paper, we provide a comprehensive review of deep learning-based visual anomaly detection techniques, from the perspectives of neural network architectures, levels of supervision, loss functions, metrics and datasets. In addition, we extract the new setting from industrial manufacturing and review the current VAD approaches under our proposed our new setting. Moreover, we highlight several opening challenges for visual anomaly detection. The merits and downsides of representative network architectures under varying supervision are discussed. Finally, we summarize the research findings and point out future research directions. More resources are available at https://github.com/M-3LAB/awesome-industrial-anomaly-detection ",
    "url": "https://arxiv.org/abs/2301.11514",
    "authors": [
      "Jiaqi Liu",
      "Guoyang Xie",
      "Jingbao Wang",
      "Shangnian Li",
      "Chengjie Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11516",
    "title": "Is Embodied Interaction Beneficial? A Study on Navigating Network  Visualizations",
    "abstract": "Network visualizations are commonly used to analyze relationships in various contexts. To efficiently explore a network visualization, the user needs to quickly navigate to different parts of the network and analyze local details. Recent advancements in display and interaction technologies inspire new visions for improved visualization and interaction design. Past research into network design has identified some key benefits to visualizing networks in 3D versus 2D. However, little work has been done to study the impact of varying levels of embodied interaction on network analysis. We present a controlled user study that compared four environments featuring conditions and hardware that leveraged different amounts of embodiment and visual perception ranging from a 2D visualization desktop environment with a standard mouse to a 3D visualization virtual reality environment. We measured the accuracy, speed, perceived workload, and preferences of 20 participants as they completed three network analytic tasks, each of which required unique navigation and substantial effort. For the task that required participants to iterate over the entire visualization rather than focus on a specific area, we found that participants were more accurate using a VR and a trackball mouse than conventional desktop settings. From a workload perspective, VR was generally considered the least mentally demanding and least frustrating in two of our three tasks. It was also preferred and ranked as the most effective and visually appealing condition overall. However, using VR to compare two side-by-side networks was difficult, and it was similar to or slower than other conditions in two of the three tasks. Overall, the accuracy and workload advantages of conditions with greater embodiment in specific tasks suggest promising opportunities to create more effective environments in which to analyze network visualizations. ",
    "url": "https://arxiv.org/abs/2301.11516",
    "authors": [
      "Helen H. Huang",
      "Hanspeter Pfister",
      "Yalong Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2301.11517",
    "title": "Task-Agnostic Graph Neural Network Evaluation via Adversarial  Collaboration",
    "abstract": "It has been increasingly demanding to develop reliable Graph Neural Network (GNN) evaluation methods to quantify the progress of the rapidly expanding GNN research. Existing GNN benchmarking methods focus on comparing the GNNs with respect to their performances on some node/graph classification/regression tasks in certain datasets. There lacks a principled, task-agnostic method to directly compare two GNNs. Moreover, most of the existing graph self-supervised learning (SSL) works incorporate handcrafted augmentations to the graph, which has several severe difficulties due to the unique characteristics of graph-structured data. To address the aforementioned issues, we propose GraphAC (Graph Adversarial Collaboration) -- a conceptually novel, principled, task-agnostic, and stable framework for evaluating GNNs through contrastive self-supervision. GraphAC succeeds in distinguishing GNNs of different expressiveness across various aspects, and has been proven to be a principled and reliable GNN evaluation method, eliminating the need for handcrafted augmentations for stable SSL. ",
    "url": "https://arxiv.org/abs/2301.11517",
    "authors": [
      "Xiangyu Zhao",
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Pietro Li\u00f2",
      "Yiren Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11520",
    "title": "SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning",
    "abstract": "As previous representations for reinforcement learning cannot effectively incorporate a human-intuitive understanding of the 3D environment, they usually suffer from sub-optimal performances. In this paper, we present Semantic-aware Neural Radiance Fields for Reinforcement Learning (SNeRL), which jointly optimizes semantic-aware neural radiance fields (NeRF) with a convolutional encoder to learn 3D-aware neural implicit representation from multi-view images. We introduce 3D semantic and distilled feature fields in parallel to the RGB radiance fields in NeRF to learn semantic and object-centric representation for reinforcement learning. SNeRL outperforms not only previous pixel-based representations but also recent 3D-aware representations both in model-free and model-based reinforcement learning. ",
    "url": "https://arxiv.org/abs/2301.11520",
    "authors": [
      "Dongseok Shim",
      "Seungjae Lee",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.11524",
    "title": "RAPTOR: Advanced Persistent Threat Detection in Industrial IoT via  Attack Stage Correlation",
    "abstract": "IIoT (Industrial Internet-of-Things) systems are getting more prone to attacks by APT (Advanced Persistent Threat) adversaries. Past APT attacks on IIoT systems such as the 2016 Ukrainian power grid attack which cut off the capital Kyiv off power for an hour and the 2017 Saudi petrochemical plant attack which almost shut down the plant's safety controllers have shown that APT campaigns can disrupt industrial processes, shut down critical systems and endanger human lives. In this work, we propose RAPTOR, a system to detect APT campaigns in IIoT environments. RAPTOR detects and correlates various APT attack stages (adapted to IIoT) using multiple data sources. Subsequently, it constructs a high-level APT campaign graph which can be used by cybersecurity analysts towards attack analysis and mitigation. A performance evaluation of RAPTOR's APT stage detection stages shows high precision and low false positive/negative rates. We also show that RAPTOR is able to construct the APT campaign graph for APT attacks (modelled after real-world attacks on ICS/OT infrastructure) executed on our IIoT testbed. ",
    "url": "https://arxiv.org/abs/2301.11524",
    "authors": [
      "Ayush Kumar",
      "Vrizlynn L.L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11525",
    "title": "Mixed Attention Network for Hyperspectral Image Denoising",
    "abstract": "Hyperspectral image denoising is unique for the highly similar and correlated spectral information that should be properly considered. However, existing methods show limitations in exploring the spectral correlations across different bands and feature interactions within each band. Besides, the low- and high-level features usually exhibit different importance for different spatial-spectral regions, which is not fully explored for current algorithms as well. In this paper, we present a Mixed Attention Network (MAN) that simultaneously considers the inter- and intra-spectral correlations as well as the interactions between low- and high-level spatial-spectral meaningful features. Specifically, we introduce a multi-head recurrent spectral attention that efficiently integrates the inter-spectral features across all the spectral bands. These features are further enhanced with a progressive spectral channel attention by exploring the intra-spectral relationships. Moreover, we propose an attentive skip-connection that adaptively controls the proportion of the low- and high-level spatial-spectral features from the encoder and decoder to better enhance the aggregated features. Extensive experiments show that our MAN outperforms existing state-of-the-art methods on simulated and real noise settings while maintaining a low cost of parameters and running time. ",
    "url": "https://arxiv.org/abs/2301.11525",
    "authors": [
      "Zeqiang Lai",
      "Ying Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.11526",
    "title": "Direct Parameterization of Lipschitz-Bounded Deep Networks",
    "abstract": "This paper introduces a new parameterization of deep neural networks (both fully-connected and convolutional) with guaranteed Lipschitz bounds, i.e. limited sensitivity to perturbations. The Lipschitz guarantees are equivalent to the tightest-known bounds based on certification via a semidefinite program (SDP), which does not scale to large models. In contrast to the SDP approach, we provide a ``direct'' parameterization, i.e. a smooth mapping from $\\mathbb R^N$ onto the set of weights of Lipschitz-bounded networks. This enables training via standard gradient methods, without any computationally intensive projections or barrier terms. The new parameterization can equivalently be thought of as either a new layer type (the \\textit{sandwich layer}), or a novel parameterization of standard feedforward networks with parameter sharing between neighbouring layers. We illustrate the method with some applications in image classification (MNIST and CIFAR-10). ",
    "url": "https://arxiv.org/abs/2301.11526",
    "authors": [
      "Ruigang Wang",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11527",
    "title": "Opinion-aware Influence Maximization in Online Social Networks",
    "abstract": "Influence maximization (IM) aims to find seed users on an online social network to maximize the spread of information about a target product through word-of-mouth propagation among all users. Prior IM methods mostly focus on maximizing the overall influence spread, which assumes that all users are potential customers of the product and that more exposure leads to higher benefits. However, in real-world scenarios, some users who dislike the product may express and spread negative opinions, damaging the product's reputation and lowering its profit. This paper investigates the opinion-aware influence maximization (OIM) problem, which finds a set of seed users to maximize the positive opinions toward the product while minimizing the negative opinions. We propose a novel algorithm for the OIM problem. Specifically, after obtaining the users with positive and negative opinions towards the product from historical data, we design a reverse reachable set-based method for opinion-aware influence estimation and a sandwich approximation algorithm for seed set selection. Despite the NP-hardness and non-submodularity of OIM, our algorithm achieves a data-dependent approximation factor for OIM. Experimental results on three real-world datasets demonstrate that our algorithm improves the spread of positive opinions while reducing the spread of negative opinions compared to existing methods. ",
    "url": "https://arxiv.org/abs/2301.11527",
    "authors": [
      "Ying Wang",
      "Yanhao Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.11530",
    "title": "Strategic Defense of Feedback-Controlled Parallel Queues against  Reliability and Security Failures",
    "abstract": "Parallel traffic service systems such as transportation, manufacturing, and computer systems typically involve feedback control (e.g., dynamic routing) to ensure stability and to improve throughput. Such control relies on connected cyber components for computation and communication. These components are susceptible to random malfunctions and malicious attacks, which motivates the design of strategic defense that are both traffic-stabilizing and cost-efficient under reliability/security failures. In this paper, we consider a parallel queuing system with dynamic routing subject to such failures. For the reliability setting, we consider an infinite-horizon Markov decision process where the system operator strategically activates the protection mechanism upon each job arrival based on the traffic state. We use Hamilton-Jacobi-Bellman equation to show that the optimal protection strategy is a deterministic threshold policy. For the security setting, we extend the model to an infinite-horizon stochastic game where the attacker strategically manipulates routing assignment. We show that a Markov perfect equilibrium of this game always exists and that both players follow a threshold strategy at each equilibrium. For both settings, we also consider the stability of the traffic queues in the face of failures. Finally, we develop approximate dynamic programming algorithms to compute the optimal/equilibrium policies and present numerical examples for validation and illustration. ",
    "url": "https://arxiv.org/abs/2301.11530",
    "authors": [
      "Qian Xie",
      "Jiayi Wang",
      "Li Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.11535",
    "title": "Learning Informative Representation for Fairness-aware Multivariate  Time-series Forecasting: A Group-based Perspective",
    "abstract": "Multivariate time series (MTS) forecasting has penetrated and benefited our daily life. However, the unfair forecasting of MTSs not only degrades their practical benefit but even brings about serious potential risk. Such unfair MTS forecasting may be attributed to variable disparity leading to advantaged and disadvantaged variables. This issue has rarely been studied in the existing MTS forecasting models. To address this significant gap, we formulate the MTS fairness modeling problem as learning informative representations attending to both advantaged and disadvantaged variables. Accordingly, we propose a novel framework, named FairFor, for fairness-aware MTS forecasting. FairFor is based on adversarial learning to generate both group-irrelevant and -relevant representations for the downstream forecasting. FairFor first adopts the recurrent graph convolution to capture spatio-temporal variable correlations and to group variables by leveraging a spectral relaxation of the K-means objective. Then, it utilizes a novel filtering & fusion module to filter the group-relevant information and generate group-irrelevant representations by orthogonality regularization. The group-irrelevant and -relevant representations form highly informative representations, facilitating to share the knowledge from advantaged variables to disadvantaged variables and guarantee fairness. Extensive experiments on four public datasets demonstrate the FairFor effectiveness for fair forecasting and significant performance improvement. ",
    "url": "https://arxiv.org/abs/2301.11535",
    "authors": [
      "Hui He",
      "Qi Zhang",
      "Shoujin Wang",
      "Kun Yi",
      "Zhendong Niu",
      "Longbing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.11541",
    "title": "Hide-and-Seek Game with Capacitated Locations and Imperfect Detection",
    "abstract": "We consider a variant of the hide-and-seek game in which a seeker inspects multiple hiding locations to find multiple items hidden by a hider. Each hiding location has a maximum hiding capacity and a probability of detecting its hidden items when an inspection by the seeker takes place. The objective of the seeker (resp. hider) is to minimize (resp. maximize) the expected number of undetected items. This model is motivated by strategic inspection problems, where a security agency is tasked with coordinating multiple inspection resources to detect and seize illegal commodities hidden by a criminal organization. To solve this large-scale zero-sum game, we leverage its structure and show that its mixed strategies Nash equilibria can be characterized using their unidimensional marginal distributions, which are Nash equilibria of a lower dimensional continuous zero-sum game. This leads to a two-step approach for efficiently solving our hide-and-seek game: First, we analytically solve the continuous game and compute the equilibrium marginal distributions. Second, we derive a combinatorial algorithm to coordinate the players' resources and compute equilibrium mixed strategies that satisfy the marginal distributions. We show that this solution approach computes a Nash equilibrium of the hide-and-seek game in quadratic time with linear support. Our analysis reveals a complex interplay between the game parameters and allows us to evaluate their impact on the players' behaviors in equilibrium and the criticality of each location. ",
    "url": "https://arxiv.org/abs/2301.11541",
    "authors": [
      "Basti\u00e1n Bahamondes",
      "Mathieu Dahan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2301.11544",
    "title": "Targeted Attacks on Timeseries Forecasting",
    "abstract": "Real-world deep learning models developed for Time Series Forecasting are used in several critical applications ranging from medical devices to the security domain. Many previous works have shown how deep learning models are prone to adversarial attacks and studied their vulnerabilities. However, the vulnerabilities of time series models for forecasting due to adversarial inputs are not extensively explored. While the attack on a forecasting model might aim to deteriorate the performance of the model, it is more effective, if the attack is focused on a specific impact on the model's output. In this paper, we propose a novel formulation of Directional, Amplitudinal, and Temporal targeted adversarial attacks on time series forecasting models. These targeted attacks create a specific impact on the amplitude and direction of the output prediction. We use the existing adversarial attack techniques from the computer vision domain and adapt them for time series. Additionally, we propose a modified version of the Auto Projected Gradient Descent attack for targeted attacks. We examine the impact of the proposed targeted attacks versus untargeted attacks. We use KS-Tests to statistically demonstrate the impact of the attack. Our experimental results show how targeted attacks on time series models are viable and are more powerful in terms of statistical similarity. It is, hence difficult to detect through statistical methods. We believe that this work opens a new paradigm in the time series forecasting domain and represents an important consideration for developing better defenses. ",
    "url": "https://arxiv.org/abs/2301.11544",
    "authors": [
      "Yuvaraj Govindarajulu",
      "Avinash Amballa",
      "Pavan Kulkarni",
      "Manojkumar Parmar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11546",
    "title": "Adapting Step-size: A Unified Perspective to Analyze and Improve  Gradient-based Methods for Adversarial Attacks",
    "abstract": "Learning adversarial examples can be formulated as an optimization problem of maximizing the loss function with some box-constraints. However, for solving this induced optimization problem, the state-of-the-art gradient-based methods such as FGSM, I-FGSM and MI-FGSM look different from their original methods especially in updating the direction, which makes it difficult to understand them and then leaves some theoretical issues to be addressed in viewpoint of optimization. In this paper, from the perspective of adapting step-size, we provide a unified theoretical interpretation of these gradient-based adversarial learning methods. We show that each of these algorithms is in fact a specific reformulation of their original gradient methods but using the step-size rules with only current gradient information. Motivated by such analysis, we present a broad class of adaptive gradient-based algorithms based on the regular gradient methods, in which the step-size strategy utilizing information of the accumulated gradients is integrated. Such adaptive step-size strategies directly normalize the scale of the gradients rather than use some empirical operations. The important benefit is that convergence for the iterative algorithms is guaranteed and then the whole optimization process can be stabilized. The experiments demonstrate that our AdaI-FGM consistently outperforms I-FGSM and AdaMI-FGM remains competitive with MI-FGSM for black-box attacks. ",
    "url": "https://arxiv.org/abs/2301.11546",
    "authors": [
      "Wei Tao",
      "Lei Bao",
      "Long Sheng",
      "Gaowei Wu",
      "Qing Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11553",
    "title": "Robust Transformer with Locality Inductive Bias and Feature  Normalization",
    "abstract": "Vision transformers have been demonstrated to yield state-of-the-art results on a variety of computer vision tasks using attention-based networks. However, research works in transformers mostly do not investigate robustness/accuracy trade-off, and they still struggle to handle adversarial perturbations. In this paper, we explore the robustness of vision transformers against adversarial perturbations and try to enhance their robustness/accuracy trade-off in white box attack settings. To this end, we propose Locality iN Locality (LNL) transformer model. We prove that the locality introduction to LNL contributes to the robustness performance since it aggregates local information such as lines, edges, shapes, and even objects. In addition, to further improve the robustness performance, we encourage LNL to extract training signal from the moments (a.k.a., mean and standard deviation) and the normalized features. We validate the effectiveness and generality of LNL by achieving state-of-the-art results in terms of accuracy and robustness metrics on German Traffic Sign Recognition Benchmark (GTSRB) and Canadian Institute for Advanced Research (CIFAR-10). More specifically, for traffic sign classification, the proposed LNL yields gains of 1.1% and ~35% in terms of clean and robustness accuracy compared to the state-of-the-art studies. ",
    "url": "https://arxiv.org/abs/2301.11553",
    "authors": [
      "Omid Nejati Manzari",
      "Hossein Kashiani",
      "Hojat Asgarian Dehkordi",
      "Shahriar Baradaran Shokouhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11564",
    "title": "Learning 6-DoF Fine-grained Grasp Detection Based on Part Affordance  Grounding",
    "abstract": "Robotic grasping is a fundamental ability for a robot to interact with the environment. Current methods focus on how to obtain a stable and reliable grasping pose in object wise, while little work has been studied on part (shape)-wise grasping which is related to fine-grained grasping and robotic affordance. Parts can be seen as atomic elements to compose an object, which contains rich semantic knowledge and a strong correlation with affordance. However, lacking a large part-wise 3D robotic dataset limits the development of part representation learning and downstream application. In this paper, we propose a new large Language-guided SHape grAsPing datasEt (named Lang-SHAPE) to learn 3D part-wise affordance and grasping ability. We design a novel two-stage fine-grained robotic grasping network (named PIONEER), including a novel 3D part language grounding model, and a part-aware grasp pose detection model. To evaluate the effectiveness, we perform multi-level difficulty part language grounding grasping experiments and deploy our proposed model on a real robot. Results show our method achieves satisfactory performance and efficiency in reference identification, affordance inference, and 3D part-aware grasping. Our dataset and code are available on our project website https://sites.google.com/view/lang-shape ",
    "url": "https://arxiv.org/abs/2301.11564",
    "authors": [
      "Yaoxian Song",
      "Penglei Sun",
      "Yi Ren",
      "Yu Zheng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.11575",
    "title": "ARiADNE: A Reinforcement learning approach using Attention-based Deep  Networks for Exploration",
    "abstract": "In autonomous robot exploration tasks, a mobile robot needs to actively explore and map an unknown environment as fast as possible. Since the environment is being revealed during exploration, the robot needs to frequently re-plan its path online, as new information is acquired by onboard sensors and used to update its partial map. While state-of-the-art exploration planners are frontier- and sampling-based, encouraged by the recent development in deep reinforcement learning (DRL), we propose ARiADNE, an attention-based neural approach to obtain real-time, non-myopic path planning for autonomous exploration. ARiADNE is able to learn dependencies at multiple spatial scales between areas of the agent's partial map, and implicitly predict potential gains associated with exploring those areas. This allows the agent to sequence movement actions that balance the natural trade-off between exploitation/refinement of the map in known areas and exploration of new areas. We experimentally demonstrate that our method outperforms both learning and non-learning state-of-the-art baselines in terms of average trajectory length to complete exploration in hundreds of simplified 2D indoor scenarios. We further validate our approach in high-fidelity Robot Operating System (ROS) simulations, where we consider a real sensor model and a realistic low-level motion controller, toward deployment on real robots. ",
    "url": "https://arxiv.org/abs/2301.11575",
    "authors": [
      "Yuhong Cao",
      "Tianxiang Hou",
      "Yizhuo Wang",
      "Xian Yi",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.11586",
    "title": "Khaos: The Impact of Inter-procedural Code Obfuscation on Binary Diffing  Techniques",
    "abstract": "Software obfuscation techniques can prevent binary diffing techniques from locating vulnerable code by obfuscating the third-party code, to achieve the purpose of protecting embedded device software. With the rapid development of binary diffing techniques, they can achieve more and more accurate function matching and identification by extracting the features within the function. This makes existing software obfuscation techniques, which mainly focus on the intra-procedural code obfuscation, no longer effective. In this paper, we propose a new inter-procedural code obfuscation mechanism Khaos, which moves the code across functions to obfuscate the function by using compilation optimizations. Two obfuscation primitives are proposed to separate and aggregate the function, which are called fission and fusion respectively. A prototype of Khaos is implemented based on the LLVM compiler and evaluated on a large number of real-world programs including SPEC CPU 2006 & 2017, CoreUtils, JavaScript engines, etc. Experimental results show that Khaos outperforms existing code obfuscations and can significantly reduce the accuracy rates of five state-of-the-art binary diffing techniques (less than 19%) with lower runtime overhead (less than 7%). ",
    "url": "https://arxiv.org/abs/2301.11586",
    "authors": [
      "Peihua Zhang",
      "Chenggang Wu",
      "Mingfan Peng",
      "Kai Zeng",
      "Ding Yu",
      "Yuanming Lai",
      "Yan Kang",
      "Wei Wang",
      "Zhe Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11589",
    "title": "Adversarial Learning for Implicit Semantic-Aware Communications",
    "abstract": "Semantic communication is a novel communication paradigm that focuses on recognizing and delivering the desired meaning of messages to the destination users. Most existing works in this area focus on delivering explicit semantics, labels or signal features that can be directly identified from the source signals. In this paper, we consider the implicit semantic communication problem in which hidden relations and closely related semantic terms that cannot be recognized from the source signals need to also be delivered to the destination user. We develop a novel adversarial learning-based implicit semantic-aware communication (iSAC) architecture in which the source user, instead of maximizing the total amount of information transmitted to the channel, aims to help the recipient learn an inference rule that can automatically generate implicit semantics based on limited clue information. We prove that by applying iSAC, the destination user can always learn an inference rule that matches the true inference rule of the source messages. Experimental results show that the proposed iSAC can offer up to a 19.69 dB improvement over existing non-inferential communication solutions, in terms of symbol error rate at the destination user. ",
    "url": "https://arxiv.org/abs/2301.11589",
    "authors": [
      "Zhimin Lu",
      "Yong Xiao",
      "Zijian Sun",
      "Yingyu Li",
      "Guangming Shi",
      "Xianfu Chen",
      "Mehdi Bennis",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2301.11600",
    "title": "Creative beyond TikToks: Investigating Adolescents' Social Privacy  Management on TikTok",
    "abstract": "TikTok has been criticized for its low privacy standards, but little is known about how its adolescent users protect their privacy. Based on interviews with 54 adolescents in Switzerland, this study provides a comprehensive understanding of young TikTok users' privacy management practices related to the creation of videos. The data were explored using the COM-B model, an established behavioral analysis framework adapted for sociotechnical privacy research. Our overall findings are in line with previous research on other social networks: adolescents are aware of privacy related to their online social connections (social privacy) and perform conscious privacy management. However, we also identified new patterns related to the central role of algorithmic recommendations potentially relevant for other social networks. Adolescents are aware that TikTok's special algorithm, combined with the app's high prevalence among their peers, could easily put them in the spotlight. Some adolescents also reduce TikTok, which was originally conceived as a social network, to its extensive audio-visual capabilities and share TikToks via more private channels (e.g., Snapchat) to manage audiences and avoid identification by peers. Young users also find other creative ways to protect their privacy such as identifying stalkers or maintaining multiple user accounts with different privacy settings to establish granular audience management. Based on our findings, we propose various concrete measures to develop interventions that protect the privacy of adolescents on TikTok. ",
    "url": "https://arxiv.org/abs/2301.11600",
    "authors": [
      "Nico Ebert",
      "Tim Geppert",
      "Joanna Strycharz",
      "Melanie Knieps",
      "Michael H\u00f6nig",
      "Elke Brucker-Kley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11604",
    "title": "A critical look at deep neural network for dynamic system modeling",
    "abstract": "Neural network models become increasingly popular as dynamic modeling tools in the control community. They have many appealing features including nonlinear structures, being able to approximate any functions. While most researchers hold optimistic attitudes towards such models, this paper questions the capability of (deep) neural networks for the modeling of dynamic systems using input-output data. For the identification of linear time-invariant (LTI) dynamic systems, two representative neural network models, Long Short-Term Memory (LSTM) and Cascade Foward Neural Network (CFNN) are compared to the standard Prediction Error Method (PEM) of system identification. In the comparison, four essential aspects of system identification are considered, then several possible defects and neglected issues of neural network based modeling are pointed out. Detailed simulation studies are performed to verify these defects: for the LTI system, both LSTM and CFNN fail to deliver consistent models even in noise-free cases; and they give worse results than PEM in noisy cases. ",
    "url": "https://arxiv.org/abs/2301.11604",
    "authors": [
      "Jinming Zhou",
      "Yucai Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.11608",
    "title": "A Multi-View Joint Learning Framework for Embedding Clinical Codes and  Text Using Graph Neural Networks",
    "abstract": "Learning to represent free text is a core task in many clinical machine learning (ML) applications, as clinical text contains observations and plans not otherwise available for inference. State-of-the-art methods use large language models developed with immense computational resources and training data; however, applying these models is challenging because of the highly varying syntax and vocabulary in clinical free text. Structured information such as International Classification of Disease (ICD) codes often succinctly abstracts the most important facts of a clinical encounter and yields good performance, but is often not as available as clinical text in real-world scenarios. We propose a \\textbf{multi-view learning framework} that jointly learns from codes and text to combine the availability and forward-looking nature of text and better performance of ICD codes. The learned text embeddings can be used as inputs to predictive algorithms independent of the ICD codes during inference. Our approach uses a Graph Neural Network (GNN) to process ICD codes, and Bi-LSTM to process text. We apply Deep Canonical Correlation Analysis (DCCA) to enforce the two views to learn a similar representation of each patient. In experiments using planned surgical procedure text, our model outperforms BERT models fine-tuned to clinical data, and in experiments using diverse text in MIMIC-III, our model is competitive to a fine-tuned BERT at a tiny fraction of its computational effort. ",
    "url": "https://arxiv.org/abs/2301.11608",
    "authors": [
      "Lecheng Kong",
      "Christopher King",
      "Bradley Fritz",
      "Yixin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11611",
    "title": "Influence of Information Blocking on the Spread of Virus in Multilayer  Networks",
    "abstract": "In this paper, we present the model of the interaction between the spread of disease and the spread of information about the disease in multilayer networks. Next, based on the characteristics of the SARS-COV-2 virus pandemic, we evaluated the influence of information blocking on the virus spread. Our results show that blocking the spread of information affects the speed at which the epidemic peak appears in our society and the number of infected individuals. ",
    "url": "https://arxiv.org/abs/2301.11611",
    "authors": [
      "Paulina W\u0105troba",
      "Piotr Br\u00f3dka"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2301.11621",
    "title": "Event Causality Extraction with Event Argument Correlations",
    "abstract": "Event Causality Identification (ECI), which aims to detect whether a causality relation exists between two given textual events, is an important task for event causality understanding. However, the ECI task ignores crucial event structure and cause-effect causality component information, making it struggle for downstream applications. In this paper, we explore a novel task, namely Event Causality Extraction (ECE), aiming to extract the cause-effect event causality pairs with their structured event information from plain texts. The ECE task is more challenging since each event can contain multiple event arguments, posing fine-grained correlations between events to decide the causeeffect event pair. Hence, we propose a method with a dual grid tagging scheme to capture the intra- and inter-event argument correlations for ECE. Further, we devise a event type-enhanced model architecture to realize the dual grid tagging scheme. Experiments demonstrate the effectiveness of our method, and extensive analyses point out several future directions for ECE. ",
    "url": "https://arxiv.org/abs/2301.11621",
    "authors": [
      "Shiyao Cui",
      "Jiawei Sheng",
      "Xin Cong",
      "QuanGang Li",
      "Tingwen Liu",
      "Jinqiao Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11624",
    "title": "Neural Wasserstein Gradient Flows for Maximum Mean Discrepancies with  Riesz Kernels",
    "abstract": "Wasserstein gradient flows of maximum mean discrepancy (MMD) functionals with non-smooth Riesz kernels show a rich structure as singular measures can become absolutely continuous ones and conversely. In this paper we contribute to the understanding of such flows. We propose to approximate the backward scheme of Jordan, Kinderlehrer and Otto for computing such Wasserstein gradient flows as well as a forward scheme for so-called Wasserstein steepest descent flows by neural networks (NNs). Since we cannot restrict ourselves to absolutely continuous measures, we have to deal with transport plans and velocity plans instead of usual transport maps and velocity fields. Indeed, we approximate the disintegration of both plans by generative NNs which are learned with respect to appropriate loss functions. In order to evaluate the quality of both neural schemes, we benchmark them on the interaction energy. Here we provide analytic formulas for Wasserstein schemes starting at a Dirac measure and show their convergence as the time step size tends to zero. Finally, we illustrate our neural MMD flows by numerical examples. ",
    "url": "https://arxiv.org/abs/2301.11624",
    "authors": [
      "Fabian Altekr\u00fcger",
      "Johannes Hertrich",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2301.11659",
    "title": "Matching Linear Algebra and Tensor Code to Specialized Hardware  Accelerators",
    "abstract": "Dedicated tensor accelerators demonstrate the importance of linear algebra in modern applications. Such accelerators have the potential for impressive performance gains, but require programmers to rewrite code using vendor APIs - a barrier to wider scale adoption. Recent work overcomes this by matching and replacing patterns within code, but such approaches are fragile and fail to cope with the diversity of real-world codes. We develop ATC, a compiler that uses program synthesis to map regions of code to specific APIs. The mapping space that ATC explores is combinatorially large, requiring the development of program classification, dynamic analysis, variable constraint generation and lexical distance matching techniques to make it tractable. We apply ATC to real-world tensor and linear algebra codes and evaluate them against four state-of-the-art approaches. We accelerate between 2.6x and 7x more programs, leading to over an order of magnitude performance improvement. ",
    "url": "https://arxiv.org/abs/2301.11659",
    "authors": [
      "Pablo Antonio Mart\u00ednez",
      "Jackson Woodruff",
      "Jordi Armengol-Estap\u00e9",
      "Gregorio Bernab\u00e9",
      "Jos\u00e9 Manuel Garc\u00eda",
      "Michael O'Boyle"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2301.11660",
    "title": "Probing Out-of-Distribution Robustness of Language Models with  Parameter-Efficient Transfer Learning Methods",
    "abstract": "As the size of the pre-trained language model (PLM) continues to increase, numerous parameter-efficient transfer learning methods have been proposed recently to compensate for the tremendous cost of fine-tuning. Despite the impressive results achieved by large pre-trained language models (PLMs) and various parameter-efficient transfer learning (PETL) methods on sundry benchmarks, it remains unclear if they can handle inputs that have been distributionally shifted effectively. In this study, we systematically explore how the ability to detect out-of-distribution (OOD) changes as the size of the PLM grows or the transfer methods are altered. Specifically, we evaluated various PETL techniques, including fine-tuning, Adapter, LoRA, and prefix-tuning, on three different intention classification tasks, each utilizing various language models with different scales. ",
    "url": "https://arxiv.org/abs/2301.11660",
    "authors": [
      "Hyunsoo Cho",
      "Choonghyun Park",
      "Junyeop Kim",
      "Hyuhng Joon Kim",
      "Kang Min Yoo",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11661",
    "title": "A denoting diffusion model for fluid flow prediction",
    "abstract": "We propose a novel denoising diffusion generative model for predicting nonlinear fluid fields named FluidDiff. By performing a diffusion process, the model is able to learn a complex representation of the high-dimensional dynamic system, and then Langevin sampling is used to generate predictions for the flow state under specified initial conditions. The model is trained with finite, discrete fluid simulation data. We demonstrate that our model has the capacity to model the distribution of simulated training data and that it gives accurate predictions on the test data. Without encoded prior knowledge of the underlying physical system, it shares competitive performance with other deep learning models for fluid prediction, which is promising for investigation on new computational fluid dynamics methods. ",
    "url": "https://arxiv.org/abs/2301.11661",
    "authors": [
      "Gefan Yang",
      "Stefan Sommer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2301.11663",
    "title": "Deep Residual Compensation Convolutional Network without Backpropagation",
    "abstract": "PCANet and its variants provided good accuracy results for classification tasks. However, despite the importance of network depth in achieving good classification accuracy, these networks were trained with a maximum of nine layers. In this paper, we introduce a residual compensation convolutional network, which is the first PCANet-like network trained with hundreds of layers while improving classification accuracy. The design of the proposed network consists of several convolutional layers, each followed by post-processing steps and a classifier. To correct the classification errors and significantly increase the network's depth, we train each layer with new labels derived from the residual information of all its preceding layers. This learning mechanism is accomplished by traversing the network's layers in a single forward pass without backpropagation or gradient computations. Our experiments on four distinct classification benchmarks (MNIST, CIFAR-10, CIFAR-100, and TinyImageNet) show that our deep network outperforms all existing PCANet-like networks and is competitive with several traditional gradient-based models. ",
    "url": "https://arxiv.org/abs/2301.11663",
    "authors": [
      "Mubarakah Alotaibi",
      "Richard Wilson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11673",
    "title": "Bayesian Self-Supervised Contrastive Learning",
    "abstract": "Recent years have witnessed many successful applications of contrastive learning in diverse domains, yet its self-supervised version still remains many exciting challenges. As the negative samples are drawn from unlabeled datasets, a randomly selected sample may be actually a false negative to an anchor, leading to incorrect encoder training. This paper proposes a new self-supervised contrastive loss called the BCL loss that still uses random samples from the unlabeled data while correcting the resulting bias with importance weights. The key idea is to design the desired sampling distribution for sampling hard true negative samples under the Bayesian framework. The prominent advantage lies in that the desired sampling distribution is a parametric structure, with a location parameter for debiasing false negative and concentration parameter for mining hard negative, respectively. Experiments validate the effectiveness and superiority of the BCL loss. ",
    "url": "https://arxiv.org/abs/2301.11673",
    "authors": [
      "Bin Liu",
      "Bang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11683",
    "title": "Neural Abstractions",
    "abstract": "We present a novel method for the safety verification of nonlinear dynamical models that uses neural networks to represent abstractions of their dynamics. Neural networks have extensively been used before as approximators; in this work, we make a step further and use them for the first time as abstractions. For a given dynamical model, our method synthesises a neural network that overapproximates its dynamics by ensuring an arbitrarily tight, formally certified bound on the approximation error. For this purpose, we employ a counterexample-guided inductive synthesis procedure. We show that this produces a neural ODE with non-deterministic disturbances that constitutes a formal abstraction of the concrete model under analysis. This guarantees a fundamental property: if the abstract model is safe, i.e., free from any initialised trajectory that reaches an undesirable state, then the concrete model is also safe. By using neural ODEs with ReLU activation functions as abstractions, we cast the safety verification problem for nonlinear dynamical models into that of hybrid automata with affine dynamics, which we verify using SpaceEx. We demonstrate that our approach performs comparably to the mature tool Flow* on existing benchmark nonlinear models. We additionally demonstrate and that it is effective on models that do not exhibit local Lipschitz continuity, which are out of reach to the existing technologies. ",
    "url": "https://arxiv.org/abs/2301.11683",
    "authors": [
      "Alessandro Abate",
      "Alec Edwards",
      "Mirco Giacobbe"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.11696",
    "title": "SLCNN: Sentence-Level Convolutional Neural Network for Text  Classification",
    "abstract": "Text classification is a fundamental task in natural language processing (NLP). Several recent studies show the success of deep learning on text processing. Convolutional neural network (CNN), as a popular deep learning model, has shown remarkable success in the task of text classification. In this paper, new baseline models have been studied for text classification using CNN. In these models, documents are fed to the network as a three-dimensional tensor representation to provide sentence-level analysis. Applying such a method enables the models to take advantage of the positional information of the sentences in the text. Besides, analysing adjacent sentences allows extracting additional features. The proposed models have been compared with the state-of-the-art models using several datasets. The results have shown that the proposed models have better performance, particularly in the longer documents. ",
    "url": "https://arxiv.org/abs/2301.11696",
    "authors": [
      "Ali Jarrahi",
      "Ramin Mousa",
      "Leila Safari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11701",
    "title": "TransNet: Transferable Neural Networks for Partial Differential  Equations",
    "abstract": "Transfer learning for partial differential equations (PDEs) is to develop a pre-trained neural network that can be used to solve a wide class of PDEs. Existing transfer learning approaches require much information of the target PDEs such as its formulation and/or data of its solution for pre-training. In this work, we propose to construct transferable neural feature spaces from purely function approximation perspectives without using PDE information. The construction of the feature space involves re-parameterization of the hidden neurons and uses auxiliary functions to tune the resulting feature space. Theoretical analysis shows the high quality of the produced feature space, i.e., uniformly distributed neurons. Extensive numerical experiments verify the outstanding performance of our method, including significantly improved transferability, e.g., using the same feature space for various PDEs with different domains and boundary conditions, and the superior accuracy, e.g., several orders of magnitude smaller mean squared error than the state of the art methods. ",
    "url": "https://arxiv.org/abs/2301.11701",
    "authors": [
      "Zezhong Zhang",
      "Feng Bao",
      "Lili Ju",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11705",
    "title": "FedHP: Heterogeneous Federated Learning with Privacy-preserving",
    "abstract": "Federated Learning is a distributed machine learning environment, which ensures that clients complete collaborative training without sharing private data, only by exchanging parameters. However, the data does not satisfy the same distribution and the computing resources of clients are different, which brings challenges to the related research. To better solve the above heterogeneous problems, we designed a novel federated learning method. The local model consists of the pre-trained model as the backbone and fully connected layers as the head. The backbone can extract features for the head, and the embedding vector of classes is shared between clients to optimize the head so that the local model can perform better. By sharing the embedding vector of classes, instead of parameters based on gradient space, clients can better adapt to private data, and it is more efficient in the communication between the server and clients. To better protect privacy, we proposed a privacy-preserving hybrid method to add noise to the embedding vector of classes, which has less impact on the local model performance under the premise of satisfying differential privacy. We conduct a comprehensive evaluation with other federated learning methods on the self-built vehicle dataset under non-independent identically distributed(Non-IID) ",
    "url": "https://arxiv.org/abs/2301.11705",
    "authors": [
      "Kuang Hangdong",
      "Mi Bo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11709",
    "title": "Semantic Network Model for Sign Language Comprehension",
    "abstract": "In this study, the authors propose a computational cognitive model for sign language (SL) perception and comprehension with detailed algorithmic descriptions based on cognitive functionalities in human language processing. The semantic network model (SNM) that represents semantic relations between concepts, it is used as a form of knowledge representation. The proposed model is applied in the comprehension of sign language for classifier predicates. The spreading activation search method is initiated by labeling a set of source nodes (e.g. concepts in the semantic network) with weights or \"activation\" and then iteratively propagating or \"spreading\" that activation out to other nodes linked to the source nodes. The results demonstrate that the proposed search method improves the performance of sign language comprehension in the SNM. ",
    "url": "https://arxiv.org/abs/2301.11709",
    "authors": [
      "Xinchen Kang",
      "Dengfeng Yao",
      "Minghu Jiang",
      "Yunlong Huang",
      "Fanshu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11714",
    "title": "Distributed Consensus in Wireless Networks with Probabilistic Broadcast  Scheduling",
    "abstract": "We consider distributed average consensus in a wireless network with partial communication to reduce the number of transmissions in every iteration/round. Considering the broadcast nature of wireless channels, we propose a probabilistic approach that schedules a subset of nodes for broadcasting information to their neighbors in every round. We compare several heuristic methods for assigning the node broadcast probabilities under a fixed number of transmissions per round. Furthermore, we introduce a pre-compensation method to correct the bias between the consensus value and the average of the initial values, and suggest possible extensions for our design. Our results are particularly relevant for developing communication-efficient consensus protocols in a wireless environment with limited frequency/time resources. ",
    "url": "https://arxiv.org/abs/2301.11714",
    "authors": [
      "Daniel P\u00e9rez Herrera",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.11749",
    "title": "A Multi-task Multi-stage Transitional Training Framework for Neural Chat  Translation",
    "abstract": "Neural chat translation (NCT) aims to translate a cross-lingual chat between speakers of different languages. Existing context-aware NMT models cannot achieve satisfactory performances due to the following inherent problems: 1) limited resources of annotated bilingual dialogues; 2) the neglect of modelling conversational properties; 3) training discrepancy between different stages. To address these issues, in this paper, we propose a multi-task multi-stage transitional (MMT) training framework, where an NCT model is trained using the bilingual chat translation dataset and additional monolingual dialogues. We elaborately design two auxiliary tasks, namely utterance discrimination and speaker discrimination, to introduce the modelling of dialogue coherence and speaker characteristic into the NCT model. The training process consists of three stages: 1) sentence-level pre-training on large-scale parallel corpus; 2) intermediate training with auxiliary tasks using additional monolingual dialogues; 3) context-aware fine-tuning with gradual transition. Particularly, the second stage serves as an intermediate phase that alleviates the training discrepancy between the pre-training and fine-tuning stages. Moreover, to make the stage transition smoother, we train the NCT model using a gradual transition strategy, i.e., gradually transiting from using monolingual to bilingual dialogues. Extensive experiments on two language pairs demonstrate the effectiveness and superiority of our proposed training framework. ",
    "url": "https://arxiv.org/abs/2301.11749",
    "authors": [
      "Chulun Zhou",
      "Yunlong Liang",
      "Fandong Meng",
      "Jie Zhou",
      "Jinan Xu",
      "Hongji Wang",
      "Min Zhang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.11754",
    "title": "Information-Theoretic Privacy-Preserving Schemes Based On Perfect  Privacy",
    "abstract": "Consider a pair of random variables $(X,Y)$ distributed according to a given joint distribution $p_{XY}$. A curator wishes to maximally disclose information about $Y$, while limiting the information leakage incurred on $X$. Adopting mutual information to measure both utility and privacy of this information disclosure, the problem is to maximize $I(Y;U)$, subject to $I(X;U)\\leq\\epsilon$, where $U$ denotes the released random variable and $\\epsilon$ is a given privacy threshold. Two settings are considered, where in the first one, the curator has access to $(X,Y)$, and hence, the optimization is over $p_{U|XY}$, while in the second one, the curator can only observe $Y$ and the optimization is over $p_{U|Y}$. In both settings, the utility-privacy trade-off is investigated from theoretical and practical perspective. More specifically, several privacy-preserving schemes are proposed in these settings based on generalizing the notion of statistical independence. Moreover, closed-form solutions are provided in certain scenarios. Finally, convexity arguments are provided for the utility-privacy trade-off as functionals of the joint distribution $p_{XY}$. ",
    "url": "https://arxiv.org/abs/2301.11754",
    "authors": [
      "Borzoo Rassouli",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.11765",
    "title": "ExplainableFold: Understanding AlphaFold Prediction with Explainable AI",
    "abstract": "This paper presents ExplainableFold, an explainable AI framework for protein structure prediction. Despite the success of AI-based methods such as AlphaFold in this field, the underlying reasons for their predictions remain unclear due to the black-box nature of deep learning models. To address this, we propose a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction, enabling a dry-lab experimentation approach. Our experimental results demonstrate the ability of ExplainableFold to generate high-quality explanations for AlphaFold's predictions, providing near-experimental understanding of the effects of amino acids on 3D protein structure. This framework has the potential to facilitate a deeper understanding of protein structures. ",
    "url": "https://arxiv.org/abs/2301.11765",
    "authors": [
      "Juntao Tan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11767",
    "title": "CAPoW: Context-Aware AI-Assisted Proof of Work based DDoS Defense",
    "abstract": "Critical servers can be secured against distributed denial of service (DDoS) attacks using proof of work (PoW) systems assisted by an Artificial Intelligence (AI) that learns contextual network request patterns. In this work, we introduce CAPoW, a context-aware anti-DDoS framework that injects latency adaptively during communication by utilizing context-aware PoW puzzles. In CAPoW, a security professional can define relevant request context attributes which can be learned by the AI system. These contextual attributes can include information about the user request, such as IP address, time, flow-level information, etc., and are utilized to generate a contextual score for incoming requests that influence the hardness of a PoW puzzle. These puzzles need to be solved by a user before the server begins to process their request. Solving puzzles slow down the volume of incoming adversarial requests. Additionally, the framework compels the adversary to incur a cost per request, hence making it expensive for an adversary to prolong a DDoS attack. We include the theoretical foundations of the CAPoW framework along with a description of its implementation and evaluation. ",
    "url": "https://arxiv.org/abs/2301.11767",
    "authors": [
      "Trisha Chakraborty",
      "Shaswata Mitra",
      "Sudip Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11773",
    "title": "Automatic Modulation Classification with Deep Neural Networks",
    "abstract": "Automatic modulation classification is a desired feature in many modern software-defined radios. In recent years, a number of convolutional deep learning architectures have been proposed for automatically classifying the modulation used on observed signal bursts. However, a comprehensive analysis of these differing architectures and importance of each design element has not been carried out. Thus it is unclear what tradeoffs the differing designs of these convolutional neural networks might have. In this research, we investigate numerous architectures for automatic modulation classification and perform a comprehensive ablation study to investigate the impacts of varying hyperparameters and design elements on automatic modulation classification performance. We show that a new state of the art in performance can be achieved using a subset of the studied design elements. In particular, we show that a combination of dilated convolutions, statistics pooling, and squeeze-and-excitation units results in the strongest performing classifier. We further investigate this best performer according to various other criteria, including short signal bursts, common misclassifications, and performance across differing modulation categories and modes. ",
    "url": "https://arxiv.org/abs/2301.11773",
    "authors": [
      "Clayton Harper",
      "Mitchell Thornton",
      "Eric Larson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11777",
    "title": "Interpreting learning in biological neural networks as zero-order  optimization method",
    "abstract": "Recently, significant progress has been made regarding the statistical understanding of artificial neural networks (ANNs). ANNs are motivated by the functioning of the brain, but differ in several crucial aspects. In particular, it is biologically implausible that the learning of the brain is based on gradient descent. In this work we look at the brain as a statistical method for supervised learning. The main contribution is to relate the local updating rule of the connection parameters in biological neural networks (BNNs) to a zero-order optimization method. ",
    "url": "https://arxiv.org/abs/2301.11777",
    "authors": [
      "Johannes Schmidt-Hieber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2301.11783",
    "title": "Certified Invertibility in Neural Networks via Mixed-Integer Programming",
    "abstract": "Neural networks are notoriously vulnerable to adversarial attacks -- small imperceptible perturbations that can change the network's output drastically. In the reverse direction, there may exist large, meaningful perturbations that leave the network's decision unchanged (excessive invariance, nonivertibility). We study the latter phenomenon in two contexts: (a) discrete-time dynamical system identification, as well as (b) calibration of the output of one neural network to the output of another (neural network matching). For ReLU networks and $L_p$ norms ($p=1,2,\\infty$), we formulate these optimization problems as mixed-integer programs (MIPs) that apply to neural network approximators of dynamical systems. We also discuss the applicability of our results to invertibility certification in transformations between neural networks (e.g. at different levels of pruning). ",
    "url": "https://arxiv.org/abs/2301.11783",
    "authors": [
      "Tianqi Cui",
      "Thomas Bertalan",
      "George J. Pappas",
      "Manfred Morari",
      "Ioannis G. Kevrekidis",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2301.11792",
    "title": "Graph Attention with Hierarchies for Multi-hop Question Answering",
    "abstract": "Multi-hop QA (Question Answering) is the task of finding the answer to a question across multiple documents. In recent years, a number of Deep Learning-based approaches have been proposed to tackle this complex task, as well as a few standard benchmarks to assess models Multi-hop QA capabilities. In this paper, we focus on the well-established HotpotQA benchmark dataset, which requires models to perform answer span extraction as well as support sentence prediction. We present two extensions to the SOTA Graph Neural Network (GNN) based model for HotpotQA, Hierarchical Graph Network (HGN): (i) we complete the original hierarchical structure by introducing new edges between the query and context sentence nodes; (ii) in the graph propagation step, we propose a novel extension to Hierarchical Graph Attention Network GATH (Graph ATtention with Hierarchies) that makes use of the graph hierarchy to update the node representations in a sequential fashion. Experiments on HotpotQA demonstrate the efficiency of the proposed modifications and support our assumptions about the effects of model related variables. ",
    "url": "https://arxiv.org/abs/2301.11792",
    "authors": [
      "Yunjie He",
      "Philip John Gorinski",
      "Ieva Staliunaite",
      "Pontus Stenetorp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11802",
    "title": "Decentralized Online Bandit Optimization on Directed Graphs with Regret  Bounds",
    "abstract": "We consider a decentralized multiplayer game, played over $T$ rounds, with a leader-follower hierarchy described by a directed acyclic graph. For each round, the graph structure dictates the order of the players and how players observe the actions of one another. By the end of each round, all players receive a joint bandit-reward based on their joint action that is used to update the player strategies towards the goal of minimizing the joint pseudo-regret. We present a learning algorithm inspired by the single-player multi-armed bandit problem and show that it achieves sub-linear joint pseudo-regret in the number of rounds for both adversarial and stochastic bandit rewards. Furthermore, we quantify the cost incurred due to the decentralized nature of our problem compared to the centralized setting. ",
    "url": "https://arxiv.org/abs/2301.11802",
    "authors": [
      "Johan \u00d6stman",
      "Ather Gattami",
      "Daniel Gillblad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2301.11804",
    "title": "TrojanSAINT: Gate-Level Netlist Sampling-Based Inductive Learning for  Hardware Trojan Detection",
    "abstract": "We propose TrojanSAINT, a graph neural network (GNN)-based hardware Trojan (HT) detection scheme working at the gate level. Unlike prior GNN-based art, TrojanSAINT enables both pre-/post-silicon HT detection. TrojanSAINT leverages a sampling-based GNN framework to detect and also localize HTs. For practical validation, TrojanSAINT achieves on average (oa) 78% true positive rate (TPR) and 85% true negative rate (TNR), respectively, on various TrustHub HT benchmarks. For best-case validation, TrojanSAINT even achieves 98% TPR and 96% TNR oa. TrojanSAINT outperforms related prior works and baseline classifiers. We release our source codes and result artifacts. ",
    "url": "https://arxiv.org/abs/2301.11804",
    "authors": [
      "Hazem Lashen",
      "Lilas Alrahis",
      "Johann Knechtel",
      "Ozgur Sinanoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.11806",
    "title": "PCV: A Point Cloud-Based Network Verifier",
    "abstract": "3D vision with real-time LiDAR-based point cloud data became a vital part of autonomous system research, especially perception and prediction modules use for object classification, segmentation, and detection. Despite their success, point cloud-based network models are vulnerable to multiple adversarial attacks, where the certain factor of changes in the validation set causes significant performance drop in well-trained networks. Most of the existing verifiers work perfectly on 2D convolution. Due to complex architecture, dimension of hyper-parameter, and 3D convolution, no verifiers can perform the basic layer-wise verification. It is difficult to conclude the robustness of a 3D vision model without performing the verification. Because there will be always corner cases and adversarial input that can compromise the model's effectiveness. In this project, we describe a point cloud-based network verifier that successfully deals state of the art 3D classifier PointNet verifies the robustness by generating adversarial inputs. We have used extracted properties from the trained PointNet and changed certain factors for perturbation input. We calculate the impact on model accuracy versus property factor and can test PointNet network's robustness against a small collection of perturbing input states resulting from adversarial attacks like the suggested hybrid reverse signed attack. The experimental results reveal that the resilience property of PointNet is affected by our hybrid reverse signed perturbation strategy ",
    "url": "https://arxiv.org/abs/2301.11806",
    "authors": [
      "Arup Kumar Sarker",
      "Farzana Yasmin Ahmad",
      "Matthew B. Dwyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.11824",
    "title": "PECAN: A Deterministic Certified Defense Against Backdoor Attacks",
    "abstract": "Neural networks are vulnerable to backdoor poisoning attacks, where the attackers maliciously poison the training set and insert triggers into the test input to change the prediction of the victim model. Existing defenses for backdoor attacks either provide no formal guarantees or come with expensive-to-compute and ineffective probabilistic guarantees. We present PECAN, an efficient and certified approach for defending against backdoor attacks. The key insight powering PECAN is to apply off-the-shelf test-time evasion certification techniques on a set of neural networks trained on disjoint partitions of the data. We evaluate PECAN on image classification and malware detection datasets. Our results demonstrate that PECAN can (1) significantly outperform the state-of-the-art certified backdoor defense, both in defense strength and efficiency, and (2) on real back-door attacks, PECAN can reduce attack success rate by order of magnitude when compared to a range of baselines from the literature. ",
    "url": "https://arxiv.org/abs/2301.11824",
    "authors": [
      "Yuhao Zhang",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11841",
    "title": "PhysGraph: Physics-Based Integration Using Graph Neural Networks",
    "abstract": "Physics-based simulation of mesh based domains remains a challenging task. State-of-the-art techniques can produce realistic results but require expert knowledge. A major bottleneck in many approaches is the step of integrating a potential energy in order to compute velocities or displacements. Recently, learning based method for physics-based simulation have sparked interest with graph based approaches being a promising research direction. One of the challenges for these methods is to generate models that are mesh independent and generalize to different material properties. Moreover, the model should also be able to react to unforeseen external forces like ubiquitous collisions. Our contribution is based on a simple observation: evaluating forces is computationally relatively cheap for traditional simulation methods and can be computed in parallel in contrast to their integration. If we learn how a system reacts to forces in general, irrespective of their origin, we can learn an integrator that can predict state changes due to the total forces with high generalization power. We effectively factor out the physical model behind resulting forces by relying on an opaque force module. We demonstrate that this idea leads to a learnable module that can be trained on basic internal forces of small mesh patches and generalizes to different mesh typologies, resolutions, material parameters and unseen forces like collisions at inference time. Our proposed paradigm is general and can be used to model a variety of physical phenomena. We focus our exposition on the detail enhancement of coarse clothing geometry which has many applications including computer games, virtual reality and virtual try-on. ",
    "url": "https://arxiv.org/abs/2301.11841",
    "authors": [
      "Oshri Halimi",
      "Egor Larionov",
      "Zohar Barzelay",
      "Philipp Herholz",
      "Tuur Stuyck"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11849",
    "title": "Complexity of equilibria in binary public goods games on undirected  graphs",
    "abstract": "We study the complexity of computing equilibria in binary public goods games on undirected graphs. In such a game, players correspond to vertices in a graph and face a binary choice of performing an action, or not. Each player's decision depends only on the number of neighbors in the graph who perform the action and is encoded by a per-player binary pattern. We show that games with decreasing patterns (where players only want to act up to a threshold number of adjacent players doing so) always have a pure Nash equilibrium and that one is reached from any starting profile by following a polynomially bounded sequence of best responses. For non-monotonic patterns of the form $10^k10^*$ (where players want to act alone or alongside $k + 1$ neighbors), we show that it is $\\mathsf{NP}$-hard to decide whether a pure Nash equilibrium exists. We further investigate a generalization of the model that permits ties of varying strength: an edge with integral weight $w$ behaves as $w$ parallel edges. While, in this model, a pure Nash equilibrium still exists for decreasing patters, we show that the task of computing one is $\\mathsf{PLS}$-complete. ",
    "url": "https://arxiv.org/abs/2301.11849",
    "authors": [
      "Max Klimm",
      "Maximilian J. Stahlberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2301.11857",
    "title": "Policy-Value Alignment and Robustness in Search-based Multi-Agent  Learning",
    "abstract": "Large-scale AI systems that combine search and learning have reached super-human levels of performance in game-playing, but have also been shown to fail in surprising ways. The brittleness of such models limits their efficacy and trustworthiness in real-world deployments. In this work, we systematically study one such algorithm, AlphaZero, and identify two phenomena related to the nature of exploration. First, we find evidence of policy-value misalignment -- for many states, AlphaZero's policy and value predictions contradict each other, revealing a tension between accurate move-selection and value estimation in AlphaZero's objective. Further, we find inconsistency within AlphaZero's value function, which causes it to generalize poorly, despite its policy playing an optimal strategy. From these insights we derive VISA-VIS: a novel method that improves policy-value alignment and value robustness in AlphaZero. Experimentally, we show that our method reduces policy-value misalignment by up to 76%, reduces value generalization error by up to 50%, and reduces average value error by up to 55%. ",
    "url": "https://arxiv.org/abs/2301.11857",
    "authors": [
      "Niko A. Grupen",
      "Michael Hanlon",
      "Alexis Hao",
      "Daniel D. Lee",
      "Bart Selman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2301.11903",
    "title": "Uplink Scheduling in Federated Learning: an Importance-Aware Approach  via Graph Representation Learning",
    "abstract": "Federated Learning (FL) has emerged as a promising framework for distributed training of AI-based services, applications, and network procedures in 6G. One of the major challenges affecting the performance and efficiency of 6G wireless FL systems is the massive scheduling of user devices over resource-constrained channels. In this work, we argue that the uplink scheduling of FL client devices is a problem with a rich relational structure. To address this challenge, we propose a novel, energy-efficient, and importance-aware metric for client scheduling in FL applications by leveraging Unsupervised Graph Representation Learning (UGRL). Our proposed approach introduces a relational inductive bias in the scheduling process and does not require the collection of training feedback information from client devices, unlike state-of-the-art importance-aware mechanisms. We evaluate our proposed solution against baseline scheduling algorithms based on recently proposed metrics in the literature. Results show that, when considering scenarios of nodes exhibiting spatial relations, our approach can achieve an average gain of up to 10% in model accuracy and up to 17 times in energy efficiency compared to state-of-the-art importance-aware policies. ",
    "url": "https://arxiv.org/abs/2301.11903",
    "authors": [
      "Marco Skocaj",
      "Pedro Enrique Iturria Rivera",
      "Roberto Verdone",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11912",
    "title": "OccRob: Efficient SMT-Based Occlusion Robustness Verification of Deep  Neural Networks",
    "abstract": "Occlusion is a prevalent and easily realizable semantic perturbation to deep neural networks (DNNs). It can fool a DNN into misclassifying an input image by occluding some segments, possibly resulting in severe errors. Therefore, DNNs planted in safety-critical systems should be verified to be robust against occlusions prior to deployment. However, most existing robustness verification approaches for DNNs are focused on non-semantic perturbations and are not suited to the occlusion case. In this paper, we propose the first efficient, SMT-based approach for formally verifying the occlusion robustness of DNNs. We formulate the occlusion robustness verification problem and prove it is NP-complete. Then, we devise a novel approach for encoding occlusions as a part of neural networks and introduce two acceleration techniques so that the extended neural networks can be efficiently verified using off-the-shelf, SMT-based neural network verification tools. We implement our approach in a prototype called OccRob and extensively evaluate its performance on benchmark datasets with various occlusion variants. The experimental results demonstrate our approach's effectiveness and efficiency in verifying DNNs' robustness against various occlusions, and its ability to generate counterexamples when these DNNs are not robust. ",
    "url": "https://arxiv.org/abs/2301.11912",
    "authors": [
      "Xingwu Guo",
      "Ziwei Zhou",
      "Yueling Zhang",
      "Guy Katz",
      "Min Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11915",
    "title": "Understanding Self-Supervised Pretraining with Part-Aware Representation  Learning",
    "abstract": "In this paper, we are interested in understanding self-supervised pretraining through studying the capability that self-supervised representation pretraining methods learn part-aware representations. The study is mainly motivated by that random views, used in contrastive learning, and random masked (visible) patches, used in masked image modeling, are often about object parts. We explain that contrastive learning is a part-to-whole task: the projection layer hallucinates the whole object representation from the object part representation learned from the encoder, and that masked image modeling is a part-to-part task: the masked patches of the object are hallucinated from the visible patches. The explanation suggests that the self-supervised pretrained encoder is required to understand the object part. We empirically compare the off-the-shelf encoders pretrained with several representative methods on object-level recognition and part-level recognition. The results show that the fully-supervised model outperforms self-supervised models for object-level recognition, and most self-supervised contrastive learning and masked image modeling methods outperform the fully-supervised method for part-level recognition. It is observed that the combination of contrastive learning and masked image modeling further improves the performance. ",
    "url": "https://arxiv.org/abs/2301.11915",
    "authors": [
      "Jie Zhu",
      "Jiyang Qi",
      "Mingyu Ding",
      "Xiaokang Chen",
      "Ping Luo",
      "Xinggang Wang",
      "Wenyu Liu",
      "Leye Wang",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11401",
    "title": "Causal Bandits without Graph Learning",
    "abstract": "We study the causal bandit problem when the causal graph is unknown and develop an efficient algorithm for finding the parent node of the reward node using atomic interventions. We derive the exact equation for the expected number of interventions performed by the algorithm and show that under certain graphical conditions it could perform either logarithmically fast or, under more general assumptions, slower but still sublinearly in the number of variables. We formally show that our algorithm is optimal as it meets the universal lower bound we establish for any algorithm that performs atomic interventions. Finally, we extend our algorithm to the case when the reward node has multiple parents. Using this algorithm together with a standard algorithm from bandit literature leads to improved regret bounds. ",
    "url": "https://arxiv.org/abs/2301.11401",
    "authors": [
      "Mikhail Konobeev",
      "Jalal Etesami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11402",
    "title": "A Hybrid Deep Neural Operator/Finite Element Method for Ice-Sheet  Modeling",
    "abstract": "One of the most challenging and consequential problems in climate modeling is to provide probabilistic projections of sea level rise. A large part of the uncertainty of sea level projections is due to uncertainty in ice sheet dynamics. At the moment, accurate quantification of the uncertainty is hindered by the cost of ice sheet computational models. In this work, we develop a hybrid approach to approximate existing ice sheet computational models at a fraction of their cost. Our approach consists of replacing the finite element model for the momentum equations for the ice velocity, the most expensive part of an ice sheet model, with a Deep Operator Network, while retaining a classic finite element discretization for the evolution of the ice thickness. We show that the resulting hybrid model is very accurate and it is an order of magnitude faster than the traditional finite element model. Further, a distinctive feature of the proposed model compared to other neural network approaches, is that it can handle high-dimensional parameter spaces (parameter fields) such as the basal friction at the bed of the glacier, and can therefore be used for generating samples for uncertainty quantification. We study the impact of hyper-parameters, number of unknowns and correlation length of the parameter distribution on the training and accuracy of the Deep Operator Network on a synthetic ice sheet model. We then target the evolution of the Humboldt glacier in Greenland and show that our hybrid model can provide accurate statistics of the glacier mass loss and can be effectively used to accelerate the quantification of uncertainty. ",
    "url": "https://arxiv.org/abs/2301.11402",
    "authors": [
      "QiZhi He",
      "Mauro Perego",
      "Amanda A. Howard",
      "George Em Karniadakis",
      "Panos Stinis"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2301.11477",
    "title": "Ananke: A Python Package For Causal Inference Using Graphical Models",
    "abstract": "We implement Ananke: an object-oriented Python package for causal inference with graphical models. At the top of our inheritance structure is an easily extensible Graph class that provides an interface to several broadly useful graph-based algorithms and methods for visualization. We use best practices of object-oriented programming to implement subclasses of the Graph superclass that correspond to types of causal graphs that are popular in the current literature. This includes directed acyclic graphs for modeling causally sufficient systems, acyclic directed mixed graphs for modeling unmeasured confounding, and chain graphs for modeling data dependence and interference. Within these subclasses, we implement specialized algorithms for common statistical and causal modeling tasks, such as separation criteria for reading conditional independence, nonparametric identification, and parametric and semiparametric estimation of model parameters. Here, we present a broad overview of the package and example usage for a problem with unmeasured confounding. Up to date documentation is available at \\url{https://ananke.readthedocs.io/en/latest/}. ",
    "url": "https://arxiv.org/abs/2301.11477",
    "authors": [
      "Jaron J. R. Lee",
      "Rohit Bhattacharya",
      "Razieh Nabi",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2301.11556",
    "title": "Conformal inference is (almost) free for neural networks trained with  early stopping",
    "abstract": "Early stopping based on hold-out data is a popular regularization technique designed to mitigate overfitting and increase the predictive accuracy of neural networks. Models trained with early stopping often provide relatively accurate predictions, but they generally still lack precise statistical guarantees unless they are further calibrated using independent hold-out data. This paper addresses the above limitation with conformalized early stopping: a novel method that combines early stopping with conformal calibration while efficiently recycling the same hold-out data. This leads to models that are both accurate and able to provide exact predictive inferences without multiple data splits nor overly conservative adjustments. Practical implementations are developed for different learning tasks -- outlier detection, multi-class classification, regression -- and their competitive performance is demonstrated on real data. ",
    "url": "https://arxiv.org/abs/2301.11556",
    "authors": [
      "Ziyi Liang",
      "Yanfei Zhou",
      "Matteo Sesia"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2301.11559",
    "title": "Enabling Multi-threading in Heterogeneous Quantum-Classical Programming  Models",
    "abstract": "In this paper, we address some of the key limitations to realizing a generic heterogeneous parallel programming model for quantum-classical heterogeneous platforms. We discuss our experience in enabling user-level multi-threading in QCOR as well as challenges that need to be addressed for programming future quantum-classical systems. Specifically, we discuss our design and implementation of introducing C++-based parallel constructs to enable 1) parallel execution of a quantum kernel with std::thread and 2) asynchronous execution with std::async. To do so, we provide a detailed overview of the current implementation of the QCOR programming model and runtime, and discuss how we add 1) thread-safety to some of its user-facing API routines, and 2) increase parallelism in QCOR by removing data races that inhibit multi-threading so as to better utilize available computing resources. We also present preliminary performance results with the Quantum++ back end on a single-node Ryzen9 3900X machine that has 12 physical cores (24 hardware threads) with 128GB of RAM. The results show that running two Bell kernels with 12 threads per kernel in parallel outperforms running the kernels one after the other each with 24 threads (1.63x improvement). In addition, we observe the same trend when running two Shor's algorthm kernels in parallel (1.22x faster than executing the kernels one after the other). It is worth noting that the trends remain the same even when we only use physical cores instead of threads. We believe that our design, implementation, and results will open up an opportunity not only for 1) enabling quicker prototyping of parallel/asynchrony-aware quantum-classical algorithms on quantum circuit simulators in the short-term, but also for 2) realizing a generic heterogeneous parallel programming model for quantum-classical heterogeneous platforms in the long-term. ",
    "url": "https://arxiv.org/abs/2301.11559",
    "authors": [
      "Akihiro Hayashi",
      "Austin Adams",
      "Jeffrey Young",
      "Alexander McCaskey",
      "Eugene Dumitrescu",
      "Vivek Sarkar",
      "Thomas M. Conte"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.11584",
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "abstract": "Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets. ",
    "url": "https://arxiv.org/abs/2301.11584",
    "authors": [
      "Matthew J. Holland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11588",
    "title": "Distributionally Robust Multi-objective Bayesian Optimization under  Uncertain Environments",
    "abstract": "In this study, we address the problem of optimizing multi-output black-box functions under uncertain environments. We formulate this problem as the estimation of the uncertain Pareto-frontier (PF) of a multi-output Bayesian surrogate model with two types of variables: design variables and environmental variables. We consider this problem within the context of Bayesian optimization (BO) under uncertain environments, where the design variables are controllable, whereas the environmental variables are assumed to be random and not controllable. The challenge of this problem is to robustly estimate the PF when the distribution of the environmental variables is unknown, that is, to estimate the PF when the environmental variables are generated from the worst possible distribution. We propose a method for solving the BO problem by appropriately incorporating the uncertainties of the environmental variables and their probability distribution. We demonstrate that the proposed method can find an arbitrarily accurate PF with high probability in a finite number of iterations. We also evaluate the performance of the proposed method through numerical experiments. ",
    "url": "https://arxiv.org/abs/2301.11588",
    "authors": [
      "Yu Inatsu",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11623",
    "title": "Higher-Order Patterns Reveal Causal Timescales of Complex Systems",
    "abstract": "The analysis of temporal networks heavily depends on the analysis of time-respecting paths. However, before being able to model and analyze the time-respecting paths, we have to infer the timescales at which the temporal edges influence each other. In this work we introduce temporal path entropy, an information theoretic measure of temporal networks, with the aim to detect the timescales at which the causal influences occur in temporal networks. The measure can be used on temporal networks as a whole, or separately for each node. We find that the temporal path entropy has a non-trivial dependency on the causal timescales of synthetic and empirical temporal networks. Furthermore, we notice in both synthetic and empirical data that the temporal path entropy tends to decrease at timescales that correspond to the causal interactions. Our results imply that timescales relevant for the dynamics of complex systems can be detected in the temporal networks themselves, by measuring temporal path entropy. This is crucial for the analysis of temporal networks where inherent timescales are unavailable and hard to measure. ",
    "url": "https://arxiv.org/abs/2301.11623",
    "authors": [
      "Luka V. Petrovi\u0107",
      "Anatol Wegner",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.11721",
    "title": "Single-Trajectory Distributionally Robust Reinforcement Learning",
    "abstract": "As a framework for sequential decision-making, Reinforcement Learning (RL) has been regarded as an essential component leading to Artificial General Intelligence (AGI). However, RL is often criticized for having the same training environment as the test one, which also hinders its application in the real world. To mitigate this problem, Distributionally Robust RL (DRRL) is proposed to improve the worst performance in a set of environments that may contain the unknown test environment. Due to the nonlinearity of the robustness goal, most of the previous work resort to the model-based approach, learning with either an empirical distribution learned from the data or a simulator that can be sampled infinitely, which limits their applications in simple dynamics environments. In contrast, we attempt to design a DRRL algorithm that can be trained along a single trajectory, i.e., no repeated sampling from a state. Based on the standard Q-learning, we propose distributionally robust Q-learning with the single trajectory (DRQ) and its average-reward variant named differential DRQ. We provide asymptotic convergence guarantees and experiments for both settings, demonstrating their superiority in the perturbed environments against the non-robust ones. ",
    "url": "https://arxiv.org/abs/2301.11721",
    "authors": [
      "Zhipeng Liang",
      "Xiaoteng Ma",
      "Jose Blanchet",
      "Jiheng Zhang",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11732",
    "title": "Convolutional neural networks for valid and efficient causal inference",
    "abstract": "Convolutional neural networks (CNN) have been successful in machine learning applications. Their success relies on their ability to consider space invariant local features. We consider the use of CNN to fit nuisance models in semiparametric estimation of the average causal effect of a treatment. In this setting, nuisance models are functions of pre-treatment covariates that need to be controlled for. In an application where we want to estimate the effect of early retirement on a health outcome, we propose to use CNN to control for time-structured covariates. Thus, CNN is used when fitting nuisance models explaining the treatment and the outcome. These fits are then combined into an augmented inverse probability weighting estimator yielding efficient and uniformly valid inference. Theoretically, we contribute by providing rates of convergence for CNN equipped with the rectified linear unit activation function and compare it to an existing result for feedforward neural networks. We also show when those rates guarantee uniformly valid inference. A Monte Carlo study is provided where the performance of the proposed estimator is evaluated and compared with other strategies. Finally, we give results on a study of the effect of early retirement on hospitalization using data covering the whole Swedish population. ",
    "url": "https://arxiv.org/abs/2301.11732",
    "authors": [
      "Mohammad Ghasempour",
      "Niloofar Moosavi",
      "Xavier de Luna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.11862",
    "title": "Neural Additive Models for Location Scale and Shape: A Framework for  Interpretable Neural Regression Beyond the Mean",
    "abstract": "Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while maintaining the interpretability of additive models. ",
    "url": "https://arxiv.org/abs/2301.11862",
    "authors": [
      "Anton Thielmann",
      "Ren\u00e9-Marcel Kruse",
      "Thomas Kneib",
      "Benjamin S\u00e4fken"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11871",
    "title": "Exploiting the Generative Adversarial Network Approach to Create a  Synthetic Topography Corneal Image",
    "abstract": "Corneal diseases are the most common eye disorders. Deep learning techniques are used to per-form automated diagnoses of cornea. Deep learning networks require large-scale annotated datasets, which is conceded as a weakness of deep learning. In this work, a method for synthesizing medical images using conditional generative adversarial networks (CGANs), is presented. It also illustrates how produced medical images may be utilized to enrich medical data, improve clinical decisions, and boost the performance of the conventional neural network (CNN) for medical image diagnosis. The study includes using corneal topography captured using a Pentacam device from patients with corneal diseases. The dataset contained 3448 different corneal images. Furthermore, it shows how an unbalanced dataset affects the performance of classifiers, where the data are balanced using the resampling approach. Finally, the results obtained from CNN networks trained on the balanced dataset are compared to those obtained from CNN networks trained on the imbalanced dataset. For performance, the system estimated the diagnosis accuracy, precision, and F1-score metrics. Lastly, some generated images were shown to an expert for evaluation and to see how well experts could identify the type of image and its condition. The expert recognized the image as useful for medical diagnosis and for determining the severity class according to the shape and values, by generating images based on real cases that could be used as new different stages of illness between healthy and unhealthy patients. ",
    "url": "https://arxiv.org/abs/2301.11871",
    "authors": [
      "Samer Kais Jameel",
      "Sezgin Aydin",
      "Nebras H. Ghaeb",
      "Jafar Majidpour",
      "Tarik A. Rashid",
      "Sinan Q. Salih",
      "P. S. JosephNg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11884",
    "title": "Long-range quantum energy teleportation and distribution on a hyperbolic  quantum network",
    "abstract": "Teleporting energy to remote locations is new challenge for quantum information science and technology. Developing a method for transferring local energy in laboratory systems to remote locations will enable non-trivial energy flows in quantum networks. From the perspective of quantum information engineering, we propose a method for distributing local energy to a large number of remote nodes using hyperbolic geometry. Hyperbolic networks are suitable for energy allocation in large quantum networks since the number of nodes grows exponentially. To realise long-range quantum energy teleportation, we propose a hybrid method of quantum state telepotation and quantum energy teleportation. By transmitting local quantum information through quantum teleportation and performing conditional operations on that information, quantum energy teleportation can theoretically be realized independent of geographical distance. The method we present will provide new insights into new applications of future large-scale quantum networks and potential applications of quantum physics to information engineering. ",
    "url": "https://arxiv.org/abs/2301.11884",
    "authors": [
      "Kazuki Ikeda"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:1602.05629",
    "title": "Communication-Efficient Learning of Deep Networks from Decentralized  Data",
    "abstract": " Comments: [v4] Fixes a typo in the FedAvg pseudocode. [v3] Updates the large-scale LSTM experiments, along with other minor changes ",
    "url": "https://arxiv.org/abs/1602.05629",
    "authors": [
      "H. Brendan McMahan",
      "Eider Moore",
      "Daniel Ramage",
      "Seth Hampson",
      "Blaise Ag\u00fcera y Arcas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2006.00339",
    "title": "Rethinking Assumptions in Deep Anomaly Detection",
    "abstract": " Comments: 17 pages; accepted at the ICML 2021 Workshop on Uncertainty & Robustness in Deep Learning; An extended Journal paper of this work has been published in Transactions on Machine Learning Research: arXiv:2205.11474 ",
    "url": "https://arxiv.org/abs/2006.00339",
    "authors": [
      "Lukas Ruff",
      "Robert A. Vandermeulen",
      "Billy Joe Franks",
      "Klaus-Robert M\u00fcller",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.09845",
    "title": "A Distributed Privacy-Preserving Learning Dynamics in General Social  Networks",
    "abstract": " Title: A Distributed Privacy-Preserving Learning Dynamics in General Social  Networks ",
    "url": "https://arxiv.org/abs/2011.09845",
    "authors": [
      "Youming Tao",
      "Shuzhen Chen",
      "Feng Li",
      "Dongxiao Yu",
      "Jiguo Yu",
      "Hao Sheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2012.00675",
    "title": "Topological Learning for Brain Networks",
    "abstract": " Comments: 31 pages, 14 figures, 4 tables, code at this https URL ",
    "url": "https://arxiv.org/abs/2012.00675",
    "authors": [
      "Tananun Songdechakraiwut",
      "Moo K. Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2202.06545",
    "title": "Provably Efficient Causal Model-Based Reinforcement Learning for  Systematic Generalization",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2202.06545",
    "authors": [
      "Mirco Mutti",
      "Riccardo De Santi",
      "Emanuele Rossi",
      "Juan Felipe Calderon",
      "Michael Bronstein",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06593",
    "title": "Statistical Inference for the Dynamic Time Warping Distance, with  Application to Abnormal Time-Series Detection",
    "abstract": " Title: Statistical Inference for the Dynamic Time Warping Distance, with  Application to Abnormal Time-Series Detection ",
    "url": "https://arxiv.org/abs/2202.06593",
    "authors": [
      "Vo Nguyen Le Duy",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.00076",
    "title": "Robust Multi-Agent Bandits Over Undirected Graphs",
    "abstract": " Title: Robust Multi-Agent Bandits Over Undirected Graphs ",
    "url": "https://arxiv.org/abs/2203.00076",
    "authors": [
      "Daniel Vial",
      "Sanjay Shakkottai",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.06274",
    "title": "Overparameterized Linear Regression under Adversarial Attacks",
    "abstract": " Title: Overparameterized Linear Regression under Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2204.06274",
    "authors": [
      "Ant\u00f4nio H. Ribeiro",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2205.06891",
    "title": "Unsupervised Representation Learning for 3D MRI Super Resolution with  Degradation Adaptation",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.06891",
    "authors": [
      "Jianan Liu",
      "Hao Li",
      "Tao Huang",
      "Euijoon Ahn",
      "Kang Han",
      "Adeel Razi",
      "Wei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2205.11775",
    "title": "Constrained Monotonic Neural Networks",
    "abstract": " Title: Constrained Monotonic Neural Networks ",
    "url": "https://arxiv.org/abs/2205.11775",
    "authors": [
      "Davor Runje",
      "Sharath M. Shankaranarayana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.03314",
    "title": "Integrating Random Effects in Deep Neural Networks",
    "abstract": " Comments: 53 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2206.03314",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07697",
    "title": "MACE: Higher Order Equivariant Message Passing Neural Networks for Fast  and Accurate Force Fields",
    "abstract": " Comments: Advances in Neural Information Processing Systems, 2022 ",
    "url": "https://arxiv.org/abs/2206.07697",
    "authors": [
      "Ilyes Batatia",
      "D\u00e1vid P\u00e9ter Kov\u00e1cs",
      "Gregor N. C. Simm",
      "Christoph Ortner",
      "G\u00e1bor Cs\u00e1nyi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2206.10265",
    "title": "KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in  Low-Resource NLP",
    "abstract": " Comments: Accepted by ICLR 2023 main track at this https URL ",
    "url": "https://arxiv.org/abs/2206.10265",
    "authors": [
      "Yufei Wang",
      "Jiayi Zheng",
      "Can Xu",
      "Xiubo Geng",
      "Tao Shen",
      "Chongyang Tao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.11386",
    "title": "Bi-stochastically normalized graph Laplacian: convergence to manifold  Laplacian and robustness to outlier noise",
    "abstract": " Title: Bi-stochastically normalized graph Laplacian: convergence to manifold  Laplacian and robustness to outlier noise ",
    "url": "https://arxiv.org/abs/2206.11386",
    "authors": [
      "Xiuyuan Cheng",
      "Boris Landa"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.03615",
    "title": "Learning and generalization of one-hidden-layer neural networks, going  beyond standard Gaussian data",
    "abstract": " Title: Learning and generalization of one-hidden-layer neural networks, going  beyond standard Gaussian data ",
    "url": "https://arxiv.org/abs/2207.03615",
    "authors": [
      "Hongkang Li",
      "Shuai Zhang",
      "Meng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.06269",
    "title": "Probabilistic Variational Causal Effect as A new Theory for Causal  Reasoning",
    "abstract": " Comments: 59 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.06269",
    "authors": [
      "Usef Faghihi",
      "Amir Saki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2208.07572",
    "title": "Fine-Grained Complexity Lower Bounds for Families of Dynamic Graphs",
    "abstract": " Comments: Accepted at ESA'22 ",
    "url": "https://arxiv.org/abs/2208.07572",
    "authors": [
      "Monika Henzinger",
      "Ami Paz",
      "A. R. Sricharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2208.14220",
    "title": "Similarity-based Link Prediction from Modular Compression of Network  Flows",
    "abstract": " Comments: In: Proceedings of the First Learning on Graphs Conference, PMLR 198:52:1-52:18, 2022. Available at this https URL ",
    "url": "https://arxiv.org/abs/2208.14220",
    "authors": [
      "Christopher Bl\u00f6cker",
      "Jelena Smiljani\u0107",
      "Ingo Scholtes",
      "Martin Rosvall"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2209.06620",
    "title": "Distributionally Robust Offline Reinforcement Learning with Linear  Function Approximation",
    "abstract": " Comments: First two authors contribute equally ",
    "url": "https://arxiv.org/abs/2209.06620",
    "authors": [
      "Xiaoteng Ma",
      "Zhipeng Liang",
      "Jose Blanchet",
      "Mingwen Liu",
      "Li Xia",
      "Jiheng Zhang",
      "Qianchuan Zhao",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.09464",
    "title": "Rethinking Dimensionality Reduction in Grid-based 3D Object Detection",
    "abstract": " Title: Rethinking Dimensionality Reduction in Grid-based 3D Object Detection ",
    "url": "https://arxiv.org/abs/2209.09464",
    "authors": [
      "Dihe Huang",
      "Ying Chen",
      "Yikang Ding",
      "Jinli Liao",
      "Jianlin Liu",
      "Kai Wu",
      "Qiang Nie",
      "Yong Liu",
      "Chengjie Wang",
      "Zhiheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.12265",
    "title": "Cooperative Sensing and Heterogeneous Information Fusion in VCPS: A  Multi-agent Deep Reinforcement Learning Approach",
    "abstract": " Title: Cooperative Sensing and Heterogeneous Information Fusion in VCPS: A  Multi-agent Deep Reinforcement Learning Approach ",
    "url": "https://arxiv.org/abs/2209.12265",
    "authors": [
      "Xincao Xu",
      "Kai Liu",
      "Penglin Dai",
      "Ruitao Xie",
      "Jingjing Cao",
      "Jiangtao Luo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.13513",
    "title": "DBGSL: Dynamic Brain Graph Structure Learning",
    "abstract": " Title: DBGSL: Dynamic Brain Graph Structure Learning ",
    "url": "https://arxiv.org/abs/2209.13513",
    "authors": [
      "Alexander Campbell",
      "Antonio Giuliano Zippo",
      "Luca Passamonti",
      "Nicola Toschi",
      "Pietro Lio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.13971",
    "title": "3D Neural Sculpting (3DNS): Editing Neural Signed Distance Functions",
    "abstract": " Comments: 14 pages, 10 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2209.13971",
    "authors": [
      "Petros Tzathas",
      "Petros Maragos",
      "Anastasios Roussos"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.15042",
    "title": "Generalizability of Adversarial Robustness Under Distribution Shifts",
    "abstract": " Comments: A preliminary version was accepted to the Practical-DL Workshop at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2209.15042",
    "authors": [
      "Kumail Alhamoud",
      "Hasan Abed Al Kader Hammoud",
      "Motasem Alfarra",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01742",
    "title": "CADet: Fully Self-Supervised Out-Of-Distribution Detection With  Contrastive Learning",
    "abstract": " Title: CADet: Fully Self-Supervised Out-Of-Distribution Detection With  Contrastive Learning ",
    "url": "https://arxiv.org/abs/2210.01742",
    "authors": [
      "Charles Guille-Escuret",
      "Pau Rodriguez",
      "David Vazquez",
      "Ioannis Mitliagkas",
      "Joao Monteiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05382",
    "title": "Uplifting Message Passing Neural Network with Graph Original Information",
    "abstract": " Comments: 13 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.05382",
    "authors": [
      "Xiao Liu",
      "Lijun Zhang",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15045",
    "title": "An Optimal Patrolling Strategy for Tree Networks",
    "abstract": " Title: An Optimal Patrolling Strategy for Tree Networks ",
    "url": "https://arxiv.org/abs/2210.15045",
    "authors": [
      "Thomas Lidbetter",
      "Thuy Bui"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.16242",
    "title": "Differential Privacy has Bounded Impact on Fairness in Classification",
    "abstract": " Comments: 28 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.16242",
    "authors": [
      "Paul Mangold",
      "Micha\u00ebl Perrot",
      "Aur\u00e9lien Bellet",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.09945",
    "title": "SparseVLR: A Framework for Verified Locally Robust Sparse Neural  Networks Search",
    "abstract": " Comments: 17 pages, 9 tables, 7 figures ",
    "url": "https://arxiv.org/abs/2211.09945",
    "authors": [
      "Sawinder Kaur",
      "Asif Salekin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10151",
    "title": "Asymptotically Tight Bounds on the Time Complexity of Broadcast and its  Variants in Dynamic Networks",
    "abstract": " Comments: 25 pages, 8 figures, to be published in ITCS'23 ",
    "url": "https://arxiv.org/abs/2211.10151",
    "authors": [
      "Antoine El-Hayek",
      "Monika Henzinger",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.00585",
    "title": "Soft Labels for Rapid Satellite Object Detection",
    "abstract": " Comments: 5 Pages, 5 Figures, 1 Tables, 22 References ",
    "url": "https://arxiv.org/abs/2212.00585",
    "authors": [
      "Matthew Ciolino",
      "Grant Rosario",
      "David Noever"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05613",
    "title": "A Study of Slang Representation Methods",
    "abstract": " Title: A Study of Slang Representation Methods ",
    "url": "https://arxiv.org/abs/2212.05613",
    "authors": [
      "Aravinda Kolla",
      "Filip Ilievski",
      "H\u00f4ng-\u00c2n Sandlin",
      "Alain Mermoud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06925",
    "title": "On the Relationship Between Explanation and Prediction: A Causal View",
    "abstract": " Title: On the Relationship Between Explanation and Prediction: A Causal View ",
    "url": "https://arxiv.org/abs/2212.06925",
    "authors": [
      "Amir-Hossein Karimi",
      "Krikamol Muandet",
      "Simon Kornblith",
      "Bernhard Sch\u00f6lkopf",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.07310",
    "title": "MR.Brick: Designing A Remote Mixed-reality Educational Game System for  Promoting Children's Social & Collaborative Skills",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2301.07310",
    "authors": [
      "Yudan Wu",
      "Shanhe You",
      "Zixuan Guo",
      "Xiangyang Li",
      "Guyue Zhou",
      "Jiangtao Gong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2301.08951",
    "title": "Time-Conditioned Generative Modeling of Object-Centric Representations  for Video Decomposition and Prediction",
    "abstract": " Title: Time-Conditioned Generative Modeling of Object-Centric Representations  for Video Decomposition and Prediction ",
    "url": "https://arxiv.org/abs/2301.08951",
    "authors": [
      "Chengmin Gao",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.10787",
    "title": "Unravelling physics beyond the standard model with classical and quantum  anomaly detection",
    "abstract": " Comments: 15 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2301.10787",
    "authors": [
      "Julian Schuhmacher",
      "Laura Boggia",
      "Vasilis Belis",
      "Ema Puljak",
      "Michele Grossi",
      "Maurizio Pierini",
      "Sofia Vallecorsa",
      "Francesco Tacchino",
      "Panagiotis Barkoutsos",
      "Ivano Tavernelli"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  }
]