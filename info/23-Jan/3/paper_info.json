[
  {
    "id": "arXiv:2301.00007",
    "title": "Selected aspects of complex, hypercomplex and fuzzy neural networks",
    "abstract": "This short report reviews the current state of the research and methodology on theoretical and practical aspects of Artificial Neural Networks (ANN). It was prepared to gather state-of-the-art knowledge needed to construct complex, hypercomplex and fuzzy neural networks. The report reflects the individual interests of the authors and, by now means, cannot be treated as a comprehensive review of the ANN discipline. Considering the fast development of this field, it is currently impossible to do a detailed review of a considerable number of pages. The report is an outcome of the Project 'The Strategic Research Partnership for the mathematical aspects of complex, hypercomplex and fuzzy neural networks' meeting at the University of Warmia and Mazury in Olsztyn, Poland, organized in September 2022. ",
    "url": "https://arxiv.org/abs/2301.00007",
    "authors": [
      "Agnieszka Niemczynowicz",
      "Rados\u0142aw A. Kycia",
      "Maciej Jaworski",
      "Artur Siemaszko",
      "Jose M. Calabuig",
      "Lluis M. Garc\u00eda-Raffi",
      "Baruch Schneider",
      "Diana Berseghyan",
      "Irina Perfiljeva",
      "Vilem Novak",
      "Piotr Artiemjew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00011",
    "title": "eVAE: Evolutionary Variational Autoencoder",
    "abstract": "The surrogate loss of variational autoencoders (VAEs) poses various challenges to their training, inducing the imbalance between task fitting and representation inference. To avert this, the existing strategies for VAEs focus on adjusting the tradeoff by introducing hyperparameters, deriving a tighter bound under some mild assumptions, or decomposing the loss components per certain neural settings. VAEs still suffer from uncertain tradeoff learning.We propose a novel evolutionary variational autoencoder (eVAE) building on the variational information bottleneck (VIB) theory and integrative evolutionary neural learning. eVAE integrates a variational genetic algorithm into VAE with variational evolutionary operators including variational mutation, crossover, and evolution. Its inner-outer-joint training mechanism synergistically and dynamically generates and updates the uncertain tradeoff learning in the evidence lower bound (ELBO) without additional constraints. Apart from learning a lossy compression and representation of data under the VIB assumption, eVAE presents an evolutionary paradigm to tune critical factors of VAEs and deep neural networks and addresses the premature convergence and random search problem by integrating evolutionary optimization into deep learning. Experiments show that eVAE addresses the KL-vanishing problem for text generation with low reconstruction loss, generates all disentangled factors with sharp images, and improves the image generation quality,respectively. eVAE achieves better reconstruction loss, disentanglement, and generation-inference balance than its competitors. ",
    "url": "https://arxiv.org/abs/2301.00011",
    "authors": [
      "Zhangkai Wu",
      "Longbing Cao",
      "Lei Qi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00012",
    "title": "GANExplainer: GAN-based Graph Neural Networks Explainer",
    "abstract": "With the rapid deployment of graph neural networks (GNNs) based techniques into a wide range of applications such as link prediction, node classification, and graph classification the explainability of GNNs has become an indispensable component for predictive and trustworthy decision-making. Thus, it is critical to explain why graph neural network (GNN) makes particular predictions for them to be believed in many applications. Some GNNs explainers have been proposed recently. However, they lack to generate accurate and real explanations. To mitigate these limitations, we propose GANExplainer, based on Generative Adversarial Network (GAN) architecture. GANExplainer is composed of a generator to create explanations and a discriminator to assist with the Generator development. We investigate the explanation accuracy of our models by comparing the performance of GANExplainer with other state-of-the-art methods. Our empirical results on synthetic datasets indicate that GANExplainer improves explanation accuracy by up to 35\\% compared to its alternatives. ",
    "url": "https://arxiv.org/abs/2301.00012",
    "authors": [
      "Yiqiao Li",
      "Jianlong Zhou",
      "Boyuan Zheng",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00015",
    "title": "Self-organization Preserved Graph Structure Learning with Principle of  Relevant Information",
    "abstract": "Most Graph Neural Networks follow the message-passing paradigm, assuming the observed structure depicts the ground-truth node relationships. However, this fundamental assumption cannot always be satisfied, as real-world graphs are always incomplete, noisy, or redundant. How to reveal the inherent graph structure in a unified way remains under-explored. We proposed PRI-GSL, a Graph Structure Learning framework guided by the Principle of Relevant Information, providing a simple and unified framework for identifying the self-organization and revealing the hidden structure. PRI-GSL learns a structure that contains the most relevant yet least redundant information quantified by von Neumann entropy and Quantum Jensen-Shannon divergence. PRI-GSL incorporates the evolution of quantum continuous walk with graph wavelets to encode node structural roles, showing in which way the nodes interplay and self-organize with the graph structure. Extensive experiments demonstrate the superior effectiveness and robustness of PRI-GSL. ",
    "url": "https://arxiv.org/abs/2301.00015",
    "authors": [
      "Qingyun Sun",
      "Jianxin Li",
      "Beining Yang",
      "Xingcheng Fu",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00036",
    "title": "Modified Query Expansion Through Generative Adversarial Networks for  Information Extraction in E-Commerce",
    "abstract": "This work addresses an alternative approach for query expansion (QE) using a generative adversarial network (GAN) to enhance the effectiveness of information search in e-commerce. We propose a modified QE conditional GAN (mQE-CGAN) framework, which resolves keywords by expanding the query with a synthetically generated query that proposes semantic information from text input. We train a sequence-to-sequence transformer model as the generator to produce keywords and use a recurrent neural network model as the discriminator to classify an adversarial output with the generator. With the modified CGAN framework, various forms of semantic insights gathered from the query document corpus are introduced to the generation process. We leverage these insights as conditions for the generator model and discuss their effectiveness for the query expansion task. Our experiments demonstrate that the utilization of condition structures within the mQE-CGAN framework can increase the semantic similarity between generated sequences and reference documents up to nearly 10% compared to baseline models ",
    "url": "https://arxiv.org/abs/2301.00036",
    "authors": [
      "Altan Cakir",
      "Mert Gurkan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.00051",
    "title": "Learning from Guided Play: Improving Exploration for Adversarial  Imitation Learning with Simple Auxiliary Tasks",
    "abstract": "Adversarial imitation learning (AIL) has become a popular alternative to supervised imitation learning that reduces the distribution shift suffered by the latter. However, AIL requires effective exploration during an online reinforcement learning phase. In this work, we show that the standard, naive approach to exploration can manifest as a suboptimal local maximum if a policy learned with AIL sufficiently matches the expert distribution without fully learning the desired task. This can be particularly catastrophic for manipulation tasks, where the difference between an expert and a non-expert state-action pair is often subtle. We present Learning from Guided Play (LfGP), a framework in which we leverage expert demonstrations of multiple exploratory, auxiliary tasks in addition to a main task. The addition of these auxiliary tasks forces the agent to explore states and actions that standard AIL may learn to ignore. Additionally, this particular formulation allows for the reusability of expert data between main tasks. Our experimental results in a challenging multitask robotic manipulation domain indicate that LfGP significantly outperforms both AIL and behaviour cloning, while also being more expert sample efficient than these baselines. To explain this performance gap, we provide further analysis of a toy problem that highlights the coupling between a local maximum and poor exploration, and also visualize the differences between the learned models from AIL and LfGP. ",
    "url": "https://arxiv.org/abs/2301.00051",
    "authors": [
      "Trevor Ablett",
      "Bryan Chan",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.00104",
    "title": "Separating Computational and Statistical Differential Privacy (Under  Plausible Assumptions)",
    "abstract": "Computational differential privacy (CDP) is a natural relaxation of the standard notion of (statistical) differential privacy (SDP) proposed by Beimel, Nissim, and Omri (CRYPTO 2008) and Mironov, Pandey, Reingold, and Vadhan (CRYPTO 2009). In contrast to SDP, CDP only requires privacy guarantees to hold against computationally-bounded adversaries rather than computationally-unbounded statistical adversaries. Despite the question being raised explicitly in several works (e.g., Bun, Chen, and Vadhan, TCC 2016), it has remained tantalizingly open whether there is any task achievable with the CDP notion but not the SDP notion. Even a candidate such task is unknown. Indeed, it is even unclear what the truth could be! In this work, we give the first construction of a task achievable with the CDP notion but not the SDP notion. More specifically, under strong but plausible cryptographic assumptions, we construct a task for which there exists an $\\varepsilon$-CDP mechanism with $\\varepsilon = O(1)$ achieving $1-o(1)$ utility, but any $(\\varepsilon, \\delta)$-SDP mechanism, including computationally unbounded ones, that achieves a constant utility must use either a super-constant $\\varepsilon$ or a non-negligible $\\delta$. To prove this, we introduce a new approach for showing that a mechanism satisfies CDP: first we show that a mechanism is \"private\" against a certain class of decision tree adversaries, and then we use cryptographic constructions to \"lift\" this into privacy against computational adversaries. We believe this approach could be useful to devise further tasks separating CDP from SDP. ",
    "url": "https://arxiv.org/abs/2301.00104",
    "authors": [
      "Badih Ghazi",
      "Rahul Ilango",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2301.00106",
    "title": "Physics-informed Neural Networks approach to solve the Blasius function",
    "abstract": "Deep learning techniques with neural networks have been used effectively in computational fluid dynamics (CFD) to obtain solutions to nonlinear differential equations. This paper presents a physics-informed neural network (PINN) approach to solve the Blasius function. This method eliminates the process of changing the non-linear differential equation to an initial value problem. Also, it tackles the convergence issue arising in the conventional series solution. It is seen that this method produces results that are at par with the numerical and conventional methods. The solution is extended to the negative axis to show that PINNs capture the singularity of the function at $\\eta=-5.69$ ",
    "url": "https://arxiv.org/abs/2301.00106",
    "authors": [
      "Greeshma Krishna",
      "Malavika S Nair",
      "Pramod P Nair",
      "Anil Lal S"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2301.00108",
    "title": "Targeted k-node Collapse Problem: Towards Understanding the Robustness  of Local k-core Structure",
    "abstract": "The concept of k-core, which indicates the largest induced subgraph where each node has k or more neighbors, plays a significant role in measuring the cohesiveness and the engagement of a network, and it is exploited in diverse applications, e.g., network analysis, anomaly detection, community detection, etc. Recent works have demonstrated the vulnerability of k-core under malicious perturbations which focuses on removing the minimal number of edges to make a whole k-core structure collapse. However, to the best of our knowledge, there is no existing research concentrating on how many edges should be removed at least to make an arbitrary node in k-core collapse. Therefore, in this paper, we make the first attempt to study the Targeted k-node Collapse Problem (TNCP) with four novel contributions. Firstly, we offer the general definition of TNCP problem with the proof of its NP-hardness. Secondly, in order to address the TNCP problem, we propose a heuristic algorithm named TNC and its improved version named ATNC for implementations on large-scale networks. After that, the experiments on 16 real-world networks across various domains verify the superiority of our proposed algorithms over 4 baseline methods along with detailed comparisons and analyses. Finally, the significance of TNCP problem for precisely evaluating the resilience of k-core structures in networks is validated. ",
    "url": "https://arxiv.org/abs/2301.00108",
    "authors": [
      "Yuqian Lv",
      "Bo Zhou",
      "Jinhuan Wang",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.00114",
    "title": "Skeletal Video Anomaly Detection using Deep Learning: Survey, Challenges  and Future Directions",
    "abstract": "The existing methods for video anomaly detection mostly utilize videos containing identifiable facial and appearance-based features. The use of videos with identifiable faces raises privacy concerns, especially when used in a hospital or community-based setting. Appearance-based features can also be sensitive to pixel-based noise, straining the anomaly detection methods to model the changes in the background and making it difficult to focus on the actions of humans in the foreground. Structural information in the form of skeletons describing the human motion in the videos is privacy-protecting and can overcome some of the problems posed by appearance-based features. In this paper, we present a survey of privacy-protecting deep learning anomaly detection methods using skeletons extracted from videos. We present a novel taxonomy of algorithms based on the various learning approaches. We conclude that skeleton-based approaches for anomaly detection can be a plausible privacy-protecting alternative for video anomaly detection. Lastly, we identify major open research questions and provide guidelines to address them. ",
    "url": "https://arxiv.org/abs/2301.00114",
    "authors": [
      "Pratik K. Mishra",
      "Alex Mihailidis",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00122",
    "title": "Hair and Scalp Disease Detection using Machine Learning and Image  Processing",
    "abstract": "Almost 80 million Americans suffer from hair loss due to aging, stress, medication, or genetic makeup. Hair and scalp-related diseases often go unnoticed in the beginning. Sometimes, a patient cannot differentiate between hair loss and regular hair fall. Diagnosing hair-related diseases is time-consuming as it requires professional dermatologists to perform visual and medical tests. Because of that, the overall diagnosis gets delayed, which worsens the severity of the illness. Due to the image-processing ability, neural network-based applications are used in various sectors, especially healthcare and health informatics, to predict deadly diseases like cancers and tumors. These applications assist clinicians and patients and provide an initial insight into early-stage symptoms. In this study, we used a deep learning approach that successfully predicts three main types of hair loss and scalp-related diseases: alopecia, psoriasis, and folliculitis. However, limited study in this area, unavailability of a proper dataset, and degree of variety among the images scattered over the internet made the task challenging. 150 images were obtained from various sources and then preprocessed by denoising, image equalization, enhancement, and data balancing, thereby minimizing the error rate. After feeding the processed data into the 2D convolutional neural network (CNN) model, we obtained overall training accuracy of 96.2%, with a validation accuracy of 91.1%. The precision and recall score of alopecia, psoriasis, and folliculitis are 0.895, 0.846, and 1.0, respectively. We also created a dataset of the scalp images for future prospective researchers. ",
    "url": "https://arxiv.org/abs/2301.00122",
    "authors": [
      "Mrinmoy Roy",
      "Anica Tasnim Protity"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00131",
    "title": "Guided Hybrid Quantization for Object detection in Multimodal Remote  Sensing Imagery via One-to-one Self-teaching",
    "abstract": "Considering the computation complexity, we propose a Guided Hybrid Quantization with One-to-one Self-Teaching (GHOST}) framework. More concretely, we first design a structure called guided quantization self-distillation (GQSD), which is an innovative idea for realizing lightweight through the synergy of quantization and distillation. The training process of the quantization model is guided by its full-precision model, which is time-saving and cost-saving without preparing a huge pre-trained model in advance. Second, we put forward a hybrid quantization (HQ) module to obtain the optimal bit width automatically under a constrained condition where a threshold for distribution distance between the center and samples is applied in the weight value search space. Third, in order to improve information transformation, we propose a one-to-one self-teaching (OST) module to give the student network a ability of self-judgment. A switch control machine (SCM) builds a bridge between the student network and teacher network in the same location to help the teacher to reduce wrong guidance and impart vital knowledge to the student. This distillation method allows a model to learn from itself and gain substantial improvement without any additional supervision. Extensive experiments on a multimodal dataset (VEDAI) and single-modality datasets (DOTA, NWPU, and DIOR) show that object detection based on GHOST outperforms the existing detectors. The tiny parameters (<9.7 MB) and Bit-Operations (BOPs) (<2158 G) compared with any remote sensing-based, lightweight or distillation-based algorithms demonstrate the superiority in the lightweight design domain. Our code and model will be released at https://github.com/icey-zhang/GHOST. ",
    "url": "https://arxiv.org/abs/2301.00131",
    "authors": [
      "Jiaqing Zhang",
      "Jie Lei",
      "Weiying Xie",
      "Yunsong Li",
      "Xiuping Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00134",
    "title": "Exploring the Use of Data-Driven Approaches for Anomaly Detection in the  Internet of Things (IoT) Environment",
    "abstract": "The Internet of Things (IoT) is a system that connects physical computing devices, sensors, software, and other technologies. Data can be collected, transferred, and exchanged with other devices over the network without requiring human interactions. One challenge the development of IoT faces is the existence of anomaly data in the network. Therefore, research on anomaly detection in the IoT environment has become popular and necessary in recent years. This survey provides an overview to understand the current progress of the different anomaly detection algorithms and how they can be applied in the context of the Internet of Things. In this survey, we categorize the widely used anomaly detection machine learning and deep learning techniques in IoT into three types: clustering-based, classification-based, and deep learning based. For each category, we introduce some state-of-the-art anomaly detection methods and evaluate the advantages and limitations of each technique. ",
    "url": "https://arxiv.org/abs/2301.00134",
    "authors": [
      "Eleonora Achiluzzi",
      "Menglu Li",
      "Md Fahd Al Georgy",
      "Rasha Kashef"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00141",
    "title": "Self-Activating Neural Ensembles for Continual Reinforcement Learning",
    "abstract": "The ability for an agent to continuously learn new skills without catastrophically forgetting existing knowledge is of critical importance for the development of generally intelligent agents. Most methods devised to address this problem depend heavily on well-defined task boundaries, and thus depend on human supervision. Our task-agnostic method, Self-Activating Neural Ensembles (SANE), uses a modular architecture designed to avoid catastrophic forgetting without making any such assumptions. At the beginning of each trajectory, a module in the SANE ensemble is activated to determine the agent's next policy. During training, new modules are created as needed and only activated modules are updated to ensure that unused modules remain unchanged. This system enables our method to retain and leverage old skills, while growing and learning new ones. We demonstrate our approach on visually rich procedurally generated environments. ",
    "url": "https://arxiv.org/abs/2301.00141",
    "authors": [
      "Sam Powers",
      "Eliot Xing",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00145",
    "title": "Attentional Graph Convolutional Network for Structure-aware Audio-Visual  Scene Classification",
    "abstract": "Audio-Visual scene understanding is a challenging problem due to the unstructured spatial-temporal relations that exist in the audio signals and spatial layouts of different objects and various texture patterns in the visual images. Recently, many studies have focused on abstracting features from convolutional neural networks while the learning of explicit semantically relevant frames of sound signals and visual images has been overlooked. To this end, we present an end-to-end framework, namely attentional graph convolutional network (AGCN), for structure-aware audio-visual scene representation. First, the spectrogram of sound and input image is processed by a backbone network for feature extraction. Then, to build multi-scale hierarchical information of input features, we utilize an attention fusion mechanism to aggregate features from multiple layers of the backbone network. Notably, to well represent the salient regions and contextual information of audio-visual inputs, the salient acoustic graph (SAG) and contextual acoustic graph (CAG), salient visual graph (SVG), and contextual visual graph (CVG) are constructed for the audio-visual scene representation. Finally, the constructed graphs pass through a graph convolutional network for structure-aware audio-visual scene recognition. Extensive experimental results on the audio, visual and audio-visual scene recognition datasets show that promising results have been achieved by the AGCN methods. Visualizing graphs on the spectrograms and images have been presented to show the effectiveness of proposed CAG/SAG and CVG/SVG that could focus on the salient and semantic relevant regions. ",
    "url": "https://arxiv.org/abs/2301.00145",
    "authors": [
      "Liguang Zhou",
      "Yuhongze Zhou",
      "Xiaonan Qi",
      "Junjie Hu",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00146",
    "title": "Peer Learning for Unbiased Scene Graph Generation",
    "abstract": "In this paper, we propose a novel framework dubbed peer learning to deal with the problem of biased scene graph generation (SGG). This framework uses predicate sampling and consensus voting (PSCV) to encourage different peers to learn from each other, improving model diversity and mitigating bias in SGG. To address the heavily long-tailed distribution of predicate classes, we propose to use predicate sampling to divide and conquer this issue. As a result, the model is less biased and makes more balanced predicate predictions. Specifically, one peer may not be sufficiently diverse to discriminate between different levels of predicate distributions. Therefore, we sample the data distribution based on frequency of predicates into sub-distributions, selecting head, body, and tail classes to combine and feed to different peers as complementary predicate knowledge during the training process. The complementary predicate knowledge of these peers is then ensembled utilizing a consensus voting strategy, which simulates a civilized voting process in our society that emphasizes the majority opinion and diminishes the minority opinion. This approach ensures that the learned representations of each peer are optimally adapted to the various data distributions. Extensive experiments on the Visual Genome dataset demonstrate that PSCV outperforms previous methods. We have established a new state-of-the-art (SOTA) on the SGCls task by achieving a mean of \\textbf{31.6}. ",
    "url": "https://arxiv.org/abs/2301.00146",
    "authors": [
      "Liguang Zhou",
      "Junjie Hu",
      "Yuhongze Zhou",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00153",
    "title": "Knowledge-Based Dataset for Training PE Malware Detection Models",
    "abstract": "Ontologies are a standard for semantic schemata in many knowledge-intensive domains of human interest. They are now becoming increasingly important also in areas until very recently dominated by subsymbolic representations and machine-learning-based data processing. One such area is information security, and more specifically malware detection. We propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE, Windows binary format) malware files. The ontology was inspired by the structure of the data in the EMBER dataset and it currently covers the data intended for static malware analysis. With this proposal, we hope to achieve: a) a unified semantic representation for PE malware datasets that are available or will be published in the future; (b) applicability of symbolic, neural-symbolic, or otherwise explainable approaches in the PE Malware domain that may lead to improved interpretability of results which may now be characterized by the terms defined in the ontology; and (c)by joint publishing of semantically treated EMBER data, including fractional datasets, also improved reproducibility of experiments. ",
    "url": "https://arxiv.org/abs/2301.00153",
    "authors": [
      "Peter \u0160vec",
      "\u0160tefan Balogh",
      "Martin Homola",
      "J\u00e1n K\u013euka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00157",
    "title": "Ponder: Point Cloud Pre-training via Neural Rendering",
    "abstract": "We propose a novel approach to self-supervised learning of point cloud representations by differentiable neural rendering. Motivated by the fact that informative point cloud features should be able to encode rich geometry and appearance cues and render realistic images, we train a point-cloud encoder within a devised point-based neural renderer by comparing the rendered images with real images on massive RGB-D data. The learned point-cloud encoder can be easily integrated into various downstream tasks, including not only high-level tasks like 3D detection and segmentation, but low-level tasks like 3D reconstruction and image synthesis. Extensive experiments on various tasks demonstrate the superiority of our approach compared to existing pre-training methods. ",
    "url": "https://arxiv.org/abs/2301.00157",
    "authors": [
      "Di Huang",
      "Sida Peng",
      "Tong He",
      "Xiaowei Zhou",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00158",
    "title": "robust synergistic hybrid feedback",
    "abstract": "Synergistic hybrid feedback refers to a collection of feedback laws that allow for global asymptotic stabilization of a compact set through the following switching logic: given a collection of Lyapunov functions that are indexed by a logic variable, whenever the currently selected Lyapunov function exceeds the value of another function in the collection by a given margin, then a switch to the corresponding feedback law is triggered. This kind of feedback has been under development over the past decade and it has led to multiple solutions for global asymptotic stabilization on compact manifolds. The contributions of this paper include a synergistic controller design in which the logic variable is not necessarily constant between jumps, a synergistic hybrid feedback that is able to tackle the presence of parametric uncertainty, backstepping of adaptive synergistic hybrid feedbacks, and a demonstration of the proposed solutions to the problem of global obstacle avoidance. ",
    "url": "https://arxiv.org/abs/2301.00158",
    "authors": [
      "Pedro Casau",
      "Ricardo G. Sanfelice",
      "Carlos Silvestre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.00169",
    "title": "Generative Graph Neural Networks for Link Prediction",
    "abstract": "Inferring missing links or detecting spurious ones based on observed graphs, known as link prediction, is a long-standing challenge in graph data analysis. With the recent advances in deep learning, graph neural networks have been used for link prediction and have achieved state-of-the-art performance. Nevertheless, existing methods developed for this purpose are typically discriminative, computing features of local subgraphs around two neighboring nodes and predicting potential links between them from the perspective of subgraph classification. In this formalism, the selection of enclosing subgraphs and heuristic structural features for subgraph classification significantly affects the performance of the methods. To overcome this limitation, this paper proposes a novel and radically different link prediction algorithm based on the network reconstruction theory, called GraphLP. Instead of sampling positive and negative links and heuristically computing the features of their enclosing subgraphs, GraphLP utilizes the feature learning ability of deep-learning models to automatically extract the structural patterns of graphs for link prediction under the assumption that real-world graphs are not locally isolated. Moreover, GraphLP explores high-order connectivity patterns to utilize the hierarchical organizational structures of graphs for link prediction. Our experimental results on all common benchmark datasets from different applications demonstrate that the proposed method consistently outperforms other state-of-the-art methods. Unlike the discriminative neural network models used for link prediction, GraphLP is generative, which provides a new paradigm for neural-network-based link prediction. ",
    "url": "https://arxiv.org/abs/2301.00169",
    "authors": [
      "Xingping Xian",
      "Tao Wu",
      "Xiaoke Ma",
      "Shaojie Qiao",
      "Yabin Shao",
      "Chao Wang",
      "Lin Yuan",
      "Yu Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00181",
    "title": "Smooth Mathematical Function from Compact Neural Networks",
    "abstract": "This is paper for the smooth function approximation by neural networks (NN). Mathematical or physical functions can be replaced by NN models through regression. In this study, we get NNs that generate highly accurate and highly smooth function, which only comprised of a few weight parameters, through discussing a few topics about regression. First, we reinterpret inside of NNs for regression; consequently, we propose a new activation function--integrated sigmoid linear unit (ISLU). Then special charateristics of metadata for regression, which is different from other data like image or sound, is discussed for improving the performance of neural networks. Finally, the one of a simple hierarchical NN that generate models substituting mathematical function is presented, and the new batch concept ``meta-batch\" which improves the performance of NN several times more is introduced. The new activation function, meta-batch method, features of numerical data, meta-augmentation with metaparameters, and a structure of NN generating a compact multi-layer perceptron(MLP) are essential in this study. ",
    "url": "https://arxiv.org/abs/2301.00181",
    "authors": [
      "I.K. Hong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00183",
    "title": "Modeling social resilience: Questions, answers, open problems",
    "abstract": "Resilience denotes the capacity of a system to withstand shocks and its ability to recover from them. We develop a framework to quantify the resilience of highly volatile, non-equilibrium social organizations, such as collectives or collaborating teams. It consists of four steps: (i) \\emph{delimitation}, i.e., narrowing down the target systems, (ii) \\emph{conceptualization}, .e., identifying how to approach social organizations, (iii) formal \\emph{representation} using a combination of agent-based and network models, (iv) \\emph{operationalization}, i.e. specifying measures and demonstrating how they enter the calculation of resilience. Our framework quantifies two dimensions of resilience, the \\emph{robustness} of social organizations and their \\emph{adaptivity}, and combines them in a novel resilience measure. It allows monitoring resilience instantaneously using longitudinal data instead of an ex-post evaluation. ",
    "url": "https://arxiv.org/abs/2301.00183",
    "authors": [
      "Frank Schweitzer",
      "Georges Andres",
      "Giona Casiraghi",
      "Christoph Gote",
      "Ramona Roller",
      "Ingo Scholtes",
      "Giacomo Vaccario",
      "Christian Zingg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2301.00188",
    "title": "New Challenges in Reinforcement Learning: A Survey of Security and  Privacy",
    "abstract": "Reinforcement learning (RL) is one of the most important branches of AI. Due to its capacity for self-adaption and decision-making in dynamic environments, reinforcement learning has been widely applied in multiple areas, such as healthcare, data markets, autonomous driving, and robotics. However, some of these applications and systems have been shown to be vulnerable to security or privacy attacks, resulting in unreliable or unstable services. A large number of studies have focused on these security and privacy problems in reinforcement learning. However, few surveys have provided a systematic review and comparison of existing problems and state-of-the-art solutions to keep up with the pace of emerging threats. Accordingly, we herein present such a comprehensive review to explain and summarize the challenges associated with security and privacy in reinforcement learning from a new perspective, namely that of the Markov Decision Process (MDP). In this survey, we first introduce the key concepts related to this area. Next, we cover the security and privacy issues linked to the state, action, environment, and reward function of the MDP process, respectively. We further highlight the special characteristics of security and privacy methodologies related to reinforcement learning. Finally, we discuss the possible future research directions within this area. ",
    "url": "https://arxiv.org/abs/2301.00188",
    "authors": [
      "Yunjiao Lei",
      "Dayong Ye",
      "Sheng Shen",
      "Yulei Sui",
      "Tianqing Zhu",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00270",
    "title": "UltraProp: Principled and Explainable Propagation on Large Graphs",
    "abstract": "Given a large graph with few node labels, how can we (a) identify the mixed network-effect of the graph and (b) predict the unknown labels accurately and efficiently? This work proposes Network Effect Analysis (NEA) and UltraProp, which are based on two insights: (a) the network-effect (NE) insight: a graph can exhibit not only one of homophily and heterophily, but also both or none in a label-wise manner, and (b) the neighbor-differentiation (ND) insight: neighbors have different degrees of influence on the target node based on the strength of connections. NEA provides a statistical test to check whether a graph exhibits network-effect or not, and surprisingly discovers the absence of NE in many real-world graphs known to have heterophily. UltraProp solves the node classification problem with notable advantages: (a) Accurate, thanks to the network-effect (NE) and neighbor-differentiation (ND) insights; (b) Explainable, precisely estimating the compatibility matrix; (c) Scalable, being linear with the input size and handling graphs with millions of nodes; and (d) Principled, with closed-form formula and theoretical guarantee. Applied on eight real-world graph datasets, UltraProp outperforms top competitors in terms of accuracy and run time, requiring only stock CPU servers. On a large real-world graph with 1.6M nodes and 22.3M edges, UltraProp achieves more than 9 times speedup (12 minutes vs. 2 hours) compared to most competitors. ",
    "url": "https://arxiv.org/abs/2301.00270",
    "authors": [
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Jaemin Yoo",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00301",
    "title": "Generalized PTR: User-Friendly Recipes for Data-Adaptive Algorithms with  Differential Privacy",
    "abstract": "The ''Propose-Test-Release'' (PTR) framework is a classic recipe for designing differentially private (DP) algorithms that are data-adaptive, i.e. those that add less noise when the input dataset is nice. We extend PTR to a more general setting by privately testing data-dependent privacy losses rather than local sensitivity, hence making it applicable beyond the standard noise-adding mechanisms, e.g. to queries with unbounded or undefined sensitivity. We demonstrate the versatility of generalized PTR using private linear regression as a case study. Additionally, we apply our algorithm to solve an open problem from ''Private Aggregation of Teacher Ensembles (PATE)'' -- privately releasing the entire model with a delicate data-dependent analysis. ",
    "url": "https://arxiv.org/abs/2301.00301",
    "authors": [
      "Rachel Redberg",
      "Yuqing Zhu",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00310",
    "title": "Graphlets over Time: A New Lens for Temporal Network Analysis",
    "abstract": "Graphs are widely used for modeling various types of interactions, such as email communications and online discussions. Many of such real-world graphs are temporal, and specifically, they grow over time with new nodes and edges. Counting the instances of each graphlet (i.e., an induced subgraph isomorphism class) has been successful in characterizing local structures of graphs, with many applications. While graphlets have been extended for temporal graphs, the extensions are designed for examining temporally-local subgraphs composed of edges with close arrival times, instead of long-term changes in local structures. In this paper, as a new lens for temporal graph analysis, we study the evolution of distributions of graphlet instances over time in real-world graphs at three different levels (graphs, nodes, and edges). At the graph level, we first discover that the evolution patterns are significantly different from those in random graphs. Then, we suggest a graphlet transition graph for measuring the similarity of the evolution patterns of graphs, and we find out a surprising similarity between the graphs from the same domain. At the node and edge levels, we demonstrate that the local structures around nodes and edges in their early stage provide a strong signal regarding their future importance. In particular, we significantly improve the predictability of the future importance of nodes and edges using the counts of the roles (a.k.a., orbits) that they take within graphlets. ",
    "url": "https://arxiv.org/abs/2301.00310",
    "authors": [
      "Deukryeol Yoon",
      "Dongjin Lee",
      "Minyoung Choe",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2301.00314",
    "title": "Causal Deep Learning: Causal Capsules and Tensor Transformers",
    "abstract": "We derive a set of causal deep neural networks whose architectures are a consequence of tensor (multilinear) factor analysis. Forward causal questions are addressed with a neural network architecture composed of causal capsules and a tensor transformer. The former estimate a set of latent variables that represent the causal factors, and the latter governs their interaction. Causal capsules and tensor transformers may be implemented using shallow autoencoders, but for a scalable architecture we employ block algebra and derive a deep neural network composed of a hierarchy of autoencoders. An interleaved kernel hierarchy preprocesses the data resulting in a hierarchy of kernel tensor factor models. Inverse causal questions are addressed with a neural network that implements multilinear projection and estimates the causes of effects. As an alternative to aggressive bottleneck dimension reduction or regularized regression that may camouflage an inherently underdetermined inverse problem, we prescribe modeling different aspects of the mechanism of data formation with piecewise tensor models whose multilinear projections are well-defined and produce multiple candidate solutions. Our forward and inverse neural network architectures are suitable for asynchronous parallel computation. ",
    "url": "https://arxiv.org/abs/2301.00314",
    "authors": [
      "M. Alex O. Vasilescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00327",
    "title": "Sharper analysis of sparsely activated wide neural networks with  trainable biases",
    "abstract": "This work studies training one-hidden-layer overparameterized ReLU networks via gradient descent in the neural tangent kernel (NTK) regime, where, differently from the previous works, the networks' biases are trainable and are initialized to some constant rather than zero. The first set of results of this work characterize the convergence of the network's gradient descent dynamics. Surprisingly, it is shown that the network after sparsification can achieve as fast convergence as the original network. The contribution over previous work is that not only the bias is allowed to be updated by gradient descent under our setting but also a finer analysis is given such that the required width to ensure the network's closeness to its NTK is improved. Secondly, the networks' generalization bound after training is provided. A width-sparsity dependence is presented which yields sparsity-dependent localized Rademacher complexity and a generalization bound matching previous analysis (up to logarithmic factors). As a by-product, if the bias initialization is chosen to be zero, the width requirement improves the previous bound for the shallow networks' generalization. Lastly, since the generalization bound has dependence on the smallest eigenvalue of the limiting NTK and the bounds from previous works yield vacuous generalization, this work further studies the least eigenvalue of the limiting NTK. Surprisingly, while it is not shown that trainable biases are necessary, trainable bias helps to identify a nice data-dependent region where a much finer analysis of the NTK's smallest eigenvalue can be conducted, which leads to a much sharper lower bound than the previously known worst-case bound and, consequently, a non-vacuous generalization bound. ",
    "url": "https://arxiv.org/abs/2301.00327",
    "authors": [
      "Hongru Yang",
      "Ziyu Jiang",
      "Ruizhe Zhang",
      "Zhangyang Wang",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00335",
    "title": "Theoretical Characterization of How Neural Network Pruning Affects its  Generalization",
    "abstract": "It has been observed in practice that applying pruning-at-initialization methods to neural networks and training the sparsified networks can not only retain the testing performance of the original dense models, but also sometimes even slightly boost the generalization performance. Theoretical understanding for such experimental observations are yet to be developed. This work makes the first attempt to study how different pruning fractions affect the model's gradient descent dynamics and generalization. Specifically, this work considers a classification task for overparameterized two-layer neural networks, where the network is randomly pruned according to different rates at the initialization. It is shown that as long as the pruning fraction is below a certain threshold, gradient descent can drive the training loss toward zero and the network exhibits good generalization performance. More surprisingly, the generalization bound gets better as the pruning fraction gets larger. To complement this positive result, this work further shows a negative result: there exists a large pruning fraction such that while gradient descent is still able to drive the training loss toward zero (by memorizing noise), the generalization performance is no better than random guessing. This further suggests that pruning can change the feature learning process, which leads to the performance drop of the pruned neural network. Up to our knowledge, this is the \\textbf{first} generalization result for pruned neural networks, suggesting that pruning can improve the neural network's generalization. ",
    "url": "https://arxiv.org/abs/2301.00335",
    "authors": [
      "Hongru Yang",
      "Yingbin Liang",
      "Xiaojie Guo",
      "Lingfei Wu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00346",
    "title": "An Adaptive Kernel Approach to Federated Learning of Heterogeneous  Causal Effects",
    "abstract": "We propose a new causal inference framework to learn causal effects from multiple, decentralized data sources in a federated setting. We introduce an adaptive transfer algorithm that learns the similarities among the data sources by utilizing Random Fourier Features to disentangle the loss function into multiple components, each of which is associated with a data source. The data sources may have different distributions; the causal effects are independently and systematically incorporated. The proposed method estimates the similarities among the sources through transfer coefficients, and hence requiring no prior information about the similarity measures. The heterogeneous causal effects can be estimated with no sharing of the raw training data among the sources, thus minimizing the risk of privacy leak. We also provide minimax lower bounds to assess the quality of the parameters learned from the disparate sources. The proposed method is empirically shown to outperform the baselines on decentralized data sources with dissimilar distributions. ",
    "url": "https://arxiv.org/abs/2301.00346",
    "authors": [
      "Thanh Vinh Vo",
      "Arnab Bhattacharyya",
      "Young Lee",
      "Tze-Yun Leong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.00351",
    "title": "Skew Class-balanced Re-weighting for Unbiased Scene Graph Generation",
    "abstract": "An unbiased scene graph generation (SGG) algorithm referred to as Skew Class-balanced Re-weighting (SCR) is proposed for considering the unbiased predicate prediction caused by the long-tailed distribution. The prior works focus mainly on alleviating the deteriorating performances of the minority predicate predictions, showing drastic dropping recall scores, i.e., losing the majority predicate performances. It has not yet correctly analyzed the trade-off between majority and minority predicate performances in the limited SGG datasets. In this paper, to alleviate the issue, the Skew Class-balanced Re-weighting (SCR) loss function is considered for the unbiased SGG models. Leveraged by the skewness of biased predicate predictions, the SCR estimates the target predicate weight coefficient and then re-weights more to the biased predicates for better trading-off between the majority predicates and the minority ones. Extensive experiments conducted on the standard Visual Genome dataset and Open Image V4 \\& V6 show the performances and generality of the SCR with the traditional SGG models. ",
    "url": "https://arxiv.org/abs/2301.00351",
    "authors": [
      "Haeyong Kang",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00354",
    "title": "RiskProp: Account Risk Rating on Ethereum via De-anonymous Score and  Network Propagation",
    "abstract": "As one of the most popular blockchain platforms supporting smart contracts, Ethereum has caught the interest of both investors and criminals. Differently from traditional financial scenarios, executing Know Your Customer verification on Ethereum is rather difficult due to the pseudonymous nature of the blockchain. Fortunately, as the transaction records stored in the Ethereum blockchain are publicly accessible, we can understand the behavior of accounts or detect illicit activities via transaction mining. Existing risk control techniques have primarily been developed from the perspectives of de-anonymizing address clustering and illicit account classification. However, these techniques cannot be used to ascertain the potential risks for all accounts and are limited by specific heuristic strategies or insufficient label information. These constraints motivate us to seek an effective rating method for quantifying the spread of risk in a transaction network. To the best of our knowledge, we are the first to address the problem of account risk rating on Ethereum by proposing a novel model called RiskProp, which includes a de-anonymous score to measure transaction anonymity and a network propagation mechanism to formulate the relationships between accounts and transactions. We demonstrate the effectiveness of RiskProp in overcoming the limitations of existing models by conducting experiments on real-world datasets from Ethereum. Through case studies on the detected high-risk accounts, we demonstrate that the risk assessment by RiskProp can be used to provide warnings for investors and protect them from possible financial losses, and the superior performance of risk score-based account classification experiments further verifies the effectiveness of our rating method. ",
    "url": "https://arxiv.org/abs/2301.00354",
    "authors": [
      "Dan Lin",
      "Jiajing Wu",
      "Qishuang Fu",
      "Zibin Zheng",
      "Ting Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.00364",
    "title": "Generalizable Black-Box Adversarial Attack with Meta Learning",
    "abstract": "In the scenario of black-box adversarial attack, the target model's parameters are unknown, and the attacker aims to find a successful adversarial perturbation based on query feedback under a query budget. Due to the limited feedback information, existing query-based black-box attack methods often require many queries for attacking each benign example. To reduce query cost, we propose to utilize the feedback information across historical attacks, dubbed example-level adversarial transferability. Specifically, by treating the attack on each benign example as one task, we develop a meta-learning framework by training a meta-generator to produce perturbations conditioned on benign examples. When attacking a new benign example, the meta generator can be quickly fine-tuned based on the feedback information of the new task as well as a few historical attacks to produce effective perturbations. Moreover, since the meta-train procedure consumes many queries to learn a generalizable generator, we utilize model-level adversarial transferability to train the meta-generator on a white-box surrogate model, then transfer it to help the attack against the target model. The proposed framework with the two types of adversarial transferability can be naturally combined with any off-the-shelf query-based attack methods to boost their performance, which is verified by extensive experiments. ",
    "url": "https://arxiv.org/abs/2301.00364",
    "authors": [
      "Fei Yin",
      "Yong Zhang",
      "Baoyuan Wu",
      "Yan Feng",
      "Jingyi Zhang",
      "Yanbo Fan",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00366",
    "title": "Self-Supervised Object Segmentation with a Cut-and-Pasting GAN",
    "abstract": "This paper proposes a novel self-supervised based Cut-and-Paste GAN to perform foreground object segmentation and generate realistic composite images without manual annotations. We accomplish this goal by a simple yet effective self-supervised approach coupled with the U-Net based discriminator. The proposed method extends the ability of the standard discriminators to learn not only the global data representations via classification (real/fake) but also learn semantic and structural information through pseudo labels created using the self-supervised task. The proposed method empowers the generator to create meaningful masks by forcing it to learn informative per-pixel as well as global image feedback from the discriminator. Our experiments demonstrate that our proposed method significantly outperforms the state-of-the-art methods on the standard benchmark datasets. ",
    "url": "https://arxiv.org/abs/2301.00366",
    "authors": [
      "Kunal Chaturvedi",
      "Ali Braytee",
      "Jun Li",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00371",
    "title": "Robust Domain Adaptive Object Detection with Unified Multi-Granularity  Alignment",
    "abstract": "Domain adaptive detection aims to improve the generalization of detectors on target domain. To reduce discrepancy in feature distributions between two domains, recent approaches achieve domain adaption through feature alignment in different granularities via adversarial learning. However, they neglect the relationship between multiple granularities and different features in alignment, degrading detection. Addressing this, we introduce a unified multi-granularity alignment (MGA)-based detection framework for domain-invariant feature learning. The key is to encode the dependencies across different granularities including pixel-, instance-, and category-levels simultaneously to align two domains. Specifically, based on pixel-level features, we first develop an omni-scale gated fusion (OSGF) module to aggregate discriminative representations of instances with scale-aware convolutions, leading to robust multi-scale detection. Besides, we introduce multi-granularity discriminators to identify where, either source or target domains, different granularities of samples come from. Note that, MGA not only leverages instance discriminability in different categories but also exploits category consistency between two domains for detection. Furthermore, we present an adaptive exponential moving average (AEMA) strategy that explores model assessments for model update to improve pseudo labels and alleviate local misalignment problem, boosting detection robustness. Extensive experiments on multiple domain adaption scenarios validate the superiority of MGA over other approaches on FCOS and Faster R-CNN detectors. Code will be released at https://github.com/tiankongzhang/MGA. ",
    "url": "https://arxiv.org/abs/2301.00371",
    "authors": [
      "Libo Zhang",
      "Wenzhang Zhou",
      "Heng Fan",
      "Tiejian Luo",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00387",
    "title": "Exactly Hittable Interval Graphs",
    "abstract": "Given a set system $\\mathcal{X} = \\{\\mathcal{U},\\mathcal{S}\\}$, where $\\mathcal{U}$ is a set of elements and $\\mathcal{S}$ is a set of subsets of $\\mathcal{U}$, an exact hitting set $\\mathcal{U}'$ is a subset of $\\mathcal{U}$ such that each subset in $\\mathcal{S}$ contains exactly one element in $\\mathcal{U}'$. We refer to a set system as exactly hittable if it has an exact hitting set. In this paper, we study interval graphs which have intersection models that are exactly hittable. We refer to these interval graphs as exactly hittable interval graphs (EHIG). We present a forbidden structure characterization for EHIG. We also show that the class of proper interval graphs is a strict subclass of EHIG. Finally, we give an algorithm that runs in polynomial time to recognize graphs belonging to the class of EHIG. ",
    "url": "https://arxiv.org/abs/2301.00387",
    "authors": [
      "S.M. Dhannya",
      "N.S. Narayanaswamy",
      "K.K. Nisha"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.00391",
    "title": "PiPAD: Pipelined and Parallel Dynamic GNN Training on GPUs",
    "abstract": "Dynamic Graph Neural Networks (DGNNs) have been broadly applied in various real-life applications, such as link prediction and pandemic forecast, to capture both static structural information and temporal characteristics from dynamic graphs. Combining both time-dependent and -independent components, DGNNs manifest substantial parallel computation and data reuse potentials, but suffer from severe memory access inefficiency and data transfer overhead under the canonical one-graph-at-a-time training pattern. To tackle the challenges, we propose PiPAD, a $\\underline{\\textbf{Pi}}pelined$ and $\\underline{\\textbf{PA}}rallel$ $\\underline{\\textbf{D}}GNN$ training framework for the end-to-end performance optimization on GPUs. From both the algorithm and runtime level, PiPAD holistically reconstructs the overall training paradigm from the data organization to computation manner. Capable of processing multiple graph snapshots in parallel, PiPAD eliminates the unnecessary data transmission and alleviates memory access inefficiency to improve the overall performance. Our evaluation across various datasets shows PiPAD achieves $1.22\\times$-$9.57\\times$ speedup over the state-of-the-art DGNN frameworks on three representative models. ",
    "url": "https://arxiv.org/abs/2301.00391",
    "authors": [
      "Chunyang Wang",
      "Desen Sun",
      "Yuebin Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2301.00399",
    "title": "Semantic Operator Prediction and Applications",
    "abstract": "In the present paper, semantic parsing challenges are briefly introduced and QDMR formalism in semantic parsing is implemented using sequence to sequence model with attention but uses only part of speech(POS) as a representation of words of a sentence to make the training as simple and as fast as possible and also avoiding curse of dimensionality as well as overfitting. It is shown how semantic operator prediction could be augmented with other models like the CopyNet model or the recursive neural net model. ",
    "url": "https://arxiv.org/abs/2301.00399",
    "authors": [
      "Farshad Noravesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.00411",
    "title": "Detachable Novel Views Synthesis of Dynamic Scenes Using  Distribution-Driven Neural Radiance Fields",
    "abstract": "Representing and synthesizing novel views in real-world dynamic scenes from casual monocular videos is a long-standing problem. Existing solutions typically approach dynamic scenes by applying geometry techniques or utilizing temporal information between several adjacent frames without considering the underlying background distribution in the entire scene or the transmittance over the ray dimension, limiting their performance on static and occlusion areas. Our approach $\\textbf{D}$istribution-$\\textbf{D}$riven neural radiance fields offers high-quality view synthesis and a 3D solution to $\\textbf{D}$etach the background from the entire $\\textbf{D}$ynamic scene, which is called $\\text{D}^4$NeRF. Specifically, it employs a neural representation to capture the scene distribution in the static background and a 6D-input NeRF to represent dynamic objects, respectively. Each ray sample is given an additional occlusion weight to indicate the transmittance lying in the static and dynamic components. We evaluate $\\text{D}^4$NeRF on public dynamic scenes and our urban driving scenes acquired from an autonomous-driving dataset. Extensive experiments demonstrate that our approach outperforms previous methods in rendering texture details and motion areas while also producing a clean static background. Our code will be released at https://github.com/Luciferbobo/D4NeRF. ",
    "url": "https://arxiv.org/abs/2301.00411",
    "authors": [
      "Boyu Zhang",
      "Wenbo Xu",
      "Zheng Zhu",
      "Guan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00427",
    "title": "Conditional Diffusion Based on Discrete Graph Structures for Molecular  Graph Generation",
    "abstract": "Learning the underlying distribution of molecular graphs and generating high-fidelity samples is a fundamental research problem in drug discovery and material science. However, accurately modeling distribution and rapidly generating novel molecular graphs remain crucial and challenging goals. To accomplish these goals, we propose a novel Conditional Diffusion model based on discrete Graph Structures (CDGS) for molecular graph generation. Specifically, we construct a forward graph diffusion process on both graph structures and inherent features through stochastic differential equations (SDE) and derive discrete graph structures as the condition for reverse generative processes. We present a specialized hybrid graph noise prediction model that extracts the global context and the local node-edge dependency from intermediate graph states. We further utilize ordinary differential equation (ODE) solvers for efficient graph sampling, based on the semi-linear structure of the probability flow ODE. Experiments on diverse datasets validate the effectiveness of our framework. Particularly, the proposed method still generates high-quality molecular graphs in a limited number of steps. ",
    "url": "https://arxiv.org/abs/2301.00427",
    "authors": [
      "Han Huang",
      "Leilei Sun",
      "Bowen Du",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2301.00433",
    "title": "Optimization of Image Transmission in a Cooperative Semantic  Communication Networks",
    "abstract": "In this paper, a semantic communication framework for image transmission is developed. In the investigated framework, a set of servers cooperatively transmit images to a set of users utilizing semantic communication techniques. To evaluate the performance of studied semantic communication system, a multimodal metric is proposed to measure the correlation between the extracted semantic information and the original image. To meet the ISS requirement of each user, each server must jointly determine the semantic information to be transmitted and the resource blocks (RBs) used for semantic information transmission. We formulate this problem as an optimization problem aiming to minimize each server's transmission latency while reaching the ISS requirement. To solve this problem, a value decomposition based entropy-maximized multi-agent reinforcement learning (RL) is proposed, which enables servers to coordinate for training and execute RB allocation in a distributed manner to approach to a globally optimal performance with less training iterations. Compared to traditional multi-agent RL, the proposed RL improves the valuable action exploration of servers and the probability of finding a globally optimal RB allocation policy based on local observation. Simulation results show that the proposed algorithm can reduce the transmission delay by up to 16.1% compared to traditional multi-agent RL. ",
    "url": "https://arxiv.org/abs/2301.00433",
    "authors": [
      "Wenjing Zhang",
      "Yining Wang",
      "Mingzhe Chen",
      "Tao Luo",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.00435",
    "title": "Trojaning semi-supervised learning model via poisoning wild images on  the web",
    "abstract": "Wild images on the web are vulnerable to backdoor (also called trojan) poisoning, causing machine learning models learned on these images to be injected with backdoors. Most previous attacks assumed that the wild images are labeled. In reality, however, most images on the web are unlabeled. Specifically, we study the effects of unlabeled backdoor images under semi-supervised learning (SSL) on widely studied deep neural networks. To be realistic, we assume that the adversary is zero-knowledge and that the semi-supervised learning model is trained from scratch. Firstly, we find the fact that backdoor poisoning always fails when poisoned unlabeled images come from different classes, which is different from poisoning the labeled images. The reason is that the SSL algorithms always strive to correct them during training. Therefore, for unlabeled images, we implement backdoor poisoning on images from the target class. Then, we propose a gradient matching strategy to craft poisoned images such that their gradients match the gradients of target images on the SSL model, which can fit poisoned images to the target class and realize backdoor injection. To the best of our knowledge, this may be the first approach to backdoor poisoning on unlabeled images of trained-from-scratch SSL models. Experiments show that our poisoning achieves state-of-the-art attack success rates on most SSL algorithms while bypassing modern backdoor defenses. ",
    "url": "https://arxiv.org/abs/2301.00435",
    "authors": [
      "Le Feng",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2301.00437",
    "title": "Neural Collapse in Deep Linear Network: From Balanced to Imbalanced Data",
    "abstract": "Modern deep neural networks have achieved superhuman performance in tasks from image classification to game play. Surprisingly, these various complex systems with massive amounts of parameters exhibit the same remarkable structural properties in their last-layer features and classifiers across canonical datasets. This phenomenon is known as \"Neural Collapse,\" and it was discovered empirically by Papyan et al. \\cite{Papyan20}. Recent papers have theoretically shown the global solutions to the training network problem under a simplified \"unconstrained feature model\" exhibiting this phenomenon. We take a step further and prove the Neural Collapse occurrence for deep linear network for the popular mean squared error (MSE) and cross entropy (CE) loss. Furthermore, we extend our research to imbalanced data for MSE loss and present the first geometric analysis for Neural Collapse under this setting. ",
    "url": "https://arxiv.org/abs/2301.00437",
    "authors": [
      "Hien Dang",
      "Tan Nguyen",
      "Tho Tran",
      "Hung Tran",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.00443",
    "title": "TaxIdMA: Towards a Taxonomy for Attacks related to Identities",
    "abstract": "Identity management refers to the technology and policies for the identification, authentication, and authorization of users in computer networks. Identity management is therefore fundamental to today's IT ecosystem. At the same time, identity management systems, where digital identities are managed, pose an attractive target for attacks. With the heterogeneity of identity management systems, every type (i.e., models, protocols, implementations) has different requirements, typical problems, and hence attack vectors. In order to provide a systematic and categorized overview, the framework Taxonomy for Identity Management Attacks (TaxIdMA) for attacks related to identities is proposed. The purpose of this framework is to classify existing attacks associated with system identities, identity management systems, and end-user identities as well as the background using an extensible structure from a scientific perspective. The taxonomy is then evaluated with eight real-world attacks resp. vulnerabilities. This analysis shows the capability of the proposed taxonomy framework TaxIdMA in describing and categorizing these attacks. ",
    "url": "https://arxiv.org/abs/2301.00443",
    "authors": [
      "Daniela P\u00f6hn und Wolfgang Hommel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00453",
    "title": "Investigating the Dynamics of Social Norm Emergence within Online  Communities",
    "abstract": "Although the effects of the social norm on mitigating misinformation are identified, scant knowledge exists about the patterns of social norm emergence, such as the patterns and variations of social tipping in online communities with diverse characteristics. Accordingly, this study investigates the features of social tipping in online communities and examines the correlations between the tipping features and characteristics of online communities. Taking the side effects of COVID-19 vaccination as the case topic, we first track the patterns of tipping features in 100 online communities, which are detected using Louvain Algorithm from the aggregated communication network on Twitter between May 2020 and April 2021. Then, we use multi-variant linear regression to explore the correlations between tipping features and community characteristics. We find that social tipping in online communities can sustain for two to four months and lead to a 50% increase in populations who accept the normative belief in online communities. The regression indicates that the duration of social tipping is positively related to the community populations and original acceptance of social norms, while the correlation between the tipping duration and the degrees among community members is negative. Additionally, the network modularity and original acceptance of social norms have negative relationships with the extent of social tipping, while the degree and betweenness centrality can have significant positive relationships with the extent of tipping. Our findings shed light on more precise normative interventions on misinformation in digital environments as it offers preliminary evidence about the timing and mechanism of social norm emergence. ",
    "url": "https://arxiv.org/abs/2301.00453",
    "authors": [
      "Shangde Gao",
      "Yan Wang",
      "My T. Thai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2301.00462",
    "title": "Deep Correlation-Aware Kernelized Autoencoders for Anomaly Detection in  Cybersecurity",
    "abstract": "Unsupervised learning-based anomaly detection in latent space has gained importance since discriminating anomalies from normal data becomes difficult in high-dimensional space. Both density estimation and distance-based methods to detect anomalies in latent space have been explored in the past. These methods prove that retaining valuable properties of input data in latent space helps in the better reconstruction of test data. Moreover, real-world sensor data is skewed and non-Gaussian in nature, making mean-based estimators unreliable for skewed data. Again, anomaly detection methods based on reconstruction error rely on Euclidean distance, which does not consider useful correlation information in the feature space and also fails to accurately reconstruct the data when it deviates from the training distribution. In this work, we address the limitations of reconstruction error-based autoencoders and propose a kernelized autoencoder that leverages a robust form of Mahalanobis distance (MD) to measure latent dimension correlation to effectively detect both near and far anomalies. This hybrid loss is aided by the principle of maximizing the mutual information gain between the latent dimension and the high-dimensional prior data space by maximizing the entropy of the latent space while preserving useful correlation information of the original data in the low-dimensional latent space. The multi-objective function has two goals -- it measures correlation information in the latent feature space in the form of robust MD distance and simultaneously tries to preserve useful correlation information from the original data space in the latent space by maximizing mutual information between the prior and latent space. ",
    "url": "https://arxiv.org/abs/2301.00462",
    "authors": [
      "Padmaksha Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00503",
    "title": "A Concept Knowledge Graph for User Next Intent Prediction at Alipay",
    "abstract": "This paper illustrates the technologies of user next intent prediction with a concept knowledge graph. The system has been deployed on the Web at Alipay, serving more than 100 million daily active users. Specifically, we propose AlipayKG to explicitly characterize user intent, which is an offline concept knowledge graph in the Life-Service domain modeling the historical behaviors of users, the rich content interacted by users and the relations between them. We further introduce a Transformer-based model which integrates expert rules from the knowledge graph to infer the online user's next intent. Experimental results demonstrate that the proposed system can effectively enhance the performance of the downstream tasks while retaining explainability. ",
    "url": "https://arxiv.org/abs/2301.00503",
    "authors": [
      "Yacheng He",
      "Qianghuai Jia",
      "Lin Yuan",
      "Ruopeng Li",
      "Yixin Ou",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00511",
    "title": "Asteria-Pro: Enhancing Deep-Learning Based Binary Code Similarity  Detection by Incorporating Domain Knowledge",
    "abstract": "The widespread code reuse allows vulnerabilities to proliferate among a vast variety of firmware. There is an urgent need to detect these vulnerable code effectively and efficiently. By measuring code similarities, AI-based binary code similarity detection is applied to detecting vulnerable code at scale. Existing studies have proposed various function features to capture the commonality for similarity detection. Nevertheless, the significant code syntactic variability induced by the diversity of IoT hardware architectures diminishes the accuracy of binary code similarity detection. In our earlier study and the tool Asteria, we adopt a Tree-LSTM network to summarize function semantics as function commonality and the evaluation result indicates an advanced performance. However, it still has utility concerns due to excessive time costs and inadequate precision while searching for large-scale firmware bugs. To this end, we propose a novel deep learning enhancement architecture by incorporating domain knowledge-based pre-filtration and re-ranking modules, and we develop a prototype based on Asteria called Asteria-Pro. Pre-filtration module seeks to eliminates dissimilar functions to boost subsequent deep learning model calculations, while re-ranking module aims to raises the rankings of vulnerable functions among candidates generated by deep learning model. Our evaluation indicates that pre-filtration module cuts the calculation time by 96.9% and re-ranking improves MRR and Recall by 23.71% and 36.4%. By incorporating the pre-filtration and re-ranking modules, Asteria-Pro outperforms existing state-of-the-art approaches in bug search task, by a significant large margin. We conduct a large-scale real-world firmware bug search and Asteria-Pro manages to detect 1,482 vulnerable functions with a high precision 91.65%. ",
    "url": "https://arxiv.org/abs/2301.00511",
    "authors": [
      "Shouguo Yang",
      "Chaopeng Dong",
      "Yang Xiao",
      "Yiran Cheng",
      "Zhiqiang Shi",
      "Zhi Li",
      "Limin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00519",
    "title": "Holistic Network Virtualization and Pervasive Network Intelligence for  6G",
    "abstract": "In this tutorial paper, we look into the evolution and prospect of network architecture and propose a novel conceptual architecture for the 6th generation (6G) networks. The proposed architecture has two key elements, i.e., holistic network virtualization and pervasive artificial intelligence (AI). The holistic network virtualization consists of network slicing and digital twin, from the aspects of service provision and service demand, respectively, to incorporate service-centric and user-centric networking. The pervasive network intelligence integrates AI into future networks from the perspectives of networking for AI and AI for networking, respectively. Building on holistic network virtualization and pervasive network intelligence, the proposed architecture can facilitate three types of interplay, i.e., the interplay between digital twin and network slicing paradigms, between model-driven and data-driven methods for network management, and between virtualization and AI, to maximize the flexibility, scalability, adaptivity, and intelligence for 6G networks. We also identify challenges and open issues related to the proposed architecture. By providing our vision, we aim to inspire further discussions and developments on the potential architecture of 6G. ",
    "url": "https://arxiv.org/abs/2301.00519",
    "authors": [
      "Xuemin",
      "Shen",
      "Jie Gao",
      "Wen Wu",
      "Mushu Li",
      "Conghao Zhou",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00561",
    "title": "Local Differential Privacy for Sequential Decision Making in a Changing  Environment",
    "abstract": "We study the problem of preserving privacy while still providing high utility in sequential decision making scenarios in a changing environment. We consider abruptly changing environment: the environment remains constant during periods and it changes at unknown time instants. To formulate this problem, we propose a variant of multi-armed bandits called non-stationary stochastic corrupt bandits. We construct an algorithm called SW-KLUCB-CF and prove an upper bound on its utility using the performance measure of regret. The proven regret upper bound for SW-KLUCB-CF is near-optimal in the number of time steps and matches the best known bound for analogous problems in terms of the number of time steps and the number of changes. Moreover, we present a provably optimal mechanism which can guarantee the desired level of local differential privacy while providing high utility. ",
    "url": "https://arxiv.org/abs/2301.00561",
    "authors": [
      "Pratik Gajane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00582",
    "title": "Sparse neural networks with skip-connections for nonlinear system  identification",
    "abstract": "Data-driven models such as neural networks are being applied more and more to safety-critical applications, such as the modeling and control of cyber-physical systems. Despite the flexibility of the approach, there are still concerns about the safety of these models in this context, as well as the need for large amounts of potentially expensive data. In particular, when long-term predictions are needed or frequent measurements are not available, the open-loop stability of the model becomes important. However, it is difficult to make such guarantees for complex black-box models such as neural networks, and prior work has shown that model stability is indeed an issue. In this work, we consider an aluminum extraction process where measurements of the internal state of the reactor are time-consuming and expensive. We model the process using neural networks and investigate the role of including skip connections in the network architecture as well as using l1 regularization to induce sparse connection weights. We demonstrate that these measures can greatly improve both the accuracy and the stability of the models for datasets of varying sizes. ",
    "url": "https://arxiv.org/abs/2301.00582",
    "authors": [
      "Erlend Torje Berg Lundby",
      "Haakon Robinsson",
      "Adil Rasheed",
      "Ivar Johan Halvorsen",
      "Jan Tommy Gravdahl"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00591",
    "title": "Analysing Discrete Self Supervised Speech Representation for Spoken  Language Modeling",
    "abstract": "This work profoundly analyzes discrete self-supervised speech representations through the eyes of Generative Spoken Language Modeling (GSLM). Following the findings of such an analysis, we propose practical improvements to the discrete unit for the GSLM. First, we start comprehending these units by analyzing them in three axes: interpretation, visualization, and resynthesis. Our analysis finds a high correlation between the speech units to phonemes and phoneme families, while their correlation with speaker or gender is weaker. Additionally, we found redundancies in the extracted units and claim that one reason may be the units' context. Following this analysis, we propose a new, unsupervised metric to measure unit redundancies. Finally, we use this metric to develop new methods that improve the robustness of units clustering and show significant improvement considering zero-resource speech metrics such as ABX. Code and analysis tools are available under the following link. ",
    "url": "https://arxiv.org/abs/2301.00591",
    "authors": [
      "Amitay Sicherman",
      "Yossi Adi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2301.00615",
    "title": "ChameleMon: Shifting Measurement Attention as Network State Changes",
    "abstract": "Flow-level network measurement is critical to many network applications. Among various measurement tasks, packet loss detection and heavy-hitter detection are two most important measurement tasks, which we call the two key tasks. In practice, the two key tasks are often required at the same time, but existing works seldom handle both tasks. In this paper, we design ChameleMon to support the two key tasks simultaneously. One key design/novelty of ChameleMon is to shift measurement attention as network state changes, through two dimensions of dynamics: 1) dynamically allocating memory between the two key tasks; 2) dynamically monitoring the flows of importance. To realize the key design, we propose a key technique, leveraging Fermat's little theorem to devise a flexible data structure, namely FermatSketch. FermatSketch is dividable, additive, and subtractive, supporting the two key tasks. We have fully implemented a ChameleMon prototype on a testbed with a Fat-tree topology. We conduct extensive experiments and the results show ChameleMon supports the two key tasks with low memory/bandwidth overhead, and more importantly, it can automatically shift measurement attention as network state changes. ",
    "url": "https://arxiv.org/abs/2301.00615",
    "authors": [
      "Kaicheng Yang",
      "Yuhan Wu",
      "Ruijie Miao",
      "Tong Yang",
      "Zirui Liu",
      "Zicang Xu",
      "Rui Qiu",
      "Yikai Zhao",
      "Hanglong Lv",
      "Zhigang Ji",
      "Gaogang Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2301.00623",
    "title": "Triple Graph Grammars for Multi-version Models",
    "abstract": "Like conventional software projects, projects in model-driven software engineering require adequate management of multiple versions of development artifacts, importantly allowing living with temporary inconsistencies. In the case of model-driven software engineering, employed versioning approaches also have to handle situations where different artifacts, that is, different models, are linked via automatic model transformations. In this report, we propose a technique for jointly handling the transformation of multiple versions of a source model into corresponding versions of a target model, which enables the use of a more compact representation that may afford improved execution time of both the transformation and further analysis operations. Our approach is based on the well-known formalism of triple graph grammars and a previously introduced encoding of model version histories called multi-version models. In addition to showing the correctness of our approach with respect to the standard semantics of triple graph grammars, we conduct an empirical evaluation that demonstrates the potential benefit regarding execution time performance. ",
    "url": "https://arxiv.org/abs/2301.00623",
    "authors": [
      "Matthias Barkowsky",
      "Holger Giese"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.00624",
    "title": "Modular and Incremental Global Model Management with Extended  Generalized Discrimination Networks",
    "abstract": "Complex projects developed under the paradigm of model-driven engineering nowadays often involve several interrelated models, which are automatically processed via a multitude of model operations. Modular and incremental construction and execution of such networks of models and model operations are required to accommodate efficient development with potentially large-scale models. The underlying problem is also called Global Model Management. In this report, we propose an approach to modular and incremental Global Model Management via an extension to the existing technique of Generalized Discrimination Networks (GDNs). In addition to further generalizing the notion of query operations employed in GDNs, we adapt the previously query-only mechanism to operations with side effects to integrate model transformation and model synchronization. We provide incremental algorithms for the execution of the resulting extended Generalized Discrimination Networks (eGDNs), as well as a prototypical implementation for a number of example eGDN operations. Based on this prototypical implementation, we experiment with an application scenario from the software development domain to empirically evaluate our approach with respect to scalability and conceptually demonstrate its applicability in a typical scenario. Initial results confirm that the presented approach can indeed be employed to realize efficient Global Model Management in the considered scenario. ",
    "url": "https://arxiv.org/abs/2301.00624",
    "authors": [
      "Matthias Barkowsky",
      "Holger Giese"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.00636",
    "title": "New Designed Loss Functions to Solve Ordinary Differential Equations  with Artificial Neural Network",
    "abstract": "This paper investigates the use of artificial neural networks (ANNs) to solve differential equations (DEs) and the construction of the loss function which meets both differential equation and its initial/boundary condition of a certain DE. In section 2, the loss function is generalized to $n^\\text{th}$ order ordinary differential equation(ODE). Other methods of construction are examined in Section 3 and applied to three different models to assess their effectiveness. ",
    "url": "https://arxiv.org/abs/2301.00636",
    "authors": [
      "Xiao Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00671",
    "title": "Political representation bias in DBpedia and Wikidata as a challenge for  downstream processing",
    "abstract": "Diversity Searcher is a tool originally developed to help analyse diversity in news media texts. It relies on a form of automated content analysis and thus rests on prior assumptions and depends on certain design choices related to diversity and fairness. One such design choice is the external knowledge source(s) used. In this article, we discuss implications that these sources can have on the results of content analysis. We compare two data sources that Diversity Searcher has worked with - DBpedia and Wikidata - with respect to their ontological coverage and diversity, and describe implications for the resulting analyses of text corpora. We describe a case study of the relative over- or under-representation of Belgian political parties between 1990 and 2020 in the English-language DBpedia, the Dutch-language DBpedia, and Wikidata, and highlight the many decisions needed with regard to the design of this data analysis and the assumptions behind it, as well as implications from the results. In particular, we came across a staggering over-representation of the political right in the English-language DBpedia. ",
    "url": "https://arxiv.org/abs/2301.00671",
    "authors": [
      "Ozgur Karadeniz",
      "Bettina Berendt",
      "Sercan Kiyak",
      "Stefan Mertens",
      "Leen d'Haenens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2301.00675",
    "title": "FlatENN: Train Flat for Enhanced Fault Tolerance of Quantized Deep  Neural Networks",
    "abstract": "Model compression via quantization and sparsity enhancement has gained an immense interest to enable the deployment of deep neural networks (DNNs) in resource-constrained edge environments. Although these techniques have shown promising results in reducing the energy, latency and memory requirements of the DNNs, their performance in non-ideal real-world settings (such as in the presence of hardware faults) is yet to be completely understood. In this paper, we investigate the impact of bit-flip and stuck-at faults on activation-sparse quantized DNNs (QDNNs). We show that a high level of activation sparsity comes at the cost of larger vulnerability to faults. For instance, activation-sparse QDNNs exhibit up to 17.32% lower accuracy than the standard QDNNs. We also establish that one of the major cause of the degraded accuracy is sharper minima in the loss landscape for activation-sparse QDNNs, which makes them more sensitive to perturbations in the weight values due to faults. Based on this observation, we propose the mitigation of the impact of faults by employing a sharpness-aware quantization (SAQ) training scheme. The activation-sparse and standard QDNNs trained with SAQ have up to 36.71% and 24.76% higher inference accuracy, respectively compared to their conventionally trained equivalents. Moreover, we show that SAQ-trained activation-sparse QDNNs show better accuracy in faulty settings than standard QDNNs trained conventionally. Thus the proposed technique can be instrumental in achieving sparsity-related energy/latency benefits without compromising on fault tolerance. ",
    "url": "https://arxiv.org/abs/2301.00675",
    "authors": [
      "Akul Malhotra",
      "Sumeet Kumar Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2301.00688",
    "title": "Active Learning for Neural Machine Translation",
    "abstract": "The machine translation mechanism translates texts automatically between different natural languages, and Neural Machine Translation (NMT) has gained attention for its rational context analysis and fluent translation accuracy. However, processing low-resource languages that lack relevant training attributes like supervised data is a current challenge for Natural Language Processing (NLP). We incorporated a technique known Active Learning with the NMT toolkit Joey NMT to reach sufficient accuracy and robust predictions of low-resource language translation. With active learning, a semi-supervised machine learning strategy, the training algorithm determines which unlabeled data would be the most beneficial for obtaining labels using selected query techniques. We implemented two model-driven acquisition functions for selecting the samples to be validated. This work uses transformer-based NMT systems; baseline model (BM), fully trained model (FTM) , active learning least confidence based model (ALLCM), and active learning margin sampling based model (ALMSM) when translating English to Hindi. The Bilingual Evaluation Understudy (BLEU) metric has been used to evaluate system results. The BLEU scores of BM, FTM, ALLCM and ALMSM systems are 16.26, 22.56 , 24.54, and 24.20, respectively. The findings in this paper demonstrate that active learning techniques helps the model to converge early and improve the overall quality of the translation system. ",
    "url": "https://arxiv.org/abs/2301.00688",
    "authors": [
      "Neeraj Vashistha",
      "Kriti Singh",
      "Ramakant Shakya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00707",
    "title": "RIS-Assisted Receive Quadrature Spatial Modulation with Low-Complexity  Greedy Detection",
    "abstract": "In this paper, we propose a novel reconfigurable intelligent surface (RIS)-assisted wireless communication scheme which uses the concept of spatial modulation, namely RIS-assisted receive quadrature spatial modulation (RIS-RQSM). In the proposed RIS-RQSM system, the information bits are conveyed via both the indices of the two selected receive antennas and the conventional in-phase/quadrature (IQ) modulation. We propose a novel methodology to adjust the phase shifts of the RIS elements in order to maximize the signal-to-noise ratio (SNR) and at the same time to construct two separate PAM symbols at the selected receive antennas, as the in-phase and quadrature components of the desired IQ symbol. An energy-based greedy detector (GD) is implemented at the receiver to efficiently detect the received signal with minimal channel state information (CSI) via the use of an appropriately designed one-tap pre-equalizer. We also derive a closed-form upper bound on the average bit error probability (ABEP) of the proposed RIS-RQSM system. Then, we formulate an optimization problem to minimize the ABEP in order to improve the performance of the system, which allows the GD to act as a near-optimal receiver. Extensive numerical results are provided to demonstrate the error rate performance of the system and to compare with that of a prominent benchmark scheme. The results verify the remarkable superiority of the proposed RIS-RQSM system over the benchmark scheme. ",
    "url": "https://arxiv.org/abs/2301.00707",
    "authors": [
      "Mohamad H. Dinan",
      "Marco Di Renzo",
      "Mark F. Flanagan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.00714",
    "title": "Learning Road Scene-level Representations via Semantic Region Prediction",
    "abstract": "In this work, we tackle two vital tasks in automated driving systems, i.e., driver intent prediction and risk object identification from egocentric images. Mainly, we investigate the question: what would be good road scene-level representations for these two tasks? We contend that a scene-level representation must capture higher-level semantic and geometric representations of traffic scenes around ego-vehicle while performing actions to their destinations. To this end, we introduce the representation of semantic regions, which are areas where ego-vehicles visit while taking an afforded action (e.g., left-turn at 4-way intersections). We propose to learn scene-level representations via a novel semantic region prediction task and an automatic semantic region labeling algorithm. Extensive evaluations are conducted on the HDD and nuScenes datasets, and the learned representations lead to state-of-the-art performance for driver intention prediction and risk object identification. ",
    "url": "https://arxiv.org/abs/2301.00714",
    "authors": [
      "Zihao Xiao",
      "Alan Yuille",
      "Yi-Ting Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.00716",
    "title": "IRT2: Inductive Linking and Ranking in Knowledge Graphs of Varying Scale",
    "abstract": "We address the challenge of building domain-specific knowledge models for industrial use cases, where labelled data and taxonomic information is initially scarce. Our focus is on inductive link prediction models as a basis for practical tools that support knowledge engineers with exploring text collections and discovering and linking new (so-called open-world) entities to the knowledge graph. We argue that - though neural approaches to text mining have yielded impressive results in the past years - current benchmarks do not reflect the typical challenges encountered in the industrial wild properly. Therefore, our first contribution is an open benchmark coined IRT2 (inductive reasoning with text) that (1) covers knowledge graphs of varying sizes (including very small ones), (2) comes with incidental, low-quality text mentions, and (3) includes not only triple completion but also ranking, which is relevant for supporting experts with discovery tasks. We investigate two neural models for inductive link prediction, one based on end-to-end learning and one that learns from the knowledge graph and text data in separate steps. These models compete with a strong bag-of-words baseline. The results show a significant advance in performance for the neural approaches as soon as the available graph data decreases for linking. For ranking, the results are promising, and the neural approaches outperform the sparse retriever by a wide margin. ",
    "url": "https://arxiv.org/abs/2301.00716",
    "authors": [
      "Felix Hamann",
      "Adrian Ulges",
      "Maurice Falk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.00717",
    "title": "Robust Consensus Clustering and its Applications for Advertising  Forecasting",
    "abstract": "Consensus clustering aggregates partitions in order to find a better fit by reconciling clustering results from different sources/executions. In practice, there exist noise and outliers in clustering task, which, however, may significantly degrade the performance. To address this issue, we propose a novel algorithm -- robust consensus clustering that can find common ground truth among experts' opinions, which tends to be minimally affected by the bias caused by the outliers. In particular, we formalize the robust consensus clustering problem as a constraint optimization problem, and then derive an effective algorithm upon alternating direction method of multipliers (ADMM) with rigorous convergence guarantee. Our method outperforms the baselines on benchmarks. We apply the proposed method to the real-world advertising campaign segmentation and forecasting tasks using the proposed consensus clustering results based on the similarity computed via Kolmogorov-Smirnov Statistics. The accurate clustering result is helpful for building the advertiser profiles so as to perform the forecasting. ",
    "url": "https://arxiv.org/abs/2301.00717",
    "authors": [
      "Deguang Kong",
      "Miao Lu",
      "Konstantin Shmakov",
      "Jian Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2301.00719",
    "title": "Detection of Groups with Biased Representation in Ranking",
    "abstract": "Real-life tools for decision-making in many critical domains are based on ranking results. With the increasing awareness of algorithmic fairness, recent works have presented measures for fairness in ranking. Many of those definitions consider the representation of different ``protected groups'', in the top-$k$ ranked items, for any reasonable $k$. Given the protected groups, confirming algorithmic fairness is a simple task. However, the groups' definitions may be unknown in advance. In this paper, we study the problem of detecting groups with biased representation in the top-$k$ ranked items, eliminating the need to pre-define protected groups. The number of such groups possible can be exponential, making the problem hard. We propose efficient search algorithms for two different fairness measures: global representation bounds, and proportional representation. Then we propose a method to explain the bias in the representations of groups utilizing the notion of Shapley values. We conclude with an experimental study, showing the scalability of our approach and demonstrating the usefulness of the proposed algorithms. ",
    "url": "https://arxiv.org/abs/2301.00719",
    "authors": [
      "Yuval Moskovitch",
      "Jinyang Li",
      "H. V. Jagadish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2301.00738",
    "title": "Training Differentially Private Graph Neural Networks with Random Walk  Sampling",
    "abstract": "Deep learning models are known to put the privacy of their training data at risk, which poses challenges for their safe and ethical release to the public. Differentially private stochastic gradient descent is the de facto standard for training neural networks without leaking sensitive information about the training data. However, applying it to models for graph-structured data poses a novel challenge: unlike with i.i.d. data, sensitive information about a node in a graph cannot only leak through its gradients, but also through the gradients of all nodes within a larger neighborhood. In practice, this limits privacy-preserving deep learning on graphs to very shallow graph neural networks. We propose to solve this issue by training graph neural networks on disjoint subgraphs of a given training graph. We develop three random-walk-based methods for generating such disjoint subgraphs and perform a careful analysis of the data-generating distributions to provide strong privacy guarantees. Through extensive experiments, we show that our method greatly outperforms the state-of-the-art baseline on three large graphs, and matches or outperforms it on four smaller ones. ",
    "url": "https://arxiv.org/abs/2301.00738",
    "authors": [
      "Morgane Ayle",
      "Jan Schuchardt",
      "Lukas Gosch",
      "Daniel Z\u00fcgner",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.00739",
    "title": "On the Complexity of Sub-Tree Scheduling for Wireless Sensor Networks  with Partial Coverage",
    "abstract": "Given an undirected graph $G$ whose edge weights change over $s$ time slots, the sub-tree scheduling for wireless sensor networks with partial coverage asks to partition the vertices of $G$ in $s$ non-empty trees such that the total weight of the trees is minimized. In this note we show that the problem is NP-hard in both the cases where $s$ $(i)$ is part of the input and $(ii)$ is a fixed instance parameter. In both our proofs we reduce from the cardinality Steiner tree problem. We additionally give polynomial-time algorithms for structured inputs of the problem. ",
    "url": "https://arxiv.org/abs/2301.00739",
    "authors": [
      "Michele Barbato",
      "Nicola Bianchessi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2301.00752",
    "title": "Point Cloud-based Proactive Link Quality Prediction for Millimeter-wave  Communications",
    "abstract": "This study demonstrates the feasibility of point cloud-based proactive link quality prediction for millimeter-wave (mmWave) communications. Image-based methods to quantitatively and deterministically predict future received signal strength using machine learning from time series of depth images to mitigate the human body line-of-sight (LOS) path blockage in mmWave communications have been proposed. However, image-based methods have been limited in applicable environments because camera images may contain private information. Thus, this study demonstrates the feasibility of using point clouds obtained from light detection and ranging (LiDAR) for the mmWave link quality prediction. Point clouds represent three-dimensional (3D) spaces as a set of points and are sparser and less likely to contain sensitive information than camera images. Additionally, point clouds provide 3D position and motion information, which is necessary for understanding the radio propagation environment involving pedestrians. This study designs the mmWave link quality prediction method and conducts two experimental evaluations using different types of point clouds obtained from LiDAR and depth cameras, as well as different numerical indicators of link quality, received signal strength and throughput. Based on these experiments, our proposed method can predict future large attenuation of mmWave link quality due to LOS blockage by human bodies, therefore our point cloud-based method can be an alternative to image-based methods. ",
    "url": "https://arxiv.org/abs/2301.00752",
    "authors": [
      "Shoki Ohta",
      "Takayuki Nishio",
      "Riichi Kudo",
      "Kahoko Takahashi",
      "Hisashi Nagata"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2301.00753",
    "title": "Polynomial representation of additive cyclic codes and new quantum codes",
    "abstract": "We give a polynomial representation for additive cyclic codes over $\\mathbb{F}_{p^2}$. This representation will be applied to uniquely present each additive cyclic code by at most two generator polynomials. We determine the generator polynomials of all different additive cyclic codes. A minimum distance lower bound for additive cyclic codes will also be provided using linear cyclic codes over $\\mathbb{F}_p$. We classify all the symplectic self-dual, self-orthogonal, and nearly self-orthogonal additive cyclic codes over $\\mathbb{F}_{p^2}$. Finally, we present ten record-breaking binary quantum codes after applying a quantum construction to self-orthogonal and nearly self-orthogonal additive cyclic codes over $\\mathbb{F}_{4}$. ",
    "url": "https://arxiv.org/abs/2301.00753",
    "authors": [
      "Reza Dastbasteh",
      "Khalil Shivji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ]
  },
  {
    "id": "arXiv:2301.00757",
    "title": "ENGNN: A General Edge-Update Empowered GNN Architecture for Radio  Resource Management in Wireless Networks",
    "abstract": "In order to achieve high data rate and ubiquitous connectivity in future wireless networks, a key task is to efficiently manage the radio resource by judicious beamforming and power allocation. Unfortunately, the iterative nature of the commonly applied optimization-based algorithms cannot meet the low latency requirements due to the high computational complexity. For real-time implementations, deep learning-based approaches, especially the graph neural networks (GNNs), have been demonstrated with good scalability and generalization performance due to the permutation equivariance (PE) property. However, the current architectures are only equipped with the node-update mechanism, which prohibits the applications to a more general setup, where the unknown variables are also defined on the graph edges. To fill this gap, we propose an edge-update mechanism, which enables GNNs to handle both node and edge variables and prove its PE property with respect to both transmitters and receivers. Simulation results on typical radio resource management problems demonstrate that the proposed method achieves higher sum rate but with much shorter computation time than state-of-the-art methods and generalizes well on different numbers of base stations and users, different noise variances, interference levels, and transmit power budgets. ",
    "url": "https://arxiv.org/abs/2301.00757",
    "authors": [
      "Yunqi Wang",
      "Yang Li",
      "Qingjiang Shi",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2301.00772",
    "title": "PCRLv2: A Unified Visual Information Preservation Framework for  Self-supervised Pre-training in Medical Image Analysis",
    "abstract": "Recent advances in self-supervised learning (SSL) in computer vision are primarily comparative, whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views. However, the preserved high-level semantics do not contain enough local information, which is vital in medical image analysis (e.g., image-based diagnosis and tumor segmentation). To mitigate the locality problem of comparative SSL, we propose to incorporate the task of pixel restoration for explicitly encoding more pixel-level information into high-level semantics. We also address the preservation of scale information, a powerful tool in aiding image understanding but has not drawn much attention in SSL. The resulting framework can be formulated as a multi-task optimization problem on the feature pyramid. Specifically, we conduct multi-scale pixel restoration and siamese feature comparison in the pyramid. In addition, we propose non-skip U-Net to build the feature pyramid and develop sub-crop to replace multi-crop in 3D medical imaging. The proposed unified SSL framework (PCRLv2) surpasses its self-supervised counterparts on various tasks, including brain tumor segmentation (BraTS 2018), chest pathology identification (ChestX-ray, CheXpert), pulmonary nodule detection (LUNA), and abdominal organ segmentation (LiTS), sometimes outperforming them by large margins with limited annotations. ",
    "url": "https://arxiv.org/abs/2301.00772",
    "authors": [
      "Hong-Yu Zhou",
      "Chixiang Lu",
      "Chaoqi Chen",
      "Sibei Yang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00794",
    "title": "STEPs: Self-Supervised Key Step Extraction from Unlabeled Procedural  Videos",
    "abstract": "We address the problem of extracting key steps from unlabeled procedural videos, motivated by the potential of Augmented Reality (AR) headsets to revolutionize job training and performance. We decompose the problem into two steps: representation learning and key steps extraction. We employ self-supervised representation learning via a training strategy that adapts off-the-shelf video features using a temporal module. Training implements self-supervised learning losses involving multiple cues such as appearance, motion and pose trajectories extracted from videos to learn generalizable representations. Our method extracts key steps via a tunable algorithm that clusters the representations extracted from procedural videos. We quantitatively evaluate our approach with key step localization and also demonstrate the effectiveness of the extracted representations on related downstream tasks like phase classification. Qualitative results demonstrate that the extracted key steps are meaningful to succinctly represent the procedural tasks. ",
    "url": "https://arxiv.org/abs/2301.00794",
    "authors": [
      "Anshul Shah",
      "Benjamin Lundell",
      "Harpreet Sawhney",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00798",
    "title": "Timely Opportunistic Gossiping in Dense Networks",
    "abstract": "We consider gossiping in a fully-connected wireless network consisting of $n$ nodes. The network receives Poisson updates from a source, which generates new information. The nodes gossip their available information with the neighboring nodes to maintain network timeliness. In this work, we propose two gossiping schemes, one semi-distributed and the other one fully-distributed. In the semi-distributed scheme, the freshest nodes use pilot signals to interact with the network and gossip with the full available update rate $B$. In the fully-distributed scheme, each node gossips for a fixed amount of time duration with the full update rate $B$. Both schemes achieve $O(1)$ age scaling, and the semi-distributed scheme has the best age performance for any symmetric randomized gossiping policy. We compare the results with the recently proposed ASUMAN scheme, which also gives $O(1)$ age performance, but the nodes need to be age-aware. ",
    "url": "https://arxiv.org/abs/2301.00798",
    "authors": [
      "Purbesh Mitra",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.00802",
    "title": "G-CEALS: Gaussian Cluster Embedding in Autoencoder Latent Space for  Tabular Data Representation",
    "abstract": "The latent space of autoencoders has been improved for clustering image data by jointly learning a t-distributed embedding with a clustering algorithm inspired by the neighborhood embedding concept proposed for data visualization. However, multivariate tabular data pose different challenges in representation learning than image data, where traditional machine learning is often superior to deep tabular data learning. In this paper, we address the challenges of learning tabular data in contrast to image data and present a novel Gaussian Cluster Embedding in Autoencoder Latent Space (G-CEALS) algorithm by replacing t-distributions with multivariate Gaussian clusters. Unlike current methods, the proposed approach independently defines the Gaussian embedding and the target cluster distribution to accommodate any clustering algorithm in representation learning. A trained G-CEALS model extracts a quality embedding for unseen test data. Based on the embedding clustering accuracy, the average rank of the proposed G-CEALS method is 1.4 (0.7), which is superior to all eight baseline clustering and cluster embedding methods on seven tabular data sets. This paper shows one of the first algorithms to jointly learn embedding and clustering to improve multivariate tabular data representation in downstream clustering. ",
    "url": "https://arxiv.org/abs/2301.00802",
    "authors": [
      "Manar D. Samad",
      "Sakib Abrar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00810",
    "title": "SIRL: Similarity-based Implicit Representation Learning",
    "abstract": "When robots learn reward functions using high capacity models that take raw state directly as input, they need to both learn a representation for what matters in the task -- the task ``features\" -- as well as how to combine these features into a single objective. If they try to do both at once from input designed to teach the full reward function, it is easy to end up with a representation that contains spurious correlations in the data, which fails to generalize to new settings. Instead, our ultimate goal is to enable robots to identify and isolate the causal features that people actually care about and use when they represent states and behavior. Our idea is that we can tune into this representation by asking users what behaviors they consider similar: behaviors will be similar if the features that matter are similar, even if low-level behavior is different; conversely, behaviors will be different if even one of the features that matter differs. This, in turn, is what enables the robot to disambiguate between what needs to go into the representation versus what is spurious, as well as what aspects of behavior can be compressed together versus not. The notion of learning representations based on similarity has a nice parallel in contrastive learning, a self-supervised representation learning technique that maps visually similar data points to similar embeddings, where similarity is defined by a designer through data augmentation heuristics. By contrast, in order to learn the representations that people use, so we can learn their preferences and objectives, we use their definition of similarity. In simulation as well as in a user study, we show that learning through such similarity queries leads to representations that, while far from perfect, are indeed more generalizable than self-supervised and task-input alternatives. ",
    "url": "https://arxiv.org/abs/2301.00810",
    "authors": [
      "Andreea Bobu",
      "Yi Liu",
      "Rohin Shah",
      "Daniel S. Brown",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00127",
    "title": "Spatiotemporal implicit neural representation for unsupervised dynamic  MRI reconstruction",
    "abstract": "Supervised Deep-Learning (DL)-based reconstruction algorithms have shown state-of-the-art results for highly-undersampled dynamic Magnetic Resonance Imaging (MRI) reconstruction. However, the requirement of excessive high-quality ground-truth data hinders their applications due to the generalization problem. Recently, Implicit Neural Representation (INR) has appeared as a powerful DL-based tool for solving the inverse problem by characterizing the attributes of a signal as a continuous function of corresponding coordinates in an unsupervised manner. In this work, we proposed an INR-based method to improve dynamic MRI reconstruction from highly undersampled k-space data, which only takes spatiotemporal coordinates as inputs. Specifically, the proposed INR represents the dynamic MRI images as an implicit function and encodes them into neural networks. The weights of the network are learned from sparsely-acquired (k, t)-space data itself only, without external training datasets or prior images. Benefiting from the strong implicit continuity regularization of INR together with explicit regularization for low-rankness and sparsity, our proposed method outperforms the compared scan-specific methods at various acceleration factors. E.g., experiments on retrospective cardiac cine datasets show an improvement of 5.5 ~ 7.1 dB in PSNR for extremely high accelerations (up to 41.6-fold). The high-quality and inner continuity of the images provided by INR has great potential to further improve the spatiotemporal resolution of dynamic MRI, without the need of any training data. ",
    "url": "https://arxiv.org/abs/2301.00127",
    "authors": [
      "Jie Feng",
      "Ruimin Feng",
      "Qing Wu",
      "Zhiyong Zhang",
      "Yuyao Zhang",
      "Hongjiang Wei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2301.00191",
    "title": "Using affine policies to reformulate two-stage Wasserstein  distributionally robust linear programs to be independent of sample size",
    "abstract": "Intensively studied in theory as a promising data-driven tool for decision-making under ambiguity, two-stage distributionally robust optimization (DRO) problems over Wasserstein balls are not necessarily easy to solve in practice. This is partly due to large sample size. In this article, we study a generic two-stage distributionally robust linear program (2-DRLP) over a 1-Wasserstein ball using an affine policy. The 2-DRLP has right-hand-side uncertainty with a rectangular support. Our main contribution is to show that the 2-DRLP problem has a tractable reformulation with a scale independent of sample size. The reformulated problem can be solved within a pre-defined optimality tolerance using robust optimization techniques. To reduce the inevitable conservativeness of the affine policy while preserving independence of sample size, we further develop a method for constructing an uncertainty set with a probabilistic guarantee over which the Wasserstein ball is re-defined. As an application, we present a novel unit commitment model for power systems under uncertainty of renewable energy generation to examine the effectiveness of the proposed 2-DRLP technique. Extensive numerical experiments demonstrate that our model leads to better out-of-sample performance on average than other state-of-the-art distributionally robust unit commitment models while staying computationally competent. ",
    "url": "https://arxiv.org/abs/2301.00191",
    "authors": [
      "Youngchae Cho",
      "Insoon Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.00201",
    "title": "Exploring Singularities in point clouds with the graph Laplacian: An  explicit approach",
    "abstract": "We develop theory and methods that use the graph Laplacian to analyze the geometry of the underlying manifold of point clouds. Our theory provides theoretical guarantees and explicit bounds on the functional form of the graph Laplacian, in the case when it acts on functions defined close to singularities of the underlying manifold. We also propose methods that can be used to estimate these geometric properties of the point cloud, which are based on the theoretical guarantees. ",
    "url": "https://arxiv.org/abs/2301.00201",
    "authors": [
      "Martin Andersson",
      "Benny Avelin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2301.00278",
    "title": "Isometric path antichain covers: beyond hyperbolic graphs",
    "abstract": "The \\emph{isometric path antichain cover number} of a graph $G$, denoted by $ipacc(G)$, is a graph parameter that was recently introduced to provide a constant factor approximation algorithm for \\textsc{Isometric Path Cover}, whose objective is to cover all vertices of a graph with a minimum number of isometric paths (i.e. shortest paths between their end-vertices). This parameter was previously shown to be bounded for chordal graphs and, more generally, for graphs of bounded \\emph{chordality} and bounded \\emph{treelength}. In this paper, we show that the isometric path antichain cover number remains bounded for graphs in three seemingly unrelated graph classes, namely, \\emph{hyperbolic graphs}, \\emph{(theta, prism, pyramid)-free graphs}, and \\emph{outerstring graphs}. Hyperbolic graphs are extensively studied in \\emph{Metric Graph Theory}. The class of (theta, prism, pyramid)-free graphs are extensively studied in \\emph{Structural Graph Theory}, \\textit{e.g.} in the context of the \\emph{Strong Perfect Graph Theorem}. The class of outerstring graphs is studied in \\emph{Geometric Graph Theory} and \\emph{Computational Geometry}. Our results imply a constant factor approximation algorithm for \\textsc{Isometric Path Cover} on all the above graph classes. Our results also show that the distance functions of these (structurally) different graph classes are more similar than previously thought. ",
    "url": "https://arxiv.org/abs/2301.00278",
    "authors": [
      "Dibyayan Chakraborty",
      "Florent Foucaud"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.00308",
    "title": "High-Accuracy Absolute-Position-Aided Code Phase Tracking Based on  RTK/INS Deep Integration in Challenging Static Scenarios",
    "abstract": "Many multi-sensor navigation systems urgently demand accurate positioning initialization from global navigation satellite systems (GNSSs) in challenging static scenarios. However, ground blockages against line-of-sight (LOS) signal reception make it difficult for GNSS users. Steering local codes in GNSS basebands is a desiring way to correct instantaneous signal phase misalignment, efficiently gathering useful signal power and increasing positioning accuracy. Besides, inertial navigation systems (INSs) have been used as a well-complementary dead reckoning (DR) sensor for GNSS receivers in kinematic scenarios resisting various interferences since early. But little work focuses on the case of whether the INS can improve GNSS receivers in static scenarios. Thus, this paper proposes an enhanced navigation system deeply integrated with low-cost INS solutions and GNSS high-accuracy carrier-based positioning. First, an absolute code phase is predicted from base station information, and integrated solution of the INS DR and real-time kinematic (RTK) results through an extended Kalman filter (EKF). Then, a numerically controlled oscillator (NCO) leverages the predicted code phase to improve the alignment between instantaneous local code phases and received ones. The proposed algorithm is realized in a vector-tracking GNSS software-defined radio (SDR). Real-world experiments demonstrate the proposed SDR regarding estimating time-of-arrival (TOA) and positioning accuracy. ",
    "url": "https://arxiv.org/abs/2301.00308",
    "authors": [
      "Yiran Luo",
      "Li-Ta Hsu",
      "Yang Jiang",
      "Baoyu Liu",
      "Zhetao Zhang",
      "Yan Xiang",
      "Naser El-Sheimy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.00317",
    "title": "A Note On Acyclic Token Sliding Reconfiguration Graphs of Independent  Sets",
    "abstract": "We continue the study of token sliding reconfiguration graphs of independent sets initiated by the authors in an earlier paper (arXiv:2203.16861). Two of the topics in that paper were to study which graphs $G$ are token sliding graphs and which properties of a graph are inherited by a token sliding graph. In this paper we continue this study specializing on the case of when $G$ and/or its token sliding graph $\\mathsf{TS}_k(G)$ is a tree or forest, where $k$ is the size of the independent sets considered. We consider two problems. The first is to find necessary and sufficient conditions on $G$ for $\\mathsf{TS}_k(G)$ to be a forest. The second is to find necessary and sufficient conditions for a tree or forest to be a token sliding graph. For the first problem we give a forbidden subgraph characterization for the cases of $k=2,3$. For the second problem we show that for every $k$-ary tree $T$ there is a graph $G$ for which $\\mathsf{TS}_{k+1}(G)$ is isomorphic to $T$. A number of other results are given along with a join operation that aids in the construction of $\\mathsf{TS}_k(G)$-graphs. ",
    "url": "https://arxiv.org/abs/2301.00317",
    "authors": [
      "David Avis",
      "Duc A. Hoang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.00434",
    "title": "Cops and robbers pebbling in graphs",
    "abstract": "Here we merge the two fields of Cops and Robbers and Graph Pebbling to introduce the new topic of Cops and Robbers Pebbling. Both paradigms can be described by moving tokens (the cops) along the edges of a graph to capture a special token (the robber). In Cops and Robbers, all tokens move freely, whereas, in Graph Pebbling, some of the chasing tokens disappear with movement while the robber is stationary. In Cops and Robbers Pebbling, some of the chasing tokens (cops) disappear with movement, while the robber moves freely. We define the cop pebbling number of a graph to be the minimum number of cops necessary to capture the robber in this context, and present upper and lower bounds and exact values, some involving various domination parameters, for an array of graph classes. We also offer several interesting problems and conjectures. ",
    "url": "https://arxiv.org/abs/2301.00434",
    "authors": [
      "Joshua Forkin",
      "Glenn Hurlbert"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.00552",
    "title": "Neural source/sink phase connectivity in developmental dyslexia by means  of interchannel causality",
    "abstract": "While the brain connectivity network can inform the understanding and diagnosis of developmental dyslexia, its cause-effect relationships have not yet enough been examined. Employing electroencephalography signals and band-limited white noise stimulus at 4.8 Hz (prosodic-syllabic frequency), we measure the phase Granger causalities among channels to identify differences between dyslexic learners and controls, thereby proposing a method to calculate directional connectivity. As causal relationships run in both directions, we explore three scenarios, namely channels' activity as sources, as sinks, and in total. Our proposed method can be used for both classification and exploratory analysis. In all scenarios, we find confirmation of the established right-lateralized Theta sampling network anomaly, in line with the temporal sampling framework's assumption of oscillatory differences in the Theta and Gamma bands. Further, we show that this anomaly primarily occurs in the causal relationships of channels acting as sinks, where it is significantly more pronounced than when only total activity is observed. In the sink scenario, our classifier obtains 0.84 and 0.88 accuracy and 0.87 and 0.93 AUC for the Theta and Gamma bands, respectively. ",
    "url": "https://arxiv.org/abs/2301.00552",
    "authors": [
      "I. Rodr\u00cdguez-Rodr\u00cdguez",
      "A. Ortiz",
      "N.J. Gallego-Molina",
      "M.A. Formoso",
      "W.L. Woo"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.00652",
    "title": "Efficient Speech Representation Learning with Low-Bit Quantization",
    "abstract": "With the development of hardware for machine learning, newer models often come at the cost of both increased sizes and computational complexity. In effort to improve the efficiency for these models, we apply and investigate recent quantization techniques on speech representation learning models. The quantization techniques were evaluated on the SUPERB benchmark. On the ASR task, with aggressive quantization to 1 bit, we achieved 86.32% storage reduction (184.42 -> 25.23), 88% estimated runtime reduction (1.00 -> 0.12) with increased word error rate (7.06 -> 15.96). In comparison with DistillHuBERT which also aims for model compression, the 2-bit configuration yielded slightly smaller storage (35.84 vs. 46.98), better word error rate (12.68 vs. 13.37) and more efficient estimated runtime (0.15 vs. 0.73). ",
    "url": "https://arxiv.org/abs/2301.00652",
    "authors": [
      "Ching-Feng Yeh",
      "Wei-Ning Hsu",
      "Paden Tomasello",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.00656",
    "title": "TriNet: stabilizing self-supervised learning from complete or slow  collapse",
    "abstract": "Self-supervised learning (SSL) models confront challenges of abrupt informational collapse or slow dimensional collapse. We propose TriNet, which introduces a novel triple-branch architecture for preventing collapse and stabilizing the pre-training. Our experimental results show that the proposed method notably stabilizes and accelerates pre-training and achieves a relative word error rate reduction (WERR) of 5.32% compared to the state-of-the-art (SOTA) Data2vec for a downstream benchmark ASR task. We will release our code at https://github.com/tencent-ailab/. ",
    "url": "https://arxiv.org/abs/2301.00656",
    "authors": [
      "Lixin Cao",
      "Jun Wang",
      "Ben Yang",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00776",
    "title": "Fusing Models for Prognostics and Health Management of Lithium-Ion  Batteries Based on Physics-Informed Neural Networks",
    "abstract": "For Prognostics and Health Management (PHM) of Lithium-ion (Li-ion) batteries, many models have been established to characterize their degradation process. The existing empirical or physical models can reveal important information regarding the degradation dynamics. However, there is no general and flexible methods to fuse the information represented by those models. Physics-Informed Neural Network (PINN) is an efficient tool to fuse empirical or physical dynamic models with data-driven models. To take full advantage of various information sources, we propose a model fusion scheme based on PINN. It is implemented by developing a semi-empirical semi-physical Partial Differential Equation (PDE) to model the degradation dynamics of Li-ion-batteries. When there is little prior knowledge about the dynamics, we leverage the data-driven Deep Hidden Physics Model (DeepHPM) to discover the underlying governing dynamic models. The uncovered dynamics information is then fused with that mined by the surrogate neural network in the PINN framework. Moreover, an uncertainty-based adaptive weighting method is employed to balance the multiple learning tasks when training the PINN. The proposed methods are verified on a public dataset of Li-ion Phosphate (LFP)/graphite batteries. ",
    "url": "https://arxiv.org/abs/2301.00776",
    "authors": [
      "Pengfei Wen",
      "Zhi-Sheng Ye",
      "Yong Li",
      "Shaowei Chen",
      "Shuai Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00785",
    "title": "CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection",
    "abstract": "An increasing number of public datasets have shown a marked clinical impact on assessing anatomical structures. However, each of the datasets is small, partially labeled, and rarely investigates severe tumor subjects. Moreover, current models are limited to segmenting specific organs/tumors, which can not be extended to novel domains and classes. To tackle these limitations, we introduce embedding learned from Contrastive Language-Image Pre-training (CLIP) to segmentation models, dubbed the CLIP-Driven Universal Model. The Universal Model can better segment 25 organs and 6 types of tumors by exploiting the semantic relationship between abdominal structures. The model is developed from an assembly of 14 datasets with 3,410 CT scans and evaluated on 6,162 external CT scans from 3 datasets. We rank first on the public leaderboard of the Medical Segmentation Decathlon (MSD) and achieve the state-of-the-art results on Beyond The Cranial Vault (BTCV). Compared with dataset-specific models, the Universal Model is computationally more efficient (6x faster), generalizes better to CT scans from varying sites, and shows stronger transfer learning performance on novel tasks. The design of CLIP embedding enables the Universal Model to be easily extended to new classes without catastrophically forgetting the previously learned classes. ",
    "url": "https://arxiv.org/abs/2301.00785",
    "authors": [
      "Jie Liu",
      "Yixiao Zhang",
      "Jie-Neng Chen",
      "Junfei Xiao",
      "Yongyi Lu",
      "Bennett A. Landman",
      "Yixuan Yuan",
      "Alan Yuille",
      "Yucheng Tang",
      "Zongwei Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00790",
    "title": "Robust machine learning pipelines for trading market-neutral stock  portfolios",
    "abstract": "The application of deep learning algorithms to financial data is difficult due to heavy non-stationarities which can lead to over-fitted models that underperform under regime changes. Using the Numerai tournament data set as a motivating example, we propose a machine learning pipeline for trading market-neutral stock portfolios based on tabular data which is robust under changes in market conditions. We evaluate various machine-learning models, including Gradient Boosting Decision Trees (GBDTs) and Neural Networks with and without simple feature engineering, as the building blocks for the pipeline. We find that GBDT models with dropout display high performance, robustness and generalisability with relatively low complexity and reduced computational cost. We then show that online learning techniques can be used in post-prediction processing to enhance the results. In particular, dynamic feature neutralisation, an efficient procedure that requires no retraining of models and can be applied post-prediction to any machine learning model, improves robustness by reducing drawdown in volatile market conditions. Furthermore, we demonstrate that the creation of model ensembles through dynamic model selection based on recent model performance leads to improved performance over baseline by improving the Sharpe and Calmar ratios. We also evaluate the robustness of our pipeline across different data splits and random seeds with good reproducibility of results. ",
    "url": "https://arxiv.org/abs/2301.00790",
    "authors": [
      "Thomas Wong",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00793",
    "title": "Causal Inference (C-inf) -- closed form worst case typical phase  transitions",
    "abstract": "In this paper we establish a mathematically rigorous connection between Causal inference (C-inf) and the low-rank recovery (LRR). Using Random Duality Theory (RDT) concepts developed in [46,48,50] and novel mathematical strategies related to free probability theory, we obtain the exact explicit typical (and achievable) worst case phase transitions (PT). These PT precisely separate scenarios where causal inference via LRR is possible from those where it is not. We supplement our mathematical analysis with numerical experiments that confirm the theoretical predictions of PT phenomena, and further show that the two closely match for fairly small sample sizes. We obtain simple closed form representations for the resulting PTs, which highlight direct relations between the low rankness of the target C-inf matrix and the time of the treatment. Hence, our results can be used to determine the range of C-inf's typical applicability. ",
    "url": "https://arxiv.org/abs/2301.00793",
    "authors": [
      "Agostino Capponi",
      "Mihailo Stojnic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00801",
    "title": "Causal Inference (C-inf) -- asymmetric scenario of typical phase  transitions",
    "abstract": "In this paper, we revisit and further explore a mathematically rigorous connection between Causal inference (C-inf) and the Low-rank recovery (LRR) established in [10]. Leveraging the Random duality - Free probability theory (RDT-FPT) connection, we obtain the exact explicit typical C-inf asymmetric phase transitions (PT). We uncover a doubling low-rankness phenomenon, which means that exactly two times larger low rankness is allowed in asymmetric scenarios compared to the symmetric worst case ones considered in [10]. Consequently, the final PT mathematical expressions are as elegant as those obtained in [10], and highlight direct relations between the targeted C-inf matrix low rankness and the time of treatment. Our results have strong implications for applications, where C-inf matrices are not necessarily symmetric. ",
    "url": "https://arxiv.org/abs/2301.00801",
    "authors": [
      "Agostino Capponi",
      "Mihailo Stojnic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1708.04073",
    "title": "Metric Embedding via Shortest Path Decompositions",
    "abstract": " Title: Metric Embedding via Shortest Path Decompositions ",
    "url": "https://arxiv.org/abs/1708.04073",
    "authors": [
      "Ittai Abraham",
      "Arnold Filtser",
      "Anupam Gupta",
      "Ofer Neiman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1902.07773",
    "title": "\"A Posteriori\" Limited High Order and Robust Residual Distribution  Schemes for Transient Simulations of Fluid Flows in Gas Dynamics",
    "abstract": " Title: \"A Posteriori\" Limited High Order and Robust Residual Distribution  Schemes for Transient Simulations of Fluid Flows in Gas Dynamics ",
    "url": "https://arxiv.org/abs/1902.07773",
    "authors": [
      "Paola Bacigaluppi",
      "R\u00e9mi Abgrall",
      "Svetlana Tokareva"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:1910.09383",
    "title": "Graph Construction from Data using Non Negative Kernel regression (NNK  Graphs)",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/1910.09383",
    "authors": [
      "Sarath Shekkizhar",
      "Antonio Ortega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.01805",
    "title": "HeLayers: A Tile Tensors Framework for Large Neural Networks on  Encrypted Data",
    "abstract": " Comments: 17 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2011.01805",
    "authors": [
      "Ehud Aharoni",
      "Allon Adir",
      "Moran Baruch",
      "Nir Drucker",
      "Gilad Ezov",
      "Ariel Farkash",
      "Lev Greenberg",
      "Ramy Masalha",
      "Guy Moshkowich",
      "Dov Murik",
      "Hayim Shaul",
      "Omri Soceanu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.00756",
    "title": "NCQ: Code reuse support for node.js developers",
    "abstract": " Comments: Submitted to IEEE Transactions on Software Engineering ",
    "url": "https://arxiv.org/abs/2101.00756",
    "authors": [
      "Brittany Reid",
      "Marcelo d`Amorim",
      "Markus Wagner",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2107.01004",
    "title": "AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks",
    "abstract": " Title: AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks ",
    "url": "https://arxiv.org/abs/2107.01004",
    "authors": [
      "Ahmed Benfaid",
      "Nadia Adem",
      "Bassem Khalfi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2107.07564",
    "title": "On the Importance of Regularisation & Auxiliary Information in OOD  Detection",
    "abstract": " Comments: Fixing errors ",
    "url": "https://arxiv.org/abs/2107.07564",
    "authors": [
      "John Mitros",
      "Brian Mac Namee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.02325",
    "title": "MyProfessors: Mining Turkish Student Reviews",
    "abstract": " Title: MyProfessors: Mining Turkish Student Reviews ",
    "url": "https://arxiv.org/abs/2109.02325",
    "authors": [
      "Ibrahim Faruk Ceylan",
      "Necmettin Bera Calik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.11926",
    "title": "Sinkhorn Distributionally Robust Optimization",
    "abstract": " Comments: 58 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2109.11926",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.02700",
    "title": "Reversible Attack based on Local Visual Adversarial Perturbation",
    "abstract": " Title: Reversible Attack based on Local Visual Adversarial Perturbation ",
    "url": "https://arxiv.org/abs/2110.02700",
    "authors": [
      "Li Chen",
      "Shaowei Zhu",
      "Zhaoxia Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.08427",
    "title": "COVID-19 Detection in Chest X-ray Images Using Swin-Transformer and  Transformer in Transformer",
    "abstract": " Title: COVID-19 Detection in Chest X-ray Images Using Swin-Transformer and  Transformer in Transformer ",
    "url": "https://arxiv.org/abs/2110.08427",
    "authors": [
      "Juntao Jiang",
      "Shuyi Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.02671",
    "title": "GraphSearchNet: Enhancing GNNs via Capturing Global Dependencies for  Semantic Code Search",
    "abstract": " Title: GraphSearchNet: Enhancing GNNs via Capturing Global Dependencies for  Semantic Code Search ",
    "url": "https://arxiv.org/abs/2111.02671",
    "authors": [
      "Shangqing Liu",
      "Xiaofei Xie",
      "Jingkai Siow",
      "Lei Ma",
      "Guozhu Meng",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2111.08452",
    "title": "On minimizers and convolutional filters: a partial justification for the  effectiveness of CNNs in categorical sequence analysis",
    "abstract": " Comments: 13 pages, 3 figures, submitted to a conference ",
    "url": "https://arxiv.org/abs/2111.08452",
    "authors": [
      "Yun William Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2111.13841",
    "title": "Adaptive Perturbation for Adversarial Attack",
    "abstract": " Comments: 13 pages, 5 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2111.13841",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Zhaoyan Jiang",
      "Liangliang Li",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11798",
    "title": "YOLO-Z: Improving small object detection in YOLOv5 for autonomous  vehicles",
    "abstract": " Comments: ICCV 2022 ",
    "url": "https://arxiv.org/abs/2112.11798",
    "authors": [
      "Aduen Benjumea",
      "Izzeddin Teeti",
      "Fabio Cuzzolin",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.03246",
    "title": "Vision in adverse weather: Augmentation using CycleGANs with various  object detectors for robust perception in autonomous racing",
    "abstract": " Comments: ICML 2022 ",
    "url": "https://arxiv.org/abs/2201.03246",
    "authors": [
      "Izzeddin Teeti",
      "Valentina Musat",
      "Salman Khan",
      "Alexander Rast",
      "Fabio Cuzzolin",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.01940",
    "title": "Distribution Embedding Networks for Generalization from a Diverse Set of  Classification Tasks",
    "abstract": " Comments: This paper is accepted at TMLR this https URL ",
    "url": "https://arxiv.org/abs/2202.01940",
    "authors": [
      "Lang Liu",
      "Mahdi Milani Fard",
      "Sen Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.06172",
    "title": "Efficient Spatial Representation and Routing of Deformable  One-Dimensional Objects for Manipulation",
    "abstract": " Comments: 6 pages ",
    "url": "https://arxiv.org/abs/2202.06172",
    "authors": [
      "Azarakhsh Keipour",
      "Maryam Bandari",
      "Stefan Schaal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11812",
    "title": "Neural System Level Synthesis: Learning over All Stabilizing Policies  for Nonlinear Systems",
    "abstract": " Title: Neural System Level Synthesis: Learning over All Stabilizing Policies  for Nonlinear Systems ",
    "url": "https://arxiv.org/abs/2203.11812",
    "authors": [
      "Luca Furieri",
      "Clara Luc\u00eda Galimberti",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.01215",
    "title": "Capturing positive network attributes during the estimation of recursive  logit models: A prism-based approach",
    "abstract": " Comments: 28 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2204.01215",
    "authors": [
      "Yuki Oyama"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.00275",
    "title": "Dynamic Curriculum Learning for Great Ape Detection in the Wild",
    "abstract": " Comments: Accepted at IJCV ",
    "url": "https://arxiv.org/abs/2205.00275",
    "authors": [
      "Xinyu Yang",
      "Tilo Burghardt",
      "Majid Mirmehdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.01901",
    "title": "Spatial-Temporal Meta-path Guided Explainable Crime Prediction",
    "abstract": " Comments: work submitted to World Wide Web: Internet and Web Information Systems (WWW) ",
    "url": "https://arxiv.org/abs/2205.01901",
    "authors": [
      "Yuting Sun",
      "Tong Chen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.05194",
    "title": "Multiplexed Immunofluorescence Brain Image Analysis Using  Self-Supervised Dual-Loss Adaptive Masked Autoencoder",
    "abstract": " Comments: Adding new results on multiplexed image data and data efficiency. Pytorch code: this https URL ",
    "url": "https://arxiv.org/abs/2205.05194",
    "authors": [
      "Son T. Ly",
      "Bai Lin",
      "Hung Q. Vo",
      "Dragan Maric",
      "Badri Roysam",
      "Hien V. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13673",
    "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "abstract": " Title: Diffusion of Community Fact-Checked Misinformation on Twitter ",
    "url": "https://arxiv.org/abs/2205.13673",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.14380",
    "title": "Deep Deconfounded Content-based Tag Recommendation for UGC with Causal  Intervention",
    "abstract": " Title: Deep Deconfounded Content-based Tag Recommendation for UGC with Causal  Intervention ",
    "url": "https://arxiv.org/abs/2205.14380",
    "authors": [
      "Yaochen Zhu",
      "Xubin Ren",
      "Jing Yi",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.07109",
    "title": "Context-aware Mixture-of-Experts for Unbiased Scene Graph Generation",
    "abstract": " Title: Context-aware Mixture-of-Experts for Unbiased Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2208.07109",
    "authors": [
      "Liguang Zhou",
      "Yuhongze Zhou",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.04588",
    "title": "Extended Feature Space-Based Automatic Melanoma Detection System",
    "abstract": " Comments: updations are required ",
    "url": "https://arxiv.org/abs/2209.04588",
    "authors": [
      "Shakti Kumar",
      "Anuj Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00248",
    "title": "Heterogeneous Graph Contrastive Multi-view Learning",
    "abstract": " Comments: Accepted by SDM 2023 ",
    "url": "https://arxiv.org/abs/2210.00248",
    "authors": [
      "Zehong Wang",
      "Qi Li",
      "Donghua Yu",
      "Xiaolong Han",
      "Xiao-Zhi Gao",
      "Shigen Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04195",
    "title": "Online Training Through Time for Spiking Neural Networks",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.04195",
    "authors": [
      "Mingqing Xiao",
      "Qingyan Meng",
      "Zongpeng Zhang",
      "Di He",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07659",
    "title": "Automated dysgraphia detection by deep learning with SensoGrip",
    "abstract": " Title: Automated dysgraphia detection by deep learning with SensoGrip ",
    "url": "https://arxiv.org/abs/2210.07659",
    "authors": [
      "Mugdim Bublin",
      "Franz Werner",
      "Andrea Kerschbaumer",
      "Gernot Korak",
      "Sebastian Geyer",
      "Lena Rettinger",
      "Erna Schoenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.08870",
    "title": "Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors",
    "abstract": " Title: Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors ",
    "url": "https://arxiv.org/abs/2210.08870",
    "authors": [
      "Jialiang Sun",
      "Tingsong Jiang",
      "Wen Yao",
      "Donghua Wang",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09028",
    "title": "Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2",
    "abstract": " Title: Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2 ",
    "url": "https://arxiv.org/abs/2210.09028",
    "authors": [
      "Pier Paolo Tricomi",
      "Lisa Facciolo",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05327",
    "title": "Ultraverse: Efficient Retroactive Operation for Attack Recovery in  Database Systems and Web Frameworks",
    "abstract": " Title: Ultraverse: Efficient Retroactive Operation for Attack Recovery in  Database Systems and Web Frameworks ",
    "url": "https://arxiv.org/abs/2211.05327",
    "authors": [
      "Ronny Ko",
      "Chuan Xiao",
      "Makoto Onizuka",
      "Yihe Huang",
      "Zhiqiang Lin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": " Comments: In this version, some related references are added. An explicit proof to Theorem 9 is sketched in the appendix. The proofs in Section 7-10 to our main results are rewritten by WL process in order for consistence ",
    "url": "https://arxiv.org/abs/2211.05637",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2212.06144",
    "title": "Optimizing Learning Rate Schedules for Iterative Pruning of Deep Neural  Networks",
    "abstract": " Comments: 23 Pages. arXiv admin note: text overlap with arXiv:2110.08764 ",
    "url": "https://arxiv.org/abs/2212.06144",
    "authors": [
      "Shiyu Liu",
      "Rohan Ghosh",
      "John Tan Chong Min",
      "Mehul Motani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.08328",
    "title": "MEIL-NeRF: Memory-Efficient Incremental Learning of Neural Radiance  Fields",
    "abstract": " Comments: 18 pages. For the project page, see this https URL ",
    "url": "https://arxiv.org/abs/2212.08328",
    "authors": [
      "Jaeyoung Chung",
      "Kanggeon Lee",
      "Sungyong Baik",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08472",
    "title": "One-Stage Cascade Refinement Networks for Infrared Small Target  Detection",
    "abstract": " Comments: Submitted to TGRS ",
    "url": "https://arxiv.org/abs/2212.08472",
    "authors": [
      "Yimian Dai",
      "Xiang Li",
      "Fei Zhou",
      "Yulei Qian",
      "Yaohong Chen",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12990",
    "title": "Unsupervised Representation Learning from Pre-trained Diffusion  Probabilistic Models",
    "abstract": " Comments: Accepted by NeurIPS 2022 Conference ",
    "url": "https://arxiv.org/abs/2212.12990",
    "authors": [
      "Zijian Zhang",
      "Zhou Zhao",
      "Zhijie Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.13939",
    "title": "Data Augmentation using Transformers and Similarity Measures for  Improving Arabic Text Classification",
    "abstract": " Comments: 15 pages, 6 Figures, this work has been submitted to the IEEE Access Journal for possible publication ",
    "url": "https://arxiv.org/abs/2212.13939",
    "authors": [
      "Dania Refai",
      "Saleh Abo-Soud",
      "Mohammad Abdel-Rahman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.14049",
    "title": "Differentiable Search of Accurate and Robust Architectures",
    "abstract": " Title: Differentiable Search of Accurate and Robust Architectures ",
    "url": "https://arxiv.org/abs/2212.14049",
    "authors": [
      "Yuwei Ou",
      "Xiangning Xie",
      "Shangce Gao",
      "Yanan Sun",
      "Kay Chen Tan",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.14289",
    "title": "High-temporal-resolution event-based vehicle detection and tracking",
    "abstract": " Comments: 38 pages, 9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2212.14289",
    "authors": [
      "Zaid El-Shair",
      "Samir Rawashdeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.14457",
    "title": "Bayesian Interpolation with Deep Linear Networks",
    "abstract": " Title: Bayesian Interpolation with Deep Linear Networks ",
    "url": "https://arxiv.org/abs/2212.14457",
    "authors": [
      "Boris Hanin",
      "Alexander Zlokapa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  }
]