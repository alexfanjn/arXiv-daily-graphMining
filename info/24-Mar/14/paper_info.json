[
  {
    "id": "arXiv:2403.07885",
    "title": "MOD-CL: Multi-label Object Detection with Constrained Loss",
    "abstract": "We introduce MOD-CL, a multi-label object detection framework that utilizes constrained loss in the training process to produce outputs that better satisfy the given requirements. In this paper, we use $\\mathrm{MOD_{YOLO}}$, a multi-label object detection model built upon the state-of-the-art object detection model YOLOv8, which has been published in recent years. In Task 1, we introduce the Corrector Model and Blender Model, two new models that follow after the object detection process, aiming to generate a more constrained output. For Task 2, constrained losses have been incorporated into the $\\mathrm{MOD_{YOLO}}$ architecture using Product T-Norm. The results show that these implementations are instrumental to improving the scores for both Task 1 and Task 2. ",
    "url": "https://arxiv.org/abs/2403.07885",
    "authors": [
      "Sota Moriyama",
      "Koji Watanabe",
      "Katsumi Inoue",
      "Akihiro Takemura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07886",
    "title": "A Memetic Algorithm To Find a Hamiltonian Cycle in a Hamiltonian Graph",
    "abstract": "We present a memetic algorithm (\\maa) approach for finding a Hamiltonian cycle in a Hamiltonian graph. The \\ma is based on a proven approach to the Asymmetric Travelling Salesman Problem (\\atspp) that, in this contribution, is boosted by the introduction of more powerful local searches. Our approach also introduces a novel technique that sparsifies the input graph under consideration for Hamiltonicity and dynamically augments it during the search. Such a combined heuristic approach helps to prove Hamiltonicity by finding a Hamiltonian cycle in less time. In addition, we also employ a recently introduced polynomial-time reduction from the \\hamcyc to the Symmetric \\tsp, which is based on computing the transitive closure of the graph. Although our approach is a metaheuristic, i.e., it does not give a theoretical guarantee for finding a Hamiltonian cycle, we have observed that the method is successful in practice in verifying the Hamiltonicity of a larger number of instances from the \\textit{Flinder University Hamiltonian Cycle Problem Challenge Set} (\\fhcpsc), even for the graphs that have large treewidth. The experiments on the \\fhcpscc instances and a computational comparison with five recent state-of-the-art baseline approaches show that the proposed method outperforms those for the majority of the instances in the \\fhcpsc. ",
    "url": "https://arxiv.org/abs/2403.07886",
    "authors": [
      "Sarwan Ali",
      "Pablo Moscato"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.07887",
    "title": "Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot  Representations",
    "abstract": "Object-centric methods have seen significant progress in unsupervised decomposition of raw perception into rich object-like abstractions. However, limited ability to ground object semantics of the real world into the learned abstractions has hindered their adoption in downstream understanding applications. We present the Neural Slot Interpreter (NSI) that learns to ground and generate object semantics via slot representations. At the core of NSI is an XML-like programming language that uses simple syntax rules to organize the object semantics of a scene into object-centric program primitives. Then, an alignment model learns to ground program primitives into slots through a bi-level contrastive learning objective over a shared embedding space. Finally, we formulate the NSI program generator model to use the dense associations inferred from the alignment model to generate object-centric programs from slots. Experiments on bi-modal retrieval tasks demonstrate the efficacy of the learned alignments, surpassing set-matching-based predictors by a significant margin. Moreover, learning the program generator from grounded associations enhances the predictive power of slots. NSI generated programs demonstrate improved performance of object-centric learners on property prediction and object detection, and scale with real-world scene complexity. ",
    "url": "https://arxiv.org/abs/2403.07887",
    "authors": [
      "Bhishma Dedhia",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07891",
    "title": "Digital Video Manipulation Detection Technique Based on Compression  Algorithms",
    "abstract": "Digital images and videos play a very important role in everyday life. Nowadays, people have access the affordable mobile devices equipped with advanced integrated cameras and powerful image processing applications. Technological development facilitates not only the generation of multimedia content, but also the intentional modification of it, either with recreational or malicious purposes. This is where forensic techniques to detect manipulation of images and videos become essential. This paper proposes a forensic technique by analysing compression algorithms used by the H.264 coding. The presence of recompression uses information of macroblocks, a characteristic of the H.264-MPEG4 standard, and motion vectors. A Vector Support Machine is used to create the model that allows to accurately detect if a video has been recompressed. ",
    "url": "https://arxiv.org/abs/2403.07891",
    "authors": [
      "Edgar Gonzalez Fernandez",
      "Ana Lucila Sandoval Orozco",
      "Luis Javier Garcia Villalba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07917",
    "title": "A Neural-Evolutionary Algorithm for Autonomous Transit Network Design",
    "abstract": "Planning a public transit network is a challenging optimization problem, but essential in order to realize the benefits of autonomous buses. We propose a novel algorithm for planning networks of routes for autonomous buses. We first train a graph neural net model as a policy for constructing route networks, and then use the policy as one of several mutation operators in a evolutionary algorithm. We evaluate this algorithm on a standard set of benchmarks for transit network design, and find that it outperforms the learned policy alone by up to 20% and a plain evolutionary algorithm approach by up to 53% on realistic benchmark instances. ",
    "url": "https://arxiv.org/abs/2403.07917",
    "authors": [
      "Andrew Holliday",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07919",
    "title": "Freshness-aware Resource Allocation for Non-orthogonal Wireless-powered  IoT Networks",
    "abstract": "This paper investigates a wireless-powered Internet of Things (IoT) network comprising a hybrid access point (HAP) and two devices. The HAP facilitates downlink wireless energy transfer (WET) for device charging and uplink wireless information transfer (WIT) to collect status updates from the devices. To keep the information fresh, concurrent WET and WIT are allowed, and orthogonal multiple access (OMA) and non-orthogonal multiple access (NOMA) are adaptively scheduled for WIT. Consequently, we formulate an expected weighted sum age of information (EWSAoI) minimization problem to adaptively schedule the transmission scheme, choosing from WET, OMA, NOMA, and WET+OMA, and to allocate transmit power. To address this, we reformulate the problem as a Markov decision process (MDP) and develop an optimal policy based on instantaneous AoI and remaining battery power to determine scheme selection and transmit power allocation. Extensive results demonstrate the effectiveness of the proposed policy, and the optimal policy has a distinct decision boundary-switching property, providing valuable insights for practical system design. ",
    "url": "https://arxiv.org/abs/2403.07919",
    "authors": [
      "Yunfeng Chen",
      "Yong Liu",
      "Jinhao Xiao",
      "Qunying Wu",
      "Han Zhang",
      "Fen Hou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.07942",
    "title": "Attacking Transformers with Feature Diversity Adversarial Perturbation",
    "abstract": "Understanding the mechanisms behind Vision Transformer (ViT), particularly its vulnerability to adversarial perturba tions, is crucial for addressing challenges in its real-world applications. Existing ViT adversarial attackers rely on la bels to calculate the gradient for perturbation, and exhibit low transferability to other structures and tasks. In this paper, we present a label-free white-box attack approach for ViT-based models that exhibits strong transferability to various black box models, including most ViT variants, CNNs, and MLPs, even for models developed for other modalities. Our inspira tion comes from the feature collapse phenomenon in ViTs, where the critical attention mechanism overly depends on the low-frequency component of features, causing the features in middle-to-end layers to become increasingly similar and eventually collapse. We propose the feature diversity attacker to naturally accelerate this process and achieve remarkable performance and transferability. ",
    "url": "https://arxiv.org/abs/2403.07942",
    "authors": [
      "Chenxing Gao",
      "Hang Zhou",
      "Junqing Yu",
      "YuTeng Ye",
      "Jiale Cai",
      "Junle Wang",
      "Wei Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.07943",
    "title": "Revisiting Edge Perturbation for Graph Neural Network in Graph Data  Augmentation and Attack",
    "abstract": "Edge perturbation is a basic method to modify graph structures. It can be categorized into two veins based on their effects on the performance of graph neural networks (GNNs), i.e., graph data augmentation and attack. Surprisingly, both veins of edge perturbation methods employ the same operations, yet yield opposite effects on GNNs' accuracy. A distinct boundary between these methods in using edge perturbation has never been clearly defined. Consequently, inappropriate perturbations may lead to undesirable outcomes, necessitating precise adjustments to achieve desired effects. Therefore, questions of ``why edge perturbation has a two-faced effect?'' and ``what makes edge perturbation flexible and effective?'' still remain unanswered. In this paper, we will answer these questions by proposing a unified formulation and establishing a clear boundary between two categories of edge perturbation methods. Specifically, we conduct experiments to elucidate the differences and similarities between these methods and theoretically unify the workflow of these methods by casting it to one optimization problem. Then, we devise Edge Priority Detector (EPD) to generate a novel priority metric, bridging these methods up in the workflow. Experiments show that EPD can make augmentation or attack flexibly and achieve comparable or superior performance to other counterparts with less time overhead. ",
    "url": "https://arxiv.org/abs/2403.07943",
    "authors": [
      "Xin Liu",
      "Yuxiang Zhang",
      "Meng Wu",
      "Mingyu Yan",
      "Kun He",
      "Wei Yan",
      "Shirui Pan",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.07952",
    "title": "AesopAgent: Agent-driven Evolutionary System on Story-to-Video  Production",
    "abstract": "The Agent and AIGC (Artificial Intelligence Generated Content) technologies have recently made significant progress. We propose AesopAgent, an Agent-driven Evolutionary System on Story-to-Video Production. AesopAgent is a practical application of agent technology for multimodal content generation. The system integrates multiple generative capabilities within a unified framework, so that individual users can leverage these modules easily. This innovative system would convert user story proposals into scripts, images, and audio, and then integrate these multimodal contents into videos. Additionally, the animating units (e.g., Gen-2 and Sora) could make the videos more infectious. The AesopAgent system could orchestrate task workflow for video generation, ensuring that the generated video is both rich in content and coherent. This system mainly contains two layers, i.e., the Horizontal Layer and the Utility Layer. In the Horizontal Layer, we introduce a novel RAG-based evolutionary system that optimizes the whole video generation workflow and the steps within the workflow. It continuously evolves and iteratively optimizes workflow by accumulating expert experience and professional knowledge, including optimizing the LLM prompts and utilities usage. The Utility Layer provides multiple utilities, leading to consistent image generation that is visually coherent in terms of composition, characters, and style. Meanwhile, it provides audio and special effects, integrating them into expressive and logically arranged videos. Overall, our AesopAgent achieves state-of-the-art performance compared with many previous works in visual storytelling. Our AesopAgent is designed for convenient service for individual users, which is available on the following page: https://aesopai.github.io/. ",
    "url": "https://arxiv.org/abs/2403.07952",
    "authors": [
      "Jiuniu Wang",
      "Zehua Du",
      "Yuyuan Zhao",
      "Bo Yuan",
      "Kexiang Wang",
      "Jian Liang",
      "Yaxi Zhao",
      "Yihen Lu",
      "Gengliang Li",
      "Junlong Gao",
      "Xin Tu",
      "Zhenyu Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.07954",
    "title": "Optimizing Polynomial Graph Filters: A Novel Adaptive Krylov Subspace  Approach",
    "abstract": "Graph Neural Networks (GNNs), known as spectral graph filters, find a wide range of applications in web networks. To bypass eigendecomposition, polynomial graph filters are proposed to approximate graph filters by leveraging various polynomial bases for filter training. However, no existing studies have explored the diverse polynomial graph filters from a unified perspective for optimization. In this paper, we first unify polynomial graph filters, as well as the optimal filters of identical degrees into the Krylov subspace of the same order, thus providing equivalent expressive power theoretically. Next, we investigate the asymptotic convergence property of polynomials from the unified Krylov subspace perspective, revealing their limited adaptability in graphs with varying heterophily degrees. Inspired by those facts, we design a novel adaptive Krylov subspace approach to optimize polynomial bases with provable controllability over the graph spectrum so as to adapt various heterophily graphs. Subsequently, we propose AdaptKry, an optimized polynomial graph filter utilizing bases from the adaptive Krylov subspaces. Meanwhile, in light of the diverse spectral properties of complex graphs, we extend AdaptKry by leveraging multiple adaptive Krylov bases without incurring extra training costs. As a consequence, extended AdaptKry is able to capture the intricate characteristics of graphs and provide insights into their inherent complexity. We conduct extensive experiments across a series of real-world datasets. The experimental results demonstrate the superior filtering capability of AdaptKry, as well as the optimized efficacy of the adaptive Krylov basis. ",
    "url": "https://arxiv.org/abs/2403.07954",
    "authors": [
      "Keke Huang",
      "Wencai Cao",
      "Hoang Ta",
      "Xiaokui Xiao",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.07956",
    "title": "DeepCDCL: An CDCL-based Neural Network Verification Framework",
    "abstract": "Neural networks in safety-critical applications face increasing safety and security concerns due to their susceptibility to little disturbance. In this paper, we propose DeepCDCL, a novel neural network verification framework based on the Conflict-Driven Clause Learning (CDCL) algorithm. We introduce an asynchronous clause learning and management structure, reducing redundant time consumption compared to the direct application of the CDCL framework. Furthermore, we also provide a detailed evaluation of the performance of our approach on the ACAS Xu and MNIST datasets, showing that a significant speed-up is achieved in most cases. ",
    "url": "https://arxiv.org/abs/2403.07956",
    "authors": [
      "Zongxin Liu",
      "Pengfei Yang",
      "Lijun Zhang",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07957",
    "title": "Efficient Post-Training Augmentation for Adaptive Inference in  Heterogeneous and Distributed IoT Environments",
    "abstract": "Early Exit Neural Networks (EENNs) present a solution to enhance the efficiency of neural network deployments. However, creating EENNs is challenging and requires specialized domain knowledge, due to the large amount of additional design choices. To address this issue, we propose an automated augmentation flow that focuses on converting an existing model into an EENN. It performs all required design decisions for the deployment to heterogeneous or distributed hardware targets: Our framework constructs the EENN architecture, maps its subgraphs to the hardware targets, and configures its decision mechanism. To the best of our knowledge, it is the first framework that is able to perform all of these steps. We evaluated our approach on a collection of Internet-of-Things and standard image classification use cases. For a speech command detection task, our solution was able to reduce the mean operations per inference by 59.67%. For an ECG classification task, it was able to terminate all samples early, reducing the mean inference energy by 74.9% and computations by 78.3%. On CIFAR-10, our solution was able to achieve up to a 58.75% reduction in computations. The search on a ResNet-152 base model for CIFAR-10 took less than nine hours on a laptop CPU. Our proposed approach enables the creation of EENN optimized for IoT environments and can reduce the inference cost of Deep Learning applications on embedded and fog platforms, while also significantly reducing the search cost - making it more accessible for scientists and engineers in industry and research. The low search cost improves the accessibility of EENNs, with the potential to improve the efficiency of neural networks in a wide range of practical applications. ",
    "url": "https://arxiv.org/abs/2403.07957",
    "authors": [
      "Max Sponner",
      "Lorenzo Servadei",
      "Bernd Waschneck",
      "Robert Wille",
      "Akash Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07958",
    "title": "Temporal Decisions: Leveraging Temporal Correlation for Efficient  Decisions in Early Exit Neural Networks",
    "abstract": "Deep Learning is becoming increasingly relevant in Embedded and Internet-of-things applications. However, deploying models on embedded devices poses a challenge due to their resource limitations. This can impact the model's inference accuracy and latency. One potential solution are Early Exit Neural Networks, which adjust model depth dynamically through additional classifiers attached between their hidden layers. However, the real-time termination decision mechanism is critical for the system's efficiency, latency, and sustained accuracy. This paper introduces Difference Detection and Temporal Patience as decision mechanisms for Early Exit Neural Networks. They leverage the temporal correlation present in sensor data streams to efficiently terminate the inference. We evaluate their effectiveness in health monitoring, image classification, and wake-word detection tasks. Our novel contributions were able to reduce the computational footprint compared to established decision mechanisms significantly while maintaining higher accuracy scores. We achieved a reduction of mean operations per inference by up to 80% while maintaining accuracy levels within 5% of the original model. These findings highlight the importance of considering temporal correlation in sensor data to improve the termination decision. ",
    "url": "https://arxiv.org/abs/2403.07958",
    "authors": [
      "Max Sponner",
      "Lorenzo Servadei",
      "Bernd Waschneck",
      "Robert Wille",
      "Akash Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07965",
    "title": "Conditional computation in neural networks: principles and research  trends",
    "abstract": "This article summarizes principles and ideas from the emerging area of applying \\textit{conditional computation} methods to the design of neural networks. In particular, we focus on neural networks that can dynamically activate or de-activate parts of their computational graph conditionally on their input. Examples include the dynamic selection of, e.g., input tokens, layers (or sets of layers), and sub-modules inside each layer (e.g., channels in a convolutional filter). We first provide a general formalism to describe these techniques in an uniform way. Then, we introduce three notable implementations of these principles: mixture-of-experts (MoEs) networks, token selection mechanisms, and early-exit neural networks. The paper aims to provide a tutorial-like introduction to this growing field. To this end, we analyze the benefits of these modular designs in terms of efficiency, explainability, and transfer learning, with a focus on emerging applicative areas ranging from automated scientific discovery to semantic communication. ",
    "url": "https://arxiv.org/abs/2403.07965",
    "authors": [
      "Simone Scardapane",
      "Alessandro Baiocchi",
      "Alessio Devoto",
      "Valerio Marsocci",
      "Pasquale Minervini",
      "Jary Pomponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07967",
    "title": "Feasibility of machine learning-based rice yield prediction in India at  the district level using climate reanalysis data",
    "abstract": "Yield forecasting, the science of predicting agricultural productivity before the crop harvest occurs, helps a wide range of stakeholders make better decisions around agricultural planning. This study aims to investigate whether machine learning-based yield prediction models can capably predict Kharif season rice yields at the district level in India several months before the rice harvest takes place. The methodology involved training 19 machine learning models such as CatBoost, LightGBM, Orthogonal Matching Pursuit, and Extremely Randomized Trees on 20 years of climate, satellite, and rice yield data across 247 of Indian rice-producing districts. In addition to model-building, a dynamic dashboard was built understand how the reliability of rice yield predictions varies across districts. The results of the proof-of-concept machine learning pipeline demonstrated that rice yields can be predicted with a reasonable degree of accuracy, with out-of-sample R2, MAE, and MAPE performance of up to 0.82, 0.29, and 0.16 respectively. These results outperformed test set performance reported in related literature on rice yield modeling in other contexts and countries. In addition, SHAP value analysis was conducted to infer both the importance and directional impact of the climate and remote sensing variables included in the model. Important features driving rice yields included temperature, soil water volume, and leaf area index. In particular, higher temperatures in August correlate with increased rice yields, particularly when the leaf area index in August is also high. Building on the results, a proof-of-concept dashboard was developed to allow users to easily explore which districts may experience a rise or fall in yield relative to the previous year. ",
    "url": "https://arxiv.org/abs/2403.07967",
    "authors": [
      "Djavan De Clercq",
      "Adam Mahdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07968",
    "title": "Do Deep Neural Network Solutions Form a Star Domain?",
    "abstract": "Entezari et al. (2022) conjectured that neural network solution sets reachable via stochastic gradient descent (SGD) are convex, considering permutation invariances. This means that two independent solutions can be connected by a linear path with low loss, given one of them is appropriately permuted. However, current methods to test this theory often fail to eliminate loss barriers between two independent solutions (Ainsworth et al., 2022; Benzing et al., 2022). In this work, we conjecture that a more relaxed claim holds: the SGD solution set is a star domain that contains a star model that is linearly connected to all the other solutions via paths with low loss values, modulo permutations. We propose the Starlight algorithm that finds a star model of a given learning task. We validate our claim by showing that this star model is linearly connected with other independently found solutions. As an additional benefit of our study, we demonstrate better uncertainty estimates on Bayesian Model Averaging over the obtained star domain. Code is available at https://github.com/aktsonthalia/starlight. ",
    "url": "https://arxiv.org/abs/2403.07968",
    "authors": [
      "Ankit Sonthalia",
      "Alexander Rubinstein",
      "Ehsan Abbasnejad",
      "Seong Joon Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.07974",
    "title": "LiveCodeBench: Holistic and Contamination Free Evaluation of Large  Language Models for Code",
    "abstract": "Large Language Models (LLMs) applied to code-related applications have emerged as a prominent field, attracting significant interest from both academia and industry. However, as new and improved LLMs are developed, existing evaluation benchmarks (e.g., HumanEval, MBPP) are no longer sufficient for assessing their capabilities. In this work, we propose LiveCodeBench, a comprehensive and contamination-free evaluation of LLMs for code, which continuously collects new problems over time from contests across three competition platforms, namely LeetCode, AtCoder, and CodeForces. Notably, our benchmark also focuses on a broader range of code related capabilities, such as self-repair, code execution, and test output prediction, beyond just code generation. Currently, LiveCodeBench hosts four hundred high-quality coding problems that were published between May 2023 and February 2024. We have evaluated 9 base LLMs and 20 instruction-tuned LLMs on LiveCodeBench. We present empirical findings on contamination, holistic performance comparisons, potential overfitting in existing benchmarks as well as individual model comparisons. We will release all prompts and model completions for further community analysis, along with a general toolkit for adding new scenarios and model ",
    "url": "https://arxiv.org/abs/2403.07974",
    "authors": [
      "Naman Jain",
      "King Han",
      "Alex Gu",
      "Wen-Ding Li",
      "Fanjia Yan",
      "Tianjun Zhang",
      "Sida Wang",
      "Armando Solar-Lezama",
      "Koushik Sen",
      "Ion Stoica"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08000",
    "title": "Overlapping community detection algorithms using Modularity and the  cosine",
    "abstract": "The issue of network community detection has been extensively studied across many fields. Most community detection methods assume that nodes belong to only one community. However, in many cases, nodes can belong to multiple communities simultaneously.This paper presents two overlapping network community detection algorithms that build on the two-step approach, using the extended modularity and cosine function. The applicability of our algorithms extends to both undirected and directed graph structures. To demonstrate the feasibility and effectiveness of these algorithms, we conducted experiments using real data. ",
    "url": "https://arxiv.org/abs/2403.08000",
    "authors": [
      "Do Duy Hieu",
      "Phan Thi Ha Duong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.08011",
    "title": "Gujarati-English Code-Switching Speech Recognition using ensemble  prediction of spoken language",
    "abstract": "An important and difficult task in code-switched speech recognition is to recognize the language, as lots of words in two languages can sound similar, especially in some accents. We focus on improving performance of end-to-end Automatic Speech Recognition models by conditioning transformer layers on language ID of words and character in the output in an per layer supervised manner. To this end, we propose two methods of introducing language specific parameters and explainability in the multi-head attention mechanism, and implement a Temporal Loss that helps maintain continuity in input alignment. Despite being unable to reduce WER significantly, our method shows promise in predicting the correct language from just spoken data. We introduce regularization in the language prediction by dropping LID in the sequence, which helps align long repeated output sequences. ",
    "url": "https://arxiv.org/abs/2403.08011",
    "authors": [
      "Yash Sharma",
      "Basil Abraham",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08013",
    "title": "Supervised Time Series Classification for Anomaly Detection in Subsea  Engineering",
    "abstract": "Time series classification is of significant importance in monitoring structural systems. In this work, we investigate the use of supervised machine learning classification algorithms on simulated data based on a physical system with two states: Intact and Broken. We provide a comprehensive discussion of the preprocessing of temporal data, using measures of statistical dispersion and dimension reduction techniques. We present an intuitive baseline method and discuss its efficiency. We conclude with a comparison of the various methods based on different performance metrics, showing the advantage of using machine learning techniques as a tool in decision making. ",
    "url": "https://arxiv.org/abs/2403.08013",
    "authors": [
      "Ergys \u00c7okaj",
      "Halvor Snersrud Gustad",
      "Andrea Leone",
      "Per Thomas Moe",
      "Lasse Moldestad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2403.08027",
    "title": "McCatch: Scalable Microcluster Detection in Dimensional and  Nondimensional Datasets",
    "abstract": "How could we have an outlier detector that works even with nondimensional data, and ranks together both singleton microclusters ('one-off' outliers) and nonsingleton microclusters by their anomaly scores? How to obtain scores that are principled in one scalable and 'hands-off' manner? Microclusters of outliers indicate coalition or repetition in fraud activities, etc.; their identification is thus highly desirable. This paper presents McCatch: a new algorithm that detects microclusters by leveraging our proposed 'Oracle' plot (1NN Distance versus Group 1NN Distance). We study 31 real and synthetic datasets with up to 1M data elements to show that McCatch is the only method that answers both of the questions above; and, it outperforms 11 other methods, especially when the data has nonsingleton microclusters or is nondimensional. We also showcase McCatch's ability to detect meaningful microclusters in graphs, fingerprints, logs of network connections, text data, and satellite imagery. For example, it found a 30-elements microcluster of confirmed 'Denial of Service' attacks in the network logs, taking only ~3 minutes for 222K data elements on a stock desktop. ",
    "url": "https://arxiv.org/abs/2403.08027",
    "authors": [
      "Braulio V. S\u00e1nchez Vinces",
      "Robson L. F. Cordeiro",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08032",
    "title": "LG-Traj: LLM Guided Pedestrian Trajectory Prediction",
    "abstract": "Accurate pedestrian trajectory prediction is crucial for various applications, and it requires a deep understanding of pedestrian motion patterns in dynamic environments. However, existing pedestrian trajectory prediction methods still need more exploration to fully leverage these motion patterns. This paper investigates the possibilities of using Large Language Models (LLMs) to improve pedestrian trajectory prediction tasks by inducing motion cues. We introduce LG-Traj, a novel approach incorporating LLMs to generate motion cues present in pedestrian past/observed trajectories. Our approach also incorporates motion cues present in pedestrian future trajectories by clustering future trajectories of training data using a mixture of Gaussians. These motion cues, along with pedestrian coordinates, facilitate a better understanding of the underlying representation. Furthermore, we utilize singular value decomposition to augment the observed trajectories, incorporating them into the model learning process to further enhance representation learning. Our method employs a transformer-based architecture comprising a motion encoder to model motion patterns and a social decoder to capture social interactions among pedestrians. We demonstrate the effectiveness of our approach on popular pedestrian trajectory prediction benchmarks, namely ETH-UCY and SDD, and present various ablation experiments to validate our approach. ",
    "url": "https://arxiv.org/abs/2403.08032",
    "authors": [
      "Pranav Singh Chib",
      "Pravendra Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08035",
    "title": "Harnessing Artificial Intelligence to Combat Online Hate: Exploring the  Challenges and Opportunities of Large Language Models in Hate Speech  Detection",
    "abstract": "Large language models (LLMs) excel in many diverse applications beyond language generation, e.g., translation, summarization, and sentiment analysis. One intriguing application is in text classification. This becomes pertinent in the realm of identifying hateful or toxic speech -- a domain fraught with challenges and ethical dilemmas. In our study, we have two objectives: firstly, to offer a literature review revolving around LLMs as classifiers, emphasizing their role in detecting and classifying hateful or toxic content. Subsequently, we explore the efficacy of several LLMs in classifying hate speech: identifying which LLMs excel in this task as well as their underlying attributes and training. Providing insight into the factors that contribute to an LLM proficiency (or lack thereof) in discerning hateful content. By combining a comprehensive literature review with an empirical analysis, our paper strives to shed light on the capabilities and constraints of LLMs in the crucial domain of hate speech detection. ",
    "url": "https://arxiv.org/abs/2403.08035",
    "authors": [
      "Tharindu Kumarage",
      "Amrita Bhattacharjee",
      "Joshua Garland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08055",
    "title": "DrivAerNet: A Parametric Car Dataset for Data-Driven Aerodynamic Design  and Graph-Based Drag Prediction",
    "abstract": "This study introduces DrivAerNet, a large-scale high-fidelity CFD dataset of 3D industry-standard car shapes, and RegDGCNN, a dynamic graph convolutional neural network model, both aimed at aerodynamic car design through machine learning. DrivAerNet, with its 4000 detailed 3D car meshes using 0.5 million surface mesh faces and comprehensive aerodynamic performance data comprising of full 3D pressure, velocity fields, and wall-shear stresses, addresses the critical need for extensive datasets to train deep learning models in engineering applications. It is 60\\% larger than the previously available largest public dataset of cars, and is the only open-source dataset that also models wheels and underbody. RegDGCNN leverages this large-scale dataset to provide high-precision drag estimates directly from 3D meshes, bypassing traditional limitations such as the need for 2D image rendering or Signed Distance Fields (SDF). By enabling fast drag estimation in seconds, RegDGCNN facilitates rapid aerodynamic assessments, offering a substantial leap towards integrating data-driven methods in automotive design. Together, DrivAerNet and RegDGCNN promise to accelerate the car design process and contribute to the development of more efficient vehicles. To lay the groundwork for future innovations in the field, the dataset and code used in our study are publicly accessible at \\url{https://github.com/Mohamedelrefaie/DrivAerNet} ",
    "url": "https://arxiv.org/abs/2403.08055",
    "authors": [
      "Mohamed Elrefaie",
      "Angela Dai",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2403.08056",
    "title": "Improving Memory Dependence Prediction with Static Analysis",
    "abstract": "This paper explores the potential of communicating information gained by static analysis from compilers to Out-of-Order (OoO) machines, focusing on the memory dependence predictor (MDP). The MDP enables loads to issue without all in-flight store addresses being known, with minimal memory order violations. We use LLVM to find loads with no dependencies and label them via their opcode. These labelled loads skip making lookups into the MDP, improving prediction accuracy by reducing false dependencies. We communicate this information in a minimally intrusive way, i.e.~without introducing additional hardware costs or instruction bandwidth, providing these improvements without any additional overhead in the CPU. We find that in select cases in Spec2017, a significant number of load instructions can skip interacting with the MDP and lead to a performance gain. These results point to greater possibilities for static analysis as a source of near zero cost performance gains in future CPU designs. ",
    "url": "https://arxiv.org/abs/2403.08056",
    "authors": [
      "Luke Panayi",
      "Rohan Gandhi",
      "Jim Whittaker",
      "Vassilios Chouliaras",
      "Martin Berger",
      "Paul Kelly"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.08057",
    "title": "MineXR: Mining Personalized Extended Reality Interfaces",
    "abstract": "Extended Reality (XR) interfaces offer engaging user experiences, but their effective design requires a nuanced understanding of user behavior and preferences. This knowledge is challenging to obtain without the widespread adoption of XR devices. We introduce MineXR, a design mining workflow and data analysis platform for collecting and analyzing personalized XR user interaction and experience data. MineXR enables elicitation of personalized interfaces from participants of a data collection: for any particular context, participants create interface elements using application screenshots from their own smartphone, place them in the environment, and simultaneously preview the resulting XR layout on a headset. Using MineXR, we contribute a dataset of personalized XR interfaces collected from 31 participants, consisting of 695 XR widgets created from 178 unique applications. We provide insights for XR widget functionalities, categories, clusters, UI element types, and placement. Our open-source tools and data support researchers and designers in developing future XR interfaces. ",
    "url": "https://arxiv.org/abs/2403.08057",
    "authors": [
      "Hyunsung Cho",
      "Yukang Yan",
      "Kashyap Todi",
      "Mark Parent",
      "Missie Smith",
      "Tanya R. Jonker",
      "Hrvoje Benko",
      "David Lindlbauer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.08063",
    "title": "Towards Code Generation for Octree-Based Multigrid Solvers",
    "abstract": "This paper presents a novel method designed to generate multigrid solvers optimized for octree-based software frameworks. Our approach focuses on accurately capturing local features within a domain while leveraging the efficiency inherent in multigrid techniques. We outline the essential steps involved in generating specialized kernels for local refinement and communication routines, integrating on-the-fly interpolations to seamlessly transfer information between refinement levels. For this purpose, we established a software coupling via an automatic fusion of generated multigrid solvers and communication kernels with manual implementations of complex octree data structures and algorithms often found in established software frameworks. We demonstrate the effectiveness of our method through numerical experiments with different interpolation orders. Large-scale benchmarks conducted on the SuperMUC-NG CPU cluster underscore the advantages of our approach, offering a comparison against a reference implementation to highlight the benefits of our method and code generation in general. ",
    "url": "https://arxiv.org/abs/2403.08063",
    "authors": [
      "Richard Angersbach",
      "Sebastian Kuckuck",
      "Harald K\u00f6stler"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2403.08077",
    "title": "A Multimodal Intermediate Fusion Network with Manifold Learning for  Stress Detection",
    "abstract": "Multimodal deep learning methods capture synergistic features from multiple modalities and have the potential to improve accuracy for stress detection compared to unimodal methods. However, this accuracy gain typically comes from high computational cost due to the high-dimensional feature spaces, especially for intermediate fusion. Dimensionality reduction is one way to optimize multimodal learning by simplifying data and making the features more amenable to processing and analysis, thereby reducing computational complexity. This paper introduces an intermediate multimodal fusion network with manifold learning-based dimensionality reduction. The multimodal network generates independent representations from biometric signals and facial landmarks through 1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN layer, followed by a fully connected dense layer. We compared various dimensionality reduction techniques for different variations of unimodal and multimodal networks. We observe that the intermediate-level fusion with the Multi-Dimensional Scaling (MDS) manifold method showed promising results with an accuracy of 96.00\\% in a Leave-One-Subject-Out Cross-Validation (LOSO-CV) paradigm over other dimensional reduction methods. MDS had the highest computational cost among manifold learning methods. However, while outperforming other networks, it managed to reduce the computational cost of the proposed networks by 25\\% when compared to six well-known conventional feature selection methods used in the preprocessing step. ",
    "url": "https://arxiv.org/abs/2403.08077",
    "authors": [
      "Morteza Bodaghi",
      "Majid Hosseini",
      "Raju Gottumukkala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08079",
    "title": "BayesFLo: Bayesian fault localization of complex software systems",
    "abstract": "Software testing is essential for the reliable development of complex software systems. A key step in software testing is fault localization, which uses test data to pinpoint failure-inducing combinations for further diagnosis. Existing fault localization methods, however, are largely deterministic, and thus do not provide a principled approach for assessing probabilistic risk of potential root causes, or for integrating domain and/or structural knowledge from test engineers. To address this, we propose a novel Bayesian fault localization framework called BayesFLo, which leverages a flexible Bayesian model on potential root cause combinations. A key feature of BayesFLo is its integration of the principles of combination hierarchy and heredity, which capture the structured nature of failure-inducing combinations. A critical challenge, however, is the sheer number of potential root cause scenarios to consider, which renders the computation of posterior root cause probabilities infeasible even for small software systems. We thus develop new algorithms for efficient computation of such probabilities, leveraging recent tools from integer programming and graph representations. We then demonstrate the effectiveness of BayesFLo over state-of-the-art fault localization methods, in a suite of numerical experiments and in two motivating case studies on the JMP XGBoost interface. ",
    "url": "https://arxiv.org/abs/2403.08079",
    "authors": [
      "Yi Ji",
      "Simon Mak",
      "Ryan Lekivetz",
      "Joseph Morgan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.08081",
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "abstract": "Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$ $\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$ $\\textit{next-token}$ $\\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$ $\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with the last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures. ",
    "url": "https://arxiv.org/abs/2403.08081",
    "authors": [
      "Yingcong Li",
      "Yixiao Huang",
      "M. Emrullah Ildiz",
      "Ankit Singh Rawat",
      "Samet Oymak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.08082",
    "title": "Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis  in the Energy Industry",
    "abstract": "As the most critical production factor in the era of the digital economy, data will have a significant impact on social production and development. Energy enterprises possess data that is interconnected with multiple industries, characterized by diverse needs, sensitivity, and long-term nature. The path to monetizing energy enterprises' data is challenging yet crucial. This paper explores the game-theoretic aspects of the data monetization process in energy enterprises by considering the relationships between enterprises and trading platforms. We construct a class of game decision models and study their equilibrium strategies. Our analysis shows that enterprises and platforms can adjust respective benefits by regulating the wholesale price of data and the intensity of data value mining to form a benign equilibrium state. Furthermore, by integrating nonlinear dynamical theory, we discuss the dynamic characteristics present in multi-period repeated game processes. We find that decision-makers should keep the adjustment parameters and initial states within reasonable ranges in multi-period dynamic decision-making to avoid market failure. Finally, based on the theoretical and numerical analysis, we provide decision insights and recommendations for enterprise decision-making to facilitate data monetization through strategic interactions with trading platforms. ",
    "url": "https://arxiv.org/abs/2403.08082",
    "authors": [
      "Zongxian Wang",
      "Jie Song"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.08094",
    "title": "Task and Motion Planning in Hierarchical 3D Scene Graphs",
    "abstract": "Recent work in the construction of 3D scene graphs has enabled mobile robots to build large-scale hybrid metric-semantic hierarchical representations of the world. These detailed models contain information that is useful for planning, however how to derive a planning domain from a 3D scene graph that enables efficient computation of executable plans is an open question. In this work, we present a novel approach for defining and solving Task and Motion Planning problems in large-scale environments using hierarchical 3D scene graphs. We identify a method for building sparse problem domains which enable scaling to large scenes, and propose a technique for incrementally adding objects to that domain during planning time to avoid wasting computation on irrelevant elements of the scene graph. We test our approach in two hand crafted domains as well as two scene graphs built from perception, including one constructed from the KITTI dataset. A video supplement is available at https://youtu.be/63xuCCaN0I4. ",
    "url": "https://arxiv.org/abs/2403.08094",
    "authors": [
      "Aaron Ray",
      "Christopher Bradley",
      "Luca Carlone",
      "Nicholas Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.08108",
    "title": "TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object  Detection",
    "abstract": "Task-oriented object detection aims to find objects suitable for accomplishing specific tasks. As a challenging task, it requires simultaneous visual data processing and reasoning under ambiguous semantics. Recent solutions are mainly all-in-one models. However, the object detection backbones are pre-trained without text supervision. Thus, to incorporate task requirements, their intricate models undergo extensive learning on a highly imbalanced and scarce dataset, resulting in capped performance, laborious training, and poor generalizability. In contrast, we propose TaskCLIP, a more natural two-stage design composed of general object detection and task-guided object selection. Particularly for the latter, we resort to the recently successful large Vision-Language Models (VLMs) as our backbone, which provides rich semantic knowledge and a uniform embedding space for images and texts. Nevertheless, the naive application of VLMs leads to sub-optimal quality, due to the misalignment between embeddings of object images and their visual attributes, which are mainly adjective phrases. To this end, we design a transformer-based aligner after the pre-trained VLMs to re-calibrate both embeddings. Finally, we employ a trainable score function to post-process the VLM matching results for object selection. Experimental results demonstrate that our TaskCLIP outperforms the state-of-the-art DETR-based model TOIST by 3.5% and only requires a single NVIDIA RTX 4090 for both training and inference. ",
    "url": "https://arxiv.org/abs/2403.08108",
    "authors": [
      "Hanning Chen",
      "Wenjun Huang",
      "Yang Ni",
      "Sanggeon Yun",
      "Fei Wen",
      "Hugo Latapie",
      "Mohsen Imani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08109",
    "title": "VANP: Learning Where to See for Navigation with Self-Supervised  Vision-Action Pre-Training",
    "abstract": "Humans excel at efficiently navigating through crowds without collision by focusing on specific visual regions relevant to navigation. However, most robotic visual navigation methods rely on deep learning models pre-trained on vision tasks, which prioritize salient objects -- not necessarily relevant to navigation and potentially misleading. Alternative approaches train specialized navigation models from scratch, requiring significant computation. On the other hand, self-supervised learning has revolutionized computer vision and natural language processing, but its application to robotic navigation remains underexplored due to the difficulty of defining effective self-supervision signals. Motivated by these observations, in this work, we propose a Self-Supervised Vision-Action Model for Visual Navigation Pre-Training (VANP). Instead of detecting salient objects that are beneficial for tasks such as classification or detection, VANP learns to focus only on specific visual regions that are relevant to the navigation task. To achieve this, VANP uses a history of visual observations, future actions, and a goal image for self-supervision, and embeds them using two small Transformer Encoders. Then, VANP maximizes the information between the embeddings by using a mutual information maximization objective function. We demonstrate that most VANP-extracted features match with human navigation intuition. VANP achieves comparable performance as models learned end-to-end with half the training time and models trained on a large-scale, fully supervised dataset, i.e., ImageNet, with only 0.08% data. ",
    "url": "https://arxiv.org/abs/2403.08109",
    "authors": [
      "Mohammad Nazeri",
      "Junzhe Wang",
      "Amirreza Payandeh",
      "Xuesu Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08111",
    "title": "AI-Assisted Causal Pathway Diagram for Human-Centered Design",
    "abstract": "This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers (N=20), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs. ",
    "url": "https://arxiv.org/abs/2403.08111",
    "authors": [
      "Ruican Zhong",
      "Donghoon Shin",
      "Rosemary Meza",
      "Predrag Klasnja",
      "Lucas Colusso",
      "Gary Hsieh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.08115",
    "title": "Legally Binding but Unfair? Towards Assessing Fairness of Privacy  Policies",
    "abstract": "Privacy policies are expected to inform data subjects about their data protection rights. They should explain the data controller's data management practices, and make facts such as retention periods or data transfers to third parties transparent. Privacy policies only fulfill their purpose, if they are correctly perceived, interpreted, understood, and trusted by the data subject. Amongst others, this requires that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background. In this work-in-progress paper, we outline our approach to assessing fairness in privacy policies. To this end, we identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics/morality are related to privacy policies. We propose options to automatically assess policies in these fairness dimensions, based on text statistics, linguistic methods and artificial intelligence. Finally, we conduct initial experiments with German privacy policies to provide evidence that our approach is applicable. Our experiments indicate that there are indeed issues in all three dimensions of fairness. For example, our approach finds out if a policy discriminates against individuals with impaired reading skills or certain demographics, and identifies questionable ethics. This is important, as future privacy policies may be used in a corpus for legal artificial intelligence models. ",
    "url": "https://arxiv.org/abs/2403.08115",
    "authors": [
      "Vincent Freiberger",
      "Erik Buchmann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.08121",
    "title": "Early Directional Convergence in Deep Homogeneous Neural Networks for  Small Initializations",
    "abstract": "This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks, starting with small initializations. The present work considers neural networks that are assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. This paper demonstrates that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in norm and approximately converge in direction along the Karush-Kuhn-Tucker (KKT) points of the neural correlation function introduced in [1]. Additionally, for square loss and under a separability assumption on the weights of neural networks, a similar directional convergence of gradient flow dynamics is shown near certain saddle points of the loss function. ",
    "url": "https://arxiv.org/abs/2403.08121",
    "authors": [
      "Akshay Kumar",
      "Jarvis Haupt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08131",
    "title": "Cost-Effective Methodology for Complex Tuning Searches in HPC:  Navigating Interdependencies and Dimensionality",
    "abstract": "Tuning searches are pivotal in High-Performance Computing (HPC), addressing complex optimization challenges in computational applications. The complexity arises not only from finely tuning parameters within routines but also potential interdependencies among them, rendering traditional optimization methods inefficient. Instead of scrutinizing interdependencies among parameters and routines, practitioners often face the dilemma of conducting independent tuning searches for each routine, thereby overlooking interdependence, or pursuing a more resource-intensive joint search for all routines. This decision is driven by the consideration that some interdependence analysis and high-dimensional decomposition techniques in literature may be prohibitively expensive in HPC tuning searches. Our methodology adapts and refines these methods to ensure computational feasibility while maximizing performance gains in real-world scenarios. Our methodology leverages a cost-effective interdependence analysis to decide whether to merge several tuning searches into a joint search or conduct orthogonal searches. Tested on synthetic functions with varying levels of parameter interdependence, our methodology efficiently explores the search space. In comparison to Bayesian-optimization-based full independent or fully joint searches, our methodology suggested an optimized breakdown of independent and merged searches that led to final configurations up to 8% more accurate, reducing the search time by up to 95%. When applied to GPU-offloaded Real-Time Time-Dependent Density Functional Theory (RT-TDDFT), an application in computational materials science that challenges modern HPC autotuners, our methodology achieved an effective tuning search. Its adaptability and efficiency extend beyond RT-TDDFT, making it valuable for related applications in HPC. ",
    "url": "https://arxiv.org/abs/2403.08131",
    "authors": [
      "Adrian Perez Dieguez",
      "Min Choi",
      "Mahmut Okyay",
      "Mauro Del Ben",
      "Bryan M. Wong",
      "Khaled Z. Ibrahim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08132",
    "title": "Information Leakage through Physical Layer Supply Voltage Coupling  Vulnerability",
    "abstract": "Side-channel attacks exploit variations in non-functional behaviors to expose sensitive information across security boundaries. Existing methods leverage side-channels based on power consumption, electromagnetic radiation, silicon substrate coupling, and channels created by malicious implants. Power-based side-channel attacks are widely known for extracting information from data processed within a device while assuming that an attacker has physical access or the ability to modify the device. In this paper, we introduce a novel side-channel vulnerability that leaks data-dependent power variations through physical layer supply voltage coupling (PSVC). Unlike traditional power side-channel attacks, the proposed vulnerability allows an adversary to mount an attack and extract information without modifying the device. We assess the effectiveness of PSVC vulnerability through three case studies, demonstrating several end-to-end attacks on general-purpose microcontrollers with varying adversary capabilities. These case studies provide evidence for the existence of PSVC vulnerability, its applicability for on-chip as well as on-board side-channel attacks, and how it can eliminate the need for physical access to the target device, making it applicable to any off-the-shelf hardware. Our experiments also reveal that designing devices to operate at the lowest operational voltage significantly reduces the risk of PSVC side-channel vulnerability. ",
    "url": "https://arxiv.org/abs/2403.08132",
    "authors": [
      "Sahan Sanjaya",
      "Aruna Jayasena",
      "Prabhat Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.08149",
    "title": "On the Feasibility of EEG-based Motor Intention Detection for Real-Time  Robot Assistive Control",
    "abstract": "This paper explores the feasibility of employing EEG-based intention detection for real-time robot assistive control. We focus on predicting and distinguishing motor intentions of left/right arm movements by presenting: i) an offline data collection and training pipeline, used to train a classifier for left/right motion intention prediction, and ii) an online real-time prediction pipeline leveraging the trained classifier and integrated with an assistive robot. Central to our approach is a rich feature representation composed of the tangent space projection of time-windowed sample covariance matrices from EEG filtered signals and derivatives; allowing for a simple SVM classifier to achieve unprecedented accuracy and real-time performance. In pre-recorded real-time settings (160 Hz), a peak accuracy of 86.88% is achieved, surpassing prior works. In robot-in-the-loop settings, our system successfully detects intended motion solely from EEG data with 70% accuracy, triggering a robot to execute an assistive task. We provide a comprehensive evaluation of the proposed classifier. ",
    "url": "https://arxiv.org/abs/2403.08149",
    "authors": [
      "Ho Jin Choi",
      "Satyajeet Das",
      "Shaoting Peng",
      "Ruzena Bajcsy",
      "Nadia Figueroa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.08151",
    "title": "Measuring the Energy Consumption and Efficiency of Deep Neural Networks:  An Empirical Analysis and Design Recommendations",
    "abstract": "Addressing the so-called ``Red-AI'' trend of rising energy consumption by large-scale neural networks, this study investigates the actual energy consumption, as measured by node-level watt-meters, of training various fully connected neural network architectures. We introduce the BUTTER-E dataset, an augmentation to the BUTTER Empirical Deep Learning dataset, containing energy consumption and performance data from 63,527 individual experimental runs spanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of trainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU hardware collected using node-level watt-meters. This dataset reveals the complex relationship between dataset size, network structure, and energy use, and highlights the impact of cache effects. We propose a straightforward and effective energy model that accounts for network size, computing, and memory hierarchy. Our analysis also uncovers a surprising, hardware-mediated non-linear relationship between energy efficiency and network design, challenging the assumption that reducing the number of parameters or FLOPs is the best way to achieve greater energy efficiency. Highlighting the need for cache-considerate algorithm development, we suggest a combined approach to energy efficient network, algorithm, and hardware design. This work contributes to the fields of sustainable computing and Green AI, offering practical guidance for creating more energy-efficient neural networks and promoting sustainable AI. ",
    "url": "https://arxiv.org/abs/2403.08151",
    "authors": [
      "Charles Edison Tripp",
      "Jordan Perr-Sauer",
      "Jamil Gafur",
      "Amabarish Nag",
      "Avi Purkayastha",
      "Sagi Zisman",
      "Erik A. Bensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.08156",
    "title": "NeRF-Supervised Feature Point Detection and Description",
    "abstract": "Feature point detection and description is the backbone for various computer vision applications, such as Structure-from-Motion, visual SLAM, and visual place recognition. While learning-based methods have surpassed traditional handcrafted techniques, their training often relies on simplistic homography-based simulations of multi-view perspectives, limiting model generalisability. This paper introduces a novel approach leveraging neural radiance fields (NeRFs) for realistic multi-view training data generation. We create a diverse multi-view dataset using NeRFs, consisting of indoor and outdoor scenes. Our proposed methodology adapts state-of-the-art feature detectors and descriptors to train on NeRF-synthesised views supervised by perspective projective geometry. Our experiments demonstrate that the proposed methods achieve competitive or superior performance on standard benchmarks for relative pose estimation, point cloud registration, and homography estimation while requiring significantly less training data compared to existing approaches. ",
    "url": "https://arxiv.org/abs/2403.08156",
    "authors": [
      "Ali Youssef",
      "Francisco Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08157",
    "title": "Multiscale Low-Frequency Memory Network for Improved Feature Extraction  in Convolutional Neural Networks",
    "abstract": "Deep learning and Convolutional Neural Networks (CNNs) have driven major transformations in diverse research areas. However, their limitations in handling low-frequency information present obstacles in certain tasks like interpreting global structures or managing smooth transition images. Despite the promising performance of transformer structures in numerous tasks, their intricate optimization complexities highlight the persistent need for refined CNN enhancements using limited resources. Responding to these complexities, we introduce a novel framework, the Multiscale Low-Frequency Memory (MLFM) Network, with the goal to harness the full potential of CNNs while keeping their complexity unchanged. The MLFM efficiently preserves low-frequency information, enhancing performance in targeted computer vision tasks. Central to our MLFM is the Low-Frequency Memory Unit (LFMU), which stores various low-frequency data and forms a parallel channel to the core network. A key advantage of MLFM is its seamless compatibility with various prevalent networks, requiring no alterations to their original core structure. Testing on ImageNet demonstrated substantial accuracy improvements in multiple 2D CNNs, including ResNet, MobileNet, EfficientNet, and ConvNeXt. Furthermore, we showcase MLFM's versatility beyond traditional image classification by successfully integrating it into image-to-image translation tasks, specifically in semantic segmentation networks like FCN and U-Net. In conclusion, our work signifies a pivotal stride in the journey of optimizing the efficacy and efficiency of CNNs with limited resources. This research builds upon the existing CNN foundations and paves the way for future advancements in computer vision. Our codes are available at https://github.com/AlphaWuSeu/ MLFM. ",
    "url": "https://arxiv.org/abs/2403.08157",
    "authors": [
      "Fuzhi Wu",
      "Jiasong Wu",
      "Youyong Kong",
      "Chunfeng Yang",
      "Guanyu Yang",
      "Huazhong Shu",
      "Guy Carrault",
      "Lotfi Senhadji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08161",
    "title": "LAFS: Landmark-based Facial Self-supervised Learning for Face  Recognition",
    "abstract": "In this work we focus on learning facial representations that can be adapted to train effective face recognition models, particularly in the absence of labels. Firstly, compared with existing labelled face datasets, a vastly larger magnitude of unlabeled faces exists in the real world. We explore the learning strategy of these unlabeled facial images through self-supervised pretraining to transfer generalized face recognition performance. Moreover, motivated by one recent finding, that is, the face saliency area is critical for face recognition, in contrast to utilizing random cropped blocks of images for constructing augmentations in pretraining, we utilize patches localized by extracted facial landmarks. This enables our method - namely LAndmark-based Facial Self-supervised learning LAFS), to learn key representation that is more critical for face recognition. We also incorporate two landmark-specific augmentations which introduce more diversity of landmark information to further regularize the learning. With learned landmark-based facial representations, we further adapt the representation for face recognition with regularization mitigating variations in landmark positions. Our method achieves significant improvement over the state-of-the-art on multiple face recognition benchmarks, especially on more challenging few-shot scenarios. ",
    "url": "https://arxiv.org/abs/2403.08161",
    "authors": [
      "Zhonglin Sun",
      "Chen Feng",
      "Ioannis Patras",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08170",
    "title": "Versatile Defense Against Adversarial Attacks on Image Recognition",
    "abstract": "Adversarial attacks present a significant security risk to image recognition tasks. Defending against these attacks in a real-life setting can be compared to the way antivirus software works, with a key consideration being how well the defense can adapt to new and evolving attacks. Another important factor is the resources involved in terms of time and cost for training defense models and updating the model database. Training many models that are specific to each type of attack can be time-consuming and expensive. Ideally, we should be able to train one single model that can handle a wide range of attacks. It appears that a defense method based on image-to-image translation may be capable of this. The proposed versatile defense approach in this paper only requires training one model to effectively resist various unknown adversarial attacks. The trained model has successfully improved the classification accuracy from nearly zero to an average of 86%, performing better than other defense methods proposed in prior studies. When facing the PGD attack and the MI-FGSM attack, versatile defense model even outperforms the attack-specific models trained based on these two attacks. The robustness check also shows that our versatile defense model performs stably regardless with the attack strength. ",
    "url": "https://arxiv.org/abs/2403.08170",
    "authors": [
      "Haibo Zhang",
      "Zhihua Yao",
      "Kouichi Sakurai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.08181",
    "title": "Differential Privacy in Nonlinear Dynamical Systems with Tracking  Performance Guarantees",
    "abstract": "We introduce a novel approach to make the tracking error of a class of nonlinear systems differentially private in addition to guaranteeing the tracking error performance. We use funnel control to make the tracking error evolve within a performance funnel that is pre-specified by the user. We make the performance funnel differentially private by adding a bounded continuous noise generated from an Ornstein-Uhlenbeck-type process. Since the funnel controller is a function of the performance funnel, the noise adds randomized perturbation to the control input. We show that, as a consequence of the differential privacy of the performance funnel, the tracking error is also differentially private. As a result, the tracking error is bounded by the noisy funnel boundary while maintaining privacy. We show a simulation result to demonstrate the framework. ",
    "url": "https://arxiv.org/abs/2403.08181",
    "authors": [
      "Dhrubajit Chowdhury",
      "Raman Goyal",
      "Shantanu Rane"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.08182",
    "title": "SeCG: Semantic-Enhanced 3D Visual Grounding via Cross-modal Graph  Attention",
    "abstract": "3D visual grounding aims to automatically locate the 3D region of the specified object given the corresponding textual description. Existing works fail to distinguish similar objects especially when multiple referred objects are involved in the description. Experiments show that direct matching of language and visual modal has limited capacity to comprehend complex referential relationships in utterances. It is mainly due to the interference caused by redundant visual information in cross-modal alignment. To strengthen relation-orientated mapping between different modalities, we propose SeCG, a semantic-enhanced relational learning model based on a graph network with our designed memory graph attention layer. Our method replaces original language-independent encoding with cross-modal encoding in visual analysis. More text-related feature expressions are obtained through the guidance of global semantics and implicit relationships. Experimental results on ReferIt3D and ScanRefer benchmarks show that the proposed method outperforms the existing state-of-the-art methods, particularly improving the localization performance for the multi-relation challenges. ",
    "url": "https://arxiv.org/abs/2403.08182",
    "authors": [
      "Feng Xiao",
      "Hongbin Xu",
      "Qiuxia Wu",
      "Wenxiong Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08199",
    "title": "Deep Submodular Peripteral Network",
    "abstract": "Submodular functions, crucial for various applications, often lack practical learning methods for their acquisition. Seemingly unrelated, learning a scaling from oracles offering graded pairwise preferences (GPC) is underexplored, despite a rich history in psychometrics. In this paper, we introduce deep submodular peripteral networks (DSPNs), a novel parametric family of submodular functions, and methods for their training using a contrastive-learning inspired GPC-ready strategy to connect and then tackle both of the above challenges. We introduce newly devised GPC-style \"peripteral\" loss which leverages numerically graded relationships between pairs of objects (sets in our case). Unlike traditional contrastive learning, our method utilizes graded comparisons, extracting more nuanced information than just binary-outcome comparisons, and contrasts sets of any size (not just two). We also define a novel suite of automatic sampling strategies for training, including active-learning inspired submodular feedback. We demonstrate DSPNs' efficacy in learning submodularity from a costly target submodular function showing superiority in downstream tasks such as experimental design and streaming applications. ",
    "url": "https://arxiv.org/abs/2403.08199",
    "authors": [
      "Gantavya Bhatt",
      "Arnav Das",
      "Jeff Bilmes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08206",
    "title": "Discrete Semantic Tokenization for Deep CTR Prediction",
    "abstract": "Incorporating item content information into click-through rate (CTR) prediction models remains a challenge, especially with the time and space constraints of industrial scenarios. The content-encoding paradigm, which integrates user and item encoders directly into CTR models, prioritizes space over time. In contrast, the embedding-based paradigm transforms item and user semantics into latent embeddings and then caches them, prioritizes space over time. In this paper, we introduce a new semantic-token paradigm and propose a discrete semantic tokenization approach, namely UIST, for user and item representation. UIST facilitates swift training and inference while maintaining a conservative memory footprint. Specifically, UIST quantizes dense embedding vectors into discrete tokens with shorter lengths and employs a hierarchical mixture inference module to weigh the contribution of each user--item token pair. Our experimental results on news recommendation showcase the effectiveness and efficiency (about 200-fold space compression) of UIST for CTR prediction. ",
    "url": "https://arxiv.org/abs/2403.08206",
    "authors": [
      "Qijiong Liu",
      "Hengchang Hu",
      "Jiahao Wu",
      "Jieming Zhu",
      "Min-Yen Kan",
      "Xiao-Ming Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.08207",
    "title": "BG-HGNN: Toward Scalable and Efficient Heterogeneous Graph Neural  Network",
    "abstract": "Many computer vision and machine learning problems are modelled as learning tasks on heterogeneous graphs, featuring a wide array of relations from diverse types of nodes and edges. Heterogeneous graph neural networks (HGNNs) stand out as a promising neural model class designed for heterogeneous graphs. Built on traditional GNNs, existing HGNNs employ different parameter spaces to model the varied relationships. However, the practical effectiveness of existing HGNNs is often limited to simple heterogeneous graphs with few relation types. This paper first highlights and demonstrates that the standard approach employed by existing HGNNs inevitably leads to parameter explosion and relation collapse, making HGNNs less effective or impractical for complex heterogeneous graphs with numerous relation types. To overcome this issue, we introduce a novel framework, Blend&Grind-HGNN (BG-HGNN), which effectively tackles the challenges by carefully integrating different relations into a unified feature space manageable by a single set of parameters. This results in a refined HGNN method that is more efficient and effective in learning from heterogeneous graphs, especially when the number of relations grows. Our empirical studies illustrate that BG-HGNN significantly surpasses existing HGNNs in terms of parameter efficiency (up to 28.96 $\\times$), training throughput (up to 8.12 $\\times$), and accuracy (up to 1.07 $\\times$). ",
    "url": "https://arxiv.org/abs/2403.08207",
    "authors": [
      "Junwei Su",
      "Lingjun Mao",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08208",
    "title": "Advancing Security in AI Systems: A Novel Approach to Detecting  Backdoors in Deep Neural Networks",
    "abstract": "In the rapidly evolving landscape of communication and network security, the increasing reliance on deep neural networks (DNNs) and cloud services for data processing presents a significant vulnerability: the potential for backdoors that can be exploited by malicious actors. Our approach leverages advanced tensor decomposition algorithms Independent Vector Analysis (IVA), Multiset Canonical Correlation Analysis (MCCA), and Parallel Factor Analysis (PARAFAC2) to meticulously analyze the weights of pre-trained DNNs and distinguish between backdoored and clean models effectively. The key strengths of our method lie in its domain independence, adaptability to various network architectures, and ability to operate without access to the training data of the scrutinized models. This not only ensures versatility across different application scenarios but also addresses the challenge of identifying backdoors without prior knowledge of the specific triggers employed to alter network behavior. We have applied our detection pipeline to three distinct computer vision datasets, encompassing both image classification and object detection tasks. The results demonstrate a marked improvement in both accuracy and efficiency over existing backdoor detection methods. This advancement enhances the security of deep learning and AI in networked systems, providing essential cybersecurity against evolving threats in emerging technologies. ",
    "url": "https://arxiv.org/abs/2403.08208",
    "authors": [
      "Khondoker Murad Hossain",
      "Tim Oates"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08220",
    "title": "Efficient geometric Markov chain Monte Carlo for nonlinear Bayesian  inversion enabled by derivative-informed neural operators",
    "abstract": "We propose an operator learning approach to accelerate geometric Markov chain Monte Carlo (MCMC) for solving infinite-dimensional nonlinear Bayesian inverse problems. While geometric MCMC employs high-quality proposals that adapt to posterior local geometry, it requires computing local gradient and Hessian information of the log-likelihood, incurring a high cost when the parameter-to-observable (PtO) map is defined through expensive model simulations. We consider a delayed-acceptance geometric MCMC method driven by a neural operator surrogate of the PtO map, where the proposal is designed to exploit fast surrogate approximations of the log-likelihood and, simultaneously, its gradient and Hessian. To achieve a substantial speedup, the surrogate needs to be accurate in predicting both the observable and its parametric derivative (the derivative of the observable with respect to the parameter). Training such a surrogate via conventional operator learning using input--output samples often demands a prohibitively large number of model simulations. In this work, we present an extension of derivative-informed operator learning [O'Leary-Roseberry et al., J. Comput. Phys., 496 (2024)] using input--output--derivative training samples. Such a learning method leads to derivative-informed neural operator (DINO) surrogates that accurately predict the observable and its parametric derivative at a significantly lower training cost than the conventional method. Cost and error analysis for reduced basis DINO surrogates are provided. Numerical studies on PDE-constrained Bayesian inversion demonstrate that DINO-driven MCMC generates effective posterior samples 3--9 times faster than geometric MCMC and 60--97 times faster than prior geometry-based MCMC. Furthermore, the training cost of DINO surrogates breaks even after collecting merely 10--25 effective posterior samples compared to geometric MCMC. ",
    "url": "https://arxiv.org/abs/2403.08220",
    "authors": [
      "Lianghao Cao",
      "Thomas O'Leary-Roseberry",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08222",
    "title": "Robust Decision Aggregation with Adversarial Experts",
    "abstract": "We consider a binary decision aggregation problem in the presence of both truthful and adversarial experts. The truthful experts will report their private signals truthfully with proper incentive, while the adversarial experts can report arbitrarily. The decision maker needs to design a robust aggregator to forecast the true state of the world based on the reports of experts. The decision maker does not know the specific information structure, which is a joint distribution of signals, states, and strategies of adversarial experts. We want to find the optimal aggregator minimizing regret under the worst information structure. The regret is defined by the difference in expected loss between the aggregator and a benchmark who makes the optimal decision given the joint distribution and reports of truthful experts. We prove that when the truthful experts are symmetric and adversarial experts are not too numerous, the truncated mean is optimal, which means that we remove some lowest reports and highest reports and take averaging among the left reports. Moreover, for many settings, the optimal aggregators are in the family of piecewise linear functions. The regret is independent of the total number of experts but only depends on the ratio of adversaries. We evaluate our aggregators by numerical experiment in an ensemble learning task. We also obtain some negative results for the aggregation problem with adversarial experts under some more general information structures and experts' report space. ",
    "url": "https://arxiv.org/abs/2403.08222",
    "authors": [
      "Yongkang Guo",
      "Yuqing Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08229",
    "title": "Boosting Disfluency Detection with Large Language Model as Disfluency  Generator",
    "abstract": "Current disfluency detection methods heavily rely on costly and scarce human-annotated data. To tackle this issue, some approaches employ heuristic or statistical features to generate disfluent sentences, partially improving detection performance. However, these sentences often deviate from real-life scenarios, constraining overall model enhancement. In this study, we propose a lightweight data augmentation approach for disfluency detection, utilizing the superior generative and semantic understanding capabilities of large language model (LLM) to generate disfluent sentences as augmentation data. We leverage LLM to generate diverse and more realistic sentences guided by specific prompts, without the need for fine-tuning the LLM. Subsequently, we apply an uncertainty-aware data filtering approach to improve the quality of the generated sentences, utilized in training a small detection model for improved performance. Experiments using enhanced data yielded state-of-the-art results. The results showed that using a small amount of LLM-generated enhanced data can significantly improve performance, thereby further enhancing cost-effectiveness. ",
    "url": "https://arxiv.org/abs/2403.08229",
    "authors": [
      "Zhenrong Cheng",
      "Jiayan Guo",
      "Hao Sun",
      "Yan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.08231",
    "title": "Object Permanence Filter for Robust Tracking with Interactive Robots",
    "abstract": "Object permanence, which refers to the concept that objects continue to exist even when they are no longer perceivable through the senses, is a crucial aspect of human cognitive development. In this work, we seek to incorporate this understanding into interactive robots by proposing a set of assumptions and rules to represent object permanence in multi-object, multi-agent interactive scenarios. We integrate these rules into the particle filter, resulting in the Object Permanence Filter (OPF). For multi-object scenarios, we propose an ensemble of K interconnected OPFs, where each filter predicts plausible object tracks that are resilient to missing, noisy, and kinematically or dynamically infeasible measurements, thus bringing perceptional robustness. Through several interactive scenarios, we demonstrate that the proposed OPF approach provides robust tracking in human-robot interactive tasks agnostic to measurement type, even in the presence of prolonged and complete occlusion. Webpage: https://opfilter.github.io/. ",
    "url": "https://arxiv.org/abs/2403.08231",
    "authors": [
      "Shaoting Peng",
      "Margaret X. Wang",
      "Julie A. Shah",
      "Nadia Figueroa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.08238",
    "title": "A Novel Feature Learning-based Bio-inspired Neural Network for Real-time  Collision-free Rescue of Multi-Robot Systems",
    "abstract": "Natural disasters and urban accidents drive the demand for rescue robots to provide safer, faster, and more efficient rescue trajectories. In this paper, a feature learning-based bio-inspired neural network (FLBBINN) is proposed to quickly generate a heuristic rescue path in complex and dynamic environments, as traditional approaches usually cannot provide a satisfactory solution to real-time responses to sudden environmental changes. The neurodynamic model is incorporated into the feature learning method that can use environmental information to improve path planning strategies. Task assignment and collision-free rescue trajectory are generated through robot poses and the dynamic landscape of neural activity. A dual-channel scale filter, a neural activity channel, and a secondary distance fusion are employed to extract and filter feature neurons. After completion of the feature learning process, a neurodynamics-based feature matrix is established to quickly generate the new heuristic rescue paths with parameter-driven topological adaptability. The proposed FLBBINN aims to reduce the computational complexity of the neural network-based approach and enable the feature learning method to achieve real-time responses to environmental changes. Several simulations and experiments have been conducted to evaluate the performance of the proposed FLBBINN. The results show that the proposed FLBBINN would significantly improve the speed, efficiency, and optimality for rescue operations. ",
    "url": "https://arxiv.org/abs/2403.08238",
    "authors": [
      "Junfei Li",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.08251",
    "title": "Emergence of Social Norms in Large Language Model-based Agent Societies",
    "abstract": "The emergence of social norms has attracted much interest in a wide array of disciplines, ranging from social science and cognitive science to artificial intelligence. In this paper, we propose the first generative agent architecture that empowers the emergence of social norms within a population of large language model-based agents. Our architecture, named CRSEC, consists of four modules: Creation & Representation, Spreading, Evaluation, and Compliance. Our architecture addresses several important aspects of the emergent processes all in one: (i) where social norms come from, (ii) how they are formally represented, (iii) how they spread through agents' communications and observations, (iv) how they are examined with a sanity check and synthesized in the long term, and (v) how they are incorporated into agents' planning and actions. Our experiments deployed in the Smallville sandbox game environment demonstrate the capability of our architecture to establish social norms and reduce social conflicts within large language model-based multi-agent systems. The positive outcomes of our human evaluation, conducted with 30 evaluators, further affirm the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2403.08251",
    "authors": [
      "Siyue Ren",
      "Zhiyao Cui",
      "Ruiqi Song",
      "Zhen Wang",
      "Shuyue Hu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.08252",
    "title": "PNeSM: Arbitrary 3D Scene Stylization via Prompt-Based Neural Style  Mapping",
    "abstract": "3D scene stylization refers to transform the appearance of a 3D scene to match a given style image, ensuring that images rendered from different viewpoints exhibit the same style as the given style image, while maintaining the 3D consistency of the stylized scene. Several existing methods have obtained impressive results in stylizing 3D scenes. However, the models proposed by these methods need to be re-trained when applied to a new scene. In other words, their models are coupled with a specific scene and cannot adapt to arbitrary other scenes. To address this issue, we propose a novel 3D scene stylization framework to transfer an arbitrary style to an arbitrary scene, without any style-related or scene-related re-training. Concretely, we first map the appearance of the 3D scene into a 2D style pattern space, which realizes complete disentanglement of the geometry and appearance of the 3D scene and makes our model be generalized to arbitrary 3D scenes. Then we stylize the appearance of the 3D scene in the 2D style pattern space via a prompt-based 2D stylization algorithm. Experimental results demonstrate that our proposed framework is superior to SOTA methods in both visual quality and generalization. ",
    "url": "https://arxiv.org/abs/2403.08252",
    "authors": [
      "Jiafu Chen",
      "Wei Xing",
      "Jiakai Sun",
      "Tianyi Chu",
      "Yiling Huang",
      "Boyan Ji",
      "Lei Zhao",
      "Huaizhong Lin",
      "Haibo Chen",
      "Zhizhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08256",
    "title": "IG-FIQA: Improving Face Image Quality Assessment through Intra-class  Variance Guidance robust to Inaccurate Pseudo-Labels",
    "abstract": "In the realm of face image quality assesment (FIQA), method based on sample relative classification have shown impressive performance. However, the quality scores used as pseudo-labels assigned from images of classes with low intra-class variance could be unrelated to the actual quality in this method. To address this issue, we present IG-FIQA, a novel approach to guide FIQA training, introducing a weight parameter to alleviate the adverse impact of these classes. This method involves estimating sample intra-class variance at each iteration during training, ensuring minimal computational overhead and straightforward implementation. Furthermore, this paper proposes an on-the-fly data augmentation methodology for improved generalization performance in FIQA. On various benchmark datasets, our proposed method, IG-FIQA, achieved novel state-of-the-art (SOTA) performance. ",
    "url": "https://arxiv.org/abs/2403.08256",
    "authors": [
      "Minsoo Kim",
      "Gi Pyo Nam",
      "Haksub Kim",
      "Haesol Park",
      "Ig-Jae Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08265",
    "title": "Random Search as a Baseline for Sparse Neural Network Architecture  Search",
    "abstract": "Sparse neural networks have shown similar or better generalization performance than their dense counterparts while having higher parameter efficiency. This has motivated a number of works to learn or search for high performing sparse networks. While reports of task performance or efficiency gains are impressive, standard baselines are lacking leading to poor comparability and unreliable reproducibility across methods. In this work, we propose Random Search as a baseline algorithm for finding good sparse configurations and study its performance. We apply Random Search on the node space of an overparameterized network with the goal of finding better initialized sparse sub-networks that are positioned more advantageously in the loss landscape. We record the post-training performances of the found sparse networks and at various levels of sparsity, and compare against both their fully connected parent networks and random sparse configurations at the same sparsity levels. First, we demonstrate performance at different levels of sparsity and highlight that a significant level of performance can still be preserved even when the network is highly sparse. Second, we observe that for this sparse architecture search task, initialized sparse networks found by Random Search neither perform better nor converge more efficiently than their random counterparts. Thus we conclude that Random Search may be viewed as a reasonable neutral baseline for sparsity search methods. ",
    "url": "https://arxiv.org/abs/2403.08265",
    "authors": [
      "Rezsa Farahani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.08267",
    "title": "SNOW-SCA: ML-assisted Side-Channel Attack on SNOW-V",
    "abstract": "This paper presents SNOW-SCA, the first power side-channel analysis (SCA) attack of a 5G mobile communication security standard candidate, SNOW-V, running on a 32-bit ARM Cortex-M4 microcontroller. First, we perform a generic known-key correlation (KKC) analysis to identify the leakage points. Next, a correlation power analysis (CPA) attack is performed, which reduces the attack complexity to two key guesses for each key byte. The correct secret key is then uniquely identified utilizing linear discriminant analysis (LDA). The profiled SCA attack with LDA achieves 100% accuracy after training with $<200$ traces, which means the attack succeeds with just a single trace. Overall, using the \\textit{combined CPA and LDA attack} model, the correct secret key byte is recovered with <50 traces collected using the ChipWhisperer platform. The entire 256-bit secret key of SNOW-V can be recovered incrementally using the proposed SCA attack. Finally, we suggest low-overhead countermeasures that can be used to prevent these SCA attacks. ",
    "url": "https://arxiv.org/abs/2403.08267",
    "authors": [
      "Harshit Saurabh",
      "Anupam Golder",
      "Samarth Shivakumar Titti",
      "Suparna Kundu",
      "Chaoyun Li",
      "Angshuman Karmakar",
      "Debayan Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.08270",
    "title": "Identity-aware Dual-constraint Network for Cloth-Changing Person  Re-identification",
    "abstract": "Cloth-Changing Person Re-Identification (CC-ReID) aims to accurately identify the target person in more realistic surveillance scenarios, where pedestrians usually change their clothing. Despite great progress, limited cloth-changing training samples in existing CC-ReID datasets still prevent the model from adequately learning cloth-irrelevant features. In addition, due to the absence of explicit supervision to keep the model constantly focused on cloth-irrelevant areas, existing methods are still hampered by the disruption of clothing variations. To solve the above issues, we propose an Identity-aware Dual-constraint Network (IDNet) for the CC-ReID task. Specifically, to help the model extract cloth-irrelevant clues, we propose a Clothes Diversity Augmentation (CDA), which generates more realistic cloth-changing samples by enriching the clothing color while preserving the texture. In addition, a Multi-scale Constraint Block (MCB) is designed, which extracts fine-grained identity-related features and effectively transfers cloth-irrelevant knowledge. Moreover, a Counterfactual-guided Attention Module (CAM) is presented, which learns cloth-irrelevant features from channel and space dimensions and utilizes the counterfactual intervention for supervising the attention map to highlight identity-related regions. Finally, a Semantic Alignment Constraint (SAC) is designed to facilitate high-level semantic feature interaction. Comprehensive experiments on four CC-ReID datasets indicate that our method outperforms prior state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2403.08270",
    "authors": [
      "Peini Guo",
      "Mengyuan Liu",
      "Hong Liu",
      "Ruijia Fan",
      "Guoquan Wang",
      "Bin He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08273",
    "title": "LiqD: A Dynamic Liquid Level Detection Model under Tricky Small  Containers",
    "abstract": "In daily life and industrial production, it is crucial to accurately detect changes in liquid level in containers. Traditional contact measurement methods have some limitations, while emerging non-contact image processing technology shows good application prospects. This paper proposes a container dynamic liquid level detection model based on U^2-Net. This model uses the SAM model to generate an initial data set, and then evaluates and filters out high-quality pseudo-label images through the SemiReward framework to build an exclusive data set. The model uses U^2-Net to extract mask images of containers from the data set, and uses morphological processing to compensate for mask defects. Subsequently, the model calculates the grayscale difference between adjacent video frame images at the same position, segments the liquid level change area by setting a difference threshold, and finally uses a lightweight neural network to classify the liquid level state. This approach not only mitigates the impact of intricate surroundings, but also reduces the demand for training data, showing strong robustness and versatility. A large number of experimental results show that the proposed model can effectively detect the dynamic liquid level changes of the liquid in the container, providing a novel and efficient solution for related fields. ",
    "url": "https://arxiv.org/abs/2403.08273",
    "authors": [
      "Yukun Ma",
      "Zikun Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08281",
    "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly  Specialized Language Models",
    "abstract": "Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a high-quality supervised instruction tuning dataset, UltraChat 2, which includes text, code, and mathematical content. This dataset comprises approximately 300,000 instructions and covers a wide range of topics in each domain. Experiments show that our model could simultaneously achieve mastery of the three crucial domains. ",
    "url": "https://arxiv.org/abs/2403.08281",
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xingtai Lv",
      "Ruobing Xie",
      "Bowen Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08283",
    "title": "Optimized Detection and Classification on GTRSB: Advancing Traffic Sign  Recognition with Convolutional Neural Networks",
    "abstract": "In the rapidly evolving landscape of transportation, the proliferation of automobiles has made road traffic more complex, necessitating advanced vision-assisted technologies for enhanced safety and navigation. These technologies are imperative for providing critical traffic sign information, influencing driver behavior, and supporting vehicle control, especially for drivers with disabilities and in the burgeoning field of autonomous vehicles. Traffic sign detection and recognition have emerged as key areas of research due to their essential roles in ensuring road safety and compliance with traffic regulations. Traditional computer vision methods have faced challenges in achieving optimal accuracy and speed due to real-world variabilities. However, the advent of deep learning and Convolutional Neural Networks (CNNs) has revolutionized this domain, offering solutions that significantly surpass previous capabilities in terms of speed and reliability. This paper presents an innovative approach leveraging CNNs that achieves an accuracy of nearly 96\\%, highlighting the potential for even greater precision through advanced localization techniques. Our findings not only contribute to the ongoing advancement of traffic sign recognition technology but also underscore the critical impact of these developments on road safety and the future of autonomous driving. ",
    "url": "https://arxiv.org/abs/2403.08283",
    "authors": [
      "Dhruv Toshniwal",
      "Saurabh Loya",
      "Anuj Khot",
      "Yash Marda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08284",
    "title": "MGIC: A Multi-Label Gradient Inversion Attack based on Canny Edge  Detection on Federated Learning",
    "abstract": "As a new distributed computing framework that can protect data privacy, federated learning (FL) has attracted more and more attention in recent years. It receives gradients from users to train the global model and releases the trained global model to working users. Nonetheless, the gradient inversion (GI) attack reflects the risk of privacy leakage in federated learning. Attackers only need to use gradients through hundreds of thousands of simple iterations to obtain relatively accurate private data stored on users' local devices. For this, some works propose simple but effective strategies to obtain user data under a single-label dataset. However, these strategies induce a satisfactory visual effect of the inversion image at the expense of higher time costs. Due to the semantic limitation of a single label, the image obtained by gradient inversion may have semantic errors. We present a novel gradient inversion strategy based on canny edge detection (MGIC) in both the multi-label and single-label datasets. To reduce semantic errors caused by a single label, we add new convolution layers' blocks in the trained model to obtain the image's multi-label. Through multi-label representation, serious semantic errors in inversion images are reduced. Then, we analyze the impact of parameters on the difficulty of input image reconstruction and discuss how image multi-subjects affect the inversion performance. Our proposed strategy has better visual inversion image results than the most widely used ones, saving more than 78% of time costs in the ImageNet dataset. ",
    "url": "https://arxiv.org/abs/2403.08284",
    "authors": [
      "Can Liu",
      "Jin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08294",
    "title": "Attack Deterministic Conditional Image Generative Models for Diverse and  Controllable Generation",
    "abstract": "Existing generative adversarial network (GAN) based conditional image generative models typically produce fixed output for the same conditional input, which is unreasonable for highly subjective tasks, such as large-mask image inpainting or style transfer. On the other hand, GAN-based diverse image generative methods require retraining/fine-tuning the network or designing complex noise injection functions, which is computationally expensive, task-specific, or struggle to generate high-quality results. Given that many deterministic conditional image generative models have been able to produce high-quality yet fixed results, we raise an intriguing question: is it possible for pre-trained deterministic conditional image generative models to generate diverse results without changing network structures or parameters? To answer this question, we re-examine the conditional image generation tasks from the perspective of adversarial attack and propose a simple and efficient plug-in projected gradient descent (PGD) like method for diverse and controllable image generation. The key idea is attacking the pre-trained deterministic generative models by adding a micro perturbation to the input condition. In this way, diverse results can be generated without any adjustment of network structures or fine-tuning of the pre-trained models. In addition, we can also control the diverse results to be generated by specifying the attack direction according to a reference text or image. Our work opens the door to applying adversarial attack to low-level vision tasks, and experiments on various conditional image generation tasks demonstrate the effectiveness and superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2403.08294",
    "authors": [
      "Tianyi Chu",
      "Wei Xing",
      "Jiafu Chen",
      "Zhizhong Wang",
      "Jiakai Sun",
      "Lei Zhao",
      "Haibo Chen",
      "Huaizhong Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08310",
    "title": "StyleDyRF: Zero-shot 4D Style Transfer for Dynamic Neural Radiance  Fields",
    "abstract": "4D style transfer aims at transferring arbitrary visual style to the synthesized novel views of a dynamic 4D scene with varying viewpoints and times. Existing efforts on 3D style transfer can effectively combine the visual features of style images and neural radiance fields (NeRF) but fail to handle the 4D dynamic scenes limited by the static scene assumption. Consequently, we aim to handle the novel challenging problem of 4D style transfer for the first time, which further requires the consistency of stylized results on dynamic objects. In this paper, we introduce StyleDyRF, a method that represents the 4D feature space by deforming a canonical feature volume and learns a linear style transformation matrix on the feature volume in a data-driven fashion. To obtain the canonical feature volume, the rays at each time step are deformed with the geometric prior of a pre-trained dynamic NeRF to render the feature map under the supervision of pre-trained visual encoders. With the content and style cues in the canonical feature volume and the style image, we can learn the style transformation matrix from their covariance matrices with lightweight neural networks. The learned style transformation matrix can reflect a direct matching of feature covariance from the content volume to the given style pattern, in analogy with the optimization of the Gram matrix in traditional 2D neural style transfer. The experimental results show that our method not only renders 4D photorealistic style transfer results in a zero-shot manner but also outperforms existing methods in terms of visual quality and consistency. ",
    "url": "https://arxiv.org/abs/2403.08310",
    "authors": [
      "Hongbin Xu",
      "Weitao Chen",
      "Feng Xiao",
      "Baigui Sun",
      "Wenxiong Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08311",
    "title": "When Code Smells Meet ML: On the Lifecycle of ML-specific Code Smells in  ML-enabled Systems",
    "abstract": "Context. The adoption of Machine Learning (ML)--enabled systems is steadily increasing. Nevertheless, there is a shortage of ML-specific quality assurance approaches, possibly because of the limited knowledge of how quality-related concerns emerge and evolve in ML-enabled systems. Objective. We aim to investigate the emergence and evolution of specific types of quality-related concerns known as ML-specific code smells, i.e., sub-optimal implementation solutions applied on ML pipelines that may significantly decrease both the quality and maintainability of ML-enabled systems. More specifically, we present a plan to study ML-specific code smells by empirically analyzing (i) their prevalence in real ML-enabled systems, (ii) how they are introduced and removed, and (iii) their survivability. Method. We will conduct an exploratory study, mining a large dataset of ML-enabled systems and analyzing over 400k commits about 337 projects. We will track and inspect the introduction and evolution of ML smells through CodeSmile, a novel ML smell detector that we will build to enable our investigation and to detect ML-specific code smells. ",
    "url": "https://arxiv.org/abs/2403.08311",
    "authors": [
      "Gilberto Recupito",
      "Giammaria Giordano",
      "Filomena Ferrucci",
      "Dario Di Nucci",
      "Fabio Palomba"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.08335",
    "title": "A Sparsity Principle for Partially Observable Causal Representation  Learning",
    "abstract": "Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variables by enforcing sparsity in the inferred representation. Experiments on different simulated datasets and established benchmarks highlight the effectiveness of our approach in recovering the ground-truth latents. ",
    "url": "https://arxiv.org/abs/2403.08335",
    "authors": [
      "Danru Xu",
      "Dingling Yao",
      "S\u00e9bastien Lachapelle",
      "Perouz Taslakian",
      "Julius von K\u00fcgelgen",
      "Francesco Locatello",
      "Sara Magliacane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08337",
    "title": "LLM-Assisted Light: Leveraging Large Language Model Capabilities for  Human-Mimetic Traffic Signal Control in Complex Urban Environments",
    "abstract": "Traffic congestion in metropolitan areas presents a formidable challenge with far-reaching economic, environmental, and societal ramifications. Therefore, effective congestion management is imperative, with traffic signal control (TSC) systems being pivotal in this endeavor. Conventional TSC systems, designed upon rule-based algorithms or reinforcement learning (RL), frequently exhibit deficiencies in managing the complexities and variabilities of urban traffic flows, constrained by their limited capacity for adaptation to unfamiliar scenarios. In response to these limitations, this work introduces an innovative approach that integrates Large Language Models (LLMs) into TSC, harnessing their advanced reasoning and decision-making faculties. Specifically, a hybrid framework that augments LLMs with a suite of perception and decision-making tools is proposed, facilitating the interrogation of both the static and dynamic traffic information. This design places the LLM at the center of the decision-making process, combining external traffic data with established TSC methods. Moreover, a simulation platform is developed to corroborate the efficacy of the proposed framework. The findings from our simulations attest to the system's adeptness in adjusting to a multiplicity of traffic environments without the need for additional training. Notably, in cases of Sensor Outage (SO), our approach surpasses conventional RL-based systems by reducing the average waiting time by $20.4\\%$. This research signifies a notable advance in TSC strategies and paves the way for the integration of LLMs into real-world, dynamic scenarios, highlighting their potential to revolutionize traffic management. The related code is available at \\href{https://github.com/Traffic-Alpha/LLM-Assisted-Light}{https://github.com/Traffic-Alpha/LLM-Assisted-Light}. ",
    "url": "https://arxiv.org/abs/2403.08337",
    "authors": [
      "Maonan Wang",
      "Aoyu Pang",
      "Yuheng Kan",
      "Man-On Pun",
      "Chung Shue Chen",
      "Bo Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08343",
    "title": "Coverage and Rate Analysis for Integrated Sensing and Communication  Networks",
    "abstract": "Integrated sensing and communication (ISAC) is increasingly recognized as a pivotal technology for next-generation cellular networks, offering mutual benefits in both sensing and communication capabilities. This advancement necessitates a re-examination of the fundamental limits within networks where these two functions coexist via shared spectrum and infrastructures. However, traditional stochastic geometry-based performance analyses are confined to either communication or sensing networks separately. This paper bridges this gap by introducing a generalized stochastic geometry framework in ISAC networks. Based on this framework, we define and calculate the coverage and ergodic rate of sensing and communication performance under resource constraints. Then, we shed light on the fundamental limits of ISAC networks by presenting theoretical results for the coverage rate of the unified performance, taking into account the coupling effects of dual functions in coexistence networks. Further, we obtain the analytical formulations for evaluating the ergodic sensing rate constrained by the maximum communication rate, and the ergodic communication rate constrained by the maximum sensing rate. Extensive numerical results validate the accuracy of all theoretical derivations, and also indicate that denser networks significantly enhance ISAC coverage. Specifically, increasing the base station density from $1$ $\\text{km}^{-2}$ to $10$ $\\text{km}^{-2}$ can boost the ISAC coverage rate from $1.4\\%$ to $39.8\\%$. Further, results also reveal that with the increase of the constrained sensing rate, the ergodic communication rate improves significantly, but the reverse is not obvious. ",
    "url": "https://arxiv.org/abs/2403.08343",
    "authors": [
      "Xu Gan",
      "Chongwen Huang",
      "Zhaohui Yang",
      "Xiaoming Chen",
      "Jiguang He",
      "Zhaoyang Zhang",
      "Chau Yuen",
      "Yong Liang Guan",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.08345",
    "title": "From human experts to machines: An LLM supported approach to ontology  and knowledge graph construction",
    "abstract": "The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (or populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by open-source LLMs. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. To evaluate the answers generated via Retrieval-Augmented-Generation (RAG) as well as the KG concepts automatically extracted using LLMs, we design a judge LLM, which rates the generated content based on ground truth. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs. ",
    "url": "https://arxiv.org/abs/2403.08345",
    "authors": [
      "Vamsi Krishna Kommineni",
      "Birgitta K\u00f6nig-Ries",
      "Sheeba Samuel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.08352",
    "title": "Data augmentation with automated machine learning: approaches and  performance comparison with classical data augmentation methods",
    "abstract": "Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. Automated data augmentation methods aim to automate the process. State-of-the-art approaches typically rely on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoML-based data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. We present extensive discussion of techniques for realizing each of the major subtasks of the data augmentation process: search space design, hyperparameter optimization and model evaluation. Finally, we carried out an extensive comparison and analysis of the performance of automated data augmentation techniques and state-of-the-art methods based on classical augmentation approaches. The results show that AutoML methods for data augmentation currently outperform state-of-the-art techniques based on conventional approaches. ",
    "url": "https://arxiv.org/abs/2403.08352",
    "authors": [
      "Alhassan Mumuni",
      "Fuseini Mumuni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.08380",
    "title": "Mitigate Target-level Insensitivity of Infrared Small Target Detection  via Posterior Distribution Modeling",
    "abstract": "Infrared Small Target Detection (IRSTD) aims to segment small targets from infrared clutter background. Existing methods mainly focus on discriminative approaches, i.e., a pixel-level front-background binary segmentation. Since infrared small targets are small and low signal-to-clutter ratio, empirical risk has few disturbances when a certain false alarm and missed detection exist, which seriously affect the further improvement of such methods. Motivated by the dense prediction generative methods, in this paper, we propose a diffusion model framework for Infrared Small Target Detection which compensates pixel-level discriminant with mask posterior distribution modeling. Furthermore, we design a Low-frequency Isolation in the wavelet domain to suppress the interference of intrinsic infrared noise on the diffusion noise estimation. This transition from the discriminative paradigm to generative one enables us to bypass the target-level insensitivity. Experiments show that the proposed method achieves competitive performance gains over state-of-the-art methods on NUAA-SIRST, IRSTD-1k, and NUDT-SIRST datasets. Code are available at https://github.com/Li-Haoqing/IRSTD-Diff. ",
    "url": "https://arxiv.org/abs/2403.08380",
    "authors": [
      "Haoqing Li",
      "Jinfu Yang",
      "Yifei Xu",
      "Runshi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08383",
    "title": "RAF-GI: Towards Robust, Accurate and Fast-Convergent Gradient Inversion  Attack in Federated Learning",
    "abstract": "Federated learning (FL) empowers privacy-preservation in model training by only exposing users' model gradients. Yet, FL users are susceptible to the gradient inversion (GI) attack which can reconstruct ground-truth training data such as images based on model gradients. However, reconstructing high-resolution images by existing GI attack works faces two challenges: inferior accuracy and slow-convergence, especially when the context is complicated, e.g., the training batch size is much greater than 1 on each FL user. To address these challenges, we present a Robust, Accurate and Fast-convergent GI attack algorithm, called RAF-GI, with two components: 1) Additional Convolution Block (ACB) which can restore labels with up to 20% improvement compared with existing works; 2) Total variance, three-channel mEan and cAnny edge detection regularization term (TEA), which is a white-box attack strategy to reconstruct images based on labels inferred by ACB. Moreover, RAF-GI is robust that can still accurately reconstruct ground-truth data when the users' training batch size is no more than 48. Our experimental results manifest that RAF-GI can diminish 94% time costs while achieving superb inversion quality in ImageNet dataset. Notably, with a batch size of 1, RAF-GI exhibits a 7.89 higher Peak Signal-to-Noise Ratio (PSNR) compared to the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2403.08383",
    "authors": [
      "Can Liu",
      "Jin Wang",
      "Dongyang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08384",
    "title": "AADNet: Attention aware Demoir\u00e9ing Network",
    "abstract": "Moire pattern frequently appears in photographs captured with mobile devices and digital cameras, potentially degrading image quality. Despite recent advancements in computer vision, image demoire'ing remains a challenging task due to the dynamic textures and variations in colour, shape, and frequency of moire patterns. Most existing methods struggle to generalize to unseen datasets, limiting their effectiveness in removing moire patterns from real-world scenarios. In this paper, we propose a novel lightweight architecture, AADNet (Attention Aware Demoireing Network), for high-resolution image demoire'ing that effectively works across different frequency bands and generalizes well to unseen datasets. Extensive experiments conducted on the UHDM dataset validate the effectiveness of our approach, resulting in high-fidelity images. ",
    "url": "https://arxiv.org/abs/2403.08384",
    "authors": [
      "M Rakesh Reddy",
      "Shubham Mandloi",
      "Aman Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08411",
    "title": "Robust Distributed Compression with Learned Heegard-Berger Scheme",
    "abstract": "We consider lossy compression of an information source when decoder-only side information may be absent. This setup, also referred to as the Heegard-Berger or Kaspi problem, is a special case of robust distributed source coding. Building upon previous works on neural network-based distributed compressors developed for the decoder-only side information (Wyner-Ziv) case, we propose learning-based schemes that are amenable to the availability of side information. We find that our learned compressors mimic the achievability part of the Heegard-Berger theorem and yield interpretable results operating close to information-theoretic bounds. Depending on the availability of the side information, our neural compressors recover characteristics of the point-to-point (i.e., with no side information) and the Wyner-Ziv coding strategies that include binning in the source space, although no structure exploiting knowledge of the source and side information was imposed into the design. ",
    "url": "https://arxiv.org/abs/2403.08411",
    "authors": [
      "Eyyup Tasci",
      "Ezgi Ozyilkan",
      "Oguzhan Kubilay Ulger",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.08414",
    "title": "Causal Graph Neural Networks for Wildfire Danger Prediction",
    "abstract": "Wildfire forecasting is notoriously hard due to the complex interplay of different factors such as weather conditions, vegetation types and human activities. Deep learning models show promise in dealing with this complexity by learning directly from data. However, to inform critical decision making, we argue that we need models that are right for the right reasons; that is, the implicit rules learned should be grounded by the underlying processes driving wildfires. In that direction, we propose integrating causality with Graph Neural Networks (GNNs) that explicitly model the causal mechanism among complex variables via graph learning. The causal adjacency matrix considers the synergistic effect among variables and removes the spurious links from highly correlated impacts. Our methodology's effectiveness is demonstrated through superior performance forecasting wildfire patterns in the European boreal and mediterranean biome. The gain is especially prominent in a highly imbalanced dataset, showcasing an enhanced robustness of the model to adapt to regime shifts in functional relationships. Furthermore, SHAP values from our trained model further enhance our understanding of the model's inner workings. ",
    "url": "https://arxiv.org/abs/2403.08414",
    "authors": [
      "Shan Zhao",
      "Ioannis Prapas",
      "Ilektra Karasante",
      "Zhitong Xiong",
      "Ioannis Papoutsis",
      "Gustau Camps-Valls",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08424",
    "title": "Tastle: Distract Large Language Models for Automatic Jailbreak Attack",
    "abstract": "Large language models (LLMs) have achieved significant advances in recent days. Extensive efforts have been made before the public release of LLMs to align their behaviors with human values. The primary goal of alignment is to ensure their helpfulness, honesty and harmlessness. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. The jailbreak is to intentionally develop a malicious prompt that escapes from the LLM security restrictions to produce uncensored detrimental contents. Previous works explore different jailbreak methods for red teaming LLMs, yet they encounter challenges regarding to effectiveness and scalability. In this work, we propose Tastle, a novel black-box jailbreak framework for automated red teaming of LLMs. We designed malicious content concealing and memory reframing with an iterative optimization algorithm to jailbreak LLMs, motivated by the research about the distractibility and over-confidence phenomenon of LLMs. Extensive experiments of jailbreaking both open-source and proprietary LLMs demonstrate the superiority of our framework in terms of effectiveness, scalability and transferability. We also evaluate the effectiveness of existing jailbreak defense methods against our attack and highlight the crucial need to develop more effective and practical defense strategies. ",
    "url": "https://arxiv.org/abs/2403.08424",
    "authors": [
      "Zeguan Xiao",
      "Yan Yang",
      "Guanhua Chen",
      "Yun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.08428",
    "title": "DeepCSHAP: Utilizing Shapley Values to Explain Deep Complex-Valued  Neural Networks",
    "abstract": "Deep Neural Networks are widely used in academy as well as corporate and public applications, including safety critical applications such as health care and autonomous driving. The ability to explain their output is critical for safety reasons as well as acceptance among applicants. A multitude of methods have been proposed to explain real-valued neural networks. Recently, complex-valued neural networks have emerged as a new class of neural networks dealing with complex-valued input data without the necessity of projecting them onto $\\mathbb{R}^2$. This brings up the need to develop explanation algorithms for this kind of neural networks. In this paper we provide these developments. While we focus on adapting the widely used DeepSHAP algorithm to the complex domain, we also present versions of four gradient based explanation methods suitable for use in complex-valued neural networks. We evaluate the explanation quality of all presented algorithms and provide all of them as an open source library adaptable to most recent complex-valued neural network architectures. ",
    "url": "https://arxiv.org/abs/2403.08428",
    "authors": [
      "Florian Eilers",
      "Xiaoyi Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08429",
    "title": "Software Vulnerability and Functionality Assessment using LLMs",
    "abstract": "While code review is central to the software development process, it can be tedious and expensive to carry out. In this paper, we investigate whether and how Large Language Models (LLMs) can aid with code reviews. Our investigation focuses on two tasks that we argue are fundamental to good reviews: (i) flagging code with security vulnerabilities and (ii) performing software functionality validation, i.e., ensuring that code meets its intended functionality. To test performance on both tasks, we use zero-shot and chain-of-thought prompting to obtain final ``approve or reject'' recommendations. As data, we employ seminal code generation datasets (HumanEval and MBPP) along with expert-written code snippets with security vulnerabilities from the Common Weakness Enumeration (CWE). Our experiments consider a mixture of three proprietary models from OpenAI and smaller open-source LLMs. We find that the former outperforms the latter by a large margin. Motivated by promising results, we finally ask our models to provide detailed descriptions of security vulnerabilities. Results show that 36.7% of LLM-generated descriptions can be associated with true CWE vulnerabilities. ",
    "url": "https://arxiv.org/abs/2403.08429",
    "authors": [
      "Rasmus Ingemann Tuffveson Jensen",
      "Vali Tawosi",
      "Salwa Alamir"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08438",
    "title": "Reproducibility and Geometric Intrinsic Dimensionality: An Investigation  on Graph Neural Network Research",
    "abstract": "Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data and impeding the training and inference processes. Using the closely linked concept of geometric intrinsic dimension we investigate to which extend the used machine learning models are influenced by the intrinsic dimension of the data sets they are trained on. ",
    "url": "https://arxiv.org/abs/2403.08438",
    "authors": [
      "Tobias Hille",
      "Maximilian Stubbemann",
      "Tom Hanika"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08448",
    "title": "Actor-Critic Physics-informed Neural Lyapunov Control",
    "abstract": "Designing control policies for stabilization tasks with provable guarantees is a long-standing problem in nonlinear control. A crucial performance metric is the size of the resulting region of attraction, which essentially serves as a robustness \"margin\" of the closed-loop system against uncertainties. In this paper, we propose a new method to train a stabilizing neural network controller along with its corresponding Lyapunov certificate, aiming to maximize the resulting region of attraction while respecting the actuation constraints. Crucial to our approach is the use of Zubov's Partial Differential Equation (PDE), which precisely characterizes the true region of attraction of a given control policy. Our framework follows an actor-critic pattern where we alternate between improving the control policy (actor) and learning a Zubov function (critic). Finally, we compute the largest certifiable region of attraction by invoking an SMT solver after the training procedure. Our numerical experiments on several design problems show consistent and significant improvements in the size of the resulting region of attraction. ",
    "url": "https://arxiv.org/abs/2403.08448",
    "authors": [
      "Jiarui Wang",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.08481",
    "title": "SoK: Reducing the Vulnerability of Fine-tuned Language Models to  Membership Inference Attacks",
    "abstract": "Natural language processing models have experienced a significant upsurge in recent years, with numerous applications being built upon them. Many of these applications require fine-tuning generic base models on customized, proprietary datasets. This fine-tuning data is especially likely to contain personal or sensitive information about individuals, resulting in increased privacy risk. Membership inference attacks are the most commonly employed attack to assess the privacy leakage of a machine learning model. However, limited research is available on the factors that affect the vulnerability of language models to this kind of attack, or on the applicability of different defense strategies in the language domain. We provide the first systematic review of the vulnerability of fine-tuned large language models to membership inference attacks, the various factors that come into play, and the effectiveness of different defense strategies. We find that some training methods provide significantly reduced privacy risk, with the combination of differential privacy and low-rank adaptors achieving the best privacy protection against these attacks. ",
    "url": "https://arxiv.org/abs/2403.08481",
    "authors": [
      "Guy Amit",
      "Abigail Goldsteen",
      "Ariel Farkash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.08493",
    "title": "A Prediction Model for Rumor Forwarding Behavior Based on Uncertain Time  Series",
    "abstract": "The rapid spread of rumors in social media is mainly caused by individual retweets. This paper applies uncertainty time series analysis (UTSA) to analyze a rumor retweeting behavior on Weibo. First, the rumor forwarding is modeled using uncertain time series, including order selection, parameter estimation, residual analysis, uncertainty hypothesis testing and forecast, and the validity of using uncertain time series analysis is further supported by analyzing the characteristics of the residual plot. The experimental results show that the uncertain time series can better predict the next stage of rumor forwarding. The results of the study have important practical significance for rumor management and the management of social media information dissemination. ",
    "url": "https://arxiv.org/abs/2403.08493",
    "authors": [
      "Ruihong Wang",
      "Fingming Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.08499",
    "title": "Improved YOLOv5 Based on Attention Mechanism and FasterNet for Foreign  Object Detection on Railway and Airway tracks",
    "abstract": "In recent years, there have been frequent incidents of foreign objects intruding into railway and Airport runways. These objects can include pedestrians, vehicles, animals, and debris. This paper introduces an improved YOLOv5 architecture incorporating FasterNet and attention mechanisms to enhance the detection of foreign objects on railways and Airport runways. This study proposes a new dataset, AARFOD (Aero and Rail Foreign Object Detection), which combines two public datasets for detecting foreign objects in aviation and railway systems.The dataset aims to improve the recognition capabilities of foreign object targets. Experimental results on this large dataset have demonstrated significant performance improvements of the proposed model over the baseline YOLOv5 model, reducing computational requirements.Improved YOLO model shows a significant improvement in precision by 1.2%, recall rate by 1.0%, and mAP@.5 by 0.6%, while mAP@.5-.95 remained unchanged. The parameters were reduced by approximately 25.12%, and GFLOPs were reduced by about 10.63%. In the ablation experiment, it is found that the FasterNet module can significantly reduce the number of parameters of the model, and the reference of the attention mechanism can slow down the performance loss caused by lightweight. ",
    "url": "https://arxiv.org/abs/2403.08499",
    "authors": [
      "Zongqing Qi",
      "Danqing Ma",
      "Jingyu Xu",
      "Ao Xiang",
      "Hedi Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08502",
    "title": "Masked Generative Story Transformer with Character Guidance and Caption  Augmentation",
    "abstract": "Story Visualization (SV) is a challenging generative vision task, that requires both visual quality and consistency between different frames in generated image sequences. Previous approaches either employ some kind of memory mechanism to maintain context throughout an auto-regressive generation of the image sequence, or model the generation of the characters and their background separately, to improve the rendering of characters. On the contrary, we embrace a completely parallel transformer-based approach, exclusively relying on Cross-Attention with past and future captions to achieve consistency. Additionally, we propose a Character Guidance technique to focus on the generation of characters in an implicit manner, by forming a combination of text-conditional and character-conditional logits in the logit space. We also employ a caption-augmentation technique, carried out by a Large Language Model (LLM), to enhance the robustness of our approach. The combination of these methods culminates into state-of-the-art (SOTA) results over various metrics in the most prominent SV benchmark (Pororo-SV), attained with constraint resources while achieving superior computational complexity compared to previous arts. The validity of our quantitative results is supported by a human survey. ",
    "url": "https://arxiv.org/abs/2403.08502",
    "authors": [
      "Christos Papadimitriou",
      "Giorgos Filandrianos",
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08507",
    "title": "MobileAtlas: Geographically Decoupled Measurements in Cellular Networks  for Security and Privacy Research",
    "abstract": "Cellular networks are not merely data access networks to the Internet. Their distinct services and ability to form large complex compounds for roaming purposes make them an attractive research target in their own right. Their promise of providing a consistent service with comparable privacy and security across roaming partners falls apart at close inspection. Thus, there is a need for controlled testbeds and measurement tools for cellular access networks doing justice to the technology's unique structure and global scope. Particularly, such measurements suffer from a combinatorial explosion of operators, mobile plans, and services. To cope with these challenges, we built a framework that geographically decouples the SIM from the cellular modem by selectively connecting both remotely. This allows testing any subscriber with any operator at any modem location within minutes without moving parts. The resulting GSM/UMTS/LTE measurement and testbed platform offers a controlled experimentation environment, which is scalable and cost-effective. The platform is extensible and fully open-sourced, allowing other researchers to contribute locations, SIM cards, and measurement scripts. Using the above framework, our international experiments in commercial networks revealed exploitable inconsistencies in traffic metering, leading to multiple phreaking opportunities, i.e., fare-dodging. We also expose problematic IPv6 firewall configurations, hidden SIM card communication to the home network, and fingerprint dial progress tones to track victims across different roaming networks and countries with voice calls. ",
    "url": "https://arxiv.org/abs/2403.08507",
    "authors": [
      "Gabriel Karl Gegenhuber",
      "Wilfried Mayer",
      "Edgar Weippl",
      "Adrian Dabrowski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.08511",
    "title": "A Multimodal Fusion Network For Student Emotion Recognition Based on  Transformer and Tensor Product",
    "abstract": "In recent years, there have been frequent incidents of foreign objects intruding into railway and Airport runways. These objects can include pedestrians, vehicles, animals, and debris. This paper introduces an improved YOLOv5 architecture incorporating FasterNet and attention mechanisms to enhance the detection of foreign objects on railways and Airport runways. This study proposes a new dataset, AARFOD (Aero and Rail Foreign Object Detection), which combines two public datasets for detecting foreign objects in aviation and railway systems. The dataset aims to improve the recognition capabilities of foreign object targets. Experimental results on this large dataset have demonstrated significant performance improvements of the proposed model over the baseline YOLOv5 model, reducing computational requirements. improved YOLO model shows a significant improvement in precision by 1.2%, recall rate by 1.0%, and mAP@.5 by 0.6%, while mAP@.5-.95 remained unchanged. The parameters were reduced by approximately 25.12%, and GFLOPs were reduced by about 10.63%. In the ablation experiment, it is found that the FasterNet module can significantly reduce the number of parameters of the model, and the reference of the attention mechanism can slow down the performance loss caused by lightweight. ",
    "url": "https://arxiv.org/abs/2403.08511",
    "authors": [
      "Ao Xiang",
      "Zongqing Qi",
      "Han Wang",
      "Qin Yang",
      "Danqing Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08525",
    "title": "From Weak to Strong Sound Event Labels using Adaptive Change-Point  Detection and Active Learning",
    "abstract": "In this work we propose an audio recording segmentation method based on an adaptive change point detection (A-CPD) for machine guided weak label annotation of audio recording segments. The goal is to maximize the amount of information gained about the temporal activation's of the target sounds. For each unlabeled audio recording, we use a prediction model to derive a probability curve used to guide annotation. The prediction model is initially pre-trained on available annotated sound event data with classes that are disjoint from the classes in the unlabeled dataset. The prediction model then gradually adapts to the annotations provided by the annotator in an active learning loop. The queries used to guide the weak label annotator towards strong labels are derived using change point detection on these probabilities. We show that it is possible to derive strong labels of high quality even with a limited annotation budget, and show favorable results for A-CPD when compared to two baseline query strategies. ",
    "url": "https://arxiv.org/abs/2403.08525",
    "authors": [
      "John Martinsson",
      "Olof Mogren",
      "Maria Sandsten",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.08528",
    "title": "Pig aggression classification using CNN, Transformers and Recurrent  Networks",
    "abstract": "The development of techniques that can be used to analyze and detect animal behavior is a crucial activity for the livestock sector, as it is possible to monitor the stress and animal welfare and contributes to decision making in the farm. Thus, the development of applications can assist breeders in making decisions to improve production performance and reduce costs, once the animal behavior is analyzed by humans and this can lead to susceptible errors and time consumption. Aggressiveness in pigs is an example of behavior that is studied to reduce its impact through animal classification and identification. However, this process is laborious and susceptible to errors, which can be reduced through automation by visually classifying videos captured in controlled environment. The captured videos can be used for training and, as a result, for classification through computer vision and artificial intelligence, employing neural network techniques. The main techniques utilized in this study are variants of transformers: STAM, TimeSformer, and ViViT, as well as techniques using convolutions, such as ResNet3D2, Resnet(2+1)D, and CnnLstm. These techniques were employed for pig video classification with the objective of identifying aggressive and non-aggressive behaviors. In this work, various techniques were compared to analyze the contribution of using transformers, in addition to the effectiveness of the convolution technique in video classification. The performance was evaluated using accuracy, precision, and recall. The TimerSformer technique showed the best results in video classification, with median accuracy of 0.729. ",
    "url": "https://arxiv.org/abs/2403.08528",
    "authors": [
      "Junior Silva Souza",
      "Eduardo Bedin",
      "Gabriel Toshio Hirokawa Higa",
      "Newton Loebens",
      "Hemerson Pistori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08536",
    "title": "HOLMES: HOLonym-MEronym based Semantic inspection for Convolutional  Image Classifiers",
    "abstract": "Convolutional Neural Networks (CNNs) are nowadays the model of choice in Computer Vision, thanks to their ability to automatize the feature extraction process in visual tasks. However, the knowledge acquired during training is fully subsymbolic, and hence difficult to understand and explain to end users. In this paper, we propose a new technique called HOLMES (HOLonym-MEronym based Semantic inspection) that decomposes a label into a set of related concepts, and provides component-level explanations for an image classification model. Specifically, HOLMES leverages ontologies, web scraping and transfer learning to automatically construct meronym (parts)-based detectors for a given holonym (class). Then, it produces heatmaps at the meronym level and finally, by probing the holonym CNN with occluded images, it highlights the importance of each part on the classification output. Compared to state-of-the-art saliency methods, HOLMES takes a step further and provides information about both where and what the holonym CNN is looking at, without relying on densely annotated datasets and without forcing concepts to be associated to single computational units. Extensive experimental evaluation on different categories of objects (animals, tools and vehicles) shows the feasibility of our approach. On average, HOLMES explanations include at least two meronyms, and the ablation of a single meronym roughly halves the holonym model confidence. The resulting heatmaps were quantitatively evaluated using the deletion/insertion/preservation curves. All metrics were comparable to those achieved by GradCAM, while offering the advantage of further decomposing the heatmap in human-understandable concepts, thus highlighting both the relevance of meronyms to object classification, as well as HOLMES ability to capture it. The code is available at https://github.com/FrancesC0de/HOLMES. ",
    "url": "https://arxiv.org/abs/2403.08536",
    "authors": [
      "Francesco Dibitonto",
      "Fabio Garcea",
      "Andr\u00e9 Panisson",
      "Alan Perotti",
      "Lia Morra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08549",
    "title": "Wet TinyML: Chemical Neural Network Using Gene Regulation and Cell  Plasticity",
    "abstract": "In our earlier work, we introduced the concept of Gene Regulatory Neural Network (GRNN), which utilizes natural neural network-like structures inherent in biological cells to perform computing tasks using chemical inputs. We define this form of chemical-based neural network as Wet TinyML. The GRNN structures are based on the gene regulatory network and have weights associated with each link based on the estimated interactions between the genes. The GRNNs can be used for conventional computing by employing an application-based search process similar to the Network Architecture Search. This study advances this concept by incorporating cell plasticity, to further exploit natural cell's adaptability, in order to diversify the GRNN search that can match larger spectrum as well as dynamic computing tasks. As an example application, we show that through the directed cell plasticity, we can extract the mathematical regression evolution enabling it to match to dynamic system applications. We also conduct energy analysis by comparing the chemical energy of the GRNN to its silicon counterpart, where this analysis includes both artificial neural network algorithms executed on von Neumann architecture as well as neuromorphic processors. The concept of Wet TinyML can pave the way for the new emergence of chemical-based, energy-efficient and miniature Biological AI. ",
    "url": "https://arxiv.org/abs/2403.08549",
    "authors": [
      "Samitha Somathilaka",
      "Adrian Ratwatte",
      "Sasitharan Balasubramaniam",
      "Mehmet Can Vuran",
      "Witawas Srisa-an",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.08550",
    "title": "CINA: Conditional Implicit Neural Atlas for Spatio-Temporal  Representation of Fetal Brains",
    "abstract": "We introduce a conditional implicit neural atlas (CINA) for spatio-temporal atlas generation from Magnetic Resonance Images (MRI) of the neurotypical and pathological fetal brain, that is fully independent of affine or non-rigid registration. During training, CINA learns a general representation of the fetal brain and encodes subject specific information into latent code. After training, CINA can construct a faithful atlas with tissue probability maps of the fetal brain for any gestational age (GA) and anatomical variation covered within the training domain. Thus, CINA is competent to represent both, neurotypical and pathological brains. Furthermore, a trained CINA model can be fit to brain MRI of unseen subjects via test-time optimization of the latent code. CINA can then produce probabilistic tissue maps tailored to a particular subject. We evaluate our method on a total of 198 T2 weighted MRI of normal and abnormal fetal brains from the dHCP and FeTA datasets. We demonstrate CINA's capability to represent a fetal brain atlas that can be flexibly conditioned on GA and on anatomical variations like ventricular volume or degree of cortical folding, making it a suitable tool for modeling both neurotypical and pathological brains. We quantify the fidelity of our atlas by means of tissue segmentation and age prediction and compare it to an established baseline. CINA demonstrates superior accuracy for neurotypical brains and pathological brains with ventriculomegaly. Moreover, CINA scores a mean absolute error of 0.23 weeks in fetal brain age prediction, further confirming an accurate representation of fetal brain development. ",
    "url": "https://arxiv.org/abs/2403.08550",
    "authors": [
      "Maik Dannecker",
      "Vanessa Kyriakopoulou",
      "Lucilio Cordero-Grande",
      "Anthony N. Price",
      "Joseph V. Hajnal",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08554",
    "title": "Federated Knowledge Graph Unlearning via Diffusion Model",
    "abstract": "Federated learning (FL) promotes the development and application of artificial intelligence technologies by enabling model sharing and collaboration while safeguarding data privacy. Knowledge graph (KG) embedding representation provides a foundation for knowledge reasoning and applications by mapping entities and relations into vector space. Federated KG embedding enables the utilization of knowledge from diverse client sources while safeguarding the privacy of local data. However, due to demands such as privacy protection and the need to adapt to dynamic data changes, investigations into machine unlearning (MU) have been sparked. However, it is challenging to maintain the performance of KG embedding models while forgetting the influence of specific forgotten data on the model. In this paper, we propose FedDM, a novel framework tailored for machine unlearning in federated knowledge graphs. Leveraging diffusion models, we generate noisy data to sensibly mitigate the influence of specific knowledge on FL models while preserving the overall performance concerning the remaining data. We conduct experimental evaluations on benchmark datasets to assess the efficacy of the proposed model. Extensive experiments demonstrate that FedDM yields promising results in knowledge forgetting. ",
    "url": "https://arxiv.org/abs/2403.08554",
    "authors": [
      "Bingchen Liu",
      "Yuanyuan Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08562",
    "title": "Structural perspective on constraint-based learning of Markov networks",
    "abstract": "Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary. On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph. When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound $q$ on the sizes of the conditioning sets, there exist graphs with $O(n q)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2\\kappa$. ",
    "url": "https://arxiv.org/abs/2403.08562",
    "authors": [
      "Tuukka Korhonen",
      "Fedor V. Fomin",
      "Pekka Parviainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.08572",
    "title": "Caformer: Rethinking Time Series Analysis from Causal Perspective",
    "abstract": "Time series analysis is a vital task with broad applications in various domains. However, effectively capturing cross-dimension and cross-time dependencies in non-stationary time series poses significant challenges, particularly in the context of environmental factors. The spurious correlation induced by the environment confounds the causal relationships between cross-dimension and cross-time dependencies. In this paper, we introduce a novel framework called Caformer (\\underline{\\textbf{Ca}}usal Trans\\underline{\\textbf{former}}) for time series analysis from a causal perspective. Specifically, our framework comprises three components: Dynamic Learner, Environment Learner, and Dependency Learner. The Dynamic Learner unveils dynamic interactions among dimensions, the Environment Learner mitigates spurious correlations caused by environment with a back-door adjustment, and the Dependency Learner aims to infer robust interactions across both time and dimensions. Our Caformer demonstrates consistent state-of-the-art performance across five mainstream time series analysis tasks, including long- and short-term forecasting, imputation, classification, and anomaly detection, with proper interpretability. ",
    "url": "https://arxiv.org/abs/2403.08572",
    "authors": [
      "Kexuan Zhang",
      "Xiaobei Zou",
      "Yang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08589",
    "title": "Can physical information aid the generalization ability of Neural  Networks for hydraulic modeling?",
    "abstract": "Application of Neural Networks to river hydraulics is fledgling, despite the field suffering from data scarcity, a challenge for machine learning techniques. Consequently, many purely data-driven Neural Networks proved to lack predictive capabilities. In this work, we propose to mitigate such problem by introducing physical information into the training phase. The idea is borrowed from Physics-Informed Neural Networks which have been recently proposed in other contexts. Physics-Informed Neural Networks embed physical information in the form of the residual of the Partial Differential Equations (PDEs) governing the phenomenon and, as such, are conceived as neural solvers, i.e. an alternative to traditional numerical solvers. Such approach is seldom suitable for environmental hydraulics, where epistemic uncertainties are large, and computing residuals of PDEs exhibits difficulties similar to those faced by classical numerical methods. Instead, we envisaged the employment of Neural Networks as neural operators, featuring physical constraints formulated without resorting to PDEs. The proposed novel methodology shares similarities with data augmentation and regularization. We show that incorporating such soft physical information can improve predictive capabilities. ",
    "url": "https://arxiv.org/abs/2403.08589",
    "authors": [
      "Gianmarco Guglielmo",
      "Andrea Montessori",
      "Jean-Michel Tucny",
      "Michele La Rocca",
      "Pietro Prestininzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2403.08600",
    "title": "Evaluation of Control/User-Plane Denial-of-Service (DoS) Attack on O-RAN  Fronthaul Interface",
    "abstract": "The open fronthaul interface defined by O-RAN ALLIANCE aims to support the interoperability between multi-vendor open radio access network (O-RAN) radio units (O-RU) and O-RAN distributed units (O-DU). This paper introduces a new tool that could be used to evaluate Denial-of-Service (DoS) attacks against the open fronthaul interface. We launched an array of control/user planes (C/U-Planes) attacks with the tool under different traffic types and data rates, and we evaluated their impacts on the throughput and block error rate (BLER) of real-world O-RAN systems with commercial hardware. ",
    "url": "https://arxiv.org/abs/2403.08600",
    "authors": [
      "Ferlinda Feliana",
      "Ting-Wei Hung",
      "Binbin Chen",
      "Ray-Guang Cheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.08605",
    "title": "Language-Grounded Dynamic Scene Graphs for Interactive Object Search  with Mobile Manipulation",
    "abstract": "To fully leverage the capabilities of mobile manipulation robots, it is imperative that they are able to autonomously execute long-horizon tasks in large unexplored environments. While large language models (LLMs) have shown emergent reasoning skills on arbitrary tasks, existing work primarily concentrates on explored environments, typically focusing on either navigation or manipulation tasks in isolation. In this work, we propose MoMa-LLM, a novel approach that grounds language models within structured representations derived from open-vocabulary scene graphs, dynamically updated as the environment is explored. We tightly interleave these representations with an object-centric action space. The resulting approach is zero-shot, open-vocabulary, and readily extendable to a spectrum of mobile manipulation and household robotic tasks. We demonstrate the effectiveness of MoMa-LLM in a novel semantic interactive search task in large realistic indoor environments. In extensive experiments in both simulation and the real world, we show substantially improved search efficiency compared to conventional baselines and state-of-the-art approaches, as well as its applicability to more abstract tasks. We make the code publicly available at this http URL ",
    "url": "https://arxiv.org/abs/2403.08605",
    "authors": [
      "Daniel Honerkamp",
      "Martin B\u00fcchner",
      "Fabien Despinoy",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.08607",
    "title": "MedInsight: A Multi-Source Context Augmentation Framework for Generating  Patient-Centric Medical Responses using Large Language Models",
    "abstract": "Large Language Models (LLMs) have shown impressive capabilities in generating human-like responses. However, their lack of domain-specific knowledge limits their applicability in healthcare settings, where contextual and comprehensive responses are vital. To address this challenge and enable the generation of patient-centric responses that are contextually relevant and comprehensive, we propose MedInsight:a novel retrieval augmented framework that augments LLM inputs (prompts) with relevant background information from multiple sources. MedInsight extracts pertinent details from the patient's medical record or consultation transcript. It then integrates information from authoritative medical textbooks and curated web resources based on the patient's health history and condition. By constructing an augmented context combining the patient's record with relevant medical knowledge, MedInsight generates enriched, patient-specific responses tailored for healthcare applications such as diagnosis, treatment recommendations, or patient education. Experiments on the MTSamples dataset validate MedInsight's effectiveness in generating contextually appropriate medical responses. Quantitative evaluation using the Ragas metric and TruLens for answer similarity and answer correctness demonstrates the model's efficacy. Furthermore, human evaluation studies involving Subject Matter Expert (SMEs) confirm MedInsight's utility, with moderate inter-rater agreement on the relevance and correctness of the generated responses. ",
    "url": "https://arxiv.org/abs/2403.08607",
    "authors": [
      "Subash Neupane",
      "Shaswata Mitra",
      "Sudip Mittal",
      "Noorbakhsh Amiri Golilarz",
      "Shahram Rahimi",
      "Amin Amirlatifi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08609",
    "title": "On the Convergence of Locally Adaptive and Scalable Diffusion-Based  Sampling Methods for Deep Bayesian Neural Network Posteriors",
    "abstract": "Achieving robust uncertainty quantification for deep neural networks represents an important requirement in many real-world applications of deep learning such as medical imaging where it is necessary to assess the reliability of a neural network's prediction. Bayesian neural networks are a promising approach for modeling uncertainties in deep neural networks. Unfortunately, generating samples from the posterior distribution of neural networks is a major challenge. One significant advance in that direction would be the incorporation of adaptive step sizes, similar to modern neural network optimizers, into Monte Carlo Markov chain sampling algorithms without significantly increasing computational demand. Over the past years, several papers have introduced sampling algorithms with claims that they achieve this property. However, do they indeed converge to the correct distribution? In this paper, we demonstrate that these methods can have a substantial bias in the distribution they sample, even in the limit of vanishing step sizes and at full batch size. ",
    "url": "https://arxiv.org/abs/2403.08609",
    "authors": [
      "Tim Rensmeyer",
      "Oliver Niggemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08613",
    "title": "Link Prediction for Social Networks using Representation Learning and  Heuristic-based Features",
    "abstract": "The exponential growth in scale and relevance of social networks enable them to provide expansive insights. Predicting missing links in social networks efficiently can help in various modern-day business applications ranging from generating recommendations to influence analysis. Several categories of solutions exist for the same. Here, we explore various feature extraction techniques to generate representations of nodes and edges in a social network that allow us to predict missing links. We compare the results of using ten feature extraction techniques categorized across Structural embeddings, Neighborhood-based embeddings, Graph Neural Networks, and Graph Heuristics, followed by modeling with ensemble classifiers and custom Neural Networks. Further, we propose combining heuristic-based features and learned representations that demonstrate improved performance for the link prediction task on social network datasets. Using this method to generate accurate recommendations for many applications is a matter of further study that appears very promising. The code for all the experiments has been made public. ",
    "url": "https://arxiv.org/abs/2403.08613",
    "authors": [
      "Samarth Khanna",
      "Sree Bhattacharyya",
      "Sudipto Ghosh",
      "Kushagra Agarwal",
      "Asit Kumar Das"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08618",
    "title": "Verifix: Post-Training Correction to Improve Label Noise Robustness with  Verified Samples",
    "abstract": "Label corruption, where training samples have incorrect labels, can significantly degrade the performance of machine learning models. This corruption often arises from non-expert labeling or adversarial attacks. Acquiring large, perfectly labeled datasets is costly, and retraining large models from scratch when a clean dataset becomes available is computationally expensive. To address this challenge, we propose Post-Training Correction, a new paradigm that adjusts model parameters after initial training to mitigate label noise, eliminating the need for retraining. We introduce Verifix, a novel Singular Value Decomposition (SVD) based algorithm that leverages a small, verified dataset to correct the model weights using a single update. Verifix uses SVD to estimate a Clean Activation Space and then projects the model's weights onto this space to suppress activations corresponding to corrupted data. We demonstrate Verifix's effectiveness on both synthetic and real-world label noise. Experiments on the CIFAR dataset with 25% synthetic corruption show 7.36% generalization improvements on average. Additionally, we observe generalization improvements of up to 2.63% on naturally corrupted datasets like WebVision1.0 and Clothing1M. ",
    "url": "https://arxiv.org/abs/2403.08618",
    "authors": [
      "Sangamesh Kodge",
      "Deepak Ravikumar",
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08624",
    "title": "Towards a Privacy and Security-Aware Framework for Ethical AI: Guiding  the Development and Assessment of AI Systems",
    "abstract": "As artificial intelligence continues its unprecedented global expansion, accompanied by a proliferation of benefits, an increasing apprehension about the privacy and security implications of AI-enabled systems emerges. The pivotal question of effectively controlling AI development at both jurisdictional and organizational levels has become a prominent theme in contemporary discourse. While the European Parliament and Council have taken a decisive step by reaching a political agreement on the EU AI Act, the first comprehensive AI law, organizations still find it challenging to adapt to the fast-evolving AI landscape, lacking a universal tool for evaluating the privacy and security dimensions of their AI models and systems. In response to this critical challenge, this study conducts a systematic literature review spanning the years 2020 to 2023, with a primary focus on establishing a unified definition of key concepts in AI Ethics, particularly emphasizing the domains of privacy and security. Through the synthesis of knowledge extracted from the SLR, this study presents a conceptual framework tailored for privacy- and security-aware AI systems. This framework is designed to assist diverse stakeholders, including organizations, academic institutions, and governmental bodies, in both the development and critical assessment of AI systems. Essentially, the proposed framework serves as a guide for ethical decision-making, fostering an environment wherein AI is developed and utilized with a strong commitment to ethical principles. In addition, the study unravels the key issues and challenges surrounding the privacy and security dimensions, delineating promising avenues for future research, thereby contributing to the ongoing dialogue on the globalization and democratization of AI ethics. ",
    "url": "https://arxiv.org/abs/2403.08624",
    "authors": [
      "Daria Korobenko",
      "Anastasija Nikiforova",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.08638",
    "title": "Disparate Effect Of Missing Mediators On Transportability of Causal  Effects",
    "abstract": "Transported mediation effects provide an avenue to understand how upstream interventions (such as improved neighborhood conditions like green spaces) would work differently when applied to different populations as a result of factors that mediate the effects. However, when mediators are missing in the population where the effect is to be transported, these estimates could be biased. We study this issue of missing mediators, motivated by challenges in public health, wherein mediators can be missing, not at random. We propose a sensitivity analysis framework that quantifies the impact of missing mediator data on transported mediation effects. This framework enables us to identify the settings under which the conditional transported mediation effect is rendered insignificant for the subgroup with missing mediator data. Specifically, we provide the bounds on the transported mediation effect as a function of missingness. We then apply the framework to longitudinal data from the Moving to Opportunity Study, a large-scale housing voucher experiment, to quantify the effect of missing mediators on transport effect estimates of voucher receipt, an upstream intervention on living location, in childhood on subsequent risk of mental health or substance use disorder mediated through parental health across sites. Our findings provide a tangible understanding of how much missing data can be withstood for unbiased effect estimates. ",
    "url": "https://arxiv.org/abs/2403.08638",
    "authors": [
      "Vishwali Mhasawade",
      "Rumi Chunara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.08639",
    "title": "HIMap: HybrId Representation Learning for End-to-end Vectorized HD Map  Construction",
    "abstract": "Vectorized High-Definition (HD) map construction requires predictions of the category and point coordinates of map elements (e.g. road boundary, lane divider, pedestrian crossing, etc.). State-of-the-art methods are mainly based on point-level representation learning for regressing accurate point coordinates. However, this pipeline has limitations in obtaining element-level information and handling element-level failures, e.g. erroneous element shape or entanglement between elements. To tackle the above issues, we propose a simple yet effective HybrId framework named HIMap to sufficiently learn and interact both point-level and element-level information. Concretely, we introduce a hybrid representation called HIQuery to represent all map elements, and propose a point-element interactor to interactively extract and encode the hybrid information of elements, e.g. point position and element shape, into the HIQuery. Additionally, we present a point-element consistency constraint to enhance the consistency between the point-level and element-level information. Finally, the output point-element integrated HIQuery can be directly converted into map elements' class, point coordinates, and mask. We conduct extensive experiments and consistently outperform previous methods on both nuScenes and Argoverse2 datasets. Notably, our method achieves $77.8$ mAP on the nuScenes dataset, remarkably superior to previous SOTAs by $8.3$ mAP at least. ",
    "url": "https://arxiv.org/abs/2403.08639",
    "authors": [
      "Yi Zhou",
      "Hui Zhang",
      "Jiaqian Yu",
      "Yifan Yang",
      "Sangil Jung",
      "Seung-In Park",
      "ByungIn Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08648",
    "title": "Meta Reinforcement Learning for Resource Allocation in Aerial  Active-RIS-assisted Networks with Rate-Splitting Multiple Access",
    "abstract": "Mounting a reconfigurable intelligent surface (RIS) on an unmanned aerial vehicle (UAV) holds promise for improving traditional terrestrial network performance. Unlike conventional methods deploying passive RIS on UAVs, this study delves into the efficacy of an aerial active RIS (AARIS). Specifically, the downlink transmission of an AARIS network is investigated, where the base station (BS) leverages rate-splitting multiple access (RSMA) for effective interference management and benefits from the support of an AARIS for jointly amplifying and reflecting the BS's transmit signals. Considering both the non-trivial energy consumption of the active RIS and the limited energy storage of the UAV, we propose an innovative element selection strategy for optimizing the on/off status of RIS elements, which adaptively and remarkably manages the system's power consumption. To this end, a resource management problem is formulated, aiming to maximize the system energy efficiency (EE) by jointly optimizing the transmit beamforming at the BS, the element activation, the phase shift and the amplification factor at the RIS, the RSMA common data rate at users, as well as the UAV's trajectory. Due to the dynamicity nature of UAV and user mobility, a deep reinforcement learning (DRL) algorithm is designed for resource allocation, utilizing meta-learning to adaptively handle fast time-varying system dynamics. Simulations indicate that incorporating an active RIS at the UAV leads to substantial EE gain, compared to passive RIS-aided UAV. We observe the superiority of the RSMA-based AARIS system in terms of EE, compared to existing approaches adopting non-orthogonal multiple access (NOMA). ",
    "url": "https://arxiv.org/abs/2403.08648",
    "authors": [
      "Sajad Faramarzi",
      "Sepideh Javadi",
      "Farshad Zeinali",
      "Hosein Zarini",
      "Mohammad Robat Mili",
      "Mehdi Bennis",
      "Yonghui Li",
      "Kai-Kit Wong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.08649",
    "title": "A Causal Inspired Early-Branching Structure for Domain Generalization",
    "abstract": "Learning domain-invariant semantic representations is crucial for achieving domain generalization (DG), where a model is required to perform well on unseen target domains. One critical challenge is that standard training often results in entangled semantic and domain-specific features. Previous works suggest formulating the problem from a causal perspective and solving the entanglement problem by enforcing marginal independence between the causal (\\ie semantic) and non-causal (\\ie domain-specific) features. Despite its simplicity, the basic marginal independent-based idea alone may be insufficient to identify the causal feature. By d-separation, we observe that the causal feature can be further characterized by being independent of the domain conditioned on the object, and we propose the following two strategies as complements for the basic framework. First, the observation implicitly implies that for the same object, the causal feature should not be associated with the non-causal feature, revealing that the common practice of obtaining the two features with a shared base feature extractor and two lightweight prediction heads might be inappropriate. To meet the constraint, we propose a simple early-branching structure, where the causal and non-causal feature obtaining branches share the first few blocks while diverging thereafter, for better structure design; Second, the observation implies that the causal feature remains invariant across different domains for the same object. To this end, we suggest that augmentation should be incorporated into the framework to better characterize the causal feature, and we further suggest an effective random domain sampling scheme to fulfill the task. Theoretical and experimental results show that the two strategies are beneficial for the basic marginal independent-based framework. Code is available at \\url{https://github.com/liangchen527/CausEB}. ",
    "url": "https://arxiv.org/abs/2403.08649",
    "authors": [
      "Liang Chen",
      "Yong Zhang",
      "Yibing Song",
      "Zhen Zhang",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08650",
    "title": "Data Augmentation in Human-Centric Vision",
    "abstract": "This survey presents a comprehensive analysis of data augmentation techniques in human-centric vision tasks, a first of its kind in the field. It delves into a wide range of research areas including person ReID, human parsing, human pose estimation, and pedestrian detection, addressing the significant challenges posed by overfitting and limited training data in these domains. Our work categorizes data augmentation methods into two main types: data generation and data perturbation. Data generation covers techniques like graphic engine-based generation, generative model-based generation, and data recombination, while data perturbation is divided into image-level and human-level perturbations. Each method is tailored to the unique requirements of human-centric tasks, with some applicable across multiple areas. Our contributions include an extensive literature review, providing deep insights into the influence of these augmentation techniques in human-centric vision and highlighting the nuances of each method. We also discuss open issues and future directions, such as the integration of advanced generative models like Latent Diffusion Models, for creating more realistic and diverse training data. This survey not only encapsulates the current state of data augmentation in human-centric vision but also charts a course for future research, aiming to develop more robust, accurate, and efficient human-centric vision systems. ",
    "url": "https://arxiv.org/abs/2403.08650",
    "authors": [
      "Wentao Jiang",
      "Yige Zhang",
      "Shaozhong Zheng",
      "Si Liu",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08652",
    "title": "Extracting Explanations, Justification, and Uncertainty from Black-Box  Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) do not inherently compute or exhibit empirically-justified task confidence. In mission critical applications, it is important to both understand associated DNN reasoning and its supporting evidence. In this paper, we propose a novel Bayesian approach to extract explanations, justifications, and uncertainty estimates from DNNs. Our approach is efficient both in terms of memory and computation, and can be applied to any black box DNN without any retraining, including applications to anomaly detection and out-of-distribution detection tasks. We validate our approach on the CIFAR-10 dataset, and show that it can significantly improve the interpretability and reliability of DNNs. ",
    "url": "https://arxiv.org/abs/2403.08652",
    "authors": [
      "Paul Ardis",
      "Arjuna Flenner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08656",
    "title": "Physical Memory Attacks and a Memory Safe Management System for Memory  Defense",
    "abstract": "Programming errors, defective hardware components (such as hard disk spindle defects), and environmental hazards can lead to invalid memory operations. In addition, less predictable forms of environmental stress, such as radiation, thermal influence, and energy fluctuations, can induce hardware faults. Sometimes, a soft error can occur instead of a complete failure, such as a bit-flip. The 'natural' factors that can cause bit-flips are replicable through targeted attacks that result in significant compromises, including full privileged system access. Existing physical defense solutions have consistently been circumvented shortly after deployment. We will explore the concept of a novel software-based low-level layer that can protect vulnerable memory targeted by physical attack vectors related to bit-flip vulnerabilities. ",
    "url": "https://arxiv.org/abs/2403.08656",
    "authors": [
      "Alon Hillel-Tuch",
      "Aspen Olmstead"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2403.08673",
    "title": "When can we Approximate Wide Contrastive Models with Neural Tangent  Kernels and Principal Component Analysis?",
    "abstract": "Contrastive learning is a paradigm for learning representations from unlabelled data that has been highly successful for image and text data. Several recent works have examined contrastive losses to claim that contrastive models effectively learn spectral embeddings, while few works show relations between (wide) contrastive models and kernel principal component analysis (PCA). However, it is not known if trained contrastive models indeed correspond to kernel methods or PCA. In this work, we analyze the training dynamics of two-layer contrastive models, with non-linear activation, and answer when these models are close to PCA or kernel methods. It is well known in the supervised setting that neural networks are equivalent to neural tangent kernel (NTK) machines, and that the NTK of infinitely wide networks remains constant during training. We provide the first convergence results of NTK for contrastive losses, and present a nuanced picture: NTK of wide networks remains almost constant for cosine similarity based contrastive losses, but not for losses based on dot product similarity. We further study the training dynamics of contrastive models with orthogonality constraints on output layer, which is implicitly assumed in works relating contrastive learning to spectral embedding. Our deviation bounds suggest that representations learned by contrastive models are close to the principal components of a certain matrix computed from random features. We empirically show that our theoretical results possibly hold beyond two-layer networks. ",
    "url": "https://arxiv.org/abs/2403.08673",
    "authors": [
      "Gautham Govind Anil",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.08680",
    "title": "Towards the THz Networks in the 6G Era",
    "abstract": "This commentary dedicates to envision what role THz is going to play in the coming human-centric 6G era. Three distinct THz network types including outdoor, indoor, and body area networks are discussed, with an emphasis on their capabilities in human body detection. Synthesizing these networks will unlock a bunch of fascinating applications across industrial, biomedical and entertainment fields, significantly enhancing the quality of human life. ",
    "url": "https://arxiv.org/abs/2403.08680",
    "authors": [
      "Qian Ding",
      "Jie Yang",
      "Yang Luo",
      "Chunbo Luo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.08738",
    "title": "Improving Acoustic Word Embeddings through Correspondence Training of  Self-supervised Speech Representations",
    "abstract": "Acoustic word embeddings (AWEs) are vector representations of spoken words. An effective method for obtaining AWEs is the Correspondence Auto-Encoder (CAE). In the past, the CAE method has been associated with traditional MFCC features. Representations obtained from self-supervised learning (SSL)-based speech models such as HuBERT, Wav2vec2, etc., are outperforming MFCC in many downstream tasks. However, they have not been well studied in the context of learning AWEs. This work explores the effectiveness of CAE with SSL-based speech representations to obtain improved AWEs. Additionally, the capabilities of SSL-based speech models are explored in cross-lingual scenarios for obtaining AWEs. Experiments are conducted on five languages: Polish, Portuguese, Spanish, French, and English. HuBERT-based CAE model achieves the best results for word discrimination in all languages, despite Hu-BERT being pre-trained on English only. Also, the HuBERT-based CAE model works well in cross-lingual settings. It outperforms MFCC-based CAE models trained on the target languages when trained on one source language and tested on target languages. ",
    "url": "https://arxiv.org/abs/2403.08738",
    "authors": [
      "Amit Meghanani",
      "Thomas Hain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.08740",
    "title": "Acoustic Side Channel Attack on Keyboards Based on Typing Patterns",
    "abstract": "Acoustic side-channel attacks on keyboards can bypass security measures in many systems that use keyboards as one of the input devices. These attacks aim to reveal users' sensitive information by targeting the sounds made by their keyboards as they type. Most existing approaches in this field ignore the negative impacts of typing patterns and environmental noise in their results. This paper seeks to address these shortcomings by proposing an applicable method that takes into account the user's typing pattern in a realistic environment. Our method achieved an average success rate of 43% across all our case studies when considering real-world scenarios. ",
    "url": "https://arxiv.org/abs/2403.08740",
    "authors": [
      "Alireza Taheritajar",
      "Reza Rahaeimehr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.08748",
    "title": "Real-time 3D semantic occupancy prediction for autonomous vehicles using  memory-efficient sparse convolution",
    "abstract": "In autonomous vehicles, understanding the surrounding 3D environment of the ego vehicle in real-time is essential. A compact way to represent scenes while encoding geometric distances and semantic object information is via 3D semantic occupancy maps. State of the art 3D mapping methods leverage transformers with cross-attention mechanisms to elevate 2D vision-centric camera features into the 3D domain. However, these methods encounter significant challenges in real-time applications due to their high computational demands during inference. This limitation is particularly problematic in autonomous vehicles, where GPU resources must be shared with other tasks such as localization and planning. In this paper, we introduce an approach that extracts features from front-view 2D camera images and LiDAR scans, then employs a sparse convolution network (Minkowski Engine), for 3D semantic occupancy prediction. Given that outdoor scenes in autonomous driving scenarios are inherently sparse, the utilization of sparse convolution is particularly apt. By jointly solving the problems of 3D scene completion of sparse scenes and 3D semantic segmentation, we provide a more efficient learning framework suitable for real-time applications in autonomous vehicles. We also demonstrate competitive accuracy on the nuScenes dataset. ",
    "url": "https://arxiv.org/abs/2403.08748",
    "authors": [
      "Samuel Sze",
      "Lars Kunze"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08760",
    "title": "MIM4D: Masked Modeling with Multi-View Video for Autonomous Driving  Representation Learning",
    "abstract": "Learning robust and scalable visual representations from massive multi-view video data remains a challenge in computer vision and autonomous driving. Existing pre-training methods either rely on expensive supervised learning with 3D annotations, limiting the scalability, or focus on single-frame or monocular inputs, neglecting the temporal information. We propose MIM4D, a novel pre-training paradigm based on dual masked image modeling (MIM). MIM4D leverages both spatial and temporal relations by training on masked multi-view video inputs. It constructs pseudo-3D features using continuous scene flow and projects them onto 2D plane for supervision. To address the lack of dense 3D supervision, MIM4D reconstruct pixels by employing 3D volumetric differentiable rendering to learn geometric representations. We demonstrate that MIM4D achieves state-of-the-art performance on the nuScenes dataset for visual representation learning in autonomous driving. It significantly improves existing methods on multiple downstream tasks, including BEV segmentation (8.7% IoU), 3D object detection (3.5% mAP), and HD map construction (1.4% mAP). Our work offers a new choice for learning representation at scale in autonomous driving. Code and models are released at https://github.com/hustvl/MIM4D ",
    "url": "https://arxiv.org/abs/2403.08760",
    "authors": [
      "Jialv Zou",
      "Bencheng Liao",
      "Qian Zhang",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08766",
    "title": "MonoOcc: Digging into Monocular Semantic Occupancy Prediction",
    "abstract": "Monocular Semantic Occupancy Prediction aims to infer the complete 3D geometry and semantic information of scenes from only 2D images. It has garnered significant attention, particularly due to its potential to enhance the 3D perception of autonomous vehicles. However, existing methods rely on a complex cascaded framework with relatively limited information to restore 3D scenes, including a dependency on supervision solely on the whole network's output, single-frame input, and the utilization of a small backbone. These challenges, in turn, hinder the optimization of the framework and yield inferior prediction results, particularly concerning smaller and long-tailed objects. To address these issues, we propose MonoOcc. In particular, we (i) improve the monocular occupancy prediction framework by proposing an auxiliary semantic loss as supervision to the shallow layers of the framework and an image-conditioned cross-attention module to refine voxel features with visual clues, and (ii) employ a distillation module that transfers temporal information and richer knowledge from a larger image backbone to the monocular semantic occupancy prediction framework with low cost of hardware. With these advantages, our method yields state-of-the-art performance on the camera-based SemanticKITTI Scene Completion benchmark. Codes and models can be accessed at https://github.com/ucaszyp/MonoOcc ",
    "url": "https://arxiv.org/abs/2403.08766",
    "authors": [
      "Yupeng Zheng",
      "Xiang Li",
      "Pengfei Li",
      "Yuhang Zheng",
      "Bu Jin",
      "Chengliang Zhong",
      "Xiaoxiao Long",
      "Hao Zhao",
      "Qichao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08770",
    "title": "FastMAC: Stochastic Spectral Sampling of Correspondence Graph",
    "abstract": "3D correspondence, i.e., a pair of 3D points, is a fundamental concept in computer vision. A set of 3D correspondences, when equipped with compatibility edges, forms a correspondence graph. This graph is a critical component in several state-of-the-art 3D point cloud registration approaches, e.g., the one based on maximal cliques (MAC). However, its properties have not been well understood. So we present the first study that introduces graph signal processing into the domain of correspondence graph. We exploit the generalized degree signal on correspondence graph and pursue sampling strategies that preserve high-frequency components of this signal. To address time-consuming singular value decomposition in deterministic sampling, we resort to a stochastic approximate sampling strategy. As such, the core of our method is the stochastic spectral sampling of correspondence graph. As an application, we build a complete 3D registration algorithm termed as FastMAC, that reaches real-time speed while leading to little to none performance drop. Through extensive experiments, we validate that FastMAC works for both indoor and outdoor benchmarks. For example, FastMAC can accelerate MAC by 80 times while maintaining high registration success rate on KITTI. Codes are publicly available at https://github.com/Forrest-110/FastMAC. ",
    "url": "https://arxiv.org/abs/2403.08770",
    "authors": [
      "Yifei Zhang",
      "Hao Zhao",
      "Hongyang Li",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.07881",
    "title": "Epidemic modelling requires knowledge of the social network",
    "abstract": "Compartmental models of epidemics are widely used to forecast the effects of communicable diseases such as COVID-19 and to guide policy. Although it has long been known that such processes take place on social networks, the assumption of random mixing is usually made, which ignores network structure. However, super-spreading events have been found to be power-law distributed, suggesting that the underlying networks may be scale free or at least highly heterogeneous. The random-mixing assumption would then produce an overestimation of the herd-immunity threshold for given $R_0$; and a (more significant) overestimation of $R_0$ itself. These two errors compound each other, and can lead to forecasts greatly overestimating the number of infections. Moreover, if networks are heterogeneous and change in time, multiple waves of infection can occur, which are not predicted by random mixing. A simple SIR model simulated on both Erd\\H{o}s-R\\'enyi and scale-free networks shows that details of the network structure can be more important than the intrinsic transmissibility of a disease. It is therefore crucial to incorporate network information into standard models of epidemics. ",
    "url": "https://arxiv.org/abs/2403.07881",
    "authors": [
      "Samuel Johnson"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2403.07892",
    "title": "Change Point Detection with Copula Entropy based Two-Sample Test",
    "abstract": "Change point detection is a typical task that aim to find changes in time series and can be tackled with two-sample test. Copula Entropy is a mathematical concept for measuring statistical independence and a two-sample test based on it was introduced recently. In this paper we propose a nonparametric multivariate method for multiple change point detection with the copula entropy-based two-sample test. The single change point detection is first proposed as a group of two-sample tests on every points of time series data and the change point is considered as with the maximum of the test statistics. The multiple change point detection is then proposed by combining the single change point detection method with binary segmentation strategy. We verified the effectiveness of our method and compared it with the other similar methods on the simulated univariate and multivariate data and the Nile data. ",
    "url": "https://arxiv.org/abs/2403.07892",
    "authors": [
      "Jian Ma"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07926",
    "title": "Value Prediction for Spatiotemporal Gait Data Using Deep Learning",
    "abstract": "Human gait has been commonly used for the diagnosis and evaluation of medical conditions and for monitoring the progress during treatment and rehabilitation. The use of wearable sensors that capture pressure or motion has yielded techniques that analyze the gait data to aid recovery, identify activity performed, or identify individuals. Deep learning, usually employing classification, has been successfully utilized in a variety of applications such as computer vision, biomedical imaging analysis, and natural language processing. We expand the application of deep learning to value prediction of time-series of spatiotemporal gait data. Moreover, we explore several deep learning architectures (Recurrent Neural Networks (RNN) and RNN combined with Convolutional Neural Networks (CNN)) to make short- and long-distance predictions using two different experimental setups. Our results show that short-distance prediction has an RMSE as low as 0.060675, and long-distance prediction RMSE as low as 0.106365. Additionally, the results show that the proposed deep learning models are capable of predicting the entire trial when trained and validated using the trials from the same participant. The proposed, customized models, used with value prediction open possibilities for additional applications, such as fall prediction, in-home progress monitoring, aiding of exoskeleton movement, and authentication. ",
    "url": "https://arxiv.org/abs/2403.07926",
    "authors": [
      "Ryan Cavanagh",
      "Jelena Trajkovic",
      "Wenlu Zhang",
      "I-Hung Khoo",
      "Vennila Krishnan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07937",
    "title": "Speech Robust Bench: A Robustness Benchmark For Speech Recognition",
    "abstract": "As Automatic Speech Recognition (ASR) models become ever more pervasive, it is important to ensure that they make reliable predictions under corruptions present in the physical and digital world. We propose Speech Robust Bench (SRB), a comprehensive benchmark for evaluating the robustness of ASR models to diverse corruptions. SRB is composed of 69 input perturbations which are intended to simulate various corruptions that ASR models may encounter in the physical and digital world. We use SRB to evaluate the robustness of several state-of-the-art ASR models and observe that model size and certain modeling choices such as discrete representations, and self-training appear to be conducive to robustness. We extend this analysis to measure the robustness of ASR models on data from various demographic subgroups, namely English and Spanish speakers, and males and females, and observed noticeable disparities in the model's robustness across subgroups. We believe that SRB will facilitate future research towards robust ASR models, by making it easier to conduct comprehensive and comparable robustness evaluations. ",
    "url": "https://arxiv.org/abs/2403.07937",
    "authors": [
      "Muhammad A. Shah",
      "David Solans Noguero",
      "Mikko A. Heikkila",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2403.07940",
    "title": "Hair and scalp disease detection using deep learning",
    "abstract": "In recent years, there has been a notable advancement in the integration of healthcare and technology, particularly evident in the field of medical image analysis. This paper introduces a pioneering approach in dermatology, presenting a robust method for the detection of hair and scalp diseases using state-of-the-art deep learning techniques. Our methodology relies on Convolutional Neural Networks (CNNs), well-known for their efficacy in image recognition, to meticulously analyze images for various dermatological conditions affecting the hair and scalp. Our proposed system represents a significant advancement in dermatological diagnostics, offering a non-invasive and highly efficient means of early detection and diagnosis. By leveraging the capabilities of CNNs, our model holds the potential to revolutionize dermatology, providing accessible and timely healthcare solutions. Furthermore, the seamless integration of our trained model into a web-based platform developed with the Django framework ensures broad accessibility and usability, democratizing advanced medical diagnostics. The integration of machine learning algorithms into web applications marks a pivotal moment in healthcare delivery, promising empowerment for both healthcare providers and patients. Through the synergy between technology and healthcare, our paper outlines the meticulous methodology, technical intricacies, and promising future prospects of our system. With a steadfast commitment to advancing healthcare frontiers, our goal is to significantly contribute to leveraging technology for improved healthcare outcomes globally. This endeavor underscores the profound impact of technological innovation in shaping the future of healthcare delivery and patient care, highlighting the transformative potential of our approach. ",
    "url": "https://arxiv.org/abs/2403.07940",
    "authors": [
      "Kavita Sultanpure",
      "Bhairavi Shirsath",
      "Bhakti Bhande",
      "Harshada Sawai",
      "Srushti Gawade",
      "Suraj Samgir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08016",
    "title": "Aedes aegypti Egg Counting with Neural Networks for Object Detection",
    "abstract": "Aedes aegypti is still one of the main concerns when it comes to disease vectors. Among the many ways to deal with it, there are important protocols that make use of egg numbers in ovitraps to calculate indices, such as the LIRAa and the Breteau Index, which can provide information on predictable outbursts and epidemics. Also, there are many research lines that require egg numbers, specially when mass production of mosquitoes is needed. Egg counting is a laborious and error-prone task that can be automated via computer vision-based techniques, specially deep learning-based counting with object detection. In this work, we propose a new dataset comprising field and laboratory eggs, along with test results of three neural networks applied to the task: Faster R-CNN, Side-Aware Boundary Localization and FoveaBox. ",
    "url": "https://arxiv.org/abs/2403.08016",
    "authors": [
      "Micheli Nayara de Oliveira Vicente",
      "Gabriel Toshio Hirokawa Higa",
      "Jo\u00e3o Vitor de Andrade Porto",
      "Higor Henrique",
      "Picoli Nucci",
      "Asser Botelho Santana",
      "Karla Rejane de Andrade Porto",
      "Antonia Railda Roel",
      "Hemerson Pistori"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08023",
    "title": "51% Attack via Difficulty Increase with a Small Quantum Miner",
    "abstract": "We present a strategy for a single quantum miner with relatively low hashing power, with the same ramifications as a 51% attack. Bitcoin nodes consider the chain with the highest cumulative proof-of-work to be the valid chain. A quantum miner can manipulate the block timestamps to multiply the difficulty by $c$. The fork-choice rule counts every block with increased difficulty with weight $c$. By using Grover's algorithm, it is only $O(\\sqrt c)$ harder for the quantum miner to mine such blocks. By picking a high enough $c$, the single quantum miner can create a competing chain with fewer blocks, but more cumulative proof-of-work. The time required is $O(\\frac{1}{r^2})$ epochs, where $r$ is the fraction of the block rewards that the quantum miner would have received if they mined honestly. Most proof-of-work cryptocurrencies, including Bitcoin, are vulnerable to our attack. However, it will likely be impossible to execute in forthcoming years, as it requires an extremely fast and fault-tolerant quantum computer. ",
    "url": "https://arxiv.org/abs/2403.08023",
    "authors": [
      "Bolton Bailey",
      "Or Sattath"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.08280",
    "title": "Pre-examinations Improve Automated Metastases Detection on Cranial MRI",
    "abstract": "Materials and methods: First, a dual-time approach was assessed, for which the CNN was provided sequences of the MRI that initially depicted new MM (diagnosis MRI) as well as of a prediagnosis MRI: inclusion of only contrast-enhanced T1-weighted images (CNNdual_ce) was compared with inclusion of also the native T1-weighted images, T2-weighted images, and FLAIR sequences of both time points (CNNdual_all).Second, results were compared with the corresponding single time approaches, in which the CNN was provided exclusively the respective sequences of the diagnosis MRI.Casewise diagnostic performance parameters were calculated from 5-fold cross-validation. Results: In total, 94 cases with 494 MMs were included. Overall, the highest diagnostic performance was achieved by inclusion of only the contrast-enhanced T1-weighted images of the diagnosis and of a prediagnosis MRI (CNNdual_ce, sensitivity = 73%, PPV = 25%, F1-score = 36%). Using exclusively contrast-enhanced T1-weighted images as input resulted in significantly less false-positives (FPs) compared with inclusion of further sequences beyond contrast-enhanced T1-weighted images (FPs = 5/7 for CNNdual_ce/CNNdual_all, P < 1e-5). Comparison of contrast-enhanced dual and mono time approaches revealed that exclusion of prediagnosis MRI significantly increased FPs (FPs = 5/10 for CNNdual_ce/CNNce, P < 1e-9).Approaches with only native sequences were clearly inferior to CNNs that were provided contrast-enhanced sequences. Conclusions: Automated MM detection on contrast-enhanced T1-weighted images performed with high sensitivity. Frequent FPs due to artifacts and vessels were significantly reduced by additional inclusion of prediagnosis MRI, but not by inclusion of further sequences beyond contrast-enhanced T1-weighted images. Future studies might investigate different change detection architectures for computer-aided detection. ",
    "url": "https://arxiv.org/abs/2403.08280",
    "authors": [
      "Katerina Deike-Hofmann",
      "Dorottya Dancs",
      "Daniel Paech",
      "Heinz-Peter Schlemmer",
      "Klaus Maier-Hein",
      "Philipp B\u00e4umer",
      "Alexander Radbruch",
      "Michael G\u00f6tz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2403.08464",
    "title": "Diffusion Models with Implicit Guidance for Medical Anomaly Detection",
    "abstract": "Diffusion models have advanced unsupervised anomaly detection by improving the transformation of pathological images into pseudo-healthy equivalents. Nonetheless, standard approaches may compromise critical information during pathology removal, leading to restorations that do not align with unaffected regions in the original scans. Such discrepancies can inadvertently increase false positive rates and reduce specificity, complicating radiological evaluations. This paper introduces Temporal Harmonization for Optimal Restoration (THOR), which refines the de-noising process by integrating implicit guidance through temporal anomaly maps. THOR aims to preserve the integrity of healthy tissue in areas unaffected by pathology. Comparative evaluations show that THOR surpasses existing diffusion-based methods in detecting and segmenting anomalies in brain MRIs and wrist X-rays. Code: https://github.com/ci-ber/THOR_DDPM. ",
    "url": "https://arxiv.org/abs/2403.08464",
    "authors": [
      "Cosmin I. Bercea",
      "Benedikt Wiestler",
      "Daniel Rueckert",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08479",
    "title": "MD-Dose: A Diffusion Model based on the Mamba for Radiotherapy Dose  Prediction",
    "abstract": "Radiation therapy is crucial in cancer treatment. Experienced experts typically iteratively generate high-quality dose distribution maps, forming the basis for excellent radiation therapy plans. Therefore, automated prediction of dose distribution maps is significant in expediting the treatment process and providing a better starting point for developing radiation therapy plans. With the remarkable results of diffusion models in predicting high-frequency regions of dose distribution maps, dose prediction methods based on diffusion models have been extensively studied. However, existing methods mainly utilize CNNs or Transformers as denoising networks. CNNs lack the capture of global receptive fields, resulting in suboptimal prediction performance. Transformers excel in global modeling but face quadratic complexity with image size, resulting in significant computational overhead. To tackle these challenges, we introduce a novel diffusion model, MD-Dose, based on the Mamba architecture for predicting radiation therapy dose distribution in thoracic cancer patients. In the forward process, MD-Dose adds Gaussian noise to dose distribution maps to obtain pure noise images. In the backward process, MD-Dose utilizes a noise predictor based on the Mamba to predict the noise, ultimately outputting the dose distribution maps. Furthermore, We develop a Mamba encoder to extract structural information and integrate it into the noise predictor for localizing dose regions in the planning target volume (PTV) and organs at risk (OARs). Through extensive experiments on a dataset of 300 thoracic tumor patients, we showcase the superiority of MD-Dose in various metrics and time consumption. ",
    "url": "https://arxiv.org/abs/2403.08479",
    "authors": [
      "Linjie Fu",
      "Xia Li",
      "Xiuding Cai",
      "Yingkai Wang",
      "Xueyao Wang",
      "Yali Shen",
      "Yu Yao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2403.08551",
    "title": "GaussianImage: 1000 FPS Image Representation and Compression by 2D  Gaussian Splatting",
    "abstract": "Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3$\\times$ lower GPU memory usage and 5$\\times$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. Furthermore, we integrate existing vector quantization technique to build an image codec. Experimental results demonstrate that our codec attains rate-distortion performance comparable to compression-based INRs such as COIN and COIN++, while facilitating decoding speeds of approximately 1000 FPS. Additionally, preliminary proof of concept shows that our codec surpasses COIN and COIN++ in performance when using partial bits-back coding. ",
    "url": "https://arxiv.org/abs/2403.08551",
    "authors": [
      "Xinjie Zhang",
      "Xingtong Ge",
      "Tongda Xu",
      "Dailan He",
      "Yan Wang",
      "Hongwei Qin",
      "Guo Lu",
      "Jing Geng",
      "Jun Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.08566",
    "title": "A Novel Implicit Neural Representation for Volume Data",
    "abstract": "The storage of medical images is one of the challenges in the medical imaging field. There are variable works that use implicit neural representation (INR) to compress volumetric medical images. However, there is room to improve the compression rate for volumetric medical images. Most of the INR techniques need a huge amount of GPU memory and a long training time for high-quality medical volume rendering. In this paper, we present a novel implicit neural representation to compress volume data using our proposed architecture, that is, the Lanczos downsampling scheme, SIREN deep network, and SRDenseNet high-resolution scheme. Our architecture can effectively reduce training time, and gain a high compression rate while retaining the final rendering quality. Moreover, it can save GPU memory in comparison with the existing works. The experiments show that the quality of reconstructed images and training speed using our architecture is higher than current works which use the SIREN only. Besides, the GPU memory cost is evidently decreased ",
    "url": "https://arxiv.org/abs/2403.08566",
    "authors": [
      "Armin Sheibanifard",
      "Hongchuan Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08662",
    "title": "Self-Supervised Learning for Covariance Estimation",
    "abstract": "We consider the use of deep learning for covariance estimation. We propose to globally learn a neural network that will then be applied locally at inference time. Leveraging recent advancements in self-supervised foundational models, we train the network without any labeling by simply masking different samples and learning to predict their covariance given their surrounding neighbors. The architecture is based on the popular attention mechanism. Its main advantage over classical methods is the automatic exploitation of global characteristics without any distributional assumptions or regularization. It can be pre-trained as a foundation model and then be repurposed for various downstream tasks, e.g., adaptive target detection in radar or hyperspectral imagery. ",
    "url": "https://arxiv.org/abs/2403.08662",
    "authors": [
      "Tzvi Diskin",
      "Ami Wiesel"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08689",
    "title": "Exploiting Structural Consistency of Chest Anatomy for Unsupervised  Anomaly Detection in Radiography Images",
    "abstract": "Radiography imaging protocols focus on particular body regions, therefore producing images of great similarity and yielding recurrent anatomical structures across patients. Exploiting this structured information could potentially ease the detection of anomalies from radiography images. To this end, we propose a Simple Space-Aware Memory Matrix for In-painting and Detecting anomalies from radiography images (abbreviated as SimSID). We formulate anomaly detection as an image reconstruction task, consisting of a space-aware memory matrix and an in-painting block in the feature space. During the training, SimSID can taxonomize the ingrained anatomical structures into recurrent visual patterns, and in the inference, it can identify anomalies (unseen/modified visual patterns) from the test image. Our SimSID surpasses the state of the arts in unsupervised anomaly detection by +8.0%, +5.0%, and +9.9% AUC scores on ZhangLab, COVIDx, and CheXpert benchmark datasets, respectively. Code: https://github.com/MrGiovanni/SimSID ",
    "url": "https://arxiv.org/abs/2403.08689",
    "authors": [
      "Tiange Xiang",
      "Yixiao Zhang",
      "Yongyi Lu",
      "Alan Yuille",
      "Chaoyi Zhang",
      "Weidong Cai",
      "Zongwei Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08750",
    "title": "Neural reproducing kernel Banach spaces and representer theorems for  deep networks",
    "abstract": "Studying the function spaces defined by neural networks helps to understand the corresponding learning models and their inductive bias. While in some limits neural networks correspond to function spaces that are reproducing kernel Hilbert spaces, these regimes do not capture the properties of the networks used in practice. In contrast, in this paper we show that deep neural networks define suitable reproducing kernel Banach spaces. These spaces are equipped with norms that enforce a form of sparsity, enabling them to adapt to potential latent structures within the input data and their representations. In particular, leveraging the theory of reproducing kernel Banach spaces, combined with variational results, we derive representer theorems that justify the finite architectures commonly employed in applications. Our study extends analogous results for shallow networks and can be seen as a step towards considering more practically plausible neural architectures. ",
    "url": "https://arxiv.org/abs/2403.08750",
    "authors": [
      "Francesca Bartolucci",
      "Ernesto De Vito",
      "Lorenzo Rosasco",
      "Stefano Vigogna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2201.02323",
    "title": "Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks",
    "abstract": " Title: Distributed Nash Equilibrium Seeking over Time-Varying Directed  Communication Networks ",
    "url": "https://arxiv.org/abs/2201.02323",
    "authors": [
      "Duong Thuy Anh Nguyen",
      "Duong Tung Nguyen",
      "Angelia Nedi\u0107"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2203.02115",
    "title": "Towards Benchmarking and Evaluating Deepfake Detection",
    "abstract": " Title: Towards Benchmarking and Evaluating Deepfake Detection ",
    "url": "https://arxiv.org/abs/2203.02115",
    "authors": [
      "Chenhao Lin",
      "Jingyi Deng",
      "Pengbin Hu",
      "Chao Shen",
      "Qian Wang",
      "Qi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.11537",
    "title": "Convolutional Neural Network-based Efficient Dense Point Cloud  Generation using Unsigned Distance Fields",
    "abstract": " Title: Convolutional Neural Network-based Efficient Dense Point Cloud  Generation using Unsigned Distance Fields ",
    "url": "https://arxiv.org/abs/2203.11537",
    "authors": [
      "Abol Basher",
      "Jani Boutellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.06388",
    "title": "TSFool: Crafting Highly-Imperceptible Adversarial Time Series through  Multi-Objective Attack",
    "abstract": " Comments: 22 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2209.06388",
    "authors": [
      "Yanyun Wang",
      "Dehui Du",
      "Haibo Hu",
      "Zi Liang",
      "Yuanhao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.10164",
    "title": "Lowering Detection in Sport Climbing Based on Orientation of the Sensor  Enhanced Quickdraw",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2211.02680 ",
    "url": "https://arxiv.org/abs/2301.10164",
    "authors": [
      "Sadaf Moaveninejad",
      "Andrea Janes",
      "Camillo Porcaro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.02926",
    "title": "Curriculum Graph Machine Learning: A Survey",
    "abstract": " Comments: IJCAI 2023 Survey Track ",
    "url": "https://arxiv.org/abs/2302.02926",
    "authors": [
      "Haoyang Li",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06670",
    "title": "Explainable Anomaly Detection in Images and Videos: A Survey",
    "abstract": " Comments: Submitted to TPAMI ",
    "url": "https://arxiv.org/abs/2302.06670",
    "authors": [
      "Yizhou Wang",
      "Dongliang Guo",
      "Sheng Li",
      "Octavia Camps",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.08913",
    "title": "Referential communication in heterogeneous communities of pre-trained  visual deep networks",
    "abstract": " Title: Referential communication in heterogeneous communities of pre-trained  visual deep networks ",
    "url": "https://arxiv.org/abs/2302.08913",
    "authors": [
      "Mat\u00e9o Mahaut",
      "Francesca Franzon",
      "Roberto Dess\u00ec",
      "Marco Baroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09195",
    "title": "Data-Efficient Contrastive Self-supervised Learning: Most Beneficial  Examples for Supervised Learning Contribute the Least",
    "abstract": " Comments: Accepted to ICML 2023, Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.09195",
    "authors": [
      "Siddharth Joshi",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.14615",
    "title": "Randomized Kaczmarz in Adversarial Distributed Setting",
    "abstract": " Title: Randomized Kaczmarz in Adversarial Distributed Setting ",
    "url": "https://arxiv.org/abs/2302.14615",
    "authors": [
      "Longxiu Huang",
      "Xia Li",
      "Deanna Needell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.15027",
    "title": "A Survey on Causal Discovery Methods for I.I.D. and Time Series Data",
    "abstract": " Comments: Published (05 Sept 2023) in Transactions on Machine Learning Research (TMLR) ",
    "url": "https://arxiv.org/abs/2303.15027",
    "authors": [
      "Uzma Hasan",
      "Emam Hossain",
      "Md Osman Gani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16521",
    "title": "Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation",
    "abstract": " Title: Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation ",
    "url": "https://arxiv.org/abs/2303.16521",
    "authors": [
      "Louis Mahon",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12333",
    "title": "GRACE: Loss-Resilient Real-Time Video through Neural Codecs",
    "abstract": " Title: GRACE: Loss-Resilient Real-Time Video through Neural Codecs ",
    "url": "https://arxiv.org/abs/2305.12333",
    "authors": [
      "Yihua Cheng",
      "Ziyi Zhang",
      "Hanchen Li",
      "Anton Arapin",
      "Yue Zhang",
      "Qizheng Zhang",
      "Yuhan Liu",
      "Xu Zhang",
      "Francis Y. Yan",
      "Amrita Mazumdar",
      "Nick Feamster",
      "Junchen Jiang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.14336",
    "title": "Schema-Driven Information Extraction from Heterogeneous Tables",
    "abstract": " Title: Schema-Driven Information Extraction from Heterogeneous Tables ",
    "url": "https://arxiv.org/abs/2305.14336",
    "authors": [
      "Fan Bai",
      "Junmo Kang",
      "Gabriel Stanovsky",
      "Dayne Freitag",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.00010",
    "title": "Trainable and Explainable Simplicial Map Neural Networks",
    "abstract": " Title: Trainable and Explainable Simplicial Map Neural Networks ",
    "url": "https://arxiv.org/abs/2306.00010",
    "authors": [
      "Eduardo Paluzo-Hidalgo",
      "Miguel A. Guti\u00e9rrez-Naranjo",
      "Rocio Gonzalez-Diaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2306.02194",
    "title": "PathFinder: A unified approach for handling paths in graph query  languages",
    "abstract": " Title: PathFinder: A unified approach for handling paths in graph query  languages ",
    "url": "https://arxiv.org/abs/2306.02194",
    "authors": [
      "Benjam\u00edn Far\u00edas",
      "Wim Martens",
      "Carlos Rojas",
      "Domagoj Vrgo\u010d"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2306.05093",
    "title": "Investigating the Effect of Misalignment on Membership Privacy in the  White-box Setting",
    "abstract": " Comments: To appear in the Proceedings on Privacy Enhancing Technologies (PoPETs 2024) ",
    "url": "https://arxiv.org/abs/2306.05093",
    "authors": [
      "Ana-Maria Cretu",
      "Daniel Jones",
      "Yves-Alexandre de Montjoye",
      "Shruti Tople"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.08852",
    "title": "BED: Bi-Encoder-Based Detectors for Out-of-Distribution Detection",
    "abstract": " Comments: Published in IEEE: this https URL ",
    "url": "https://arxiv.org/abs/2306.08852",
    "authors": [
      "Louis Owen",
      "Biddwan Ahmed",
      "Abhay Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.14306",
    "title": "Adaptive Sharpness-Aware Pruning for Robust Sparse Networks",
    "abstract": " Title: Adaptive Sharpness-Aware Pruning for Robust Sparse Networks ",
    "url": "https://arxiv.org/abs/2306.14306",
    "authors": [
      "Anna Bair",
      "Hongxu Yin",
      "Maying Shen",
      "Pavlo Molchanov",
      "Jose Alvarez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16175",
    "title": "$\\mathbf{C}^2$Former: Calibrated and Complementary Transformer for  RGB-Infrared Object Detection",
    "abstract": " Title: $\\mathbf{C}^2$Former: Calibrated and Complementary Transformer for  RGB-Infrared Object Detection ",
    "url": "https://arxiv.org/abs/2306.16175",
    "authors": [
      "Maoxun Yuan",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.13510",
    "title": "HeightFormer: Explicit Height Modeling without Extra Data for  Camera-only 3D Object Detection in Bird's Eye View",
    "abstract": " Title: HeightFormer: Explicit Height Modeling without Extra Data for  Camera-only 3D Object Detection in Bird's Eye View ",
    "url": "https://arxiv.org/abs/2307.13510",
    "authors": [
      "Yiming Wu",
      "Ruixiang Li",
      "Zequn Qin",
      "Xinhai Zhao",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02535",
    "title": "Learning to Generate Training Datasets for Robust Semantic Segmentation",
    "abstract": " Comments: Published as a conference paper at WACV 2024 ",
    "url": "https://arxiv.org/abs/2308.02535",
    "authors": [
      "Marwane Hariat",
      "Olivier Laurent",
      "R\u00e9mi Kazmierczak",
      "Shihao Zhang",
      "Andrei Bursuc",
      "Angela Yao",
      "Gianni Franchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.09945",
    "title": "Dual Branch Deep Learning Network for Detection and Stage Grading of  Diabetic Retinopathy",
    "abstract": " Comments: Published in the Biomedical Signal Processing & Control journal, 16 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2308.09945",
    "authors": [
      "Hossein Shakibania",
      "Sina Raoufi",
      "Behnam Pourafkham",
      "Hassan Khotanlou",
      "Muharram Mansoorizadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11767",
    "title": "Detection of ChatGPT Fake Science with the xFakeSci Learning Algorithm",
    "abstract": " Comments: 14 pages, 6 figures, 6 tables, 5 algorithms ",
    "url": "https://arxiv.org/abs/2308.11767",
    "authors": [
      "Ahmed Abdeen Hamed",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.13658",
    "title": "Generating and Explaining Corner Cases Using Learnt Probabilistic Lane  Graphs",
    "abstract": " Comments: 8 Pages, 3 Figures, 1 Table, Published in the Proceedings of the 26th IEEE International Conference on Intelligent Transport Systems (2023), Final submission version with added IEEE copyright notice ",
    "url": "https://arxiv.org/abs/2308.13658",
    "authors": [
      "Enrik Maci",
      "Rhys Howard",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.15992",
    "title": "AI-powered Fraud Detection in Decentralized Finance: A Project Life  Cycle Perspective",
    "abstract": " Comments: 38 pages, update references ",
    "url": "https://arxiv.org/abs/2308.15992",
    "authors": [
      "Bingqiao Luo",
      "Zhen Zhang",
      "Qian Wang",
      "Anli Ke",
      "Shengliang Lu",
      "Bingsheng He"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.16207",
    "title": "MASA-TCN: Multi-anchor Space-aware Temporal Convolutional Neural  Networks for Continuous and Discrete EEG Emotion Recognition",
    "abstract": " Comments: 12 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2308.16207",
    "authors": [
      "Yi Ding",
      "Su Zhang",
      "Chuangao Tang",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11676",
    "title": "Cardinality and Representation of Stone Relation Algebras",
    "abstract": " Comments: added explanations ",
    "url": "https://arxiv.org/abs/2309.11676",
    "authors": [
      "Hitoshi Furusawa",
      "Walter Guttmann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2309.15030",
    "title": "Quadratic Detection in Noncoherent Massive SIMO Systems over Correlated  Channels",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2309.15030",
    "authors": [
      "Marc Vil\u00e0-Insa",
      "Aniol Mart\u00ed",
      "Jaume Riba",
      "Meritxell Lamarca"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.15048",
    "title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction",
    "abstract": " Title: Class Incremental Learning via Likelihood Ratio Based Task Prediction ",
    "url": "https://arxiv.org/abs/2309.15048",
    "authors": [
      "Haowei Lin",
      "Yijia Shao",
      "Weinan Qian",
      "Ningxin Pan",
      "Yiduo Guo",
      "Bing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16456",
    "title": "Resisting Backdoor Attacks in Federated Learning via Bidirectional  Elections and Individual Perspective",
    "abstract": " Comments: Accepted by AAAI 2024. Codes are publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2309.16456",
    "authors": [
      "Zhen Qin",
      "Feiyi Chen",
      "Chen Zhi",
      "Xueqiang Yan",
      "Shuiguang Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00116",
    "title": "Certified Robustness via Dynamic Margin Maximization and Improved  Lipschitz Regularization",
    "abstract": " Comments: 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2310.00116",
    "authors": [
      "Mahyar Fazlyab",
      "Taha Entesari",
      "Aniket Roy",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01188",
    "title": "Quantifying the Plausibility of Context Reliance in Neural Machine  Translation",
    "abstract": " Comments: ICLR 2024 Camera Ready. Code: this https URL Artifacts: this https URL ",
    "url": "https://arxiv.org/abs/2310.01188",
    "authors": [
      "Gabriele Sarti",
      "Grzegorz Chrupa\u0142a",
      "Malvina Nissim",
      "Arianna Bisazza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04475",
    "title": "Demystifying Embedding Spaces using Large Language Models",
    "abstract": " Comments: Accepted to ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.04475",
    "authors": [
      "Guy Tennenholtz",
      "Yinlam Chow",
      "Chih-Wei Hsu",
      "Jihwan Jeong",
      "Lior Shani",
      "Azamat Tulepbergenov",
      "Deepak Ramachandran",
      "Martin Mladenov",
      "Craig Boutilier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06169",
    "title": "Synthesizing Robust Walking Gaits via Discrete-Time Barrier Functions  with Application to Multi-Contact Exoskeleton Locomotion",
    "abstract": " Title: Synthesizing Robust Walking Gaits via Discrete-Time Barrier Functions  with Application to Multi-Contact Exoskeleton Locomotion ",
    "url": "https://arxiv.org/abs/2310.06169",
    "authors": [
      "Maegan Tucker",
      "Kejun Li",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.07449",
    "title": "PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction",
    "abstract": " Comments: Accepted to ICLR 2024. Find the project page at this https URL ",
    "url": "https://arxiv.org/abs/2310.07449",
    "authors": [
      "Jia-Wang Bian",
      "Wenjing Bian",
      "Victor Adrian Prisacariu",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07793",
    "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph",
    "abstract": " Comments: 14 pages, Findings of NAACL 2024 ",
    "url": "https://arxiv.org/abs/2310.07793",
    "authors": [
      "Ruotong Liao",
      "Xu Jia",
      "Yunpu Ma",
      "Yangzhe Li",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08750",
    "title": "Search-Adaptor: Embedding Customization for Information Retrieval",
    "abstract": " Title: Search-Adaptor: Embedding Customization for Information Retrieval ",
    "url": "https://arxiv.org/abs/2310.08750",
    "authors": [
      "Jinsung Yoon",
      "Sercan O Arik",
      "Yanfei Chen",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.11762",
    "title": "A Quasi-Wasserstein Loss for Learning Graph Neural Networks",
    "abstract": " Title: A Quasi-Wasserstein Loss for Learning Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2310.11762",
    "authors": [
      "Minjie Cheng",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07042",
    "title": "Open-Vocabulary Video Anomaly Detection",
    "abstract": " Comments: Accepted to CVPR2024 ",
    "url": "https://arxiv.org/abs/2311.07042",
    "authors": [
      "Peng Wu",
      "Xuerong Zhou",
      "Guansong Pang",
      "Yujia Sun",
      "Jing Liu",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10747",
    "title": "Safety-aware Causal Representation for Trustworthy Offline Reinforcement  Learning in Autonomous Driving",
    "abstract": " Title: Safety-aware Causal Representation for Trustworthy Offline Reinforcement  Learning in Autonomous Driving ",
    "url": "https://arxiv.org/abs/2311.10747",
    "authors": [
      "Haohong Lin",
      "Wenhao Ding",
      "Zuxin Liu",
      "Yaru Niu",
      "Jiacheng Zhu",
      "Yuming Niu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11646",
    "title": "Toward Open Vocabulary Aerial Object Detection with CLIP-Activated  Student-Teacher Learning",
    "abstract": " Title: Toward Open Vocabulary Aerial Object Detection with CLIP-Activated  Student-Teacher Learning ",
    "url": "https://arxiv.org/abs/2311.11646",
    "authors": [
      "Yan Li",
      "Weiwei Guo",
      "Xue Yang",
      "Ning Liao",
      "Dunyun He",
      "Jiaqi Zhou",
      "Wenxian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16496",
    "title": "DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection",
    "abstract": " Title: DPOD: Domain-Specific Prompt Tuning for Multimodal Fake News Detection ",
    "url": "https://arxiv.org/abs/2311.16496",
    "authors": [
      "Debarshi Brahma",
      "Amartya Bhattacharya",
      "Suraj Nagaje Mahadev",
      "Anmol Asati",
      "Vikas Verma",
      "Soma Biswas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17074",
    "title": "Self-Supervised Learning of Whole and Component-Based Semantic  Representations for Person Re-Identification",
    "abstract": " Title: Self-Supervised Learning of Whole and Component-Based Semantic  Representations for Person Re-Identification ",
    "url": "https://arxiv.org/abs/2311.17074",
    "authors": [
      "Siyuan Huang",
      "Yifan Zhou",
      "Ram Prabhakar",
      "Xijun Liu",
      "Yuxiang Guo",
      "Hongrui Yi",
      "Cheng Peng",
      "Rama Chellappa",
      "Chun Pong Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.18765",
    "title": "MLLMs-Augmented Visual-Language Representation Learning",
    "abstract": " Title: MLLMs-Augmented Visual-Language Representation Learning ",
    "url": "https://arxiv.org/abs/2311.18765",
    "authors": [
      "Yanqing Liu",
      "Kai Wang",
      "Wenqi Shao",
      "Ping Luo",
      "Yu Qiao",
      "Mike Zheng Shou",
      "Kaipeng Zhang",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03701",
    "title": "Return of Unconditional Generation: A Self-supervised Representation  Generation Method",
    "abstract": " Title: Return of Unconditional Generation: A Self-supervised Representation  Generation Method ",
    "url": "https://arxiv.org/abs/2312.03701",
    "authors": [
      "Tianhong Li",
      "Dina Katabi",
      "Kaiming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.03878",
    "title": "Domain constraints improve risk prediction when outcome data is missing",
    "abstract": " Title: Domain constraints improve risk prediction when outcome data is missing ",
    "url": "https://arxiv.org/abs/2312.03878",
    "authors": [
      "Sidhika Balachandar",
      "Nikhil Garg",
      "Emma Pierson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.04142",
    "title": "TimeDRL: Disentangled Representation Learning for Multivariate  Time-Series",
    "abstract": " Comments: This paper has been accepted by the International Conference on Data Engineering (ICDE) 2024 ",
    "url": "https://arxiv.org/abs/2312.04142",
    "authors": [
      "Ching Chang",
      "Chiao-Tung Chan",
      "Wei-Yao Wang",
      "Wen-Chih Peng",
      "Tien-Fu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.05720",
    "title": "Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning",
    "abstract": " Title: Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning ",
    "url": "https://arxiv.org/abs/2312.05720",
    "authors": [
      "Jianwei Li",
      "Sheng Liu",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.09481",
    "title": "Continual Adversarial Defense",
    "abstract": " Title: Continual Adversarial Defense ",
    "url": "https://arxiv.org/abs/2312.09481",
    "authors": [
      "Qian Wang",
      "Yaoyao Liu",
      "Hefei Ling",
      "Yingwei Li",
      "Qihao Liu",
      "Ping Li",
      "Jiazhong Chen",
      "Alan Yuille",
      "Ning Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.00241",
    "title": "Image Super-resolution Reconstruction Network based on Enhanced Swin  Transformer via Alternating Aggregation of Local-Global Features",
    "abstract": " Title: Image Super-resolution Reconstruction Network based on Enhanced Swin  Transformer via Alternating Aggregation of Local-Global Features ",
    "url": "https://arxiv.org/abs/2401.00241",
    "authors": [
      "Yuming Huang",
      "Yingpin Chen",
      "Changhui Wu",
      "Hanrong Xie",
      "Binhui Song",
      "Hui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.08407",
    "title": "Cross-Domain Few-Shot Segmentation via Iterative Support-Query  Correspondence Mining",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2401.08407",
    "authors": [
      "Jiahao Nie",
      "Yun Xing",
      "Gongjie Zhang",
      "Pei Yan",
      "Aoran Xiao",
      "Yap-Peng Tan",
      "Alex C. Kot",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.15604",
    "title": "Neural Network-Based Score Estimation in Diffusion Models: Optimization  and Generalization",
    "abstract": " Comments: 39 pages ",
    "url": "https://arxiv.org/abs/2401.15604",
    "authors": [
      "Yinbin Han",
      "Meisam Razaviyayn",
      "Renyuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.16183",
    "title": "Scalable Reinforcement Learning for Linear-Quadratic Control of Networks",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2401.16183",
    "authors": [
      "Johan Olsson",
      "Runyu Zhang",
      "Emma Tegling",
      "Na Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2402.03166",
    "title": "RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein  Segmentation and Classification",
    "abstract": " Title: RRWNet: Recursive Refinement Network for Effective Retinal Artery/Vein  Segmentation and Classification ",
    "url": "https://arxiv.org/abs/2402.03166",
    "authors": [
      "Jos\u00e9 Morano",
      "Guilherme Aresta",
      "Hrvoje Bogunovi\u0107"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.03246",
    "title": "SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM",
    "abstract": " Title: SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM ",
    "url": "https://arxiv.org/abs/2402.03246",
    "authors": [
      "Mingrui Li",
      "Shuhong Liu",
      "Heng Zhou",
      "Guohao Zhu",
      "Na Cheng",
      "Tianchen Deng",
      "Hongyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2402.09264",
    "title": "UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers",
    "abstract": " Title: UR2M: Uncertainty and Resource-Aware Event Detection on Microcontrollers ",
    "url": "https://arxiv.org/abs/2402.09264",
    "authors": [
      "Hong Jia",
      "Young D. Kwon",
      "Dong Ma",
      "Nhat Pham",
      "Lorena Qendro",
      "Tam Vu",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.10659",
    "title": "Network Formation and Dynamics Among Multi-LLMs",
    "abstract": " Title: Network Formation and Dynamics Among Multi-LLMs ",
    "url": "https://arxiv.org/abs/2402.10659",
    "authors": [
      "Marios Papachristou",
      "Yuan Yuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2402.14172",
    "title": "Open Source Software Field Research: Spanning Social and Practice  Networks for Re-Entering the Field",
    "abstract": " Title: Open Source Software Field Research: Spanning Social and Practice  Networks for Re-Entering the Field ",
    "url": "https://arxiv.org/abs/2402.14172",
    "authors": [
      "Sean P. Goggins",
      "Kevin Lumbard",
      "Matt Germonprez",
      "Caifan Du",
      "Karthik Ram",
      "James Howison"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2402.14989",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular  Time Series Data",
    "abstract": " Comments: Accepted at ICLR 2024, Spotlight presentation (Notable Top 5%). this https URL ",
    "url": "https://arxiv.org/abs/2402.14989",
    "authors": [
      "YongKyung Oh",
      "Dongyoung Lim",
      "Sungil Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15281",
    "title": "Neural Implicit Swept Volume Models for Fast Collision Detection",
    "abstract": " Comments: To be published at ICRA 2024. Dominik Joho and Jonas Schwinn have equal contribution ",
    "url": "https://arxiv.org/abs/2402.15281",
    "authors": [
      "Dominik Joho",
      "Jonas Schwinn",
      "Kirill Safronov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.01644",
    "title": "OccFusion: A Straightforward and Effective Multi-Sensor Fusion Framework  for 3D Occupancy Prediction",
    "abstract": " Title: OccFusion: A Straightforward and Effective Multi-Sensor Fusion Framework  for 3D Occupancy Prediction ",
    "url": "https://arxiv.org/abs/2403.01644",
    "authors": [
      "Zhenxing Ming",
      "Julie Stephany Berrio",
      "Mao Shan",
      "Stewart Worrall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.03165",
    "title": "Leveraging Federated Learning and Edge Computing for Recommendation  Systems within Cloud Computing Networks",
    "abstract": " Title: Leveraging Federated Learning and Edge Computing for Recommendation  Systems within Cloud Computing Networks ",
    "url": "https://arxiv.org/abs/2403.03165",
    "authors": [
      "Yaqian Qi",
      "Yuan Feng",
      "Xiangxiang Wang",
      "Hanzhe Li",
      "Jingxiao Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.04780",
    "title": "MuseGraph: Graph-oriented Instruction Tuning of Large Language Models  for Generic Graph Mining",
    "abstract": " Title: MuseGraph: Graph-oriented Instruction Tuning of Large Language Models  for Generic Graph Mining ",
    "url": "https://arxiv.org/abs/2403.04780",
    "authors": [
      "Yanchao Tan",
      "Hang Lv",
      "Xinyi Huang",
      "Jiawei Zhang",
      "Shiping Wang",
      "Carl Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.05452",
    "title": "The R2D2 deep neural network series paradigm for fast precision imaging  in radio astronomy",
    "abstract": " Comments: Confusing typo on the target dynamic range corrected, submitted to ApJS ",
    "url": "https://arxiv.org/abs/2403.05452",
    "authors": [
      "Amir Aghabiglou",
      "Chung San Chu",
      "Arwa Dabbech",
      "Yves Wiaux"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.05457",
    "title": "Sparse dynamic network reconstruction through L1-regularization of a  Lyapunov equation",
    "abstract": " Title: Sparse dynamic network reconstruction through L1-regularization of a  Lyapunov equation ",
    "url": "https://arxiv.org/abs/2403.05457",
    "authors": [
      "Ian Xul Belaustegui",
      "Marcela Ordorica Arango",
      "Rom\u00e1n Rossi-Pool",
      "Naomi Ehrich Leonard",
      "Alessio Franci"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.05693",
    "title": "Shielded Deep Reinforcement Learning for Complex Spacecraft Tasking",
    "abstract": " Comments: 9 pages, 2 figures, 2 tables, ACC 2024 ",
    "url": "https://arxiv.org/abs/2403.05693",
    "authors": [
      "Robert Reed",
      "Hanspeter Schaub",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.05924",
    "title": "CSCNET: Class-Specified Cascaded Network for Compositional Zero-Shot  Learning",
    "abstract": " Comments: ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2403.05924",
    "authors": [
      "Yanyi Zhang",
      "Qi Jia",
      "Xin Fan",
      "Yu Liu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.06026",
    "title": "Towards a Generic Representation of Combinatorial Problems for  Learning-Based Approaches",
    "abstract": " Title: Towards a Generic Representation of Combinatorial Problems for  Learning-Based Approaches ",
    "url": "https://arxiv.org/abs/2403.06026",
    "authors": [
      "L\u00e9o Boisvert",
      "H\u00e9l\u00e8ne Verhaeghe",
      "Quentin Cappart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.06452",
    "title": "Text2QR: Harmonizing Aesthetic Customization and Scanning Robustness for  Text-Guided QR Code Generation",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.06452",
    "authors": [
      "Guangyang Wu",
      "Xiaohong Liu",
      "Jun Jia",
      "Xuehao Cui",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.06487",
    "title": "Multilingual Turn-taking Prediction Using Voice Activity Projection",
    "abstract": " Comments: This paper has been accepted for presentation at The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) and represents the author's version of the work ",
    "url": "https://arxiv.org/abs/2403.06487",
    "authors": [
      "Koji Inoue",
      "Bing'er Jiang",
      "Erik Ekstedt",
      "Tatsuya Kawahara",
      "Gabriel Skantze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.06493",
    "title": "A Lower bound for Secure Domination Number of an Outerplanar Graph",
    "abstract": " Comments: 7 pages, 1 figure. arXiv admin note: text overlap with arXiv:2403.03404 ",
    "url": "https://arxiv.org/abs/2403.06493",
    "authors": [
      "Toru Araki"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2403.06747",
    "title": "MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation",
    "abstract": " Comments: WWW'24 Industry Track ",
    "url": "https://arxiv.org/abs/2403.06747",
    "authors": [
      "Wenhao Wu",
      "Jialiang Zhou",
      "Ailong He",
      "Shuguang Han",
      "Jufeng Chen",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.07353",
    "title": "Graph Unlearning with Efficient Partial Retraining",
    "abstract": " Comments: 8 pages, 3 figures, accepted by The Web Conference 2024 (PhD Symposium Track) ",
    "url": "https://arxiv.org/abs/2403.07353",
    "authors": [
      "Jiahao Zhang",
      "Lin Wang",
      "Shijie Wang",
      "Wenqi Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.07420",
    "title": "DragAnything: Motion Control for Anything using Entity Representation",
    "abstract": " Comments: The project website is at: this https URL . The code is at: this https URL ",
    "url": "https://arxiv.org/abs/2403.07420",
    "authors": [
      "Weijia Wu",
      "Zhuang Li",
      "Yuchao Gu",
      "Rui Zhao",
      "Yefei He",
      "David Junhao Zhang",
      "Mike Zheng Shou",
      "Yan Li",
      "Tingting Gao",
      "Di Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.07673",
    "title": "Towards Model Extraction Attacks in GAN-Based Image Translation via  Domain Shift Mitigation",
    "abstract": " Comments: Accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2403.07673",
    "authors": [
      "Di Mi",
      "Yanjun Zhang",
      "Leo Yu Zhang",
      "Shengshan Hu",
      "Qi Zhong",
      "Haizhuan Yuan",
      "Shirui Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  }
]