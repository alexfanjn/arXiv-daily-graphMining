[
  {
    "id": "arXiv:2403.10534",
    "title": "VISREAS: Complex Visual Reasoning with Unanswerable Questions",
    "abstract": "Verifying a question's validity before answering is crucial in real-world applications, where users may provide imperfect instructions. In this scenario, an ideal model should address the discrepancies in the query and convey them to the users rather than generating the best possible answer. Addressing this requirement, we introduce a new compositional visual question-answering dataset, VISREAS, that consists of answerable and unanswerable visual queries formulated by traversing and perturbing commonalities and differences among objects, attributes, and relations. VISREAS contains 2.07M semantically diverse queries generated automatically using Visual Genome scene graphs. The unique feature of this task, validating question answerability with respect to an image before answering, and the poor performance of state-of-the-art models inspired the design of a new modular baseline, LOGIC2VISION that reasons by producing and executing pseudocode without any external modules to generate the answer. LOGIC2VISION outperforms generative models in VISREAS (+4.82% over LLaVA-1.5; +12.23% over InstructBLIP) and achieves a significant gain in performance against the classification models. ",
    "url": "https://arxiv.org/abs/2403.10534",
    "authors": [
      "Syeda Nahida Akter",
      "Sangwu Lee",
      "Yingshan Chang",
      "Yonatan Bisk",
      "Eric Nyberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10542",
    "title": "SF-MMCN: A Low Power Re-configurable Server Flow Convolution Neural  Network Accelerator",
    "abstract": "Convolution Neural Network (CNN) accelerators have been developed rapidly in recent studies. There are lots of CNN accelerators equipped with a variety of function and algorithm which results in low power and high-speed performances. However, the scale of a PE array in traditional CNN accelerators is too big, which costs the most energy consumption while conducting multiply and accumulation (MAC) computations. The other issue is that due to the advance of CNN models, there are enormous models consist of parallel structures such as residual block in Residual Network (ResNet). The appearance of parallel structure in CNN models gives a challenge to the design of CNN accelerators owing to impacts on both operation and area efficiency. This study proposed SF-MMCN structure. The scale of PE array in proposed designs is reduced by pipeline technique in a PE. Proposed SF structure successfully make proposed SF-MMCN operate in high efficiency when facing parallel structures in CNN models. Proposed design is implemented with TSMC 90nm technology on VGG-16 and ResNet-18 environments. The performance of proposed design achieves 76% energy saving, 55% area saving and increases operation and are efficiency 9.25 times and 4.92 times respectively. ",
    "url": "https://arxiv.org/abs/2403.10542",
    "authors": [
      "Huan-Ke Hsu",
      "I-Chyn Wey",
      "T.Hui Teo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10543",
    "title": "Distinguishing Neighborhood Representations Through Reverse Process of  GNNs for Heterophilic Graphs",
    "abstract": "Graph Neural Network (GNN) resembles the diffusion process, leading to the over-smoothing of learned representations when stacking many layers. Hence, the reverse process of message passing can sharpen the node representations by inverting the forward message propagation. The sharpened representations can help us to better distinguish neighboring nodes with different labels, such as in heterophilic graphs. In this work, we apply the design principle of the reverse process to the three variants of the GNNs. Through the experiments on heterophilic graph data, where adjacent nodes need to have different representations for successful classification, we show that the reverse process significantly improves the prediction performance in many cases. Additional analysis reveals that the reverse mechanism can mitigate the over-smoothing over hundreds of layers. ",
    "url": "https://arxiv.org/abs/2403.10543",
    "authors": [
      "MoonJeong Park",
      "Jaeseung Heo",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10550",
    "title": "Semi-Supervised Learning for Anomaly Traffic Detection via Bidirectional  Normalizing Flows",
    "abstract": "With the rapid development of the Internet, various types of anomaly traffic are threatening network security. We consider the problem of anomaly network traffic detection and propose a three-stage anomaly detection framework using only normal traffic. Our framework can generate pseudo anomaly samples without prior knowledge of anomalies to achieve the detection of anomaly data. Firstly, we employ a reconstruction method to learn the deep representation of normal samples. Secondly, these representations are normalized to a standard normal distribution using a bidirectional flow module. To simulate anomaly samples, we add noises to the normalized representations which are then passed through the generation direction of the bidirectional flow module. Finally, a simple classifier is trained to differentiate the normal samples and pseudo anomaly samples in the latent space. During inference, our framework requires only two modules to detect anomalous samples, leading to a considerable reduction in model size. According to the experiments, our method achieves the state of-the-art results on the common benchmarking datasets of anomaly network traffic detection. The code is given in the https://github.com/ZxuanDang/ATD-via-Flows.git ",
    "url": "https://arxiv.org/abs/2403.10550",
    "authors": [
      "Zhangxuan Dang",
      "Yu Zheng",
      "Xinglin Lin",
      "Chunlei Peng",
      "Qiuyu Chen",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10558",
    "title": "Adaptive Hybrid Masking Strategy for Privacy-Preserving Face Recognition  Against Model Inversion Attack",
    "abstract": "The utilization of personal sensitive data in training face recognition (FR) models poses significant privacy concerns, as adversaries can employ model inversion attacks (MIA) to infer the original training data. Existing defense methods, such as data augmentation and differential privacy, have been employed to mitigate this issue. However, these methods often fail to strike an optimal balance between privacy and accuracy. To address this limitation, this paper introduces an adaptive hybrid masking algorithm against MIA. Specifically, face images are masked in the frequency domain using an adaptive MixUp strategy. Unlike the traditional MixUp algorithm, which is predominantly used for data augmentation, our modified approach incorporates frequency domain mixing. Previous studies have shown that increasing the number of images mixed in MixUp can enhance privacy preservation but at the expense of reduced face recognition accuracy. To overcome this trade-off, we develop an enhanced adaptive MixUp strategy based on reinforcement learning, which enables us to mix a larger number of images while maintaining satisfactory recognition accuracy. To optimize privacy protection, we propose maximizing the reward function (i.e., the loss function of the FR system) during the training of the strategy network. While the loss function of the FR network is minimized in the phase of training the FR network. The strategy network and the face recognition network can be viewed as antagonistic entities in the training process, ultimately reaching a more balanced trade-off. Experimental results demonstrate that our proposed hybrid masking scheme outperforms existing defense algorithms in terms of privacy preservation and recognition accuracy against MIA. ",
    "url": "https://arxiv.org/abs/2403.10558",
    "authors": [
      "Yuanqing Huang",
      "Yinggui Wang",
      "Jianshu Li",
      "Le Yang",
      "Kai Song",
      "Lei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10561",
    "title": "A collection of the accepted papers for the Human-Centric Representation  Learning workshop at AAAI 2024",
    "abstract": "This non-archival index is not complete, as some accepted papers chose to opt-out of inclusion. The list of all accepted papers is available on the workshop website. ",
    "url": "https://arxiv.org/abs/2403.10561",
    "authors": [
      "Dimitris Spathis",
      "Aaqib Saeed",
      "Ali Etemad",
      "Sana Tonekaboni",
      "Stefanos Laskaridis",
      "Shohreh Deldari",
      "Chi Ian Tang",
      "Patrick Schwab",
      "Shyam Tailor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10562",
    "title": "Counter-Samples: A Stateless Strategy to Neutralize Black Box  Adversarial Attacks",
    "abstract": "Our paper presents a novel defence against black box attacks, where attackers use the victim model as an oracle to craft their adversarial examples. Unlike traditional preprocessing defences that rely on sanitizing input samples, our stateless strategy counters the attack process itself. For every query we evaluate a counter-sample instead, where the counter-sample is the original sample optimized against the attacker's objective. By countering every black box query with a targeted white box optimization, our strategy effectively introduces an asymmetry to the game to the defender's advantage. This defence not only effectively misleads the attacker's search for an adversarial example, it also preserves the model's accuracy on legitimate inputs and is generic to multiple types of attacks. We demonstrate that our approach is remarkably effective against state-of-the-art black box attacks and outperforms existing defences for both the CIFAR-10 and ImageNet datasets. Additionally, we also show that the proposed defence is robust against strong adversaries as well. ",
    "url": "https://arxiv.org/abs/2403.10562",
    "authors": [
      "Roey Bokobza",
      "Yisroel Mirsky"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10572",
    "title": "Discovering Invariant Neighborhood Patterns for Heterophilic Graphs",
    "abstract": "This paper studies the problem of distribution shifts on non-homophilous graphs Mosting existing graph neural network methods rely on the homophilous assumption that nodes from the same class are more likely to be linked. However, such assumptions of homophily do not always hold in real-world graphs, which leads to more complex distribution shifts unaccounted for in previous methods. The distribution shifts of neighborhood patterns are much more diverse on non-homophilous graphs. We propose a novel Invariant Neighborhood Pattern Learning (INPL) to alleviate the distribution shifts problem on non-homophilous graphs. Specifically, we propose the Adaptive Neighborhood Propagation (ANP) module to capture the adaptive neighborhood information, which could alleviate the neighborhood pattern distribution shifts problem on non-homophilous graphs. We propose Invariant Non-Homophilous Graph Learning (INHGL) module to constrain the ANP and learn invariant graph representation on non-homophilous graphs. Extensive experimental results on real-world non-homophilous graphs show that INPL could achieve state-of-the-art performance for learning on large non-homophilous graphs. ",
    "url": "https://arxiv.org/abs/2403.10572",
    "authors": [
      "Ruihao Zhang",
      "Zhengyu Chen",
      "Teng Xiao",
      "Yueyang Wang",
      "Kun Kuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10575",
    "title": "Exploring Language Model's Code Generation Ability with Auxiliary  Functions",
    "abstract": "Auxiliary function is a helpful component to improve language model's code generation ability. However, a systematic exploration of how they affect has yet to be done. In this work, we comprehensively evaluate the ability to utilize auxiliary functions encoded in recent code-pretrained language models. First, we construct a human-crafted evaluation set, called HumanExtension, which contains examples of two functions where one function assists the other. With HumanExtension, we design several experiments to examine their ability in a multifaceted way. Our evaluation processes enable a comprehensive understanding of including auxiliary functions in the prompt in terms of effectiveness and robustness. An additional implementation style analysis captures the models' various implementation patterns when they access the auxiliary function. Through this analysis, we discover the models' promising ability to utilize auxiliary functions including their self-improving behavior by implementing the two functions step-by-step. However, our analysis also reveals the model's underutilized behavior to call the auxiliary function, suggesting the future direction to enhance their implementation by eliciting the auxiliary function call ability encoded in the models. We release our code and dataset to facilitate this research direction. ",
    "url": "https://arxiv.org/abs/2403.10575",
    "authors": [
      "Seonghyeon Lee",
      "Sanghwan Jang",
      "Seongbo Jang",
      "Dongha Lee",
      "Hwanjo Yu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10586",
    "title": "From Algorithms to Outcomes: Reviewing AI's Role in Non-Muscle-Invasive  Bladder Cancer Recurrence Prediction",
    "abstract": "Bladder cancer, the leading urinary tract cancer, is responsible for 15 deaths daily in the UK. This cancer predominantly manifests as non-muscle-invasive bladder cancer (NMIBC), characterised by tumours not yet penetrating the muscle layer of the bladder wall. NMIBC is plagued by a very high recurrence rate of 70-80% and hence the costliest treatments. Current tools for predicting recurrence use scoring systems that overestimate risk and have poor accuracy. Inaccurate and delayed prediction of recurrence significantly elevates the likelihood of mortality. Accurate prediction of recurrence is hence vital for cost-effective management and treatment planning. This is where Machine learning (ML) techniques have emerged as a promising approach for predicting NMIBC recurrence by leveraging molecular and clinical data. This review provides a comprehensive analysis of ML approaches for predicting NMIBC recurrence. Our systematic evaluation demonstrates the potential of diverse ML algorithms and markers, including radiomic, clinical, histopathological, genomic, and biochemical data in enhancing recurrence prediction and personalised patient management. We summarise various prediction tasks, data modalities, and ML models used, highlighting their performance, limitations, and future directions of incorporating cost-effectiveness. Challenges related to generalisability and interpretability of artificial intelligent models are discussed, emphasising the need for collaborative efforts and robust datasets. ",
    "url": "https://arxiv.org/abs/2403.10586",
    "authors": [
      "Saram Abbas",
      "Dr Rishad Shafik",
      "Prof Naeem Soomro",
      "Prof Rakesh Heer",
      "Dr Kabita Adhikari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10596",
    "title": "Neural Erosion: Emulating Controlled Neurodegeneration and Aging in AI  Systems",
    "abstract": "Creating controlled methods to simulate neurodegeneration in artificial intelligence (AI) is crucial for applications that emulate brain function decline and cognitive disorders. We use IQ tests performed by Large Language Models (LLMs) and, more specifically, the LLaMA 2 to introduce the concept of ``neural erosion.\" This deliberate erosion involves ablating synapses or neurons, or adding Gaussian noise during or after training, resulting in a controlled progressive decline in the LLMs' performance. We are able to describe the neurodegeneration in the IQ tests and show that the LLM first loses its mathematical abilities and then its linguistic abilities, while further losing its ability to understand the questions. To the best of our knowledge, this is the first work that models neurodegeneration with text data, compared to other works that operate in the computer vision domain. Finally, we draw similarities between our study and cognitive decline clinical studies involving test subjects. We find that with the application of neurodegenerative methods, LLMs lose abstract thinking abilities, followed by mathematical degradation, and ultimately, a loss in linguistic ability, responding to prompts incoherently. These findings are in accordance with human studies. ",
    "url": "https://arxiv.org/abs/2403.10596",
    "authors": [
      "Antonios Alexos",
      "Yu-Dai Tsai",
      "Ian Domingo",
      "Maryam Pishgar",
      "Pierre Baldi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2403.10603",
    "title": "SurvRNC: Learning Ordered Representations for Survival Prediction using  Rank-N-Contrast",
    "abstract": "Predicting the likelihood of survival is of paramount importance for individuals diagnosed with cancer as it provides invaluable information regarding prognosis at an early stage. This knowledge enables the formulation of effective treatment plans that lead to improved patient outcomes. In the past few years, deep learning models have provided a feasible solution for assessing medical images, electronic health records, and genomic data to estimate cancer risk scores. However, these models often fall short of their potential because they struggle to learn regression-aware feature representations. In this study, we propose Survival Rank-N Contrast (SurvRNC) method, which introduces a loss function as a regularizer to obtain an ordered representation based on the survival times. This function can handle censored data and can be incorporated into any survival model to ensure that the learned representation is ordinal. The model was extensively evaluated on a HEad \\& NeCK TumOR (HECKTOR) segmentation and the outcome-prediction task dataset. We demonstrate that using the SurvRNC method for training can achieve higher performance on different deep survival models. Additionally, it outperforms state-of-the-art methods by 3.6% on the concordance index. The code is publicly available on https://github.com/numanai/SurvRNC ",
    "url": "https://arxiv.org/abs/2403.10603",
    "authors": [
      "Numan Saeed",
      "Muhammad Ridzuan",
      "Fadillah Adamsyah Maani",
      "Hussain Alasmawi",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10621",
    "title": "Lyapunov Neural Network with Region of Attraction Search",
    "abstract": "Deep learning methods have been widely used in robotic applications, making learning-enabled control design for complex nonlinear systems a promising direction. Although deep reinforcement learning methods have demonstrated impressive empirical performance, they lack the stability guarantees that are important in safety-critical situations. One way to provide these guarantees is to learn Lyapunov certificates alongside control policies. There are three related problems: 1) verify that a given Lyapunov function candidate satisfies the conditions for a given controller on a region, 2) find a valid Lyapunov function and controller on a given region, and 3) find a valid Lyapunov function and a controller such that the region of attraction is as large as possible. Previous work has shown that if the dynamics are piecewise linear, it is possible to solve problems 1) and 2) by solving a Mixed-Integer Linear Program (MILP). In this work, we build upon this method by proposing a Lyapunov neural network that considers monotonicity over half spaces in different directions. We 1) propose a specific choice of Lyapunov function architecture that ensures non-negativity and a unique global minimum by construction, and 2) show that this can be leveraged to find the controller and Lyapunov certificates faster and with a larger valid region by maximizing the size of a square inscribed in a given level set. We apply our method to a 2D inverted pendulum, unicycle path following, a 3-D feedback system, and a 4-D cart pole system, and demonstrate it can shorten the training time by half compared to the baseline, as well as find a larger ROA. ",
    "url": "https://arxiv.org/abs/2403.10621",
    "authors": [
      "Zili Wang",
      "Sean B. Andersson",
      "Roberto Tron"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.10646",
    "title": "A Survey of Source Code Representations for Machine Learning-Based  Cybersecurity Tasks",
    "abstract": "Machine learning techniques for cybersecurity-related software engineering tasks are becoming increasingly popular. The representation of source code is a key portion of the technique that can impact the way the model is able to learn the features of the source code. With an increasing number of these techniques being developed, it is valuable to see the current state of the field to better understand what exists and what's not there yet. This paper presents a study of these existing ML-based approaches and demonstrates what type of representations were used for different cybersecurity tasks and programming languages. Additionally, we study what types of models are used with different representations. We have found that graph-based representations are the most popular category of representation, and Tokenizers and Abstract Syntax Trees (ASTs) are the two most popular representations overall. We also found that the most popular cybersecurity task is vulnerability detection, and the language that is covered by the most techniques is C. Finally, we found that sequence-based models are the most popular category of models, and Support Vector Machines (SVMs) are the most popular model overall. ",
    "url": "https://arxiv.org/abs/2403.10646",
    "authors": [
      "Beatrice Casey",
      "Joanna C. S. Santos",
      "George Perry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10659",
    "title": "Towards Practical Fabrication Stage Attacks Using Interrupt-Resilient  Hardware Trojans",
    "abstract": "We introduce a new class of hardware trojans called interrupt-resilient trojans (IRTs). Our work is motivated by the observation that hardware trojan attacks on CPUs, even under favorable attack scenarios (e.g., an attacker with local system access), are affected by unpredictability due to non-deterministic context switching events. As we confirm experimentally, these events can lead to race conditions between trigger signals and the CPU events targeted by the trojan payloads (e.g., a CPU memory access), thus affecting the reliability of the attacks. Our work shows that interrupt-resilient trojans can successfully address the problem of non-deterministic triggering in CPUs, thereby providing high reliability guarantees in the implementation of sophisticated hardware trojan attacks. Specifically, we successfully utilize IRTs in different attack scenarios against a Linux-capable CPU design and showcase its resilience against context-switching events. More importantly, we show that our design allows for seamless integration during fabrication stage attacks.We evaluate different strategies for the implementation of our attacks on a tape-out ready high-speed RISC-V microarchitecture in a 28nm commercial technology process and successfully implement them with an average overhead delay of only 20 picoseconds, while leaving the sign-off characteristics of the layout intact. In doing so, we challenge the common wisdom regarding the low flexibility of late supply chain stages (e.g., fabrication) for the insertion of powerful trojans. To promote further research on microprocessor trojans, we open-source our designs and provide the accompanying supporting software logic. ",
    "url": "https://arxiv.org/abs/2403.10659",
    "authors": [
      "Athanasios Moschos",
      "Fabian Monrose",
      "Angelos D. Keromytis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10663",
    "title": "Not Just Change the Labels, Learn the Features: Watermarking Deep Neural  Networks with Multi-View Data",
    "abstract": "With the increasing prevalence of Machine Learning as a Service (MLaaS) platforms, there is a growing focus on deep neural network (DNN) watermarking techniques. These methods are used to facilitate the verification of ownership for a target DNN model to protect intellectual property. One of the most widely employed watermarking techniques involves embedding a trigger set into the source model. Unfortunately, existing methodologies based on trigger sets are still susceptible to functionality-stealing attacks, potentially enabling adversaries to steal the functionality of the source model without a reliable means of verifying ownership. In this paper, we first introduce a novel perspective on trigger set-based watermarking methods from a feature learning perspective. Specifically, we demonstrate that by selecting data exhibiting multiple features, also referred to as $\\textit{multi-view data}$, it becomes feasible to effectively defend functionality stealing attacks. Based on this perspective, we introduce a novel watermarking technique based on Multi-view dATa, called MAT, for efficiently embedding watermarks within DNNs. This approach involves constructing a trigger set with multi-view data and incorporating a simple feature-based regularization method for training the source model. We validate our method across various benchmarks and demonstrate its efficacy in defending against model extraction attacks, surpassing relevant baselines by a significant margin. ",
    "url": "https://arxiv.org/abs/2403.10663",
    "authors": [
      "Yuxuan Li",
      "Sarthak Kumar Maharana",
      "Yunhui Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10676",
    "title": "Secure Distributed Storage: Optimal Trade-Off Between Storage Rate and  Privacy Leakage",
    "abstract": "Consider the problem of storing data in a distributed manner over $T$ servers. Specifically, the data needs to (i) be recoverable from any $\\tau$ servers, and (ii) remain private from any $z$ colluding servers, where privacy is quantified in terms of mutual information between the data and all the information available at any $z$ colluding servers. For this model, our main results are (i) the fundamental trade-off between storage size and the level of desired privacy, and (ii) the optimal amount of local randomness necessary at the encoder. As a byproduct, our results provide an optimal lower bound on the individual share size of ramp secret sharing schemes under a more general leakage symmetry condition than the ones previously considered in the literature. ",
    "url": "https://arxiv.org/abs/2403.10676",
    "authors": [
      "Remi A. Chou",
      "Joerg Kliewer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10677",
    "title": "Spiking Neural Networks for Fast-Moving Object Detection on Neuromorphic  Hardware Devices Using an Event-Based Camera",
    "abstract": "Table tennis is a fast-paced and exhilarating sport that demands agility, precision, and fast reflexes. In recent years, robotic table tennis has become a popular research challenge for robot perception algorithms. Fast and accurate ball detection is crucial for enabling a robotic arm to rally the ball back successfully. Previous approaches have employed conventional frame-based cameras with Convolutional Neural Networks (CNNs) or traditional computer vision methods. In this paper, we propose a novel solution that combines an event-based camera with Spiking Neural Networks (SNNs) for ball detection. We use multiple state-of-the-art SNN frameworks and develop a SNN architecture for each of them, complying with their corresponding constraints. Additionally, we implement the SNN solution across multiple neuromorphic edge devices, conducting comparisons of their accuracies and run-times. This furnishes robotics researchers with a benchmark illustrating the capabilities achievable with each SNN framework and a corresponding neuromorphic edge device. Next to this comparison of SNN solutions for robots, we also show that an SNN on a neuromorphic edge device is able to run in real-time in a closed loop robotic system, a table tennis robot in our use case. ",
    "url": "https://arxiv.org/abs/2403.10677",
    "authors": [
      "Andreas Ziegler",
      "Karl Vetter",
      "Thomas Gossard",
      "Jonas Tebbe",
      "Andreas Zell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10698",
    "title": "Robust Influence-based Training Methods for Noisy Brain MRI",
    "abstract": "Correctly classifying brain tumors is imperative to the prompt and accurate treatment of a patient. While several classification algorithms based on classical image processing or deep learning methods have been proposed to rapidly classify tumors in MR images, most assume the unrealistic setting of noise-free training data. In this work, we study a difficult but realistic setting of training a deep learning model on noisy MR images to classify brain tumors. We propose two training methods that are robust to noisy MRI training data, Influence-based Sample Reweighing (ISR) and Influence-based Sample Perturbation (ISP), which are based on influence functions from robust statistics. Using the influence functions, in ISR, we adaptively reweigh training examples according to how helpful/harmful they are to the training process, while in ISP, we craft and inject helpful perturbation proportional to the influence score. Both ISR and ISP harden the classification model against noisy training data without significantly affecting the generalization ability of the model on test data. We conduct empirical evaluations over a common brain tumor dataset and compare ISR and ISP to three baselines. Our empirical results show that ISR and ISP can efficiently train deep learning models robust against noisy training data. ",
    "url": "https://arxiv.org/abs/2403.10698",
    "authors": [
      "Minh-Hao Van",
      "Alycia N. Carey",
      "Xintao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10700",
    "title": "Mind the Error! Detection and Localization of Instruction Errors in  Vision-and-Language Navigation",
    "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of the most intuitive yet challenging embodied AI tasks. Agents are tasked to navigate towards a target goal by executing a set of low-level actions, following a series of natural language instructions. All VLN-CE methods in the literature assume that language instructions are exact. However, in practice, instructions given by humans can contain errors when describing a spatial environment due to inaccurate memory or confusion. Current VLN-CE benchmarks do not address this scenario, making the state-of-the-art methods in VLN-CE fragile in the presence of erroneous instructions from human users. For the first time, we propose a novel benchmark dataset that introduces various types of instruction errors considering potential human causes. This benchmark provides valuable insight into the robustness of VLN systems in continuous environments. We observe a noticeable performance drop (up to -25%) in Success Rate when evaluating the state-of-the-art VLN-CE methods on our benchmark. Moreover, we formally define the task of Instruction Error Detection and Localization, and establish an evaluation protocol on top of our benchmark dataset. We also propose an effective method, based on a cross-modal transformer architecture, that achieves the best performance in error detection and localization, compared to baselines. Surprisingly, our proposed method has revealed errors in the validation set of the two commonly used datasets for VLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in other tasks. Code and dataset will be made available upon acceptance at https://intelligolabs.github.io/R2RIE-CE ",
    "url": "https://arxiv.org/abs/2403.10700",
    "authors": [
      "Francesco Taioli",
      "Stefano Rosa",
      "Alberto Castellini",
      "Lorenzo Natale",
      "Alessio Del Bue",
      "Alessandro Farinelli",
      "Marco Cristani",
      "Yiming Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10701",
    "title": "IMPRINT: Generative Object Compositing by Learning Identity-Preserving  Representation",
    "abstract": "Generative object compositing emerges as a promising new avenue for compositional image editing. However, the requirement of object identity preservation poses a significant challenge, limiting practical usage of most existing methods. In response, this paper introduces IMPRINT, a novel diffusion-based generative model trained with a two-stage learning framework that decouples learning of identity preservation from that of compositing. The first stage is targeted for context-agnostic, identity-preserving pretraining of the object encoder, enabling the encoder to learn an embedding that is both view-invariant and conducive to enhanced detail preservation. The subsequent stage leverages this representation to learn seamless harmonization of the object composited to the background. In addition, IMPRINT incorporates a shape-guidance mechanism offering user-directed control over the compositing process. Extensive experiments demonstrate that IMPRINT significantly outperforms existing methods and various baselines on identity preservation and composition quality. ",
    "url": "https://arxiv.org/abs/2403.10701",
    "authors": [
      "Yizhi Song",
      "Zhifei Zhang",
      "Zhe Lin",
      "Scott Cohen",
      "Brian Price",
      "Jianming Zhang",
      "Soo Ye Kim",
      "He Zhang",
      "Wei Xiong",
      "Daniel Aliaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10705",
    "title": "Susceptibility of Communities against Low-Credibility Content in Social  News Websites",
    "abstract": "Social news websites, such as Reddit, have evolved into prominent platforms for sharing and discussing news. A key issue on social news websites sites is the formation of echo chambers, which often lead to the spread of highly biased or uncredible news. We develop a method to identify communities within a social news website that are prone to uncredible or highly biased news. We employ a user embedding pipeline that detects user communities based on their stances towards posts and news sources. We then project each community onto a credibility-bias space and analyze the distributional characteristics of each projected community to identify those that have a high risk of adopting beliefs with low credibility or high bias. This approach also enables the prediction of individual users' susceptibility to low credibility content, based on their community affiliation. Our experiments show that latent space clusters effectively indicate the credibility and bias levels of their users, with significant differences observed across clusters -- a $34\\%$ difference in the users' susceptibility to low-credibility content and a $8.3\\%$ difference in the users' susceptibility to high political bias. ",
    "url": "https://arxiv.org/abs/2403.10705",
    "authors": [
      "Yigit Ege Bayiz",
      "Arash Amini",
      "Radu Marculescu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10707",
    "title": "Uncovering Latent Themes of Messaging on Social Media by Integrating  LLMs: A Case Study on Climate Campaigns",
    "abstract": "This paper introduces a novel approach to uncovering and analyzing themes in social media messaging. Recognizing the limitations of traditional topic-level analysis, which tends to capture only the overarching patterns, this study emphasizes the need for a finer-grained, theme-focused exploration. Conventional methods of theme discovery, involving manual processes and a human-in-the-loop approach, are valuable but face challenges in scalability, consistency, and resource intensity in terms of time and cost. To address these challenges, we propose a machine-in-the-loop approach that leverages the advanced capabilities of Large Language Models (LLMs). This approach allows for a deeper investigation into the thematic aspects of social media discourse, enabling us to uncover a diverse array of themes, each with unique characteristics and relevance, thereby offering a comprehensive understanding of the nuances present within broader topics. Furthermore, this method efficiently maps the text and the newly discovered themes, enhancing our understanding of the thematic nuances in social media messaging. We employ climate campaigns as a case study and demonstrate that our methodology yields more accurate and interpretable results compared to traditional topic models. Our results not only demonstrate the effectiveness of our approach in uncovering latent themes but also illuminate how these themes are tailored for demographic targeting in social media contexts. Additionally, our work sheds light on the dynamic nature of social media, revealing the shifts in the thematic focus of messaging in response to real-world events. ",
    "url": "https://arxiv.org/abs/2403.10707",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10717",
    "title": "Backdoor Secrets Unveiled: Identifying Backdoor Data with Optimized  Scaled Prediction Consistency",
    "abstract": "Modern machine learning (ML) systems demand substantial training data, often resorting to external sources. Nevertheless, this practice renders them vulnerable to backdoor poisoning attacks. Prior backdoor defense strategies have primarily focused on the identification of backdoored models or poisoned data characteristics, typically operating under the assumption of access to clean data. In this work, we delve into a relatively underexplored challenge: the automatic identification of backdoor data within a poisoned dataset, all under realistic conditions, i.e., without the need for additional clean data or without manually defining a threshold for backdoor detection. We draw an inspiration from the scaled prediction consistency (SPC) technique, which exploits the prediction invariance of poisoned data to an input scaling factor. Based on this, we pose the backdoor data identification problem as a hierarchical data splitting optimization problem, leveraging a novel SPC-based loss function as the primary optimization objective. Our innovation unfolds in several key aspects. First, we revisit the vanilla SPC method, unveiling its limitations in addressing the proposed backdoor identification problem. Subsequently, we develop a bi-level optimization-based approach to precisely identify backdoor data by minimizing the advanced SPC loss. Finally, we demonstrate the efficacy of our proposal against a spectrum of backdoor attacks, encompassing basic label-corrupted attacks as well as more sophisticated clean-label attacks, evaluated across various benchmark datasets. Experiment results show that our approach often surpasses the performance of current baselines in identifying backdoor data points, resulting in about 4%-36% improvement in average AUROC. Codes are available at https://github.com/OPTML-Group/BackdoorMSPC. ",
    "url": "https://arxiv.org/abs/2403.10717",
    "authors": [
      "Soumyadeep Pal",
      "Yuguang Yao",
      "Ren Wang",
      "Bingquan Shen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10720",
    "title": "Development and Application of a Monte Carlo Tree Search Algorithm for  Simulating Da Vinci Code Game Strategies",
    "abstract": "In this study, we explore the efficiency of the Monte Carlo Tree Search (MCTS), a prominent decision-making algorithm renowned for its effectiveness in complex decision environments, contingent upon the volume of simulations conducted. Notwithstanding its broad applicability, the algorithm's performance can be adversely impacted in certain scenarios, particularly within the domain of game strategy development. This research posits that the inherent branch divergence within the Da Vinci Code board game significantly impedes parallelism when executed on Graphics Processing Units (GPUs). To investigate this hypothesis, we implemented and meticulously evaluated two variants of the MCTS algorithm, specifically designed to assess the impact of branch divergence on computational performance. Our comparative analysis reveals a linear improvement in performance with the CPU-based implementation, in stark contrast to the GPU implementation, which exhibits a non-linear enhancement pattern and discernible performance troughs. These findings contribute to a deeper understanding of the MCTS algorithm's behavior in divergent branch scenarios, highlighting critical considerations for optimizing game strategy algorithms on parallel computing architectures. ",
    "url": "https://arxiv.org/abs/2403.10720",
    "authors": [
      "Ye Zhang",
      "Mengran Zhu",
      "Kailin Gui",
      "Jiayue Yu",
      "Yong Hao",
      "Haozhan Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10722",
    "title": "Cannabis Seed Variant Detection using Faster R-CNN",
    "abstract": "Analyzing and detecting cannabis seed variants is crucial for the agriculture industry. It enables precision breeding, allowing cultivators to selectively enhance desirable traits. Accurate identification of seed variants also ensures regulatory compliance, facilitating the cultivation of specific cannabis strains with defined characteristics, ultimately improving agricultural productivity and meeting diverse market demands. This paper presents a study on cannabis seed variant detection by employing a state-of-the-art object detection model Faster R-CNN. This study implemented the model on a locally sourced cannabis seed dataset in Thailand, comprising 17 distinct classes. We evaluate six Faster R-CNN models by comparing performance on various metrics and achieving a mAP score of 94.08\\% and an F1 score of 95.66\\%. This paper presents the first known application of deep neural network object detection models to the novel task of visually identifying cannabis seed types. ",
    "url": "https://arxiv.org/abs/2403.10722",
    "authors": [
      "Toqi Tahamid Sarker",
      "Taminul Islam",
      "Khaled R Ahmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10730",
    "title": "Counterfactual Analysis of Neural Networks Used to Create Fertilizer  Management Zones",
    "abstract": "In Precision Agriculture, the utilization of management zones (MZs) that take into account within-field variability facilitates effective fertilizer management. This approach enables the optimization of nitrogen (N) rates to maximize crop yield production and enhance agronomic use efficiency. However, existing works often neglect the consideration of responsivity to fertilizer as a factor influencing MZ determination. In response to this gap, we present a MZ clustering method based on fertilizer responsivity. We build upon the statement that the responsivity of a given site to the fertilizer rate is described by the shape of its corresponding N fertilizer-yield response (N-response) curve. Thus, we generate N-response curves for all sites within the field using a convolutional neural network (CNN). The shape of the approximated N-response curves is then characterized using functional principal component analysis. Subsequently, a counterfactual explanation (CFE) method is applied to discern the impact of various variables on MZ membership. The genetic algorithm-based CFE solves a multi-objective optimization problem and aims to identify the minimum combination of features needed to alter a site's cluster assignment. Results from two yield prediction datasets indicate that the features with the greatest influence on MZ membership are associated with terrain characteristics that either facilitate or impede fertilizer runoff, such as terrain slope or topographic aspect. ",
    "url": "https://arxiv.org/abs/2403.10730",
    "authors": [
      "Giorgio Morales",
      "John Sheppard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10737",
    "title": "Leveraging Synthetic Data for Generalizable and Fair Facial Action Unit  Detection",
    "abstract": "Facial action unit (AU) detection is a fundamental block for objective facial expression analysis. Supervised learning approaches require a large amount of manual labeling which is costly. The limited labeled data are also not diverse in terms of gender which can affect model fairness. In this paper, we propose to use synthetically generated data and multi-source domain adaptation (MSDA) to address the problems of the scarcity of labeled data and the diversity of subjects. Specifically, we propose to generate a diverse dataset through synthetic facial expression re-targeting by transferring the expressions from real faces to synthetic avatars. Then, we use MSDA to transfer the AU detection knowledge from a real dataset and the synthetic dataset to a target dataset. Instead of aligning the overall distributions of different domains, we propose Paired Moment Matching (PM2) to align the features of the paired real and synthetic data with the same facial expression. To further improve gender fairness, PM2 matches the features of the real data with a female and a male synthetic image. Our results indicate that synthetic data and the proposed model improve both AU detection performance and fairness across genders, demonstrating its potential to solve AU detection in-the-wild. ",
    "url": "https://arxiv.org/abs/2403.10737",
    "authors": [
      "Liupei Lu",
      "Yufeng Yin",
      "Yuming Gu",
      "Yizhen Wu",
      "Pratusha Prasad",
      "Yajie Zhao",
      "Mohammad Soleymani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10750",
    "title": "Depression Detection on Social Media with Large Language Models",
    "abstract": "Depression harms. However, due to a lack of mental health awareness and fear of stigma, many patients do not actively seek diagnosis and treatment, leading to detrimental outcomes. Depression detection aims to determine whether an individual suffers from depression by analyzing their history of posts on social media, which can significantly aid in early detection and intervention. It mainly faces two key challenges: 1) it requires professional medical knowledge, and 2) it necessitates both high accuracy and explainability. To address it, we propose a novel depression detection system called DORIS, combining medical knowledge and the recent advances in large language models (LLMs). Specifically, to tackle the first challenge, we proposed an LLM-based solution to first annotate whether high-risk texts meet medical diagnostic criteria. Further, we retrieve texts with high emotional intensity and summarize critical information from the historical mood records of users, so-called mood courses. To tackle the second challenge, we combine LLM and traditional classifiers to integrate medical knowledge-guided features, for which the model can also explain its prediction results, achieving both high accuracy and explainability. Extensive experimental results on benchmarking datasets show that, compared to the current best baseline, our approach improves by 0.036 in AUPRC, which can be considered significant, demonstrating the effectiveness of our approach and its high value as an NLP application. ",
    "url": "https://arxiv.org/abs/2403.10750",
    "authors": [
      "Xiaochong Lan",
      "Yiming Cheng",
      "Li Sheng",
      "Chen Gao",
      "Yong Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10751",
    "title": "LIGHTCODE: Light Analytical and Neural Codes for Channels with Feedback",
    "abstract": "The design of reliable and efficient codes for channels with feedback remains a longstanding challenge in communication theory. While significant improvements have been achieved by leveraging deep learning techniques, neural codes often suffer from high computational costs, a lack of interpretability, and limited practicality in resource-constrained settings. We focus on designing low-complexity coding schemes that are interpretable and more suitable for communication systems. We advance both analytical and neural codes. First, we demonstrate that POWERBLAST, an analytical coding scheme inspired by Schalkwijk-Kailath (SK) and Gallager-Nakiboglu (GN) schemes, achieves notable reliability improvements over both SK and GN schemes, outperforming neural codes in high signal-to-noise ratio (SNR) regions. Next, to enhance reliability in low-SNR regions, we propose LIGHTCODE, a lightweight neural code that achieves state-of-the-art reliability while using a fraction of memory and compute compared to existing deep-learning-based codes. Finally, we systematically analyze the learned codes, establishing connections between LIGHTCODE and POWERBLAST, identifying components crucial for performance, and providing interpretation aided by linear regression analysis. ",
    "url": "https://arxiv.org/abs/2403.10751",
    "authors": [
      "Sravan Kumar Ankireddy",
      "Krishna Narayanan",
      "Hyeji Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10760",
    "title": "CORN: Contact-based Object Representation for Nonprehensile Manipulation  of General Unseen Objects",
    "abstract": "Nonprehensile manipulation is essential for manipulating objects that are too thin, large, or otherwise ungraspable in the wild. To sidestep the difficulty of contact modeling in conventional modeling-based approaches, reinforcement learning (RL) has recently emerged as a promising alternative. However, previous RL approaches either lack the ability to generalize over diverse object shapes, or use simple action primitives that limit the diversity of robot motions. Furthermore, using RL over diverse object geometry is challenging due to the high cost of training a policy that takes in high-dimensional sensory inputs. We propose a novel contact-based object representation and pretraining pipeline to tackle this. To enable massively parallel training, we leverage a lightweight patch-based transformer architecture for our encoder that processes point clouds, thus scaling our training across thousands of environments. Compared to learning from scratch, or other shape representation baselines, our representation facilitates both time- and data-efficient learning. We validate the efficacy of our overall system by zero-shot transferring the trained policy to novel real-world objects. Code and videos are available at https://sites.google.com/view/contact-non-prehensile. ",
    "url": "https://arxiv.org/abs/2403.10760",
    "authors": [
      "Yoonyoung Cho",
      "Junhyek Han",
      "Yoontae Cho",
      "Beomjoon Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10766",
    "title": "ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference",
    "abstract": "Inferring unbiased treatment effects has received widespread attention in the machine learning community. In recent years, our community has proposed numerous solutions in standard settings, high-dimensional treatment settings, and even longitudinal settings. While very diverse, the solution has mostly relied on neural networks for inference and simultaneous correction of assignment bias. New approaches typically build on top of previous approaches by proposing new (or refined) architectures and learning algorithms. However, the end result -- a neural-network-based inference machine -- remains unchallenged. In this paper, we introduce a different type of solution in the longitudinal setting: a closed-form ordinary differential equation (ODE). While we still rely on continuous optimization to learn an ODE, the resulting inference machine is no longer a neural network. Doing so yields several advantages such as interpretability, irregular sampling, and a different set of identification assumptions. Above all, we consider the introduction of a completely new type of solution to be our most important contribution as it may spark entirely new innovations in treatment effects in general. We facilitate this by formulating our contribution as a framework that can transform any ODE discovery method into a treatment effects method. ",
    "url": "https://arxiv.org/abs/2403.10766",
    "authors": [
      "Krzysztof Kacprzyk",
      "Samuel Holt",
      "Jeroen Berrevoets",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.10778",
    "title": "HCF-Net: Hierarchical Context Fusion Network for Infrared Small Object  Detection",
    "abstract": "Infrared small object detection is an important computer vision task involving the recognition and localization of tiny objects in infrared images, which usually contain only a few pixels. However, it encounters difficulties due to the diminutive size of the objects and the generally complex backgrounds in infrared images. In this paper, we propose a deep learning method, HCF-Net, that significantly improves infrared small object detection performance through multiple practical modules. Specifically, it includes the parallelized patch-aware attention (PPA) module, dimension-aware selective integration (DASI) module, and multi-dilated channel refiner (MDCR) module. The PPA module uses a multi-branch feature extraction strategy to capture feature information at different scales and levels. The DASI module enables adaptive channel selection and fusion. The MDCR module captures spatial features of different receptive field ranges through multiple depth-separable convolutional layers. Extensive experimental results on the SIRST infrared single-frame image dataset show that the proposed HCF-Net performs well, surpassing other traditional and deep learning models. Code is available at https://github.com/zhengshuchen/HCFNet. ",
    "url": "https://arxiv.org/abs/2403.10778",
    "authors": [
      "Shibiao Xu",
      "ShuChen Zheng",
      "Wenhao Xu",
      "Rongtao Xu",
      "Changwei Wang",
      "Jiguang Zhang",
      "Xiaoqiang Teng",
      "Ao Li",
      "Li Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10787",
    "title": "Time Series Representation Learning with Supervised Contrastive Temporal  Transformer",
    "abstract": "Finding effective representations for time series data is a useful but challenging task. Several works utilize self-supervised or unsupervised learning methods to address this. However, there still remains the open question of how to leverage available label information for better representations. To answer this question, we exploit pre-existing techniques in time series and representation learning domains and develop a simple, yet novel fusion model, called: \\textbf{S}upervised \\textbf{CO}ntrastive \\textbf{T}emporal \\textbf{T}ransformer (SCOTT). We first investigate suitable augmentation methods for various types of time series data to assist with learning change-invariant representations. Secondly, we combine Transformer and Temporal Convolutional Networks in a simple way to efficiently learn both global and local features. Finally, we simplify Supervised Contrastive Loss for representation learning of labelled time series data. We preliminarily evaluate SCOTT on a downstream task, Time Series Classification, using 45 datasets from the UCR archive. The results show that with the representations learnt by SCOTT, even a weak classifier can perform similar to or better than existing state-of-the-art models (best performance on 23/45 datasets and highest rank against 9 baseline models). Afterwards, we investigate SCOTT's ability to address a real-world task, online Change Point Detection (CPD), on two datasets: a human activity dataset and a surgical patient dataset. We show that the model performs with high reliability and efficiency on the online CPD problem ($\\sim$98\\% and $\\sim$97\\% area under precision-recall curve respectively). Furthermore, we demonstrate the model's potential in tackling early detection and show it performs best compared to other candidates. ",
    "url": "https://arxiv.org/abs/2403.10787",
    "authors": [
      "Yuansan Liu",
      "Sudanthi Wijewickrema",
      "Christofer Bester",
      "Stephen O'Leary",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10789",
    "title": "Adversarial Knapsack and Secondary Effects of Common Information for  Cyber Operations",
    "abstract": "Variations of the Flip-It game have been applied to model network cyber operations. While Flip-It can accurately express uncertainty and loss of control, it imposes no essential resource constraints for operations. Capture the flag (CTF) style competitive games, such as Flip-It , entail uncertainties and loss of control, but also impose realistic constraints on resource use. As such, they bear a closer resemblance to actual cyber operations. We formalize a dynamical network control game for CTF competitions and detail the static game for each time step. The static game can be reformulated as instances of a novel optimization problem called Adversarial Knapsack (AK) or Dueling Knapsack (DK) when there are only two players. We define the Adversarial Knapsack optimization problems as a system of interacting Weighted Knapsack problems, and illustrate its applications to general scenarios involving multiple agents with conflicting optimization goals, e.g., cyber operations and CTF games in particular. Common awareness of the scenario, rewards, and costs will set the stage for a non-cooperative game. Critically, rational players may second guess that their AK solution -- with a better response and higher reward -- is possible if opponents predictably play their AK optimal solutions. Thus, secondary reasoning which such as belief modeling of opponents play can be anticipated for rational players and will introduce a type of non-stability where players maneuver for slight reward differentials. To analyze this, we provide the best-response algorithms and simulation software to consider how rational agents may heuristically search for maneuvers. We further summarize insights offered by the game model by predicting that metrics such as Common Vulnerability Scoring System (CVSS) may intensify the secondary reasoning in cyber operations. ",
    "url": "https://arxiv.org/abs/2403.10789",
    "authors": [
      "Jon Goohs",
      "Georgel Savin",
      "Lucas Starks",
      "Josiah Dykstra",
      "William Casey"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10794",
    "title": "Diffusion-Reinforcement Learning Hierarchical Motion Planning in  Adversarial Multi-agent Games",
    "abstract": "Reinforcement Learning- (RL-)based motion planning has recently shown the potential to outperform traditional approaches from autonomous navigation to robot manipulation. In this work, we focus on a motion planning task for an evasive target in a partially observable multi-agent adversarial pursuit-evasion games (PEG). These pursuit-evasion problems are relevant to various applications, such as search and rescue operations and surveillance robots, where robots must effectively plan their actions to gather intelligence or accomplish mission tasks while avoiding detection or capture themselves. We propose a hierarchical architecture that integrates a high-level diffusion model to plan global paths responsive to environment data while a low-level RL algorithm reasons about evasive versus global path-following behavior. Our approach outperforms baselines by 51.2% by leveraging the diffusion model to guide the RL algorithm for more efficient exploration and improves the explanability and predictability. ",
    "url": "https://arxiv.org/abs/2403.10794",
    "authors": [
      "Zixuan Wu",
      "Sean Ye",
      "Manisha Natarajan",
      "Matthew C. Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2403.10801",
    "title": "Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples",
    "abstract": "With the evolution of self-supervised learning, the pre-training paradigm has emerged as a predominant solution within the deep learning landscape. Model providers furnish pre-trained encoders designed to function as versatile feature extractors, enabling downstream users to harness the benefits of expansive models with minimal effort through fine-tuning. Nevertheless, recent works have exposed a vulnerability in pre-trained encoders, highlighting their susceptibility to downstream-agnostic adversarial examples (DAEs) meticulously crafted by attackers. The lingering question pertains to the feasibility of fortifying the robustness of downstream models against DAEs, particularly in scenarios where the pre-trained encoders are publicly accessible to the attackers. In this paper, we initially delve into existing defensive mechanisms against adversarial examples within the pre-training paradigm. Our findings reveal that the failure of current defenses stems from the domain shift between pre-training data and downstream tasks, as well as the sensitivity of encoder parameters. In response to these challenges, we propose Genetic Evolution-Nurtured Adversarial Fine-tuning (Gen-AF), a two-stage adversarial fine-tuning approach aimed at enhancing the robustness of downstream models. Our extensive experiments, conducted across ten self-supervised training methods and six datasets, demonstrate that Gen-AF attains high testing accuracy and robust testing accuracy against state-of-the-art DAEs. ",
    "url": "https://arxiv.org/abs/2403.10801",
    "authors": [
      "Ziqi Zhou",
      "Minghui Li",
      "Wei Liu",
      "Shengshan Hu",
      "Yechao Zhang",
      "Wei Wan",
      "Lulu Xue",
      "Leo Yu Zhang",
      "Dezhong Yao",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10802",
    "title": "Anomaly Detection Based on Isolation Mechanisms: A Survey",
    "abstract": "Anomaly detection is a longstanding and active research area that has many applications in domains such as finance, security, and manufacturing. However, the efficiency and performance of anomaly detection algorithms are challenged by the large-scale, high-dimensional, and heterogeneous data that are prevalent in the era of big data. Isolation-based unsupervised anomaly detection is a novel and effective approach for identifying anomalies in data. It relies on the idea that anomalies are few and different from normal instances, and thus can be easily isolated by random partitioning. Isolation-based methods have several advantages over existing methods, such as low computational complexity, low memory usage, high scalability, robustness to noise and irrelevant features, and no need for prior knowledge or heavy parameter tuning. In this survey, we review the state-of-the-art isolation-based anomaly detection methods, including their data partitioning strategies, anomaly score functions, and algorithmic details. We also discuss some extensions and applications of isolation-based methods in different scenarios, such as detecting anomalies in streaming data, time series, trajectory, and image datasets. Finally, we identify some open challenges and future directions for isolation-based anomaly detection research. ",
    "url": "https://arxiv.org/abs/2403.10802",
    "authors": [
      "Yang Cao",
      "Haolong Xiang",
      "Hang Zhang",
      "Ye Zhu",
      "Kai Ming Ting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10803",
    "title": "Enhancing Out-of-Distribution Detection with Multitesting-based  Layer-wise Feature Fusion",
    "abstract": "Deploying machine learning in open environments presents the challenge of encountering diverse test inputs that differ significantly from the training data. These out-of-distribution samples may exhibit shifts in local or global features compared to the training distribution. The machine learning (ML) community has responded with a number of methods aimed at distinguishing anomalous inputs from original training data. However, the majority of previous studies have primarily focused on the output layer or penultimate layer of pre-trained deep neural networks. In this paper, we propose a novel framework, Multitesting-based Layer-wise Out-of-Distribution (OOD) Detection (MLOD), to identify distributional shifts in test samples at different levels of features through rigorous multiple testing procedure. Our approach distinguishes itself from existing methods as it does not require modifying the structure or fine-tuning of the pre-trained classifier. Through extensive experiments, we demonstrate that our proposed framework can seamlessly integrate with any existing distance-based inspection method while efficiently utilizing feature extractors of varying depths. Our scheme effectively enhances the performance of out-of-distribution detection when compared to baseline methods. In particular, MLOD-Fisher achieves superior performance in general. When trained using KNN on CIFAR10, MLOD-Fisher significantly lowers the false positive rate (FPR) from 24.09% to 7.47% on average compared to merely utilizing the features of the last layer. ",
    "url": "https://arxiv.org/abs/2403.10803",
    "authors": [
      "Jiawei Li",
      "Sitong Li",
      "Shanshan Wang",
      "Yicheng Zeng",
      "Falong Tan",
      "Chuanlong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10807",
    "title": "FlyKD: Graph Knowledge Distillation on the Fly with Curriculum Learning",
    "abstract": "Knowledge Distillation (KD) aims to transfer a more capable teacher model's knowledge to a lighter student model in order to improve the efficiency of the model, making it faster and more deployable. However, the student model's optimization process over the noisy pseudo labels (generated by the teacher model) is tricky and the amount of pseudo labels one can generate is limited due to Out of Memory (OOM) error. In this paper, we propose FlyKD (Knowledge Distillation on the Fly) which enables the generation of virtually unlimited number of pseudo labels, coupled with Curriculum Learning that greatly alleviates the optimization process over the noisy pseudo labels. Empirically, we observe that FlyKD outperforms vanilla KD and the renown Local Structure Preserving Graph Convolutional Network (LSPGCN). Lastly, with the success of Curriculum Learning, we shed light on a new research direction of improving optimization over noisy pseudo labels. ",
    "url": "https://arxiv.org/abs/2403.10807",
    "authors": [
      "Eugene Ku"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10808",
    "title": "Transformer-Based Wireless Traffic Prediction and Network Optimization  in O-RAN",
    "abstract": "This paper introduces an innovative method for predicting wireless network traffic in concise temporal intervals for Open Radio Access Networks (O-RAN) using a transformer architecture, which is the machine learning model behind generative AI tools. Depending on the anticipated traffic, the system either launches a reinforcement learning-based traffic steering xApp or a cell sleeping rApp to enhance performance metrics like throughput or energy efficiency. Our simulation results demonstrate that the proposed traffic prediction-based network optimization mechanism matches the performance of standalone RAN applications (rApps/ xApps) that are always on during the whole simulation time while offering on-demand activation. This feature is particularly advantageous during instances of abrupt fluctuations in traffic volume. Rather than persistently operating specific applications irrespective of the actual incoming traffic conditions, the proposed prediction-based method increases the average energy efficiency by 39.7% compared to the \"Always on Traffic Steering xApp\" and achieves 10.1% increase in throughput compared to the \"Always on Cell Sleeping rApp\". The simulation has been conducted over 24 hours, emulating a whole day traffic pattern for a dense urban area. ",
    "url": "https://arxiv.org/abs/2403.10808",
    "authors": [
      "Md Arafat Habib",
      "Pedro Enrique Iturria-Rivera",
      "Yigit Ozcan",
      "Medhat Elsayed",
      "Majid Bavand",
      "Raimundus Gaigalas",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.10814",
    "title": "DarkGS: Learning Neural Illumination and 3D Gaussians Relighting for  Robotic Exploration in the Dark",
    "abstract": "Humans have the remarkable ability to construct consistent mental models of an environment, even under limited or varying levels of illumination. We wish to endow robots with this same capability. In this paper, we tackle the challenge of constructing a photorealistic scene representation under poorly illuminated conditions and with a moving light source. We approach the task of modeling illumination as a learning problem, and utilize the developed illumination model to aid in scene reconstruction. We introduce an innovative framework that uses a data-driven approach, Neural Light Simulators (NeLiS), to model and calibrate the camera-light system. Furthermore, we present DarkGS, a method that applies NeLiS to create a relightable 3D Gaussian scene model capable of real-time, photorealistic rendering from novel viewpoints. We show the applicability and robustness of our proposed simulator and system in a variety of real-world environments. ",
    "url": "https://arxiv.org/abs/2403.10814",
    "authors": [
      "Tianyi Zhang",
      "Kaining Huang",
      "Weiming Zhi",
      "Matthew Johnson-Roberson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10821",
    "title": "H3-Mapping: Quasi-Heterogeneous Feature Grids for Real-time Dense  Mapping Using Hierarchical Hybrid Representation",
    "abstract": "In recent years, implicit online dense mapping methods have achieved high-quality reconstruction results, showcasing great potential in robotics, AR/VR, and digital twins applications. However, existing methods struggle with slow texture modeling which limits their real-time performance. To address these limitations, we propose a NeRF-based dense mapping method that enables faster and higher-quality reconstruction. To improve texture modeling, we introduce quasi-heterogeneous feature grids, which inherit the fast querying ability of uniform feature grids while adapting to varying levels of texture complexity. Besides, we present a gradient-aided coverage-maximizing strategy for keyframe selection that enables the selected keyframes to exhibit a closer focus on rich-textured regions and a broader scope for weak-textured areas. Experimental results demonstrate that our method surpasses existing NeRF-based approaches in texture fidelity, geometry accuracy, and time consumption. The code for our method will be available at: https://github.com/SYSU-STAR/H3-Mapping. ",
    "url": "https://arxiv.org/abs/2403.10821",
    "authors": [
      "Chenxing Jiang",
      "Yiming Luo",
      "Boyu Zhou",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10828",
    "title": "Data Availability and Decentralization: New Techniques for zk-Rollups in  Layer 2 Blockchain Networks",
    "abstract": "The scalability limitations of public blockchains have hindered their widespread adoption in real-world applications. While the Ethereum community is pushing forward in zk-rollup (zero-knowledge rollup) solutions, such as introducing the ``blob transaction'' in EIP-4844, Layer 2 networks encounter a data availability problem: storing transactions completely off-chain poses a risk of data loss, particularly when Layer 2 nodes are untrusted. Additionally, building Layer 2 blocks requires significant computational power, compromising the decentralization aspect of Layer 2 networks. This paper introduces new techniques to address the data availability and decentralization challenges in Layer 2 networks. To ensure data availability, we introduce the concept of ``proof of download'', which ensures that Layer 2 nodes cannot aggregate transactions without downloading historical data. Additionally, we design a ``proof of storage'' scheme that punishes nodes who maliciously delete historical data. For decentralization, we introduce a new role separation for Layer 2, allowing nodes with limited hardware to participate. To further avoid collusion among Layer 2 nodes, we design a ``proof of luck'' scheme, which also provides robust protection against maximal extractable value (MEV) attacks. Experimental results show our techniques not only ensure data availability but also improve overall network efficiency, which implies the practicality and potential of our techniques for real-world implementation. ",
    "url": "https://arxiv.org/abs/2403.10828",
    "authors": [
      "Chengpeng Huang",
      "Rui Song",
      "Shang Gao",
      "Yu Guo",
      "Bin Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10832",
    "title": "Joint Power Allocation and Beamforming for In-band Full-duplex  Multi-cell Multi-user Networks",
    "abstract": "This paper investigates a robust joint power allocation and beamforming scheme for in-band full-duplex multi-cell multi-user (IBFD-MCMU) networks. A mean-squared error (MSE) minimization problem is formulated with constraints on the power budgets and residual self-interference (RSI) power. The problem is not convex, so we decompose it into two sub-problems: interference management beamforming and power allocation, and give closed-form solutions to the sub-problems. Then we propose an iterative algorithm to yield an overall solution. The computational complexity and convergence behavior of the algorithm are analyzed. Our method can enhance the analog self-interference cancellation (ASIC) depth provided by the precoder with less effect on the downlink communication than the existing null-space projection method, inspiring a low-cost but efficient IBFD transceiver design. It can achieve 42.9% of IBFD gain in terms of spectral efficiency with only antenna isolation, while this value increases to 60.9% with further digital self-interference cancellation (DSIC). Numerical results illustrate that our algorithm is robust to hardware impairments and channel uncertainty. With sufficient ASIC depth, our method reduces the computation time by at least 20% than the existing scheme due to its faster convergence speed at the cost of < 12.5% sum rate loss. The benefit is much more significant with single-antenna users that our algorithm saves at least 40% of the computation time at the cost of < 10% sum rate reduction. ",
    "url": "https://arxiv.org/abs/2403.10832",
    "authors": [
      "Haifeng Luo",
      "Navneet Garg",
      "Mark Holm",
      "Tharmalingam Ratnarajah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.10834",
    "title": "SF(DA)$^2$: Source-free Domain Adaptation Through the Lens of Data  Augmentation",
    "abstract": "In the face of the deep learning model's vulnerability to domain shift, source-free domain adaptation (SFDA) methods have been proposed to adapt models to new, unseen target domains without requiring access to source domain data. Although the potential benefits of applying data augmentation to SFDA are attractive, several challenges arise such as the dependence on prior knowledge of class-preserving transformations and the increase in memory and computational requirements. In this paper, we propose Source-free Domain Adaptation Through the Lens of Data Augmentation (SF(DA)$^2$), a novel approach that leverages the benefits of data augmentation without suffering from these challenges. We construct an augmentation graph in the feature space of the pretrained model using the neighbor relationships between target features and propose spectral neighborhood clustering to identify partitions in the prediction space. Furthermore, we propose implicit feature augmentation and feature disentanglement as regularization loss functions that effectively utilize class semantic information within the feature space. These regularizers simulate the inclusion of an unlimited number of augmented target features into the augmentation graph while minimizing computational and memory demands. Our method shows superior adaptation performance in SFDA scenarios, including 2D image and 3D point cloud datasets and a highly imbalanced dataset. ",
    "url": "https://arxiv.org/abs/2403.10834",
    "authors": [
      "Uiwon Hwang",
      "Jonghyun Lee",
      "Juhyeon Shin",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10838",
    "title": "Two-step Automated Cybercrime Coded Word Detection using Multi-level  Representation Learning",
    "abstract": "In social network service platforms, crime suspects are likely to use cybercrime coded words for communication by adding criminal meanings to existing words or replacing them with similar words. For instance, the word 'ice' is often used to mean methamphetamine in drug crimes. To analyze the nature of cybercrime and the behavior of criminals, quickly detecting such words and further understanding their meaning are critical. In the automated cybercrime coded word detection problem, it is difficult to collect a sufficient amount of training data for supervised learning and to directly apply language models that utilize context information to better understand natural language. To overcome these limitations, we propose a new two-step approach, in which a mean latent vector is constructed for each cybercrime through one of five different AutoEncoder models in the first step, and cybercrime coded words are detected based on multi-level latent representations in the second step. Moreover, to deeply understand cybercrime coded words detected through the two-step approach, we propose three novel methods: (1) Detection of new words recently coined, (2) Detection of words frequently appeared in both drug and sex crimes, and (3) Automatic generation of word taxonomy. According to our experimental results, among various AutoEncoder models, the stacked AutoEncoder model shows the best performance. Additionally, the F1-score of the two-step approach is 0.991, which is higher than 0.987 and 0.903 of the existing dark-GloVe and dark-BERT models. By analyzing the experimental results of the three proposed methods, we can gain a deeper understanding of drug and sex crimes. ",
    "url": "https://arxiv.org/abs/2403.10838",
    "authors": [
      "Yongyeon Kim",
      "Byung-Won On",
      "Ingyu Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10840",
    "title": "MSI-NeRF: Linking Omni-Depth with View Synthesis through Multi-Sphere  Image aided Generalizable Neural Radiance Field",
    "abstract": "Panoramic observation using fisheye cameras is significant in robot perception, reconstruction, and remote operation. However, panoramic images synthesized by traditional methods lack depth information and can only provide three degrees-of-freedom (3DoF) rotation rendering in virtual reality applications. To fully preserve and exploit the parallax information within the original fisheye cameras, we introduce MSI-NeRF, which combines deep learning omnidirectional depth estimation and novel view rendering. We first construct a multi-sphere image as a cost volume through feature extraction and warping of the input images. It is then processed by geometry and appearance decoders, respectively. Unlike methods that regress depth maps directly, we further build an implicit radiance field using spatial points and interpolated 3D feature vectors as input. In this way, we can simultaneously realize omnidirectional depth estimation and 6DoF view synthesis. Our method is trained in a semi-self-supervised manner. It does not require target view images and only uses depth data for supervision. Our network has the generalization ability to reconstruct unknown scenes efficiently using only four images. Experimental results show that our method outperforms existing methods in depth estimation and novel view synthesis tasks. ",
    "url": "https://arxiv.org/abs/2403.10840",
    "authors": [
      "Dongyu Yan",
      "Guanyu Huang",
      "Fengyu Quan",
      "Haoyao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10842",
    "title": "Twin Transformer using Gated Dynamic Learnable Attention mechanism for  Fault Detection and Diagnosis in the Tennessee Eastman Process",
    "abstract": "Fault detection and diagnosis (FDD) is a crucial task for ensuring the safety and efficiency of industrial processes. We propose a novel FDD methodology for the Tennessee Eastman Process (TEP), a widely used benchmark for chemical process control. The model employs two separate Transformer branches, enabling independent processing of input data and potential extraction of diverse information. A novel attention mechanism, Gated Dynamic Learnable Attention (GDLAttention), is introduced which integrates a gating mechanism and dynamic learning capabilities. The gating mechanism modulates the attention weights, allowing the model to focus on the most relevant parts of the input. The dynamic learning approach adapts the attention strategy during training, potentially leading to improved performance. The attention mechanism uses a bilinear similarity function, providing greater flexibility in capturing complex relationships between query and key vectors. In order to assess the effectiveness of our approach, we tested it against 21 and 18 distinct fault scenarios in TEP, and compared its performance with several established FDD techniques. The outcomes indicate that the method outperforms others in terms of accuracy, false alarm rate, and misclassification rate. This underscores the robustness and efficacy of the approach for FDD in intricate industrial processes. ",
    "url": "https://arxiv.org/abs/2403.10842",
    "authors": [
      "Mohammad Ali Labbaf-Khaniki",
      "Mohammad Manthouri",
      "Hanieh Ajami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10849",
    "title": "RETINAQA : A Knowledge Base Question Answering Model Robust to both  Answerable and Unanswerable Questions",
    "abstract": "State-of-the-art KBQA models assume answerability of questions. Recent research has shown that while these can be adapted to detect unaswerability with suitable training and thresholding, this comes at the expense of accuracy for answerable questions, and no single model is able to handle all categories of unanswerability. We propose a new model for KBQA named RetinaQA that is robust against unaswerability. It complements KB-traversal based logical form retrieval with sketch-filling based logical form construction. This helps with questions that have valid logical forms but no data paths in the KB leading to an answer. Additionally, it uses discrimination instead of generation to better identify questions that do not have valid logical forms. We demonstrate that RetinaQA significantly outperforms adaptations of state-of-the-art KBQA models across answerable and unanswerable questions, while showing robustness across unanswerability categories. Remarkably, it also establishes a new state-of-the art for answerable KBQA by surpassing existing models ",
    "url": "https://arxiv.org/abs/2403.10849",
    "authors": [
      "Prayushi Faldu",
      "Indrajit Bhattacharya",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10850",
    "title": "GAgent: An Adaptive Rigid-Soft Gripping Agent with Vision Language  Models for Complex Lighting Environments",
    "abstract": "This paper introduces GAgent: an Gripping Agent designed for open-world environments that provides advanced cognitive abilities via VLM agents and flexible grasping abilities with variable stiffness soft grippers. GAgent comprises three primary components - Prompt Engineer module, Visual-Language Model (VLM) core and Workflow module. These three modules enhance gripper success rates by recognizing objects and materials and accurately estimating grasp area even under challenging lighting conditions. As part of creativity, researchers also created a bionic hybrid soft gripper with variable stiffness capable of gripping heavy loads while still gently engaging objects. This intelligent agent, featuring VLM-based cognitive processing with bionic design, shows promise as it could potentially benefit UAVs in various scenarios. ",
    "url": "https://arxiv.org/abs/2403.10850",
    "authors": [
      "Zhuowei Li",
      "Miao Zhang",
      "Xiaotian Lin",
      "Meng Yin",
      "Shuai Lu",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10868",
    "title": "Approximation Ratio of the Min-Degree Greedy Algorithm for Maximum  Independent Set on Interval and Chordal Graphs",
    "abstract": "In this article we prove that the minimum-degree greedy algorithm, with adversarial tie-breaking, is a $(2/3)$-approximation for the Maximum Independent Set problem on interval graphs. We show that this is tight, even on unit interval graphs of maximum degree 3. We show that on chordal graphs, the greedy algorithm is a $(1/2)$-approximation and that this is again tight. These results contrast with the known (tight) approximation ratio of $\\frac{3}{\\Delta+2}$ of the greedy algorithm for general graphs of maximum degree $\\Delta$. ",
    "url": "https://arxiv.org/abs/2403.10868",
    "authors": [
      "Steven Chaplick",
      "Martin Frohn",
      "Steven Kelk",
      "Johann Lottermoser",
      "Matus Mihalak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.10882",
    "title": "Optimizing Language Augmentation for Multilingual Large Language Models:  A Case Study on Korean",
    "abstract": "Large language models (LLMs) use pretraining to predict the subsequent word; however, their expansion requires significant computing resources. Numerous big tech companies and research institutes have developed multilingual LLMs (MLLMs) to meet current demands, overlooking less-resourced languages (LRLs). This study proposed three strategies to enhance the performance of LRLs based on the publicly available MLLMs. First, the MLLM vocabularies of LRLs were expanded to enhance expressiveness. Second, bilingual data were used for pretraining to align the high- and less-resourced languages. Third, a high-quality small-scale instruction dataset was constructed and instruction-tuning was performed to augment the LRL. The experiments employed the Llama2 model and Korean was used as the LRL, which was quantitatively evaluated against other developed LLMs across eight tasks. Furthermore, a qualitative assessment was performed based on human evaluation and GPT4. Experimental results showed that our proposed Bllossom model exhibited superior performance in qualitative analyses compared to previously proposed Korean monolingual models. ",
    "url": "https://arxiv.org/abs/2403.10882",
    "authors": [
      "ChangSu Choi",
      "Yongbin Jeong",
      "Seoyoon Park",
      "InHo Won",
      "HyeonSeok Lim",
      "SangMin Kim",
      "Yejee Kang",
      "Chanhyuk Yoon",
      "Jaewan Park",
      "Yiseul Lee",
      "HyeJin Lee",
      "Younggyun Hahm",
      "Hansaem Kim",
      "KyungTae Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10883",
    "title": "Improving Adversarial Transferability of Visual-Language Pre-training  Models through Collaborative Multimodal Interaction",
    "abstract": "Despite the substantial advancements in Vision-Language Pre-training (VLP) models, their susceptibility to adversarial attacks poses a significant challenge. Existing work rarely studies the transferability of attacks on VLP models, resulting in a substantial performance gap from white-box attacks. We observe that prior work overlooks the interaction mechanisms between modalities, which plays a crucial role in understanding the intricacies of VLP models. In response, we propose a novel attack, called Collaborative Multimodal Interaction Attack (CMI-Attack), leveraging modality interaction through embedding guidance and interaction enhancement. Specifically, attacking text at the embedding level while preserving semantics, as well as utilizing interaction image gradients to enhance constraints on perturbations of texts and images. Significantly, in the image-text retrieval task on Flickr30K dataset, CMI-Attack raises the transfer success rates from ALBEF to TCL, $\\text{CLIP}_{\\text{ViT}}$ and $\\text{CLIP}_{\\text{CNN}}$ by 8.11%-16.75% over state-of-the-art methods. Moreover, CMI-Attack also demonstrates superior performance in cross-task generalization scenarios. Our work addresses the underexplored realm of transfer attacks on VLP models, shedding light on the importance of modality interaction for enhanced adversarial robustness. ",
    "url": "https://arxiv.org/abs/2403.10883",
    "authors": [
      "Jiyuan Fu",
      "Zhaoyu Chen",
      "Kaixun Jiang",
      "Haijing Guo",
      "Jiafeng Wang",
      "Shuyong Gao",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.10894",
    "title": "Towards Robustness and Diversity: Continual Learning in Dialog  Generation with Text-Mixup and Batch Nuclear-Norm Maximization",
    "abstract": "In our dynamic world where data arrives in a continuous stream, continual learning enables us to incrementally add new tasks/domains without the need to retrain from scratch. A major challenge in continual learning of language model is catastrophic forgetting, the tendency of models to forget knowledge from previously trained tasks/domains when training on new ones. This paper studies dialog generation under the continual learning setting. We propose a novel method that 1) uses \\textit{Text-Mixup} as data augmentation to avoid model overfitting on replay memory and 2) leverages Batch-Nuclear Norm Maximization (BNNM) to alleviate the problem of mode collapse. Experiments on a $37$-domain task-oriented dialog dataset and DailyDialog (a $10$-domain chitchat dataset) demonstrate that our proposed approach outperforms the state-of-the-art in continual learning. ",
    "url": "https://arxiv.org/abs/2403.10894",
    "authors": [
      "Zihan Wang",
      "Jiayu Xiao",
      "Mengxiang Li",
      "Zhongjiang He",
      "Yongxiang Li",
      "Chao Wang",
      "Shuangyong Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10897",
    "title": "Rethinking Multi-view Representation Learning via Distilled  Disentangling",
    "abstract": "Multi-view representation learning aims to derive robust representations that are both view-consistent and view-specific from diverse data sources. This paper presents an in-depth analysis of existing approaches in this domain, highlighting a commonly overlooked aspect: the redundancy between view-consistent and view-specific representations. To this end, we propose an innovative framework for multi-view representation learning, which incorporates a technique we term 'distilled disentangling'. Our method introduces the concept of masked cross-view prediction, enabling the extraction of compact, high-quality view-consistent representations from various sources without incurring extra computational overhead. Additionally, we develop a distilled disentangling module that efficiently filters out consistency-related information from multi-view representations, resulting in purer view-specific representations. This approach significantly reduces redundancy between view-consistent and view-specific representations, enhancing the overall efficiency of the learning process. Our empirical evaluations reveal that higher mask ratios substantially improve the quality of view-consistent representations. Moreover, we find that reducing the dimensionality of view-consistent representations relative to that of view-specific representations further refines the quality of the combined representations. Our code is accessible at: https://github.com/Guanzhou-Ke/MRDD. ",
    "url": "https://arxiv.org/abs/2403.10897",
    "authors": [
      "Guanzhou Ke",
      "Bo Wang",
      "Xiaoli Wang",
      "Shengfeng He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.10904",
    "title": "Urban Sound Propagation: a Benchmark for 1-Step Generative Modeling of  Complex Physical Systems",
    "abstract": "Data-driven modeling of complex physical systems is receiving a growing amount of attention in the simulation and machine learning communities. Since most physical simulations are based on compute-intensive, iterative implementations of differential equation systems, a (partial) replacement with learned, 1-step inference models has the potential for significant speedups in a wide range of application areas. In this context, we present a novel benchmark for the evaluation of 1-step generative learning models in terms of speed and physical correctness. Our Urban Sound Propagation benchmark is based on the physically complex and practically relevant, yet intuitively easy to grasp task of modeling the 2d propagation of waves from a sound source in an urban environment. We provide a dataset with 100k samples, where each sample consists of pairs of real 2d building maps drawn from OpenStreetmap, a parameterized sound source, and a simulated ground truth sound propagation for the given scene. The dataset provides four different simulation tasks with increasing complexity regarding reflection, diffraction and source variance. A first baseline evaluation of common generative U-Net, GAN and Diffusion models shows, that while these models are very well capable of modeling sound propagations in simple cases, the approximation of sub-systems represented by higher order equations systematically fails. Information about the dataset, download instructions and source codes are provided on our anonymous website: https://www.urban-sound-data.org. ",
    "url": "https://arxiv.org/abs/2403.10904",
    "authors": [
      "Martin Spitznagel",
      "Janis Keuper"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.10906",
    "title": "HourglassNeRF: Casting an Hourglass as a Bundle of Rays for Few-shot  Neural Rendering",
    "abstract": "Recent advancements in the Neural Radiance Field (NeRF) have bolstered its capabilities for novel view synthesis, yet its reliance on dense multi-view training images poses a practical challenge. Addressing this, we propose HourglassNeRF, an effective regularization-based approach with a novel hourglass casting strategy. Our proposed hourglass is conceptualized as a bundle of additional rays within the area between the original input ray and its corresponding reflection ray, by featurizing the conical frustum via Integrated Positional Encoding (IPE). This design expands the coverage of unseen views and enables an adaptive high-frequency regularization based on target pixel photo-consistency. Furthermore, we propose luminance consistency regularization based on the Lambertian assumption, which is known to be effective for training a set of augmented rays under the few-shot setting. Leveraging the inherent property of a Lambertian surface, which retains consistent luminance irrespective of the viewing angle, we assume our proposed hourglass as a collection of flipped diffuse reflection rays and enhance the luminance consistency between the original input ray and its corresponding hourglass, resulting in more physically grounded training framework and performance improvement. Our HourglassNeRF outperforms its baseline and achieves competitive results on multiple benchmarks with sharply rendered fine details. The code will be available. ",
    "url": "https://arxiv.org/abs/2403.10906",
    "authors": [
      "Seunghyeon Seo",
      "Yeonjin Chang",
      "Jayeon Yoo",
      "Seungwoo Lee",
      "Hojun Lee",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10910",
    "title": "Graph Regularized NMF with L20-norm for Unsupervised Feature Learning",
    "abstract": "Nonnegative Matrix Factorization (NMF) is a widely applied technique in the fields of machine learning and data mining. Graph Regularized Non-negative Matrix Factorization (GNMF) is an extension of NMF that incorporates graph regularization constraints. GNMF has demonstrated exceptional performance in clustering and dimensionality reduction, effectively discovering inherent low-dimensional structures embedded within high-dimensional spaces. However, the sensitivity of GNMF to noise limits its stability and robustness in practical applications. In order to enhance feature sparsity and mitigate the impact of noise while mining row sparsity patterns in the data for effective feature selection, we introduce the $\\ell_{2,0}$-norm constraint as the sparsity constraints for GNMF. We propose an unsupervised feature learning framework based on GNMF\\_$\\ell_{20}$ and devise an algorithm based on PALM and its accelerated version to address this problem. Additionally, we establish the convergence of the proposed algorithms and validate the efficacy and superiority of our approach through experiments conducted on both simulated and real image data. ",
    "url": "https://arxiv.org/abs/2403.10910",
    "authors": [
      "Zhen Wang",
      "Wenwen Min"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10912",
    "title": "Automatic location detection based on deep learning",
    "abstract": "The proliferation of digital images and the advancements in deep learning have paved the way for innovative solutions in various domains, especially in the field of image classification. Our project presents an in-depth study and implementation of an image classification system specifically tailored to identify and classify images of Indian cities. Drawing from an extensive dataset, our model classifies images into five major Indian cities: Ahmedabad, Delhi, Kerala, Kolkata, and Mumbai to recognize the distinct features and characteristics of each city/state. To achieve high precision and recall rates, we adopted two approaches. The first, a vanilla Convolutional Neural Network (CNN) and then we explored the power of transfer learning by leveraging the VGG16 model. The vanilla CNN achieved commendable accuracy and the VGG16 model achieved a test accuracy of 63.6%. Evaluations highlighted the strengths and potential areas of improvement, positioning our model as not only competitive but also scalable for broader applications. With an emphasis on open-source ethos, our work aims to contribute to the community, encouraging further development and diverse applications. Our findings demonstrate the potential applications in tourism, urban planning, and even real-time location identification systems, among others. ",
    "url": "https://arxiv.org/abs/2403.10912",
    "authors": [
      "Anjali Karangiya",
      "Anirudh Sharma",
      "Divax Shah",
      "Kartavya Badgujar",
      "Dr. Chintan Thacker",
      "Dainik Dave"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10916",
    "title": "FishNet: Deep Neural Networks for Low-Cost Fish Stock Estimation",
    "abstract": "Fish stock assessment often involves manual fish counting by taxonomy specialists, which is both time-consuming and costly. We propose an automated computer vision system that performs both taxonomic classification and fish size estimation from images taken with a low-cost digital camera. The system first performs object detection and segmentation using a Mask R-CNN to identify individual fish from images containing multiple fish, possibly consisting of different species. Then each fish species is classified and the predicted length using separate machine learning models. These models are trained on a dataset of 50,000 hand-annotated images containing 163 different fish species, ranging in length from 10cm to 250cm. Evaluated on held-out test data, our system achieves a $92\\%$ intersection over union on the fish segmentation task, a $89\\%$ top-1 classification accuracy on single fish species classification, and a $2.3$~cm mean error on the fish length estimation task. ",
    "url": "https://arxiv.org/abs/2403.10916",
    "authors": [
      "Moseli Mots'oehli",
      "Anton Nikolaev",
      "Wawan B. IGede",
      "John Lynham",
      "Peter J. Mous",
      "Peter Sadowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2403.10920",
    "title": "Batch-oriented Element-wise Approximate Activation for  Privacy-Preserving Neural Networks",
    "abstract": "Privacy-Preserving Neural Networks (PPNN) are advanced to perform inference without breaching user privacy, which can serve as an essential tool for medical diagnosis to simultaneously achieve big data utility and privacy protection. As one of the key techniques to enable PPNN, Fully Homomorphic Encryption (FHE) is facing a great challenge that homomorphic operations cannot be easily adapted for non-linear activation calculations. In this paper, batch-oriented element-wise data packing and approximate activation are proposed, which train linear low-degree polynomials to approximate the non-linear activation function - ReLU. Compared with other approximate activation methods, the proposed fine-grained, trainable approximation scheme can effectively reduce the accuracy loss caused by approximation errors. Meanwhile, due to element-wise data packing, a large batch of images can be packed and inferred concurrently, leading to a much higher utility ratio of ciphertext slots. Therefore, although the total inference time increases sharply, the amortized time for each image actually decreases, especially when the batch size increases. Furthermore, knowledge distillation is adopted in the training process to further enhance the inference accuracy. Experiment results show that when ciphertext inference is performed on 4096 input images, compared with the current most efficient channel-wise method, the inference accuracy is improved by 1.65%, and the amortized inference time is reduced by 99.5%. ",
    "url": "https://arxiv.org/abs/2403.10920",
    "authors": [
      "Peng Zhang",
      "Ao Duan",
      "Xianglu Zou",
      "Yuhong Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10925",
    "title": "Learning Dual-Level Deformable Implicit Representation for Real-World  Scale Arbitrary Super-Resolution",
    "abstract": "Scale arbitrary super-resolution based on implicit image function gains increasing popularity since it can better represent the visual world in a continuous manner. However, existing scale arbitrary works are trained and evaluated on simulated datasets, where low-resolution images are generated from their ground truths by the simplest bicubic downsampling. These models exhibit limited generalization to real-world scenarios due to the greater complexity of real-world degradations. To address this issue, we build a RealArbiSR dataset, a new real-world super-resolution benchmark with both integer and non-integer scaling factors for the training and evaluation of real-world scale arbitrary super-resolution. Moreover, we propose a Dual-level Deformable Implicit Representation (DDIR) to solve real-world scale arbitrary super-resolution. Specifically, we design the appearance embedding and deformation field to handle both image-level and pixel-level deformations caused by real-world degradations. The appearance embedding models the characteristics of low-resolution inputs to deal with photometric variations at different scales, and the pixel-based deformation field learns RGB differences which result from the deviations between the real-world and simulated degradations at arbitrary coordinates. Extensive experiments show our trained model achieves state-of-the-art performance on the RealArbiSR and RealSR benchmarks for real-world scale arbitrary super-resolution. Our dataset as well as source code will be publicly available. ",
    "url": "https://arxiv.org/abs/2403.10925",
    "authors": [
      "Zhiheng Li",
      "Muheng Li",
      "Jixuan Fan",
      "Lei Chen",
      "Yansong Tang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10935",
    "title": "Understanding Robustness of Visual State Space Models for Image  Classification",
    "abstract": "Visual State Space Model (VMamba) has recently emerged as a promising architecture, exhibiting remarkable performance in various computer vision tasks. However, its robustness has not yet been thoroughly studied. In this paper, we delve into the robustness of this architecture through comprehensive investigations from multiple perspectives. Firstly, we investigate its robustness to adversarial attacks, employing both whole-image and patch-specific adversarial attacks. Results demonstrate superior adversarial robustness compared to Transformer architectures while revealing scalability weaknesses. Secondly, the general robustness of VMamba is assessed against diverse scenarios, including natural adversarial examples, out-of-distribution data, and common corruptions. VMamba exhibits exceptional generalizability with out-of-distribution data but shows scalability weaknesses against natural adversarial examples and common corruptions. Additionally, we explore VMamba's gradients and back-propagation during white-box attacks, uncovering unique vulnerabilities and defensive capabilities of its novel components. Lastly, the sensitivity of VMamba to image structure variations is examined, highlighting vulnerabilities associated with the distribution of disturbance areas and spatial information, with increased susceptibility closer to the image center. Through these comprehensive studies, we contribute to a deeper understanding of VMamba's robustness, providing valuable insights for refining and advancing the capabilities of deep neural networks in computer vision applications. ",
    "url": "https://arxiv.org/abs/2403.10935",
    "authors": [
      "Chengbin Du",
      "Yanxi Li",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10939",
    "title": "Improving the Robustness of Dense Retrievers Against Typos via  Multi-Positive Contrastive Learning",
    "abstract": "Dense retrieval has become the new paradigm in passage retrieval. Despite its effectiveness on typo-free queries, it is not robust when dealing with queries that contain typos. Current works on improving the typo-robustness of dense retrievers combine (i) data augmentation to obtain the typoed queries during training time with (ii) additional robustifying subtasks that aim to align the original, typo-free queries with their typoed variants. Even though multiple typoed variants are available as positive samples per query, some methods assume a single positive sample and a set of negative ones per anchor and tackle the robustifying subtask with contrastive learning; therefore, making insufficient use of the multiple positives (typoed queries). In contrast, in this work, we argue that all available positives can be used at the same time and employ contrastive learning that supports multiple positives (multi-positive). Experimental results on two datasets show that our proposed approach of leveraging all positives simultaneously and employing multi-positive contrastive learning on the robustifying subtask yields improvements in robustness against using contrastive learning with a single positive. ",
    "url": "https://arxiv.org/abs/2403.10939",
    "authors": [
      "Georgios Sidiropoulos",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.10943",
    "title": "MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent  Recognition and Out-of-scope Detection in Conversations",
    "abstract": "Multimodal intent recognition poses significant challenges, requiring the incorporation of non-verbal modalities from real-world contexts to enhance the comprehension of human intentions. Existing benchmark datasets are limited in scale and suffer from difficulties in handling out-of-scope samples that arise in multi-turn conversational interactions. We introduce MIntRec2.0, a large-scale benchmark dataset for multimodal intent recognition in multi-party conversations. It contains 1,245 dialogues with 15,040 samples, each annotated within a new intent taxonomy of 30 fine-grained classes. Besides 9,304 in-scope samples, it also includes 5,736 out-of-scope samples appearing in multi-turn contexts, which naturally occur in real-world scenarios. Furthermore, we provide comprehensive information on the speakers in each utterance, enriching its utility for multi-party conversational research. We establish a general framework supporting the organization of single-turn and multi-turn dialogue data, modality feature extraction, multimodal fusion, as well as in-scope classification and out-of-scope detection. Evaluation benchmarks are built using classic multimodal fusion methods, ChatGPT, and human evaluators. While existing methods incorporating nonverbal information yield improvements, effectively leveraging context information and detecting out-of-scope samples remains a substantial challenge. Notably, large language models exhibit a significant performance gap compared to humans, highlighting the limitations of machine learning methods in the cognitive intent understanding task. We believe that MIntRec2.0 will serve as a valuable resource, providing a pioneering foundation for research in human-machine conversational interactions, and significantly facilitating related applications. The full dataset and codes are available at https://github.com/thuiar/MIntRec2.0. ",
    "url": "https://arxiv.org/abs/2403.10943",
    "authors": [
      "Hanlei Zhang",
      "Xin Wang",
      "Hua Xu",
      "Qianrui Zhou",
      "Kai Gao",
      "Jianhua Su",
      "jinyue Zhao",
      "Wenrui Li",
      "Yanting Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10963",
    "title": "Pointer-Generator Networks for Low-Resource Machine Translation: Don't  Copy That!",
    "abstract": "While Transformer-based neural machine translation (NMT) is very effective in high-resource settings, many languages lack the necessary large parallel corpora to benefit from it. In the context of low-resource (LR) MT between two closely-related languages, a natural intuition is to seek benefits from structural \"shortcuts\", such as copying subwords from the source to the target, given that such language pairs often share a considerable number of identical words, cognates, and borrowings. We test Pointer-Generator Networks for this purpose for six language pairs over a variety of resource ranges, and find weak improvements for most settings. However, analysis shows that the model does not show greater improvements for closely-related vs. more distant language pairs, or for lower resource ranges, and that the models do not exhibit the expected usage of the mechanism for shared subwords. Our discussion of the reasons for this behaviour highlights several general challenges for LR NMT, such as modern tokenization strategies, noisy real-world conditions, and linguistic complexities. We call for better scrutiny of linguistically motivated improvements to NMT given the blackbox nature of Transformer models, as well as for a focus on the above problems in the field. ",
    "url": "https://arxiv.org/abs/2403.10963",
    "authors": [
      "Niyati Bafna",
      "David Yarowsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10966",
    "title": "Robust Co-Design of Canonical Underactuated Systems for Increased  Certifiable Stability",
    "abstract": "Optimal behaviours of a system to perform a specific task can be achieved by leveraging the coupling between trajectory optimization, stabilization, and design optimization. This approach is particularly advantageous for underactuated systems, which are systems that have fewer actuators than degrees of freedom and thus require for more elaborate control systems. This paper proposes a novel co-design algorithm, namely Robust Trajectory Control with Design optimization (RTC-D). An inner optimization layer (RTC) simultaneously performs direct transcription (DIRTRAN) to find a nominal trajectory while computing optimal hyperparameters for a stabilizing time-varying linear quadratic regulator (TVLQR). RTC-D augments RTC with a design optimization layer, maximizing the system's robustness through a time-varying Lyapunov-based region of attraction (ROA) analysis. This analysis provides a formal guarantee of stability for a set of off-nominal states. The proposed algorithm has been tested on two different underactuated systems: the torque-limited simple pendulum and the cart-pole. Extensive simulations of off-nominal initial conditions demonstrate improved robustness, while real-system experiments show increased insensitivity to torque disturbances. ",
    "url": "https://arxiv.org/abs/2403.10966",
    "authors": [
      "Federico Girlanda",
      "Lasse Shala",
      "Shivesh Kumar",
      "Frank Kirchner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.10968",
    "title": "Enhancing IoT Security Against DDoS Attacks through Federated Learning",
    "abstract": "The rapid proliferation of the Internet of Things (IoT) has ushered in transformative connectivity between physical devices and the digital realm. Nonetheless, the escalating threat of Distributed Denial of Service (DDoS) attacks jeopardizes the integrity and reliability of IoT networks. Conventional DDoS mitigation approaches are ill-equipped to handle the intricacies of IoT ecosystems, potentially compromising data privacy. This paper introduces an innovative strategy to bolster the security of IoT networks against DDoS attacks by harnessing the power of Federated Learning that allows multiple IoT devices or edge nodes to collaboratively build a global model while preserving data privacy and minimizing communication overhead. The research aims to investigate Federated Learning's effectiveness in detecting and mitigating DDoS attacks in IoT. Our proposed framework leverages IoT devices' collective intelligence for real-time attack detection without compromising sensitive data. This study proposes innovative deep autoencoder approaches for data dimensionality reduction, retraining, and partial selection to enhance the performance and stability of the proposed model. Additionally, two renowned aggregation algorithms, FedAvg and FedAvgM, are employed in this research. Various metrics, including true positive rate, false positive rate, and F1-score, are employed to evaluate the model. The dataset utilized in this research, N-BaIoT, exhibits non-IID data distribution, where data categories are distributed quite differently. The negative impact of these distribution disparities is managed by employing retraining and partial selection techniques, enhancing the final model's stability. Furthermore, evaluation results demonstrate that the FedAvgM aggregation algorithm outperforms FedAvg, indicating that in non-IID datasets, FedAvgM provides better stability and performance. ",
    "url": "https://arxiv.org/abs/2403.10968",
    "authors": [
      "Ghazaleh Shirvani",
      "Saeid Ghasemshirazi",
      "Mohammad Ali Alipour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10980",
    "title": "Inverse learning of black-box aggregator for robust Nash equilibrium",
    "abstract": "In this note, we investigate the robustness of Nash equilibria (NE) in multi-player aggregative games with coupling constraints. There are many algorithms for computing an NE of an aggregative game given a known aggregator. When the coupling parameters are affected by uncertainty, robust NE need to be computed. We consider a scenario where players' weight in the aggregator is unknown, making the aggregator kind of \"a black box\". We pursue a suitable learning approach to estimate the unknown aggregator by proposing an inverse variational inequality-based relationship. We then utilize the counterpart to reconstruct the game and obtain first-order conditions for robust NE in the worst case. Furthermore, we characterize the generalization property of the learning methodology via an upper bound on the violation probability. Simulation experiments show the effectiveness of the proposed inverse learning approach. ",
    "url": "https://arxiv.org/abs/2403.10980",
    "authors": [
      "Guanpu Chen",
      "Gehui Xu",
      "Fengxiang He",
      "Dacheng Tao",
      "Thomas Parisini",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.10985",
    "title": "Bounding the Graph Capacity with Quantum Mechanics and Finite Automata",
    "abstract": "The zero-error capacity of a channel (or Shannon capacity of a graph) quantifies how much information can be transmitted with no risk of error. In contrast to the Shannon capacity of a channel, the zero-error capacity has not even been shown to be computable: we have no convergent upper bounds. In this work, we present a new quantity, the zero-error {\\em unitary} capacity, and show that it can be succinctly represented as the tensor product value of a quantum game. By studying the structure of finite automata, we show that the unitary capacity is within a controllable factor of the zero-error capacity. This allows new upper bounds through the sum-of-squares hierarchy, which converges to the commuting operator value of the game. Under the conjecture that the commuting operator and tensor product value of this game are equal, this would yield an algorithm for computing the zero-error capacity. ",
    "url": "https://arxiv.org/abs/2403.10985",
    "authors": [
      "Alexander Meiburg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2403.10994",
    "title": "SSUP-HRI: Social Signaling in Urban Public Human-Robot Interaction  dataset",
    "abstract": "This paper introduces our dataset featuring human-robot interactions (HRI) in urban public environments. This dataset is rich with social signals that we believe can be modeled to help understand naturalistic human-robot interaction. Our dataset currently comprises approximately 15 hours of video footage recorded from the robots' perspectives, within which we annotated a total of 274 observable interactions featuring a wide range of naturalistic human-robot interactions. The data was collected by two mobile trash barrel robots deployed in Astor Place, New York City, over the course of a week. We invite the HRI community to access and utilize our dataset. To the best of our knowledge, this is the first dataset showcasing robot deployments in a complete public, non-controlled setting involving urban residents. ",
    "url": "https://arxiv.org/abs/2403.10994",
    "authors": [
      "Fanjun Bu",
      "Wendy Ju"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10995",
    "title": "Edge Private Graph Neural Networks with Singular Value Perturbation",
    "abstract": "Graph neural networks (GNNs) play a key role in learning representations from graph-structured data and are demonstrated to be useful in many applications. However, the GNN training pipeline has been shown to be vulnerable to node feature leakage and edge extraction attacks. This paper investigates a scenario where an attacker aims to recover private edge information from a trained GNN model. Previous studies have employed differential privacy (DP) to add noise directly to the adjacency matrix or a compact graph representation. The added perturbations cause the graph structure to be substantially morphed, reducing the model utility. We propose a new privacy-preserving GNN training algorithm, Eclipse, that maintains good model utility while providing strong privacy protection on edges. Eclipse is based on two key observations. First, adjacency matrices in graph structures exhibit low-rank behavior. Thus, Eclipse trains GNNs with a low-rank format of the graph via singular values decomposition (SVD), rather than the original graph. Using the low-rank format, Eclipse preserves the primary graph topology and removes the remaining residual edges. Eclipse adds noise to the low-rank singular values instead of the entire graph, thereby preserving the graph privacy while still maintaining enough of the graph structure to maintain model utility. We theoretically show Eclipse provide formal DP guarantee on edges. Experiments on benchmark graph datasets show that Eclipse achieves significantly better privacy-utility tradeoff compared to existing privacy-preserving GNN training methods. In particular, under strong privacy constraints ($\\epsilon$ < 4), Eclipse shows significant gains in the model utility by up to 46%. We further demonstrate that Eclipse also has better resilience against common edge attacks (e.g., LPA), lowering the attack AUC by up to 5% compared to other state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2403.10995",
    "authors": [
      "Tingting Tang",
      "Yue Niu",
      "Salman Avestimehr",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10997",
    "title": "N2F2: Hierarchical Scene Understanding with Nested Neural Feature Fields",
    "abstract": "Understanding complex scenes at multiple levels of abstraction remains a formidable challenge in computer vision. To address this, we introduce Nested Neural Feature Fields (N2F2), a novel approach that employs hierarchical supervision to learn a single feature field, wherein different dimensions within the same high-dimensional feature encode scene properties at varying granularities. Our method allows for a flexible definition of hierarchies, tailored to either the physical dimensions or semantics or both, thereby enabling a comprehensive and nuanced understanding of scenes. We leverage a 2D class-agnostic segmentation model to provide semantically meaningful pixel groupings at arbitrary scales in the image space, and query the CLIP vision-encoder to obtain language-aligned embeddings for each of these segments. Our proposed hierarchical supervision method then assigns different nested dimensions of the feature field to distill the CLIP embeddings using deferred volumetric rendering at varying physical scales, creating a coarse-to-fine representation. Extensive experiments show that our approach outperforms the state-of-the-art feature field distillation methods on tasks such as open-vocabulary 3D segmentation and localization, demonstrating the effectiveness of the learned nested feature field. ",
    "url": "https://arxiv.org/abs/2403.10997",
    "authors": [
      "Yash Bhalgat",
      "Iro Laina",
      "Jo\u00e3o F. Henriques",
      "Andrew Zisserman",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11004",
    "title": "Forward Learning of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have achieved remarkable success across a wide range of applications, such as recommendation, drug discovery, and question answering. Behind the success of GNNs lies the backpropagation (BP) algorithm, which is the de facto standard for training deep neural networks (NNs). However, despite its effectiveness, BP imposes several constraints, which are not only biologically implausible, but also limit the scalability, parallelism, and flexibility in learning NNs. Examples of such constraints include storage of neural activities computed in the forward pass for use in the subsequent backward pass, and the dependence of parameter updates on non-local signals. To address these limitations, the forward-forward algorithm (FF) was recently proposed as an alternative to BP in the image classification domain, which trains NNs by performing two forward passes over positive and negative data. Inspired by this advance, we propose ForwardGNN in this work, a new forward learning procedure for GNNs, which avoids the constraints imposed by BP via an effective layer-wise local forward training. ForwardGNN extends the original FF to deal with graph data and GNNs, and makes it possible to operate without generating negative inputs (hence no longer forward-forward). Further, ForwardGNN enables each layer to learn from both the bottom-up and top-down signals without relying on the backpropagation of errors. Extensive experiments on real-world datasets show the effectiveness and generality of the proposed forward graph learning framework. We release our code at https://github.com/facebookresearch/forwardgnn. ",
    "url": "https://arxiv.org/abs/2403.11004",
    "authors": [
      "Namyong Park",
      "Xing Wang",
      "Antoine Simoulin",
      "Shuai Yang",
      "Grey Yang",
      "Ryan Rossi",
      "Puja Trivedi",
      "Nesreen Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.11032",
    "title": "FH-TabNet: Multi-Class Familial Hypercholesterolemia Detection via a  Multi-Stage Tabular Deep Learning",
    "abstract": "Familial Hypercholesterolemia (FH) is a genetic disorder characterized by elevated levels of Low-Density Lipoprotein (LDL) cholesterol or its associated genes. Early-stage and accurate categorization of FH is of significance allowing for timely interventions to mitigate the risk of life-threatening conditions. Conventional diagnosis approach, however, is complex, costly, and a challenging interpretation task even for experienced clinicians resulting in high underdiagnosis rates. Although there has been a recent surge of interest in using Machine Learning (ML) models for early FH detection, existing solutions only consider a binary classification task solely using classical ML models. Despite its significance, application of Deep Learning (DL) for FH detection is in its infancy, possibly, due to categorical nature of the underlying clinical data. The paper addresses this gap by introducing the FH-TabNet, which is a multi-stage tabular DL network for multi-class (Definite, Probable, Possible, and Unlikely) FH detection. The FH-TabNet initially involves applying a deep tabular data learning architecture (TabNet) for primary categorization into healthy (Possible/Unlikely) and patient (Probable/Definite) classes. Subsequently, independent TabNet classifiers are applied to each subgroup, enabling refined classification. The model's performance is evaluated through 5-fold cross-validation illustrating superior performance in categorizing FH patients, particularly in the challenging low-prevalence subcategories. ",
    "url": "https://arxiv.org/abs/2403.11032",
    "authors": [
      "Sadaf Khademi",
      "Zohreh Hajiakhondi",
      "Golnaz Vaseghi",
      "Nizal Sarrafzadegan",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.11038",
    "title": "Texture Edge detection by Patch consensus (TEP)",
    "abstract": "We propose Texture Edge detection using Patch consensus (TEP) which is a training-free method to detect the boundary of texture. We propose a new simple way to identify the texture edge location, using the consensus of segmented local patch information. While on the boundary, even using local patch information, the distinction between textures are typically not clear, but using neighbor consensus give a clear idea of the boundary. We utilize local patch, and its response against neighboring regions, to emphasize the similarities and the differences across different textures. The step of segmentation of response further emphasizes the edge location, and the neighborhood voting gives consensus and stabilize the edge detection. We analyze texture as a stationary process to give insight into the patch width parameter verses the quality of edge detection. We derive the necessary condition for textures to be distinguished, and analyze the patch width with respect to the scale of textures. Various experiments are presented to validate the proposed model. ",
    "url": "https://arxiv.org/abs/2403.11038",
    "authors": [
      "Guangyu Cui",
      "Sung Ha Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.11057",
    "title": "Large Language Models Powered Context-aware Motion Prediction",
    "abstract": "Motion prediction is among the most fundamental tasks in autonomous driving. Traditional methods of motion forecasting primarily encode vector information of maps and historical trajectory data of traffic participants, lacking a comprehensive understanding of overall traffic semantics, which in turn affects the performance of prediction tasks. In this paper, we utilized Large Language Models (LLMs) to enhance the global traffic context understanding for motion prediction tasks. We first conducted systematic prompt engineering, visualizing complex traffic environments and historical trajectory information of traffic participants into image prompts -- Transportation Context Map (TC-Map), accompanied by corresponding text prompts. Through this approach, we obtained rich traffic context information from the LLM. By integrating this information into the motion prediction model, we demonstrate that such context can enhance the accuracy of motion predictions. Furthermore, considering the cost associated with LLMs, we propose a cost-effective deployment strategy: enhancing the accuracy of motion prediction tasks at scale with 0.7\\% LLM-augmented datasets. Our research offers valuable insights into enhancing the understanding of traffic scenes of LLMs and the motion prediction performance of autonomous driving. ",
    "url": "https://arxiv.org/abs/2403.11057",
    "authors": [
      "Xiaoji Zheng",
      "Lixiu Wu",
      "Zhijie Yan",
      "Yuanrong Tang",
      "Hao Zhao",
      "Chen Zhong",
      "Bokui Chen",
      "Jiangtao Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11060",
    "title": "Intelligent Railroad Grade Crossing: Leveraging Semantic Segmentation  and Object Detection for Enhanced Safety",
    "abstract": "Crashes and delays at Railroad Highway Grade Crossings (RHGC), where highways and railroads intersect, pose significant safety concerns for the U.S. Federal Railroad Administration (FRA). Despite the critical importance of addressing accidents and traffic delays at highway-railroad intersections, there is a notable dearth of research on practical solutions for managing these issues. In response to this gap in the literature, our study introduces an intelligent system that leverages machine learning and computer vision techniques to enhance safety at Railroad Highway Grade crossings (RHGC). This research proposed a Non-Maximum Suppression (NMS)- based ensemble model that integrates a variety of YOLO variants, specifically YOLOv5S, YOLOv5M, and YOLOv5L, for grade-crossing object detection, utilizes segmentation techniques from the UNet architecture for detecting approaching rail at a grade crossing. Both methods are implemented on a Raspberry Pi. Moreover, the strategy employs high-definition cameras installed at the RHGC. This framework enables the system to monitor objects within the Region of Interest (ROI) at crossings, detect the approach of trains, and clear the crossing area before a train arrives. Regarding accuracy, precision, recall, and Intersection over Union (IoU), the proposed state-of-the-art NMS-based object detection ensemble model achieved 96% precision. In addition, the UNet segmentation model obtained a 98% IoU value. This automated railroad grade crossing system powered by artificial intelligence represents a promising solution for enhancing safety at highway-railroad intersections. ",
    "url": "https://arxiv.org/abs/2403.11060",
    "authors": [
      "Al Amin",
      "Deo Chimba",
      "Kamrul Hasan",
      "Emmanuel Samson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11079",
    "title": "Bridging Expert Knowledge with Deep Learning Techniques for Just-In-Time  Defect Prediction",
    "abstract": "Just-In-Time (JIT) defect prediction aims to automatically predict whether a commit is defective or not, and has been widely studied in recent years. In general, most studies can be classified into two categories: 1) simple models using traditional machine learning classifiers with hand-crafted features, and 2) complex models using deep learning techniques to automatically extract features from commit contents. Hand-crafted features used by simple models are based on expert knowledge but may not fully represent the semantic meaning of the commits. On the other hand, deep learning-based features used by complex models represent the semantic meaning of commits but may not reflect useful expert knowledge. Simple models and complex models seem complementary to each other to some extent. To utilize the advantages of both simple and complex models, we propose a model fusion framework that adopts both early fusions on the feature level and late fusions on the decision level. We propose SimCom++ by adopting the best early and late fusion strategies. The experimental results show that SimCom++ can significantly outperform the baselines by 5.7--26.9\\%. In addition, our experimental results confirm that the simple model and complex model are complementary to each other. ",
    "url": "https://arxiv.org/abs/2403.11079",
    "authors": [
      "Xin Zhou",
      "DongGyun Han",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11082",
    "title": "RobustSentEmbed: Robust Sentence Embeddings Using Adversarial  Self-Supervised Contrastive Learning",
    "abstract": "Pre-trained language models (PLMs) have consistently demonstrated outstanding performance across a diverse spectrum of natural language processing tasks. Nevertheless, despite their success with unseen data, current PLM-based representations often exhibit poor robustness in adversarial settings. In this paper, we introduce RobustSentEmbed, a self-supervised sentence embedding framework designed to improve both generalization and robustness in diverse text representation tasks and against a diverse set of adversarial attacks. Through the generation of high-risk adversarial perturbations and their utilization in a novel objective function, RobustSentEmbed adeptly learns high-quality and robust sentence embeddings. Our experiments confirm the superiority of RobustSentEmbed over state-of-the-art representations. Specifically, Our framework achieves a significant reduction in the success rate of various adversarial attacks, notably reducing the BERTAttack success rate by almost half (from 75.51\\% to 38.81\\%). The framework also yields improvements of 1.59\\% and 0.23\\% in semantic textual similarity tasks and various transfer tasks, respectively. ",
    "url": "https://arxiv.org/abs/2403.11082",
    "authors": [
      "Javad Rafiei Asl",
      "Prajwal Panzade",
      "Eduardo Blanco",
      "Daniel Takabi",
      "Zhipeng Cai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11083",
    "title": "Customizing Visual-Language Foundation Models for Multi-modal Anomaly  Detection and Reasoning",
    "abstract": "Anomaly detection is vital in various industrial scenarios, including the identification of unusual patterns in production lines and the detection of manufacturing defects for quality control. Existing techniques tend to be specialized in individual scenarios and lack generalization capacities. In this study, we aim to develop a generic anomaly detection model applicable across multiple scenarios. To achieve this, we customize generic visual-language foundation models that possess extensive knowledge and robust reasoning abilities into anomaly detectors and reasoners. Specifically, we introduce a multi-modal prompting strategy that incorporates domain knowledge from experts as conditions to guide the models. Our approach considers multi-modal prompt types, including task descriptions, class context, normality rules, and reference images. In addition, we unify the input representation of multi-modality into a 2D image format, enabling multi-modal anomaly detection and reasoning. Our preliminary studies demonstrate that combining visual and language prompts as conditions for customizing the models enhances anomaly detection performance. The customized models showcase the ability to detect anomalies across different data modalities such as images and point clouds. Qualitative case studies further highlight the anomaly detection and reasoning capabilities, particularly for multi-object scenes and temporal data. Our code is available at https://github.com/Xiaohao-Xu/Customizable-VLM. ",
    "url": "https://arxiv.org/abs/2403.11083",
    "authors": [
      "Xiaohao Xu",
      "Yunkang Cao",
      "Yongqi Chen",
      "Weiming Shen",
      "Xiaonan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11087",
    "title": "Incorporating Higher-order Structural Information for Graph Clustering",
    "abstract": "Clustering holds profound significance in data mining. In recent years, graph convolutional network (GCN) has emerged as a powerful tool for deep clustering, integrating both graph structural information and node attributes. However, most existing methods ignore the higher-order structural information of the graph. Evidently, nodes within the same cluster can establish distant connections. Besides, recent deep clustering methods usually apply a self-supervised module to monitor the training process of their model, focusing solely on node attributes without paying attention to graph structure. In this paper, we propose a novel graph clustering network to make full use of graph structural information. To capture the higher-order structural information, we design a graph mutual infomax module, effectively maximizing mutual information between graph-level and node-level representations, and employ a trinary self-supervised module that includes modularity as a structural constraint. Our proposed model outperforms many state-of-the-art methods on various datasets, demonstrating its superiority. ",
    "url": "https://arxiv.org/abs/2403.11087",
    "authors": [
      "Qiankun Li",
      "Haobing Liu",
      "Ruobing Jiang",
      "Tingting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.11088",
    "title": "Programming Frameworks for Differential Privacy",
    "abstract": "Many programming frameworks have been introduced to support the development of differentially private software applications. In this chapter, we survey some of the conceptual ideas underlying these frameworks in a way that we hope will be helpful for both practitioners and researchers. For practitioners, the survey can provide a starting point for understanding what features may be valuable when selecting a programming framework. For researchers, it can help organize existing work in a unified way and provide context for understanding new features in future frameworks. ",
    "url": "https://arxiv.org/abs/2403.11088",
    "authors": [
      "Marco Gaboardi",
      "Michael Hay",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.11090",
    "title": "Brain-on-Switch: Towards Advanced Intelligent Network Data Plane via  NN-Driven Traffic Analysis at Line-Speed",
    "abstract": "The emerging programmable networks sparked significant research on Intelligent Network Data Plane (INDP), which achieves learning-based traffic analysis at line-speed. Prior art in INDP focus on deploying tree/forest models on the data plane. We observe a fundamental limitation in tree-based INDP approaches: although it is possible to represent even larger tree/forest tables on the data plane, the flow features that are computable on the data plane are fundamentally limited by hardware constraints. In this paper, we present BoS to push the boundaries of INDP by enabling Neural Network (NN) driven traffic analysis at line-speed. Many types of NNs (such as Recurrent Neural Network (RNN), and transformers) that are designed to work with sequential data have advantages over tree-based models, because they can take raw network data as input without complex feature computations on the fly. However, the challenge is significant: the recurrent computation scheme used in RNN inference is fundamentally different from the match-action paradigm used on the network data plane. BoS addresses this challenge by (i) designing a novel data plane friendly RNN architecture that can execute unlimited RNN time steps with limited data plane stages, effectively achieving line-speed RNN inference; and (ii) complementing the on-switch RNN model with an off-switch transformer-based traffic analysis module to further boost the overall performance. We implement a prototype of BoS using a P4 programmable switch as our data plane, and extensively evaluate it over multiple traffic analysis tasks. The results show that BoS outperforms state-of-the-art in both analysis accuracy and scalability. ",
    "url": "https://arxiv.org/abs/2403.11090",
    "authors": [
      "Jinzhu Yan",
      "Haotian Xu",
      "Zhuotao Liu",
      "Qi Li",
      "Ke Xu",
      "Mingwei Xu",
      "Jianping Wu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11091",
    "title": "Multitask frame-level learning for few-shot sound event detection",
    "abstract": "This paper focuses on few-shot Sound Event Detection (SED), which aims to automatically recognize and classify sound events with limited samples. However, prevailing methods methods in few-shot SED predominantly rely on segment-level predictions, which often providing detailed, fine-grained predictions, particularly for events of brief duration. Although frame-level prediction strategies have been proposed to overcome these limitations, these strategies commonly face difficulties with prediction truncation caused by background noise. To alleviate this issue, we introduces an innovative multitask frame-level SED framework. In addition, we introduce TimeFilterAug, a linear timing mask for data augmentation, to increase the model's robustness and adaptability to diverse acoustic environments. The proposed method achieves a F-score of 63.8%, securing the 1st rank in the few-shot bioacoustic event detection category of the Detection and Classification of Acoustic Scenes and Events Challenge 2023. ",
    "url": "https://arxiv.org/abs/2403.11091",
    "authors": [
      "Liang Zou",
      "Genwei Yan",
      "Ruoyu Wang",
      "Jun Du",
      "Meng Lei",
      "Tian Gao",
      "Xin Fang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.11097",
    "title": "Secrecy Outage Probability Analysis for Downlink RIS-NOMA Networks with  On-Off Control",
    "abstract": "Reconfigurable intelligent surface (RIS) has been regarded as a promising technology since it has ability to create the favorable channel conditions. This paper investigates the secure communications of RIS assisted non-orthogonal multiple access (NOMA) networks, where both external and internal eavesdropping scenarios are taken into consideration. More specifically, novel approximate and asymptotic expressions of secrecy outage probability (SOP) for the k-th legitimate user (LU) are derived by invoking imperfect successive interference cancellation (ipSIC) and perfect successive interference cancellation (pSIC). To characterize the secrecy performance of RIS-NOMA networks, the diversity order of the k-th LU with ipSIC/pSIC is obtained in the high signal-to-noise ratio region. The secrecy system throughput of RIS-NOMA networks is discussed in delay-limited transmission mode. Numerical results are presented to verify theoretical analysis that: i) The SOP of RIS-NOMA networks is superior to that of RIS assisted orthogonal multiple access (OMA) and conventional cooperative communication schemes; ii) As the number of reflecting elements increases, the RIS-NOMA networks are capable of achieving the enhanced secrecy performance; and iii) The RIS-NOMA networks have better secrecy system throughput than that of RIS-OMA networks and conventional cooperative communication schemes. ",
    "url": "https://arxiv.org/abs/2403.11097",
    "authors": [
      "Yingjie Pei",
      "Xinwei Yue",
      "Wenqiang Yi",
      "Yuanwei Liu",
      "Xuehua Li",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2403.11100",
    "title": "Graph Expansion in Pruned Recurrent Neural Network Layers Preserve  Performance",
    "abstract": "Expansion property of a graph refers to its strong connectivity as well as sparseness. It has been reported that deep neural networks can be pruned to a high degree of sparsity while maintaining their performance. Such pruning is essential for performing real time sequence learning tasks using recurrent neural networks in resource constrained platforms. We prune recurrent networks such as RNNs and LSTMs, maintaining a large spectral gap of the underlying graphs and ensuring their layerwise expansion properties. We also study the time unfolded recurrent network graphs in terms of the properties of their bipartite layers. Experimental results for the benchmark sequence MNIST, CIFAR-10, and Google speech command data show that expander graph properties are key to preserving classification accuracy of RNN and LSTM. ",
    "url": "https://arxiv.org/abs/2403.11100",
    "authors": [
      "Suryam Arnav Kalra",
      "Arindam Biswas",
      "Pabitra Mitra",
      "Biswajit Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.11101",
    "title": "Hierarchical Generative Network for Face Morphing Attacks",
    "abstract": "Face morphing attacks circumvent face recognition systems (FRSs) by creating a morphed image that contains multiple identities. However, existing face morphing attack methods either sacrifice image quality or compromise the identity preservation capability. Consequently, these attacks fail to bypass FRSs verification well while still managing to deceive human observers. These methods typically rely on global information from contributing images, ignoring the detailed information from effective facial regions. To address the above issues, we propose a novel morphing attack method to improve the quality of morphed images and better preserve the contributing identities. Our proposed method leverages the hierarchical generative network to capture both local detailed and global consistency information. Additionally, a mask-guided image blending module is dedicated to removing artifacts from areas outside the face to improve the image's visual quality. The proposed attack method is compared to state-of-the-art methods on three public datasets in terms of FRSs' vulnerability, attack detectability, and image quality. The results show our method's potential threat of deceiving FRSs while being capable of passing multiple morphing attack detection (MAD) scenarios. ",
    "url": "https://arxiv.org/abs/2403.11101",
    "authors": [
      "Zuyuan He",
      "Zongyong Deng",
      "Qiaoyun He",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11102",
    "title": "Jointly Optimizing Terahertz based Sensing and Communications in  Vehicular Networks: A Dynamic Graph Neural Network Approach",
    "abstract": "In this paper, the problem of vehicle service mode selection (sensing, communication, or both) and vehicle connections within terahertz (THz) enabled joint sensing and communications over vehicular networks is studied. The considered network consists of several service provider vehicles (SPVs) that can provide: 1) only sensing service, 2) only communication service, and 3) both services, sensing service request vehicles, and communication service request vehicles. Based on the vehicle network topology and their service accessibility, SPVs strategically select service request vehicles to provide sensing, communication, or both services. This problem is formulated as an optimization problem, aiming to maximize the number of successfully served vehicles by jointly determining the service mode of each SPV and its associated vehicles. To solve this problem, we propose a dynamic graph neural network (GNN) model that selects appropriate graph information aggregation functions according to the vehicle network topology, thus extracting more vehicle network information compared to traditional static GNNs that use fixed aggregation functions for different vehicle network topologies. Using the extracted vehicle network information, the service mode of each SPV and its served service request vehicles will be determined. Simulation results show that the proposed dynamic GNN based method can improve the number of successfully served vehicles by up to 17% and 28% compared to a GNN based algorithm with a fixed neural network model and a conventional optimization algorithm without using GNNs. ",
    "url": "https://arxiv.org/abs/2403.11102",
    "authors": [
      "Xuefei Li",
      "Mingzhe Chen",
      "Ye Hu",
      "Zhilong Zhang",
      "Danpu Liu",
      "Shiwen Mao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.11104",
    "title": "Deep Neural Network NMPC for Computationally Tractable Optimal Power  Management of Hybrid Electric Vehicle",
    "abstract": "This study presents a method for deep neural network nonlinear model predictive control (DNN-MPC) to reduce computational complexity, and we show its practical utility through its application in optimizing the energy management of hybrid electric vehicles (HEVs). For optimal power management of HEVs, we first design the online NMPC to collect the data set, and the deep neural network is trained to approximate the NMPC solutions. We assess the effectiveness of our approach by conducting comparative simulations with rule and online NMPC-based power management strategies for HEV, evaluating both fuel consumption and computational complexity. Lastly, we verify the real-time feasibility of our approach through process-in-the-loop (PIL) testing. The test results demonstrate that the proposed method closely approximates the NMPC performance while substantially reducing the computational burden. ",
    "url": "https://arxiv.org/abs/2403.11104",
    "authors": [
      "Suyong Park",
      "Duc Giap Nguyen",
      "Jinrak Park",
      "Dohee Kim",
      "Jeong Soo Eo",
      "Kyoungseok Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11106",
    "title": "Self-Supervised Quantization-Aware Knowledge Distillation",
    "abstract": "Quantization-aware training (QAT) and Knowledge Distillation (KD) are combined to achieve competitive performance in creating low-bit deep learning models. However, existing works applying KD to QAT require tedious hyper-parameter tuning to balance the weights of different loss terms, assume the availability of labeled training data, and require complex, computationally intensive training procedures for good performance. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation (SQAKD) framework. SQAKD first unifies the forward and backward dynamics of various quantization functions, making it flexible for incorporating various QAT works. Then it formulates QAT as a co-optimization problem that simultaneously minimizes the KL-Loss between the full-precision and low-bit models for KD and the discretization error for quantization, without supervision from labels. A comprehensive evaluation shows that SQAKD substantially outperforms the state-of-the-art QAT and KD works for a variety of model architectures. Our code is at: https://github.com/kaiqi123/SQAKD.git. ",
    "url": "https://arxiv.org/abs/2403.11106",
    "authors": [
      "Kaiqi Zhao",
      "Ming Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11107",
    "title": "Self-supervised co-salient object detection via feature correspondence  at multiple scales",
    "abstract": "Our paper introduces a novel two-stage self-supervised approach for detecting co-occurring salient objects (CoSOD) in image groups without requiring segmentation annotations. Unlike existing unsupervised methods that rely solely on patch-level information (e.g. clustering patch descriptors) or on computation heavy off-the-shelf components for CoSOD, our lightweight model leverages feature correspondences at both patch and region levels, significantly improving prediction performance. In the first stage, we train a self-supervised network that detects co-salient regions by computing local patch-level feature correspondences across images. We obtain the segmentation predictions using confidence-based adaptive thresholding. In the next stage, we refine these intermediate segmentations by eliminating the detected regions (within each image) whose averaged feature representations are dissimilar to the foreground feature representation averaged across all the cross-attention maps (from the previous stage). Extensive experiments on three CoSOD benchmark datasets show that our self-supervised model outperforms the corresponding state-of-the-art models by a huge margin (e.g. on the CoCA dataset, our model has a 13.7% F-measure gain over the SOTA unsupervised CoSOD model). Notably, our self-supervised model also outperforms several recent fully supervised CoSOD models on the three test datasets (e.g., on the CoCA dataset, our model has a 4.6% F-measure gain over a recent supervised CoSOD model). ",
    "url": "https://arxiv.org/abs/2403.11107",
    "authors": [
      "Souradeep Chakraborty",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11108",
    "title": "HarmPot: An Annotation Framework for Evaluating Offline Harm Potential  of Social Media Text",
    "abstract": "In this paper, we discuss the development of an annotation schema to build datasets for evaluating the offline harm potential of social media texts. We define \"harm potential\" as the potential for an online public post to cause real-world physical harm (i.e., violence). Understanding that real-world violence is often spurred by a web of triggers, often combining several online tactics and pre-existing intersectional fissures in the social milieu, to result in targeted physical violence, we do not focus on any single divisive aspect (i.e., caste, gender, religion, or other identities of the victim and perpetrators) nor do we focus on just hate speech or mis/dis-information. Rather, our understanding of the intersectional causes of such triggers focuses our attempt at measuring the harm potential of online content, irrespective of whether it is hateful or not. In this paper, we discuss the development of a framework/annotation schema that allows annotating the data with different aspects of the text including its socio-political grounding and intent of the speaker (as expressed through mood and modality) that together contribute to it being a trigger for offline harm. We also give a comparative analysis and mapping of our framework with some of the existing frameworks. ",
    "url": "https://arxiv.org/abs/2403.11108",
    "authors": [
      "Ritesh Kumar",
      "Ojaswee Bhalla",
      "Madhu Vanthi",
      "Shehlat Maknoon Wani",
      "Siddharth Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11109",
    "title": "Secure Communication of Active RIS Assisted NOMA Networks",
    "abstract": "As a revolutionary technology, reconfigurable intelligent surface (RIS) has been deemed as an indispensable part of the 6th generation communications due to its inherent ability to regulate the wireless channels. However, passive RIS (PRIS) still suffers from some pressing issues, one of which is that the fading of the entire reflection link is proportional to the product of the distances from the base station to the PRIS and from the PRIS to the users, i.e., the productive attenuation. To tackle this problem, active RIS (ARIS) has been proposed to reconfigure the wireless propagation condition and alleviate the productive attenuation. In this paper, we investigate the physical layer security of the ARIS assisted non-orthogonal multiple access (NOMA) networks with the attendance of external and internal eavesdroppers. To be specific, the closed-form expressions of secrecy outage probability (SOP) and secrecy system throughput are derived by invoking both imperfect successive interference cancellation (ipSIC) and perfect SIC. The secrecy diversity orders of legitimate users are obtained at high signal-to-noise ratios. Numerical results are presented to verify the accuracy of the theoretical expressions and indicate that: i) The SOP of ARIS assisted NOMA networks exceeds that of PRIS-NOMA, ARIS/PRIS-assisted orthogonal multiple access (OMA); ii) Due to the balance between the thermal noise and residual interference, introducing excess reconfigurable elements at ARIS is not helpful to reduce the SOP; and iii) The secrecy throughput performance of ARIS-NOMA networks outperforms that of PRIS-NOMA and ARIS/PRIS-OMA networks. ",
    "url": "https://arxiv.org/abs/2403.11109",
    "authors": [
      "Xuehua Li",
      "Yingjie Pei",
      "Xinwei Yue",
      "Yuanwei Liu",
      "Zhiguo Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.11117",
    "title": "Secrecy Performance Analysis of RIS Assisted Ambient Backscatter  Communication Networks",
    "abstract": "Reconfigurable intelligent surface (RIS) and ambient backscatter communication (AmBC) have been envisioned as two promising technologies due to their high transmission reliability as well as energy-efficiency. This paper investigates the secrecy performance of RIS assisted AmBC networks. New closed-form and asymptotic expressions of secrecy outage probability for RIS-AmBC networks are derived by taking into account both imperfect successive interference cancellation (ipSIC) and perfect SIC (pSIC) cases. On top of these, the secrecy diversity order of legitimate user is obtained in high signal-to-noise ratio region, which equals \\emph{zero} and is proportional to the number of RIS elements for ipSIC and pSIC, respectively. The secrecy throughput and energy efficiency are further surveyed to evaluate the secure effectiveness of RIS-AmBC networks. Numerical results are provided to verify the accuracy of theoretical analyses and manifest that: i) The secrecy outage behavior of RIS-AmBC networks exceeds that of conventional AmBC networks; ii) Due to the mutual interference between direct and backscattering links, the number of RIS elements has an optimal value to minimise the secrecy system outage probability; and iii) Secrecy throughput and energy efficiency are strongly influenced by the reflecting coefficient and eavesdropper's wiretapping ability. ",
    "url": "https://arxiv.org/abs/2403.11117",
    "authors": [
      "Yingjie Pei",
      "Xinwei Yue",
      "Chongwen Huang",
      "Zhiping Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.11129",
    "title": "Enhancing Event Causality Identification with Rationale and  Structure-Aware Causal Question Answering",
    "abstract": "Document-level Event Causality Identification (DECI) aims to identify causal relations between two events in documents. Recent research tends to use pre-trained language models to generate the event causal relations. Whereas, these methods are prone to the errors of sequential generation due to multiple events in a document. Moreover, the potential structures such as event coreference and related causal chain are neglected. In this paper, we propose a multi-task learning framework to enhance event causality identification with rationale and structure-aware causal question answering. Specifically, the DECI task is transformed into multiple-choice question answering, and the causes and effects of the questioned event are generated with large language models. In addition, we generate the rationales to explain why these events have causal relations. Moreover, we construct an event structure graph, which models the multi-hop potential relations for causal reasoning of the current event. Experiments on two benchmark datasets show the great advantages of our proposed approach compared to the state-of-the-art methods. Moreover, we conduct both quantitative and qualitative analyses, which shed light on why each component of our approach can lead to great improvements. ",
    "url": "https://arxiv.org/abs/2403.11129",
    "authors": [
      "Baiyan Zhang",
      "Qin Chen",
      "Jie Zhou",
      "Jian Jin",
      "Liang He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11131",
    "title": "Omni-Recon: Towards General-Purpose Neural Radiance Fields for Versatile  3D Applications",
    "abstract": "Recent breakthroughs in Neural Radiance Fields (NeRFs) have sparked significant demand for their integration into real-world 3D applications. However, the varied functionalities required by different 3D applications often necessitate diverse NeRF models with various pipelines, leading to tedious NeRF training for each target task and cumbersome trial-and-error experiments. Drawing inspiration from the generalization capability and adaptability of emerging foundation models, our work aims to develop one general-purpose NeRF for handling diverse 3D tasks. We achieve this by proposing a framework called Omni-Recon, which is capable of (1) generalizable 3D reconstruction and zero-shot multitask scene understanding, and (2) adaptability to diverse downstream 3D applications such as real-time rendering and scene editing. Our key insight is that an image-based rendering pipeline, with accurate geometry and appearance estimation, can lift 2D image features into their 3D counterparts, thus extending widely explored 2D tasks to the 3D world in a generalizable manner. Specifically, our Omni-Recon features a general-purpose NeRF model using image-based rendering with two decoupled branches: one complex transformer-based branch that progressively fuses geometry and appearance features for accurate geometry estimation, and one lightweight branch for predicting blending weights of source views. This design achieves state-of-the-art (SOTA) generalizable 3D surface reconstruction quality with blending weights reusable across diverse tasks for zero-shot multitask scene understanding. In addition, it can enable real-time rendering after baking the complex geometry branch into meshes, swift adaptation to achieve SOTA generalizable 3D understanding performance, and seamless integration with 2D diffusion models for text-guided 3D editing. ",
    "url": "https://arxiv.org/abs/2403.11131",
    "authors": [
      "Yonggan Fu",
      "Huaizhi Qu",
      "Zhifan Ye",
      "Chaojian Li",
      "Kevin Zhao",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11136",
    "title": "Is Contrastive Learning Necessary? A Study of Data Augmentation vs  Contrastive Learning in Sequential Recommendation",
    "abstract": "Sequential recommender systems (SRS) are designed to predict users' future behaviors based on their historical interaction data. Recent research has increasingly utilized contrastive learning (CL) to leverage unsupervised signals to alleviate the data sparsity issue in SRS. In general, CL-based SRS first augments the raw sequential interaction data by using data augmentation strategies and employs a contrastive training scheme to enforce the representations of those sequences from the same raw interaction data to be similar. Despite the growing popularity of CL, data augmentation, as a basic component of CL, has not received sufficient attention. This raises the question: Is it possible to achieve superior recommendation results solely through data augmentation? To answer this question, we benchmark eight widely used data augmentation strategies, as well as state-of-the-art CL-based SRS methods, on four real-world datasets under both warm- and cold-start settings. Intriguingly, the conclusion drawn from our study is that, certain data augmentation strategies can achieve similar or even superior performance compared with some CL-based methods, demonstrating the potential to significantly alleviate the data sparsity issue with fewer computational overhead. We hope that our study can further inspire more fundamental studies on the key functional components of complex CL techniques. Our processed datasets and codes are available at https://github.com/AIM-SE/DA4Rec. ",
    "url": "https://arxiv.org/abs/2403.11136",
    "authors": [
      "Peilin Zhou",
      "You-Liang Huang",
      "Yueqi Xie",
      "Jingqi Gao",
      "Shoujin Wang",
      "Jae Boum Kim",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.11145",
    "title": "A Challenge Dataset and Effective Models for Conversational Stance  Detection",
    "abstract": "Previous stance detection studies typically concentrate on evaluating stances within individual instances, thereby exhibiting limitations in effectively modeling multi-party discussions concerning the same specific topic, as naturally transpire in authentic social media interactions. This constraint arises primarily due to the scarcity of datasets that authentically replicate real social media contexts, hindering the research progress of conversational stance detection. In this paper, we introduce a new multi-turn conversation stance detection dataset (called \\textbf{MT-CSD}), which encompasses multiple targets for conversational stance detection. To derive stances from this challenging dataset, we propose a global-local attention network (\\textbf{GLAN}) to address both long and short-range dependencies inherent in conversational data. Notably, even state-of-the-art stance detection methods, exemplified by GLAN, exhibit an accuracy of only 50.47\\%, highlighting the persistent challenges in conversational stance detection. Furthermore, our MT-CSD dataset serves as a valuable resource to catalyze advancements in cross-domain stance detection, where a classifier is adapted from a different yet related target. We believe that MT-CSD will contribute to advancing real-world applications of stance detection research. Our source code, data, and models are available at \\url{https://github.com/nfq729/MT-CSD}. ",
    "url": "https://arxiv.org/abs/2403.11145",
    "authors": [
      "Fuqiang Niu",
      "Min Yang",
      "Ang Li",
      "Baoquan Zhang",
      "Xiaojiang Peng",
      "Bowen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11158",
    "title": "An Empirical Study on JIT Defect Prediction Based on BERT-style Model",
    "abstract": "Previous works on Just-In-Time (JIT) defect prediction tasks have primarily applied pre-trained models directly, neglecting the configurations of their fine-tuning process. In this study, we perform a systematic empirical study to understand the impact of the settings of the fine-tuning process on BERT-style pre-trained model for JIT defect prediction. Specifically, we explore the impact of different parameter freezing settings, parameter initialization settings, and optimizer strategies on the performance of BERT-style models for JIT defect prediction. Our findings reveal the crucial role of the first encoder layer in the BERT-style model and the project sensitivity to parameter initialization settings. Another notable finding is that the addition of a weight decay strategy in the Adam optimizer can slightly improve model performance. Additionally, we compare performance using different feature extractors (FCN, CNN, LSTM, transformer) and find that a simple network can achieve great performance. These results offer new insights for fine-tuning pre-trained models for JIT defect prediction. We combine these findings to find a cost-effective fine-tuning method based on LoRA, which achieve a comparable performance with only one-third memory consumption than original fine-tuning process. ",
    "url": "https://arxiv.org/abs/2403.11158",
    "authors": [
      "Yuxiang Guo",
      "Xiaopeng Gao",
      "Bo Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.11159",
    "title": "Deep Neural Crossover",
    "abstract": "We present a novel multi-parent crossover operator in genetic algorithms (GAs) called ``Deep Neural Crossover'' (DNC). Unlike conventional GA crossover operators that rely on a random selection of parental genes, DNC leverages the capabilities of deep reinforcement learning (DRL) and an encoder-decoder architecture to select the genes. Specifically, we use DRL to learn a policy for selecting promising genes. The policy is stochastic, to maintain the stochastic nature of GAs, representing a distribution for selecting genes with a higher probability of improving fitness. Our architecture features a recurrent neural network (RNN) to encode the parental genomes into latent memory states, and a decoder RNN that utilizes an attention-based pointing mechanism to generate a distribution over the next selected gene in the offspring. To improve the training time, we present a pre-training approach, wherein the architecture is initially trained on a single problem within a specific domain and then applied to solving other problems of the same domain. We compare DNC to known operators from the literature over two benchmark domains -- bin packing and graph coloring. We compare with both two- and three-parent crossover, outperforming all baselines. DNC is domain-independent and can be easily applied to other problem domains. ",
    "url": "https://arxiv.org/abs/2403.11159",
    "authors": [
      "Eliad Shem-Tov",
      "Achiya Elyasaf"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.11169",
    "title": "Correcting misinformation on social media with a large language model",
    "abstract": "Misinformation undermines public trust in science and democracy, particularly on social media where inaccuracies can spread rapidly. Experts and laypeople have shown to be effective in correcting misinformation by manually identifying and explaining inaccuracies. Nevertheless, this approach is difficult to scale, a concern as technologies like large language models (LLMs) make misinformation easier to produce. LLMs also have versatile capabilities that could accelerate misinformation correction; however, they struggle due to a lack of recent information, a tendency to produce plausible but false content and references, and limitations in addressing multimodal information. To address these issues, we propose MUSE, an LLM augmented with access to and credibility evaluation of up-to-date information. By retrieving contextual evidence and refutations, MUSE can provide accurate and trustworthy explanations and references. It also describes visuals and conducts multimodal searches for correcting multimodal misinformation. We recruit fact-checking and journalism experts to evaluate corrections to real social media posts across 13 dimensions, ranging from the factuality of explanation to the relevance of references. The results demonstrate MUSE's ability to correct misinformation promptly after appearing on social media; overall, MUSE outperforms GPT-4 by 37% and even high-quality corrections from laypeople by 29%. This work underscores the potential of LLMs to combat real-world misinformation effectively and efficiently. ",
    "url": "https://arxiv.org/abs/2403.11169",
    "authors": [
      "Xinyi Zhou",
      "Ashish Sharma",
      "Amy X. Zhang",
      "Tim Althoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11172",
    "title": "Artifact Feature Purification for Cross-domain Detection of AI-generated  Images",
    "abstract": "In the era of AIGC, the fast development of visual content generation technologies, such as diffusion models, bring potential security risks to our society. Existing generated image detection methods suffer from performance drop when faced with out-of-domain generators and image scenes. To relieve this problem, we propose Artifact Purification Network (APN) to facilitate the artifact extraction from generated images through the explicit and implicit purification processes. For the explicit one, a suspicious frequency-band proposal method and a spatial feature decomposition method are proposed to extract artifact-related features. For the implicit one, a training strategy based on mutual information estimation is proposed to further purify the artifact-related features. Experiments show that for cross-generator detection, the average accuracy of APN is 5.6% ~ 16.4% higher than the previous 10 methods on GenImage dataset and 1.7% ~ 50.1% on DiffusionForensics dataset. For cross-scene detection, APN maintains its high performance. Via visualization analysis, we find that the proposed method extracts flexible forgery patterns and condenses the forgery information diluted in irrelevant features. We also find that the artifact features APN focuses on across generators and scenes are global and diverse. The code will be available on GitHub. ",
    "url": "https://arxiv.org/abs/2403.11172",
    "authors": [
      "Zheling Meng",
      "Bo Peng",
      "Jing Dong",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11173",
    "title": "Multi-Objective Evolutionary Neural Architecture Search for Recurrent  Neural Networks",
    "abstract": "Artificial neural network (NN) architecture design is a nontrivial and time-consuming task that often requires a high level of human expertise. Neural architecture search (NAS) serves to automate the design of NN architectures and has proven to be successful in automatically finding NN architectures that outperform those manually designed by human experts. NN architecture performance can be quantified based on multiple objectives, which include model accuracy and some NN architecture complexity objectives, among others. The majority of modern NAS methods that consider multiple objectives for NN architecture performance evaluation are concerned with automated feed forward NN architecture design, which leaves multi-objective automated recurrent neural network (RNN) architecture design unexplored. RNNs are important for modeling sequential datasets, and prominent within the natural language processing domain. It is often the case in real world implementations of machine learning and NNs that a reasonable trade-off is accepted for marginally reduced model accuracy in favour of lower computational resources demanded by the model. This paper proposes a multi-objective evolutionary algorithm-based RNN architecture search method. The proposed method relies on approximate network morphisms for RNN architecture complexity optimisation during evolution. The results show that the proposed method is capable of finding novel RNN architectures with comparable performance to state-of-the-art manually designed RNN architectures, but with reduced computational demand. ",
    "url": "https://arxiv.org/abs/2403.11173",
    "authors": [
      "Reinhard Booysen",
      "Anna Sergeevna Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11180",
    "title": "usfAD Based Effective Unknown Attack Detection Focused IDS Framework",
    "abstract": "The rapid expansion of varied network systems, including the Internet of Things (IoT) and Industrial Internet of Things (IIoT), has led to an increasing range of cyber threats. Ensuring robust protection against these threats necessitates the implementation of an effective Intrusion Detection System (IDS). For more than a decade, researchers have delved into supervised machine learning techniques to develop IDS to classify normal and attack traffic. However, building effective IDS models using supervised learning requires a substantial number of benign and attack samples. To collect a sufficient number of attack samples from real-life scenarios is not possible since cyber attacks occur occasionally. Further, IDS trained and tested on known datasets fails in detecting zero-day or unknown attacks due to the swift evolution of attack patterns. To address this challenge, we put forth two strategies for semi-supervised learning based IDS where training samples of attacks are not required: 1) training a supervised machine learning model using randomly and uniformly dispersed synthetic attack samples; 2) building a One Class Classification (OCC) model that is trained exclusively on benign network traffic. We have implemented both approaches and compared their performances using 10 recent benchmark IDS datasets. Our findings demonstrate that the OCC model based on the state-of-art anomaly detection technique called usfAD significantly outperforms conventional supervised classification and other OCC based techniques when trained and tested considering real-life scenarios, particularly to detect previously unseen attacks. ",
    "url": "https://arxiv.org/abs/2403.11180",
    "authors": [
      "Md. Ashraf Uddin",
      "Sunil Aryal",
      "Mohamed Reda Bouadjenek",
      "Muna Al-Hawawreh",
      "Md. Alamin Talukder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11184",
    "title": "DuPL: Dual Student with Trustworthy Progressive Learning for Robust  Weakly Supervised Semantic Segmentation",
    "abstract": "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets. Code is available at https://github.com/Wu0409/DuPL. ",
    "url": "https://arxiv.org/abs/2403.11184",
    "authors": [
      "Yuanchen Wu",
      "Xichen Ye",
      "Kequan Yang",
      "Jide Li",
      "Xiaoqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11192",
    "title": "Self-Supervised Video Desmoking for Laparoscopic Surgery",
    "abstract": "Due to the difficulty of collecting real paired data, most existing desmoking methods train the models by synthesizing smoke, generalizing poorly to real surgical scenarios. Although a few works have explored single-image real-world desmoking in unpaired learning manners, they still encounter challenges in handling dense smoke. In this work, we address these issues together by introducing the self-supervised surgery video desmoking (SelfSVD). On the one hand, we observe that the frame captured before the activation of high-energy devices is generally clear (named pre-smoke frame, PS frame), thus it can serve as supervision for other smoky frames, making real-world self-supervised video desmoking practically feasible. On the other hand, in order to enhance the desmoking performance, we further feed the valuable information from PS frame into models, where a masking strategy and a regularization term are presented to avoid trivial solutions. In addition, we construct a real surgery video dataset for desmoking, which covers a variety of smoky scenes. Extensive experiments on the dataset show that our SelfSVD can remove smoke more effectively and efficiently while recovering more photo-realistic details than the state-of-the-art methods. The dataset, codes, and pre-trained models are available at \\url{https://github.com/ZcsrenlongZ/SelfSVD}. ",
    "url": "https://arxiv.org/abs/2403.11192",
    "authors": [
      "Renlong Wu",
      "Zhilu Zhang",
      "Shuohao Zhang",
      "Longfei Gou",
      "Haobin Chen",
      "Lei Zhang",
      "Hao Chen",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11193",
    "title": "Neural Markov Random Field for Stereo Matching",
    "abstract": "Stereo matching is a core task for many computer vision and robotics applications. Despite their dominance in traditional stereo methods, the hand-crafted Markov Random Field (MRF) models lack sufficient modeling accuracy compared to end-to-end deep models. While deep learning representations have greatly improved the unary terms of the MRF models, the overall accuracy is still severely limited by the hand-crafted pairwise terms and message passing. To address these issues, we propose a neural MRF model, where both potential functions and message passing are designed using data-driven neural networks. Our fully data-driven model is built on the foundation of variational inference theory, to prevent convergence issues and retain stereo MRF's graph inductive bias. To make the inference tractable and scale well to high-resolution images, we also propose a Disparity Proposal Network (DPN) to adaptively prune the search space of disparity. The proposed approach ranks $1^{st}$ on both KITTI 2012 and 2015 leaderboards among all published methods while running faster than 100 ms. This approach significantly outperforms prior global methods, e.g., lowering D1 metric by more than 50% on KITTI 2015. In addition, our method exhibits strong cross-domain generalization and can recover sharp edges. The codes at https://github.com/aeolusguan/NMRF . ",
    "url": "https://arxiv.org/abs/2403.11193",
    "authors": [
      "Tongfan Guan",
      "Chen Wang",
      "Yun-Hui Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11199",
    "title": "Graph Unitary Message Passing",
    "abstract": "Message passing mechanism contributes to the success of GNNs in various applications, but also brings the oversquashing problem. Recent works combat oversquashing by improving the graph spectrums with rewiring techniques, disrupting the structural bias in graphs, and having limited improvement on oversquashing in terms of oversquashing measure. Motivated by unitary RNN, we propose Graph Unitary Message Passing (GUMP) to alleviate oversquashing in GNNs by applying unitary adjacency matrix for message passing. To design GUMP, a transformation is first proposed to make general graphs have unitary adjacency matrix and keep its structural bias. Then, unitary adjacency matrix is obtained with a unitary projection algorithm, which is implemented by utilizing the intrinsic structure of unitary adjacency matrix and allows GUMP to be permutation-equivariant. Experimental results show the effectiveness of GUMP in improving the performance on various graph learning tasks. ",
    "url": "https://arxiv.org/abs/2403.11199",
    "authors": [
      "Haiquan Qiu",
      "Yatao Bian",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11202",
    "title": "Data is all you need: Finetuning LLMs for Chip Design via an Automated  design-data augmentation framework",
    "abstract": "Recent advances in large language models have demonstrated their potential for automated generation of hardware description language (HDL) code from high-level prompts. Researchers have utilized fine-tuning to enhance the ability of these large language models (LLMs) in the field of Chip Design. However, the lack of Verilog data hinders further improvement in the quality of Verilog generation by LLMs. Additionally, the absence of a Verilog and Electronic Design Automation (EDA) script data augmentation framework significantly increases the time required to prepare the training dataset for LLM trainers. This paper proposes an automated design-data augmentation framework, which generates high-volume and high-quality natural language aligned with Verilog and EDA scripts. For Verilog generation, it translates Verilog files to an abstract syntax tree and then maps nodes to natural language with a predefined template. For Verilog repair, it uses predefined rules to generate the wrong verilog file and then pairs EDA Tool feedback with the right and wrong verilog file. For EDA Script generation, it uses existing LLM(GPT-3.5) to obtain the description of the Script. To evaluate the effectiveness of our data augmentation method, we finetune Llama2-13B and Llama2-7B models using the dataset generated by our augmentation framework. The results demonstrate a significant improvement in the Verilog generation tasks with LLMs. Moreover, the accuracy of Verilog generation surpasses that of the current state-of-the-art open-source Verilog generation model, increasing from 58.8% to 70.6% with the same benchmark. Our 13B model (ChipGPT-FT) has a pass rate improvement compared with GPT-3.5 in Verilog generation and outperforms in EDA script (i.e., SiliconCompiler) generation with only 200 EDA script data. ",
    "url": "https://arxiv.org/abs/2403.11202",
    "authors": [
      "Kaiyan Chang",
      "Kun Wang",
      "Nan Yang",
      "Ying Wang",
      "Dantong Jin",
      "Wenlong Zhu",
      "Zhirong Chen",
      "Cangyuan Li",
      "Hao Yan",
      "Yunhao Zhou",
      "Zhuoliang Zhao",
      "Yuan Cheng",
      "Yudong Pan",
      "Yiqi Liu",
      "Mengdi Wang",
      "Shengwen Liang",
      "yinhe han",
      "Huawei Li",
      "Xiaowei Li"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.11203",
    "title": "TRELM: Towards Robust and Efficient Pre-training for Knowledge-Enhanced  Language Models",
    "abstract": "KEPLMs are pre-trained models that utilize external knowledge to enhance language understanding. Previous language models facilitated knowledge acquisition by incorporating knowledge-related pre-training tasks learned from relation triples in knowledge graphs. However, these models do not prioritize learning embeddings for entity-related tokens. Moreover, updating the entire set of parameters in KEPLMs is computationally demanding. This paper introduces TRELM, a Robust and Efficient Pre-training framework for Knowledge-Enhanced Language Models. We observe that entities in text corpora usually follow the long-tail distribution, where the representations of some entities are suboptimally optimized and hinder the pre-training process for KEPLMs. To tackle this, we employ a robust approach to inject knowledge triples and employ a knowledge-augmented memory bank to capture valuable information. Furthermore, updating a small subset of neurons in the feed-forward networks (FFNs) that store factual knowledge is both sufficient and efficient. Specifically, we utilize dynamic knowledge routing to identify knowledge paths in FFNs and selectively update parameters during pre-training. Experimental results show that TRELM reduces pre-training time by at least 50% and outperforms other KEPLMs in knowledge probing tasks and multiple knowledge-aware language understanding tasks. ",
    "url": "https://arxiv.org/abs/2403.11203",
    "authors": [
      "Junbing Yan",
      "Chengyu Wang",
      "Taolin Zhang",
      "Xiaofeng He",
      "Jun Huang",
      "Longtao Huang",
      "Hui Xue",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11204",
    "title": "Partitioned Neural Network Training via Synthetic Intermediate Labels",
    "abstract": "The proliferation of extensive neural network architectures, particularly deep learning models, presents a challenge in terms of resource-intensive training. GPU memory constraints have become a notable bottleneck in training such sizable models. Existing strategies, including data parallelism, model parallelism, pipeline parallelism, and fully sharded data parallelism, offer partial solutions. Model parallelism, in particular, enables the distribution of the entire model across multiple GPUs, yet the ensuing data communication between these partitions slows down training. Additionally, the substantial memory overhead required to store auxiliary parameters on each GPU compounds computational demands. Instead of using the entire model for training, this study advocates partitioning the model across GPUs and generating synthetic intermediate labels to train individual segments. These labels, produced through a random process, mitigate memory overhead and computational load. This approach results in a more efficient training process that minimizes data communication while maintaining model accuracy. To validate this method, a 6-layer fully connected neural network is partitioned into two parts and its performance is assessed on the extended MNIST dataset. Experimental results indicate that the proposed approach achieves similar testing accuracies to conventional training methods, while significantly reducing memory and computational requirements. This work contributes to mitigating the resource-intensive nature of training large neural networks, paving the way for more efficient deep learning model development. ",
    "url": "https://arxiv.org/abs/2403.11204",
    "authors": [
      "Cevat Volkan Karada\u011f",
      "Nezih Topalo\u011flu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2403.11206",
    "title": "CBR - Boosting Adaptive Classification By Retrieval of Encrypted Network  Traffic with Out-of-distribution",
    "abstract": "Encrypted network traffic Classification tackles the problem from different approaches and with different goals. One of the common approaches is using Machine learning or Deep Learning-based solutions on a fixed number of classes, leading to misclassification when an unknown class is given as input. One of the solutions for handling unknown classes is to retrain the model, however, retraining models every time they become obsolete is both resource and time-consuming. Therefore, there is a growing need to allow classification models to detect and adapt to new classes dynamically, without retraining, but instead able to detect new classes using few shots learning [1]. In this paper, we introduce Adaptive Classification By Retrieval CBR, a novel approach for encrypted network traffic classification. Our new approach is based on an ANN-based method, which allows us to effectively identify new and existing classes without retraining the model. The novel approach is simple, yet effective and achieved similar results to RF with up to 5% difference (usually less than that) in the classification tasks while having a slight decrease in the case of new samples (from new classes) without retraining. To summarize, the new method is a real-time classification, which can classify new classes without retraining. Furthermore, our solution can be used as a complementary solution alongside RF or any other machine/deep learning classification method, as an aggregated solution. ",
    "url": "https://arxiv.org/abs/2403.11206",
    "authors": [
      "Amir Lukach",
      "Ran Dubin",
      "Amit Dvir",
      "Chen Hajaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.11217",
    "title": "Research on Personal Credit Risk Assessment Methods Based on Causal  Inference",
    "abstract": "The discussion on causality in human history dates back to ancient Greece, yet to this day, there is still no consensus. Fundamentally, this stems from the nature of human cognition, as understanding causality requires abstract tools to transcend the limitations of human cognition. In recent decades, the rapid development of mathematical and computational tools has provided new theoretical and technical means for exploring causality, creating more avenues for investigation. Based on this, this paper introduces a new definition of causality using category theory, proposed by Samuel Eilenberg and Saunders Mac Lane in 1945 to avoid the self-referential contradictions in set theory, notably the Russell paradox. Within this framework, the feasibility of indicator synthesis in causal inference is demonstrated. Due to the limitations in the development of category theory-related technical tools, this paper adopts the widely-used probabilistic causal graph tool proposed by Judea Pearl in 1995 to study the application of causal inference in personal credit risk management. The specific work includes: research on the construction method of causal inference index system, definition of causality and feasibility proof of indicator synthesis causal inference within this framework, application methods of causal graph model and intervention alternative criteria in personal credit risk management, and so on. ",
    "url": "https://arxiv.org/abs/2403.11217",
    "authors": [
      "Jiaxin Wang",
      "YiLong Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2403.11219",
    "title": "Causality from Bottom to Top: A Survey",
    "abstract": "Causality has become a fundamental approach for explaining the relationships between events, phenomena, and outcomes in various fields of study. It has invaded various fields and applications, such as medicine, healthcare, economics, finance, fraud detection, cybersecurity, education, public policy, recommender systems, anomaly detection, robotics, control, sociology, marketing, and advertising. In this paper, we survey its development over the past five decades, shedding light on the differences between causality and other approaches, as well as the preconditions for using it. Furthermore, the paper illustrates how causality interacts with new approaches such as Artificial Intelligence (AI), Generative AI (GAI), Machine and Deep Learning, Reinforcement Learning (RL), and Fuzzy Logic. We study the impact of causality on various fields, its contribution, and its interaction with state-of-the-art approaches. Additionally, the paper exemplifies the trustworthiness and explainability of causality models. We offer several ways to evaluate causality models and discuss future directions. ",
    "url": "https://arxiv.org/abs/2403.11219",
    "authors": [
      "Abraham Itzhak Weinberg",
      "Cristiano Premebida",
      "Diego Resende Faria"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11220",
    "title": "CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object  Detection under Unknown Degradations",
    "abstract": "Object detection methods under known single degradations have been extensively investigated. However, existing approaches require prior knowledge of the degradation type and train a separate model for each, limiting their practical applications in unpredictable environments. To address this challenge, we propose a chain-of-thought (CoT) prompted adaptive enhancer, CPA-Enhancer, for object detection under unknown degradations. Specifically, CPA-Enhancer progressively adapts its enhancement strategy under the step-by-step guidance of CoT prompts, that encode degradation-related information. To the best of our knowledge, it's the first work that exploits CoT prompting for object detection tasks. Overall, CPA-Enhancer is a plug-and-play enhancement model that can be integrated into any generic detectors to achieve substantial gains on degraded images, without knowing the degradation type priorly. Experimental results demonstrate that CPA-Enhancer not only sets the new state of the art for object detection but also boosts the performance of other downstream vision tasks under unknown degradations. ",
    "url": "https://arxiv.org/abs/2403.11220",
    "authors": [
      "Yuwei Zhang",
      "Yan Wu",
      "Yanming Liu",
      "Xinyue Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11222",
    "title": "SpikeNeRF: Learning Neural Radiance Fields from Continuous Spike Stream",
    "abstract": "Spike cameras, leveraging spike-based integration sampling and high temporal resolution, offer distinct advantages over standard cameras. However, existing approaches reliant on spike cameras often assume optimal illumination, a condition frequently unmet in real-world scenarios. To address this, we introduce SpikeNeRF, the first work that derives a NeRF-based volumetric scene representation from spike camera data. Our approach leverages NeRF's multi-view consistency to establish robust self-supervision, effectively eliminating erroneous measurements and uncovering coherent structures within exceedingly noisy input amidst diverse real-world illumination scenarios. The framework comprises two core elements: a spike generation model incorporating an integrate-and-fire neuron layer and parameters accounting for non-idealities, such as threshold variation, and a spike rendering loss capable of generalizing across varying illumination conditions. We describe how to effectively optimize neural radiance fields to render photorealistic novel views from the novel continuous spike stream, demonstrating advantages over other vision sensors in certain scenes. Empirical evaluations conducted on both real and novel realistically simulated sequences affirm the efficacy of our methodology. The dataset and source code are released at https://github.com/BIT-Vision/SpikeNeRF. ",
    "url": "https://arxiv.org/abs/2403.11222",
    "authors": [
      "Lin Zhu",
      "Kangmin Jia",
      "Yifan Zhao",
      "Yunshan Qi",
      "Lizhi Wang",
      "Hua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11251",
    "title": "NeoNeXt: Novel neural network operator and architecture based on the  patch-wise matrix multiplications",
    "abstract": "Most of the computer vision architectures nowadays are built upon the well-known foundation operations: fully-connected layers, convolutions and multi-head self-attention blocks. In this paper we propose a novel foundation operation - NeoCell - which learns matrix patterns and performs patchwise matrix multiplications with the input data. The main advantages of the proposed operator are (1) simple implementation without need in operations like im2col, (2) low computational complexity (especially for large matrices) and (3) simple and flexible implementation of up-/down-sampling. We validate NeoNeXt family of models based on this operation on ImageNet-1K classification task and show that they achieve competitive quality. ",
    "url": "https://arxiv.org/abs/2403.11251",
    "authors": [
      "Vladimir Korviakov",
      "Denis Koposov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11254",
    "title": "Efficiently Detecting Reentrancy Vulnerabilities in Complex Smart  Contracts",
    "abstract": "Reentrancy vulnerability as one of the most notorious vulnerabilities, has been a prominent topic in smart contract security research. Research shows that existing vulnerability detection presents a range of challenges, especially as smart contracts continue to increase in complexity. Existing tools perform poorly in terms of efficiency and successful detection rates for vulnerabilities in complex contracts. To effectively detect reentrancy vulnerabilities in contracts with complex logic, we propose a tool named SliSE. SliSE's detection process consists of two stages: Warning Search and Symbolic Execution Verification. In Stage I, SliSE utilizes program slicing to analyze the Inter-contract Program Dependency Graph (I-PDG) of the contract, and collects suspicious vulnerability information as warnings. In Stage II, symbolic execution is employed to verify the reachability of these warnings, thereby enhancing vulnerability detection accuracy. SliSE obtained the best performance compared with eight state-of-the-art detection tools. It achieved an F1 score of 78.65%, surpassing the highest score recorded by an existing tool of 9.26%. Additionally, it attained a recall rate exceeding 90% for detection of contracts on Ethereum. Overall, SliSE provides a robust and efficient method for detection of Reentrancy vulnerabilities for complex contracts. ",
    "url": "https://arxiv.org/abs/2403.11254",
    "authors": [
      "Zexu Wang",
      "Jiachi Chen",
      "Yanlin Wang",
      "Yu Zhang",
      "Weizhe Zhang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.11265",
    "title": "Forging the Forger: An Attempt to Improve Authorship Verification via  Data Augmentation",
    "abstract": "Authorship Verification (AV) is a text classification task concerned with inferring whether a candidate text has been written by one specific author or by someone else. It has been shown that many AV systems are vulnerable to adversarial attacks, where a malicious author actively tries to fool the classifier by either concealing their writing style, or by imitating the style of another author. In this paper, we investigate the potential benefits of augmenting the classifier training set with (negative) synthetic examples. These synthetic examples are generated to imitate the style of the author of interest. We analyze the improvements in classifier prediction that this augmentation brings to bear in the task of AV in an adversarial setting. In particular, we experiment with three different generator architectures (one based on Recurrent Neural Networks, another based on small-scale transformers, and another based on the popular GPT model) and with two training strategies (one inspired by standard Language Models, and another inspired by Wasserstein Generative Adversarial Networks). We evaluate our hypothesis on five datasets (three of which have been specifically collected to represent an adversarial setting) and using two learning algorithms for the AV classifier (Support Vector Machines and Convolutional Neural Networks). This experimentation has yielded negative results, revealing that, although our methodology proves effective in many adversarial settings, its benefits are too sporadic for a pragmatical application. ",
    "url": "https://arxiv.org/abs/2403.11265",
    "authors": [
      "Silvia Corbara",
      "Alejandro Moreo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11270",
    "title": "Bilateral Propagation Network for Depth Completion",
    "abstract": "Depth completion aims to derive a dense depth map from sparse depth measurements with a synchronized color image. Current state-of-the-art (SOTA) methods are predominantly propagation-based, which work as an iterative refinement on the initial estimated dense depth. However, the initial depth estimations mostly result from direct applications of convolutional layers on the sparse depth map. In this paper, we present a Bilateral Propagation Network (BP-Net), that propagates depth at the earliest stage to avoid directly convolving on sparse data. Specifically, our approach propagates the target depth from nearby depth measurements via a non-linear model, whose coefficients are generated through a multi-layer perceptron conditioned on both \\emph{radiometric difference} and \\emph{spatial distance}. By integrating bilateral propagation with multi-modal fusion and depth refinement in a multi-scale framework, our BP-Net demonstrates outstanding performance on both indoor and outdoor scenes. It achieves SOTA on the NYUv2 dataset and ranks 1st on the KITTI depth completion benchmark at the time of submission. Experimental results not only show the effectiveness of bilateral propagation but also emphasize the significance of early-stage propagation in contrast to the refinement stage. Our code and trained models will be available on the project page. ",
    "url": "https://arxiv.org/abs/2403.11270",
    "authors": [
      "Jie Tang",
      "Fei-Peng Tian",
      "Boshi An",
      "Jian Li",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11292",
    "title": "Multi-Relational Graph Neural Network for Out-of-Domain Link Prediction",
    "abstract": "Dynamic multi-relational graphs are an expressive relational representation for data enclosing entities and relations of different types, and where relationships are allowed to vary in time. Addressing predictive tasks over such data requires the ability to find structure embeddings that capture the diversity of the relationships involved, as well as their dynamic evolution. In this work, we establish a novel class of challenging tasks for dynamic multi-relational graphs involving out-of-domain link prediction, where the relationship being predicted is not available in the input graph. We then introduce a novel Graph Neural Network model, named GOOD, designed specifically to tackle the out-of-domain generalization problem. GOOD introduces a novel design concept for multi-relation embedding aggregation, based on the idea that good representations are such when it is possible to disentangle the mixing proportions of the different relational embeddings that have produced it. We also propose five benchmarks based on two retail domains, where we show that GOOD can effectively generalize predictions out of known relationship types and achieve state-of-the-art results. Most importantly, we provide insights into problems where out-of-domain prediction might be preferred to an in-domain formulation, that is, where the relationship to be predicted has very few positive examples. ",
    "url": "https://arxiv.org/abs/2403.11292",
    "authors": [
      "Asma Sattar",
      "Georgios Deligiorgis",
      "Marco Trincavelli",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11297",
    "title": "A Modified Word Saliency-Based Adversarial Attack on Text Classification  Models",
    "abstract": "This paper introduces a novel adversarial attack method targeting text classification models, termed the Modified Word Saliency-based Adversarial At-tack (MWSAA). The technique builds upon the concept of word saliency to strategically perturb input texts, aiming to mislead classification models while preserving semantic coherence. By refining the traditional adversarial attack approach, MWSAA significantly enhances its efficacy in evading detection by classification systems. The methodology involves first identifying salient words in the input text through a saliency estimation process, which prioritizes words most influential to the model's decision-making process. Subsequently, these salient words are subjected to carefully crafted modifications, guided by semantic similarity metrics to ensure that the altered text remains coherent and retains its original meaning. Empirical evaluations conducted on diverse text classification datasets demonstrate the effectiveness of the proposed method in generating adversarial examples capable of successfully deceiving state-of-the-art classification models. Comparative analyses with existing adversarial attack techniques further indicate the superiority of the proposed approach in terms of both attack success rate and preservation of text coherence. ",
    "url": "https://arxiv.org/abs/2403.11297",
    "authors": [
      "Hetvi Waghela",
      "Sneha Rakshit",
      "Jaydip Sen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11303",
    "title": "A Brief Study of Computer Network Security Technologies",
    "abstract": "The rapid development of computer network system brings both a great convenience and new security threats for users. Network security problem generally includes network system security and data security. Specifically, it refers to the reliability of network system, confidentiality, integrity and availability of data information in the system. This paper introduces the significance of network security systems and highlights related technologies, mainly authentication, data encryption, firewall and antivirus technology. Network security problems can be faced by any network user, therefore we must greatly prioritize network security, try to prevent hostile attacks and ensure the overall security of the network system. ",
    "url": "https://arxiv.org/abs/2403.11303",
    "authors": [
      "Tulasi Udupa A",
      "Sushma Jayaram",
      "Shreya Ganesh Hegde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.11332",
    "title": "Graph Neural Network based Double Machine Learning Estimator of Network  Causal Effects",
    "abstract": "Our paper addresses the challenge of inferring causal effects in social network data, characterized by complex interdependencies among individuals resulting in challenges such as non-independence of units, interference (where a unit's outcome is affected by neighbors' treatments), and introduction of additional confounding factors from neighboring units. We propose a novel methodology combining graph neural networks and double machine learning, enabling accurate and efficient estimation of direct and peer effects using a single observational social network. Our approach utilizes graph isomorphism networks in conjunction with double machine learning to effectively adjust for network confounders and consistently estimate the desired causal effects. We demonstrate that our estimator is both asymptotically normal and semiparametrically efficient. A comprehensive evaluation against four state-of-the-art baseline methods using three semi-synthetic social network datasets reveals our method's on-par or superior efficacy in precise causal effect estimation. Further, we illustrate the practical application of our method through a case study that investigates the impact of Self-Help Group participation on financial risk tolerance. The results indicate a significant positive direct effect, underscoring the potential of our approach in social network analysis. Additionally, we explore the effects of network sparsity on estimation performance. ",
    "url": "https://arxiv.org/abs/2403.11332",
    "authors": [
      "Seyedeh Baharan Khatami",
      "Harsh Parikh",
      "Haowei Chen",
      "Sudeepa Roy",
      "Babak Salimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.11337",
    "title": "Enhancing Bandwidth Efficiency for Video Motion Transfer Applications  using Deep Learning Based Keypoint Prediction",
    "abstract": "We propose a deep learning based novel prediction framework for enhanced bandwidth reduction in motion transfer enabled video applications such as video conferencing, virtual reality gaming and privacy preservation for patient health monitoring. To model complex motion, we use the First Order Motion Model (FOMM) that represents dynamic objects using learned keypoints along with their local affine transformations. Keypoints are extracted by a self-supervised keypoint detector and organized in a time series corresponding to the video frames. Prediction of keypoints, to enable transmission using lower frames per second on the source device, is performed using a Variational Recurrent Neural Network (VRNN). The predicted keypoints are then synthesized to video frames using an optical flow estimator and a generator network. This efficacy of leveraging keypoint based representations in conjunction with VRNN based prediction for both video animation and reconstruction is demonstrated on three diverse datasets. For real-time applications, our results show the effectiveness of our proposed architecture by enabling up to 2x additional bandwidth reduction over existing keypoint based video motion transfer frameworks without significantly compromising video quality. ",
    "url": "https://arxiv.org/abs/2403.11337",
    "authors": [
      "Xue Bai",
      "Tasmiah Haque",
      "Sumit Mohan",
      "Yuliang Cai",
      "Byungheon Jeong",
      "Adam Halasz",
      "Srinjoy Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11343",
    "title": "Federated Transfer Learning with Differential Privacy",
    "abstract": "Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \\textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of differential privacy. Our analyses incorporate data heterogeneity and privacy, highlighting the fundamental costs of both in federated learning and underscoring the benefit of knowledge transfer across data sets. ",
    "url": "https://arxiv.org/abs/2403.11343",
    "authors": [
      "Mengchu Li",
      "Ye Tian",
      "Yang Feng",
      "Yi Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.11348",
    "title": "COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via  Probabilistic Circuits",
    "abstract": "Conformal prediction has shown spurring performance in constructing statistically rigorous prediction sets for arbitrary black-box machine learning models, assuming the data is exchangeable. However, even small adversarial perturbations during the inference can violate the exchangeability assumption, challenge the coverage guarantees, and result in a subsequent decline in empirical coverage. In this work, we propose a certifiably robust learning-reasoning conformal prediction framework (COLEP) via probabilistic circuits, which comprise a data-driven learning component that trains statistical models to learn different semantic concepts, and a reasoning component that encodes knowledge and characterizes the relationships among the trained models for logic reasoning. To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) within the reasoning component. Theoretically, we provide end-to-end certification of prediction coverage for COLEP in the presence of bounded adversarial perturbations. We also provide certified coverage considering the finite size of the calibration set. Furthermore, we prove that COLEP achieves higher prediction coverage and accuracy over a single model as long as the utilities of knowledge models are non-trivial. Empirically, we show the validity and tightness of our certified coverage, demonstrating the robust conformal prediction of COLEP on various datasets, including GTSRB, CIFAR10, and AwA2. We show that COLEP achieves up to 12% improvement in certified coverage on GTSRB, 9% on CIFAR-10, and 14% on AwA2. ",
    "url": "https://arxiv.org/abs/2403.11348",
    "authors": [
      "Mintong Kang",
      "Nezihe Merve G\u00fcrel",
      "Linyi Li",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.11350",
    "title": "Robustness of the data-driven approach in limited angle tomography",
    "abstract": "The limited angle Radon transform is notoriously difficult to invert due to the ill-posedness. In this work, we give a mathematical explanation that the data-driven approach based on deep neural networks can reconstruct more information in a stable way compared to traditional methods. ",
    "url": "https://arxiv.org/abs/2403.11350",
    "authors": [
      "Yiran Wang",
      "Yimin Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11361",
    "title": "Graph Theory for Consent Management: A New Approach for Complex Data  Flows",
    "abstract": "Through legislation and technical advances users gain more control over how their data is processed, and they expect online services to respect their privacy choices and preferences. However, data may be processed for many different purposes by several layers of algorithms that create complex data workflows. To date, there is no existing approach to automatically satisfy fine-grained privacy constraints of a user in a way which optimises the service provider's gains from processing. In this article, we propose a solution to this problem by modelling a data flow as a graph. User constraints and processing purposes are pairs of vertices which need to be disconnected in this graph. In general, this problem is NP-hard, thus, we propose several heuristics and algorithms. We discuss the optimality versus efficiency of our algorithms and evaluate them using synthetically generated data. On the practical side, our algorithms can provide nearly optimal solutions for tens of constraints and graphs of thousands of nodes, in a few seconds. ",
    "url": "https://arxiv.org/abs/2403.11361",
    "authors": [
      "Dorota Filipczuk",
      "Enrico H. Gerding",
      "George Konstantinidis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.11367",
    "title": "3DGS-ReLoc: 3D Gaussian Splatting for Map Representation and Visual  ReLocalization",
    "abstract": "This paper presents a novel system designed for 3D mapping and visual relocalization using 3D Gaussian Splatting. Our proposed method uses LiDAR and camera data to create accurate and visually plausible representations of the environment. By leveraging LiDAR data to initiate the training of the 3D Gaussian Splatting map, our system constructs maps that are both detailed and geometrically accurate. To mitigate excessive GPU memory usage and facilitate rapid spatial queries, we employ a combination of a 2D voxel map and a KD-tree. This preparation makes our method well-suited for visual localization tasks, enabling efficient identification of correspondences between the query image and the rendered image from the Gaussian Splatting map via normalized cross-correlation (NCC). Additionally, we refine the camera pose of the query image using feature-based matching and the Perspective-n-Point (PnP) technique. The effectiveness, adaptability, and precision of our system are demonstrated through extensive evaluation on the KITTI360 dataset. ",
    "url": "https://arxiv.org/abs/2403.11367",
    "authors": [
      "Peng Jiang",
      "Gaurav Pandey",
      "Srikanth Saripalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11370",
    "title": "DynamicGlue: Epipolar and Time-Informed Data Association in Dynamic  Environments using Graph Neural Networks",
    "abstract": "The assumption of a static environment is common in many geometric computer vision tasks like SLAM but limits their applicability in highly dynamic scenes. Since these tasks rely on identifying point correspondences between input images within the static part of the environment, we propose a graph neural network-based sparse feature matching network designed to perform robust matching under challenging conditions while excluding keypoints on moving objects. We employ a similar scheme of attentional aggregation over graph edges to enhance keypoint representations as state-of-the-art feature-matching networks but augment the graph with epipolar and temporal information and vastly reduce the number of graph edges. Furthermore, we introduce a self-supervised training scheme to extract pseudo labels for image pairs in dynamic environments from exclusively unprocessed visual-inertial data. A series of experiments show the superior performance of our network as it excludes keypoints on moving objects compared to state-of-the-art feature matching networks while still achieving similar results regarding conventional matching metrics. When integrated into a SLAM system, our network significantly improves performance, especially in highly dynamic scenes. ",
    "url": "https://arxiv.org/abs/2403.11370",
    "authors": [
      "Theresa Huber",
      "Simon Schaefer",
      "Stefan Leutenegger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11375",
    "title": "Path-GPTOmic: A Balanced Multi-modal Learning Framework for Survival  Outcome Prediction",
    "abstract": "For predicting cancer survival outcomes, standard approaches in clinical research are often based on two main modalities: pathology images for observing cell morphology features, and genomic (e.g., bulk RNA-seq) for quantifying gene expressions. However, existing pathology-genomic multi-modal algorithms face significant challenges: (1) Valuable biological insights regarding genes and gene-gene interactions are frequently overlooked; (2) one modality often dominates the optimization process, causing inadequate training for the other modality. In this paper, we introduce a new multi-modal ``Path-GPTOmic\" framework for cancer survival outcome prediction. First, to extract valuable biological insights, we regulate the embedding space of a foundation model, scGPT, initially trained on single-cell RNA-seq data, making it adaptable for bulk RNA-seq data. Second, to address the imbalance-between-modalities problem, we propose a gradient modulation mechanism tailored to the Cox partial likelihood loss for survival prediction. The contributions of the modalities are dynamically monitored and adjusted during the training process, encouraging that both modalities are sufficiently trained. Evaluated on two TCGA(The Cancer Genome Atlas) datasets, our model achieves substantially improved survival prediction accuracy. ",
    "url": "https://arxiv.org/abs/2403.11375",
    "authors": [
      "Hongxiao Wang",
      "Yang Yang",
      "Zhuo Zhao",
      "Pengfei Gu",
      "Nishchal Sapkota",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2403.11380",
    "title": "Boosting Order-Preserving and Transferability for Neural Architecture  Search: a Joint Architecture Refined Search and Fine-tuning Approach",
    "abstract": "Supernet is a core component in many recent Neural Architecture Search (NAS) methods. It not only helps embody the search space but also provides a (relative) estimation of the final performance of candidate architectures. Thus, it is critical that the top architectures ranked by a supernet should be consistent with those ranked by true performance, which is known as the order-preserving ability. In this work, we analyze the order-preserving ability on the whole search space (global) and a sub-space of top architectures (local), and empirically show that the local order-preserving for current two-stage NAS methods still need to be improved. To rectify this, we propose a novel concept of Supernet Shifting, a refined search strategy combining architecture searching with supernet fine-tuning. Specifically, apart from evaluating, the training loss is also accumulated in searching and the supernet is updated every iteration. Since superior architectures are sampled more frequently in evolutionary searching, the supernet is encouraged to focus on top architectures, thus improving local order-preserving. Besides, a pre-trained supernet is often un-reusable for one-shot methods. We show that Supernet Shifting can fulfill transferring supernet to a new dataset. Specifically, the last classifier layer will be unset and trained through evolutionary searching. Comprehensive experiments show that our method has better order-preserving ability and can find a dominating architecture. Moreover, the pre-trained supernet can be easily transferred into a new dataset with no loss of performance. ",
    "url": "https://arxiv.org/abs/2403.11380",
    "authors": [
      "Beichen Zhang",
      "Xiaoxing Wang",
      "Xiaohan Qin",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11391",
    "title": "Investigating the Benefits of Projection Head for Representation  Learning",
    "abstract": "An effective technique for obtaining high-quality representations is adding a projection head on top of the encoder during training, then discarding it and using the pre-projection representations. Despite its proven practical effectiveness, the reason behind the success of this technique is poorly understood. The pre-projection representations are not directly optimized by the loss function, raising the question: what makes them better? In this work, we provide a rigorous theoretical answer to this question. We start by examining linear models trained with self-supervised contrastive loss. We reveal that the implicit bias of training algorithms leads to layer-wise progressive feature weighting, where features become increasingly unequal as we go deeper into the layers. Consequently, lower layers tend to have more normalized and less specialized representations. We theoretically characterize scenarios where such representations are more beneficial, highlighting the intricate interplay between data augmentation and input features. Additionally, we demonstrate that introducing non-linearity into the network allows lower layers to learn features that are completely absent in higher layers. Finally, we show how this mechanism improves the robustness in supervised contrastive learning and supervised learning. We empirically validate our results through various experiments on CIFAR-10/100, UrbanCars and shifted versions of ImageNet. We also introduce a potential alternative to projection head, which offers a more interpretable and controllable design. ",
    "url": "https://arxiv.org/abs/2403.11391",
    "authors": [
      "Yihao Xue",
      "Eric Gan",
      "Jiayi Ni",
      "Siddharth Joshi",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11397",
    "title": "Defense Against Adversarial Attacks on No-Reference Image Quality Models  with Gradient Norm Regularization",
    "abstract": "The task of No-Reference Image Quality Assessment (NR-IQA) is to estimate the quality score of an input image without additional information. NR-IQA models play a crucial role in the media industry, aiding in performance evaluation and optimization guidance. However, these models are found to be vulnerable to adversarial attacks, which introduce imperceptible perturbations to input images, resulting in significant changes in predicted scores. In this paper, we propose a defense method to improve the stability in predicted scores when attacked by small perturbations, thus enhancing the adversarial robustness of NR-IQA models. To be specific, we present theoretical evidence showing that the magnitude of score changes is related to the $\\ell_1$ norm of the model's gradient with respect to the input image. Building upon this theoretical foundation, we propose a norm regularization training strategy aimed at reducing the $\\ell_1$ norm of the gradient, thereby boosting the robustness of NR-IQA models. Experiments conducted on four NR-IQA baseline models demonstrate the effectiveness of our strategy in reducing score changes in the presence of adversarial attacks. To the best of our knowledge, this work marks the first attempt to defend against adversarial attacks on NR-IQA models. Our study offers valuable insights into the adversarial robustness of NR-IQA models and provides a foundation for future research in this area. ",
    "url": "https://arxiv.org/abs/2403.11397",
    "authors": [
      "Yujia Liu",
      "Chenxi Yang",
      "Dingquan Li",
      "Jianhao Ding",
      "Tingting Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.11408",
    "title": "Layer-diverse Negative Sampling for Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are a powerful solution for various structure learning applications due to their strong representation capabilities for graph data. However, traditional GNNs, relying on message-passing mechanisms that gather information exclusively from first-order neighbours (known as positive samples), can lead to issues such as over-smoothing and over-squashing. To mitigate these issues, we propose a layer-diverse negative sampling method for message-passing propagation. This method employs a sampling matrix within a determinantal point process, which transforms the candidate set into a space and selectively samples from this space to generate negative samples. To further enhance the diversity of the negative samples during each forward pass, we develop a space-squeezing method to achieve layer-wise diversity in multi-layer GNNs. Experiments on various real-world graph datasets demonstrate the effectiveness of our approach in improving the diversity of negative samples and overall learning performance. Moreover, adding negative samples dynamically changes the graph's topology, thus with the strong potential to improve the expressiveness of GNNs and reduce the risk of over-squashing. ",
    "url": "https://arxiv.org/abs/2403.11408",
    "authors": [
      "Wei Duan",
      "Jie Lu",
      "Yu Guang Wang",
      "Junyu Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11414",
    "title": "Table-Lookup MAC: Scalable Processing of Quantised Neural Networks in  FPGA Soft Logic",
    "abstract": "Recent advancements in neural network quantisation have yielded remarkable outcomes, with three-bit networks reaching state-of-the-art full-precision accuracy in complex tasks. These achievements present valuable opportunities for accelerating neural networks by computing in reduced precision. Implementing it on FPGAs can take advantage of bit-level reconfigurability, which is not available on conventional CPUs and GPUs. Simultaneously, the high data intensity of neural network processing has inspired computing-in-memory paradigms, including on FPGA platforms. By programming the effects of trained model weights as lookup operations in soft logic, the transfer of weight data from memory units can be avoided, alleviating the memory bottleneck. However, previous methods face poor scalability - the high logic utilisation limiting them to small networks/sub-networks of binary models with low accuracy. In this paper, we introduce Table Lookup Multiply-Accumulate (TLMAC) as a framework to compile and optimise quantised neural networks for scalable lookup-based processing. TLMAC clusters and maps unique groups of weights to lookup-based processing elements, enabling highly parallel computation while taking advantage of parameter redundancy. Further place and route algorithms are proposed to reduce LUT utilisation and routing congestion. We demonstrate that TLMAC significantly improves the scalability of previous related works. Our efficient logic mapping and high degree of reuse enables entire ImageNet-scale quantised models with full-precision accuracy to be implemented using lookup-based computing on one commercially available FPGA. ",
    "url": "https://arxiv.org/abs/2403.11414",
    "authors": [
      "Daniel Gerlinghoff",
      "Benjamin Chen Ming Choong",
      "Rick Siow Mong Goh",
      "Weng-Fai Wong",
      "Tao Luo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.11421",
    "title": "FastDecode: High-Throughput GPU-Efficient LLM Serving using  Heterogeneous Pipelines",
    "abstract": "Cost of serving large language models (LLM) is high, but the expensive and scarce GPUs are poorly efficient when generating tokens sequentially, unless the batch of sequences is enlarged. However, the batch size is limited by some constantly reused intermediate results, namely KV-Cache. They occupy too much memory to fit more sequences into a GPU simultaneously. While they could be offloaded to host memory, the CPU-GPU bandwidth is an inevitable bottleneck. We find a way to decompose the transformer models into two parts of different characteristics, one of which includes the memory-bound KV-Cache accessing. Our key insight is that the aggregated memory capacity, bandwidth, and computing power of CPUs across multiple nodes is an efficient option to process this part. Performance improvement comes from reduced data transmission overhead and boosted GPU throughput to process the other model part. Moreover, we address efficiency challenges brought by heterogeneity at both temporal and inter-device scopes using scheduling and performance modeling techniques. Evaluation results show that our system achieves 1.88x - 5.04x the throughput of vLLM when serving modern LLMs with the same GPU. ",
    "url": "https://arxiv.org/abs/2403.11421",
    "authors": [
      "Jiaao He",
      "Jidong Zhai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2403.11424",
    "title": "Benchmarking the Robustness of UAV Tracking Against Common Corruptions",
    "abstract": "The robustness of unmanned aerial vehicle (UAV) tracking is crucial in many tasks like surveillance and robotics. Despite its importance, little attention is paid to the performance of UAV trackers under common corruptions due to lack of a dedicated platform. Addressing this, we propose UAV-C, a large-scale benchmark for assessing robustness of UAV trackers under common corruptions. Specifically, UAV-C is built upon two popular UAV datasets by introducing 18 common corruptions from 4 representative categories including adversarial, sensor, blur, and composite corruptions in different levels. Finally, UAV-C contains more than 10K sequences. To understand the robustness of existing UAV trackers against corruptions, we extensively evaluate 12 representative algorithms on UAV-C. Our study reveals several key findings: 1) Current trackers are vulnerable to corruptions, indicating more attention needed in enhancing the robustness of UAV trackers; 2) When accompanying together, composite corruptions result in more severe degradation to trackers; and 3) While each tracker has its unique performance profile, some trackers may be more sensitive to specific corruptions. By releasing UAV-C, we hope it, along with comprehensive analysis, serves as a valuable resource for advancing the robustness of UAV tracking against corruption. Our UAV-C will be available at https://github.com/Xiaoqiong-Liu/UAV-C. ",
    "url": "https://arxiv.org/abs/2403.11424",
    "authors": [
      "Xiaoqiong Liu",
      "Yunhe Feng",
      "Shu Hu",
      "Xiaohui Yuan",
      "Heng Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11426",
    "title": "ETH-Tight Algorithm for Cycle Packing on Unit Disk Graphs",
    "abstract": "In this paper, we consider the Cycle Packing problem on unit disk graphs defined as follows. Given a unit disk graph G with n vertices and an integer k, the goal is to find a set of $k$ vertex-disjoint cycles of G if it exists. Our algorithm runs in time $2^{O(\\sqrt k)}n^{O(1)}$. This improves the $2^{O(\\sqrt k\\log k)}n^{O(1)}$-time algorithm by Fomin et al. [SODA 2012, ICALP 2017]. Moreover, our algorithm is optimal assuming the exponential-time hypothesis. ",
    "url": "https://arxiv.org/abs/2403.11426",
    "authors": [
      "Shinwoo An",
      "Eunjin Oh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2403.11440",
    "title": "Boosting Continuous Emotion Recognition with Self-Pretraining using  Masked Autoencoders, Temporal Convolutional Networks, and Transformers",
    "abstract": "Human emotion recognition holds a pivotal role in facilitating seamless human-computer interaction. This paper delineates our methodology in tackling the Valence-Arousal (VA) Estimation Challenge, Expression (Expr) Classification Challenge, and Action Unit (AU) Detection Challenge within the ambit of the 6th Workshop and Competition on Affective Behavior Analysis in-the-wild (ABAW). Our study advocates a novel approach aimed at refining continuous emotion recognition. We achieve this by initially harnessing pre-training with Masked Autoencoders (MAE) on facial datasets, followed by fine-tuning on the aff-wild2 dataset annotated with expression (Expr) labels. The pre-trained model serves as an adept visual feature extractor, thereby enhancing the model's robustness. Furthermore, we bolster the performance of continuous emotion recognition by integrating Temporal Convolutional Network (TCN) modules and Transformer Encoder modules into our framework. ",
    "url": "https://arxiv.org/abs/2403.11440",
    "authors": [
      "Weiwei Zhou",
      "Jiada Lu",
      "Chenkun Ling",
      "Weifeng Wang",
      "Shaowei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11445",
    "title": "Budget Recycling Differential Privacy",
    "abstract": "Differential Privacy (DP) mechanisms usually {force} reduction in data utility by producing ``out-of-bound'' noisy results for a tight privacy budget. We introduce the Budget Recycling Differential Privacy (BR-DP) framework, designed to provide soft-bounded noisy outputs for a broad range of existing DP mechanisms. By ``soft-bounded,\" we refer to the mechanism's ability to release most outputs within a predefined error boundary, thereby improving utility and maintaining privacy simultaneously. The core of BR-DP consists of two components: a DP kernel responsible for generating a noisy answer per iteration, and a recycler that probabilistically recycles/regenerates or releases the noisy answer. We delve into the privacy accounting of BR-DP, culminating in the development of a budgeting principle that optimally sub-allocates the available budget between the DP kernel and the recycler. Furthermore, we introduce algorithms for tight BR-DP accounting in composition scenarios, and our findings indicate that BR-DP achieves reduced privacy leakage post-composition compared to DP. Additionally, we explore the concept of privacy amplification via subsampling within the BR-DP framework and propose optimal sampling rates for BR-DP across various queries. We experiment with real data, and the results demonstrate BR-DP's effectiveness in lifting the utility-privacy tradeoff provided by DP mechanisms. ",
    "url": "https://arxiv.org/abs/2403.11445",
    "authors": [
      "Bo Jiang",
      "Jian Du",
      "Sagar Shamar",
      "Qiang Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.11448",
    "title": "Robust Overfitting Does Matter: Test-Time Adversarial Purification With  FGSM",
    "abstract": "Numerous studies have demonstrated the susceptibility of deep neural networks (DNNs) to subtle adversarial perturbations, prompting the development of many advanced adversarial defense methods aimed at mitigating adversarial attacks. Current defense strategies usually train DNNs for a specific adversarial attack method and can achieve good robustness in defense against this type of adversarial attack. Nevertheless, when subjected to evaluations involving unfamiliar attack modalities, empirical evidence reveals a pronounced deterioration in the robustness of DNNs. Meanwhile, there is a trade-off between the classification accuracy of clean examples and adversarial examples. Most defense methods often sacrifice the accuracy of clean examples in order to improve the adversarial robustness of DNNs. To alleviate these problems and enhance the overall robust generalization of DNNs, we propose the Test-Time Pixel-Level Adversarial Purification (TPAP) method. This approach is based on the robust overfitting characteristic of DNNs to the fast gradient sign method (FGSM) on training and test datasets. It utilizes FGSM for adversarial purification, to process images for purifying unknown adversarial perturbations from pixels at testing time in a \"counter changes with changelessness\" manner, thereby enhancing the defense capability of DNNs against various unknown adversarial attacks. Extensive experimental results show that our method can effectively improve both overall robust generalization of DNNs, notably over previous methods. ",
    "url": "https://arxiv.org/abs/2403.11448",
    "authors": [
      "Linyu Tang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11449",
    "title": "Graph Partial Label Learning with Potential Cause Discovering",
    "abstract": "Graph Neural Networks (GNNs) have gained considerable attention for their potential in addressing challenges posed by complex graph-structured data in diverse domains. However, accurately annotating graph data for training is difficult due to the inherent complexity and interconnectedness of graphs. To tackle this issue, we propose a novel graph representation learning method that enables GNN models to effectively learn discriminative information even in the presence of noisy labels within the context of Partially Labeled Learning (PLL). PLL is a critical weakly supervised learning problem, where each training instance is associated with a set of candidate labels, including both the true label and additional noisy labels. Our approach leverages potential cause extraction to obtain graph data that exhibit a higher likelihood of possessing a causal relationship with the labels. By incorporating auxiliary training based on the extracted graph data, our model can effectively filter out the noise contained in the labels. We support the rationale behind our approach with a series of theoretical analyses. Moreover, we conduct extensive evaluations and ablation studies on multiple datasets, demonstrating the superiority of our proposed method. ",
    "url": "https://arxiv.org/abs/2403.11449",
    "authors": [
      "Hang Gao",
      "Jiaguo Yuan",
      "Jiangmeng Li",
      "Chengyu Yao",
      "Fengge Wu",
      "Junsuo Zhao",
      "Changwen Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11456",
    "title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive  Speech Detection via Large Language Models",
    "abstract": "The ubiquitousness of social media has led to the need for reliable and efficient detection of offensive content to limit harmful effects. This has led to a proliferation of datasets and models related to detecting offensive content. While sophisticated models have attained strong performance on individual datasets, these models often do not generalize due to differences between how \"offensive content\" is conceptualized, and the resulting differences in how these datasets are labeled. In this paper, we introduce HateCOT, a dataset of 52,000 samples drawn from diverse existing sources with explanations generated by GPT-3.5-Turbo and human-curated. We show that pre-training models for the detection of offensive content on HateCOT significantly boots open-sourced Language Models on three benchmark datasets in both zero and few-shot settings, despite differences in domain and task.} We further find that HateCOT enables effective K-shot fine-tuning in the low-resource settings. ",
    "url": "https://arxiv.org/abs/2403.11456",
    "authors": [
      "Huy Nghiem",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.11492",
    "title": "SmartRefine: An Scenario-Adaptive Refinement Framework for Efficient  Motion Prediction",
    "abstract": "Predicting the future motion of surrounding agents is essential for autonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed environments. Context information, such as road maps and surrounding agents' states, provides crucial geometric and semantic information for motion behavior prediction. To this end, recent works explore two-stage prediction frameworks where coarse trajectories are first proposed, and then used to select critical context information for trajectory refinement. However, they either incur a large amount of computation or bring limited improvement, if not both. In this paper, we introduce a novel scenario-adaptive refinement strategy, named SmartRefine, to refine prediction with minimal additional computation. Specifically, SmartRefine can comprehensively adapt refinement configurations based on each scenario's properties, and smartly chooses the number of refinement iterations by introducing a quality score to measure the prediction quality and remaining refinement potential of each scenario. SmartRefine is designed as a generic and flexible approach that can be seamlessly integrated into most state-of-the-art motion prediction models. Experiments on Argoverse (1 & 2) show that our method consistently improves the prediction accuracy of multiple state-of-the-art prediction models. Specifically, by adding SmartRefine to QCNet, we outperform all published ensemble-free works on the Argoverse 2 leaderboard (single agent track) at submission. Comprehensive studies are also conducted to ablate design choices and explore the mechanism behind multi-iteration refinement. Codes are available at https://github.com/opendilab/SmartRefine/ ",
    "url": "https://arxiv.org/abs/2403.11492",
    "authors": [
      "Yang Zhou",
      "Hao Shao",
      "Letian Wang",
      "Steven L. Waslander",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11495",
    "title": "Semantic-Enhanced Representation Learning for Road Networks with  Temporal Dynamics",
    "abstract": "In this study, we introduce a novel framework called Toast for learning general-purpose representations of road networks, along with its advanced counterpart DyToast, designed to enhance the integration of temporal dynamics to boost the performance of various time-sensitive downstream tasks. Specifically, we propose to encode two pivotal semantic characteristics intrinsic to road networks: traffic patterns and traveling semantics. To achieve this, we refine the skip-gram module by incorporating auxiliary objectives aimed at predicting the traffic context associated with a target road segment. Moreover, we leverage trajectory data and design pre-training strategies based on Transformer to distill traveling semantics on road networks. DyToast further augments this framework by employing unified trigonometric functions characterized by their beneficial properties, enabling the capture of temporal evolution and dynamic nature of road networks more effectively. With these proposed techniques, we can obtain representations that encode multi-faceted aspects of knowledge within road networks, applicable across both road segment-based applications and trajectory-based applications. Extensive experiments on two real-world datasets across three tasks demonstrate that our proposed framework consistently outperforms the state-of-the-art baselines by a significant margin. ",
    "url": "https://arxiv.org/abs/2403.11495",
    "authors": [
      "Yile Chen",
      "Xiucheng Li",
      "Gao Cong",
      "Zhifeng Bao",
      "Cheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11502",
    "title": "Accelerating Handover in Mobile Satellite Network",
    "abstract": "The construction of Low Earth Orbit (LEO) satellite constellations has recently spurred tremendous attention from academia and industry. 5G and 6G standards have specified LEO satellite network as a key component of 5G and 6G networks. However, ground terminals experience frequent, high-latency handover incurred by satellites' fast travelling speed, which deteriorates the performance of latency-sensitive applications. To address this challenge, we propose a novel handover flowchart for mobile satellite networks, which can considerably reduce the handover latency. The innovation behind this scheme is to mitigate the interaction between the access and core networks that occupy the majority of time overhead by leveraging the predictable travelling trajectory and spatial distribution inherent in mobile satellite networks. Specifically, we design a fine-grained synchronized algorithm to address the synchronization problem due to the lack of control signalling delivery between the access and core networks. Moreover, we minimize the computational complexity of the core network using information such as the satellite access strategy and unique spatial distribution, which is caused by frequent prediction operations. We have built a prototype for a mobile satellite network using modified Open5GS and UERANSIM, which is driven by actual LEO satellite constellations such as Starlink and Kuiper. We have conducted extensive experiments, and the results demonstrate that our proposed handover scheme can considerably reduce the handover latency compared to the 3GPP Non-terrestrial Networks (NTN) and two other existing handover schemes. ",
    "url": "https://arxiv.org/abs/2403.11502",
    "authors": [
      "Jiasheng Wu",
      "Shaojie Su",
      "Xiong Wang",
      "Jingjing Zhang",
      "Yue Gao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.11507",
    "title": "Circle Representation for Medical Instance Object Segmentation",
    "abstract": "Recently, circle representation has been introduced for medical imaging, designed specifically to enhance the detection of instance objects that are spherically shaped (e.g., cells, glomeruli, and nuclei). Given its outstanding effectiveness in instance detection, it is compelling to consider the application of circle representation for segmenting instance medical objects. In this study, we introduce CircleSnake, a simple end-to-end segmentation approach that utilizes circle contour deformation for segmenting ball-shaped medical objects at the instance level. The innovation of CircleSnake lies in these three areas: (1) It substitutes the complex bounding box-to-octagon contour transformation with a more consistent and rotation-invariant bounding circle-to-circle contour adaptation. This adaptation specifically targets ball-shaped medical objects. (2) The circle representation employed in CircleSnake significantly reduces the degrees of freedom to two, compared to eight in the octagon representation. This reduction enhances both the robustness of the segmentation performance and the rotational consistency of the method. (3) CircleSnake is the first end-to-end deep instance segmentation pipeline to incorporate circle representation, encompassing consistent circle detection, circle contour proposal, and circular convolution in a unified framework. This integration is achieved through the novel application of circular graph convolution within the context of circle detection and instance segmentation. In practical applications, such as the detection of glomeruli, nuclei, and eosinophils in pathological images, CircleSnake has demonstrated superior performance and greater rotation invariance when compared to benchmarks. The code has been made publicly available: https://github.com/hrlblab/CircleSnake. ",
    "url": "https://arxiv.org/abs/2403.11507",
    "authors": [
      "Juming Xiong",
      "Ethan H. Nguyen",
      "Yilin Liu",
      "Ruining Deng",
      "Regina N Tyree",
      "Hernan Correa",
      "Girish Hiremath",
      "Yaohong Wang",
      "Haichun Yang",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11511",
    "title": "Sim-to-Real Grasp Detection with Global-to-Local RGB-D Adaptation",
    "abstract": "This paper focuses on the sim-to-real issue of RGB-D grasp detection and formulates it as a domain adaptation problem. In this case, we present a global-to-local method to address hybrid domain gaps in RGB and depth data and insufficient multi-modal feature alignment. First, a self-supervised rotation pre-training strategy is adopted to deliver robust initialization for RGB and depth networks. We then propose a global-to-local alignment pipeline with individual global domain classifiers for scene features of RGB and depth images as well as a local one specifically working for grasp features in the two modalities. In particular, we propose a grasp prototype adaptation module, which aims to facilitate fine-grained local feature alignment by dynamically updating and matching the grasp prototypes from the simulation and real-world scenarios throughout the training process. Due to such designs, the proposed method substantially reduces the domain shift and thus leads to consistent performance improvements. Extensive experiments are conducted on the GraspNet-Planar benchmark and physical environment, and superior results are achieved which demonstrate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2403.11511",
    "authors": [
      "Haoxiang Ma",
      "Ran Qin",
      "Modi shi",
      "Boyang Gao",
      "Di Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11515",
    "title": "SSAP: A Shape-Sensitive Adversarial Patch for Comprehensive Disruption  of Monocular Depth Estimation in Autonomous Navigation Applications",
    "abstract": "Monocular depth estimation (MDE) has advanced significantly, primarily through the integration of convolutional neural networks (CNNs) and more recently, Transformers. However, concerns about their susceptibility to adversarial attacks have emerged, especially in safety-critical domains like autonomous driving and robotic navigation. Existing approaches for assessing CNN-based depth prediction methods have fallen short in inducing comprehensive disruptions to the vision system, often limited to specific local areas. In this paper, we introduce SSAP (Shape-Sensitive Adversarial Patch), a novel approach designed to comprehensively disrupt monocular depth estimation (MDE) in autonomous navigation applications. Our patch is crafted to selectively undermine MDE in two distinct ways: by distorting estimated distances or by creating the illusion of an object disappearing from the system's perspective. Notably, our patch is shape-sensitive, meaning it considers the specific shape and scale of the target object, thereby extending its influence beyond immediate proximity. Furthermore, our patch is trained to effectively address different scales and distances from the camera. Experimental results demonstrate that our approach induces a mean depth estimation error surpassing 0.5, impacting up to 99% of the targeted region for CNN-based MDE models. Additionally, we investigate the vulnerability of Transformer-based MDE models to patch-based attacks, revealing that SSAP yields a significant error of 0.59 and exerts substantial influence over 99% of the target region on these models. ",
    "url": "https://arxiv.org/abs/2403.11515",
    "authors": [
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Ihsen Alouani",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11522",
    "title": "LOOPer: A Learned Automatic Code Optimizer For Polyhedral Compilers",
    "abstract": "While polyhedral compilers have shown success in implementing advanced code transformations, they still have challenges in selecting the most profitable transformations that lead to the best speedups. This has motivated the use of machine learning to build cost models to guide the search for polyhedral optimizations. State-of-the-art polyhedral compilers have demonstrated a viable proof-of-concept of this approach. While such a proof-of-concept has shown promise, it still has significant limitations. State-of-the-art polyhedral compilers that use a deep-learning cost model only support a small subset of affine transformations, limiting their ability to apply complex code transformations. They also only support simple programs that have a single loop nest and a rectangular iteration domain, limiting their applicability to many programs. These limitations significantly impact the generality of such compilers and autoschedulers and put into question the whole approach. In this paper, we introduce LOOPer, the first polyhedral autoscheduler that uses a deep-learning based cost model and covers a large set of affine transformations and programs. It supports the exploration of a large set of affine transformations, allowing the application of complex sequences of polyhedral transformations. It also supports the optimization of programs with multiple loop nests and with rectangular and non-rectangular iteration domains, allowing the optimization of an extensive set of programs. We implement and evaluate LOOPer and show that it achieves speedups over the state-of-the-art. On the Polybench benchmark, LOOPer achieves a geometric mean speedup of 1.59x over Tiramisu. LOOPer also achieves competitive speedups with a geometric mean speedup of 1.34x over Pluto, a state-of-the-art polyhedral compiler that does not use a machine-learning based cost model. ",
    "url": "https://arxiv.org/abs/2403.11522",
    "authors": [
      "Massinissa Merouani",
      "Khaled Afif Boudaoud",
      "Iheb Nassim Aouadj",
      "Nassim Tchoulak",
      "Islam Kara Bernou",
      "Hamza Benyamina",
      "Fatima Benbouzid-Si Tayeb",
      "Karima Benatchba",
      "Hugh Leather",
      "Riyadh Baghdadi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11536",
    "title": "OCR is All you need: Importing Multi-Modality into Image-based Defect  Detection System",
    "abstract": "Automatic optical inspection (AOI) plays a pivotal role in the manufacturing process, predominantly leveraging high-resolution imaging instruments for scanning purposes. It detects anomalies by analyzing image textures or patterns, making it an essential tool in industrial manufacturing and quality control. Despite its importance, the deployment of models for AOI often faces challenges. These include limited sample sizes, which hinder effective feature learning, variations among source domains, and sensitivities to changes in lighting and camera positions during imaging. These factors collectively compromise the accuracy of model predictions. Traditional AOI often fails to capitalize on the rich mechanism-parameter information from machines or inside images, including statistical parameters, which typically benefit AOI classification. To address this, we introduce an external modality-guided data mining framework, primarily rooted in optical character recognition (OCR), to extract statistical features from images as a second modality to enhance performance, termed OANet (Ocr-Aoi-Net). A key aspect of our approach is the alignment of external modality features, extracted using a single modality-aware model, with image features encoded by a convolutional neural network. This synergy enables a more refined fusion of semantic representations from different modalities. We further introduce feature refinement and a gating function in our OANet to optimize the combination of these features, enhancing inference and decision-making capabilities. Experimental outcomes show that our methodology considerably boosts the recall rate of the defect detection model and maintains high robustness even in challenging scenarios. ",
    "url": "https://arxiv.org/abs/2403.11536",
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Chun-Hung Sun",
      "Kuang-Ming Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11542",
    "title": "Topology Data Analysis-based Error Detection for Semantic Image  Transmission with Incremental Knowledge-based HARQ",
    "abstract": "Semantic communication (SemCom) aims to achieve high fidelity information delivery under low communication consumption by only guaranteeing semantic accuracy. Nevertheless, semantic communication still suffers from unexpected channel volatility and thus developing a re-transmission mechanism (e.g., hybrid automatic repeat request [HARQ]) is indispensable. In that regard, instead of discarding previously transmitted information, the incremental knowledge-based HARQ (IK-HARQ) is deemed as a more effective mechanism that could sufficiently utilize the information semantics. However, considering the possible existence of semantic ambiguity in image transmission, a simple bit-level cyclic redundancy check (CRC) might compromise the performance of IK-HARQ. Therefore, it emerges a strong incentive to revolutionize the CRC mechanism, so as to reap the benefits of both SemCom and HARQ. In this paper, built on top of swin transformer-based joint source-channel coding (JSCC) and IK-HARQ, we propose a semantic image transmission framework SC-TDA-HARQ. In particular, different from the conventional CRC, we introduce a topological data analysis (TDA)-based error detection method, which capably digs out the inner topological and geometric information of images, so as to capture semantic information and determine the necessity for re-transmission. Extensive numerical results validate the effectiveness and efficiency of the proposed SC-TDA-HARQ framework, especially under the limited bandwidth condition, and manifest the superiority of TDA-based error detection method in image transmission. ",
    "url": "https://arxiv.org/abs/2403.11542",
    "authors": [
      "Fei Ni",
      "Rongpeng Li",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11550",
    "title": "TARN-VIST: Topic Aware Reinforcement Network for Visual Storytelling",
    "abstract": "As a cross-modal task, visual storytelling aims to generate a story for an ordered image sequence automatically. Different from the image captioning task, visual storytelling requires not only modeling the relationships between objects in the image but also mining the connections between adjacent images. Recent approaches primarily utilize either end-to-end frameworks or multi-stage frameworks to generate relevant stories, but they usually overlook latent topic information. In this paper, in order to generate a more coherent and relevant story, we propose a novel method, Topic Aware Reinforcement Network for VIsual StoryTelling (TARN-VIST). In particular, we pre-extracted the topic information of stories from both visual and linguistic perspectives. Then we apply two topic-consistent reinforcement learning rewards to identify the discrepancy between the generated story and the human-labeled story so as to refine the whole generation process. Extensive experimental results on the VIST dataset and human evaluation demonstrate that our proposed model outperforms most of the competitive models across multiple evaluation metrics. ",
    "url": "https://arxiv.org/abs/2403.11550",
    "authors": [
      "Weiran Chen",
      "Xin Li",
      "Jiaqi Su",
      "Guiqian Zhu",
      "Ying Li",
      "Yi Ji",
      "Chunping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11561",
    "title": "Learning Unified Reference Representation for Unsupervised Multi-class  Anomaly Detection",
    "abstract": "In the field of multi-class anomaly detection, reconstruction-based methods derived from single-class anomaly detection face the well-known challenge of ``learning shortcuts'', wherein the model fails to learn the patterns of normal samples as it should, opting instead for shortcuts such as identity mapping or artificial noise elimination. Consequently, the model becomes unable to reconstruct genuine anomalies as normal instances, resulting in a failure of anomaly detection. To counter this issue, we present a novel unified feature reconstruction-based anomaly detection framework termed RLR (Reconstruct features from a Learnable Reference representation). Unlike previous methods, RLR utilizes learnable reference representations to compel the model to learn normal feature patterns explicitly, thereby prevents the model from succumbing to the ``learning shortcuts'' issue. Additionally, RLR incorporates locality constraints into the learnable reference to facilitate more effective normal pattern capture and utilizes a masked learnable key attention mechanism to enhance robustness. Evaluation of RLR on the 15-category MVTec-AD dataset and the 12-category VisA dataset shows superior performance compared to state-of-the-art methods under the unified setting. The code of RLR will be publicly available. ",
    "url": "https://arxiv.org/abs/2403.11561",
    "authors": [
      "Liren He",
      "Zhengkai Jiang",
      "Jinlong Peng",
      "Liang Liu",
      "Qiangang Du",
      "Xiaobin Hu",
      "Wenbing Zhu",
      "Mingmin Chi",
      "Yabiao Wang",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11563",
    "title": "Advancing Neuromorphic Computing: Mixed-Signal Design Techniques  Leveraging Brain Code Units and Fundamental Code Units",
    "abstract": "This paper introduces a groundbreaking digital neuromorphic architecture that innovatively integrates Brain Code Unit (BCU) and Fundamental Code Unit (FCU) using mixedsignal design methodologies. Leveraging open-source datasets and the latest advances in materials science, our research focuses on enhancing the computational efficiency, accuracy, and adaptability of neuromorphic systems. The core of our approach lies in harmonizing the precision and scalability of digital systems with the robustness and energy efficiency of analog processing. Through experimentation, we demonstrate the effectiveness of our system across various metrics. The BCU achieved an accuracy of 88.0% and a power efficiency of 20.0 GOP/s/W, while the FCU recorded an accuracy of 86.5% and a power efficiency of 18.5 GOP/s/W. Our mixed-signal design approach significantly improved latency and throughput, achieving a latency as low as 0.75 ms and throughput up to 213 TOP/s. These results firmly establish the potential of our architecture in neuromorphic computing, providing a solid foundation for future developments in this domain. Our study underscores the feasibility of mixedsignal neuromorphic systems and their promise in advancing the field, particularly in applications requiring high efficiency and adaptability ",
    "url": "https://arxiv.org/abs/2403.11563",
    "authors": [
      "Murat Isik",
      "Sols Miziev",
      "Wiktoria Pawlak",
      "Newton Howard"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.11567",
    "title": "R2SNet: Scalable Domain Adaptation for Object Detection in Cloud-Based  Robots Ecosystems via Proposal Refinement",
    "abstract": "We introduce a novel approach for scalable domain adaptation in cloud robotics scenarios where robots rely on third-party AI inference services powered by large pre-trained deep neural networks. Our method is based on a downstream proposal-refinement stage running locally on the robots, exploiting a new lightweight DNN architecture, R2SNet. This architecture aims to mitigate performance degradation from domain shifts by adapting the object detection process to the target environment, focusing on relabeling, rescoring, and suppression of bounding-box proposals. Our method allows for local execution on robots, addressing the scalability challenges of domain adaptation without incurring significant computational costs. Real-world results on mobile service robots performing door detection show the effectiveness of the proposed method in achieving scalable domain adaptation. ",
    "url": "https://arxiv.org/abs/2403.11567",
    "authors": [
      "Michele Antonazzi",
      "Matteo Luperto",
      "N. Alberto Borghese",
      "Nicola Basilico"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11574",
    "title": "Offline Multitask Representation Learning for Reinforcement Learning",
    "abstract": "We study offline multitask representation learning in reinforcement learning (RL), where a learner is provided with an offline dataset from different tasks that share a common representation and is asked to learn the shared representation. We theoretically investigate offline multitask low-rank RL, and propose a new algorithm called MORL for offline multitask representation learning. Furthermore, we examine downstream RL in reward-free, offline and online scenarios, where a new task is introduced to the agent that shares the same representation as the upstream offline tasks. Our theoretical results demonstrate the benefits of using the learned representation from the upstream offline task instead of directly learning the representation of the low-rank model. ",
    "url": "https://arxiv.org/abs/2403.11574",
    "authors": [
      "Haque Ishfaq",
      "Thanh Nguyen-Tang",
      "Songtao Feng",
      "Raman Arora",
      "Mengdi Wang",
      "Ming Yin",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11585",
    "title": "Linguacodus: A Synergistic Framework for Transformative Code Generation  in Machine Learning Pipelines",
    "abstract": "In the ever-evolving landscape of machine learning, seamless translation of natural language descriptions into executable code remains a formidable challenge. This paper introduces Linguacodus, an innovative framework designed to tackle this challenge by deploying a dynamic pipeline that iteratively transforms natural language task descriptions into code through high-level data-shaping instructions. The core of Linguacodus is a fine-tuned large language model (LLM), empowered to evaluate diverse solutions for various problems and select the most fitting one for a given task. This paper details the fine-tuning process, and sheds light on how natural language descriptions can be translated into functional code. Linguacodus represents a substantial leap towards automated code generation, effectively bridging the gap between task descriptions and executable code. It holds great promise for advancing machine learning applications across diverse domains. Additionally, we propose an algorithm capable of transforming a natural description of an ML task into code with minimal human interaction. In extensive experiments on a vast machine learning code dataset originating from Kaggle, we showcase the effectiveness of Linguacodus. The investigations highlight its potential applications across diverse domains, emphasizing its impact on applied machine learning in various scientific fields. ",
    "url": "https://arxiv.org/abs/2403.11585",
    "authors": [
      "Ekaterina Trofimova",
      "Emil Sataev",
      "Andrey E. Ustyuzhanin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.11586",
    "title": "DynoSurf: Neural Deformation-based Temporally Consistent Dynamic Surface  Reconstruction",
    "abstract": "This paper explores the problem of reconstructing temporally consistent surfaces from a 3D point cloud sequence without correspondence. To address this challenging task, we propose DynoSurf, an unsupervised learning framework integrating a template surface representation with a learnable deformation field. Specifically, we design a coarse-to-fine strategy for learning the template surface based on the deformable tetrahedron representation. Furthermore, we propose a learnable deformation representation based on the learnable control points and blending weights, which can deform the template surface non-rigidly while maintaining the consistency of the local shape. Experimental results demonstrate the significant superiority of DynoSurf over current state-of-the-art approaches, showcasing its potential as a powerful tool for dynamic mesh reconstruction. The code is publicly available at https://github.com/yaoyx689/DynoSurf. ",
    "url": "https://arxiv.org/abs/2403.11586",
    "authors": [
      "Yuxin Yao",
      "Siyu Ren",
      "Junhui Hou",
      "Zhi Deng",
      "Juyong Zhang",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11590",
    "title": "HSEmotion Team at the 6th ABAW Competition: Facial Expressions,  Valence-Arousal and Emotion Intensity Prediction",
    "abstract": "This article presents our results for the sixth Affective Behavior Analysis in-the-wild (ABAW) competition. To improve the trustworthiness of facial analysis, we study the possibility of using pre-trained deep models that extract reliable emotional features without the need to fine-tune the neural networks for a downstream task. In particular, we introduce several lightweight models based on MobileViT, MobileFaceNet, EfficientNet, and DDAMFN architectures trained in multi-task scenarios to recognize facial expressions, valence, and arousal on static photos. These neural networks extract frame-level features fed into a simple classifier, e.g., linear feed-forward neural network, to predict emotion intensity, compound expressions, action units, facial expressions, and valence/arousal. Experimental results for five tasks from the sixth ABAW challenge demonstrate that our approach lets us significantly improve quality metrics on validation sets compared to existing non-ensemble techniques. ",
    "url": "https://arxiv.org/abs/2403.11590",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11591",
    "title": "A physics-informed neural network method for the approximation of slow  invariant manifolds for the general class of stiff systems of ODEs",
    "abstract": "We present a physics-informed neural network (PINN) approach for the discovery of slow invariant manifolds (SIMs), for the most general class of fast/slow dynamical systems of ODEs. In contrast to other machine learning (ML) approaches that construct reduced order black box surrogate models using simple regression, and/or require a priori knowledge of the fast and slow variables, our approach, simultaneously decomposes the vector field into fast and slow components and provides a functional of the underlying SIM in a closed form. The decomposition is achieved by finding a transformation of the state variables to the fast and slow ones, which enables the derivation of an explicit, in terms of fast variables, SIM functional. The latter is obtained by solving a PDE corresponding to the invariance equation within the Geometric Singular Perturbation Theory (GSPT) using a single-layer feedforward neural network with symbolic differentiation. The performance of the proposed physics-informed ML framework is assessed via three benchmark problems: the Michaelis-Menten, the target mediated drug disposition (TMDD) reaction model and a fully competitive substrate-inhibitor(fCSI) mechanism. We also provide a comparison with other GPST methods, namely the quasi steady state approximation (QSSA), the partial equilibrium approximation (PEA) and CSP with one and two iterations. We show that the proposed PINN scheme provides SIM approximations, of equivalent or even higher accuracy, than those provided by QSSA, PEA and CSP, especially close to the boundaries of the underlying SIMs. ",
    "url": "https://arxiv.org/abs/2403.11591",
    "authors": [
      "Dimitrios G. Patsatzis",
      "Lucia Russo",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2403.11603",
    "title": "Fair Distributed Cooperative Bandit Learning on Networks for Intelligent  Internet of Things Systems (Technical Report)",
    "abstract": "In intelligent Internet of Things (IoT) systems, edge servers within a network exchange information with their neighbors and collect data from sensors to complete delivered tasks. In this paper, we propose a multiplayer multi-armed bandit model for intelligent IoT systems to facilitate data collection and incorporate fairness considerations. In our model, we establish an effective communication protocol that helps servers cooperate with their neighbors. Then we design a distributed cooperative bandit algorithm, DC-ULCB, enabling servers to collaboratively select sensors to maximize data rates while maintaining fairness in their choices. We conduct an analysis of the reward regret and fairness regret of DC-ULCB, and prove that both regrets have logarithmic instance-dependent upper bounds. Additionally, through extensive simulations, we validate that DC-ULCB outperforms existing algorithms in maximizing reward and ensuring fairness. ",
    "url": "https://arxiv.org/abs/2403.11603",
    "authors": [
      "Ziqun Chen",
      "Kechao Cai",
      "Jinbei Zhang",
      "Zhigang Yu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11624",
    "title": "Dual-Channel Multiplex Graph Neural Networks for Recommendation",
    "abstract": "Efficient recommender systems play a crucial role in accurately capturing user and item attributes that mirror individual preferences. Some existing recommendation techniques have started to shift their focus towards modeling various types of interaction relations between users and items in real-world recommendation scenarios, such as clicks, marking favorites, and purchases on online shopping platforms. Nevertheless, these approaches still grapple with two significant shortcomings: (1) Insufficient modeling and exploitation of the impact of various behavior patterns formed by multiplex relations between users and items on representation learning, and (2) ignoring the effect of different relations in the behavior patterns on the target relation in recommender system scenarios. In this study, we introduce a novel recommendation framework, Dual-Channel Multiplex Graph Neural Network (DCMGNN), which addresses the aforementioned challenges. It incorporates an explicit behavior pattern representation learner to capture the behavior patterns composed of multiplex user-item interaction relations, and includes a relation chain representation learning and a relation chain-aware encoder to discover the impact of various auxiliary relations on the target relation, the dependencies between different relations, and mine the appropriate order of relations in a behavior pattern. Extensive experiments on three real-world datasets demonstrate that our \\model surpasses various state-of-the-art recommendation methods. It outperforms the best baselines by 10.06\\% and 12.15\\% on average across all datasets in terms of R@10 and N@10 respectively. ",
    "url": "https://arxiv.org/abs/2403.11624",
    "authors": [
      "Xiang Li",
      "Chaofan Fu",
      "Zhongying Zhao",
      "Guanjie Zheng",
      "Chao Huang",
      "Junyu Dong",
      "Yanwei Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11626",
    "title": "QEAN: Quaternion-Enhanced Attention Network for Visual Dance Generation",
    "abstract": "The study of music-generated dance is a novel and challenging Image generation task. It aims to input a piece of music and seed motions, then generate natural dance movements for the subsequent music. Transformer-based methods face challenges in time series prediction tasks related to human movements and music due to their struggle in capturing the nonlinear relationship and temporal aspects. This can lead to issues like joint deformation, role deviation, floating, and inconsistencies in dance movements generated in response to the music. In this paper, we propose a Quaternion-Enhanced Attention Network (QEAN) for visual dance synthesis from a quaternion perspective, which consists of a Spin Position Embedding (SPE) module and a Quaternion Rotary Attention (QRA) module. First, SPE embeds position information into self-attention in a rotational manner, leading to better learning of features of movement sequences and audio sequences, and improved understanding of the connection between music and dance. Second, QRA represents and fuses 3D motion features and audio features in the form of a series of quaternions, enabling the model to better learn the temporal coordination of music and dance under the complex temporal cycle conditions of dance generation. Finally, we conducted experiments on the dataset AIST++, and the results show that our approach achieves better and more robust performance in generating accurate, high-quality dance movements. Our source code and dataset can be available from https://github.com/MarasyZZ/QEAN and https://google.github.io/aistplusplus_dataset respectively. ",
    "url": "https://arxiv.org/abs/2403.11626",
    "authors": [
      "Zhizhen Zhou",
      "Yejing Huo",
      "Guoheng Huang",
      "An Zeng",
      "Xuhang Chen",
      "Lian Huang",
      "Zinuo Li"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.11643",
    "title": "Diffusion-Based Environment-Aware Trajectory Prediction",
    "abstract": "The ability to predict the future trajectories of traffic participants is crucial for the safe and efficient operation of autonomous vehicles. In this paper, a diffusion-based generative model for multi-agent trajectory prediction is proposed. The model is capable of capturing the complex interactions between traffic participants and the environment, accurately learning the multimodal nature of the data. The effectiveness of the approach is assessed on large-scale datasets of real-world traffic scenarios, showing that our model outperforms several well-established methods in terms of prediction accuracy. By the incorporation of differential motion constraints on the model output, we illustrate that our model is capable of generating a diverse set of realistic future trajectories. Through the use of an interaction-aware guidance signal, we further demonstrate that the model can be adapted to predict the behavior of less cooperative agents, emphasizing its practical applicability under uncertain traffic conditions. ",
    "url": "https://arxiv.org/abs/2403.11643",
    "authors": [
      "Theodor Westny",
      "Bj\u00f6rn Olofsson",
      "Erik Frisk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11648",
    "title": "Vehicle single track modeling using physics guided neural differential  equations",
    "abstract": "In this paper, we follow the physics guided modeling approach and integrate a neural differential equation network into the physical structure of a vehicle single track model. By relying on the kinematic relations of the single track ordinary differential equations (ODE), a small neural network and few training samples are sufficient to substantially improve the model accuracy compared with a pure physics based vehicle single track model. To be more precise, the sum of squared error is reduced by 68% in the considered scenario. In addition, it is demonstrated that the prediction capabilities of the physics guided neural ODE model are superior compared with a pure black box neural differential equation approach. ",
    "url": "https://arxiv.org/abs/2403.11648",
    "authors": [
      "Stephan Rhode",
      "Fabian Jarmolowitz",
      "Felix Berkel"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2403.11656",
    "title": "LocalStyleFool: Regional Video Style Transfer Attack Using Segment  Anything Model",
    "abstract": "Previous work has shown that well-crafted adversarial perturbations can threaten the security of video recognition systems. Attackers can invade such models with a low query budget when the perturbations are semantic-invariant, such as StyleFool. Despite the query efficiency, the naturalness of the minutia areas still requires amelioration, since StyleFool leverages style transfer to all pixels in each frame. To close the gap, we propose LocalStyleFool, an improved black-box video adversarial attack that superimposes regional style-transfer-based perturbations on videos. Benefiting from the popularity and scalably usability of Segment Anything Model (SAM), we first extract different regions according to semantic information and then track them through the video stream to maintain the temporal consistency. Then, we add style-transfer-based perturbations to several regions selected based on the associative criterion of transfer-based gradient information and regional area. Perturbation fine adjustment is followed to make stylized videos adversarial. We demonstrate that LocalStyleFool can improve both intra-frame and inter-frame naturalness through a human-assessed survey, while maintaining competitive fooling rate and query efficiency. Successful experiments on the high-resolution dataset also showcase that scrupulous segmentation of SAM helps to improve the scalability of adversarial attacks under high-resolution data. ",
    "url": "https://arxiv.org/abs/2403.11656",
    "authors": [
      "Yuxin Cao",
      "Jinghao Li",
      "Xi Xiao",
      "Derui Wang",
      "Minhui Xue",
      "Hao Ge",
      "Wei Liu",
      "Guangwu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11662",
    "title": "FE-DeTr: Keypoint Detection and Tracking in Low-quality Image Frames  with Events",
    "abstract": "Keypoint detection and tracking in traditional image frames are often compromised by image quality issues such as motion blur and extreme lighting conditions. Event cameras offer potential solutions to these challenges by virtue of their high temporal resolution and high dynamic range. However, they have limited performance in practical applications due to their inherent noise in event data. This paper advocates fusing the complementary information from image frames and event streams to achieve more robust keypoint detection and tracking. Specifically, we propose a novel keypoint detection network that fuses the textural and structural information from image frames with the high-temporal-resolution motion information from event streams, namely FE-DeTr. The network leverages a temporal response consistency for supervision, ensuring stable and efficient keypoint detection. Moreover, we use a spatio-temporal nearest-neighbor search strategy for robust keypoint tracking. Extensive experiments are conducted on a new dataset featuring both image frames and event data captured under extreme conditions. The experimental results confirm the superior performance of our method over both existing frame-based and event-based methods. ",
    "url": "https://arxiv.org/abs/2403.11662",
    "authors": [
      "Xiangyuan Wang",
      "Kuangyi Chen",
      "Wen Yang",
      "Lei Yu",
      "Yannan Xing",
      "Huai Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11667",
    "title": "Binary Noise for Binary Tasks: Masked Bernoulli Diffusion for  Unsupervised Anomaly Detection",
    "abstract": "The high performance of denoising diffusion models for image generation has paved the way for their application in unsupervised medical anomaly detection. As diffusion-based methods require a lot of GPU memory and have long sampling times, we present a novel and fast unsupervised anomaly detection approach based on latent Bernoulli diffusion models. We first apply an autoencoder to compress the input images into a binary latent representation. Next, a diffusion model that follows a Bernoulli noise schedule is employed to this latent space and trained to restore binary latent representations from perturbed ones. The binary nature of this diffusion model allows us to identify entries in the latent space that have a high probability of flipping their binary code during the denoising process, which indicates out-of-distribution data. We propose a masking algorithm based on these probabilities, which improves the anomaly detection scores. We achieve state-of-the-art performance compared to other diffusion-based unsupervised anomaly detection algorithms while significantly reducing sampling time and memory consumption. The code is available at https://github.com/JuliaWolleb/Anomaly_berdiff. ",
    "url": "https://arxiv.org/abs/2403.11667",
    "authors": [
      "Julia Wolleb",
      "Florentin Bieder",
      "Paul Friedrich",
      "Peter Zhang",
      "Alicia Durrer",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.11669",
    "title": "Semantic Data Representation for Explainable Windows Malware Detection  Models",
    "abstract": "Ontologies are a standard tool for creating semantic schemata in many knowledge intensive domains of human interest. They are becoming increasingly important also in the areas that have been until very recently dominated by subsymbolic knowledge representation and machine-learning (ML) based data processing. One such area is information security, and specifically, malware detection. We thus propose PE Malware Ontology that offers a reusable semantic schema for Portable Executable (PE - the Windows binary format) malware files. This ontology is inspired by the structure of the EMBER dataset, which focuses on the static malware analysis of PE files. With this proposal, we hope to provide a unified semantic representation for the existing and future PE-malware datasets and facilitate the application of symbolic, neuro-symbolic, or otherwise explainable approaches in the PE-malware-detection domain, which may produce interpretable results described by the terms defined in our ontology. In addition, we also publish semantically treated EMBER data, including fractional datasets, to support the reproducibility of experiments on EMBER. We supplement our work with a preliminary case study, conducted using concept learning, to show the general feasibility of our approach. While we were not able to match the precision of the state-of-the-art ML tools, the learned malware discriminators were interesting and highly interpretable. ",
    "url": "https://arxiv.org/abs/2403.11669",
    "authors": [
      "Peter \u0160vec",
      "\u0160tefan Balogh",
      "Martin Homola",
      "J\u00e1n K\u013euka",
      "Tom\u00e1\u0161 Bist\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.11679",
    "title": "NEDS-SLAM: A Novel Neural Explicit Dense Semantic SLAM Framework using  3D Gaussian Splatting",
    "abstract": "We propose NEDS-SLAM, an Explicit Dense semantic SLAM system based on 3D Gaussian representation, that enables robust 3D semantic mapping, accurate camera tracking, and high-quality rendering in real-time. In the system, we propose a Spatially Consistent Feature Fusion model to reduce the effect of erroneous estimates from pre-trained segmentation head on semantic reconstruction, achieving robust 3D semantic Gaussian mapping. Additionally, we employ a lightweight encoder-decoder to compress the high-dimensional semantic features into a compact 3D Gaussian representation, mitigating the burden of excessive memory consumption. Furthermore, we leverage the advantage of 3D Gaussian splatting, which enables efficient and differentiable novel view rendering, and propose a Virtual Camera View Pruning method to eliminate outlier GS points, thereby effectively enhancing the quality of scene representations. Our NEDS-SLAM method demonstrates competitive performance over existing dense semantic SLAM methods in terms of mapping and tracking accuracy on Replica and ScanNet datasets, while also showing excellent capabilities in 3D dense semantic mapping. ",
    "url": "https://arxiv.org/abs/2403.11679",
    "authors": [
      "Yiming Ji",
      "Yang Liu",
      "Guanghu Xie",
      "Boyu Ma",
      "Zongwu Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11681",
    "title": "MASSTAR: A Multi-Modal and Large-Scale Scene Dataset with a Versatile  Toolchain for Surface Prediction and Completion",
    "abstract": "Surface prediction and completion have been widely studied in various applications. Recently, research in surface completion has evolved from small objects to complex large-scale scenes. As a result, researchers have begun increasing the volume of data and leveraging a greater variety of data modalities including rendered RGB images, descriptive texts, depth images, etc, to enhance algorithm performance. However, existing datasets suffer from a deficiency in the amounts of scene-level models along with the corresponding multi-modal information. Therefore, a method to scale the datasets and generate multi-modal information in them efficiently is essential. To bridge this research gap, we propose MASSTAR: a Multi-modal lArge-scale Scene dataset with a verSatile Toolchain for surfAce pRediction and completion. We develop a versatile and efficient toolchain for processing the raw 3D data from the environments. It screens out a set of fine-grained scene models and generates the corresponding multi-modal data. Utilizing the toolchain, we then generate an example dataset composed of over a thousand scene-level models with partial real-world data added. We compare MASSTAR with the existing datasets, which validates its superiority: the ability to efficiently extract high-quality models from complex scenarios to expand the dataset. Additionally, several representative surface completion algorithms are benchmarked on MASSTAR, which reveals that existing algorithms can hardly deal with scene-level completion. We will release the source code of our toolchain and the dataset. For more details, please see our project page at https://sysu-star.github.io/MASSTAR. ",
    "url": "https://arxiv.org/abs/2403.11681",
    "authors": [
      "Guiyong Zheng",
      "Jinqi Jiang",
      "Chen Feng",
      "Shaojie Shen",
      "Boyu Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11695",
    "title": "TrajectoryNAS: A Neural Architecture Search for Trajectory Prediction",
    "abstract": "Autonomous driving systems are a rapidly evolving technology that enables driverless car production. Trajectory prediction is a critical component of autonomous driving systems, enabling cars to anticipate the movements of surrounding objects for safe navigation. Trajectory prediction using Lidar point-cloud data performs better than 2D images due to providing 3D information. However, processing point-cloud data is more complicated and time-consuming than 2D images. Hence, state-of-the-art 3D trajectory predictions using point-cloud data suffer from slow and erroneous predictions. This paper introduces TrajectoryNAS, a pioneering method that focuses on utilizing point cloud data for trajectory prediction. By leveraging Neural Architecture Search (NAS), TrajectoryNAS automates the design of trajectory prediction models, encompassing object detection, tracking, and forecasting in a cohesive manner. This approach not only addresses the complex interdependencies among these tasks but also emphasizes the importance of accuracy and efficiency in trajectory modeling. Through empirical studies, TrajectoryNAS demonstrates its effectiveness in enhancing the performance of autonomous driving systems, marking a significant advancement in the field.Experimental results reveal that TrajcetoryNAS yield a minimum of 4.8 higger accuracy and 1.1* lower latency over competing methods on the NuScenes dataset. ",
    "url": "https://arxiv.org/abs/2403.11695",
    "authors": [
      "Ali Asghar Sharifi",
      "Ali Zoljodi",
      "Masoud Daneshtalab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11722",
    "title": "Time Series Compression using Quaternion Valued Neural Networks and  Quaternion Backpropagation",
    "abstract": "We propose a novel quaternionic time-series compression methodology where we divide a long time-series into segments of data, extract the min, max, mean and standard deviation of these chunks as representative features and encapsulate them in a quaternion, yielding a quaternion valued time-series. This time-series is processed using quaternion valued neural network layers, where we aim to preserve the relation between these features through the usage of the Hamilton product. To train this quaternion neural network, we derive quaternion backpropagation employing the GHR calculus, which is required for a valid product and chain rule in quaternion space. Furthermore, we investigate the connection between the derived update rules and automatic differentiation. We apply our proposed compression method on the Tennessee Eastman Dataset, where we perform fault classification using the compressed data in two settings: a fully supervised one and in a semi supervised, contrastive learning setting. Both times, we were able to outperform real valued counterparts as well as two baseline models: one with the uncompressed time-series as the input and the other with a regular downsampling using the mean. Further, we could improve the classification benchmark set by SimCLR-TS from 81.43% to 83.90%. ",
    "url": "https://arxiv.org/abs/2403.11722",
    "authors": [
      "Johannes P\u00f6ppelbaum",
      "Andreas Schwung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11732",
    "title": "Hallucination in Perceptual Metric-Driven Speech Enhancement Networks",
    "abstract": "Within the area of speech enhancement, there is an ongoing interest in the creation of neural systems which explicitly aim to improve the perceptual quality of the processed audio. In concert with this is the topic of non-intrusive (i.e. without clean reference) speech quality prediction, for which neural networks are trained to predict human-assigned quality labels directly from distorted audio. When combined, these areas allow for the creation of powerful new speech enhancement systems which can leverage large real-world datasets of distorted audio, by taking inference of a pre-trained speech quality predictor as the sole loss function of the speech enhancement system. This paper aims to identify a potential pitfall with this approach, namely hallucinations which are introduced by the enhancement system `tricking' the speech quality predictor. ",
    "url": "https://arxiv.org/abs/2403.11732",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.11743",
    "title": "PARMESAN: Parameter-Free Memory Search and Transduction for Dense  Prediction Tasks",
    "abstract": "In this work we address flexibility in deep learning by means of transductive reasoning. For adaptation to new tasks or new data, existing methods typically involve tuning of learnable parameters or even complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable transduction method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding examples. In contrast to other methods, PARMESAN learns without the requirement for any continuous training or fine-tuning of learnable parameters simply by modifying the memory content. Our method is compatible with commonly used neural architectures and canonically transfers to 1D, 2D, and 3D grid-based data. We demonstrate the capabilities of our approach at complex tasks such as continual and few-shot learning. PARMESAN learns up to 370 times faster than common baselines while being on par in terms of predictive performance, knowledge retention, and data-efficiency. ",
    "url": "https://arxiv.org/abs/2403.11743",
    "authors": [
      "Philip Matthias Winter",
      "Maria Wimmer",
      "David Major",
      "Dimitrios Lenis",
      "Astrid Berg",
      "Theresa Neubauer",
      "Gaia Romana De Paolis",
      "Johannes Novotny",
      "Sophia Ulonska",
      "Katja B\u00fchler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.11751",
    "title": "Relational Representation Learning Network for Cross-Spectral Image  Patch Matching",
    "abstract": "Recently, feature relation learning has drawn widespread attention in cross-spectral image patch matching. However, existing related research focuses on extracting diverse relations between image patch features and ignores sufficient intrinsic feature representations of individual image patches. Therefore, an innovative relational representation learning idea is proposed for the first time, which simultaneously focuses on sufficiently mining the intrinsic features of individual image patches and the relations between image patch features. Based on this, we construct a lightweight Relational Representation Learning Network (RRL-Net). Specifically, we innovatively construct an autoencoder to fully characterize the individual intrinsic features, and introduce a Feature Interaction Learning (FIL) module to extract deep-level feature relations. To further fully mine individual intrinsic features, a lightweight Multi-dimensional Global-to-Local Attention (MGLA) module is constructed to enhance the global feature extraction of individual image patches and capture local dependencies within global features. By combining the MGLA module, we further explore the feature extraction network and construct an Attention-based Lightweight Feature Extraction (ALFE) network. In addition, we propose a Multi-Loss Post-Pruning (MLPP) optimization strategy, which greatly promotes network optimization while avoiding increases in parameters and inference time. Extensive experiments demonstrate that our RRL-Net achieves state-of-the-art (SOTA) performance on multiple public datasets. Our code will be made public later. ",
    "url": "https://arxiv.org/abs/2403.11751",
    "authors": [
      "Chuang Yu",
      "Yunpeng Liu",
      "Jinmiao Zhao",
      "Dou Quan",
      "Zelin Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11776",
    "title": "DVN-SLAM: Dynamic Visual Neural SLAM Based on Local-Global Encoding",
    "abstract": "Recent research on Simultaneous Localization and Mapping (SLAM) based on implicit representation has shown promising results in indoor environments. However, there are still some challenges: the limited scene representation capability of implicit encodings, the uncertainty in the rendering process from implicit representations, and the disruption of consistency by dynamic objects. To address these challenges, we propose a real-time dynamic visual SLAM system based on local-global fusion neural implicit representation, named DVN-SLAM. To improve the scene representation capability, we introduce a local-global fusion neural implicit representation that enables the construction of an implicit map while considering both global structure and local details. To tackle uncertainties arising from the rendering process, we design an information concentration loss for optimization, aiming to concentrate scene information on object surfaces. The proposed DVN-SLAM achieves competitive performance in localization and mapping across multiple datasets. More importantly, DVN-SLAM demonstrates robustness in dynamic scenes, a trait that sets it apart from other NeRF-based methods. ",
    "url": "https://arxiv.org/abs/2403.11776",
    "authors": [
      "Wenhua Wu",
      "Guangming Wang",
      "Ting Deng",
      "Sebastian Aegidius",
      "Stuart Shanks",
      "Valerio Modugno",
      "Dimitrios Kanoulas",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11778",
    "title": "Towards the Development of a Real-Time Deepfake Audio Detection System  in Communication Platforms",
    "abstract": "Deepfake audio poses a rising threat in communication platforms, necessitating real-time detection for audio stream integrity. Unlike traditional non-real-time approaches, this study assesses the viability of employing static deepfake audio detection models in real-time communication platforms. An executable software is developed for cross-platform compatibility, enabling real-time execution. Two deepfake audio detection models based on Resnet and LCNN architectures are implemented using the ASVspoof 2019 dataset, achieving benchmark performances compared to ASVspoof 2019 challenge baselines. The study proposes strategies and frameworks for enhancing these models, paving the way for real-time deepfake audio detection in communication platforms. This work contributes to the advancement of audio stream security, ensuring robust detection capabilities in dynamic, real-time communication scenarios. ",
    "url": "https://arxiv.org/abs/2403.11778",
    "authors": [
      "Jonat John Mathew",
      "Rakin Ahsan",
      "Sae Furukawa",
      "Jagdish Gautham Krishna Kumar",
      "Huzaifa Pallan",
      "Agamjeet Singh Padda",
      "Sara Adamski",
      "Madhu Reddiboina",
      "Arjun Pankajakshan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.11786",
    "title": "Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained  Large Language Models",
    "abstract": "Extracting hyper-relations is crucial for constructing comprehensive knowledge graphs, but there are limited supervised methods available for this task. To address this gap, we introduce a zero-shot prompt-based method using OpenAI's GPT-3.5 model for extracting hyper-relational knowledge from text. Comparing our model with a baseline, we achieved promising results, with a recall of 0.77. Although our precision is currently lower, a detailed analysis of the model outputs has uncovered potential pathways for future research in this area. ",
    "url": "https://arxiv.org/abs/2403.11786",
    "authors": [
      "Preetha Datta",
      "Fedor Vitiugin",
      "Anastasiia Chizhikova",
      "Nitin Sawhney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11792",
    "title": "SETA: Semantic-Aware Token Augmentation for Domain Generalization",
    "abstract": "Domain generalization (DG) aims to enhance the model robustness against domain shifts without accessing target domains. A prevalent category of methods for DG is data augmentation, which focuses on generating virtual samples to simulate domain shifts. However, existing augmentation techniques in DG are mainly tailored for convolutional neural networks (CNNs), with limited exploration in token-based architectures, i.e., vision transformer (ViT) and multi-layer perceptrons (MLP) models. In this paper, we study the impact of prior CNN-based augmentation methods on token-based models, revealing their performance is suboptimal due to the lack of incentivizing the model to learn holistic shape information. To tackle the issue, we propose the SEmantic-aware Token Augmentation (SETA) method. SETA transforms token features by perturbing local edge cues while preserving global shape features, thereby enhancing the model learning of shape information. To further enhance the generalization ability of the model, we introduce two stylized variants of our method combined with two state-of-the-art style augmentation methods in DG. We provide a theoretical insight into our method, demonstrating its effectiveness in reducing the generalization risk bound. Comprehensive experiments on five benchmarks prove that our method achieves SOTA performances across various ViT and MLP architectures. Our code is available at https://github.com/lingeringlight/SETA. ",
    "url": "https://arxiv.org/abs/2403.11792",
    "authors": [
      "Jintao Guo",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11796",
    "title": "OpenOcc: Open Vocabulary 3D Scene Reconstruction via Occupancy  Representation",
    "abstract": "3D reconstruction has been widely used in autonomous navigation fields of mobile robotics. However, the former research can only provide the basic geometry structure without the capability of open-world scene understanding, limiting advanced tasks like human interaction and visual navigation. Moreover, traditional 3D scene understanding approaches rely on expensive labeled 3D datasets to train a model for a single task with supervision. Thus, geometric reconstruction with zero-shot scene understanding i.e. Open vocabulary 3D Understanding and Reconstruction, is crucial for the future development of mobile robots. In this paper, we propose OpenOcc, a novel framework unifying the 3D scene reconstruction and open vocabulary understanding with neural radiance fields. We model the geometric structure of the scene with occupancy representation and distill the pre-trained open vocabulary model into a 3D language field via volume rendering for zero-shot inference. Furthermore, a novel semantic-aware confidence propagation (SCP) method has been proposed to relieve the issue of language field representation degeneracy caused by inconsistent measurements in distilled features. Experimental results show that our approach achieves competitive performance in 3D scene understanding tasks, especially for small and long-tail objects. ",
    "url": "https://arxiv.org/abs/2403.11796",
    "authors": [
      "Haochen Jiang",
      "Yueming Xu",
      "Yihan Zeng",
      "Hang Xu",
      "Wei Zhang",
      "Jianfeng Feng",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.11811",
    "title": "A Simple 2-Approximation Algorithm For Minimum Manhattan Network Problem",
    "abstract": "Given a n points in two dimensional space, a Manhattan Network G is a network that connects all n points with either horizontal or vertical edges, with the property that for any two point in G should be connected by a Manhattan path and distance between this two points is equal to Manhattan Distance. The Minimum Manhattan Network problem is to find a Manhattan network with minimum network length, i.e., summation of all line segment in network should be minimize. In this paper, we proposed a 2-approximation algorithm with time complexity O(|E|lgN) where |E| is the number of edges and N is the number of nodes. Using randomly generated datasets, we compare our result with the optimal one. ",
    "url": "https://arxiv.org/abs/2403.11811",
    "authors": [
      "Md. Musfiqur Rahman Sanim",
      "Safrunnesa Saira",
      "Fatin Faiaz Ahsan",
      "Rajon Bardhan",
      "S.M. Ferdous"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.11812",
    "title": "Aerial Lifting: Neural Urban Semantic and Building Instance Lifting from  Aerial Imagery",
    "abstract": "We present a neural radiance field method for urban-scale semantic and building-level instance segmentation from aerial images by lifting noisy 2D labels to 3D. This is a challenging problem due to two primary reasons. Firstly, objects in urban aerial images exhibit substantial variations in size, including buildings, cars, and roads, which pose a significant challenge for accurate 2D segmentation. Secondly, the 2D labels generated by existing segmentation methods suffer from the multi-view inconsistency problem, especially in the case of aerial images, where each image captures only a small portion of the entire scene. To overcome these limitations, we first introduce a scale-adaptive semantic label fusion strategy that enhances the segmentation of objects of varying sizes by combining labels predicted from different altitudes, harnessing the novel-view synthesis capabilities of NeRF. We then introduce a novel cross-view instance label grouping strategy based on the 3D scene representation to mitigate the multi-view inconsistency problem in the 2D instance labels. Furthermore, we exploit multi-view reconstructed depth priors to improve the geometric quality of the reconstructed radiance field, resulting in enhanced segmentation results. Experiments on multiple real-world urban-scale datasets demonstrate that our approach outperforms existing methods, highlighting its effectiveness. ",
    "url": "https://arxiv.org/abs/2403.11812",
    "authors": [
      "Yuqi Zhang",
      "Guanying Chen",
      "Jiaxing Chen",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11827",
    "title": "Sound Event Detection and Localization with Distance Estimation",
    "abstract": "Sound Event Detection and Localization (SELD) is a combined task of identifying sound events and their corresponding direction-of-arrival (DOA). While this task has numerous applications and has been extensively researched in recent years, it fails to provide full information about the sound source position. In this paper, we overcome this problem by extending the task to Sound Event Detection, Localization with Distance Estimation (3D SELD). We study two ways of integrating distance estimation within the SELD core - a multi-task approach, in which the problem is tackled by a separate model output, and a single-task approach obtained by extending the multi-ACCDOA method to include distance information. We investigate both methods for the Ambisonic and binaural versions of STARSS23: Sony-TAU Realistic Spatial Soundscapes 2023. Moreover, our study involves experiments on the loss function related to the distance estimation part. Our results show that it is possible to perform 3D SELD without any degradation of performance in sound event detection and DOA estimation. ",
    "url": "https://arxiv.org/abs/2403.11827",
    "authors": [
      "Daniel Aleksander Krause",
      "Archontis Politis",
      "Annamaria Mesaros"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.11830",
    "title": "Problem space structural adversarial attacks for Network Intrusion  Detection Systems based on Graph Neural Networks",
    "abstract": "Machine Learning (ML) algorithms have become increasingly popular for supporting Network Intrusion Detection Systems (NIDS). Nevertheless, extensive research has shown their vulnerability to adversarial attacks, which involve subtle perturbations to the inputs of the models aimed at compromising their performance. Recent proposals have effectively leveraged Graph Neural Networks (GNN) to produce predictions based also on the structural patterns exhibited by intrusions to enhance the detection robustness. However, the adoption of GNN-based NIDS introduces new types of risks. In this paper, we propose the first formalization of adversarial attacks specifically tailored for GNN in network intrusion detection. Moreover, we outline and model the problem space constraints that attackers need to consider to carry out feasible structural attacks in real-world scenarios. As a final contribution, we conduct an extensive experimental campaign in which we launch the proposed attacks against state-of-the-art GNN-based NIDS. Our findings demonstrate the increased robustness of the models against classical feature-based adversarial attacks, while highlighting their susceptibility to structure-based attacks. ",
    "url": "https://arxiv.org/abs/2403.11830",
    "authors": [
      "Andrea Venturi",
      "Dario Stabili",
      "Mirco Marchetti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11833",
    "title": "SSCAE -- Semantic, Syntactic, and Context-aware natural language  Adversarial Examples generator",
    "abstract": "Machine learning models are vulnerable to maliciously crafted Adversarial Examples (AEs). Training a machine learning model with AEs improves its robustness and stability against adversarial attacks. It is essential to develop models that produce high-quality AEs. Developing such models has been much slower in natural language processing (NLP) than in areas such as computer vision. This paper introduces a practical and efficient adversarial attack model called SSCAE for \\textbf{S}emantic, \\textbf{S}yntactic, and \\textbf{C}ontext-aware natural language \\textbf{AE}s generator. SSCAE identifies important words and uses a masked language model to generate an early set of substitutions. Next, two well-known language models are employed to evaluate the initial set in terms of semantic and syntactic characteristics. We introduce (1) a dynamic threshold to capture more efficient perturbations and (2) a local greedy search to generate high-quality AEs. As a black-box method, SSCAE generates humanly imperceptible and context-aware AEs that preserve semantic consistency and the source language's syntactical and grammatical requirements. The effectiveness and superiority of the proposed SSCAE model are illustrated with fifteen comparative experiments and extensive sensitivity analysis for parameter optimization. SSCAE outperforms the existing models in all experiments while maintaining a higher semantic consistency with a lower query number and a comparable perturbation rate. ",
    "url": "https://arxiv.org/abs/2403.11833",
    "authors": [
      "Javad Rafiei Asl",
      "Mohammad H. Rafiei",
      "Manar Alohaly",
      "Daniel Takabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11836",
    "title": "Stochastic Mean Field Game for Strategic Bidding of Consumers in  Congested Distribution Networks",
    "abstract": "The rapid increase of photovoltaic cells, batteries, and Electric Vehicles (EVs) in electric grids can result in congested distribution networks. An alternative to enhancing network capacity is a redispatch market, allowing Distribution System Operators (DSOs) to alleviate congested networks by asking energy consumers to change their consumption schedules. However, energy consumers can anticipate the redispatch market outcomes and strategically adjust their bids in the day-ahead market. This behaviour, known as increase-decrease gaming, can result in the exacerbation of congestion and enable energy consumers to gain windfall profits from the DSO. In this paper, we consider a two-stage problem consisting of the day-ahead market (first stage) and redispatch market (second stage). Then, we model the increase-decrease game for large populations of energy consumers in power networks using a stochastic mean field game approach. The agents (energy consumers) maximize their individual welfare in the day-ahead market with anticipation of the redispatch market. We show that all the agent strategies are ordered along their utilities and there exists a unique Nash equilibrium for this game. ",
    "url": "https://arxiv.org/abs/2403.11836",
    "authors": [
      "Amirreza Silani",
      "Simon H. Tindemans"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11848",
    "title": "GraphBEV: Towards Robust BEV Feature Alignment for Multi-Modal 3D Object  Detection",
    "abstract": "Integrating LiDAR and camera information into Bird's-Eye-View (BEV) representation has emerged as a crucial aspect of 3D object detection in autonomous driving. However, existing methods are susceptible to the inaccurate calibration relationship between LiDAR and the camera sensor. Such inaccuracies result in errors in depth estimation for the camera branch, ultimately causing misalignment between LiDAR and camera BEV features. In this work, we propose a robust fusion framework called Graph BEV. Addressing errors caused by inaccurate point cloud projection, we introduce a Local Align module that employs neighbor-aware depth features via Graph matching. Additionally, we propose a Global Align module to rectify the misalignment between LiDAR and camera BEV features. Our Graph BEV framework achieves state-of-the-art performance, with an mAP of 70.1\\%, surpassing BEV Fusion by 1.6\\% on the nuscenes validation set. Importantly, our Graph BEV outperforms BEV Fusion by 8.3\\% under conditions with misalignment noise. ",
    "url": "https://arxiv.org/abs/2403.11848",
    "authors": [
      "Ziying Song",
      "Lei Yang",
      "Shaoqing Xu",
      "Lin Liu",
      "Dongyang Xu",
      "Caiyan Jia",
      "Feiyang Jia",
      "Li Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11857",
    "title": "Complete and Efficient Graph Transformers for Crystal Material Property  Prediction",
    "abstract": "Crystal structures are characterized by atomic bases within a primitive unit cell that repeats along a regular lattice throughout 3D space. The periodic and infinite nature of crystals poses unique challenges for geometric graph representation learning. Specifically, constructing graphs that effectively capture the complete geometric information of crystals and handle chiral crystals remains an unsolved and challenging problem. In this paper, we introduce a novel approach that utilizes the periodic patterns of unit cells to establish the lattice-based representation for each atom, enabling efficient and expressive graph representations of crystals. Furthermore, we propose ComFormer, a SE(3) transformer designed specifically for crystalline materials. ComFormer includes two variants; namely, iComFormer that employs invariant geometric descriptors of Euclidean distances and angles, and eComFormer that utilizes equivariant vector representations. Experimental results demonstrate the state-of-the-art predictive accuracy of ComFormer variants on various tasks across three widely-used crystal benchmarks. Our code is publicly available as part of the AIRS library (https://github.com/divelab/AIRS). ",
    "url": "https://arxiv.org/abs/2403.11857",
    "authors": [
      "Keqiang Yan",
      "Cong Fu",
      "Xiaofeng Qian",
      "Xiaoning Qian",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2403.11865",
    "title": "Exploring Multi-modal Neural Scene Representations With Applications on  Thermal Imaging",
    "abstract": "Neural Radiance Fields (NeRFs) quickly evolved as the new de-facto standard for the task of novel view synthesis when trained on a set of RGB images. In this paper, we conduct a comprehensive evaluation of neural scene representations, such as NeRFs, in the context of multi-modal learning. Specifically, we present four different strategies of how to incorporate a second modality, other than RGB, into NeRFs: (1) training from scratch independently on both modalities; (2) pre-training on RGB and fine-tuning on the second modality; (3) adding a second branch; and (4) adding a separate component to predict (color) values of the additional modality. We chose thermal imaging as second modality since it strongly differs from RGB in terms of radiosity, making it challenging to integrate into neural scene representations. For the evaluation of the proposed strategies, we captured a new publicly available multi-view dataset, ThermalMix, consisting of six common objects and about 360 RGB and thermal images in total. We employ cross-modality calibration prior to data capturing, leading to high-quality alignments between RGB and thermal images. Our findings reveal that adding a second branch to NeRF performs best for novel view synthesis on thermal images while also yielding compelling results on RGB. Finally, we also show that our analysis generalizes to other modalities, including near-infrared images and depth maps. Project page: https://mert-o.github.io/ThermalNeRF/. ",
    "url": "https://arxiv.org/abs/2403.11865",
    "authors": [
      "Mert \u00d6zer",
      "Maximilian Weiherer",
      "Martin Hundhausen",
      "Bernhard Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2403.11875",
    "title": "Towards Real-Time Fast Unmanned Aerial Vehicle Detection Using Dynamic  Vision Sensors",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are gaining popularity in civil and military applications. However, uncontrolled access to restricted areas threatens privacy and security. Thus, prevention and detection of UAVs are pivotal to guarantee confidentiality and safety. Although active scanning, mainly based on radars, is one of the most accurate technologies, it can be expensive and less versatile than passive inspections, e.g., object recognition. Dynamic vision sensors (DVS) are bio-inspired event-based vision models that leverage timestamped pixel-level brightness changes in fast-moving scenes that adapt well to low-latency object detection. This paper presents F-UAV-D (Fast Unmanned Aerial Vehicle Detector), an embedded system that enables fast-moving drone detection. In particular, we propose a setup to exploit DVS as an alternative to RGB cameras in a real-time and low-power configuration. Our approach leverages the high-dynamic range (HDR) and background suppression of DVS and, when trained with various fast-moving drones, outperforms RGB input in suboptimal ambient conditions such as low illumination and fast-moving scenes. Our results show that F-UAV-D can (i) detect drones by using less than <15 W on average and (ii) perform real-time inference (i.e., <50 ms) by leveraging the CPU and GPU nodes of our edge computer. ",
    "url": "https://arxiv.org/abs/2403.11875",
    "authors": [
      "Jakub Mandula",
      "Jonas K\u00fchne",
      "Luca Pascarella",
      "Michele Magno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2403.11899",
    "title": "GNeRP: Gaussian-guided Neural Reconstruction of Reflective Objects with  Noisy Polarization Priors",
    "abstract": "Learning surfaces from neural radiance field (NeRF) became a rising topic in Multi-View Stereo (MVS). Recent Signed Distance Function (SDF)-based methods demonstrated their ability to reconstruct accurate 3D shapes of Lambertian scenes. However, their results on reflective scenes are unsatisfactory due to the entanglement of specular radiance and complicated geometry. To address the challenges, we propose a Gaussian-based representation of normals in SDF fields. Supervised by polarization priors, this representation guides the learning of geometry behind the specular reflection and captures more details than existing methods. Moreover, we propose a reweighting strategy in the optimization process to alleviate the noise issue of polarization priors. To validate the effectiveness of our design, we capture polarimetric information, and ground truth meshes in additional reflective scenes with various geometry. We also evaluated our framework on the PANDORA dataset. Comparisons prove our method outperforms existing neural 3D reconstruction methods in reflective scenes by a large margin. ",
    "url": "https://arxiv.org/abs/2403.11899",
    "authors": [
      "LI Yang",
      "WU Ruizheng",
      "LI Jiyong",
      "CHEN Ying-cong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11909",
    "title": "RoGUENeRF: A Robust Geometry-Consistent Universal Enhancer for NeRF",
    "abstract": "Recent advances in neural rendering have enabled highly photorealistic 3D scene reconstruction and novel view synthesis. Despite this progress, current state-of-the-art methods struggle to reconstruct high frequency detail, due to factors such as a low-frequency bias of radiance fields and inaccurate camera calibration. One approach to mitigate this issue is to enhance images post-rendering. 2D enhancers can be pre-trained to recover some detail but are agnostic to scene geometry and do not easily generalize to new distributions of image degradation. Conversely, existing 3D enhancers are able to transfer detail from nearby training images in a generalizable manner, but suffer from inaccurate camera calibration and can propagate errors from the geometry into rendered images. We propose a neural rendering enhancer, RoGUENeRF, which exploits the best of both paradigms. Our method is pre-trained to learn a general enhancer while also leveraging information from nearby training images via robust 3D alignment and geometry-aware fusion. Our approach restores high-frequency textures while maintaining geometric consistency and is also robust to inaccurate camera calibration. We show that RoGUENeRF substantially enhances the rendering quality of a wide range of neural rendering baselines, e.g. improving the PSNR of MipNeRF360 by 0.63dB and Nerfacto by 1.34dB on the real world 360v2 dataset. ",
    "url": "https://arxiv.org/abs/2403.11909",
    "authors": [
      "Sibi Catley-Chandar",
      "Richard Shaw",
      "Gregory Slabaugh",
      "Eduardo Perez-Pellitero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11921",
    "title": "Adaptative Bilingual Aligning Using Multilingual Sentence Embedding",
    "abstract": "In this paper, we present an adaptive bitextual alignment system called AIlign. This aligner relies on sentence embeddings to extract reliable anchor points that can guide the alignment path, even for texts whose parallelism is fragmentary and not strictly monotonic. In an experiment on several datasets, we show that AIlign achieves results equivalent to the state of the art, with quasi-linear complexity. In addition, AIlign is able to handle texts whose parallelism and monotonicity properties are only satisfied locally, unlike recent systems such as Vecalign or Bertalign. ",
    "url": "https://arxiv.org/abs/2403.11921",
    "authors": [
      "Olivier Kraif"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11938",
    "title": "State space representations of the Roesser type for convolutional layers",
    "abstract": "From the perspective of control theory, convolutional layers (of neural networks) are 2-D (or N-D) linear time-invariant dynamical systems. The usual representation of convolutional layers by the convolution kernel corresponds to the representation of a dynamical system by its impulse response. However, many analysis tools from control theory, e.g., involving linear matrix inequalities, require a state space representation. For this reason, we explicitly provide a state space representation of the Roesser type for 2-D convolutional layers with $c_\\mathrm{in}r_1 + c_\\mathrm{out}r_2$ states, where $c_\\mathrm{in}$/$c_\\mathrm{out}$ is the number of input/output channels of the layer and $r_1$/$r_2$ characterizes the width/length of the convolution kernel. This representation is shown to be minimal for $c_\\mathrm{in} = c_\\mathrm{out}$. We further construct state space representations for dilated, strided, and N-D convolutions. ",
    "url": "https://arxiv.org/abs/2403.11938",
    "authors": [
      "Patricia Pauli",
      "Dennis Gramlich",
      "Fran Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.11960",
    "title": "CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for  Spatiotemporal Time Series Imputation",
    "abstract": "Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could result in overfitting and make the model vulnerable to noises. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective, which shows the causal relationships among the input, output, embeddings and confounders. Next, we show how to block the confounders via the frontdoor adjustment. Based on the results of the frontdoor adjustment, we introduce a novel Causality-Aware SPatiotEmpoRal graph neural network (CASPER), which contains a novel Spatiotemporal Causal Attention (SCA) and a Prompt Based Decoder (PBD). PBD could reduce the impact of confounders and SCA could discover the sparse causal relationships among embeddings. Theoretical analysis reveals that SCA discovers causal relationships based on the values of gradients. We evaluate Casper on three real-world datasets, and the experimental results show that Casper outperforms the baselines and effectively discovers causal relationships. ",
    "url": "https://arxiv.org/abs/2403.11960",
    "authors": [
      "Baoyu Jing",
      "Dawei Zhou",
      "Kan Ren",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.11964",
    "title": "Probabilistic Calibration by Design for Neural Network Regression",
    "abstract": "Generating calibrated and sharp neural network predictive distributions for regression problems is essential for optimal decision-making in many real-world applications. To address the miscalibration issue of neural networks, various methods have been proposed to improve calibration, including post-hoc methods that adjust predictions after training and regularization methods that act during training. While post-hoc methods have shown better improvement in calibration compared to regularization methods, the post-hoc step is completely independent of model training. We introduce a novel end-to-end model training procedure called Quantile Recalibration Training, integrating post-hoc calibration directly into the training process without additional parameters. We also present a unified algorithm that includes our method and other post-hoc and regularization methods, as particular cases. We demonstrate the performance of our method in a large-scale experiment involving 57 tabular regression datasets, showcasing improved predictive accuracy while maintaining calibration. We also conduct an ablation study to evaluate the significance of different components within our proposed method, as well as an in-depth analysis of the impact of the base model and different hyperparameters on predictive accuracy. ",
    "url": "https://arxiv.org/abs/2403.11964",
    "authors": [
      "Victor Dheur",
      "Souhaib Ben Taieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.11966",
    "title": "Informed Spectral Normalized Gaussian Processes for Trajectory  Prediction",
    "abstract": "Prior parameter distributions provide an elegant way to represent prior expert and world knowledge for informed learning. Previous work has shown that using such informative priors to regularize probabilistic deep learning (DL) models increases their performance and data-efficiency. However, commonly used sampling-based approximations for probabilistic DL models can be computationally expensive, requiring multiple inference passes and longer training times. Promising alternatives are compute-efficient last layer kernel approximations like spectral normalized Gaussian processes (SNGPs). We propose a novel regularization-based continual learning method for SNGPs, which enables the use of informative priors that represent prior knowledge learned from previous tasks. Our proposal builds upon well-established methods and requires no rehearsal memory or parameter expansion. We apply our informed SNGP model to the trajectory prediction problem in autonomous driving by integrating prior drivability knowledge. On two public datasets, we investigate its performance under diminishing training data and across locations, and thereby demonstrate an increase in data-efficiency and robustness to location-transfers over non-informed and informed baselines. ",
    "url": "https://arxiv.org/abs/2403.11966",
    "authors": [
      "Christian Schlauch",
      "Christian Wirth",
      "Nadja Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11981",
    "title": "Diffusion Denoising as a Certified Defense against Clean-label Poisoning",
    "abstract": "We present a certified defense to clean-label poisoning attacks. These attacks work by injecting a small number of poisoning samples (e.g., 1%) that contain $p$-norm bounded adversarial perturbations into the training data to induce a targeted misclassification of a test-time input. Inspired by the adversarial robustness achieved by $denoised$ $smoothing$, we show how an off-the-shelf diffusion model can sanitize the tampered training data. We extensively test our defense against seven clean-label poisoning attacks and reduce their attack success to 0-16% with only a negligible drop in the test time accuracy. We compare our defense with existing countermeasures against clean-label poisoning, showing that the defense reduces the attack success the most and offers the best model utility. Our results highlight the need for future work on developing stronger clean-label attacks and using our certified yet practical defense as a strong baseline to evaluate these attacks. ",
    "url": "https://arxiv.org/abs/2403.11981",
    "authors": [
      "Sanghyun Hong",
      "Nicholas Carlini",
      "Alexey Kurakin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11996",
    "title": "Accelerating Scientific Discovery with Generative Knowledge Extraction,  Graph-Based Representation, and Multimodal Intelligent Graph Reasoning",
    "abstract": "Using generative Artificial Intelligence (AI), we transformed a set of 1,000 scientific papers in the area of biological materials into detailed ontological knowledge graphs, revealing their inherently scale-free nature. Using graph traversal path detection between dissimilar concepts based on combinatorial ranking of node similarity and betweenness centrality, we reveal deep insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, and propose never-before-seen material designs and their behaviors. One comparison revealed detailed structural parallels between biological materials and Beethoven's 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. The algorithm further created an innovative hierarchical mycelium-based composite that incorporates joint synthesis of graph sampling with principles extracted from Kandinsky's Composition VII painting, where the resulting composite reflects a balance of chaos and order, with features like adjustable porosity, mechanical strength, and complex patterned chemical functionalization. We uncover other isomorphisms across physical, biological, and artistic spheres, revealing a nuanced ontology of immanence and material flux that resonates with postmodern philosophy, and positions these interconnections within a heterarchical framework. Our findings reveal the dynamic, context-dependent interplay of entities beyond traditional hierarchical paradigms, emphasizing the significant role of individual components and their fluctuative relationships within the system. Our predictions achieve a far higher degree of novelty, technical detail and explorative capacity than conventional generative AI methods. The approach establishes a widely useful framework for innovation by revealing hidden connections that facilitate discovery. ",
    "url": "https://arxiv.org/abs/2403.11996",
    "authors": [
      "Markus J. Buehler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.11998",
    "title": "Learning Useful Representations of Recurrent Neural Network Weight  Matrices",
    "abstract": "Recurrent Neural Networks (RNNs) are general-purpose parallel-sequential computers. The program of an RNN is its weight matrix. How to learn useful representations of RNN weights that facilitate RNN analysis as well as downstream tasks? While the mechanistic approach directly looks at some RNN's weights to predict its behavior, the functionalist approach analyzes its overall functionality -- specifically, its input-output mapping. We consider several mechanistic approaches for RNN weights and adapt the permutation equivariant Deep Weight Space layer for RNNs. Our two novel functionalist approaches extract information from RNN weights by 'interrogating' the RNN through probing inputs. We develop a theoretical framework that demonstrates conditions under which the functionalist approach can generate rich representations that help determine RNN behavior. We create and release the first two 'model zoo' datasets for RNN weight representation learning. One consists of generative models of a class of formal languages, and the other one of classifiers of sequentially processed MNIST digits. With the help of an emulation-based self-supervised learning technique we compare and evaluate the different RNN weight encoding techniques on multiple downstream applications. On the most challenging one, namely predicting which exact task the RNN was trained on, functionalist approaches show clear superiority. ",
    "url": "https://arxiv.org/abs/2403.11998",
    "authors": [
      "Vincent Herrmann",
      "Francesco Faccio",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.12003",
    "title": "GenView: Enhancing View Quality with Pretrained Generative Model for  Self-Supervised Learning",
    "abstract": "Self-supervised learning has achieved remarkable success in acquiring high-quality representations from unlabeled data. The widely adopted contrastive learning framework aims to learn invariant representations by minimizing the distance between positive views originating from the same image. However, existing techniques to construct positive views highly rely on manual transformations, resulting in limited diversity and potentially false positive pairs. To tackle these challenges, we present GenView, a controllable framework that augments the diversity of positive views leveraging the power of pretrained generative models while preserving semantics. We develop an adaptive view generation method that dynamically adjusts the noise level in sampling to ensure the preservation of essential semantic meaning while introducing variability. Additionally, we introduce a quality-driven contrastive loss, which assesses the quality of positive pairs by considering both foreground similarity and background diversity. This loss prioritizes the high-quality positive pairs we construct while reducing the influence of low-quality pairs, thereby mitigating potential semantic inconsistencies introduced by generative models and aggressive data augmentation. Thanks to the improved positive view quality and the quality-driven contrastive loss, GenView significantly improves self-supervised learning across various tasks. For instance, GenView improves MoCov2 performance by 2.5%/2.2% on ImageNet linear/semi-supervised classification. Moreover, GenView even performs much better than naively augmenting the ImageNet dataset with Laion400M or ImageNet21K. Code is available at https://github.com/xiaojieli0903/genview. ",
    "url": "https://arxiv.org/abs/2403.12003",
    "authors": [
      "Xiaojie Li",
      "Yibo Yang",
      "Xiangtai Li",
      "Jianlong Wu",
      "Yue Yu",
      "Bernard Ghanem",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.12009",
    "title": "Leveraging Spatial and Semantic Feature Extraction for Skin Cancer  Diagnosis with Capsule Networks and Graph Neural Networks",
    "abstract": "In the realm of skin lesion image classification, the intricate spatial and semantic features pose significant challenges for conventional Convolutional Neural Network (CNN)-based methodologies. These challenges are compounded by the imbalanced nature of skin lesion datasets, which hampers the ability of models to learn minority class features effectively. Despite augmentation strategies, such as those using Generative Adversarial Networks (GANs), previous attempts have not fully addressed these complexities. This study introduces an innovative approach by integrating Graph Neural Networks (GNNs) with Capsule Networks to enhance classification performance. GNNs, known for their proficiency in handling graph-structured data, offer an advanced mechanism for capturing complex patterns and relationships beyond the capabilities of traditional CNNs. Capsule Networks further contribute by providing superior recognition of spatial hierarchies within images. Our research focuses on evaluating and enhancing the Tiny Pyramid Vision GNN (Tiny Pyramid ViG) architecture by incorporating it with a Capsule Network. This hybrid model was applied to the MNIST:HAM10000 dataset, a comprehensive skin lesion dataset designed for benchmarking classification models. After 75 epochs of training, our model achieved a significant accuracy improvement, reaching 89.23% and 95.52%, surpassing established benchmarks such as GoogLeNet (83.94%), InceptionV3 (86.82%), MobileNet V3 (89.87%), EfficientNet-B7 (92.07%), ResNet18 (92.22%), ResNet34 (91.90%), ViT-Base (73.70%), and IRv2-SA (93.47%) on the same dataset. This outcome underscores the potential of our approach in overcoming the inherent challenges of skin lesion classification, contributing to the advancement of image-based diagnosis in dermatology. ",
    "url": "https://arxiv.org/abs/2403.12009",
    "authors": [
      "K. P. Santoso",
      "R. V. H. Ginardi",
      "R. A. Sastrowardoyo",
      "F. A. Madany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.12015",
    "title": "Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion  Distillation",
    "abstract": "Diffusion models are the main driver of progress in image and video synthesis, but suffer from slow inference speed. Distillation methods, like the recently introduced adversarial diffusion distillation (ADD) aim to shift the model from many-shot to single-step inference, albeit at the cost of expensive and difficult optimization due to its reliance on a fixed pretrained DINOv2 discriminator. We introduce Latent Adversarial Diffusion Distillation (LADD), a novel distillation approach overcoming the limitations of ADD. In contrast to pixel-based ADD, LADD utilizes generative features from pretrained latent diffusion models. This approach simplifies training and enhances performance, enabling high-resolution multi-aspect ratio image synthesis. We apply LADD to Stable Diffusion 3 (8B) to obtain SD3-Turbo, a fast model that matches the performance of state-of-the-art text-to-image generators using only four unguided sampling steps. Moreover, we systematically investigate its scaling behavior and demonstrate LADD's effectiveness in various applications such as image editing and inpainting. ",
    "url": "https://arxiv.org/abs/2403.12015",
    "authors": [
      "Axel Sauer",
      "Frederic Boesel",
      "Tim Dockhorn",
      "Andreas Blattmann",
      "Patrick Esser",
      "Robin Rombach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.12019",
    "title": "LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D  Generation",
    "abstract": "The field of neural rendering has witnessed significant progress with advancements in generative models and differentiable rendering techniques. Though 2D diffusion has achieved success, a unified 3D diffusion pipeline remains unsettled. This paper introduces a novel framework called LN3Diff to address this gap and enable fast, high-quality, and generic conditional 3D generation. Our approach harnesses a 3D-aware architecture and variational autoencoder (VAE) to encode the input image into a structured, compact, and 3D latent space. The latent is decoded by a transformer-based decoder into a high-capacity 3D neural field. Through training a diffusion model on this 3D-aware latent space, our method achieves state-of-the-art performance on ShapeNet for 3D generation and demonstrates superior performance in monocular 3D reconstruction and conditional 3D generation across various datasets. Moreover, it surpasses existing 3D diffusion methods in terms of inference speed, requiring no per-instance optimization. Our proposed LN3Diff presents a significant advancement in 3D generative modeling and holds promise for various applications in 3D vision and graphics tasks. ",
    "url": "https://arxiv.org/abs/2403.12019",
    "authors": [
      "Yushi Lan",
      "Fangzhou Hong",
      "Shuai Yang",
      "Shangchen Zhou",
      "Xuyi Meng",
      "Bo Dai",
      "Xingang Pan",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.12029",
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object  Detection",
    "abstract": "Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +2.0 AP50 on CFC Kenai to Channel. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting. ",
    "url": "https://arxiv.org/abs/2403.12029",
    "authors": [
      "Justin Kay",
      "Timm Haucke",
      "Suzanne Stathatos",
      "Siqi Deng",
      "Erik Young",
      "Pietro Perona",
      "Sara Beery",
      "Grant Van Horn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.12033",
    "title": "HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation",
    "abstract": "Being able to understand visual scenes is a precursor for many downstream tasks, including autonomous driving, robotics, and other vision-based approaches. A common approach enabling the ability to reason over visual data is Scene Graph Generation (SGG); however, many existing approaches assume undisturbed vision, i.e., the absence of real-world corruptions such as fog, snow, smoke, as well as non-uniform perturbations like sun glare or water drops. In this work, we propose a novel SGG benchmark containing procedurally generated weather corruptions and other transformations over the Visual Genome dataset. Further, we introduce a corresponding approach, Hierarchical Knowledge Enhanced Robust Scene Graph Generation (HiKER-SGG), providing a strong baseline for scene graph generation under such challenging setting. At its core, HiKER-SGG utilizes a hierarchical knowledge graph in order to refine its predictions from coarse initial estimates to detailed predictions. In our extensive experiments, we show that HiKER-SGG does not only demonstrate superior performance on corrupted images in a zero-shot manner, but also outperforms current state-of-the-art methods on uncorrupted SGG tasks. Code is available at https://github.com/zhangce01/HiKER-SGG. ",
    "url": "https://arxiv.org/abs/2403.12033",
    "authors": [
      "Ce Zhang",
      "Simon Stepputtis",
      "Joseph Campbell",
      "Katia Sycara",
      "Yaqi Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10522",
    "title": "Ordinal Classification with Distance Regularization for Robust Brain Age  Prediction",
    "abstract": "Age is one of the major known risk factors for Alzheimer's Disease (AD). Detecting AD early is crucial for effective treatment and preventing irreversible brain damage. Brain age, a measure derived from brain imaging reflecting structural changes due to aging, may have the potential to identify AD onset, assess disease risk, and plan targeted interventions. Deep learning-based regression techniques to predict brain age from magnetic resonance imaging (MRI) scans have shown great accuracy recently. However, these methods are subject to an inherent regression to the mean effect, which causes a systematic bias resulting in an overestimation of brain age in young subjects and underestimation in old subjects. This weakens the reliability of predicted brain age as a valid biomarker for downstream clinical applications. Here, we reformulate the brain age prediction task from regression to classification to address the issue of systematic bias. Recognizing the importance of preserving ordinal information from ages to understand aging trajectory and monitor aging longitudinally, we propose a novel ORdinal Distance Encoded Regularization (ORDER) loss that incorporates the order of age labels, enhancing the model's ability to capture age-related patterns. Extensive experiments and ablation studies demonstrate that this framework reduces systematic bias, outperforms state-of-art methods by statistically significant margins, and can better capture subtle differences between clinical groups in an independent AD dataset. Our implementation is publicly available at ***. ",
    "url": "https://arxiv.org/abs/2403.10522",
    "authors": [
      "Jay Shah",
      "Md Mahfuzur Rahman Siddiquee",
      "Yi Su",
      "Teresa Wu",
      "Baoxin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10547",
    "title": "Robust Second-Order Nonconvex Optimization and Its Application to Low  Rank Matrix Sensing",
    "abstract": "Finding an approximate second-order stationary point (SOSP) is a well-studied and fundamental problem in stochastic nonconvex optimization with many applications in machine learning. However, this problem is poorly understood in the presence of outliers, limiting the use of existing nonconvex algorithms in adversarial settings. In this paper, we study the problem of finding SOSPs in the strong contamination model, where a constant fraction of datapoints are arbitrarily corrupted. We introduce a general framework for efficiently finding an approximate SOSP with \\emph{dimension-independent} accuracy guarantees, using $\\widetilde{O}({D^2}/{\\epsilon})$ samples where $D$ is the ambient dimension and $\\epsilon$ is the fraction of corrupted datapoints. As a concrete application of our framework, we apply it to the problem of low rank matrix sensing, developing efficient and provably robust algorithms that can tolerate corruptions in both the sensing matrices and the measurements. In addition, we establish a Statistical Query lower bound providing evidence that the quadratic dependence on $D$ in the sample complexity is necessary for computationally efficient algorithms. ",
    "url": "https://arxiv.org/abs/2403.10547",
    "authors": [
      "Shuyao Li",
      "Yu Cheng",
      "Ilias Diakonikolas",
      "Jelena Diakonikolas",
      "Rong Ge",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10581",
    "title": "Large Language Model-informed ECG Dual Attention Network for Heart  Failure Risk Prediction",
    "abstract": "Heart failure (HF) poses a significant public health challenge due to its rising global mortality rate. Addressing this issue through early diagnosis and prevention could significantly reduce the disease's impact. This work introduces a methodology for HF risk prediction using clinically acquired 12-lead electrocardiograms (ECGs). We present a novel, lightweight dual-attention ECG network designed to capture complex ECG features essential for early HF prediction, despite the notable imbalance between low and high-risk groups. The network features a cross-lead attention module and twelve lead-specific temporal attention modules to capture cross-lead interactions and local temporal dynamics within each lead. To prevent model overfitting from limited training data, we leverage a large language model (LLM) with a public ECG-Report dataset for pretraining on an ECG-report alignment task. The network is then fine-tuned for HF risk prediction using two specific cohorts from the UK Biobank study, focusing on patients with hypertension (UKB-HYP) and those who have had a myocardial infarction (UKB-MI). Our findings show that LLM-informed pretraining significantly improves the network's HF risk prediction capability in these cohorts. Moreover, the dual-attention mechanism enhances interpretability and predictive performance, ensuring a transparent and reliable prediction process. The method outperforms existing models, achieving average C-index scores of 0.6349 and 0.5805 on the UKB-HYP and UKB-MI test sets, respectively. This performance demonstrates our approach's effectiveness in managing complex clinical ECG data and its potential to improve HF risk assessment across various populations. ",
    "url": "https://arxiv.org/abs/2403.10581",
    "authors": [
      "Chen Chen",
      "Lei Li",
      "Marcel Beetz",
      "Abhirup Banerjee",
      "Ramneek Gupta",
      "Vicente Grau"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.10613",
    "title": "Process-and-Forward: Deep Joint Source-Channel Coding Over Cooperative  Relay Networks",
    "abstract": "This paper introduces an innovative deep joint source-channel coding (DeepJSCC) approach to image transmission over a cooperative relay channel. The relay either amplifies and forwards a scaled version of its received signal, referred to as DeepJSCC-AF, or leverages neural networks to extract relevant features about the source signal before forwarding it to the destination, which we call DeepJSCC-PF (Process-and-Forward). In the full-duplex scheme, inspired by the block Markov coding (BMC) concept, we introduce a novel block transmission strategy built upon novel vision transformer architecture. In the proposed scheme, the source transmits information in blocks, and the relay updates its knowledge about the input signal after each block and generates its own signal to be conveyed to the destination. To enhance practicality, we introduce an adaptive transmission model, which allows a single trained DeepJSCC model to adapt seamlessly to various channel qualities, making it a versatile solution. Simulation results demonstrate the superior performance of our proposed DeepJSCC compared to the state-of-the-art BPG image compression algorithm, even when operating at the maximum achievable rate of conventional decode-and-forward and compress-and-forward protocols, for both half-duplex and full-duplex relay scenarios. ",
    "url": "https://arxiv.org/abs/2403.10613",
    "authors": [
      "Chenghong Bian",
      "Yulin Shao",
      "Haotian Wu",
      "Emre Ozfatura",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.10622",
    "title": "NeuralOCT: Airway OCT Analysis via Neural Fields",
    "abstract": "Optical coherence tomography (OCT) is a popular modality in ophthalmology and is also used intravascularly. Our interest in this work is OCT in the context of airway abnormalities in infants and children where the high resolution of OCT and the fact that it is radiation-free is important. The goal of airway OCT is to provide accurate estimates of airway geometry (in 2D and 3D) to assess airway abnormalities such as subglottic stenosis. We propose $\\texttt{NeuralOCT}$, a learning-based approach to process airway OCT images. Specifically, $\\texttt{NeuralOCT}$ extracts 3D geometries from OCT scans by robustly bridging two steps: point cloud extraction via 2D segmentation and 3D reconstruction from point clouds via neural fields. Our experiments show that $\\texttt{NeuralOCT}$ produces accurate and robust 3D airway reconstructions with an average A-line error smaller than 70 micrometer. Our code will cbe available on GitHub. ",
    "url": "https://arxiv.org/abs/2403.10622",
    "authors": [
      "Yining Jiao",
      "Amy Oldenburg",
      "Yinghan Xu",
      "Srikamal Soundararajan",
      "Carlton Zdanski",
      "Julia Kimbell",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10631",
    "title": "Default Resilience and Worst-Case Effects in Financial Networks",
    "abstract": "In this paper we analyze the resilience of a network of banks to joint price fluctuations of the external assets in which they have shared exposures, and evaluate the worst-case effects of the possible default contagion. Indeed, when the prices of certain external assets either decrease or increase, all banks exposed to them experience varying degrees of simultaneous shocks to their balance sheets. These coordinated and structured shocks have the potential to exacerbate the likelihood of defaults. In this context, we introduce first a concept of {default resilience margin}, $\\epsilon^*$, i.e., the maximum amplitude of asset prices fluctuations that the network can tolerate without generating defaults. Such threshold value is computed by considering two different measures of price fluctuations, one based on the maximum individual variation of each asset, and the other based on the sum of all the asset's absolute variations. For any price perturbation having amplitude no larger than $\\epsilon^*$, the network absorbs the shocks remaining default free. When the perturbation amplitude goes beyond $\\epsilon^*$, however, defaults may occur. In this case we find the worst-case systemic loss, that is, the total unpaid debt under the most severe price variation of given magnitude. Computation of both the threshold level $\\epsilon^*$ and of the worst-case loss and of a corresponding worst-case asset price scenario, amounts to solving suitable linear programming problems.} ",
    "url": "https://arxiv.org/abs/2403.10631",
    "authors": [
      "Giuseppe Calafiore",
      "Giulia Fracastoro",
      "Anton Proskurnikov"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2403.10636",
    "title": "Resilient by Design: Simulating Street Network Disruptions across Every  Urban Area in the World",
    "abstract": "Street networks allow people and goods to move through cities, but they are vulnerable to disasters like floods, earthquakes, and terrorist attacks. Well-planned network design can make a city more resilient and robust to such disruptions, but we still know little about worldwide patterns of vulnerability, or worldwide empirical relationships between specific design characteristics and resilience. This study quantifies and measures the vulnerability of the street networks of every urban area in the world then models the relationships between vulnerability and street network design characteristics. To do so, we simulate over 2.4 billion trips across more than 8,000 urban areas in 178 countries, while also simulating network disruption events representing floods, earthquakes, and targeted attacks. We find that disrupting high-centrality nodes severely impacts network function. All else equal, networks with higher connectivity, fewer chokepoints, or less circuity are less vulnerable to disruption's impacts. This study thus contributes a new global understanding of network design and vulnerability to the literature. We argue that these design characteristics offer high leverage points for street network resilience and robustness that planners should emphasize when designing or retrofitting urban networks. ",
    "url": "https://arxiv.org/abs/2403.10636",
    "authors": [
      "Geoff Boeing",
      "Jaehyun Ha"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.10763",
    "title": "A Primal-Dual Algorithm for Faster Distributionally Robust Optimization",
    "abstract": "We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression. ",
    "url": "https://arxiv.org/abs/2403.10763",
    "authors": [
      "Ronak Mehta",
      "Jelena Diakonikolas",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.10790",
    "title": "QuantumLeak: Stealing Quantum Neural Networks from Cloud-based NISQ  Machines",
    "abstract": "Variational quantum circuits (VQCs) have become a powerful tool for implementing Quantum Neural Networks (QNNs), addressing a wide range of complex problems. Well-trained VQCs serve as valuable intellectual assets hosted on cloud-based Noisy Intermediate Scale Quantum (NISQ) computers, making them susceptible to malicious VQC stealing attacks. However, traditional model extraction techniques designed for classical machine learning models encounter challenges when applied to NISQ computers due to significant noise in current devices. In this paper, we introduce QuantumLeak, an effective and accurate QNN model extraction technique from cloud-based NISQ machines. Compared to existing classical model stealing techniques, QuantumLeak improves local VQC accuracy by 4.99\\%$\\sim$7.35\\% across diverse datasets and VQC architectures. ",
    "url": "https://arxiv.org/abs/2403.10790",
    "authors": [
      "Zhenxiao Fu",
      "Min Yang",
      "Cheng Chu",
      "Yilun Xu",
      "Gang Huang",
      "Fan Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10861",
    "title": "FedQNN: Federated Learning using Quantum Neural Networks",
    "abstract": "In this study, we explore the innovative domain of Quantum Federated Learning (QFL) as a framework for training Quantum Machine Learning (QML) models via distributed networks. Conventional machine learning models frequently grapple with issues about data privacy and the exposure of sensitive information. Our proposed Federated Quantum Neural Network (FedQNN) framework emerges as a cutting-edge solution, integrating the singular characteristics of QML with the principles of classical federated learning. This work thoroughly investigates QFL, underscoring its capability to secure data handling in a distributed environment and facilitate cooperative learning without direct data sharing. Our research corroborates the concept through experiments across varied datasets, including genomics and healthcare, thereby validating the versatility and efficacy of our FedQNN framework. The results consistently exceed 86% accuracy across three distinct datasets, proving its suitability for conducting various QML tasks. Our research not only identifies the limitations of classical paradigms but also presents a novel framework to propel the field of QML into a new era of secure and collaborative innovation. ",
    "url": "https://arxiv.org/abs/2403.10861",
    "authors": [
      "Nouhaila Innan",
      "Muhammad Al-Zafar Khan",
      "Alberto Marchisio",
      "Muhammad Shafique",
      "Mohamed Bennai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10863",
    "title": "stMCDI: Masked Conditional Diffusion Model with Graph Neural Network for  Spatial Transcriptomics Data Imputation",
    "abstract": "Spatially resolved transcriptomics represents a significant advancement in single-cell analysis by offering both gene expression data and their corresponding physical locations. However, this high degree of spatial resolution entails a drawback, as the resulting spatial transcriptomic data at the cellular level is notably plagued by a high incidence of missing values. Furthermore, most existing imputation methods either overlook the spatial information between spots or compromise the overall gene expression data distribution. To address these challenges, our primary focus is on effectively utilizing the spatial location information within spatial transcriptomic data to impute missing values, while preserving the overall data distribution. We introduce \\textbf{stMCDI}, a novel conditional diffusion model for spatial transcriptomics data imputation, which employs a denoising network trained using randomly masked data portions as guidance, with the unmasked data serving as conditions. Additionally, it utilizes a GNN encoder to integrate the spatial position information, thereby enhancing model performance. The results obtained from spatial transcriptomics datasets elucidate the performance of our methods relative to existing approaches. ",
    "url": "https://arxiv.org/abs/2403.10863",
    "authors": [
      "Xiaoyu Li",
      "Wenwen Min",
      "Shunfang Wang",
      "Changmiao Wang",
      "Taosheng Xu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10880",
    "title": "COVID-CT-H-UNet: a novel COVID-19 CT segmentation network based on  attention mechanism and Bi-category Hybrid loss",
    "abstract": "Since 2019, the global COVID-19 outbreak has emerged as a crucial focus in healthcare research. Although RT-PCR stands as the primary method for COVID-19 detection, its extended detection time poses a significant challenge. Consequently, supplementing RT-PCR with the pathological study of COVID-19 through CT imaging has become imperative. The current segmentation approach based on TVLoss enhances the connectivity of afflicted areas. Nevertheless, it tends to misclassify normal pixels between certain adjacent diseased regions as diseased pixels. The typical Binary cross entropy(BCE) based U-shaped network only concentrates on the entire CT images without emphasizing on the affected regions, which results in hazy borders and low contrast in the projected output. In addition, the fraction of infected pixels in CT images is much less, which makes it a challenge for segmentation models to make accurate predictions. In this paper, we propose COVID-CT-H-UNet, a COVID-19 CT segmentation network to solve these problems. To recognize the unaffected pixels between neighbouring diseased regions, extra visual layer information is captured by combining the attention module on the skip connections with the proposed composite function Bi-category Hybrid Loss. The issue of hazy boundaries and poor contrast brought on by the BCE Loss in conventional techniques is resolved by utilizing the composite function Bi-category Hybrid Loss that concentrates on the pixels in the diseased area. The experiment shows when compared to the previous COVID-19 segmentation networks, the proposed COVID-CT-H-UNet's segmentation impact has greatly improved, and it may be used to identify and study clinical COVID-19. ",
    "url": "https://arxiv.org/abs/2403.10880",
    "authors": [
      "Anay Panja",
      "Somenath Kuiry",
      "Alaka Das",
      "Mita Nasipuri",
      "Nibaran Das"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10929",
    "title": "Function-space Parameterization of Neural Networks for Sequential  Learning",
    "abstract": "Sequential learning paradigms pose challenges for gradient-based deep learning due to difficulties incorporating new data and retaining prior knowledge. While Gaussian processes elegantly tackle these problems, they struggle with scalability and handling rich inputs, such as images. To address these issues, we introduce a technique that converts neural networks from weight space to function space, through a dual parameterization. Our parameterization offers: (i) a way to scale function-space methods to large data sets via sparsification, (ii) retention of prior knowledge when access to past data is limited, and (iii) a mechanism to incorporate new data without retraining. Our experiments demonstrate that we can retain knowledge in continual learning and incorporate new data efficiently. We further show its strengths in uncertainty quantification and guiding exploration in model-based RL. Further information and code is available on the project website. ",
    "url": "https://arxiv.org/abs/2403.10929",
    "authors": [
      "Aidan Scannell",
      "Riccardo Mereu",
      "Paul Chang",
      "Ella Tamir",
      "Joni Pajarinen",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10938",
    "title": "Modelling co-evolution of resource feedback and social network dynamics  in human-environmental systems",
    "abstract": "Games with environmental feedback have become a crucial area of study across various scientific domains, modelling the dynamic interplay between human decisions and environmental changes, and highlighting the consequences of our choices on natural resources and biodiversity. In this work, we propose a co-evolutionary model for human-environment systems that incorporates the effects of knowledge feedback and social interaction on the sustainability of common pool resources. The model represents consumers as agents who adjust their resource extraction based on the resource's state. These agents are connected through social networks, where links symbolize either affinity or aversion among them. The interplay between social dynamics and resource dynamics is explored, with the system's evolution analyzed across various network topologies and initial conditions. We find that knowledge feedback can independently sustain common pool resources. However, the impact of social interactions on sustainability is dual-faceted: it can either support or impede sustainability, influenced by the network's connectivity and heterogeneity. A notable finding is the identification of a critical network mean degree, beyond which a depletion/repletion transition parallels an absorbing/active state transition in social dynamics, i.e., individual agents and their connections are/are not prone to being frozen in their social states. Furthermore, the study examines the evolution of the social network, revealing the emergence of two polarized groups where agents within each community have the same affinity. Comparative analyses using Monte-Carlo simulations and rate equations are employed, along with analytical arguments, to reinforce the study's findings. The model successfully captures how information spread and social dynamics may impact the sustanebility of common pool resource. ",
    "url": "https://arxiv.org/abs/2403.10938",
    "authors": [
      "Meghdad Saeedian",
      "Chengyi Tu",
      "Fabio Menegazzo",
      "Paolo D'Odorico",
      "Sandro Azaele",
      "Samir Suweis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2403.11015",
    "title": "Identifying the Attractors of Gene Regulatory Networks from Expression  Data under Uncertainty: An Interpretable Approach",
    "abstract": "In systems biology, attractor landscape analysis of gene regulatory networks is recognized as a powerful computational tool for studying various cellular states from proliferation and differentiation to senescence and apoptosis. Therefore, accurate identification of attractors plays a critical role in determination of the cell fates. On the other hand, in a real biological circuit, genetic/epigenetic alterations as well as varying environmental factors drastically take effect on the location, characteristics, and even the number of attractors. The central question is: Given a temporal gene expression profile of a real gene regulatory network, how can the attractors be robustly identified in the presence of huge amount of uncertainty? This paper addresses this question using a novel approach based on Zadeh Computing with Words. The proposed scheme could effectively identify the attractors from temporal gene expression data in terms of both fuzzy logic-based and linguistic descriptions which are simply interpretable by human experts. Therefore, this method can be considered as an effective step towards interpretable artificial intelligence. Without loss of generality, genetic toggle switch is considered as the case study. The nonlinear dynamics of this benchmark gene regulatory network is computationally modeled by the notion of uncertain stochastic differential equations. The results of in-silico study demonstrate the efficiency and robustness of the proposed method. ",
    "url": "https://arxiv.org/abs/2403.11015",
    "authors": [
      "Alireza Rowhanimanesh"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11037",
    "title": "Fine-Grained Engine Fault Sound Event Detection Using Multimodal Signals",
    "abstract": "Sound event detection (SED) is an active area of audio research that aims to detect the temporal occurrence of sounds. In this paper, we apply SED to engine fault detection by introducing a multimodal SED framework that detects fine-grained engine faults of automobile engines using audio and accelerometer-recorded vibration. We first introduce the problem of engine fault SED on a dataset collected from a large variety of vehicles with expertly-labeled engine fault sound events. Next, we propose a SED model to temporally detect ten fine-grained engine faults that occur within vehicle engines and further explore a pretraining strategy using a large-scale weakly-labeled engine fault dataset. Through multiple evaluations, we show our proposed framework is able to effectively detect engine fault sound events. Finally, we investigate the interaction and characteristics of each modality and show that fusing features from audio and vibration improves overall engine fault SED capabilities. ",
    "url": "https://arxiv.org/abs/2403.11037",
    "authors": [
      "Dennis Fedorishin",
      "Livio Forte III",
      "Philip Schneider",
      "Srirangaraj Setlur",
      "Venu Govindaraju"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2403.11048",
    "title": "JustQ: Automated Deployment of Fair and Accurate Quantum Neural Networks",
    "abstract": "Despite the success of Quantum Neural Networks (QNNs) in decision-making systems, their fairness remains unexplored, as the focus primarily lies on accuracy. This work conducts a design space exploration, unveiling QNN unfairness, and highlighting the significant influence of QNN deployment and quantum noise on accuracy and fairness. To effectively navigate the vast QNN deployment design space, we propose JustQ, a framework for deploying fair and accurate QNNs on NISQ computers. It includes a complete NISQ error model, reinforcement learning-based deployment, and a flexible optimization objective incorporating both fairness and accuracy. Experimental results show JustQ outperforms previous methods, achieving superior accuracy and fairness. This work pioneers fair QNN design on NISQ computers, paving the way for future investigations. ",
    "url": "https://arxiv.org/abs/2403.11048",
    "authors": [
      "Ruhan Wang",
      "Fahiz Baba-Yara",
      "Fan Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11155",
    "title": "Interactive $360^{\\circ}$ Video Streaming Using FoV-Adaptive Coding with  Temporal Prediction",
    "abstract": "For $360^{\\circ}$ video streaming, FoV-adaptive coding that allocates more bits for the predicted user's field of view (FoV) is an effective way to maximize the rendered video quality under the limited bandwidth. We develop a low-latency FoV-adaptive coding and streaming system for interactive applications that is robust to bandwidth variations and FoV prediction errors. To minimize the end-to-end delay and yet maximize the coding efficiency, we propose a frame-level FoV-adaptive inter-coding structure. In each frame, regions that are in or near the predicted FoV are coded using temporal and spatial prediction, while a small rotating region is coded with spatial prediction only. This rotating intra region periodically refreshes the entire frame, thereby providing robustness to both FoV prediction errors and frame losses due to transmission errors. The system adapts the sizes and rates of different regions for each video segment to maximize the rendered video quality under the predicted bandwidth constraint. Integrating such frame-level FoV adaptation with temporal prediction is challenging due to the temporal variations of the FoV. We propose novel ways for modeling the influence of FoV dynamics on the quality-rate performance of temporal predictive coding.We further develop LSTM-based machine learning models to predict the user's FoV and network bandwidth.The proposed system is compared with three benchmark systems, using real-world network bandwidth traces and FoV traces, and is shown to significantly improve the rendered video quality, while achieving very low end-to-end delay and low frame-freeze probability. ",
    "url": "https://arxiv.org/abs/2403.11155",
    "authors": [
      "Yixiang Mao",
      "Liyang Sun",
      "Yong Liu",
      "Yao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.11230",
    "title": "Simple 2D Convolutional Neural Network-based Approach for COVID-19  Detection",
    "abstract": "This study explores the use of deep learning techniques for analyzing lung Computed Tomography (CT) images. Classic deep learning approaches face challenges with varying slice counts and resolutions in CT images, a diversity arising from the utilization of assorted scanning equipment. Typically, predictions are made on single slices which are then combined for a comprehensive outcome. Yet, this method does not incorporate learning features specific to each slice, leading to a compromise in effectiveness. To address these challenges, we propose an advanced Spatial-Slice Feature Learning (SSFL++) framework specifically tailored for CT scans. It aims to filter out out-of-distribution (OOD) data within the entire CT scan, allowing us to select essential spatial-slice features for analysis by reducing data redundancy by 70\\%. Additionally, we introduce a Kernel-Density-based slice Sampling (KDS) method to enhance stability during training and inference phases, thereby accelerating convergence and enhancing overall performance. Remarkably, our experiments reveal that our model achieves promising results with a simple EfficientNet-2D (E2D) model. The effectiveness of our approach is confirmed on the COVID-19-CT-DB datasets provided by the DEF-AI-MIA workshop. ",
    "url": "https://arxiv.org/abs/2403.11230",
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Yang Fan Chiang",
      "Yi-Shiuan Chou",
      "Chih-Yu Jiang",
      "Shen-Chieh Tai",
      "Chi-Han Tsai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11249",
    "title": "YOLOv9 for Fracture Detection in Pediatric Wrist Trauma X-ray Images",
    "abstract": "The introduction of YOLOv9, the latest version of the You Only Look Once (YOLO) series, has led to its widespread adoption across various scenarios. This paper is the first to apply the YOLOv9 algorithm model to the fracture detection task as computer-assisted diagnosis (CAD) to help radiologists and surgeons to interpret X-ray images. Specifically, this paper trained the model on the GRAZPEDWRI-DX dataset and extended the training set using data augmentation techniques to improve the model performance. Experimental results demonstrate that compared to the mAP 50-95 of the current state-of-the-art (SOTA) model, the YOLOv9 model increased the value from 42.16% to 43.73%, with an improvement of 3.7%. The implementation code is publicly available at https://github.com/RuiyangJu/YOLOv9-Fracture-Detection. ",
    "url": "https://arxiv.org/abs/2403.11249",
    "authors": [
      "Chun-Tse Chien",
      "Rui-Yang Ju",
      "Kuang-Yi Chou",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11338",
    "title": "Ensembling and Test Augmentation for Covid-19 Detection and Covid-19  Domain Adaptation from 3D CT-Scans",
    "abstract": "Since the emergence of Covid-19 in late 2019, medical image analysis using artificial intelligence (AI) has emerged as a crucial research area, particularly with the utility of CT-scan imaging for disease diagnosis. This paper contributes to the 4th COV19D competition, focusing on Covid-19 Detection and Covid-19 Domain Adaptation Challenges. Our approach centers on lung segmentation and Covid-19 infection segmentation employing the recent CNN-based segmentation architecture PDAtt-Unet, which simultaneously segments lung regions and infections. Departing from traditional methods, we concatenate the input slice (grayscale) with segmented lung and infection, generating three input channels akin to color channels. Additionally, we employ three 3D CNN backbones Customized Hybrid-DeCoVNet, along with pretrained 3D-Resnet-18 and 3D-Resnet-50 models to train Covid-19 recognition for both challenges. Furthermore, we explore ensemble approaches and testing augmentation to enhance performance. Comparison with baseline results underscores the substantial efficiency of our approach, with a significant margin in terms of F1-score (14 %). This study advances the field by presenting a comprehensive methodology for accurate Covid-19 detection and adaptation, leveraging cutting-edge AI techniques in medical image analysis. ",
    "url": "https://arxiv.org/abs/2403.11338",
    "authors": [
      "Fares Bougourzi",
      "Feryal Windal Moula",
      "Halim Benhabiles",
      "Fadi Dornaika",
      "Abdelmalik Taleb-Ahmed"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11420",
    "title": "Neural network representation of quantum systems",
    "abstract": "It has been proposed that random wide neural networks near Gaussian process are quantum field theories around Gaussian fixed points. In this paper, we provide a novel map with which a wide class of quantum mechanical systems can be cast into the form of a neural network with a statistical summation over network parameters. Our simple idea is to use the universal approximation theorem of neural networks to generate arbitrary paths in the Feynman's path integral. The map can be applied to interacting quantum systems / field theories, even away from the Gaussian limit. Our findings bring machine learning closer to the quantum world. ",
    "url": "https://arxiv.org/abs/2403.11420",
    "authors": [
      "Koji Hashimoto",
      "Yuji Hirono",
      "Jun Maeda",
      "Jojiro Totsuka-Yoshinaka"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2403.11433",
    "title": "Measuring Quantum Information Leakage Under Detection Threat",
    "abstract": "Gentle quantum leakage is proposed as a measure of information leakage to arbitrary eavesdroppers that aim to avoid detection. Gentle (also sometimes referred to as weak or non-demolition) measurements are used to encode the desire of the eavesdropper to evade detection. The gentle quantum leakage meets important axioms proposed for measures of information leakage including positivity, independence, and unitary invariance. Global depolarizing noise, an important family of physical noise in quantum devices, is shown to reduce gentle quantum leakage (and hence can be used as a mechanism to ensure privacy or security). A lower bound for the gentle quantum leakage based on asymmetric approximate cloning is presented. This lower bound relates information leakage to mutual incompatibility of quantum states. A numerical example, based on the encoding in the celebrated BB84 quantum key distribution algorithm, is used to demonstrate the results. ",
    "url": "https://arxiv.org/abs/2403.11433",
    "authors": [
      "Farhad Farokhi",
      "Sejeong Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11480",
    "title": "Towards understanding the nature of direct functional connectivity in  visual brain network",
    "abstract": "Recent advances in neuroimaging have enabled studies in functional connectivity (FC) of human brain, alongside investigation of the neuronal basis of cognition. One important FC study is the representation of vision in human brain. The release of publicly available dataset BOLD5000 has made it possible to study the brain dynamics during visual tasks in greater detail. In this paper, a comprehensive analysis of fMRI time series (TS) has been performed to explore different types of visual brain networks (VBN). The novelty of this work lies in (1) constructing VBN with consistently significant direct connectivity using both marginal and partial correlation, which is further analyzed using graph theoretic measures, (2) classification of VBNs as formed by image complexity-specific TS, using graphical features. In image complexity-specific VBN classification, XGBoost yields average accuracy in the range of 86.5% to 91.5% for positively correlated VBN, which is 2% greater than that using negative correlation. This result not only reflects the distinguishing graphical characteristics of each image complexity-specific VBN, but also highlights the importance of studying both positively correlated and negatively correlated VBN to understand the how differently brain functions while viewing different complexities of real-world images. ",
    "url": "https://arxiv.org/abs/2403.11480",
    "authors": [
      "Debanjali Bhattacharya",
      "Neelam Sinha"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11498",
    "title": "Domain Adaptation Using Pseudo Labels for COVID-19 Detection",
    "abstract": "In response to the need for rapid and accurate COVID-19 diagnosis during the global pandemic, we present a two-stage framework that leverages pseudo labels for domain adaptation to enhance the detection of COVID-19 from CT scans. By utilizing annotated data from one domain and non-annotated data from another, the model overcomes the challenge of data scarcity and variability, common in emergent health crises. The innovative approach of generating pseudo labels enables the model to iteratively refine its learning process, thereby improving its accuracy and adaptability across different hospitals and medical centres. Experimental results on COV19-CT-DB database showcase the model's potential to achieve high diagnostic precision, significantly contributing to efficient patient management and alleviating the strain on healthcare systems. Our method achieves 0.92 Macro F1 Score on the validation set of Covid-19 domain adaptation challenge. ",
    "url": "https://arxiv.org/abs/2403.11498",
    "authors": [
      "Runtian Yuan",
      "Qingqiu Li",
      "Junlin Hou",
      "Jilan Xu",
      "Yuejie Zhang",
      "Rui Feng",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11504",
    "title": "MLVICX: Multi-Level Variance-Covariance Exploration for Chest X-ray  Self-Supervised Representation Learning",
    "abstract": "Self-supervised learning (SSL) is potentially useful in reducing the need for manual annotation and making deep learning models accessible for medical image analysis tasks. By leveraging the representations learned from unlabeled data, self-supervised models perform well on tasks that require little to no fine-tuning. However, for medical images, like chest X-rays, which are characterized by complex anatomical structures and diverse clinical conditions, there arises a need for representation learning techniques that can encode fine-grained details while preserving the broader contextual information. In this context, we introduce MLVICX (Multi-Level Variance-Covariance Exploration for Chest X-ray Self-Supervised Representation Learning), an approach to capture rich representations in the form of embeddings from chest X-ray images. Central to our approach is a novel multi-level variance and covariance exploration strategy that empowers the model to detect diagnostically meaningful patterns while reducing redundancy effectively. By enhancing the variance and covariance of the learned embeddings, MLVICX promotes the retention of critical medical insights by adapting both global and local contextual details. We demonstrate the performance of MLVICX in advancing self-supervised chest X-ray representation learning through comprehensive experiments. The performance enhancements we observe across various downstream tasks highlight the significance of the proposed approach in enhancing the utility of chest X-ray embeddings for precision medical diagnosis and comprehensive image analysis. For pertaining, we used the NIH-Chest X-ray dataset, while for downstream tasks, we utilized NIH-Chest X-ray, Vinbig-CXR, RSNA pneumonia, and SIIM-ACR Pneumothorax datasets. Overall, we observe more than 3% performance gains over SOTA SSL approaches in various downstream tasks. ",
    "url": "https://arxiv.org/abs/2403.11504",
    "authors": [
      "Azad Singh",
      "Vandan Gorade",
      "Deepak Mishra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11505",
    "title": "Covid-19 detection from CT scans using EfficientNet and Attention  mechanism",
    "abstract": "Manual diagnosis and analysis of COVID-19 through the examination of lung Computed Tomography (CT) scan images by physicians tends to result in inefficiency, especially with high patient volumes and numerous images per patient. We address the need for automation by developing a deep learning model-based pipeline for COVID-19 detection from CT scan images of the lungs. The Domain adaptation, Explainability, and Fairness in AI for Medical Image Analysis Workshop and COVID-19 Diagnosis Competition (DEF-AI-MIA COV19D) provides an opportunity to assess our designed pipeline for COVID-19 detection from CT scan images. The proposed pipeline incorporates EfficientNet with an Attention mechanism with a pre-processing step. Our pipeline outperforms last year's teams on the validation set of the competition dataset. ",
    "url": "https://arxiv.org/abs/2403.11505",
    "authors": [
      "Ramy Farag",
      "Parth Upadhyay",
      "Guilhermen DeSouza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11517",
    "title": "Inter-individual and inter-site neural code conversion and image  reconstruction without shared stimuli",
    "abstract": "The human brain demonstrates substantial inter-individual variability in fine-grained functional topography, posing challenges in identifying common neural representations across individuals. Functional alignment has the potential to harmonize these individual differences. However, it typically requires an identical set of stimuli presented to different individuals, which is often unavailable. To address this, we propose a content loss-based neural code converter, designed to convert brain activity from one subject to another representing the same content. The converter is optimized so that the source subject's converted brain activity is decoded into a latent image representation that closely resembles that of the stimulus given to the source subject. We show that converters optimized using hierarchical image representations achieve conversion accuracy comparable to those optimized by paired brain activity as in conventional methods. The brain activity converted from a different individual and even from a different site sharing no stimuli produced reconstructions that approached the quality of within-individual reconstructions. The converted brain activity had a generalizable representation that can be read out by different decoding schemes. The converter required much fewer training samples than that typically required for decoder training to produce recognizable reconstructions. These results demonstrate that our method can effectively combine image representations to convert brain activity across individuals without the need for shared stimuli, providing a promising tool for flexibly aligning data from complex cognitive tasks and a basis for brain-to-brain communication. ",
    "url": "https://arxiv.org/abs/2403.11517",
    "authors": [
      "Haibao Wang",
      "Jun Kai Ho",
      "Fan L. Cheng",
      "Shuntaro C. Aoki",
      "Yusuke Muraki",
      "Misato Tanaka",
      "Yukiyasu Kamitani"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.11521",
    "title": "A Data-driven Approach for Rapid Detection of Aeroelastic Modes from  Flutter Flight Test Based on Limited Sensor Measurements",
    "abstract": "Flutter flight test involves the evaluation of the airframes aeroelastic stability by applying artificial excitation on the aircraft lifting surfaces. The subsequent responses are captured and analyzed to extract the frequencies and damping characteristics of the system. However, noise contamination, turbulence, non-optimal excitation of modes, and sensor malfunction in one or more sensors make it time-consuming and corrupt the extraction process. In order to expedite the process of identifying and analyzing aeroelastic modes, this study implements a time-delay embedded Dynamic Mode Decomposition technique. This approach is complemented by Robust Principal Component Analysis methodology, and a sparsity promoting criterion which enables the automatic and optimal selection of sparse modes. The anonymized flutter flight test data, provided by the fifth author of this research paper, is utilized in this implementation. The methodology assumes no knowledge of the input excitation, only deals with the responses captured by accelerometer channels, and rapidly identifies the aeroelastic modes. By incorporating a compressed sensing algorithm, the methodology gains the ability to identify aeroelastic modes, even when the number of available sensors is limited. This augmentation greatly enhances the methodology's robustness and effectiveness, making it an excellent choice for real-time implementation during flutter test campaigns. ",
    "url": "https://arxiv.org/abs/2403.11521",
    "authors": [
      "Arpan Das",
      "Pier Marzocca",
      "Giuliano Coppotelli",
      "Oleg Levinski",
      "Paul Taylor"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2403.11532",
    "title": "Out-of-Distribution Detection Should Use Conformal Prediction (and  Vice-versa?)",
    "abstract": "Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of using OOD together with CP apply the other way around by using OOD scores as non-conformity scores, which results in improving upon current CP methods. One of the key messages of these contributions is that since OOD is concerned with designing scores and CP with interpreting these scores, the two fields may be inherently intertwined. ",
    "url": "https://arxiv.org/abs/2403.11532",
    "authors": [
      "Paul Novello",
      "Joseba Dalmau",
      "L\u00e9o Andeol"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11672",
    "title": "WIA-LD2ND: Wavelet-based Image Alignment for Self-supervised Low-Dose CT  Denoising",
    "abstract": "In clinical examinations and diagnoses, low-dose computed tomography (LDCT) is crucial for minimizing health risks compared with normal-dose computed tomography (NDCT). However, reducing the radiation dose compromises the signal-to-noise ratio, leading to degraded quality of CT images. To address this, we analyze LDCT denoising task based on experimental results from the frequency perspective, and then introduce a novel self-supervised CT image denoising method called WIA-LD2ND, only using NDCT data. The proposed WIA-LD2ND comprises two modules: Wavelet-based Image Alignment (WIA) and Frequency-Aware Multi-scale Loss (FAM). First, WIA is introduced to align NDCT with LDCT by mainly adding noise to the high-frequency components, which is the main difference between LDCT and NDCT. Second, to better capture high-frequency components and detailed information, Frequency-Aware Multi-scale Loss (FAM) is proposed by effectively utilizing multi-scale feature space. Extensive experiments on two public LDCT denoising datasets demonstrate that our WIA-LD2ND, only uses NDCT, outperforms existing several state-of-the-art weakly-supervised and self-supervised methods. ",
    "url": "https://arxiv.org/abs/2403.11672",
    "authors": [
      "Haoyu Zhao",
      "Yuliang Gu",
      "Zhou Zhao",
      "Bo Du",
      "Yongchao Xu",
      "Rui Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11694",
    "title": "Object Segmentation-Assisted Inter Prediction for Versatile Video Coding",
    "abstract": "In modern video coding standards, block-based inter prediction is widely adopted, which brings high compression efficiency. However, in natural videos, there are usually multiple moving objects of arbitrary shapes, resulting in complex motion fields that are difficult to compactly represent. This problem has been tackled by more flexible block partitioning methods in the Versatile Video Coding (VVC) standard, but the more flexible partitions require more overhead bits to signal and still cannot be made arbitrary shaped. To address this limitation, we propose an object segmentation-assisted inter prediction method (SAIP), where objects in the reference frames are segmented by some advanced technologies. With a proper indication, the object segmentation mask is translated from the reference frame to the current frame as the arbitrary-shaped partition of different regions without any extra signal. Using the segmentation mask, motion compensation is separately performed for different regions, achieving higher prediction accuracy. The segmentation mask is further used to code the motion vectors of different regions more efficiently. Moreover, segmentation mask is considered in the joint rate-distortion optimization for motion estimation and partition estimation to derive the motion vector of different regions and partition more accurately. The proposed method is implemented into the VVC reference software, VTM version 12.0. Experimental results show that the proposed method achieves up to 1.98%, 1.14%, 0.79%, and on average 0.82%, 0.49%, 0.37% BD-rate reduction for common test sequences, under the Low-delay P, Low-delay B, and Random Access configurations, respectively. ",
    "url": "https://arxiv.org/abs/2403.11694",
    "authors": [
      "Zhuoyuan Li",
      "Zikun Yuan",
      "Li Li",
      "Dong Liu",
      "Xiaohu Tang",
      "Feng Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11699",
    "title": "A Spatial-Temporal Progressive Fusion Network for Breast Lesion  Segmentation in Ultrasound Videos",
    "abstract": "Ultrasound video-based breast lesion segmentation provides a valuable assistance in early breast lesion detection and treatment. However, existing works mainly focus on lesion segmentation based on ultrasound breast images which usually can not be adapted well to obtain desirable results on ultrasound videos. The main challenge for ultrasound video-based breast lesion segmentation is how to exploit the lesion cues of both intra-frame and inter-frame simultaneously. To address this problem, we propose a novel Spatial-Temporal Progressive Fusion Network (STPFNet) for video based breast lesion segmentation problem. The main aspects of the proposed STPFNet are threefold. First, we propose to adopt a unified network architecture to capture both spatial dependences within each ultrasound frame and temporal correlations between different frames together for ultrasound data representation. Second, we propose a new fusion module, termed Multi-Scale Feature Fusion (MSFF), to fuse spatial and temporal cues together for lesion detection. MSFF can help to determine the boundary contour of lesion region to overcome the issue of lesion boundary blurring. Third, we propose to exploit the segmentation result of previous frame as the prior knowledge to suppress the noisy background and learn more robust representation. In particular, we introduce a new publicly available ultrasound video breast lesion segmentation dataset, termed UVBLS200, which is specifically dedicated to breast lesion segmentation. It contains 200 videos, including 80 videos of benign lesions and 120 videos of malignant lesions. Experiments on the proposed dataset demonstrate that the proposed STPFNet achieves better breast lesion detection performance than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.11699",
    "authors": [
      "Zhengzheng Tu",
      "Zigang Zhu",
      "Yayang Duan",
      "Bo Jiang",
      "Qishun Wang",
      "Chaoxue Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.11744",
    "title": "A First-Order Gradient Approach for the Connectivity Analysis of  Weighted Graphs",
    "abstract": "Weighted graphs are commonly used to model various complex systems, including social networks, power grids, transportation networks, and biological systems. In many applications, the connectivity of these networks can be expressed through the Mean First Passage Times (MFPTs) of a Markov chain modeling a random walker on the graph. In this paper, we generalize the network metrics based on Markov chains' MFPTs and extend them to networks affected by uncertainty, in which edges may fail and hence not be present according to a pre-determined stochastic model. To find optimally connected graphs, we present a parameterization-free method for optimizing the MFPTs of the underlying Markov chain. More specifically, we show how to extend the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm in the context of Markov chain optimization. The proposed algorithm is suitable for both fixed and random networks. Using various numerical experiments, we demonstrate scalability compared to established benchmarks. Importantly, our algorithm finds an optimal solution without requiring prior knowledge of edge failure probabilities, allowing for an online optimization approach. ",
    "url": "https://arxiv.org/abs/2403.11744",
    "authors": [
      "Christian P.C. Franssen",
      "Alessandro Zocca",
      "Bernd F. Heidergott"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.11826",
    "title": "CapsLorentzNet: Integrating Physics Inspired Features with Graph  Convolution",
    "abstract": "With the advent of advanced machine learning techniques, boosted object tagging has witnessed significant progress. In this article, we take this field further by introducing novel architectural modifications compatible with a wide array of Graph Neural Network (GNN) architectures. Our approach advocates for integrating capsule layers, replacing the conventional decoding blocks in standard GNNs. These capsules are a group of neurons with vector activations. The orientation of these vectors represents important properties of the objects under study, with their magnitude characterizing whether the object under study belongs to the class represented by the capsule. Moreover, capsule networks incorporate a regularization by reconstruction mechanism, facilitating the seamless integration of expert-designed high-level features into the analysis. We have studied the usefulness of our architecture with the LorentzNet architecture for quark-gluon tagging. Here, we have replaced the decoding block of LorentzNet with a capsulated decoding block and have called the resulting architecture CapsLorentzNet. Our new architecture can enhance the performance of LorentzNet by 20 \\% for the quark-gluon tagging task. ",
    "url": "https://arxiv.org/abs/2403.11826",
    "authors": [
      "Rameswar Sahu"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2403.11841",
    "title": "Pessimistic Causal Reinforcement Learning with Mediators for Confounded  Offline Data",
    "abstract": "In real-world scenarios, datasets collected from randomized experiments are often constrained by size, due to limitations in time and budget. As a result, leveraging large observational datasets becomes a more attractive option for achieving high-quality policy learning. However, most existing offline reinforcement learning (RL) methods depend on two key assumptions--unconfoundedness and positivity--which frequently do not hold in observational data contexts. Recognizing these challenges, we propose a novel policy learning algorithm, PESsimistic CAusal Learning (PESCAL). We utilize the mediator variable based on front-door criterion to remove the confounding bias; additionally, we adopt the pessimistic principle to address the distributional shift between the action distributions induced by candidate policies, and the behavior policy that generates the observational data. Our key observation is that, by incorporating auxiliary variables that mediate the effect of actions on system dynamics, it is sufficient to learn a lower bound of the mediator distribution function, instead of the Q-function, to partially mitigate the issue of distributional shift. This insight significantly simplifies our algorithm, by circumventing the challenging task of sequential uncertainty quantification for the estimated Q-function. Moreover, we provide theoretical guarantees for the algorithms we propose, and demonstrate their efficacy through simulations, as well as real-world experiments utilizing offline datasets from a leading ride-hailing platform. ",
    "url": "https://arxiv.org/abs/2403.11841",
    "authors": [
      "Danyang Wang",
      "Chengchun Shi",
      "Shikai Luo",
      "Will Wei Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11871",
    "title": "The Real Tropical Geometry of Neural Networks",
    "abstract": "We consider a binary classifier defined as the sign of a tropical rational function, that is, as the difference of two convex piecewise linear functions. The parameter space of ReLU neural networks is contained as a semialgebraic set inside the parameter space of tropical rational functions. We initiate the study of two different subdivisions of this parameter space: a subdivision into semialgebraic sets, on which the combinatorial type of the decision boundary is fixed, and a subdivision into a polyhedral fan, capturing the combinatorics of the partitions of the dataset. The sublevel sets of the 0/1-loss function arise as subfans of this classification fan, and we show that the level-sets are not necessarily connected. We describe the classification fan i) geometrically, as normal fan of the activation polytope, and ii) combinatorially through a list of properties of associated bipartite graphs, in analogy to covector axioms of oriented matroids and tropical oriented matroids. Our findings extend and refine the connection between neural networks and tropical geometry by observing structures established in real tropical geometry, such as positive tropicalizations of hypersurfaces and tropical semialgebraic sets. ",
    "url": "https://arxiv.org/abs/2403.11871",
    "authors": [
      "Marie-Charlotte Brandenburg",
      "Georg Loho",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.11872",
    "title": "NuGraph2: A Graph Neural Network for Neutrino Physics Event  Reconstruction",
    "abstract": "Liquid Argon Time Projection Chamber (LArTPC) detector technology offers a wealth of high-resolution information on particle interactions, and leveraging that information to its full potential requires sophisticated automated reconstruction techniques. This article describes NuGraph2, a Graph Neural Network (GNN) for low-level reconstruction of simulated neutrino interactions in a LArTPC detector. Simulated neutrino interactions in the MicroBooNE detector geometry are described as heterogeneous graphs, with energy depositions on each detector plane forming nodes on planar subgraphs. The network utilizes a multi-head attention message-passing mechanism to perform background filtering and semantic labelling on these graph nodes, identifying those associated with the primary physics interaction with 98.0\\% efficiency and labelling them according to particle type with 94.9\\% efficiency. The network operates directly on detector observables across multiple 2D representations, but utilizes a 3D-context-aware mechanism to encourage consistency between these representations. Model inference takes 0.12 s/event on a CPU, and 0.005 s/event batched on a GPU. This architecture is designed to be a general-purpose solution for particle reconstruction in neutrino physics, with the potential for deployment across a broad range of detector technologies, and offers a core convolution engine that can be leveraged for a variety of tasks beyond the two described in this article. ",
    "url": "https://arxiv.org/abs/2403.11872",
    "authors": [
      "V Hewes",
      "Adam Aurisano",
      "Giuseppe Cerati",
      "Jim Kowalkowski",
      "Claire Lee",
      "Wei-keng Liao",
      "Daniel Grzenda",
      "Kaushal Gumpula",
      "Xiaohe Zhang"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2403.11893",
    "title": "Quantum Coordination Rates in Multi-Partite Networks",
    "abstract": "The optimal coordination rates are determined in three primary settings of multi-partite quantum networks, thus characterizing the minimal resources required in order to simulate a joint quantum state among multiple parties. We study the following models: (1) a cascade network with limited entanglement, (2) a broadcast network, which consists of a single sender and two receivers, (3) a multiple-access network with two senders and a single receiver. We establish the necessary and sufficient conditions on the asymptotically-achievable communication and entanglement rates in each setting. At last, we show the implications of our results on nonlocal games with quantum strategies. ",
    "url": "https://arxiv.org/abs/2403.11893",
    "authors": [
      "Hosen Nator",
      "Uzi Pereg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.11953",
    "title": "Advancing COVID-19 Detection in 3D CT Scans",
    "abstract": "To make a more accurate diagnosis of COVID-19, we propose a straightforward yet effective model. Firstly, we analyse the characteristics of 3D CT scans and remove the non-lung parts, facilitating the model to focus on lesion-related areas and reducing computational cost. We use ResNeSt50 as the strong feature extractor, initializing it with pretrained weights which have COVID-19-specific prior knowledge. Our model achieves a Macro F1 Score of 0.94 on the validation set of the 4th COV19D Competition Challenge $\\mathrm{I}$, surpassing the baseline by 16%. This indicates its effectiveness in distinguishing between COVID-19 and non-COVID-19 cases, making it a robust method for COVID-19 detection. ",
    "url": "https://arxiv.org/abs/2403.11953",
    "authors": [
      "Qingqiu Li",
      "Runtian Yuan",
      "Junlin Hou",
      "Jilan Xu",
      "Yuejie Zhang",
      "Rui Feng",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1703.05537",
    "title": "Shift Aggregate Extract Networks",
    "abstract": " Title: Shift Aggregate Extract Networks ",
    "url": "https://arxiv.org/abs/1703.05537",
    "authors": [
      "Francesco Orsini",
      "Daniele Baracchi",
      "Paolo Frasconi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.17271",
    "title": "DCVNet: Dilated Cost Volume Networks for Fast Optical Flow",
    "abstract": " Title: DCVNet: Dilated Cost Volume Networks for Fast Optical Flow ",
    "url": "https://arxiv.org/abs/2103.17271",
    "authors": [
      "Huaizu Jiang",
      "Erik Learned-Miller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.00815",
    "title": "Representation Learning for Weakly Supervised Relation Extraction",
    "abstract": " Comments: Master's Research Thesis for the Australian National University, 60 pages, submitted in October 2015 ",
    "url": "https://arxiv.org/abs/2105.00815",
    "authors": [
      "Zhuang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2108.02759",
    "title": "Unifying Global-Local Representations in Salient Object Detection with  Transformer",
    "abstract": " Comments: accepted by IEEE TETCI ",
    "url": "https://arxiv.org/abs/2108.02759",
    "authors": [
      "Sucheng Ren",
      "Qiang Wen",
      "Nanxuan Zhao",
      "Guoqiang Han",
      "Shengfeng He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03546",
    "title": "Beyond network centrality: Individual-level behavioral traits for  predicting information superspreaders in social media",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2112.03546",
    "authors": [
      "Fang Zhou",
      "Linyuan L\u00fc",
      "Jianguo Liu",
      "Manuel Sebastian Mariani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2203.02511",
    "title": "Self-Supervised Learning for Joint Pushing and Grasping Policies in  Highly Cluttered Environments",
    "abstract": " Comments: This paper has been accepted for publication at the ICRA2024 conference ",
    "url": "https://arxiv.org/abs/2203.02511",
    "authors": [
      "Yongliang Wang",
      "Kamal Mokhtar",
      "Cock Heemskerk",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2204.04236",
    "title": "ChildCI Framework: Analysis of Motor and Cognitive Development in  Children-Computer Interaction for Age Detection",
    "abstract": " Comments: 12 pages, 3 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2204.04236",
    "authors": [
      "Juan Carlos Ruiz-Garcia",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Julian Fierrez",
      "Jaime Herreros-Rodriguez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.12095",
    "title": "PyGOD: A Python Library for Graph Outlier Detection",
    "abstract": " Comments: Accepted by JMLR. Library available at this https URL ",
    "url": "https://arxiv.org/abs/2204.12095",
    "authors": [
      "Kay Liu",
      "Yingtong Dou",
      "Xueying Ding",
      "Xiyang Hu",
      "Ruitong Zhang",
      "Hao Peng",
      "Lichao Sun",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.03386",
    "title": "Egocentric Visual Self-Modeling for Autonomous Robot Dynamics Prediction  and Adaptation",
    "abstract": " Title: Egocentric Visual Self-Modeling for Autonomous Robot Dynamics Prediction  and Adaptation ",
    "url": "https://arxiv.org/abs/2207.03386",
    "authors": [
      "Yuhang Hu",
      "Boyuan Chen",
      "Hod Lipson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.04589",
    "title": "Causal Intervention for Fairness in Multi-behavior Recommendation",
    "abstract": " Comments: This paper is accepted by IEEE Transactions on Computational Social Systems ",
    "url": "https://arxiv.org/abs/2209.04589",
    "authors": [
      "Xi Wang",
      "Wenjie Wang",
      "Wenge Rong",
      "Fuli Feng",
      "Chuantao Yin",
      "Zhang Xiong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.05208",
    "title": "Graph Neural Modeling of Network Flows",
    "abstract": " Title: Graph Neural Modeling of Network Flows ",
    "url": "https://arxiv.org/abs/2209.05208",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2209.08747",
    "title": "On Robust Cross-View Consistency in Self-Supervised Monocular Depth  Estimation",
    "abstract": " Title: On Robust Cross-View Consistency in Self-Supervised Monocular Depth  Estimation ",
    "url": "https://arxiv.org/abs/2209.08747",
    "authors": [
      "Haimei Zhao",
      "Jing Zhang",
      "Zhuo Chen",
      "Bo Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.12605",
    "title": "MechProNet: Machine Learning Prediction of Mechanical Properties in  Metal Additive Manufacturing",
    "abstract": " Title: MechProNet: Machine Learning Prediction of Mechanical Properties in  Metal Additive Manufacturing ",
    "url": "https://arxiv.org/abs/2209.12605",
    "authors": [
      "Parand Akbari",
      "Masoud Zamani",
      "Amir Mostafaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14568",
    "title": "Local and Regional Counterfactual Rules: Summarized and Robust Recourses",
    "abstract": " Comments: ICML (International Conference on Machine Learning) 2023 Workshop on Counterfactuals in Minds and Machines ",
    "url": "https://arxiv.org/abs/2209.14568",
    "authors": [
      "Salim I. Amoukou",
      "Nicolas J.B Brunel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14769",
    "title": "Navigation as Attackers Wish? Towards Building Robust Embodied Agents  under Federated Learning",
    "abstract": " Title: Navigation as Attackers Wish? Towards Building Robust Embodied Agents  under Federated Learning ",
    "url": "https://arxiv.org/abs/2211.14769",
    "authors": [
      "Yunchao Zhang",
      "Zonglin Di",
      "Kaiwen Zhou",
      "Cihang Xie",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.00371",
    "title": "Robust Domain Adaptive Object Detection with Unified Multi-Granularity  Alignment",
    "abstract": " Title: Robust Domain Adaptive Object Detection with Unified Multi-Granularity  Alignment ",
    "url": "https://arxiv.org/abs/2301.00371",
    "authors": [
      "Libo Zhang",
      "Wenzhang Zhou",
      "Heng Fan",
      "Tiejian Luo",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.01404",
    "title": "Provably Bounding Neural Network Preimages",
    "abstract": " Comments: NeurIPS 2023 (Spotlight) ",
    "url": "https://arxiv.org/abs/2302.01404",
    "authors": [
      "Suhas Kotha",
      "Christopher Brix",
      "Zico Kolter",
      "Krishnamurthy Dvijotham",
      "Huan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2302.02060",
    "title": "Representation Deficiency in Masked Language Modeling",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2302.02060",
    "authors": [
      "Yu Meng",
      "Jitin Krishnan",
      "Sinong Wang",
      "Qifan Wang",
      "Yuning Mao",
      "Han Fang",
      "Marjan Ghazvininejad",
      "Jiawei Han",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04552",
    "title": "Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial  Online Convex Optimization",
    "abstract": " Comments: v3 substantially improves the presentation and has a few improvements, including the regret bound for strongly convex functions; v2 is an extended version that enriches the content with improved regret bounds for strongly convex functions, discussions on the optimism design for dynamic regret minimization, and extensions to non-smooth scenarios; v1 is the ICML 2023 conference version ",
    "url": "https://arxiv.org/abs/2302.04552",
    "authors": [
      "Sijia Chen",
      "Yu-Jie Zhang",
      "Wei-Wei Tu",
      "Peng Zhao",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.13451",
    "title": "A low latency attention module for streaming self-supervised speech  representation learning",
    "abstract": " Comments: 19 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2302.13451",
    "authors": [
      "Jianbo Ma",
      "Siqi Pan",
      "Deepak Chandran",
      "Andrea Fanelli",
      "Richard Cartwright"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.11323",
    "title": "Tangent Bundle Convolutional Learning: from Manifolds to Cellular  Sheaves and Back",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2210.15058 ",
    "url": "https://arxiv.org/abs/2303.11323",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.00436",
    "title": "Instance-Level Trojan Attacks on Visual Question Answering via  Adversarial Learning in Neuron Activation Space",
    "abstract": " Comments: Accepted for IJCNN 2024 ",
    "url": "https://arxiv.org/abs/2304.00436",
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03376",
    "title": "Interpretable statistical representations of neural population dynamics  and geometry",
    "abstract": " Comments: Version before peer review ",
    "url": "https://arxiv.org/abs/2304.03376",
    "authors": [
      "Adam Gosztolai",
      "Robert L. Peach",
      "Alexis Arnaudon",
      "Mauricio Barahona",
      "Pierre Vandergheynst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2304.05104",
    "title": "Approaching Test Time Augmentation in the Context of Uncertainty  Calibration for Deep Neural Networks",
    "abstract": " Comments: Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2304.05104",
    "authors": [
      "Pedro Conde",
      "Tiago Barros",
      "Rui L. Lopes",
      "Cristiano Premebida",
      "Urbano J. Nunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.06094",
    "title": "Energy-guided Entropic Neural Optimal Transport",
    "abstract": " Title: Energy-guided Entropic Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2304.06094",
    "authors": [
      "Petr Mokrov",
      "Alexander Korotin",
      "Alexander Kolesov",
      "Nikita Gushchin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09097",
    "title": "Sheaf4Rec: Sheaf Neural Networks for Graph-based Recommender Systems",
    "abstract": " Comments: 21 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2304.09097",
    "authors": [
      "Antonio Purificato",
      "Giulia Cassar\u00e0",
      "Federico Siciliano",
      "Pietro Li\u00f2",
      "Fabrizio Silvestri"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09444",
    "title": "Rank-Based Learning and Local Model Based Evolutionary Algorithm for  High-Dimensional Expensive Multi-Objective Problems",
    "abstract": " Title: Rank-Based Learning and Local Model Based Evolutionary Algorithm for  High-Dimensional Expensive Multi-Objective Problems ",
    "url": "https://arxiv.org/abs/2304.09444",
    "authors": [
      "Guodong Chen",
      "Jiu Jimmy Jiao",
      "Xiaoming Xue",
      "Zhongzheng Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.10268",
    "title": "BackCache: Mitigating Contention-Based Cache Timing Attacks by Hiding  Cache Line Evictions",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2304.10268",
    "authors": [
      "Quancheng Wang",
      "Xige Zhang",
      "Han Wang",
      "Yuzhe Gu",
      "Ming Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.00385",
    "title": "Cross-Shaped Windows Transformer with Self-supervised Pretraining for  Clinically Significant Prostate Cancer Detection in Bi-parametric MRI",
    "abstract": " Title: Cross-Shaped Windows Transformer with Self-supervised Pretraining for  Clinically Significant Prostate Cancer Detection in Bi-parametric MRI ",
    "url": "https://arxiv.org/abs/2305.00385",
    "authors": [
      "Yuheng Li",
      "Jacob Wynne",
      "Jing Wang",
      "Richard L.J. Qiu",
      "Justin Roper",
      "Shaoyan Pan",
      "Ashesh B. Jani",
      "Tian Liu",
      "Pretesh R. Patel",
      "Hui Mao",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11074",
    "title": "Tram: A Token-level Retrieval-augmented Mechanism for Source Code  Summarization",
    "abstract": " Comments: NAACL 2024 ",
    "url": "https://arxiv.org/abs/2305.11074",
    "authors": [
      "Tong Ye",
      "Lingfei Wu",
      "Tengfei Ma",
      "Xuhong Zhang",
      "Yangkai Du",
      "Peiyu Liu",
      "Shouling Ji",
      "Wenhai Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11997",
    "title": "Robust Counterfactual Explanations for Neural Networks With  Probabilistic Guarantees",
    "abstract": " Comments: International Conference on Machine Learning (ICML), 2023 ",
    "url": "https://arxiv.org/abs/2305.11997",
    "authors": [
      "Faisal Hamman",
      "Erfaun Noorani",
      "Saumitra Mishra",
      "Daniele Magazzeni",
      "Sanghamitra Dutta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12681",
    "title": "Phased Data Augmentation for Training a Likelihood-Based Generative  Model with Limited Data",
    "abstract": " Title: Phased Data Augmentation for Training a Likelihood-Based Generative  Model with Limited Data ",
    "url": "https://arxiv.org/abs/2305.12681",
    "authors": [
      "Yuta Mimura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.12854",
    "title": "RDA-INR: Riemannian Diffeomorphic Autoencoding via Implicit Neural  Representations",
    "abstract": " Comments: 34 pages, 27 figures (including subfigures) ",
    "url": "https://arxiv.org/abs/2305.12854",
    "authors": [
      "Sven Dummer",
      "Nicola Strisciuglio",
      "Christoph Brune"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.13991",
    "title": "Expressive Losses for Verified Robustness via Convex Combinations",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2305.13991",
    "authors": [
      "Alessandro De Palma",
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Robert Stanforth",
      "Alessio Lomuscio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14534",
    "title": "Detecting Propaganda Techniques in Code-Switched Social Media Text",
    "abstract": " Title: Detecting Propaganda Techniques in Code-Switched Social Media Text ",
    "url": "https://arxiv.org/abs/2305.14534",
    "authors": [
      "Muhammad Umar Salman",
      "Asif Hanif",
      "Shady Shehata",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15852",
    "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation",
    "abstract": " Title: Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation ",
    "url": "https://arxiv.org/abs/2305.15852",
    "authors": [
      "Niels M\u00fcndler",
      "Jingxuan He",
      "Slobodan Jenko",
      "Martin Vechev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04590",
    "title": "Proximity-Informed Calibration for Deep Neural Networks",
    "abstract": " Comments: The paper is accepted by NeurIPS 2023. The code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2306.04590",
    "authors": [
      "Miao Xiong",
      "Ailin Deng",
      "Pang Wei Koh",
      "Jiaying Wu",
      "Shen Li",
      "Jianqing Xu",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.10060",
    "title": "MUBen: Benchmarking the Uncertainty of Molecular Representation Models",
    "abstract": " Title: MUBen: Benchmarking the Uncertainty of Molecular Representation Models ",
    "url": "https://arxiv.org/abs/2306.10060",
    "authors": [
      "Yinghao Li",
      "Lingkai Kong",
      "Yuanqi Du",
      "Yue Yu",
      "Yuchen Zhuang",
      "Wenhao Mu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16001",
    "title": "Streamlining Social Media Information Retrieval for COVID-19 Research  with Deep Learning",
    "abstract": " Comments: Updated full paper. Abstract presented at IEEE ICHI 2023 and AMIA Annual Symposium 2023 ",
    "url": "https://arxiv.org/abs/2306.16001",
    "authors": [
      "Yining Hua",
      "Jiageng Wu",
      "Shixu Lin",
      "Minghui Li",
      "Yujie Zhang",
      "Dinah Foer",
      "Siwen Wang",
      "Peilin Zhou",
      "Jie Yang",
      "Li Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.01187",
    "title": "SAMAug: Point Prompt Augmentation for Segment Anything Model",
    "abstract": " Title: SAMAug: Point Prompt Augmentation for Segment Anything Model ",
    "url": "https://arxiv.org/abs/2307.01187",
    "authors": [
      "Haixing Dai",
      "Chong Ma",
      "Zhiling Yan",
      "Zhengliang Liu",
      "Enze Shi",
      "Yiwei Li",
      "Peng Shu",
      "Xiaozheng Wei",
      "Lin Zhao",
      "Zihao Wu",
      "Fang Zeng",
      "Dajiang Zhu",
      "Wei Liu",
      "Quanzheng Li",
      "Lichao Sun",
      "Shu Zhang Tianming Liu",
      "Xiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.06029",
    "title": "Pluggable Neural Machine Translation Models via Memory-augmented  Adapters",
    "abstract": " Comments: Accepted by LREC-COLING 2024 ",
    "url": "https://arxiv.org/abs/2307.06029",
    "authors": [
      "Yuzhuang Xu",
      "Shuo Wang",
      "Peng Li",
      "Xuebo Liu",
      "Xiaolong Wang",
      "Weidong Liu",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.07919",
    "title": "Neural Architecture Retrieval",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2307.07919",
    "authors": [
      "Xiaohuan Pei",
      "Yanxi Li",
      "Minjing Dong",
      "Chang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11714",
    "title": "Convergence of SGD for Training Neural Networks with Sliced Wasserstein  Losses",
    "abstract": " Title: Convergence of SGD for Training Neural Networks with Sliced Wasserstein  Losses ",
    "url": "https://arxiv.org/abs/2307.11714",
    "authors": [
      "Eloi Tanguy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2308.01151",
    "title": "Conservation, convergence, and computation for evolving heterogeneous  elastic wires",
    "abstract": " Comments: 34 pages, 13 figures. Final version. To appear in SIAM J. Math. Anal ",
    "url": "https://arxiv.org/abs/2308.01151",
    "authors": [
      "Anna Dall'Acqua",
      "Gaspard Jankowiak",
      "Leonie Langer",
      "Fabian Rupp"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.03135",
    "title": "EventBind: Learning a Unified Representation to Bind Them All for  Event-based Open-world Understanding",
    "abstract": " Comments: Conference version with supplementary ",
    "url": "https://arxiv.org/abs/2308.03135",
    "authors": [
      "Jiazhou Zhou",
      "Xu Zheng",
      "Yuanhuiyi Lyu",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.03584",
    "title": "A Polystore Architecture Using Knowledge Graphs to Support Queries on  Heterogeneous Data Stores",
    "abstract": " Comments: Reference the paper as L. G. Azevedo, R. Souza, E. F. de S. Soares, R. M. Thiago, J. C. D. Tesolin, A. C. Oliveira, M. F. Moreno, A Polystore Architecture Using Knowledge Graphs to Support Queries on Heterogeneous Data Stores. Proceedings of 20th Brazilian Symposium in Information Systems, 2024 (to be published) ",
    "url": "https://arxiv.org/abs/2308.03584",
    "authors": [
      "Leonardo Guerreiro Azevedo",
      "Renan Francisco Santos Souza",
      "Elton F. de S. Soares",
      "Raphael M. Thiago",
      "Julio Cesar Cardoso Tesolin",
      "Ann C. Oliveira",
      "Marcio Ferreira Moreno"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2308.06378",
    "title": "DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System",
    "abstract": " Title: DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System ",
    "url": "https://arxiv.org/abs/2308.06378",
    "authors": [
      "Mojtaba Yeganejou",
      "Kimia Honari",
      "Ryan Kluzinski",
      "Scott Dick",
      "Michael Lipsett",
      "James Miller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07233",
    "title": "A Unifying Generator Loss Function for Generative Adversarial Networks",
    "abstract": " Comments: 33 pages, 4 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2308.07233",
    "authors": [
      "Justin Veiner",
      "Fady Alajaji",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07553",
    "title": "Enhancing the Antidote: Improved Pointwise Certifications against  Poisoning Attacks",
    "abstract": " Title: Enhancing the Antidote: Improved Pointwise Certifications against  Poisoning Attacks ",
    "url": "https://arxiv.org/abs/2308.07553",
    "authors": [
      "Shijie Liu",
      "Andrew C. Cullen",
      "Paul Montague",
      "Sarah M. Erfani",
      "Benjamin I. P. Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.08487",
    "title": "Temporal Interest Network for User Response Prediction",
    "abstract": " Title: Temporal Interest Network for User Response Prediction ",
    "url": "https://arxiv.org/abs/2308.08487",
    "authors": [
      "Haolin Zhou",
      "Junwei Pan",
      "Xinyi Zhou",
      "Xihua Chen",
      "Jie Jiang",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.00464",
    "title": "A Theoretical and Practical Framework for Evaluating Uncertainty  Calibration in Object Detection",
    "abstract": " Comments: Pre-print ",
    "url": "https://arxiv.org/abs/2309.00464",
    "authors": [
      "Pedro Conde",
      "Rui L. Lopes",
      "Cristiano Premebida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.04664",
    "title": "Compact: Approximating Complex Activation Functions for Secure  Computation",
    "abstract": " Comments: Accepted to Proceedings on Privacy Enhancing Technologies (PoPETs) ",
    "url": "https://arxiv.org/abs/2309.04664",
    "authors": [
      "Mazharul Islam",
      "Sunpreet S. Arora",
      "Rahul Chatterjee",
      "Peter Rindal",
      "Maliheh Shirvanian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.05472",
    "title": "LeBenchmark 2.0: a Standardized, Replicable and Enhanced Framework for  Self-supervised Representations of French Speech",
    "abstract": " Comments: Published in Computer Science and Language. Preprint allowed ",
    "url": "https://arxiv.org/abs/2309.05472",
    "authors": [
      "Titouan Parcollet",
      "Ha Nguyen",
      "Solene Evain",
      "Marcely Zanon Boito",
      "Adrien Pupier",
      "Salima Mdhaffar",
      "Hang Le",
      "Sina Alisamir",
      "Natalia Tomashenko",
      "Marco Dinarelli",
      "Shucong Zhang",
      "Alexandre Allauzen",
      "Maximin Coavoux",
      "Yannick Esteve",
      "Mickael Rouvier",
      "Jerome Goulian",
      "Benjamin Lecouteux",
      "Francois Portet",
      "Solange Rossato",
      "Fabien Ringeval",
      "Didier Schwab",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.08005",
    "title": "Efficient Face Detection with Audio-Based Region Proposals for  Human-Robot Interactions",
    "abstract": " Title: Efficient Face Detection with Audio-Based Region Proposals for  Human-Robot Interactions ",
    "url": "https://arxiv.org/abs/2309.08005",
    "authors": [
      "William Aris",
      "Fran\u00e7ois Grondin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.08927",
    "title": "DynaMoN: Motion-Aware Fast and Robust Camera Localization for Dynamic  Neural Radiance Fields",
    "abstract": " Comments: 6 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.08927",
    "authors": [
      "Nicolas Schischka",
      "Hannah Schieber",
      "Mert Asim Karaoglu",
      "Melih G\u00f6rg\u00fcl\u00fc",
      "Florian Gr\u00f6tzner",
      "Alexander Ladikos",
      "Daniel Roth",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09258",
    "title": "Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets",
    "abstract": " Comments: 18 Pages, 1 figure. Published in the Transactions on Machine Learning Research (TMLR) in Feb, 2024. arXiv admin note: substantial text overlap with arXiv:2210.11452 ",
    "url": "https://arxiv.org/abs/2309.09258",
    "authors": [
      "Pulkit Gopalani",
      "Samyak Jha",
      "Anirbit Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.10370",
    "title": "Geometric structure of shallow neural networks and constructive  ${\\mathcal L}^2$ cost minimization",
    "abstract": " Comments: AMS Latex, 28 pages. Exposition has been streamlined ",
    "url": "https://arxiv.org/abs/2309.10370",
    "authors": [
      "Thomas Chen",
      "Patricia Mu\u00f1oz Ewald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Mathematical Physics (math-ph)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.12128",
    "title": "Convergence and Recovery Guarantees of Unsupervised Neural Networks for  Inverse Problems",
    "abstract": " Title: Convergence and Recovery Guarantees of Unsupervised Neural Networks for  Inverse Problems ",
    "url": "https://arxiv.org/abs/2309.12128",
    "authors": [
      "Nathan Buskulic",
      "Jalal Fadili",
      "Yvain Qu\u00e9au"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16512",
    "title": "From Complexity to Clarity: Analytical Expressions of Deep Neural  Network Weights via Clifford's Geometric Algebra and Convexity",
    "abstract": " Title: From Complexity to Clarity: Analytical Expressions of Deep Neural  Network Weights via Clifford's Geometric Algebra and Convexity ",
    "url": "https://arxiv.org/abs/2309.16512",
    "authors": [
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00873",
    "title": "Deep Neural Networks Tend To Extrapolate Predictably",
    "abstract": " Title: Deep Neural Networks Tend To Extrapolate Predictably ",
    "url": "https://arxiv.org/abs/2310.00873",
    "authors": [
      "Katie Kang",
      "Amrith Setlur",
      "Claire Tomlin",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01012",
    "title": "Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised  Learning",
    "abstract": " Title: Unconstrained Stochastic CCA: Unifying Multiview and Self-Supervised  Learning ",
    "url": "https://arxiv.org/abs/2310.01012",
    "authors": [
      "James Chapman",
      "Lennie Wells",
      "Ana Lawry Aguila"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.01820",
    "title": "Towards Robust Fidelity for Evaluating Explainability of Graph Neural  Networks",
    "abstract": " Comments: Accepted by International Conference on Learning Representations (ICLR 2024); 26 Pages, 12 figures ",
    "url": "https://arxiv.org/abs/2310.01820",
    "authors": [
      "Xu Zheng",
      "Farhad Shirani",
      "Tianchun Wang",
      "Wei Cheng",
      "Zhuomin Chen",
      "Haifeng Chen",
      "Hua Wei",
      "Dongsheng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02003",
    "title": "L2MAC: Large Language Model Automatic Computer for Extensive Code  Generation",
    "abstract": " Comments: Published in The Twelfth International Conference on Learning Representations (ICLR), 2024. Copyright 2023 by the author(s) ",
    "url": "https://arxiv.org/abs/2310.02003",
    "authors": [
      "Samuel Holt",
      "Max Ruiz Luyten",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.02729",
    "title": "Efficient Quantification and Representation of Aggregate Flexibility in  Electric Vehicles",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2310.02729",
    "authors": [
      "Nanda Kishor Panda",
      "Simon H. Tindemans"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.04152",
    "title": "Improving Neural Radiance Field using Near-Surface Sampling with Point  Cloud Generation",
    "abstract": " Comments: 14 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2310.04152",
    "authors": [
      "Hye Bin Yoo",
      "Hyun Min Han",
      "Sung Soo Hwang",
      "Il Yong Chun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04971",
    "title": "Understanding the Robustness of Multi-modal Contrastive Learning to  Distribution Shift",
    "abstract": " Title: Understanding the Robustness of Multi-modal Contrastive Learning to  Distribution Shift ",
    "url": "https://arxiv.org/abs/2310.04971",
    "authors": [
      "Yihao Xue",
      "Siddharth Joshi",
      "Dang Nguyen",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05556",
    "title": "WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth  Estimation under Adverse Weather Conditions",
    "abstract": " Comments: 6 pages, accept by ICRA 2024 ",
    "url": "https://arxiv.org/abs/2310.05556",
    "authors": [
      "Jiyuan Wang",
      "Chunyu Lin",
      "Lang Nie",
      "Shujun Huang",
      "Yao Zhao",
      "Xing Pan",
      "Rui Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.06171",
    "title": "Memory-Consistent Neural Networks for Imitation Learning",
    "abstract": " Comments: ICLR 2024. 26 pages (9 main pages) ",
    "url": "https://arxiv.org/abs/2310.06171",
    "authors": [
      "Kaustubh Sridhar",
      "Souradeep Dutta",
      "Dinesh Jayaraman",
      "James Weimer",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.06790",
    "title": "Enhancing Predictive Capabilities in Data-Driven Dynamical Modeling with  Automatic Differentiation: Koopman and Neural ODE Approaches",
    "abstract": " Title: Enhancing Predictive Capabilities in Data-Driven Dynamical Modeling with  Automatic Differentiation: Koopman and Neural ODE Approaches ",
    "url": "https://arxiv.org/abs/2310.06790",
    "authors": [
      "C. Ricardo Constante-Amores",
      "Alec J. Linot",
      "Michael D. Graham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06921",
    "title": "Hybrid Zonotope-Based Backward Reachability Analysis for Neural Feedback  Systems With Nonlinear Plant Models",
    "abstract": " Comments: Accepted by IEEE American Control Conference 2024, 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2310.06921",
    "authors": [
      "Hang Zhang",
      "Yuhao Zhang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.08044",
    "title": "EC-Depth: Exploring the consistency of self-supervised monocular depth  estimation in challenging scenes",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2310.08044",
    "authors": [
      "Ziyang Song",
      "Ruijie Zhu",
      "Chuxin Wang",
      "Jiacheng Deng",
      "Jianfeng He",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08755",
    "title": "PU-Ray: Domain-Independent Point Cloud Upsampling via Ray Marching on  Neural Implicit Surface",
    "abstract": " Comments: 17 pages (11 main + 6 supplement), 21 figures (8 main + 13 supplement), 8 tables ",
    "url": "https://arxiv.org/abs/2310.08755",
    "authors": [
      "Sangwon Lim",
      "Karim El-Basyouny",
      "Yee Hong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.11784",
    "title": "Progressive3D: Progressively Local Editing for Text-to-3D Content  Creation with Complex Semantic Prompts",
    "abstract": " Comments: Accept by ICLR2024. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2310.11784",
    "authors": [
      "Xinhua Cheng",
      "Tianyu Yang",
      "Jianan Wang",
      "Yu Li",
      "Lei Zhang",
      "Jian Zhang",
      "Li Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.12790",
    "title": "Anomaly Heterogeneity Learning for Open-set Supervised Anomaly Detection",
    "abstract": " Comments: Accepted by CVPR2024; 15 pages; 4 figures ",
    "url": "https://arxiv.org/abs/2310.12790",
    "authors": [
      "Jiawen Zhu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.13694",
    "title": "Studying speed-accuracy trade-offs in best-of-n collective  decision-making through heterogeneous mean-field modeling",
    "abstract": " Comments: 29 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2310.13694",
    "authors": [
      "Andreagiovanni Reina",
      "Thierry Njougouo",
      "Elio Tuci",
      "Timoteo Carletti"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.15778",
    "title": "Privacy Protection in MRI Scans Using 3D Masked Autoencoders",
    "abstract": " Title: Privacy Protection in MRI Scans Using 3D Masked Autoencoders ",
    "url": "https://arxiv.org/abs/2310.15778",
    "authors": [
      "Lennart Alexander Van der Goten",
      "Kevin Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16597",
    "title": "Beyond IID weights: sparse and low-rank deep Neural Networks are also  Gaussian Processes",
    "abstract": " Title: Beyond IID weights: sparse and low-rank deep Neural Networks are also  Gaussian Processes ",
    "url": "https://arxiv.org/abs/2310.16597",
    "authors": [
      "Thiziri Nait-Saada",
      "Alireza Naderi",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17405",
    "title": "Causal Modeling with Stationary Diffusions",
    "abstract": " Comments: AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2310.17405",
    "authors": [
      "Lars Lorch",
      "Andreas Krause",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17645",
    "title": "PubDef: Defending Against Transfer Attacks From Public Models",
    "abstract": " Comments: ICLR 2024. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2310.17645",
    "authors": [
      "Chawin Sitawarin",
      "Jaewon Chang",
      "David Huang",
      "Wesson Altoyan",
      "David Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18247",
    "title": "Guided Data Augmentation for Offline Reinforcement Learning and  Imitation Learning",
    "abstract": " Title: Guided Data Augmentation for Offline Reinforcement Learning and  Imitation Learning ",
    "url": "https://arxiv.org/abs/2310.18247",
    "authors": [
      "Nicholas E. Corrado",
      "Yuxiao Qu",
      "John U. Balis",
      "Adam Labiosa",
      "Josiah P. Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.18917",
    "title": "TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural  Radiance Fields",
    "abstract": " Title: TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural  Radiance Fields ",
    "url": "https://arxiv.org/abs/2310.18917",
    "authors": [
      "Chengyao Duan",
      "Zhiliu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00318",
    "title": "Flooding Regularization for Stable Training of Generative Adversarial  Networks",
    "abstract": " Comments: 25 pages, 9 figures, 18 tables ",
    "url": "https://arxiv.org/abs/2311.00318",
    "authors": [
      "Iu Yahiro",
      "Takashi Ishida",
      "Naoto Yokoya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.06572",
    "title": "Swin UNETR++: Advancing Transformer-Based Dense Dose Prediction Towards  Fully Automated Radiation Oncology Treatments",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 16 pages ",
    "url": "https://arxiv.org/abs/2311.06572",
    "authors": [
      "Kuancheng Wang",
      "Hai Siong Tan",
      "Rafe Mcbeth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07914",
    "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
    "abstract": " Comments: Accepted Paper in NAACL 2024 ",
    "url": "https://arxiv.org/abs/2311.07914",
    "authors": [
      "Garima Agrawal",
      "Tharindu Kumarage",
      "Zeyad Alghamdi",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10319",
    "title": "Shifting to Machine Supervision: Annotation-Efficient Semi and  Self-Supervised Learning for Automatic Medical Image Segmentation and  Classification",
    "abstract": " Comments: Seventeen pages (incl. references), five figures, and one table. (Under Review) ",
    "url": "https://arxiv.org/abs/2311.10319",
    "authors": [
      "Pranav Singh",
      "Raviteja Chukkapalli",
      "Shravan Chaudhari",
      "Luoyao Chen",
      "Mei Chen",
      "Jinqian Pan",
      "Craig Smuda",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11013",
    "title": "Implicit Event-RGBD Neural SLAM",
    "abstract": " Comments: Accept at CVPR 2024 ",
    "url": "https://arxiv.org/abs/2311.11013",
    "authors": [
      "Delin Qu",
      "Chi Yan",
      "Dong Wang",
      "Jie Yin",
      "Dan Xu",
      "Bin Zhao",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11749",
    "title": "Revealing behavioral impact on mobility prediction networks through  causal interventions",
    "abstract": " Comments: 31 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2311.11749",
    "authors": [
      "Ye Hong",
      "Yanan Xin",
      "Simon Dirmeier",
      "Fernando Perez-Cruz",
      "Martin Raubal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.14265",
    "title": "Adaptive Calibration: A Unified Conversion Framework of Spiking Neural  Networks",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2311.14265",
    "authors": [
      "Ziqing Wang",
      "Yuetong Fang",
      "Jiahang Cao",
      "Renjing Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.15241",
    "title": "CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration  Network",
    "abstract": " Title: CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration  Network ",
    "url": "https://arxiv.org/abs/2311.15241",
    "authors": [
      "Yuxuan Xiao",
      "Yao Li",
      "Chengzhen Meng",
      "Xingchen Li",
      "Jianmin Ji",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.16834",
    "title": "Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention",
    "abstract": " Title: Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention ",
    "url": "https://arxiv.org/abs/2311.16834",
    "authors": [
      "Qiqi Su",
      "Christos Kloukinas",
      "Artur d'Avila Garcez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16909",
    "title": "Multinomial belief networks",
    "abstract": " Comments: 15 pages, 4 figs; supplement: 16 pages ",
    "url": "https://arxiv.org/abs/2311.16909",
    "authors": [
      "H. C. Donker",
      "D. Neijzen",
      "J. de Jong",
      "G. A. Lunter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2311.17248",
    "title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse  Problems",
    "abstract": " Comments: Supplementary material appears after the main article in the PDF. Main article has 16 pages, 7 figures, 3 tables, and 1 algorithm. Supplementary material has 4 pages and 5 figures ",
    "url": "https://arxiv.org/abs/2311.17248",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.00029",
    "title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based  Alignment Framework",
    "abstract": " Title: Bergeron: Combating Adversarial Attacks through a Conscience-Based  Alignment Framework ",
    "url": "https://arxiv.org/abs/2312.00029",
    "authors": [
      "Matthew Pisano",
      "Peter Ly",
      "Abraham Sanders",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Tomek Strzalkowski",
      "Mei Si"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00502",
    "title": "A Comprehensive Evaluation of Augmentations for Robust OOD  Self-Supervised Contrastive Phonocardiogram Representation Learning",
    "abstract": " Comments: PREPRINT Manuscript under review ",
    "url": "https://arxiv.org/abs/2312.00502",
    "authors": [
      "Aristotelis Ballas",
      "Vasileios Papapanagiotou",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2312.04135",
    "title": "A Novel Federated Learning-Based IDS for Enhancing UAVs Privacy and  Security",
    "abstract": " Comments: 15 ",
    "url": "https://arxiv.org/abs/2312.04135",
    "authors": [
      "Ozlem Ceviz",
      "Pinar Sadioglu",
      "Sevil Sen",
      "Vassilios G. Vassilakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.05720",
    "title": "Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning",
    "abstract": " Title: Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning ",
    "url": "https://arxiv.org/abs/2312.05720",
    "authors": [
      "Jianwei Li",
      "Sheng Liu",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.07061",
    "title": "MaxQ: Multi-Axis Query for N:M Sparsity Network",
    "abstract": " Comments: Accepted by the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024 (CVPR2024) ",
    "url": "https://arxiv.org/abs/2312.07061",
    "authors": [
      "Jingyang Xiang",
      "Siqi Li",
      "Junhao Chen",
      "Zhuangzhi Chen",
      "Tianxin Huang",
      "Linpeng Peng",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.07460",
    "title": "Empirical Validation of Conformal Prediction for Trustworthy Skin  Lesions Classification",
    "abstract": " Title: Empirical Validation of Conformal Prediction for Trustworthy Skin  Lesions Classification ",
    "url": "https://arxiv.org/abs/2312.07460",
    "authors": [
      "Jamil Fayyad",
      "Shadi Alijani",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08459",
    "title": "FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head  Models",
    "abstract": " Comments: Paper Video: this https URL Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2312.08459",
    "authors": [
      "Shivangi Aneja",
      "Justus Thies",
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.15245",
    "title": "Resonant Inductive Coupling Network for Human-Sized Magnetic Particle  Imaging",
    "abstract": " Title: Resonant Inductive Coupling Network for Human-Sized Magnetic Particle  Imaging ",
    "url": "https://arxiv.org/abs/2312.15245",
    "authors": [
      "Fabian Mohn",
      "Fynn F\u00f6rger",
      "Florian Thieben",
      "Martin M\u00f6ddel",
      "Ingo Schmale",
      "Tobias Knopp",
      "Matthias Graeser"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2312.16016",
    "title": "V-STRONG: Visual Self-Supervised Traversability Learning for Off-road  Navigation",
    "abstract": " Comments: ICRA 2024; 8 pages ",
    "url": "https://arxiv.org/abs/2312.16016",
    "authors": [
      "Sanghun Jung",
      "JoonHo Lee",
      "Xiangyun Meng",
      "Byron Boots",
      "Alexander Lambert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.16960",
    "title": "Adaptive Flip Graph Algorithm for Matrix Multiplication",
    "abstract": " Comments: 7 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2312.16960",
    "authors": [
      "Yamato Arai",
      "Yuma Ichikawa",
      "Koji Hukushima"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2401.01524",
    "title": "Multimodal self-supervised learning for lesion localization",
    "abstract": " Title: Multimodal self-supervised learning for lesion localization ",
    "url": "https://arxiv.org/abs/2401.01524",
    "authors": [
      "Hao Yang",
      "Hong-Yu Zhou",
      "Cheng Li",
      "Weijian Huang",
      "Jiarun Liu",
      "Yong Liang",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.01851",
    "title": "The Power of Training: How Different Neural Network Setups Influence the  Energy Demand",
    "abstract": " Title: The Power of Training: How Different Neural Network Setups Influence the  Energy Demand ",
    "url": "https://arxiv.org/abs/2401.01851",
    "authors": [
      "Daniel Gei\u00dfler",
      "Bo Zhou",
      "Mengxi Liu",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2401.04791",
    "title": "SOS-Match: Segmentation for Open-Set Robust Correspondence Search and  Robot Localization in Unstructured Environments",
    "abstract": " Comments: 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2401.04791",
    "authors": [
      "Annika Thomas",
      "Jouko Kinnari",
      "Parker Lusk",
      "Kota Kondo",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.06637",
    "title": "Adversarial Examples are Misaligned in Diffusion Model Manifolds",
    "abstract": " Comments: accepted at IJCNN ",
    "url": "https://arxiv.org/abs/2401.06637",
    "authors": [
      "Peter Lorenz",
      "Ricard Durall",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.07658",
    "title": "Robustness Evaluation of Localization Techniques for Autonomous Racing",
    "abstract": " Comments: Accepted at the Design, Automation and Test in Europe Conference 2024 as an extended abstract ",
    "url": "https://arxiv.org/abs/2401.07658",
    "authors": [
      "Tian Yi Lim",
      "Edoardo Ghignone",
      "Nicolas Baumann",
      "Michele Magno"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.08948",
    "title": "PINSAT: Parallelized Interleaving of Graph Search and Trajectory  Optimization for Kinodynamic Motion Planning",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2401.08948",
    "authors": [
      "Ramkumar Natarajan",
      "Shohin Mukherjee",
      "Howie Choset",
      "Maxim Likhachev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2401.10253",
    "title": "Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable  and Transferable Bandwidth Allocation",
    "abstract": " Title: Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable  and Transferable Bandwidth Allocation ",
    "url": "https://arxiv.org/abs/2401.10253",
    "authors": [
      "Xin Hao",
      "Changyang She",
      "Phee Lep Yeoh",
      "Yuhong Liu",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.10383",
    "title": "Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis",
    "abstract": " Title: Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis ",
    "url": "https://arxiv.org/abs/2401.10383",
    "authors": [
      "Phevos Paschalidis",
      "Runyu Zhang",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2401.11317",
    "title": "Third-Party Developers and Tool Development For Community Management on  Live Streaming Platform Twitch",
    "abstract": " Comments: Accepted by ACM CHI 2024 ",
    "url": "https://arxiv.org/abs/2401.11317",
    "authors": [
      "Jie Cai",
      "Ya-Fang Lin",
      "He Zhang",
      "John M. Carroll"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.11969",
    "title": "Claim Detection for Automated Fact-checking: A Survey on Monolingual,  Multilingual and Cross-Lingual Research",
    "abstract": " Comments: Accepted revision ",
    "url": "https://arxiv.org/abs/2401.11969",
    "authors": [
      "Rrubaa Panchendrarajan",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.13652",
    "title": "Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors",
    "abstract": " Title: Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors ",
    "url": "https://arxiv.org/abs/2401.13652",
    "authors": [
      "Francesco Della Santa",
      "Sandra Pieraccini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.13937",
    "title": "Self-supervised Video Object Segmentation with Distillation Learning of  Deformable Attention",
    "abstract": " Comments: under review ",
    "url": "https://arxiv.org/abs/2401.13937",
    "authors": [
      "Quang-Trung Truong",
      "Duc Thanh Nguyen",
      "Binh-Son Hua",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.14846",
    "title": "Understanding Domain Generalization: A Noise Robustness Perspective",
    "abstract": " Comments: Accepted to the 12th International Conference on Learning Representations (ICLR 2024). Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2401.14846",
    "authors": [
      "Rui Qiao",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.15603",
    "title": "Improving Expressive Power of Spectral Graph Neural Networks with  Eigenvalue Correction",
    "abstract": " Comments: Accepted by AAAI-24 ",
    "url": "https://arxiv.org/abs/2401.15603",
    "authors": [
      "Kangkang Lu",
      "Yanhua Yu",
      "Hao Fei",
      "Xuan Li",
      "Zixuan Yang",
      "Zirui Guo",
      "Meiyu Liang",
      "Mengran Yin",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2401.16414",
    "title": "A Causal Model for Quantifying Multipartite Classical and Quantum  Correlations",
    "abstract": " Comments: 22 pages, 13 figures. Changes in v2: Appendix B added; some notations changed ",
    "url": "https://arxiv.org/abs/2401.16414",
    "authors": [
      "Shuchan Wang",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2402.01001",
    "title": "Ensuring Data Privacy in AC Optimal Power Flow with a Distributed  Co-Simulation Framework",
    "abstract": " Title: Ensuring Data Privacy in AC Optimal Power Flow with a Distributed  Co-Simulation Framework ",
    "url": "https://arxiv.org/abs/2402.01001",
    "authors": [
      "Xinliang Dai",
      "Alexander Kocher",
      "Jovana Kova\u010devi\u0107",
      "Burak Dindar",
      "Yuning Jiang",
      "Colin N. Jones",
      "H\u00fcseyin \u00c7akmak",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2402.01030",
    "title": "Executable Code Actions Elicit Better LLM Agents",
    "abstract": " Comments: Code, data, model, and demo are available at this https URL ",
    "url": "https://arxiv.org/abs/2402.01030",
    "authors": [
      "Xingyao Wang",
      "Yangyi Chen",
      "Lifan Yuan",
      "Yizhe Zhang",
      "Yunzhu Li",
      "Hao Peng",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.05347",
    "title": "Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix  Differential Equations",
    "abstract": " Title: Robust Implicit Adaptive Low Rank Time-Stepping Methods for Matrix  Differential Equations ",
    "url": "https://arxiv.org/abs/2402.05347",
    "authors": [
      "Daniel Appel\u00f6",
      "Yingda Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.05713",
    "title": "Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on  Vulnerable Patient Populations",
    "abstract": " Comments: 29 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2402.05713",
    "authors": [
      "Pranav Kulkarni",
      "Andrew Chan",
      "Nithya Navarathna",
      "Skylar Chan",
      "Paul H. Yi",
      "Vishwa S. Parekh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.07563",
    "title": "Joint User and Beam Selection in Millimeter Wave Networks",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2402.07563",
    "authors": [
      "Santosh Kumar Singh",
      "Satyabrata Sahu",
      "Ayushi Thawait",
      "Prasanna Chaporkar",
      "Gaurav S. Kasbekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.08976",
    "title": "Confidence-aware Fine-tuning of Sequential Recommendation Systems via  Conformal Prediction",
    "abstract": " Title: Confidence-aware Fine-tuning of Sequential Recommendation Systems via  Conformal Prediction ",
    "url": "https://arxiv.org/abs/2402.08976",
    "authors": [
      "Chen Wang",
      "Fangxin Wang",
      "Ruocheng Guo",
      "Yueqing Liang",
      "Kay Liu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2402.10228",
    "title": "HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement  Learning Framework for Complex Environments",
    "abstract": " Comments: Bridging the theory and practice! Invited talk in Informs Optimization Conference 2024 and International Symposium on Mathematical Programming 2024! ",
    "url": "https://arxiv.org/abs/2402.10228",
    "authors": [
      "Yingru Li",
      "Jiawei Xu",
      "Lei Han",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2402.10359",
    "title": "Can we Soft Prompt LLMs for Graph Learning Tasks?",
    "abstract": " Comments: Accepted by The Web Conference (WWW) 2024 Short Paper Track ",
    "url": "https://arxiv.org/abs/2402.10359",
    "authors": [
      "Zheyuan Liu",
      "Xiaoxin He",
      "Yijun Tian",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.11702",
    "title": "Can ChatGPT Support Developers? An Empirical Evaluation of Large  Language Models for Code Generation",
    "abstract": " Comments: 4 pages, 3 figures, 21st International Conference on Mining Software Repositories (MSR '24), April 15-16, 2024, Lisbon, Portugal ",
    "url": "https://arxiv.org/abs/2402.11702",
    "authors": [
      "Kailun Jin",
      "Chung-Yu Wang",
      "Hung Viet Pham",
      "Hadi Hemmati"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.11887",
    "title": "Generative Semi-supervised Graph Anomaly Detection",
    "abstract": " Comments: 13 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2402.11887",
    "authors": [
      "Hezhe Qiao",
      "Qingsong Wen",
      "Xiaoli Li",
      "Ee-Peng Lim",
      "Guansong Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.12261",
    "title": "NEO-BENCH: Evaluating Robustness of Large Language Models with  Neologisms",
    "abstract": " Comments: pre-print, 9 pages ",
    "url": "https://arxiv.org/abs/2402.12261",
    "authors": [
      "Jonathan Zheng",
      "Alan Ritter",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.13605",
    "title": "KorNAT: LLM Alignment Benchmark for Korean Social Values and Common  Knowledge",
    "abstract": " Comments: 35 pages, 7 figures, 16 tables ",
    "url": "https://arxiv.org/abs/2402.13605",
    "authors": [
      "Jiyoung Lee",
      "Minwoo Kim",
      "Seungho Kim",
      "Junghwan Kim",
      "Seunghyun Won",
      "Hwaran Lee",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2402.14424",
    "title": "Automating Psychological Hypothesis Generation with AI: Large Language  Models Meet Causal Graph",
    "abstract": " Title: Automating Psychological Hypothesis Generation with AI: Large Language  Models Meet Causal Graph ",
    "url": "https://arxiv.org/abs/2402.14424",
    "authors": [
      "Song Tong",
      "Kai Mao",
      "Zhen Huang",
      "Yukun Zhao",
      "Kaiping Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2402.14899",
    "title": "Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning  Meets Adversarial Images",
    "abstract": " Title: Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning  Meets Adversarial Images ",
    "url": "https://arxiv.org/abs/2402.14899",
    "authors": [
      "Zefeng Wang",
      "Zhen Han",
      "Shuo Chen",
      "Fan Xue",
      "Zifeng Ding",
      "Xun Xiao",
      "Volker Tresp",
      "Philip Torr",
      "Jindong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.17736",
    "title": "Learning-Based Algorithms for Graph Searching Problems",
    "abstract": " Comments: AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2402.17736",
    "authors": [
      "Adela Frances DePavia",
      "Erasmo Tani",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.18152",
    "title": "Boosting Neural Representations for Videos with a Conditional Decoder",
    "abstract": " Comments: Accept by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2402.18152",
    "authors": [
      "Xinjie Zhang",
      "Ren Yang",
      "Dailan He",
      "Xingtong Ge",
      "Tongda Xu",
      "Yan Wang",
      "Hongwei Qin",
      "Jun Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.00033",
    "title": "Identification of Craving Maps among Marijuana Users via the Analysis of  Functional Brain Networks with High-Order Attention Graph Neural Networks",
    "abstract": " Title: Identification of Craving Maps among Marijuana Users via the Analysis of  Functional Brain Networks with High-Order Attention Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2403.00033",
    "authors": [
      "Jun-En Ding",
      "Shihao Yang",
      "Anna Zilverstand",
      "Feng Liu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.01232",
    "title": "Polynormer: Polynomial-Expressive Graph Transformer in Linear Time",
    "abstract": " Comments: Published as a conference paper at International Conference on Learning Representations (ICLR) 2024 ",
    "url": "https://arxiv.org/abs/2403.01232",
    "authors": [
      "Chenhui Deng",
      "Zichao Yue",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.01570",
    "title": "SERVAL: Synergy Learning between Vertical Models and LLMs towards  Oracle-Level Zero-shot Medical Prediction",
    "abstract": " Title: SERVAL: Synergy Learning between Vertical Models and LLMs towards  Oracle-Level Zero-shot Medical Prediction ",
    "url": "https://arxiv.org/abs/2403.01570",
    "authors": [
      "Jiahuan Yan",
      "Jintai Chen",
      "Chaowen Hu",
      "Bo Zheng",
      "Yaojun Hu",
      "Jimeng Sun",
      "Jian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02148",
    "title": "MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection",
    "abstract": " Comments: The first Mamba-based model for infrared small target detection ",
    "url": "https://arxiv.org/abs/2403.02148",
    "authors": [
      "Tianxiang Chen",
      "Zhentao Tan",
      "Tao Gong",
      "Qi Chu",
      "Yue Wu",
      "Bin Liu",
      "Jieping Ye",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.02221",
    "title": "TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language  Models",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2403.02221",
    "authors": [
      "Yilong Ren",
      "Yue Chen",
      "Shuai Liu",
      "Boyue Wang",
      "Haiyang Yu",
      "Zhiyong Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.03193",
    "title": "VeriEQL: Bounded Equivalence Verification for Complex SQL Queries with  Integrity Constraints",
    "abstract": " Comments: OOPSLA 2024 ",
    "url": "https://arxiv.org/abs/2403.03193",
    "authors": [
      "Yang He",
      "Pinhan Zhao",
      "Xinyu Wang",
      "Yuepeng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.03720",
    "title": "Criminal organizations exhibit hysteresis, resilience, and robustness by  balancing security and efficiency",
    "abstract": " Title: Criminal organizations exhibit hysteresis, resilience, and robustness by  balancing security and efficiency ",
    "url": "https://arxiv.org/abs/2403.03720",
    "authors": [
      "Casper van Elteren",
      "V\u00edtor V. Vasconcelos",
      "Mike Lees"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.05445",
    "title": "The minimum distance of a parameterized code over an even cycle",
    "abstract": " Title: The minimum distance of a parameterized code over an even cycle ",
    "url": "https://arxiv.org/abs/2403.05445",
    "authors": [
      "Eduardo Camps-Moreno",
      "Jorge Neves",
      "Eliseo Sarmiento"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2403.06095",
    "title": "RepoHyper: Better Context Retrieval Is All You Need for Repository-Level  Code Completion",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2403.06095",
    "authors": [
      "Huy N. Phan",
      "Hoang N. Phan",
      "Tien N. Nguyen",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.06495",
    "title": "Toward Generalist Anomaly Detection via In-context Residual Learning  with Few-shot Sample Prompts",
    "abstract": " Comments: Accepted to CVPR 2024; 17 pages; 5 figures ",
    "url": "https://arxiv.org/abs/2403.06495",
    "authors": [
      "Jiawen Zhu",
      "Guansong Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.06747",
    "title": "MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation",
    "abstract": " Comments: WWW 2024; The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2403.06747",
    "authors": [
      "Wenhao Wu",
      "Jialiang Zhou",
      "Ailong He",
      "Shuguang Han",
      "Jufeng Chen",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2403.07311",
    "title": "Knowledge Graph Large Language Model (KG-LLM) for Link Prediction",
    "abstract": " Comments: 23 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2403.07311",
    "authors": [
      "Dong Shu",
      "Tianle Chen",
      "Mingyu Jin",
      "Yiting Zhang",
      "Mengnan Du",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.07331",
    "title": "LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial  Keyword Queries",
    "abstract": " Title: LIST: Learning to Index Spatio-Textual Data for Embedding based Spatial  Keyword Queries ",
    "url": "https://arxiv.org/abs/2403.07331",
    "authors": [
      "Ziqi Yin",
      "Shanshan Feng",
      "Shang Liu",
      "Gao Cong",
      "Yew Soon Ong",
      "Bin Cui"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.08199",
    "title": "Deep Submodular Peripteral Networks",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2403.08199",
    "authors": [
      "Gantavya Bhatt",
      "Arnav Das",
      "Jeff Bilmes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08281",
    "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly  Specialized Language Models",
    "abstract": " Title: Mastering Text, Code and Math Simultaneously via Fusing Highly  Specialized Language Models ",
    "url": "https://arxiv.org/abs/2403.08281",
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xingtai Lv",
      "Weilin Zhao",
      "Ruobing Xie",
      "Bowen Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09034",
    "title": "rFaceNet: An End-to-End Network for Enhanced Physiological Signal  Extraction through Identity-Specific Facial Contours",
    "abstract": " Comments: under-review ",
    "url": "https://arxiv.org/abs/2403.09034",
    "authors": [
      "Dali Zhu",
      "Wenli Zhang",
      "Hualin Zeng",
      "Xiaohao Liu",
      "Long Yang",
      "Jiaqi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09209",
    "title": "LAN: Learning Adaptive Neighbors for Real-Time Insider Threat Detection",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2403.09209",
    "authors": [
      "Xiangrui Cai",
      "Yang Wang",
      "Sihan Xu",
      "Hao Li",
      "Ying Zhang",
      "Zheli Liu",
      "Xiaojie Yuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09254",
    "title": "Gun Culture in Fringe Social Media",
    "abstract": " Title: Gun Culture in Fringe Social Media ",
    "url": "https://arxiv.org/abs/2403.09254",
    "authors": [
      "Fatemeh Tahmasbi",
      "Aakarsha Chug",
      "Barry Bradlyn",
      "Jeremy Blackburn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2403.09401",
    "title": "Unsupervised Modality-Transferable Video Highlight Detection with  Representation Activation Sequence Learning",
    "abstract": " Comments: Accepted by IEEE Transactions on Image Processing, 2024 ",
    "url": "https://arxiv.org/abs/2403.09401",
    "authors": [
      "Tingtian Li",
      "Zixun Sun",
      "Xinyu Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10075",
    "title": "A survey of synthetic data augmentation methods in computer vision",
    "abstract": " Title: A survey of synthetic data augmentation methods in computer vision ",
    "url": "https://arxiv.org/abs/2403.10075",
    "authors": [
      "Alhassan Mumuni",
      "Fuseini Mumuni",
      "Nana Kobina Gerrar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  }
]