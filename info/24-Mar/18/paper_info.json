[
  {
    "id": "arXiv:2403.09672",
    "title": "COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced  Medical Image Representation",
    "abstract": "Substantial advances in multi-modal Artificial Intelligence (AI) facilitate the combination of diverse medical modalities to achieve holistic health assessments. We present COMPRER , a novel multi-modal, multi-objective pretraining framework which enhances medical-image representation, diagnostic inferences, and prognosis of diseases. COMPRER employs a multi-objective training framework, where each objective introduces distinct knowledge to the model. This includes a multimodal loss that consolidates information across different imaging modalities; A temporal loss that imparts the ability to discern patterns over time; Medical-measure prediction adds appropriate medical insights; Lastly, reconstruction loss ensures the integrity of image structure within the latent space. Despite the concern that multiple objectives could weaken task performance, our findings show that this combination actually boosts outcomes on certain tasks. Here, we apply this framework to both fundus images and carotid ultrasound, and validate our downstream tasks capabilities by predicting both current and future cardiovascular conditions. COMPRER achieved higher Area Under the Curve (AUC) scores in evaluating medical conditions compared to existing models on held-out data. On the Out-of-distribution (OOD) UK-Biobank dataset COMPRER maintains favorable performance over well-established models with more parameters, even though these models were trained on $75\\times$ more data than COMPRER. In addition, to better assess our model's performance in contrastive learning, we introduce a novel evaluation metric, providing deeper understanding of the effectiveness of the latent space pairing. ",
    "url": "https://arxiv.org/abs/2403.09672",
    "authors": [
      "Guy Lutsker",
      "Hagai Rossman",
      "Nastya Godiva",
      "Eran Segal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09706",
    "title": "Schema-Aware Multi-Task Learning for Complex Text-to-SQL",
    "abstract": "Conventional text-to-SQL parsers are not good at synthesizing complex SQL queries that involve multiple tables or columns, due to the challenges inherent in identifying the correct schema items and performing accurate alignment between question and schema items. To address the above issue, we present a schema-aware multi-task learning framework (named MTSQL) for complicated SQL queries. Specifically, we design a schema linking discriminator module to distinguish the valid question-schema linkings, which explicitly instructs the encoder by distinctive linking relations to enhance the alignment quality. On the decoder side, we define 6-type relationships to describe the connections between tables and columns (e.g., WHERE_TC), and introduce an operator-centric triple extractor to recognize those associated schema items with the predefined relationship. Also, we establish a rule set of grammar constraints via the predicted triples to filter the proper SQL operators and schema items during the SQL generation. On Spider, a cross-domain challenging text-to-SQL benchmark, experimental results indicate that MTSQL is more effective than baselines, especially in extremely hard scenarios. Moreover, further analyses verify that our approach leads to promising improvements for complicated SQL queries. ",
    "url": "https://arxiv.org/abs/2403.09706",
    "authors": [
      "Yangjun Wu",
      "Han Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.09713",
    "title": "A Hybrid Intelligence Method for Argument Mining",
    "abstract": "Large-scale survey tools enable the collection of citizen feedback in opinion corpora. Extracting the key arguments from a large and noisy set of opinions helps in understanding the opinions quickly and accurately. Fully automated methods can extract arguments but (1) require large labeled datasets that induce large annotation costs and (2) work well for known viewpoints, but not for novel points of view. We propose HyEnA, a hybrid (human + AI) method for extracting arguments from opinionated texts, combining the speed of automated processing with the understanding and reasoning capabilities of humans. We evaluate HyEnA on three citizen feedback corpora. We find that, on the one hand, HyEnA achieves higher coverage and precision than a state-of-the-art automated method when compared to a common set of diverse opinions, justifying the need for human insight. On the other hand, HyEnA requires less human effort and does not compromise quality compared to (fully manual) expert analysis, demonstrating the benefit of combining human and artificial intelligence. ",
    "url": "https://arxiv.org/abs/2403.09713",
    "authors": [
      "Michiel van der Meer",
      "Enrico Liscio",
      "Catholijn M. Jonker",
      "Aske Plaat",
      "Piek Vossen",
      "Pradeep K. Murukannaiah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.09721",
    "title": "A Semantic Mention Graph Augmented Model for Document-Level Event  Argument Extraction",
    "abstract": "Document-level Event Argument Extraction (DEAE) aims to identify arguments and their specific roles from an unstructured document. The advanced approaches on DEAE utilize prompt-based methods to guide pre-trained language models (PLMs) in extracting arguments from input documents. They mainly concentrate on establishing relations between triggers and entity mentions within documents, leaving two unresolved problems: a) independent modeling of entity mentions; b) document-prompt isolation. To this end, we propose a semantic mention Graph Augmented Model (GAM) to address these two problems in this paper. Firstly, GAM constructs a semantic mention graph that captures relations within and between documents and prompts, encompassing co-existence, co-reference and co-type relations. Furthermore, we introduce an ensembled graph transformer module to address mentions and their three semantic relations effectively. Later, the graph-augmented encoder-decoder module incorporates the relation-specific graph into the input embedding of PLMs and optimizes the encoder section with topology information, enhancing the relations comprehensively. Extensive experiments on the RAMS and WikiEvents datasets demonstrate the effectiveness of our approach, surpassing baseline methods and achieving a new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2403.09721",
    "authors": [
      "Jian Zhang",
      "Changlin Yang",
      "Haiping Zhu",
      "Qika Lin",
      "Fangzhi Xu",
      "Jun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09722",
    "title": "Prediction of readmission of patients by extracting biomedical concepts  from clinical texts",
    "abstract": "Today, the existence of a vast amount of electronic health data has created potential capacities for conducting studies aiming to improve the medical services provided to patients and reduce the costs of the healthcare system. One of the topics that has been receiving attention in the field of medicine in recent years is the identification of patients who are likely to be re-hospitalized shortly after being discharged from the hospital. This identification can help doctors choose appropriate treatment methods, thereby reducing the rate of patient re-hospitalization and resulting in effective treatment cost reduction. In this study, the prediction of patient re-hospitalization using text mining approaches and the processing of discharge report texts in the patient's electronic file has been discussed. To this end, the performance of various machine learning models has been evaluated using two approaches: bag of word and bag of concept, in the process of predicting patient readmission. Comparing the efficiency of these approaches has shown the superiority of the random forest model and the bag of concept approach over other machine learning models and approaches. This research has achieved the highest score in predicting the probability of patient re-hospitalization, with a recall score of 68.9%, compared to similar works that have utilized machine learning models in this field. ",
    "url": "https://arxiv.org/abs/2403.09722",
    "authors": [
      "Rasoul Samani",
      "Fahime Shahrokh",
      "Mohammad Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09724",
    "title": "ClaimVer: Explainable Claim-Level Verification and Evidence Attribution  of Text Through Knowledge Graphs",
    "abstract": "In the midst of widespread misinformation and disinformation through social media and the proliferation of AI-generated texts, it has become increasingly difficult for people to validate and trust information they encounter. Many fact-checking approaches and tools have been developed, but they often lack appropriate explainability or granularity to be useful in various contexts. A text validation method that is easy to use, accessible, and can perform fine-grained evidence attribution has become crucial. More importantly, building user trust in such a method requires presenting the rationale behind each prediction, as research shows this significantly influences people's belief in automated systems. It is also paramount to localize and bring users' attention to the specific problematic content, instead of providing simple blanket labels. In this paper, we present $\\textit{ClaimVer, a human-centric framework}$ tailored to meet users' informational and verification needs by generating rich annotations and thereby reducing cognitive load. Designed to deliver comprehensive evaluations of texts, it highlights each claim, verifies it against a trusted knowledge graph (KG), presents the evidence, and provides succinct, clear explanations for each claim prediction. Finally, our framework introduces an attribution score, enhancing applicability across a wide range of downstream tasks. ",
    "url": "https://arxiv.org/abs/2403.09724",
    "authors": [
      "Preetam Prabhu Srikar Dammu",
      "Himanshu Naidu",
      "Mouly Dewan",
      "YoungMin Kim",
      "Tanya Roosta",
      "Aman Chadha",
      "Chirag Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09735",
    "title": "A Sophisticated Framework for the Accurate Detection of Phishing  Websites",
    "abstract": "Phishing is an increasingly sophisticated form of cyberattack that is inflicting huge financial damage to corporations throughout the globe while also jeopardizing individuals' privacy. Attackers are constantly devising new methods of launching such assaults and detecting them has become a daunting task. Many different techniques have been suggested, each with its own pros and cons. While machine learning-based techniques have been most successful in identifying such attacks, they continue to fall short in terms of performance and generalizability. This paper proposes a comprehensive methodology for detecting phishing websites. The goal is to design a system that is capable of accurately distinguishing phishing websites from legitimate ones and provides generalized performance over a broad variety of datasets. A combination of feature selection, greedy algorithm, cross-validation, and deep learning methods have been utilized to construct a sophisticated stacking ensemble classifier. Extensive experimentation on four different phishing datasets was conducted to evaluate the performance of the proposed technique. The proposed algorithm outperformed the other existing phishing detection models obtaining accuracy of 97.49%, 98.23%, 97.48%, and 98.20% on dataset-1 (UCI Phishing Websites Dataset), dataset-2 (Phishing Dataset for Machine Learning: Feature Evaluation), dataset-3 (Phishing Websites Dataset), and dataset-4 (Web page phishing detection), respectively. The high accuracy values obtained across all datasets imply the models' generalizability and effectiveness in the accurate identification of phishing websites. ",
    "url": "https://arxiv.org/abs/2403.09735",
    "authors": [
      "Asif Newaz",
      "Farhan Shahriyar Haq",
      "Nadim Ahmed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09742",
    "title": "A Short Review on Novel Approaches for Maximum Clique Problem: from  Classical algorithms to Graph Neural Networks and Quantum algorithms",
    "abstract": "This manuscript provides a comprehensive review of the Maximum Clique Problem, a computational problem that involves finding subsets of vertices in a graph that are all pairwise adjacent to each other. The manuscript covers in a simple way classical algorithms for solving the problem and includes a review of recent developments in graph neural networks and quantum algorithms. The review concludes with benchmarks for testing classical as well as new learning, and quantum algorithms. ",
    "url": "https://arxiv.org/abs/2403.09742",
    "authors": [
      "Raffaele Marino",
      "Lorenzo Buffoni",
      "Bogdan Zavalnij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2403.09751",
    "title": "What Was Your Prompt? A Remote Keylogging Attack on AI Assistants",
    "abstract": "AI assistants are becoming an integral part of society, used for asking advice or help in personal and confidential issues. In this paper, we unveil a novel side-channel that can be used to read encrypted responses from AI Assistants over the web: the token-length side-channel. We found that many vendors, including OpenAI and Microsoft, have this side-channel. However, inferring the content of a response from a token-length sequence alone proves challenging. This is because tokens are akin to words, and responses can be several sentences long leading to millions of grammatically correct sentences. In this paper, we show how this can be overcome by (1) utilizing the power of a large language model (LLM) to translate these sequences, (2) providing the LLM with inter-sentence context to narrow the search space and (3) performing a known-plaintext attack by fine-tuning the model on the target model's writing style. Using these methods, we were able to accurately reconstruct 29\\% of an AI assistant's responses and successfully infer the topic from 55\\% of them. To demonstrate the threat, we performed the attack on OpenAI's ChatGPT-4 and Microsoft's Copilot on both browser and API traffic. ",
    "url": "https://arxiv.org/abs/2403.09751",
    "authors": [
      "Roy Weiss",
      "Daniel Ayzenshteyn",
      "Guy Amit",
      "Yisroel Mirsky"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.09752",
    "title": "Explainable Machine Learning-Based Security and Privacy Protection  Framework for Internet of Medical Things Systems",
    "abstract": "The Internet of Medical Things (IoMT) transcends traditional medical boundaries, enabling a transition from reactive treatment to proactive prevention. This innovative method revolutionizes healthcare by facilitating early disease detection and tailored care, particularly in chronic disease management, where IoMT automates treatments based on real-time health data collection. Nonetheless, its benefits are countered by significant security challenges that endanger the lives of its users due to the sensitivity and value of the processed data, thereby attracting malicious interests. Moreover, the utilization of wireless communication for data transmission exposes medical data to interception and tampering by cybercriminals. Additionally, anomalies may arise due to human errors, network interference, or hardware malfunctions. In this context, anomaly detection based on Machine Learning (ML) is an interesting solution, but it comes up against obstacles in terms of explicability and protection of privacy. To address these challenges, a new framework for Intrusion Detection Systems (IDS) is introduced, leveraging Artificial Neural Networks (ANN) for intrusion detection while utilizing Federated Learning (FL) for privacy preservation. Additionally, eXplainable Artificial Intelligence (XAI) methods are incorporated to enhance model explanation and interpretation. The efficacy of the proposed framework is evaluated and compared with centralized approaches using multiple datasets containing network and medical data, simulating various attack types impacting the confidentiality, integrity, and availability of medical and physiological data. The results obtained offer compelling evidence that the FL method performs comparably to the centralized method, demonstrating high performance. Additionally, it affords the dual advantage of safeguarding privacy and providing model explanation. ",
    "url": "https://arxiv.org/abs/2403.09752",
    "authors": [
      "Ayoub Si-ahmed",
      "Mohammed Ali Al-Garadi",
      "Narhimene Boustia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09766",
    "title": "An Image Is Worth 1000 Lies: Adversarial Transferability across Prompts  on Vision-Language Models",
    "abstract": "Different from traditional task-specific vision models, recent large VLMs can readily adapt to different vision tasks by simply using different textual instructions, i.e., prompts. However, a well-known concern about traditional task-specific vision models is that they can be misled by imperceptible adversarial perturbations. Furthermore, the concern is exacerbated by the phenomenon that the same adversarial perturbations can fool different task-specific models. Given that VLMs rely on prompts to adapt to different tasks, an intriguing question emerges: Can a single adversarial image mislead all predictions of VLMs when a thousand different prompts are given? This question essentially introduces a novel perspective on adversarial transferability: cross-prompt adversarial transferability. In this work, we propose the Cross-Prompt Attack (CroPA). This proposed method updates the visual adversarial perturbation with learnable prompts, which are designed to counteract the misleading effects of the adversarial image. By doing this, CroPA significantly improves the transferability of adversarial examples across prompts. Extensive experiments are conducted to verify the strong cross-prompt adversarial transferability of CroPA with prevalent VLMs including Flamingo, BLIP-2, and InstructBLIP in various different tasks. Our source code is available at \\url{https://github.com/Haochen-Luo/CroPA}. ",
    "url": "https://arxiv.org/abs/2403.09766",
    "authors": [
      "Haochen Luo",
      "Jindong Gu",
      "Fengyuan Liu",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09782",
    "title": "Redundancy Transmission in UAV-Aided LoRa Networks Featuring Wake-Up  Radios",
    "abstract": "We consider a LoRa sensor network featuring a UAV-mounted gateway for collecting sensor data (messages). Wake-up radios (WuR) are employed to inform the sensors of the UAV's arrival. Building on an existing random access scheme for such setups, we propose and evaluate two redundancy transmission protocols for enhancing the reliability of the data transfer. One protocol employs fountain-coded transmissions, whereas the other performs message replication. Our results illustrate how redundancy transmission can be beneficial under the time constraints imposed by the UAV's limited hovering duration, and how node density, hovering time, and sensor energy budget impact the performance of the schemes. ",
    "url": "https://arxiv.org/abs/2403.09782",
    "authors": [
      "Kushwanth Sistu",
      "Siddhartha S. Borkotoky"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2403.09793",
    "title": "Socially Integrated Navigation: A Social Acting Robot with Deep  Reinforcement Learning",
    "abstract": "Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, which states that social acting is oriented toward the acting of others. The DRL policy is trained in an environment where other agents interact socially integrated and reward the robot's behavior individually. The simulation results indicate that the proposed socially integrated navigation approach outperforms a socially aware approach in terms of distance traveled, time to completion, and negative impact on all agents within the environment. ",
    "url": "https://arxiv.org/abs/2403.09793",
    "authors": [
      "Daniel Fl\u00f6gel",
      "Lars Fischer",
      "Thomas Rudolf",
      "Tobias Sch\u00fcrmann",
      "S\u00f6ren Hohmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.09806",
    "title": "xLP: Explainable Link Prediction for Master Data Management",
    "abstract": "Explaining neural model predictions to users requires creativity. Especially in enterprise applications, where there are costs associated with users' time, and their trust in the model predictions is critical for adoption. For link prediction in master data management, we have built a number of explainability solutions drawing from research in interpretability, fact verification, path ranking, neuro-symbolic reasoning and self-explaining AI. In this demo, we present explanations for link prediction in a creative way, to allow users to choose explanations they are more comfortable with. ",
    "url": "https://arxiv.org/abs/2403.09806",
    "authors": [
      "Balaji Ganesan",
      "Matheen Ahmed Pasha",
      "Srinivasa Parkala",
      "Neeraj R Singh",
      "Gayatri Mishra",
      "Sumit Bhatia",
      "Hima Patel",
      "Somashekar Naganna",
      "Sameep Mehta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09809",
    "title": "Self-Supervised Learning for Time Series: Contrastive or Generative?",
    "abstract": "Self-supervised learning (SSL) has recently emerged as a powerful approach to learning representations from large-scale unlabeled data, showing promising results in time series analysis. The self-supervised representation learning can be categorized into two mainstream: contrastive and generative. In this paper, we will present a comprehensive comparative study between contrastive and generative methods in time series. We first introduce the basic frameworks for contrastive and generative SSL, respectively, and discuss how to obtain the supervision signal that guides the model optimization. We then implement classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative analysis in fair settings. Our results provide insights into the strengths and weaknesses of each approach and offer practical recommendations for choosing suitable SSL methods. We also discuss the implications of our findings for the broader field of representation learning and propose future research directions. All the code and data are released at \\url{https://github.com/DL4mHealth/SSL_Comparison}. ",
    "url": "https://arxiv.org/abs/2403.09809",
    "authors": [
      "Ziyu Liu",
      "Azadeh Alavi",
      "Minyi Li",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2403.09817",
    "title": "Impact of Objective Function on Spectral Efficiency in Integrated  HAPS-Terrestrial Networks",
    "abstract": "Integrating non-terrestrial networks (NTNs), in particular high altitude platform stations (HAPS), with terrestrial networks, referred to as vHetNets, emerges as a promising future wireless network architecture for providing ubiquitous connectivity. In this context, optimizing the performance of vHetNets has become a paramount concern, particularly in harmonized spectrum vHetNets, where HAPS and terrestrial networks share the same frequency band, resulting in severe inter-/intra-tier interference. This paper provides a comparative analysis of different objective functions, specifically focusing on weighted sum rate (WSR), network-wide proportional fairness (NW-PF), and network-wide max-min fairness (NW-MMF), with an aim to design a joint user association scheme and multiple-input multiple-output (MIMO) beamforming weights in a vHetNet, operating in an urban area. The simulation results comprehensively compare the behavior of different objective functions in vHetNets and standalone terrestrial networks. This analysis aims to shed light on the impact of diverse objective functions on the achievable spectral efficiency (SE) of vHetNets. ",
    "url": "https://arxiv.org/abs/2403.09817",
    "authors": [
      "Afsoon Alidadi Shamsabadi",
      "Animesh Yadav",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.09830",
    "title": "Towards the Reusability and Compositionality of Causal Representations",
    "abstract": "Causal Representation Learning (CRL) aims at identifying high-level causal factors and their relationships from high-dimensional observations, e.g., images. While most CRL works focus on learning causal representations in a single environment, in this work we instead propose a first step towards learning causal representations from temporal sequences of images that can be adapted in a new environment, or composed across multiple related environments. In particular, we introduce DECAF, a framework that detects which causal factors can be reused and which need to be adapted from previously learned causal representations. Our approach is based on the availability of intervention targets, that indicate which variables are perturbed at each time step. Experiments on three benchmark datasets show that integrating our framework with four state-of-the-art CRL approaches leads to accurate representations in a new environment with only a few samples. ",
    "url": "https://arxiv.org/abs/2403.09830",
    "authors": [
      "Davide Talon",
      "Phillip Lippe",
      "Stuart James",
      "Alessio Del Bue",
      "Sara Magliacane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.09832",
    "title": "Scaling Behavior of Machine Translation with Large Language Models under  Prompt Injection Attacks",
    "abstract": "Large Language Models (LLMs) are increasingly becoming the preferred foundation platforms for many Natural Language Processing tasks such as Machine Translation, owing to their quality often comparable to or better than task-specific models, and the simplicity of specifying the task through natural language instructions or in-context examples. Their generality, however, opens them up to subversion by end users who may embed into their requests instructions that cause the model to behave in unauthorized and possibly unsafe ways. In this work we study these Prompt Injection Attacks (PIAs) on multiple families of LLMs on a Machine Translation task, focusing on the effects of model size on the attack success rates. We introduce a new benchmark data set and we discover that on multiple language pairs and injected prompts written in English, larger models under certain conditions may become more susceptible to successful attacks, an instance of the Inverse Scaling phenomenon (McKenzie et al., 2023). To our knowledge, this is the first work to study non-trivial LLM scaling behaviour in a multi-lingual setting. ",
    "url": "https://arxiv.org/abs/2403.09832",
    "authors": [
      "Zhifan Sun",
      "Antonio Valerio Miceli-Barone"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.09863",
    "title": "A Conceptual Framework For White Box Neural Networks",
    "abstract": "This paper introduces semantic features as a general conceptual framework for fully explainable neural network layers. A well-motivated proof of concept model for relevant subproblem of MNIST consists of 4 such layers with the total of 4.8K learnable parameters. The model is easily interpretable, achieves human-level adversarial test accuracy with no form of adversarial training, requires little hyperparameter tuning and can be quickly trained on a single CPU. The general nature of the technique bears promise for a paradigm shift towards radically democratised and truly generalizable white box neural networks. The code is available at https://github.com/314-Foundation/white-box-nn ",
    "url": "https://arxiv.org/abs/2403.09863",
    "authors": [
      "Maciej Satkiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.09883",
    "title": "Influence of Personality and Communication Behavior of a Conversational  Agent on User Experience and Social Presence in Augmented Reality",
    "abstract": "A virtual embodiment can benefit conversational agents, but it is unclear how their personalities and non-verbal behavior influence the User Experience and Social Presence in Augmented Reality (AR). We asked 30 users to converse with a virtual assistant who gives recommendations about city activities. The participants interacted with two different personalities: Sammy, a cheerful blue mouse, and Olive, a serious green human-like agent. Each was presented with two body languages - happy/friendly and annoyed/unfriendly. We conclude how agent representation and humor affect User Experience aspects, and that body language is significant in the evaluation and perception of the AR agent. ",
    "url": "https://arxiv.org/abs/2403.09883",
    "authors": [
      "Katerina Koleva",
      "Maurizio Vergari",
      "Tanja Koji\u0107",
      "Sebastian M\u00f6ller",
      "Jan-Niklas Voigt-Antons"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.09901",
    "title": "Robust Subgraph Learning by Monitoring Early Training Representations",
    "abstract": "Graph neural networks (GNNs) have attracted significant attention for their outstanding performance in graph learning and node classification tasks. However, their vulnerability to adversarial attacks, particularly through susceptible nodes, poses a challenge in decision-making. The need for robust graph summarization is evident in adversarial challenges resulting from the propagation of attacks throughout the entire graph. In this paper, we address both performance and adversarial robustness in graph input by introducing the novel technique SHERD (Subgraph Learning Hale through Early Training Representation Distances). SHERD leverages information from layers of a partially trained graph convolutional network (GCN) to detect susceptible nodes during adversarial attacks using standard distance metrics. The method identifies \"vulnerable (bad)\" nodes and removes such nodes to form a robust subgraph while maintaining node classification performance. Through our experiments, we demonstrate the increased performance of SHERD in enhancing robustness by comparing the network's performance on original and subgraph inputs against various baselines alongside existing adversarial attacks. Our experiments across multiple datasets, including citation datasets such as Cora, Citeseer, and Pubmed, as well as microanatomical tissue structures of cell graphs in the placenta, highlight that SHERD not only achieves substantial improvement in robust performance but also outperforms several baselines in terms of node classification accuracy and computational complexity. ",
    "url": "https://arxiv.org/abs/2403.09901",
    "authors": [
      "Sepideh Neshatfar",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.09914",
    "title": "ProMark: Proactive Diffusion Watermarking for Causal Attribution",
    "abstract": "Generative AI (GenAI) is transforming creative workflows through the capability to synthesize and manipulate images via high-level prompts. Yet creatives are not well supported to receive recognition or reward for the use of their content in GenAI training. To this end, we propose ProMark, a causal attribution technique to attribute a synthetically generated image to its training data concepts like objects, motifs, templates, artists, or styles. The concept information is proactively embedded into the input training images using imperceptible watermarks, and the diffusion models (unconditional or conditional) are trained to retain the corresponding watermarks in generated images. We show that we can embed as many as $2^{16}$ unique watermarks into the training data, and each training image can contain more than one watermark. ProMark can maintain image quality whilst outperforming correlation-based attribution. Finally, several qualitative examples are presented, providing the confidence that the presence of the watermark conveys a causative relationship between training data and synthetic images. ",
    "url": "https://arxiv.org/abs/2403.09914",
    "authors": [
      "Vishal Asnani",
      "John Collomosse",
      "Tu Bui",
      "Xiaoming Liu",
      "Shruti Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09915",
    "title": "Robust Light-Weight Facial Affective Behavior Recognition with CLIP",
    "abstract": "Human affective behavior analysis aims to delve into human expressions and behaviors to deepen our understanding of human emotions. Basic expression categories (EXPR) and Action Units (AUs) are two essential components in this analysis, which categorize emotions and break down facial movements into elemental units, respectively. Despite advancements, existing approaches in expression classification and AU detection often necessitate complex models and substantial computational resources, limiting their applicability in everyday settings. In this work, we introduce the first lightweight framework adept at efficiently tackling both expression classification and AU detection. This framework employs a frozen CLIP image encoder alongside a trainable multilayer perceptron (MLP), enhanced with Conditional Value at Risk (CVaR) for robustness and a loss landscape flattening strategy for improved generalization. Experimental results on the Aff-wild2 dataset demonstrate superior performance in comparison to the baseline while maintaining minimal computational demands, offering a practical solution for affective behavior analysis. The code is available at https://github.com/Purdue-M2/Affective_Behavior_Analysis_M2_PURDUE ",
    "url": "https://arxiv.org/abs/2403.09915",
    "authors": [
      "Li Lin",
      "Sarah Papabathini",
      "Xin Wang",
      "Shu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09918",
    "title": "Attention-based Class-Conditioned Alignment for Multi-Source Domain  Adaptive Object Detection",
    "abstract": "Domain adaptation methods for object detection (OD) strive to mitigate the impact of distribution shifts by promoting feature alignment across source and target domains. Multi-source domain adaptation (MSDA) allows leveraging multiple annotated source datasets, and unlabeled target data to improve the accuracy and robustness of the detection model. Most state-of-the-art MSDA methods for OD perform feature alignment in a class-agnostic manner. This is challenging since the objects have unique modal information due to variations in object appearance across domains. A recent prototype-based approach proposed a class-wise alignment, yet it suffers from error accumulation due to noisy pseudo-labels which can negatively affect adaptation with imbalanced data. To overcome these limitations, we propose an attention-based class-conditioned alignment scheme for MSDA that aligns instances of each object category across domains. In particular, an attention module coupled with an adversarial domain classifier allows learning domain-invariant and class-specific instance representations. Experimental results on multiple benchmarking MSDA datasets indicate that our method outperforms the state-of-the-art methods and is robust to class imbalance. Our code is available at https://github.com/imatif17/ACIA. ",
    "url": "https://arxiv.org/abs/2403.09918",
    "authors": [
      "Atif Belal",
      "Akhil Meethal",
      "Francisco Perdigon Romero",
      "Marco Pedersoli",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09939",
    "title": "Quantization Effects on Neural Networks Perception: How would  quantization change the perceptual field of vision models?",
    "abstract": "Neural network quantization is an essential technique for deploying models on resource-constrained devices. However, its impact on model perceptual fields, particularly regarding class activation maps (CAMs), remains a significant area of investigation. In this study, we explore how quantization alters the spatial recognition ability of the perceptual field of vision models, shedding light on the alignment between CAMs and visual saliency maps across various architectures. Leveraging a dataset of 10,000 images from ImageNet, we rigorously evaluate six diverse foundational CNNs: VGG16, ResNet50, EfficientNet, MobileNet, SqueezeNet, and DenseNet. We uncover nuanced changes in CAMs and their alignment with human visual saliency maps through systematic quantization techniques applied to these models. Our findings reveal the varying sensitivities of different architectures to quantization and underscore its implications for real-world applications in terms of model performance and interpretability. The primary contribution of this work revolves around deepening our understanding of neural network quantization, providing insights crucial for deploying efficient and interpretable models in practical settings. ",
    "url": "https://arxiv.org/abs/2403.09939",
    "authors": [
      "Mohamed Amine Kerkouri",
      "Marouane Tliba",
      "Aladine Chetouani",
      "Alessandro Bruno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09953",
    "title": "Online GNN Evaluation Under Test-time Graph Distribution Shifts",
    "abstract": "Evaluating the performance of a well-trained GNN model on real-world graphs is a pivotal step for reliable GNN online deployment and serving. Due to a lack of test node labels and unknown potential training-test graph data distribution shifts, conventional model evaluation encounters limitations in calculating performance metrics (e.g., test error) and measuring graph data-level discrepancies, particularly when the training graph used for developing GNNs remains unobserved during test time. In this paper, we study a new research problem, online GNN evaluation, which aims to provide valuable insights into the well-trained GNNs's ability to effectively generalize to real-world unlabeled graphs under the test-time graph distribution shifts. Concretely, we develop an effective learning behavior discrepancy score, dubbed LeBeD, to estimate the test-time generalization errors of well-trained GNN models. Through a novel GNN re-training strategy with a parameter-free optimality criterion, the proposed LeBeD comprehensively integrates learning behavior discrepancies from both node prediction and structure reconstruction perspectives. This enables the effective evaluation of the well-trained GNNs' ability to capture test node semantics and structural representations, making it an expressive metric for estimating the generalization error in online GNN evaluation. Extensive experiments on real-world test graphs under diverse graph distribution shifts could verify the effectiveness of the proposed method, revealing its strong correlation with ground-truth test errors on various well-trained GNN models. ",
    "url": "https://arxiv.org/abs/2403.09953",
    "authors": [
      "Xin Zheng",
      "Dongjin Song",
      "Qingsong Wen",
      "Bo Du",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09954",
    "title": "Search-based Ordered Password Generation of Autoregressive Neural  Networks",
    "abstract": "Passwords are the most widely used method of authentication and password guessing is the essential part of password cracking and password security research. The progress of deep learning technology provides a promising way to improve the efficiency of password guessing. However, current research on neural network password guessing methods mostly focuses on model structure and has overlooked the generation method. Due to the randomness of sampling, not only the generated passwords have a large number of duplicates, but also the order in which passwords generated is random, leading to inefficient password attacks. In this paper, we propose SOPG, a search-based ordered password generation method, which enables the password guessing model based on autoregressive neural network to generate passwords in approximately descending order of probability. Experiment on comparison of SOPG and Random sampling shows passwords generated by SOPG do not repeat, and when they reach the same cover rate, SOPG requires fewer inferences and far fewer generated passwords than Random sampling, which brings great efficiency improvement to subsequent password attacks. We build SOPGesGPT, a password guessing model based on GPT, using SOPG to generate passwords. Compared with the most influential models OMEN, FLA, PassGAN, VAEPass and the latest model PassGPT in one-site test, experiments show that SOPGesGPT is far ahead in terms of both effective rate and cover rate. As to cover rate that everyone recognizes, SOPGesGPT reaches 35.06%, which is 254%, 298%, 421%, 380%, 81% higher than OMEN, FLA, PassGAN, VAEPass, and PassGPT respectively. ",
    "url": "https://arxiv.org/abs/2403.09954",
    "authors": [
      "Min Jin",
      "Junbin Ye",
      "Rongxuan Shen",
      "Huaxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.09962",
    "title": "ViTCN: Vision Transformer Contrastive Network For Reasoning",
    "abstract": "Machine learning models have achieved significant milestones in various domains, for example, computer vision models have an exceptional result in object recognition, and in natural language processing, where Large Language Models (LLM) like GPT can start a conversation with human-like proficiency. However, abstract reasoning remains a challenge for these models, Can AI really thinking like a human? still be a question yet to be answered. Raven Progressive Matrices (RPM) is a metric designed to assess human reasoning capabilities. It presents a series of eight images as a problem set, where the participant should try to discover the underlying rules among these images and select the most appropriate image from eight possible options that best completes the sequence. This task always be used to test human reasoning abilities and IQ. Zhang et al proposed a dataset called RAVEN which can be used to test Machine Learning model abstract reasoning ability. In this paper, we purposed Vision Transformer Contrastive Network which build on previous work with the Contrastive Perceptual Inference network (CoPiNet), which set a new benchmark for permutationinvariant models Raven Progressive Matrices by incorporating contrast effects from psychology, cognition, and education, and extends this foundation by leveraging the cutting-edge Vision Transformer architecture. This integration aims to further refine the machine ability to process and reason about spatial-temporal information from pixel-level inputs and global wise features on RAVEN dataset. ",
    "url": "https://arxiv.org/abs/2403.09962",
    "authors": [
      "Bo Song",
      "Yuanhao Xu",
      "Yichao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09969",
    "title": "Prediction of Vessel Arrival Time to Pilotage Area Using Multi-Data  Fusion and Deep Learning",
    "abstract": "This paper investigates the prediction of vessels' arrival time to the pilotage area using multi-data fusion and deep learning approaches. Firstly, the vessel arrival contour is extracted based on Multivariate Kernel Density Estimation (MKDE) and clustering. Secondly, multiple data sources, including Automatic Identification System (AIS), pilotage booking information, and meteorological data, are fused before latent feature extraction. Thirdly, a Temporal Convolutional Network (TCN) framework that incorporates a residual mechanism is constructed to learn the hidden arrival patterns of the vessels. Extensive tests on two real-world data sets from Singapore have been conducted and the following promising results have been obtained: 1) fusion of pilotage booking information and meteorological data improves the prediction accuracy, with pilotage booking information having a more significant impact; 2) using discrete embedding for the meteorological data performs better than using continuous embedding; 3) the TCN outperforms the state-of-the-art baseline methods in regression tasks, exhibiting Mean Absolute Error (MAE) ranging from 4.58 min to 4.86 min; and 4) approximately 89.41% to 90.61% of the absolute prediction residuals fall within a time frame of 10 min. ",
    "url": "https://arxiv.org/abs/2403.09969",
    "authors": [
      "Xiaocai Zhang",
      "Xiuju Fu",
      "Zhe Xiao",
      "Haiyan Xu",
      "Xiaoyang Wei",
      "Jimmy Koh",
      "Daichi Ogawa",
      "Zheng Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09996",
    "title": "MEDPNet: Achieving High-Precision Adaptive Registration for Complex Die  Castings",
    "abstract": "Due to their complex spatial structure and diverse geometric features, achieving high-precision and robust point cloud registration for complex Die Castings has been a significant challenge in the die-casting industry. Existing point cloud registration methods primarily optimize network models using well-established high-quality datasets, often neglecting practical application in real scenarios. To address this gap, this paper proposes a high-precision adaptive registration method called Multiscale Efficient Deep Closest Point (MEDPNet) and introduces a die-casting point cloud dataset, DieCastCloud, specifically designed to tackle the challenges of point cloud registration in the die-casting industry. The MEDPNet method performs coarse die-casting point cloud data registration using the Efficient-DCP method, followed by precision registration using the Multiscale feature fusion dual-channel registration (MDR) method. We enhance the modeling capability and computational efficiency of the model by replacing the attention mechanism of the Transformer in DCP with Efficient Attention and implementing a collaborative scale mechanism through the combination of serial and parallel blocks. Additionally, we propose the MDR method, which utilizes multilayer perceptrons (MLP), Normal Distributions Transform (NDT), and Iterative Closest Point (ICP) to achieve learnable adaptive fusion, enabling high-precision, scalable, and noise-resistant global point cloud registration. Our proposed method demonstrates excellent performance compared to state-of-the-art geometric and learning-based registration methods when applied to complex die-casting point cloud data. ",
    "url": "https://arxiv.org/abs/2403.09996",
    "authors": [
      "Yu Du",
      "Yu Song",
      "Ce Guo",
      "Xiaojing Tian",
      "Dong Liu",
      "Ming Cong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10000",
    "title": "Federated Learning with Anomaly Detection via Gradient and  Reconstruction Analysis",
    "abstract": "In the evolving landscape of Federated Learning (FL), the challenge of ensuring data integrity against poisoning attacks is paramount, particularly for applications demanding stringent privacy preservation. Traditional anomaly detection strategies often struggle to adapt to the distributed nature of FL, leaving a gap our research aims to bridge. We introduce a novel framework that synergizes gradient-based analysis with autoencoder-driven data reconstruction to detect and mitigate poisoned data with unprecedented precision. Our approach uniquely combines detecting anomalous gradient patterns with identifying reconstruction errors, significantly enhancing FL model security. Validated through extensive experiments on MNIST and CIFAR-10 datasets, our method outperforms existing solutions by 15\\% in anomaly detection accuracy while maintaining a minimal false positive rate. This robust performance, consistent across varied data types and network sizes, underscores our framework's potential in securing FL deployments in critical domains such as healthcare and finance. By setting new benchmarks for anomaly detection within FL, our work paves the way for future advancements in distributed learning security. ",
    "url": "https://arxiv.org/abs/2403.10000",
    "authors": [
      "Zahir Alsulaimawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10005",
    "title": "Securing Federated Learning with Control-Flow Attestation: A Novel  Framework for Enhanced Integrity and Resilience against Adversarial Attacks",
    "abstract": "The advent of Federated Learning (FL) as a distributed machine learning paradigm has introduced new cybersecurity challenges, notably adversarial attacks that threaten model integrity and participant privacy. This study proposes an innovative security framework inspired by Control-Flow Attestation (CFA) mechanisms, traditionally used in cybersecurity, to ensure software execution integrity. By integrating digital signatures and cryptographic hashing within the FL framework, we authenticate and verify the integrity of model updates across the network, effectively mitigating risks associated with model poisoning and adversarial interference. Our approach, novel in its application of CFA principles to FL, ensures contributions from participating nodes are authentic and untampered, thereby enhancing system resilience without compromising computational efficiency or model performance. Empirical evaluations on benchmark datasets, MNIST and CIFAR-10, demonstrate our framework's effectiveness, achieving a 100\\% success rate in integrity verification and authentication and notable resilience against adversarial attacks. These results validate the proposed security enhancements and open avenues for more secure, reliable, and privacy-conscious distributed machine learning solutions. Our work bridges a critical gap between cybersecurity and distributed machine learning, offering a foundation for future advancements in secure FL. ",
    "url": "https://arxiv.org/abs/2403.10005",
    "authors": [
      "Zahir Alsulaimawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10006",
    "title": "Graph Enhanced Reinforcement Learning for Effective Group Formation in  Collaborative Problem Solving",
    "abstract": "This study addresses the challenge of forming effective groups in collaborative problem-solving environments. Recognizing the complexity of human interactions and the necessity for efficient collaboration, we propose a novel approach leveraging graph theory and reinforcement learning. Our methodology involves constructing a graph from a dataset where nodes represent participants, and edges signify the interactions between them. We conceptualize each participant as an agent within a reinforcement learning framework, aiming to learn an optimal graph structure that reflects effective group dynamics. Clustering techniques are employed to delineate clear group structures based on the learned graph. Our approach provides theoretical solutions based on evaluation metrics and graph measurements, offering insights into potential improvements in group effectiveness and reductions in conflict incidences. This research contributes to the fields of collaborative work and educational psychology by presenting a data-driven, analytical approach to group formation. It has practical implications for organizational team building, classroom settings, and any collaborative scenario where group dynamics are crucial. The study opens new avenues for exploring the application of graph theory and reinforcement learning in social and behavioral sciences, highlighting the potential for empirical validation in future work. ",
    "url": "https://arxiv.org/abs/2403.10006",
    "authors": [
      "Zheng Fang",
      "Fucai Ke",
      "Jae Young Han",
      "Zhijie Feng",
      "Toby Cai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10007",
    "title": "Compositionally Verifiable Vector Neural Lyapunov Functions for  Stability Analysis of Interconnected Nonlinear Systems",
    "abstract": "While there has been increasing interest in using neural networks to compute Lyapunov functions, verifying that these functions satisfy the Lyapunov conditions and certifying stability regions remain challenging due to the curse of dimensionality. In this paper, we demonstrate that by leveraging the compositional structure of interconnected nonlinear systems, it is possible to verify neural Lyapunov functions for high-dimensional systems beyond the capabilities of current satisfiability modulo theories (SMT) solvers using a monolithic approach. Our numerical examples employ neural Lyapunov functions trained by solving Zubov's partial differential equation (PDE), which characterizes the domain of attraction for individual subsystems. These examples show a performance advantage over sums-of-squares (SOS) polynomial Lyapunov functions derived from semidefinite programming. ",
    "url": "https://arxiv.org/abs/2403.10007",
    "authors": [
      "Jun Liu",
      "Yiming Meng",
      "Maxwell Fitzsimmons",
      "Ruikun Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.10012",
    "title": "Real-World Computational Aberration Correction via Quantized  Domain-Mixing Representation",
    "abstract": "Relying on paired synthetic data, existing learning-based Computational Aberration Correction (CAC) methods are confronted with the intricate and multifaceted synthetic-to-real domain gap, which leads to suboptimal performance in real-world applications. In this paper, in contrast to improving the simulation pipeline, we deliver a novel insight into real-world CAC from the perspective of Unsupervised Domain Adaptation (UDA). By incorporating readily accessible unpaired real-world data into training, we formalize the Domain Adaptive CAC (DACAC) task, and then introduce a comprehensive Real-world aberrated images (Realab) dataset to benchmark it. The setup task presents a formidable challenge due to the intricacy of understanding the target aberration domain. To this intent, we propose a novel Quntized Domain-Mixing Representation (QDMR) framework as a potent solution to the issue. QDMR adapts the CAC model to the target domain from three key aspects: (1) reconstructing aberrated images of both domains by a VQGAN to learn a Domain-Mixing Codebook (DMC) which characterizes the degradation-aware priors; (2) modulating the deep features in CAC model with DMC to transfer the target domain knowledge; and (3) leveraging the trained VQGAN to generate pseudo target aberrated images from the source ones for convincing target domain supervision. Extensive experiments on both synthetic and real-world benchmarks reveal that the models with QDMR consistently surpass the competitive methods in mitigating the synthetic-to-real gap, which produces visually pleasant real-world CAC results with fewer artifacts. Codes and datasets will be made publicly available. ",
    "url": "https://arxiv.org/abs/2403.10012",
    "authors": [
      "Qi Jiang",
      "Zhonghua Yi",
      "Shaohua Gao",
      "Yao Gao",
      "Xiaolong Qian",
      "Hao Shi",
      "Lei Sun",
      "Zhijie Xu",
      "Kailun Yang",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2403.10013",
    "title": "LyZNet: A Lightweight Python Tool for Learning and Verifying Neural  Lyapunov Functions and Regions of Attraction",
    "abstract": "In this paper, we describe a lightweight Python framework that provides integrated learning and verification of neural Lyapunov functions for stability analysis. The proposed tool, named LyZNet, learns neural Lyapunov functions using physics-informed neural networks (PINNs) to solve Zubov's equation and verifies them using satisfiability modulo theories (SMT) solvers. What distinguishes this tool from others in the literature is its ability to provide verified regions of attraction close to the domain of attraction. This is achieved by encoding Zubov's partial differential equation (PDE) into the PINN approach. By embracing the non-convex nature of the underlying optimization problems, we demonstrate that in cases where convex optimization, such as semidefinite programming, fails to capture the domain of attraction, our neural network framework proves more successful. The tool also offers automatic decomposition of coupled nonlinear systems into a network of low-dimensional subsystems for compositional verification. We illustrate the tool's usage and effectiveness with several numerical examples, including both non-trivial low-dimensional nonlinear systems and high-dimensional systems. The repository of the tool can be found at https://git.uwaterloo.ca/hybrid-systems-lab/lyznet. ",
    "url": "https://arxiv.org/abs/2403.10013",
    "authors": [
      "Jun Liu",
      "Yiming Meng",
      "Maxwell Fitzsimmons",
      "Ruikun Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.10014",
    "title": "NNCTC: Physical Layer Cross-Technology Communication via Neural Networks",
    "abstract": "Cross-technology communication(CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. In this work, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework inspired by the adaptability of trainable neural models in wireless communications. By converting signal processing components within the CTC pipeline into neural models, the NNCTC is designed for end-to-end training without requiring labeled data. This enables the NNCTC system to autonomously derive the optimal CTC payload, which significantly eases the development complexity and showcases the scalability potential for various CTC links. Particularly, we construct a CTC system from Wi-Fi to ZigBee. The NNCTC system outperforms the well-recognized WEBee and WIDE design in error performance, achieving an average packet reception rate(PRR) of 92.3% and an average symbol error rate(SER) as low as 1.3%. ",
    "url": "https://arxiv.org/abs/2403.10014",
    "authors": [
      "Haoyu Wang",
      "Jiazhao Wang",
      "Demin Gao",
      "Wenchao Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10021",
    "title": "Time-Frequency Jointed Imperceptible Adversarial Attack to Brainprint  Recognition with Deep Learning Models",
    "abstract": "EEG-based brainprint recognition with deep learning models has garnered much attention in biometric identification. Yet, studies have indicated vulnerability to adversarial attacks in deep learning models with EEG inputs. In this paper, we introduce a novel adversarial attack method that jointly attacks time-domain and frequency-domain EEG signals by employing wavelet transform. Different from most existing methods which only target time-domain EEG signals, our method not only takes advantage of the time-domain attack's potent adversarial strength but also benefits from the imperceptibility inherent in frequency-domain attack, achieving a better balance between attack performance and imperceptibility. Extensive experiments are conducted in both white- and grey-box scenarios and the results demonstrate that our attack method achieves state-of-the-art attack performance on three datasets and three deep-learning models. In the meanwhile, the perturbations in the signals attacked by our method are barely perceptible to the human visual system. ",
    "url": "https://arxiv.org/abs/2403.10021",
    "authors": [
      "Hangjie Yi",
      "Yuhang Ming",
      "Dongjun Liu",
      "Wanzeng Kong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10041",
    "title": "Towards Embedding Dynamic Personas in Interactive Robots: Masquerading  Animated Social Kinematics (MASK)",
    "abstract": "This paper presents the design and development of an innovative interactive robotic system to enhance audience engagement using character-like personas. Built upon the foundations of persona-driven dialog agents, this work extends the agent application to the physical realm, employing robots to provide a more immersive and interactive experience. The proposed system, named the Masquerading Animated Social Kinematics (MASK), leverages an anthropomorphic robot which interacts with guests using non-verbal interactions, including facial expressions and gestures. A behavior generation system based upon a finite-state machine structure effectively conditions robotic behavior to convey distinct personas. The MASK framework integrates a perception engine, a behavior selection engine, and a comprehensive action library to enable real-time, dynamic interactions with minimal human intervention in behavior design. Throughout the user subject studies, we examined whether the users could recognize the intended character in film-character-based persona conditions. We conclude by discussing the role of personas in interactive agents and the factors to consider for creating an engaging user experience. ",
    "url": "https://arxiv.org/abs/2403.10041",
    "authors": [
      "Jeongeun Park",
      "Taemoon Jeong",
      "Hyeonseong Kim",
      "Taehyun Byun",
      "Seungyoon Shin",
      "Keunjun Choi",
      "Jaewoon Kwon",
      "Taeyoon Lee",
      "Matthew Pan",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10045",
    "title": "Towards Adversarially Robust Dataset Distillation by Curvature  Regularization",
    "abstract": "Dataset distillation (DD) allows datasets to be distilled to fractions of their original size while preserving the rich distributional information so that models trained on the distilled datasets can achieve a comparable accuracy while saving significant computational loads. Recent research in this area has been focusing on improving the accuracy of models trained on distilled datasets. In this paper, we aim to explore a new perspective of DD. We study how to embed adversarial robustness in distilled datasets, so that models trained on these datasets maintain the high accuracy and meanwhile acquire better adversarial robustness. We propose a new method that achieves this goal by incorporating curvature regularization into the distillation process with much less computational overhead than standard adversarial training. Extensive empirical experiments suggest that our method not only outperforms standard adversarial training on both accuracy and robustness with less computation overhead but is also capable of generating robust distilled datasets that can withstand various adversarial attacks. ",
    "url": "https://arxiv.org/abs/2403.10045",
    "authors": [
      "Eric Xue",
      "Yijiang Li",
      "Haoyang Liu",
      "Yifan Shen",
      "Haohan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10049",
    "title": "PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction",
    "abstract": "Click-through rate (CTR) prediction is a core task in recommender systems. Existing methods (IDRec for short) rely on unique identities to represent distinct users and items that have prevailed for decades. On one hand, IDRec often faces significant performance degradation on cold-start problem; on the other hand, IDRec cannot use longer training data due to constraints imposed by iteration efficiency. Most prior studies alleviate the above problems by introducing pre-trained knowledge(e.g. pre-trained user model or multi-modal embeddings). However, the explosive growth of online latency can be attributed to the huge parameters in the pre-trained model. Therefore, most of them cannot employ the unified model of end-to-end training with IDRec in industrial recommender systems, thus limiting the potential of the pre-trained model. To this end, we propose a $\\textbf{P}$re-trained $\\textbf{P}$lug-in CTR $\\textbf{M}$odel, namely PPM. PPM employs multi-modal features as input and utilizes large-scale data for pre-training. Then, PPM is plugged in IDRec model to enhance unified model's performance and iteration efficiency. Upon incorporating IDRec model, certain intermediate results within the network are cached, with only a subset of the parameters participating in training and serving. Hence, our approach can successfully deploy an end-to-end model without causing huge latency increases. Comprehensive offline experiments and online A/B testing at JD E-commerce demonstrate the efficiency and effectiveness of PPM. ",
    "url": "https://arxiv.org/abs/2403.10049",
    "authors": [
      "Yuanbo Gao",
      "Peng Lin",
      "Dongyue Wang",
      "Feng Mei",
      "Xiwei Zhao",
      "Sulong Xu",
      "Jinghe Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10051",
    "title": "Accelerating Regular Path Queries over Graph Database with  Processing-in-Memory",
    "abstract": "Regular path queries (RPQs) in graph databases are bottlenecked by the memory wall. Emerging processing-in-memory (PIM) technologies offer a promising solution to dispatch and execute path matching tasks in parallel within PIM modules. We present Moctopus, a PIM-based data management system for graph databases that supports efficient batch RPQs and graph updates. Moctopus employs a PIM-friendly dynamic graph partitioning algorithm, which tackles graph skewness and preserves graph locality with low overhead for RPQ processing. Moctopus enables efficient graph update by amortizing the host CPU's update overhead to PIM modules. Evaluation of Moctopus demonstrates superiority over the state-of-the-art traditional graph database. ",
    "url": "https://arxiv.org/abs/2403.10051",
    "authors": [
      "Ruoyan Ma",
      "Shengan Zheng",
      "Guifeng Wang",
      "Jin Pu",
      "Yifan Hua",
      "Wentao Wang",
      "Linpeng Huang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.10052",
    "title": "T4P: Test-Time Training of Trajectory Prediction via Masked Autoencoder  and Actor-specific Token Memory",
    "abstract": "Trajectory prediction is a challenging problem that requires considering interactions among multiple actors and the surrounding environment. While data-driven approaches have been used to address this complex problem, they suffer from unreliable predictions under distribution shifts during test time. Accordingly, several online learning methods have been proposed using regression loss from the ground truth of observed data leveraging the auto-labeling nature of trajectory prediction task. We mainly tackle the following two issues. First, previous works underfit and overfit as they only optimize the last layer of the motion decoder. To this end, we employ the masked autoencoder (MAE) for representation learning to encourage complex interaction modeling in shifted test distribution for updating deeper layers. Second, utilizing the sequential nature of driving data, we propose an actor-specific token memory that enables the test-time learning of actor-wise motion characteristics. Our proposed method has been validated across various challenging cross-dataset distribution shift scenarios including nuScenes, Lyft, Waymo, and Interaction. Our method surpasses the performance of existing state-of-the-art online learning methods in terms of both prediction accuracy and computational efficiency. The code is available at https://github.com/daeheepark/T4P. ",
    "url": "https://arxiv.org/abs/2403.10052",
    "authors": [
      "Daehee Park",
      "Jaeseok Jeong",
      "Sung-Hoon Yoon",
      "Jaewoo Jeong",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10059",
    "title": "Repoformer: Selective Retrieval for Repository-Level Code Completion",
    "abstract": "Recent advances in retrieval-augmented generation (RAG) have initiated a new era in repository-level code completion. However, the invariable use of retrieval in existing methods exposes issues in both efficiency and robustness, with a large proportion of the retrieved contexts proving unhelpful or harmful to code language models (code LMs). To tackle the challenges, this paper proposes a selective RAG framework where retrieval is avoided when unnecessary. To power this framework, we design a self-supervised learning approach that enables a code LM to accurately self-evaluate whether retrieval can improve its output quality and robustly leverage the potentially noisy retrieved contexts. Using this LM as both the selective retrieval policy and the generation model, our framework consistently outperforms the state-of-the-art prompting with an invariable retrieval approach on diverse benchmarks including RepoEval, CrossCodeEval, and a new benchmark. Meanwhile, our selective retrieval strategy results in strong efficiency improvements by as much as 70% inference speedup without harming the performance. We demonstrate that our framework effectively accommodates different generation models, retrievers, and programming languages. These advancements position our framework as an important step towards more accurate and efficient repository-level code completion. ",
    "url": "https://arxiv.org/abs/2403.10059",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Dejiao Zhang",
      "Murali Krishna Ramanathan",
      "Xiaofei Ma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10061",
    "title": "PAME: Self-Supervised Masked Autoencoder for No-Reference Point Cloud  Quality Assessment",
    "abstract": "No-reference point cloud quality assessment (NR-PCQA) aims to automatically predict the perceptual quality of point clouds without reference, which has achieved remarkable performance due to the utilization of deep learning-based models. However, these data-driven models suffer from the scarcity of labeled data and perform unsatisfactorily in cross-dataset evaluations. To address this problem, we propose a self-supervised pre-training framework using masked autoencoders (PAME) to help the model learn useful representations without labels. Specifically, after projecting point clouds into images, our PAME employs dual-branch autoencoders, reconstructing masked patches from distorted images into the original patches within reference and distorted images. In this manner, the two branches can separately learn content-aware features and distortion-aware features from the projected images. Furthermore, in the model fine-tuning stage, the learned content-aware features serve as a guide to fuse the point cloud quality features extracted from different perspectives. Extensive experiments show that our method outperforms the state-of-the-art NR-PCQA methods on popular benchmarks in terms of prediction accuracy and generalizability. ",
    "url": "https://arxiv.org/abs/2403.10061",
    "authors": [
      "Ziyu Shan",
      "Yujie Zhang",
      "Qi Yang",
      "Haichen Yang",
      "Yiling Xu",
      "Shan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.10063",
    "title": "Unified Projection-Free Algorithms for Adversarial DR-Submodular  Optimization",
    "abstract": "This paper introduces unified projection-free Frank-Wolfe type algorithms for adversarial continuous DR-submodular optimization, spanning scenarios such as full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. For every problem considered in the non-monotone setting, the proposed algorithms are either the first with proven sub-linear $\\alpha$-regret bounds or have better $\\alpha$-regret bounds than the state of the art, where $\\alpha$ is a corresponding approximation bound in the offline setting. In the monotone setting, the proposed approach gives state-of-the-art sub-linear $\\alpha$-regret bounds among projection-free algorithms in 7 of the 8 considered cases while matching the result of the remaining case. Additionally, this paper addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization, advancing the understanding of this optimization area. ",
    "url": "https://arxiv.org/abs/2403.10063",
    "authors": [
      "Mohammad Pedramfar",
      "Yididiya Y. Nadew",
      "Christopher J. Quinn",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2403.10073",
    "title": "Revisiting Adversarial Training under Long-Tailed Distributions",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks, often leading to erroneous outputs. Adversarial training has been recognized as one of the most effective methods to counter such attacks. However, existing adversarial training techniques have predominantly been tested on balanced datasets, whereas real-world data often exhibit a long-tailed distribution, casting doubt on the efficacy of these methods in practical scenarios. In this paper, we delve into adversarial training under long-tailed distributions. Through an analysis of the previous work \"RoBal\", we discover that utilizing Balanced Softmax Loss alone can achieve performance comparable to the complete RoBal approach while significantly reducing training overheads. Additionally, we reveal that, similar to uniform distributions, adversarial training under long-tailed distributions also suffers from robust overfitting. To address this, we explore data augmentation as a solution and unexpectedly discover that, unlike results obtained with balanced data, data augmentation not only effectively alleviates robust overfitting but also significantly improves robustness. We further investigate the reasons behind the improvement of robustness through data augmentation and identify that it is attributable to the increased diversity of examples. Extensive experiments further corroborate that data augmentation alone can significantly improve robustness. Finally, building on these findings, we demonstrate that compared to RoBal, the combination of BSL and data augmentation leads to a +6.66% improvement in model robustness under AutoAttack on CIFAR-10-LT. Our code is available at https://github.com/NISPLab/AT-BSL . ",
    "url": "https://arxiv.org/abs/2403.10073",
    "authors": [
      "Xinli Yue",
      "Ningping Mou",
      "Qian Wang",
      "Lingchen Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10075",
    "title": "A survey of synthetic data augmentation methods in computer vision",
    "abstract": "The standard approach to tackling computer vision problems is to train deep convolutional neural network (CNN) models using large-scale image datasets which are representative of the target task. However, in many scenarios, it is often challenging to obtain sufficient image data for the target task. Data augmentation is a way to mitigate this challenge. A common practice is to explicitly transform existing images in desired ways so as to create the required volume and variability of training data necessary to achieve good generalization performance. In situations where data for the target domain is not accessible, a viable workaround is to synthesize training data from scratch--i.e., synthetic data augmentation. This paper presents an extensive review of synthetic data augmentation techniques. It covers data synthesis approaches based on realistic 3D graphics modeling, neural style transfer (NST), differential neural rendering, and generative artificial intelligence (AI) techniques such as generative adversarial networks (GANs) and variational autoencoders (VAEs). For each of these classes of methods, we focus on the important data generation and augmentation techniques, general scope of application and specific use-cases, as well as existing limitations and possible workarounds. Additionally, we provide a summary of common synthetic datasets for training computer vision models, highlighting the main features, application domains and supported tasks. Finally, we discuss the effectiveness of synthetic data augmentation methods. Since this is the first paper to explore synthetic data augmentation methods in great detail, we are hoping to equip readers with the necessary background information and in-depth knowledge of existing methods and their attendant issues. ",
    "url": "https://arxiv.org/abs/2403.10075",
    "authors": [
      "Alhassan Mumuni",
      "Fuseini Mumuni",
      "Nana Kobina Gerrar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10076",
    "title": "Benchmarking Adversarial Robustness of Image Shadow Removal with  Shadow-adaptive Attacks",
    "abstract": "Shadow removal is a task aimed at erasing regional shadows present in images and reinstating visually pleasing natural scenes with consistent illumination. While recent deep learning techniques have demonstrated impressive performance in image shadow removal, their robustness against adversarial attacks remains largely unexplored. Furthermore, many existing attack frameworks typically allocate a uniform budget for perturbations across the entire input image, which may not be suitable for attacking shadow images. This is primarily due to the unique characteristic of spatially varying illumination within shadow images. In this paper, we propose a novel approach, called shadow-adaptive adversarial attack. Different from standard adversarial attacks, our attack budget is adjusted based on the pixel intensity in different regions of shadow images. Consequently, the optimized adversarial noise in the shadowed regions becomes visually less perceptible while permitting a greater tolerance for perturbations in non-shadow regions. The proposed shadow-adaptive attacks naturally align with the varying illumination distribution in shadow images, resulting in perturbations that are less conspicuous. Building on this, we conduct a comprehensive empirical evaluation of existing shadow removal methods, subjecting them to various levels of attack on publicly available datasets. ",
    "url": "https://arxiv.org/abs/2403.10076",
    "authors": [
      "Chong Wang",
      "Yi Yu",
      "Lanqing Guo",
      "Bihan Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10079",
    "title": "Learning Physical Dynamics for Object-centric Visual Prediction",
    "abstract": "The ability to model the underlying dynamics of visual scenes and reason about the future is central to human intelligence. Many attempts have been made to empower intelligent systems with such physical understanding and prediction abilities. However, most existing methods focus on pixel-to-pixel prediction, which suffers from heavy computational costs while lacking a deep understanding of the physical dynamics behind videos. Recently, object-centric prediction methods have emerged and attracted increasing interest. Inspired by it, this paper proposes an unsupervised object-centric prediction model that makes future predictions by learning visual dynamics between objects. Our model consists of two modules, perceptual, and dynamic module. The perceptual module is utilized to decompose images into several objects and synthesize images with a set of object-centric representations. The dynamic module fuses contextual information, takes environment-object and object-object interaction into account, and predicts the future trajectory of objects. Extensive experiments are conducted to validate the effectiveness of the proposed method. Both quantitative and qualitative experimental results demonstrate that our model generates higher visual quality and more physically reliable predictions compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.10079",
    "authors": [
      "Huilin Xu",
      "Tao Chen",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10085",
    "title": "VRHCF: Cross-Source Point Cloud Registration via Voxel Representation  and Hierarchical Correspondence Filtering",
    "abstract": "Addressing the challenges posed by the substantial gap in point cloud data collected from diverse sensors, achieving robust cross-source point cloud registration becomes a formidable task. In response, we present a novel framework for point cloud registration with broad applicability, suitable for both homologous and cross-source registration scenarios. To tackle the issues arising from different densities and distributions in cross-source point cloud data, we introduce a feature representation based on spherical voxels. Furthermore, addressing the challenge of numerous outliers and mismatches in cross-source registration, we propose a hierarchical correspondence filtering approach. This method progressively filters out mismatches, yielding a set of high-quality correspondences. Our method exhibits versatile applicability and excels in both traditional homologous registration and challenging cross-source registration scenarios. Specifically, in homologous registration using the 3DMatch dataset, we achieve the highest registration recall of 95.1% and an inlier ratio of 87.8%. In cross-source point cloud registration, our method attains the best RR on the 3DCSR dataset, demonstrating a 9.3 percentage points improvement. The code is available at https://github.com/GuiyuZhao/VRHCF. ",
    "url": "https://arxiv.org/abs/2403.10085",
    "authors": [
      "Guiyu Zhao",
      "Zewen Du",
      "Zhentao Guo",
      "Hongbin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10097",
    "title": "Adaptive Random Feature Regularization on Fine-tuning Deep Neural  Networks",
    "abstract": "While fine-tuning is a de facto standard method for training deep neural networks, it still suffers from overfitting when using small target datasets. Previous methods improve fine-tuning performance by maintaining knowledge of the source datasets or introducing regularization terms such as contrastive loss. However, these methods require auxiliary source information (e.g., source labels or datasets) or heavy additional computations. In this paper, we propose a simple method called adaptive random feature regularization (AdaRand). AdaRand helps the feature extractors of training models to adaptively change the distribution of feature vectors for downstream classification tasks without auxiliary source information and with reasonable computation costs. To this end, AdaRand minimizes the gap between feature vectors and random reference vectors that are sampled from class conditional Gaussian distributions. Furthermore, AdaRand dynamically updates the conditional distribution to follow the currently updated feature extractors and balance the distance between classes in feature spaces. Our experiments show that AdaRand outperforms the other fine-tuning regularization, which requires auxiliary source information and heavy computation costs. ",
    "url": "https://arxiv.org/abs/2403.10097",
    "authors": [
      "Shin'ya Yamaguchi",
      "Sekitoshi Kanai",
      "Kazuki Adachi",
      "Daiki Chijiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10100",
    "title": "Efficient Multiplayer Battle Game Optimizer for Adversarial Robust  Neural Architecture Search",
    "abstract": "This paper introduces a novel metaheuristic algorithm, known as the efficient multiplayer battle game optimizer (EMBGO), specifically designed for addressing complex numerical optimization tasks. The motivation behind this research stems from the need to rectify identified shortcomings in the original MBGO, particularly in search operators during the movement phase, as revealed through ablation experiments. EMBGO mitigates these limitations by integrating the movement and battle phases to simplify the original optimization framework and improve search efficiency. Besides, two efficient search operators: differential mutation and L\\'evy flight are introduced to increase the diversity of the population. To evaluate the performance of EMBGO comprehensively and fairly, numerical experiments are conducted on benchmark functions such as CEC2017, CEC2020, and CEC2022, as well as engineering problems. Twelve well-established MA approaches serve as competitor algorithms for comparison. Furthermore, we apply the proposed EMBGO to the complex adversarial robust neural architecture search (ARNAS) tasks and explore its robustness and scalability. The experimental results and statistical analyses confirm the efficiency and effectiveness of EMBGO across various optimization tasks. As a potential optimization technique, EMBGO holds promise for diverse applications in real-world problems and deep learning scenarios. The source code of EMBGO is made available in \\url{https://github.com/RuiZhong961230/EMBGO}. ",
    "url": "https://arxiv.org/abs/2403.10100",
    "authors": [
      "Rui Zhong",
      "Yuefeng Xu",
      "Chao Zhang",
      "Jun Yu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2403.10103",
    "title": "DyBluRF: Dynamic Neural Radiance Fields from Blurry Monocular Video",
    "abstract": "Recent advancements in dynamic neural radiance field methods have yielded remarkable outcomes. However, these approaches rely on the assumption of sharp input images. When faced with motion blur, existing dynamic NeRF methods often struggle to generate high-quality novel views. In this paper, we propose DyBluRF, a dynamic radiance field approach that synthesizes sharp novel views from a monocular video affected by motion blur. To account for motion blur in input images, we simultaneously capture the camera trajectory and object Discrete Cosine Transform (DCT) trajectories within the scene. Additionally, we employ a global cross-time rendering approach to ensure consistent temporal coherence across the entire scene. We curate a dataset comprising diverse dynamic scenes that are specifically tailored for our task. Experimental results on our dataset demonstrate that our method outperforms existing approaches in generating sharp novel views from motion-blurred inputs while maintaining spatial-temporal consistency of the scene. ",
    "url": "https://arxiv.org/abs/2403.10103",
    "authors": [
      "Huiqiang Sun",
      "Xingyi Li",
      "Liao Shen",
      "Xinyi Ye",
      "Ke Xian",
      "Zhiguo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10104",
    "title": "CSDNet: Detect Salient Object in Depth-Thermal via A Lightweight Cross  Shallow and Deep Perception Network",
    "abstract": "While we enjoy the richness and informativeness of multimodal data, it also introduces interference and redundancy of information. To achieve optimal domain interpretation with limited resources, we propose CSDNet, a lightweight \\textbf{C}ross \\textbf{S}hallow and \\textbf{D}eep Perception \\textbf{Net}work designed to integrate two modalities with less coherence, thereby discarding redundant information or even modality. We implement our CSDNet for Salient Object Detection (SOD) task in robotic perception. The proposed method capitalises on spatial information prescreening and implicit coherence navigation across shallow and deep layers of the depth-thermal (D-T) modality, prioritising integration over fusion to maximise the scene interpretation. To further refine the descriptive capabilities of the encoder for the less-known D-T modalities, we also propose SAMAEP to guide an effective feature mapping to the generalised feature space. Our approach is tested on the VDT-2048 dataset, leveraging the D-T modality outperforms those of SOTA methods using RGB-T or RGB-D modalities for the first time, achieves comparable performance with the RGB-D-T triple-modality benchmark method with 5.97 times faster at runtime and demanding 0.0036 times fewer FLOPs. Demonstrates the proposed CSDNet effectively integrates the information from the D-T modality. The code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2403.10104",
    "authors": [
      "Xiaotong Yu",
      "Ruihan Xie",
      "Zhihe Zhao",
      "Chang-Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10110",
    "title": "Meta Operator for Complex Query Answering on Knowledge Graphs",
    "abstract": "Knowledge graphs contain informative factual knowledge but are considered incomplete. To answer complex queries under incomplete knowledge, learning-based Complex Query Answering (CQA) models are proposed to directly learn from the query-answer samples to avoid the direct traversal of incomplete graph data. Existing works formulate the training of complex query answering models as multi-task learning and require a large number of training samples. In this work, we explore the compositional structure of complex queries and argue that the different logical operator types, rather than the different complex query types, are the key to improving generalizability. Accordingly, we propose a meta-learning algorithm to learn the meta-operators with limited data and adapt them to different instances of operators under various complex queries. Empirical results show that learning meta-operators is more effective than learning original CQA or meta-CQA models. ",
    "url": "https://arxiv.org/abs/2403.10110",
    "authors": [
      "Hang Yin",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2403.10116",
    "title": "Instance-optimal Clipping for Summation Problems in the Shuffle Model of  Differential Privacy",
    "abstract": "Differentially private mechanisms achieving worst-case optimal error bounds (e.g., the classical Laplace mechanism) are well-studied in the literature. However, when typical data are far from the worst case, \\emph{instance-specific} error bounds -- which depend on the largest value in the dataset -- are more meaningful. For example, consider the sum estimation problem, where each user has an integer $x_i$ from the domain $\\{0,1,\\dots,U\\}$ and we wish to estimate $\\sum_i x_i$. This has a worst-case optimal error of $O(U/\\varepsilon)$, while recent work has shown that the clipping mechanism can achieve an instance-optimal error of $O(\\max_i x_i \\cdot \\log\\log U /\\varepsilon)$. Under the shuffle model, known instance-optimal protocols are less communication-efficient. The clipping mechanism also works in the shuffle model, but requires two rounds: Round one finds the clipping threshold, and round two does the clipping and computes the noisy sum of the clipped data. In this paper, we show how these two seemingly sequential steps can be done simultaneously in one round using just $1+o(1)$ messages per user, while maintaining the instance-optimal error bound. We also extend our technique to the high-dimensional sum estimation problem and sparse vector aggregation (a.k.a. frequency estimation under user-level differential privacy). Our experiments show order-of-magnitude improvements of our protocols in terms of error compared with prior work. ",
    "url": "https://arxiv.org/abs/2403.10116",
    "authors": [
      "Wei Dong",
      "Qiyao Luo",
      "Giulia Fanti",
      "Elaine Shi",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.10119",
    "title": "URS-NeRF: Unordered Rolling Shutter Bundle Adjustment for Neural  Radiance Fields",
    "abstract": "We propose a novel rolling shutter bundle adjustment method for neural radiance fields (NeRF), which utilizes the unordered rolling shutter (RS) images to obtain the implicit 3D representation. Existing NeRF methods suffer from low-quality images and inaccurate initial camera poses due to the RS effect in the image, whereas, the previous method that incorporates the RS into NeRF requires strict sequential data input, limiting its widespread applicability. In constant, our method recovers the physical formation of RS images by estimating camera poses and velocities, thereby removing the input constraints on sequential data. Moreover, we adopt a coarse-to-fine training strategy, in which the RS epipolar constraints of the pairwise frames in the scene graph are used to detect the camera poses that fall into local minima. The poses detected as outliers are corrected by the interpolation method with neighboring poses. The experimental results validate the effectiveness of our method over state-of-the-art works and demonstrate that the reconstruction of 3D representations is not constrained by the requirement of video sequence input. ",
    "url": "https://arxiv.org/abs/2403.10119",
    "authors": [
      "Bo Xu",
      "Ziao Liu",
      "Mengqi Guo",
      "Jiancheng Li",
      "Gim Hee Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10124",
    "title": "Depth-induced Saliency Comparison Network for Diagnosis of Alzheimer's  Disease via Jointly Analysis of Visual Stimuli and Eye Movements",
    "abstract": "Early diagnosis of Alzheimer's Disease (AD) is very important for following medical treatments, and eye movements under special visual stimuli may serve as a potential non-invasive biomarker for detecting cognitive abnormalities of AD patients. In this paper, we propose an Depth-induced saliency comparison network (DISCN) for eye movement analysis, which may be used for diagnosis the Alzheimers disease. In DISCN, a salient attention module fuses normal eye movements with RGB and depth maps of visual stimuli using hierarchical salient attention (SAA) to evaluate comprehensive saliency maps, which contain information from both visual stimuli and normal eye movement behaviors. In addition, we introduce serial attention module (SEA) to emphasis the most abnormal eye movement behaviors to reduce personal bias for a more robust result. According to our experiments, the DISCN achieves consistent validity in classifying the eye movements between the AD patients and normal controls. ",
    "url": "https://arxiv.org/abs/2403.10124",
    "authors": [
      "Yu Liu",
      "Wenlin Zhang",
      "Shaochu Wang",
      "Fangyu Zuo",
      "Peiguang Jing",
      "Yong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10144",
    "title": "NLP Verification: Towards a General Methodology for Certifying  Robustness",
    "abstract": "Deep neural networks have exhibited substantial success in the field of Natural Language Processing (NLP) and ensuring their safety and reliability is crucial: there are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Unlike Computer Vision, NLP lacks a unified verification methodology and, despite recent advancements in literature, they are often light on the pragmatical issues of NLP verification. In this paper, we make an attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we give a general characterisation of verifiable subspaces that result from embedding sentences into continuous spaces. We identify, and give an effective method to deal with, the technical challenge of semantic generalisability of verified subspaces; and propose it as a standard metric in the NLP verification pipelines (alongside with the standard metrics of model accuracy and model verifiability). Secondly, we propose a general methodology to analyse the effect of the embedding gap, a problem that refers to the discrepancy between verification of geometric subpspaces on the one hand, and semantic meaning of sentences which the geometric subspaces are supposed to represent, on the other hand. In extreme cases, poor choices in embedding of sentences may invalidate verification results. We propose a number of practical NLP methods that can help to identify the effects of the embedding gap; and in particular we propose the metric of falsifiability of semantic subpspaces as another fundamental metric to be reported as part of the NLP verification pipeline. We believe that together these general principles pave the way towards a more consolidated and effective development of this new domain. ",
    "url": "https://arxiv.org/abs/2403.10144",
    "authors": [
      "Marco Casadio",
      "Tanvi Dinkar",
      "Ekaterina Komendantskaya",
      "Luca Arnaboldi",
      "Omri Isac",
      "Matthew L. Daggitt",
      "Guy Katz",
      "Verena Rieser",
      "Oliver Lemon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2403.10158",
    "title": "Functional Graph Convolutional Networks: A unified multi-task and  multi-modal learning framework to facilitate health and social-care insights",
    "abstract": "This paper introduces a novel Functional Graph Convolutional Network (funGCN) framework that combines Functional Data Analysis and Graph Convolutional Networks to address the complexities of multi-task and multi-modal learning in digital health and longitudinal studies. With the growing importance of health solutions to improve health care and social support, ensure healthy lives, and promote well-being at all ages, funGCN offers a unified approach to handle multivariate longitudinal data for multiple entities and ensures interpretability even with small sample sizes. Key innovations include task-specific embedding components that manage different data types, the ability to perform classification, regression, and forecasting, and the creation of a knowledge graph for insightful data interpretation. The efficacy of funGCN is validated through simulation experiments and a real-data application. ",
    "url": "https://arxiv.org/abs/2403.10158",
    "authors": [
      "Tobia Boschi",
      "Francesca Bonin",
      "Rodrigo Ordonez-Hurtado",
      "C\u00e9cile Rosseau",
      "Alessandra Pascale",
      "John Dinsmore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10164",
    "title": "CoReEcho: Continuous Representation Learning for 2D+time  Echocardiography Analysis",
    "abstract": "Deep learning (DL) models have been advancing automatic medical image analysis on various modalities, including echocardiography, by offering a comprehensive end-to-end training pipeline. This approach enables DL models to regress ejection fraction (EF) directly from 2D+time echocardiograms, resulting in superior performance. However, the end-to-end training pipeline makes the learned representations less explainable. The representations may also fail to capture the continuous relation among echocardiogram clips, indicating the existence of spurious correlations, which can negatively affect the generalization. To mitigate this issue, we propose CoReEcho, a novel training framework emphasizing continuous representations tailored for direct EF regression. Our extensive experiments demonstrate that CoReEcho: 1) outperforms the current state-of-the-art (SOTA) on the largest echocardiography dataset (EchoNet-Dynamic) with MAE of 3.90 & R2 of 82.44, and 2) provides robust and generalizable features that transfer more effectively in related downstream tasks. The code is publicly available at https://github.com/fadamsyah/CoReEcho. ",
    "url": "https://arxiv.org/abs/2403.10164",
    "authors": [
      "Fadillah Adamsyah Maani",
      "Numan Saeed",
      "Aleksandr Matsun",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10167",
    "title": "Efficient Detection of Exchangeable Factors in Factor Graphs",
    "abstract": "To allow for tractable probabilistic inference with respect to domain sizes, lifted probabilistic inference exploits symmetries in probabilistic graphical models. However, checking whether two factors encode equivalent semantics and hence are exchangeable is computationally expensive. In this paper, we efficiently solve the problem of detecting exchangeable factors in a factor graph. In particular, we introduce the detection of exchangeable factors (DEFT) algorithm, which allows us to drastically reduce the computational effort for checking whether two factors are exchangeable in practice. While previous approaches iterate all $O(n!)$ permutations of a factor's argument list in the worst case (where $n$ is the number of arguments of the factor), we prove that DEFT efficiently identifies restrictions to drastically reduce the number of permutations and validate the efficiency of DEFT in our empirical evaluation. ",
    "url": "https://arxiv.org/abs/2403.10167",
    "authors": [
      "Malte Luttermann",
      "Johann Machemer",
      "Marcel Gehrke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.10168",
    "title": "Explainability through uncertainty: Trustworthy decision-making with  neural networks",
    "abstract": "Uncertainty is a key feature of any machine learning model and is particularly important in neural networks, which tend to be overconfident. This overconfidence is worrying under distribution shifts, where the model performance silently degrades as the data distribution diverges from the training data distribution. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Although methods for uncertainty estimation have been developed, they have not been explicitly linked to the field of explainable artificial intelligence (XAI). Furthermore, literature in operations research ignores the actionability component of uncertainty estimation and does not consider distribution shifts. This work proposes a general uncertainty framework, with contributions being threefold: (i) uncertainty estimation in ML models is positioned as an XAI technique, giving local and model-specific explanations; (ii) classification with rejection is used to reduce misclassifications by bringing a human expert in the loop for uncertain observations; (iii) the framework is applied to a case study on neural networks in educational data mining subject to distribution shifts. Uncertainty as XAI improves the model's trustworthiness in downstream decision-making tasks, giving rise to more actionable and robust machine learning systems in operations research. ",
    "url": "https://arxiv.org/abs/2403.10168",
    "authors": [
      "Arthur Thuy",
      "Dries F. Benoit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.10172",
    "title": "Unpacking ICT-supported Social Connections and Support of Late-life  Migration: From the Lens of Social Convoys",
    "abstract": "Migration and aging-related dilemmas have limited the opportunities for late-life migrants to rebuild social connections and access support. While research on migrants has drawn increasing attention in HCI, limited attention has been paid to the increasing number of late-life migrants. This paper reports a qualitative study examining the social connections and support of late-life migrants. In particular, drawing on the social convoy model, we pay specific attention to the dynamic changes of late-life migrants' social convoy, the supporting roles each convoy plays, the functions ICT plays in the process, as well as the encountered challenges and expectations of late-life migrants regarding ICT-supported social convoys. Based on these findings, we deeply discuss the role of the social convoy in supporting more targeted social support for late-life migrants, as well as broader migrant communities. Finally, we offer late-life migrant-oriented design considerations. ",
    "url": "https://arxiv.org/abs/2403.10172",
    "authors": [
      "Ying Lei",
      "Shuai Ma",
      "Yuling Sun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2403.10173",
    "title": "A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial  and Temporal Attention",
    "abstract": "Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for object detection tasks. While Spiking Neural Networks (SNNs) are a natural match for event-based sensory data and enable ultra-energy efficient and low latency inference on neuromorphic hardware, Artificial Neural Networks (ANNs) tend to display more stable training dynamics and faster convergence resulting in greater task performance. Hybrid SNN-ANN approaches are a promising alternative, enabling to leverage the strengths of both SNN and ANN architectures. In this work, we introduce the first Hybrid Attention-based SNN-ANN backbone for object detection using event cameras. We propose a novel Attention-based SNN-ANN bridge module to capture sparse spatial and temporal relations from the SNN layer and convert them into dense feature maps for the ANN part of the backbone. Experimental results demonstrate that our proposed method surpasses baseline hybrid and SNN-based approaches by significant margins, with results comparable to existing ANN-based methods. Extensive ablation studies confirm the effectiveness of our proposed modules and architectural choices. These results pave the way toward a hybrid SNN-ANN architecture that achieves ANN like performance at a drastically reduced parameter budget. We implemented the SNN blocks on digital neuromorphic hardware to investigate latency and power consumption and demonstrate the feasibility of our approach. ",
    "url": "https://arxiv.org/abs/2403.10173",
    "authors": [
      "Soikat Hasan Ahmed",
      "Jan Finkbeiner",
      "Emre Neftci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10182",
    "title": "Reliable uncertainty with cheaper neural network ensembles: a case study  in industrial parts classification",
    "abstract": "In operations research (OR), predictive models often encounter out-of-distribution (OOD) scenarios where the data distribution differs from the training data distribution. In recent years, neural networks (NNs) are gaining traction in OR for their exceptional performance in fields such as image classification. However, NNs tend to make confident yet incorrect predictions when confronted with OOD data. Uncertainty estimation offers a solution to overconfident models, communicating when the output should (not) be trusted. Hence, reliable uncertainty quantification in NNs is crucial in the OR domain. Deep ensembles, composed of multiple independent NNs, have emerged as a promising approach, offering not only strong predictive accuracy but also reliable uncertainty estimation. However, their deployment is challenging due to substantial computational demands. Recent fundamental research has proposed more efficient NN ensembles, namely the snapshot, batch, and multi-input multi-output ensemble. This study is the first to provide a comprehensive comparison of a single NN, a deep ensemble, and the three efficient NN ensembles. In addition, we propose a Diversity Quality metric to quantify the ensembles' performance on the in-distribution and OOD sets in one single metric. The OR case study discusses industrial parts classification to identify and manage spare parts, important for timely maintenance of industrial plants. The results highlight the batch ensemble as a cost-effective and competitive alternative to the deep ensemble. It outperforms the deep ensemble in both uncertainty and accuracy while exhibiting a training time speedup of 7x, a test time speedup of 8x, and 9x memory savings. ",
    "url": "https://arxiv.org/abs/2403.10182",
    "authors": [
      "Arthur Thuy",
      "Dries F. Benoit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.10184",
    "title": "Lifted Causal Inference in Relational Domains",
    "abstract": "Lifted inference exploits symmetries in probabilistic graphical models by using a representative for indistinguishable objects, thereby speeding up query answering while maintaining exact answers. Even though lifting is a well-established technique for the task of probabilistic inference in relational domains, it has not yet been applied to the task of causal inference. In this paper, we show how lifting can be applied to efficiently compute causal effects in relational domains. More specifically, we introduce parametric causal factor graphs as an extension of parametric factor graphs incorporating causal knowledge and give a formal semantics of interventions therein. We further present the lifted causal inference algorithm to compute causal effects on a lifted level, thereby drastically speeding up causal inference compared to propositional inference, e.g., in causal Bayesian networks. In our empirical evaluation, we demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2403.10184",
    "authors": [
      "Malte Luttermann",
      "Mattis Hartwig",
      "Tanya Braun",
      "Ralf M\u00f6ller",
      "Marcel Gehrke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2403.10191",
    "title": "Generative Region-Language Pretraining for Open-Ended Object Detection",
    "abstract": "In recent research, significant attention has been devoted to the open-vocabulary object detection task, aiming to generalize beyond the limited number of classes labeled during training and detect objects described by arbitrary category names at inference. Compared with conventional object detection, open vocabulary object detection largely extends the object detection categories. However, it relies on calculating the similarity between image regions and a set of arbitrary category names with a pretrained vision-and-language model. This implies that, despite its open-set nature, the task still needs the predefined object categories during the inference stage. This raises the question: What if we do not have exact knowledge of object categories during inference? In this paper, we call such a new setting as generative open-ended object detection, which is a more general and practical problem. To address it, we formulate object detection as a generative problem and propose a simple framework named GenerateU, which can detect dense objects and generate their names in a free-form way. Particularly, we employ Deformable DETR as a region proposal generator with a language model translating visual regions to object names. To assess the free-form object detection task, we introduce an evaluation method designed to quantitatively measure the performance of generative outcomes. Extensive experiments demonstrate strong zero-shot detection performance of our GenerateU. For example, on the LVIS dataset, our GenerateU achieves comparable results to the open-vocabulary object detection method GLIP, even though the category names are not seen by GenerateU during inference. Code is available at: https:// github.com/FoundationVision/GenerateU . ",
    "url": "https://arxiv.org/abs/2403.10191",
    "authors": [
      "Chuang Lin",
      "Yi Jiang",
      "Lizhen Qu",
      "Zehuan Yuan",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10214",
    "title": "Enhanced Coherence-Aware Network with Hierarchical Disentanglement for  Aspect-Category Sentiment Analysis",
    "abstract": "Aspect-category-based sentiment analysis (ACSA), which aims to identify aspect categories and predict their sentiments has been intensively studied due to its wide range of NLP applications. Most approaches mainly utilize intrasentential features. However, a review often includes multiple different aspect categories, and some of them do not explicitly appear in the review. Even in a sentence, there is more than one aspect category with its sentiments, and they are entangled intra-sentence, which makes the model fail to discriminately preserve all sentiment characteristics. In this paper, we propose an enhanced coherence-aware network with hierarchical disentanglement (ECAN) for ACSA tasks. Specifically, we explore coherence modeling to capture the contexts across the whole review and to help the implicit aspect and sentiment identification. To address the issue of multiple aspect categories and sentiment entanglement, we propose a hierarchical disentanglement module to extract distinct categories and sentiment features. Extensive experimental and visualization results show that our ECAN effectively decouples multiple categories and sentiments entangled in the coherence representations and achieves state-of-the-art (SOTA) performance. Our codes and data are available online: \\url{https://github.com/cuijin-23/ECAN}. ",
    "url": "https://arxiv.org/abs/2403.10214",
    "authors": [
      "Jin Cui",
      "Fumiyo Fukumoto",
      "Xinfeng Wang",
      "Yoshimi Suzuki",
      "Jiyi Li",
      "Noriko Tomuro",
      "Wanzeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10220",
    "title": "From Chaos to Clarity: Time Series Anomaly Detection in Astronomical  Observations",
    "abstract": "With the development of astronomical facilities, large-scale time series data observed by these facilities is being collected. Analyzing anomalies in these astronomical observations is crucial for uncovering potential celestial events and physical phenomena, thus advancing the scientific research process. However, existing time series anomaly detection methods fall short in tackling the unique characteristics of astronomical observations where each star is inherently independent but interfered by random concurrent noise, resulting in a high rate of false alarms. To overcome the challenges, we propose AERO, a novel two-stage framework tailored for unsupervised anomaly detection in astronomical observations. In the first stage, we employ a Transformer-based encoder-decoder architecture to learn the normal temporal patterns on each variate (i.e., star) in alignment with the characteristic of variate independence. In the second stage, we enhance the graph neural network with a window-wise graph structure learning to tackle the occurrence of concurrent noise characterized by spatial and temporal randomness. In this way, AERO is not only capable of distinguishing normal temporal patterns from potential anomalies but also effectively differentiating concurrent noise, thus decreasing the number of false alarms. We conducted extensive experiments on three synthetic datasets and three real-world datasets. The results demonstrate that AERO outperforms the compared baselines. Notably, compared to the state-of-the-art model, AERO improves the F1-score by up to 8.76% and 2.63% on synthetic and real-world datasets respectively. ",
    "url": "https://arxiv.org/abs/2403.10220",
    "authors": [
      "Xinli Hao",
      "Yile Chen",
      "Chen Yang",
      "Zhihui Du",
      "Chaohong Ma",
      "Chao Wu",
      "Xiaofeng Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.10231",
    "title": "Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge  Graphs",
    "abstract": "To deduce new facts on a knowledge graph (KG), a link predictor learns from the graph structure and collects local evidence to find the answer to a given query. However, existing methods suffer from a severe scalability problem due to the utilization of the whole KG for prediction, which hinders their promise on large scale KGs and cannot be directly addressed by vanilla sampling methods. In this work, we propose the one-shot-subgraph link prediction to achieve efficient and adaptive prediction. The design principle is that, instead of directly acting on the whole KG, the prediction procedure is decoupled into two steps, i.e., (i) extracting only one subgraph according to the query and (ii) predicting on this single, query dependent subgraph. We reveal that the non-parametric and computation-efficient heuristics Personalized PageRank (PPR) can effectively identify the potential answers and supporting evidence. With efficient subgraph-based prediction, we further introduce the automated searching of the optimal configurations in both data and model spaces. Empirically, we achieve promoted efficiency and leading performances on five large-scale benchmarks. The code is publicly available at: https://github.com/tmlr-group/one-shot-subgraph. ",
    "url": "https://arxiv.org/abs/2403.10231",
    "authors": [
      "Zhanke Zhou",
      "Yongqi Zhang",
      "Jiangchao Yao",
      "Quanming Yao",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10232",
    "title": "Matrix Completion via Nonsmooth Regularization of Fully Connected Neural  Networks",
    "abstract": "Conventional matrix completion methods approximate the missing values by assuming the matrix to be low-rank, which leads to a linear approximation of missing values. It has been shown that enhanced performance could be attained by using nonlinear estimators such as deep neural networks. Deep fully connected neural networks (FCNNs), one of the most suitable architectures for matrix completion, suffer from over-fitting due to their high capacity, which leads to low generalizability. In this paper, we control over-fitting by regularizing the FCNN model in terms of the $\\ell_{1}$ norm of intermediate representations and nuclear norm of weight matrices. As such, the resulting regularized objective function becomes nonsmooth and nonconvex, i.e., existing gradient-based methods cannot be applied to our model. We propose a variant of the proximal gradient method and investigate its convergence to a critical point. In the initial epochs of FCNN training, the regularization terms are ignored, and through epochs, the effect of that increases. The gradual addition of nonsmooth regularization terms is the main reason for the better performance of the deep neural network with nonsmooth regularization terms (DNN-NSR) algorithm. Our simulations indicate the superiority of the proposed algorithm in comparison with existing linear and nonlinear algorithms. ",
    "url": "https://arxiv.org/abs/2403.10232",
    "authors": [
      "Sajad Faramarzi",
      "Farzan Haddadi",
      "Sajjad Amini",
      "Masoud Ahookhosh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10237",
    "title": "A comprehensive study on Frequent Pattern Mining and Clustering  categories for topic detection in Persian text stream",
    "abstract": "Topic detection is a complex process and depends on language because it somehow needs to analyze text. There have been few studies on topic detection in Persian, and the existing algorithms are not remarkable. Therefore, we aimed to study topic detection in Persian. The objectives of this study are: 1) to conduct an extensive study on the best algorithms for topic detection, 2) to identify necessary adaptations to make these algorithms suitable for the Persian language, and 3) to evaluate their performance on Persian social network texts. To achieve these objectives, we have formulated two research questions: First, considering the lack of research in Persian, what modifications should be made to existing frameworks, especially those developed in English, to make them compatible with Persian? Second, how do these algorithms perform, and which one is superior? There are various topic detection methods that can be categorized into different categories. Frequent pattern and clustering are selected for this research, and a hybrid of both is proposed as a new category. Then, ten methods from these three categories are selected. All of them are re-implemented from scratch, changed, and adapted with Persian. These ten methods encompass different types of topic detection methods and have shown good performance in English. The text of Persian social network posts is used as the dataset. Additionally, a new multiclass evaluation criterion, called FS, is used in this paper for the first time in the field of topic detection. Approximately 1.4 billion tokens are processed during experiments. The results indicate that if we are searching for keyword-topics that are easily understandable by humans, the hybrid category is better. However, if the aim is to cluster posts for further analysis, the frequent pattern category is more suitable. ",
    "url": "https://arxiv.org/abs/2403.10237",
    "authors": [
      "Elnaz Zafarani-Moattar",
      "Mohammad Reza Kangavari",
      "Amir Masoud Rahmani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10255",
    "title": "Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion  Model and Implicit Neural Decoder",
    "abstract": "Super-resolution (SR) and image generation are important tasks in computer vision and are widely adopted in real-world applications. Most existing methods, however, generate images only at fixed-scale magnification and suffer from over-smoothing and artifacts. Additionally, they do not offer enough diversity of output images nor image consistency at different scales. Most relevant work applied Implicit Neural Representation (INR) to the denoising diffusion model to obtain continuous-resolution yet diverse and high-quality SR results. Since this model operates in the image space, the larger the resolution of image is produced, the more memory and inference time is required, and it also does not maintain scale-specific consistency. We propose a novel pipeline that can super-resolve an input image or generate from a random noise a novel image at arbitrary scales. The method consists of a pretrained auto-encoder, a latent diffusion model, and an implicit neural decoder, and their learning strategies. The proposed method adopts diffusion processes in a latent space, thus efficient, yet aligned with output image space decoded by MLPs at arbitrary scales. More specifically, our arbitrary-scale decoder is designed by the symmetric decoder w/o up-scaling from the pretrained auto-encoder, and Local Implicit Image Function (LIIF) in series. The latent diffusion process is learnt by the denoising and the alignment losses jointly. Errors in output images are backpropagated via the fixed decoder, improving the quality of output images. In the extensive experiments using multiple public benchmarks on the two tasks i.e. image super-resolution and novel image generation at arbitrary scales, the proposed method outperforms relevant methods in metrics of image quality, diversity and scale consistency. It is significantly better than the relevant prior-art in the inference speed and memory usage. ",
    "url": "https://arxiv.org/abs/2403.10255",
    "authors": [
      "Jinseok Kim",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10261",
    "title": "Towards Generalizable Deepfake Video Detection with Thumbnail Layout and  Graph Reasoning",
    "abstract": "The deepfake threats to society and cybersecurity have provoked significant public apprehension, driving intensified efforts within the realm of deepfake video detection. Current video-level methods are mostly based on {3D CNNs} resulting in high computational demands, although have achieved good performance. This paper introduces an elegantly simple yet effective strategy named Thumbnail Layout (TALL), which transforms a video clip into a pre-defined layout to realize the preservation of spatial and temporal dependencies. This transformation process involves sequentially masking frames at the same positions within each frame. These frames are then resized into sub-frames and reorganized into the predetermined layout, forming thumbnails. TALL is model-agnostic and has remarkable simplicity, necessitating only minimal code modifications. Furthermore, we introduce a graph reasoning block (GRB) and semantic consistency (SC) loss to strengthen TALL, culminating in TALL++. GRB enhances interactions between different semantic regions to capture semantic-level inconsistency clues. The semantic consistency loss imposes consistency constraints on semantic features to improve model generalization ability. Extensive experiments on intra-dataset, cross-dataset, diffusion-generated image detection, and deepfake generation method recognition show that TALL++ achieves results surpassing or comparable to the state-of-the-art methods, demonstrating the effectiveness of our approaches for various deepfake detection problems. The code is available at https://github.com/rainy-xu/TALL4Deepfake. ",
    "url": "https://arxiv.org/abs/2403.10261",
    "authors": [
      "Yuting Xu",
      "Jian Liang",
      "Lijun Sheng",
      "Xiao-Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10279",
    "title": "Emotion-Aware Multimodal Fusion for Meme Emotion Detection",
    "abstract": "The ever-evolving social media discourse has witnessed an overwhelming use of memes to express opinions or dissent. Besides being misused for spreading malcontent, they are mined by corporations and political parties to glean the public's opinion. Therefore, memes predominantly offer affect-enriched insights towards ascertaining the societal psyche. However, the current approaches are yet to model the affective dimensions expressed in memes effectively. They rely extensively on large multimodal datasets for pre-training and do not generalize well due to constrained visual-linguistic grounding. In this paper, we introduce MOOD (Meme emOtiOns Dataset), which embodies six basic emotions. We then present ALFRED (emotion-Aware muLtimodal Fusion foR Emotion Detection), a novel multimodal neural framework that (i) explicitly models emotion-enriched visual cues, and (ii) employs an efficient cross-modal fusion via a gating mechanism. Our investigation establishes ALFRED's superiority over existing baselines by 4.94% F1. Additionally, ALFRED competes strongly with previous best approaches on the challenging Memotion task. We then discuss ALFRED's domain-agnostic generalizability by demonstrating its dominance on two recently-released datasets - HarMeme and Dank Memes, over other baselines. Further, we analyze ALFRED's interpretability using attention maps. Finally, we highlight the inherent challenges posed by the complex interplay of disparate modality-specific cues toward meme analysis. ",
    "url": "https://arxiv.org/abs/2403.10279",
    "authors": [
      "Shivam Sharma",
      "Ramaneswaran S",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.10283",
    "title": "Local positional graphs and attentive local features for a data and  runtime-efficient hierarchical place recognition pipeline",
    "abstract": "Large-scale applications of Visual Place Recognition (VPR) require computationally efficient approaches. Further, a well-balanced combination of data-based and training-free approaches can decrease the required amount of training data and effort and can reduce the influence of distribution shifts between the training and application phases. This paper proposes a runtime and data-efficient hierarchical VPR pipeline that extends existing approaches and presents novel ideas. There are three main contributions: First, we propose Local Positional Graphs (LPG), a training-free and runtime-efficient approach to encode spatial context information of local image features. LPG can be combined with existing local feature detectors and descriptors and considerably improves the image-matching quality compared to existing techniques in our experiments. Second, we present Attentive Local SPED (ATLAS), an extension of our previous local features approach with an attention module that improves the feature quality while maintaining high data efficiency. The influence of the proposed modifications is evaluated in an extensive ablation study. Third, we present a hierarchical pipeline that exploits hyperdimensional computing to use the same local features as holistic HDC-descriptors for fast candidate selection and for candidate reranking. We combine all contributions in a runtime and data-efficient VPR pipeline that shows benefits over the state-of-the-art method Patch-NetVLAD on a large collection of standard place recognition datasets with 15$\\%$ better performance in VPR accuracy, 54$\\times$ faster feature comparison speed, and 55$\\times$ less descriptor storage occupancy, making our method promising for real-world high-performance large-scale VPR in changing environments. Code will be made available with publication of this paper. ",
    "url": "https://arxiv.org/abs/2403.10283",
    "authors": [
      "Fangming Yuan",
      "Stefan Schubert",
      "Peter Protzel",
      "Peer Neubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10291",
    "title": "Deep Learning for Multi-Level Detection and Localization of Myocardial  Scars Based on Regional Strain Validated on Virtual Patients",
    "abstract": "How well the heart is functioning can be quantified through measurements of myocardial deformation via echocardiography. Clinical assessment of cardiac function is generally focused on global indices of relative shortening, however, territorial, and segmental strain indices have shown to be abnormal in regions of myocardial disease, such as scar. In this work, we propose a single framework to predict myocardial disease substrates at global, territorial, and segmental levels using regional myocardial strain traces as input to a convolutional neural network (CNN)-based classification algorithm. An anatomically meaningful representation of the input data from the clinically standard bullseye representation to a multi-channel 2D image is proposed, to formulate the task as an image classification problem, thus enabling the use of state-of-the-art neural network configurations. A Fully Convolutional Network (FCN) is trained to detect and localize myocardial scar from regional left ventricular (LV) strain patterns. Simulated regional strain data from a controlled dataset of virtual patients with varying degrees and locations of myocardial scar is used for training and validation. The proposed method successfully detects and localizes the scars on 98% of the 5490 left ventricle (LV) segments of the 305 patients in the test set using strain traces only. Due to the sparse existence of scar, only 10% of the LV segments in the virtual patient cohort have scar. Taking the imbalance into account, the class balanced accuracy is calculated as 95%. The performance is reported on global, territorial, and segmental levels. The proposed method proves successful on the strain traces of the virtual cohort and offers the potential to solve the regional myocardial scar detection problem on the strain traces of the real patient cohorts. ",
    "url": "https://arxiv.org/abs/2403.10291",
    "authors": [
      "M\u00fcjde Akdeniz",
      "Claudia Alessandra Manetti",
      "Tijmen Koopsen",
      "Hani Nozari Mirar",
      "Sten Roar Snare",
      "Svein Arne Aase",
      "Joost Lumens",
      "Jurica \u0160prem",
      "Kristin Sarah McLeod"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10297",
    "title": "Leveraging Neural Radiance Field in Descriptor Synthesis for Keypoints  Scene Coordinate Regression",
    "abstract": "Classical structural-based visual localization methods offer high accuracy but face trade-offs in terms of storage, speed, and privacy. A recent innovation, keypoint scene coordinate regression (KSCR) named D2S addresses these issues by leveraging graph attention networks to enhance keypoint relationships and predict their 3D coordinates using a simple multilayer perceptron (MLP). Camera pose is then determined via PnP+RANSAC, using established 2D-3D correspondences. While KSCR achieves competitive results, rivaling state-of-the-art image-retrieval methods like HLoc across multiple benchmarks, its performance is hindered when data samples are limited due to the deep learning model's reliance on extensive data. This paper proposes a solution to this challenge by introducing a pipeline for keypoint descriptor synthesis using Neural Radiance Field (NeRF). By generating novel poses and feeding them into a trained NeRF model to create new views, our approach enhances the KSCR's generalization capabilities in data-scarce environments. The proposed system could significantly improve localization accuracy by up to 50\\% and cost only a fraction of time for data synthesis. Furthermore, its modular design allows for the integration of multiple NeRFs, offering a versatile and efficient solution for visual localization. The implementation is publicly available at: https://github.com/ais-lab/DescriptorSynthesis4Feat2Map. ",
    "url": "https://arxiv.org/abs/2403.10297",
    "authors": [
      "Huy-Hoang Bui",
      "Bach-Thuan Bui",
      "Dinh-Tuan Tran",
      "Joo-Ho Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10298",
    "title": "Context-Semantic Quality Awareness Network for Fine-Grained Visual  Categorization",
    "abstract": "Exploring and mining subtle yet distinctive features between sub-categories with similar appearances is crucial for fine-grained visual categorization (FGVC). However, less effort has been devoted to assessing the quality of extracted visual representations. Intuitively, the network may struggle to capture discriminative features from low-quality samples, which leads to a significant decline in FGVC performance. To tackle this challenge, we propose a weakly supervised Context-Semantic Quality Awareness Network (CSQA-Net) for FGVC. In this network, to model the spatial contextual relationship between rich part descriptors and global semantics for capturing more discriminative details within the object, we design a novel multi-part and multi-scale cross-attention (MPMSCA) module. Before feeding to the MPMSCA module, the part navigator is developed to address the scale confusion problems and accurately identify the local distinctive regions. Furthermore, we propose a generic multi-level semantic quality evaluation module (MLSQE) to progressively supervise and enhance hierarchical semantics from different levels of the backbone network. Finally, context-aware features from MPMSCA and semantically enhanced features from MLSQE are fed into the corresponding quality probing classifiers to evaluate their quality in real-time, thus boosting the discriminability of feature representations. Comprehensive experiments on four popular and highly competitive FGVC datasets demonstrate the superiority of the proposed CSQA-Net in comparison with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2403.10298",
    "authors": [
      "Qin Xu",
      "Sitong Li",
      "Jiahui Wang",
      "Bo Jiang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10303",
    "title": "An Investigation of the Factors Influencing Evolutionary Dynamics in the  Joint Evolution of Robot Body and Control",
    "abstract": "In evolutionary robotics, jointly optimising the design and the controller of robots is a challenging task due to the huge complexity of the solution space formed by the possible combinations of body and controller. We focus on the evolution of robots that can be physically created rather than just simulated, in a rich morphological space that includes a voxel-based chassis, wheels, legs and sensors. On the one hand, this space offers a high degree of liberty in the range of robots that can be produced, while on the other hand introduces a complexity rarely dealt with in previous works relating to matching controllers to designs and in evolving closed-loop control. This is usually addressed by augmenting evolution with a learning algorithm to refine controllers. Although several frameworks exist, few have studied the role of the \\textit{evolutionary dynamics} of the intertwined `evolution+learning' processes in realising high-performing robots. We conduct an in-depth study of the factors that influence these dynamics, specifically: synchronous vs asynchronous evolution; the mechanism for replacing parents with offspring, and rewarding goal-based fitness vs novelty via selection. Results show that asynchronicity combined with goal-based selection and a `replace worst' strategy results in the highest performance. ",
    "url": "https://arxiv.org/abs/2403.10303",
    "authors": [
      "L\u00e9ni K. Le Goff",
      "Edgar Buchanan",
      "Emma Hart"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10304",
    "title": "KIF: A Framework for Virtual Integration of Heterogeneous Knowledge  Bases using Wikidata",
    "abstract": "We present a knowledge integration framework (called KIF) that uses Wikidata as a lingua franca to integrate heterogeneous knowledge bases. These can be triplestores, relational databases, CSV files, etc., which may or may not use the Wikidata dialect of RDF. KIF leverages Wikidata's data model and vocabulary plus user-defined mappings to expose a unified view of the integrated bases while keeping track of the context and provenance of their statements. The result is a virtual knowledge base which behaves like an \"extended Wikidata\" and which can be queried either through an efficient filter interface or using SPARQL. We present the design and implementation of KIF, discuss how we have used it to solve a real integration problem in the domain of chemistry (involving Wikidata, PubChem, and IBM CIRCA), and present experimental results on the performance and overhead of KIF. ",
    "url": "https://arxiv.org/abs/2403.10304",
    "authors": [
      "Guilherme Lima",
      "Marcelo Machado",
      "Elton Soares",
      "Sandro R. Fiorini",
      "Raphael Thiago",
      "Leonardo G. Azevedo",
      "Viviane T. da Silva",
      "Renato Cerqueira"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2403.10307",
    "title": "Chernoff Information as a Privacy Constraint for Adversarial  Classification",
    "abstract": "This work studies a privacy metric based on Chernoff information, \\textit{Chernoff differential privacy}, due to its significance in characterization of classifier performance. Adversarial classification, as any other classification problem is built around minimization of the (average or correct detection) probability of error in deciding on either of the classes in the case of binary classification. Unlike the classical hypothesis testing problem, where the false alarm and mis-detection probabilities are handled separately resulting in an asymmetric behavior of the best error exponent, in this work, we focus on the Bayesian setting and characterize the relationship between the best error exponent of the average error probability and $\\varepsilon-$differential privacy. Accordingly, we re-derive Chernoff differential privacy in terms of $\\varepsilon-$differential privacy using the Radon-Nikodym derivative and show that it satisfies the composition property. Subsequently, we present numerical evaluation results, which demonstrates that Chernoff information outperforms Kullback-Leibler divergence as a function of the privacy parameter $\\varepsilon$, the impact of the adversary's attack and global sensitivity for the problem of adversarial classification in Laplace mechanisms. ",
    "url": "https://arxiv.org/abs/2403.10307",
    "authors": [
      "Ay\u015fe \u00dcnsal",
      "Melek \u00d6nen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2403.10318",
    "title": "Anytime Neural Architecture Search on Tabular Data",
    "abstract": "The increasing demand for tabular data analysis calls for transitioning from manual architecture design to Neural Architecture Search (NAS). This transition demands an efficient and responsive anytime NAS approach that is capable of returning current optimal architectures within any given time budget while progressively enhancing architecture quality with increased budget allocation. However, the area of research on Anytime NAS for tabular data remains unexplored. To this end, we introduce ATLAS, the first anytime NAS approach tailored for tabular data. ATLAS introduces a novel two-phase filtering-and-refinement optimization scheme with joint optimization, combining the strengths of both paradigms of training-free and training-based architecture evaluation. Specifically, in the filtering phase, ATLAS employs a new zero-cost proxy specifically designed for tabular data to efficiently estimate the performance of candidate architectures, thereby obtaining a set of promising architectures. Subsequently, in the refinement phase, ATLAS leverages a fixed-budget search algorithm to schedule the training of the promising candidates, so as to accurately identify the optimal architecture. To jointly optimize the two phases for anytime NAS, we also devise a budget-aware coordinator that delivers high NAS performance within constraints. Experimental evaluations demonstrate that our ATLAS can obtain a good-performing architecture within any predefined time budget and return better architectures as and when a new time budget is made available. Overall, it reduces the search time on tabular data by up to 82.75x compared to existing NAS approaches. ",
    "url": "https://arxiv.org/abs/2403.10318",
    "authors": [
      "Naili Xing",
      "Shaofeng Cai",
      "Zhaojing Luo",
      "BengChin Ooi",
      "Jian Pei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10319",
    "title": "NetBench: A Large-Scale and Comprehensive Network Traffic Benchmark  Dataset for Foundation Models",
    "abstract": "In computer networking, network traffic refers to the amount of data transmitted in the form of packets between internetworked computers or systems. Monitoring and analyzing network traffic is crucial for ensuring the performance, security, and reliability of a network. However, a significant challenge in network traffic analysis is to process diverse data packets including both ciphertext and plaintext. While many methods have been adopted to analyze network traffic, they often rely on different datasets for performance evaluation. This inconsistency results in substantial manual data processing efforts and unfair comparisons. Moreover, some data processing methods may cause data leakage due to improper separation of training and test data. To address these issues, we introduce NetBench, a large-scale and comprehensive benchmark dataset for assessing machine learning models, especially foundation models, in both traffic classification and generation tasks. NetBench is built upon seven publicly available datasets and encompasses a broad spectrum of 20 tasks, including 15 classification tasks and 5 generation tasks. Furthermore, we evaluate eight State-Of-The-Art (SOTA) classification models and two generative models using our benchmark. The results show that foundation models significantly outperform the traditional deep learning methods in traffic classification. We believe NetBench will facilitate fair comparisons among various approaches and advance the development of foundation models for network traffic. Our benchmark is available at https://github.com/WM-JayLab/NetBench. ",
    "url": "https://arxiv.org/abs/2403.10319",
    "authors": [
      "Chen Qian",
      "Xiaochang Li",
      "Qineng Wang",
      "Gang Zhou",
      "Huajie Shao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.10335",
    "title": "NECA: Neural Customizable Human Avatar",
    "abstract": "Human avatar has become a novel type of 3D asset with various applications. Ideally, a human avatar should be fully customizable to accommodate different settings and environments. In this work, we introduce NECA, an approach capable of learning versatile human representation from monocular or sparse-view videos, enabling granular customization across aspects such as pose, shadow, shape, lighting and texture. The core of our approach is to represent humans in complementary dual spaces and predict disentangled neural fields of geometry, albedo, shadow, as well as an external lighting, from which we are able to derive realistic rendering with high-frequency details via volumetric rendering. Extensive experiments demonstrate the advantage of our method over the state-of-the-art methods in photorealistic rendering, as well as various editing tasks such as novel pose synthesis and relighting. The code is available at https://github.com/iSEE-Laboratory/NECA. ",
    "url": "https://arxiv.org/abs/2403.10335",
    "authors": [
      "Junjin Xiao",
      "Qing Zhang",
      "Zhan Xu",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10339",
    "title": "Generation is better than Modification: Combating High Class Homophily  Variance in Graph Anomaly Detection",
    "abstract": "Graph-based anomaly detection is currently an important research topic in the field of graph neural networks (GNNs). We find that in graph anomaly detection, the homophily distribution differences between different classes are significantly greater than those in homophilic and heterophilic graphs. For the first time, we introduce a new metric called Class Homophily Variance, which quantitatively describes this phenomenon. To mitigate its impact, we propose a novel GNN model named Homophily Edge Generation Graph Neural Network (HedGe). Previous works typically focused on pruning, selecting or connecting on original relationships, and we refer to these methods as modifications. Different from these works, our method emphasizes generating new relationships with low class homophily variance, using the original relationships as an auxiliary. HedGe samples homophily adjacency matrices from scratch using a self-attention mechanism, and leverages nodes that are relevant in the feature space but not directly connected in the original graph. Additionally, we modify the loss function to punish the generation of unnecessary heterophilic edges by the model. Extensive comparison experiments demonstrate that HedGe achieved the best performance across multiple benchmark datasets, including anomaly detection and edgeless node classification. The proposed model also improves the robustness under the novel Heterophily Attack with increased class homophily variance on other graph classification tasks. ",
    "url": "https://arxiv.org/abs/2403.10339",
    "authors": [
      "Rui Zhang",
      "Dawei Cheng",
      "Xin Liu",
      "Jie Yang",
      "Yi Ouyang",
      "Xian Wu",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10340",
    "title": "Thermal-NeRF: Neural Radiance Fields from an Infrared Camera",
    "abstract": "In recent years, Neural Radiance Fields (NeRFs) have demonstrated significant potential in encoding highly-detailed 3D geometry and environmental appearance, positioning themselves as a promising alternative to traditional explicit representation for 3D scene reconstruction. However, the predominant reliance on RGB imaging presupposes ideal lighting conditions: a premise frequently unmet in robotic applications plagued by poor lighting or visual obstructions. This limitation overlooks the capabilities of infrared (IR) cameras, which excel in low-light detection and present a robust alternative under such adverse scenarios. To tackle these issues, we introduce Thermal-NeRF, the first method that estimates a volumetric scene representation in the form of a NeRF solely from IR imaging. By leveraging a thermal mapping and structural thermal constraint derived from the thermal characteristics of IR imaging, our method showcasing unparalleled proficiency in recovering NeRFs in visually degraded scenes where RGB-based methods fall short. We conduct extensive experiments to demonstrate that Thermal-NeRF can achieve superior quality compared to existing methods. Furthermore, we contribute a dataset for IR-based NeRF applications, paving the way for future research in IR NeRF reconstruction. ",
    "url": "https://arxiv.org/abs/2403.10340",
    "authors": [
      "Tianxiang Ye",
      "Qi Wu",
      "Junyuan Deng",
      "Guoqing Liu",
      "Liu Liu",
      "Songpengcheng Xia",
      "Liang Pang",
      "Wenxian Yu",
      "Ling Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.10353",
    "title": "SimPB: A Single Model for 2D and 3D Object Detection from Multiple  Cameras",
    "abstract": "The field of autonomous driving has attracted considerable interest in approaches that directly infer 3D objects in the Bird's Eye View (BEV) from multiple cameras. Some attempts have also explored utilizing 2D detectors from single images to enhance the performance of 3D detection. However, these approaches rely on a two-stage process with separate detectors, where the 2D detection results are utilized only once for token selection or query initialization. In this paper, we present a single model termed SimPB, which simultaneously detects 2D objects in the perspective view and 3D objects in the BEV space from multiple cameras. To achieve this, we introduce a hybrid decoder consisting of several multi-view 2D decoder layers and several 3D decoder layers, specifically designed for their respective detection tasks. A Dynamic Query Allocation module and an Adaptive Query Aggregation module are proposed to continuously update and refine the interaction between 2D and 3D results, in a cyclic 3D-2D-3D manner. Additionally, Query-group Attention is utilized to strengthen the interaction among 2D queries within each camera group. In the experiments, we evaluate our method on the nuScenes dataset and demonstrate promising results for both 2D and 3D detection tasks. Our code is available at: https://github.com/nullmax-vision/SimPB. ",
    "url": "https://arxiv.org/abs/2403.10353",
    "authors": [
      "Yingqi Tang",
      "Zhaotie Meng",
      "Guoliang Chen",
      "Erkang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10356",
    "title": "Understanding Stress: A Web Interface for Mental Arithmetic Tasks in a  Trier Social Stress Test",
    "abstract": "Stress is a dynamic process that reflects the responses of the brain. Traditional methods for measuring stress are often time-consuming and susceptible to recall bias. To address this, we investigated changes in heart rate (HR) during the Trier Social Stress Test (TSST). Our study incorporated varying levels of complexity in mental arithmetic problems. Participants' HR increased during the Mental Arithmetic Task phase compared to baseline and resting stages, indicating that stress is reflected in HR. ",
    "url": "https://arxiv.org/abs/2403.10356",
    "authors": [
      "Manjeet Yadav",
      "Nilesh Kumar Sahu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2403.10357",
    "title": "ANIM: Accurate Neural Implicit Model for Human Reconstruction from a  single RGB-D image",
    "abstract": "Recent progress in human shape learning, shows that neural implicit models are effective in generating 3D human surfaces from limited number of views, and even from a single RGB image. However, existing monocular approaches still struggle to recover fine geometric details such as face, hands or cloth wrinkles. They are also easily prone to depth ambiguities that result in distorted geometries along the camera optical axis. In this paper, we explore the benefits of incorporating depth observations in the reconstruction process by introducing ANIM, a novel method that reconstructs arbitrary 3D human shapes from single-view RGB-D images with an unprecedented level of accuracy. Our model learns geometric details from both multi-resolution pixel-aligned and voxel-aligned features to leverage depth information and enable spatial relationships, mitigating depth ambiguities. We further enhance the quality of the reconstructed shape by introducing a depth-supervision strategy, which improves the accuracy of the signed distance field estimation of points that lie on the reconstructed surface. Experiments demonstrate that ANIM outperforms state-of-the-art works that use RGB, surface normals, point cloud or RGB-D data as input. In addition, we introduce ANIM-Real, a new multi-modal dataset comprising high-quality scans paired with consumer-grade RGB-D camera, and our protocol to fine-tune ANIM, enabling high-quality reconstruction from real-world human capture. ",
    "url": "https://arxiv.org/abs/2403.10357",
    "authors": [
      "Marco Pesavento",
      "Yuanlu Xu",
      "Nikolaos Sarafianos",
      "Robert Maier",
      "Ziyan Wang",
      "Chun-Han Yao",
      "Marco Volino",
      "Edmond Boyer",
      "Adrian Hilton",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2403.10381",
    "title": "Monotonic Representation of Numeric Properties in Language Models",
    "abstract": "Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model's internal representations is not understood well. Here, we introduce a simple method for finding and editing representations of numeric properties such as an entity's birth year. Empirically, we find low-dimensional subspaces that encode numeric properties monotonically, in an interpretable and editable fashion. When editing representations along directions in these subspaces, LM output changes accordingly. For example, by patching activations along a \"birthyear\" direction we can make the LM express an increasingly late birthyear: Karl Popper was born in 1929, Karl Popper was born in 1957, Karl Popper was born in 1968. Property-encoding directions exist across several numeric properties in all models under consideration, suggesting the possibility that monotonic representation of numeric properties consistently emerges during LM pretraining. Code: https://github.com/bheinzerling/numeric-property-repr ",
    "url": "https://arxiv.org/abs/2403.10381",
    "authors": [
      "Benjamin Heinzerling",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.10395",
    "title": "Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding",
    "abstract": "Encouraged by the growing availability of pre-trained 2D diffusion models, image-to-3D generation by leveraging Score Distillation Sampling (SDS) is making remarkable progress. Most existing methods combine novel-view lifting from 2D diffusion models which usually take the reference image as a condition while applying hard L2 image supervision at the reference view. Yet heavily adhering to the image is prone to corrupting the inductive knowledge of the 2D diffusion model leading to flat or distorted 3D generation frequently. In this work, we reexamine image-to-3D in a novel perspective and present Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input. Isotropic3D allows the optimization to be isotropic w.r.t. the azimuth angle by solely resting on the SDS loss. The core of our framework lies in a two-stage diffusion model fine-tuning. Firstly, we fine-tune a text-to-3D diffusion model by substituting its text encoder with an image encoder, by which the model preliminarily acquires image-to-image capabilities. Secondly, we perform fine-tuning using our Explicit Multi-view Attention (EMA) which combines noisy multi-view images with the noise-free reference image as an explicit condition. CLIP embedding is sent to the diffusion model throughout the whole process while reference images are discarded once after fine-tuning. As a result, with a single image CLIP embedding, Isotropic3D is capable of generating multi-view mutually consistent images and also a 3D model with more symmetrical and neat content, well-proportioned geometry, rich colored texture, and less distortion compared with existing image-to-3D methods while still preserving the similarity to the reference image to a large extent. The project page is available at https://isotropic3d.github.io/. The code and models are available at https://github.com/pkunliu/Isotropic3D. ",
    "url": "https://arxiv.org/abs/2403.10395",
    "authors": [
      "Pengkun Liu",
      "Yikai Wang",
      "Fuchun Sun",
      "Jiafang Li",
      "Hang Xiao",
      "Hongxiang Xue",
      "Xinzhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10396",
    "title": "On well-posedness of the leak localization problem in parallel pipe  networks",
    "abstract": "With the advent of integrated sensor technology (smart flow meters and pressure sensors), various new numerical algorithms for leak localization (a core element of water distribution system operation) have been developed. However, there is a lack of theory regarding the limitations of leak localization. In this work, we contribute to the development of such a theory by introducing an example water network structure with parallel pipes that is tractable for analytical treatment. We define the leak localization problem for this structure and show how many sensors and what conditions are needed for the well-posedness of the problem. We present a formula for the leak position as a function of measurements from these sensors. However, we also highlight the risk of finding false but plausible leak positions in the multiple pipes. We try to answer the questions of how and when the leaking pipe can be isolated. In particular, we show that nonlinearities in the pipes' head loss functions are essential for the well-posedness of the isolation problem. We propose procedures to get around the pitfall of multiple plausible leak positions. ",
    "url": "https://arxiv.org/abs/2403.10396",
    "authors": [
      "Victor Moln\u00f6",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.10403",
    "title": "Energy Correction Model in the Feature Space for Out-of-Distribution  Detection",
    "abstract": "In this work, we study the out-of-distribution (OOD) detection problem through the use of the feature space of a pre-trained deep classifier. We show that learning the density of in-distribution (ID) features with an energy-based models (EBM) leads to competitive detection results. However, we found that the non-mixing of MCMC sampling during the EBM's training undermines its detection performance. To overcome this an energy-based correction of a mixture of class-conditional Gaussian distributions. We obtains favorable results when compared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100 OOD detection benchmarks. ",
    "url": "https://arxiv.org/abs/2403.10403",
    "authors": [
      "Marc Lafon",
      "Cl\u00e9ment Rambour",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10406",
    "title": "Deep Bi-directional Attention Network for Image Super-Resolution Quality  Assessment",
    "abstract": "There has emerged a growing interest in exploring efficient quality assessment algorithms for image super-resolution (SR). However, employing deep learning techniques, especially dual-branch algorithms, to automatically evaluate the visual quality of SR images remains challenging. Existing SR image quality assessment (IQA) metrics based on two-stream networks lack interactions between branches. To address this, we propose a novel full-reference IQA (FR-IQA) method for SR images. Specifically, producing SR images and evaluating how close the SR images are to the corresponding HR references are separate processes. Based on this consideration, we construct a deep Bi-directional Attention Network (BiAtten-Net) that dynamically deepens visual attention to distortions in both processes, which aligns well with the human visual system (HVS). Experiments on public SR quality databases demonstrate the superiority of our proposed BiAtten-Net over state-of-the-art quality assessment methods. In addition, the visualization results and ablation study show the effectiveness of bi-directional attention. ",
    "url": "https://arxiv.org/abs/2403.10406",
    "authors": [
      "Yixiao Li",
      "Xiaoyuan Yang",
      "Jun Fu",
      "Guanghui Yue",
      "Wei Zhou"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.10408",
    "title": "SocialGenPod: Privacy-Friendly Generative AI Social Web Applications  with Decentralised Personal Data Stores",
    "abstract": "We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid -- a decentralised Web specification -- to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user's personal Pod; separate from specific model or application providers. Besides better privacy controls, this approach also enables portability across different services and applications. Finally, we discuss challenges, posed by the large compute requirements of state-of-the-art models, that future research in this area should address. Our prototype is open-source and available at: https://github.com/Vidminas/socialgenpod/. ",
    "url": "https://arxiv.org/abs/2403.10408",
    "authors": [
      "Vidminas Vizgirda",
      "Rui Zhao",
      "Naman Goel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2403.10416",
    "title": "Robust Sparse Estimation for Gaussians with Optimal Error under Huber  Contamination",
    "abstract": "We study Gaussian sparse estimation tasks in Huber's contamination model with a focus on mean estimation, PCA, and linear regression. For each of these tasks, we give the first sample and computationally efficient robust estimators with optimal error guarantees, within constant factors. All prior efficient algorithms for these tasks incur quantitatively suboptimal error. Concretely, for Gaussian robust $k$-sparse mean estimation on $\\mathbb{R}^d$ with corruption rate $\\epsilon>0$, our algorithm has sample complexity $(k^2/\\epsilon^2)\\mathrm{polylog}(d/\\epsilon)$, runs in sample polynomial time, and approximates the target mean within $\\ell_2$-error $O(\\epsilon)$. Previous efficient algorithms inherently incur error $\\Omega(\\epsilon \\sqrt{\\log(1/\\epsilon)})$. At the technical level, we develop a novel multidimensional filtering method in the sparse regime that may find other applications. ",
    "url": "https://arxiv.org/abs/2403.10416",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Sushrut Karmalkar",
      "Ankit Pensia",
      "Thanasis Pittas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2403.10452",
    "title": "Robust Shape Fitting for 3D Scene Abstraction",
    "abstract": "Humans perceive and construct the world as an arrangement of simple parametric models. In particular, we can often describe man-made environments using volumetric primitives such as cuboids or cylinders. Inferring these primitives is important for attaining high-level, abstract scene descriptions. Previous approaches for primitive-based abstraction estimate shape parameters directly and are only able to reproduce simple objects. In contrast, we propose a robust estimator for primitive fitting, which meaningfully abstracts complex real-world environments using cuboids. A RANSAC estimator guided by a neural network fits these primitives to a depth map. We condition the network on previously detected parts of the scene, parsing it one-by-one. To obtain cuboids from single RGB images, we additionally optimise a depth estimation CNN end-to-end. Naively minimising point-to-primitive distances leads to large or spurious cuboids occluding parts of the scene. We thus propose an improved occlusion-aware distance metric correctly handling opaque scenes. Furthermore, we present a neural network based cuboid solver which provides more parsimonious scene abstractions while also reducing inference time. The proposed algorithm does not require labour-intensive labels, such as cuboid annotations, for training. Results on the NYU Depth v2 dataset demonstrate that the proposed algorithm successfully abstracts cluttered real-world 3D scene layouts. ",
    "url": "https://arxiv.org/abs/2403.10452",
    "authors": [
      "Florian Kluger",
      "Eric Brachmann",
      "Michael Ying Yang",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10461",
    "title": "Introducing Adaptive Continuous Adversarial Training (ACAT) to Enhance  ML Robustness",
    "abstract": "Machine Learning (ML) is susceptible to adversarial attacks that aim to trick ML models, making them produce faulty predictions. Adversarial training was found to increase the robustness of ML models against these attacks. However, in network and cybersecurity, obtaining labeled training and adversarial training data is challenging and costly. Furthermore, concept drift deepens the challenge, particularly in dynamic domains like network and cybersecurity, and requires various models to conduct periodic retraining. This letter introduces Adaptive Continuous Adversarial Training (ACAT) to continuously integrate adversarial training samples into the model during ongoing learning sessions, using real-world detected adversarial data, to enhance model resilience against evolving adversarial threats. ACAT is an adaptive defense mechanism that utilizes periodic retraining to effectively counter adversarial attacks while mitigating catastrophic forgetting. Our approach also reduces the total time required for adversarial sample detection, especially in environments such as network security where the rate of attacks could be very high. Traditional detection processes that involve two stages may result in lengthy procedures. Experimental results using a SPAM detection dataset demonstrate that with ACAT, the accuracy of the SPAM filter increased from 69% to over 88% after just three retraining sessions. Furthermore, ACAT outperforms conventional adversarial sample detectors, providing faster decision times, up to four times faster in some cases. ",
    "url": "https://arxiv.org/abs/2403.10461",
    "authors": [
      "Mohamed elShehaby",
      "Aditya Kotha",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2403.10476",
    "title": "Approximate Nullspace Augmented Finetuning for Robust Vision  Transformers",
    "abstract": "Enhancing the robustness of deep learning models, particularly in the realm of vision transformers (ViTs), is crucial for their real-world deployment. In this work, we provide a finetuning approach to enhance the robustness of vision transformers inspired by the concept of nullspace from linear algebra. Our investigation centers on whether a vision transformer can exhibit resilience to input variations akin to the nullspace property in linear mappings, implying that perturbations sampled from this nullspace do not influence the model's output when added to the input. Firstly, we show that for many pretrained ViTs, a non-trivial nullspace exists due to the presence of the patch embedding layer. Secondly, as nullspace is a concept associated with linear algebra, we demonstrate that it is possible to synthesize approximate nullspace elements for the non-linear blocks of ViTs employing an optimisation strategy. Finally, we propose a fine-tuning strategy for ViTs wherein we augment the training data with synthesized approximate nullspace noise. After finetuning, we find that the model demonstrates robustness to adversarial and natural image perbutations alike. ",
    "url": "https://arxiv.org/abs/2403.10476",
    "authors": [
      "Haoyang Liu",
      "Aditya Singh",
      "Yijiang Li",
      "Haohan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10492",
    "title": "Mitigating Dialogue Hallucination for Large Multi-modal Models via  Adversarial Instruction Tuning",
    "abstract": "Mitigating hallucinations of Large Multi-modal Models(LMMs) is crucial to enhance their reliability for general-purpose assistants. This paper shows that such hallucinations of LMMs can be significantly exacerbated by preceding user-system dialogues. To precisely measure this, we first present an evaluation benchmark by extending popular multi-modal benchmark datasets with prepended hallucinatory dialogues generated by our novel Adversarial Question Generator, which can automatically generate image-related yet adversarial dialogues by adopting adversarial attacks on LMMs. On our benchmark, the zero-shot performance of state-of-the-art LMMs dropped significantly for both the VQA and Captioning tasks. Next, we further reveal this hallucination is mainly due to the prediction bias toward preceding dialogues rather than visual content. To reduce this bias, we propose Adversarial Instruction Tuning that robustly fine-tunes LMMs on augmented multi-modal instruction-following datasets with hallucinatory dialogues. Extensive experiments show that our proposed approach successfully reduces dialogue hallucination while maintaining or even improving performance. ",
    "url": "https://arxiv.org/abs/2403.10492",
    "authors": [
      "Dongmin Park",
      "Zhaofang Qian",
      "Guangxing Han",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10497",
    "title": "Data-Driven Distributionally Robust Safety Verification Using Barrier  Certificates and Conditional Mean Embeddings",
    "abstract": "Algorithmic verification of realistic systems to satisfy safety and other temporal requirements has suffered from poor scalability of the employed formal approaches. To design systems with rigorous guarantees, many approaches still rely on exact models of the underlying systems. Since this assumption can rarely be met in practice, models have to be inferred from measurement data or are bypassed completely. Whilst former usually requires the model structure to be known a-priori and immense amounts of data to be available, latter gives rise to a plethora of restrictive mathematical assumptions about the unknown dynamics. In a pursuit of developing scalable formal verification algorithms without shifting the problem to unrealistic assumptions, we employ the concept of barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a compact set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result w.r.t. a set of plausible transition kernels. We show how to solve the resulting program efficiently using sum-of-squares optimization and a Gaussian process envelope. Our approach lifts the need for restrictive assumptions on the system dynamics and uncertainty, and suggests an improvement in the sample complexity of verifying the safety of a system on a tested case study compared to a state-of-the-art approach. ",
    "url": "https://arxiv.org/abs/2403.10497",
    "authors": [
      "Oliver Sch\u00f6n",
      "Zhengang Zhong",
      "Sadegh Soudjani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10499",
    "title": "Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A  Pilot Study",
    "abstract": "Pre-training image representations from the raw text about images enables zero-shot vision transfer to downstream tasks. Through pre-training on millions of samples collected from the internet, multimodal foundation models, such as CLIP, produce state-of-the-art zero-shot results that often reach competitiveness with fully supervised methods without the need for task-specific training. Besides the encouraging performance on classification accuracy, it is reported that these models close the robustness gap by matching the performance of supervised models trained on ImageNet under natural distribution shift. Because robustness is critical to real-world applications, especially safety-critical ones, in this paper, we present a comprehensive evaluation based on a large-scale robustness benchmark covering 7 natural, 3 synthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a pilot study. We show that CLIP leads to a significant robustness drop compared to supervised ImageNet models on our benchmark, especially under synthetic distribution shift and adversarial attacks. Furthermore, data overlap analysis suggests that the observed robustness under natural distribution shifts could be attributed, at least in part, to data overlap. In summary, our evaluation shows a comprehensive evaluation of robustness is necessary; and there is a significant need to improve the robustness of zero-shot multimodal models. ",
    "url": "https://arxiv.org/abs/2403.10499",
    "authors": [
      "Chenguang Wang",
      "Ruoxi Jia",
      "Xin Liu",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10507",
    "title": "Demystifying Faulty Code with LLM: Step-by-Step Reasoning for  Explainable Fault Localization",
    "abstract": "Fault localization is a critical process that involves identifying specific program elements responsible for program failures. Manually pinpointing these elements, such as classes, methods, or statements, which are associated with a fault is laborious and time-consuming. To overcome this challenge, various fault localization tools have been developed. These tools typically generate a ranked list of suspicious program elements. However, this information alone is insufficient. A prior study emphasized that automated fault localization should offer a rationale. In this study, we investigate the step-by-step reasoning for explainable fault localization. We explore the potential of Large Language Models (LLM) in assisting developers in reasoning about code. We proposed FuseFL that utilizes several combinations of information to enhance the LLM results which are spectrum-based fault localization results, test case execution outcomes, and code description (i.e., explanation of what the given code is intended to do). We conducted our investigation using faulty code from Refactory dataset. First, we evaluate the performance of the automated fault localization. Our results demonstrate a more than 30% increase in the number of successfully localized faults at Top-1 compared to the baseline. To evaluate the explanations generated by FuseFL, we create a dataset of human explanations that provide step-by-step reasoning as to why specific lines of code are considered faulty. This dataset consists of 324 faulty code files, along with explanations for 600 faulty lines. Furthermore, we also conducted human studies to evaluate the explanations. We found that for 22 out of the 30 randomly sampled cases, FuseFL generated correct explanations. ",
    "url": "https://arxiv.org/abs/2403.10507",
    "authors": [
      "Ratnadira Widyasari",
      "Jia Wei Ang",
      "Truong Giang Nguyen",
      "Neil Sharma",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2403.10511",
    "title": "A Novel Framework for Multi-Person Temporal Gaze Following and Social  Gaze Prediction",
    "abstract": "Gaze following and social gaze prediction are fundamental tasks providing insights into human communication behaviors, intent, and social interactions. Most previous approaches addressed these tasks separately, either by designing highly specialized social gaze models that do not generalize to other social gaze tasks or by considering social gaze inference as an ad-hoc post-processing of the gaze following task. Furthermore, the vast majority of gaze following approaches have proposed static models that can handle only one person at a time, therefore failing to take advantage of social interactions and temporal dynamics. In this paper, we address these limitations and introduce a novel framework to jointly predict the gaze target and social gaze label for all people in the scene. The framework comprises of: (i) a temporal, transformer-based architecture that, in addition to image tokens, handles person-specific tokens capturing the gaze information related to each individual; (ii) a new dataset, VSGaze, that unifies annotation types across multiple gaze following and social gaze datasets. We show that our model trained on VSGaze can address all tasks jointly, and achieves state-of-the-art results for multi-person gaze following and social gaze prediction. ",
    "url": "https://arxiv.org/abs/2403.10511",
    "authors": [
      "Anshul Gupta",
      "Samy Tafasca",
      "Arya Farkhondeh",
      "Pierre Vuillecard",
      "Jean-Marc Odobez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10518",
    "title": "Lodge: A Coarse to Fine Diffusion Network for Long Dance Generation  Guided by the Characteristic Dance Primitives",
    "abstract": "We propose Lodge, a network capable of generating extremely long dance sequences conditioned on given music. We design Lodge as a two-stage coarse to fine diffusion architecture, and propose the characteristic dance primitives that possess significant expressiveness as intermediate representations between two diffusion models. The first stage is global diffusion, which focuses on comprehending the coarse-level music-dance correlation and production characteristic dance primitives. In contrast, the second-stage is the local diffusion, which parallelly generates detailed motion sequences under the guidance of the dance primitives and choreographic rules. In addition, we propose a Foot Refine Block to optimize the contact between the feet and the ground, enhancing the physical realism of the motion. Our approach can parallelly generate dance sequences of extremely long length, striking a balance between global choreographic patterns and local motion quality and expressiveness. Extensive experiments validate the efficacy of our method. ",
    "url": "https://arxiv.org/abs/2403.10518",
    "authors": [
      "Ronghui Li",
      "YuXiang Zhang",
      "Yachao Zhang",
      "Hongwen Zhang",
      "Jie Guo",
      "Yan Zhang",
      "Yebin Liu",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.10519",
    "title": "Frozen Feature Augmentation for Few-Shot Image Classification",
    "abstract": "Training a linear classifier or lightweight model on top of pretrained vision model outputs, so-called 'frozen features', leads to impressive performance on a number of downstream few-shot tasks. Currently, frozen features are not modified during training. On the other hand, when networks are trained directly on images, data augmentation is a standard recipe that improves performance with no substantial overhead. In this paper, we conduct an extensive pilot study on few-shot image classification that explores applying data augmentations in the frozen feature space, dubbed 'frozen feature augmentation (FroFA)', covering twenty augmentations in total. Our study demonstrates that adopting a deceptively simple pointwise FroFA, such as brightness, can improve few-shot performance consistently across three network architectures, three large pretraining datasets, and eight transfer datasets. ",
    "url": "https://arxiv.org/abs/2403.10519",
    "authors": [
      "Andreas B\u00e4r",
      "Neil Houlsby",
      "Mostafa Dehghani",
      "Manoj Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09758",
    "title": "Reconstructing Blood Flow in Data-Poor Regimes: A Vasculature Network  Kernel for Gaussian Process Regression",
    "abstract": "Blood flow reconstruction in the vasculature is important for many clinical applications. However, in clinical settings, the available data are often quite limited. For instance, Transcranial Doppler ultrasound (TCD) is a noninvasive clinical tool that is commonly used in the clinical settings to measure blood velocity waveform at several locations on brain's vasculature. This amount of data is grossly insufficient for training machine learning surrogate models, such as deep neural networks or Gaussian process regression. In this work, we propose a Gaussian process regression approach based on physics-informed kernels, enabling near-real-time reconstruction of blood flow in data-poor regimes. We introduce a novel methodology to reconstruct the kernel within the vascular network, which is a non-Euclidean space. The proposed kernel encodes both spatiotemporal and vessel-to-vessel correlations, thus enabling blood flow reconstruction in vessels that lack direct measurements. We demonstrate that any prediction made with the proposed kernel satisfies the conservation of mass principle. The kernel is constructed by running stochastic one-dimensional blood flow simulations, where the stochasticity captures the epistemic uncertainties, such as lack of knowledge about boundary conditions and uncertainties in vasculature geometries. We demonstrate the performance of the model on three test cases, namely, a simple Y-shaped bifurcation, abdominal aorta, and the Circle of Willis in the brain. ",
    "url": "https://arxiv.org/abs/2403.09758",
    "authors": [
      "Shaghayegh Z. Ashtiani",
      "Mohammad Sarabian",
      "Kaveh Laksari",
      "Hessam Babaee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09828",
    "title": "Analyzing Data Augmentation for Medical Images: A Case Study in  Ultrasound Images",
    "abstract": "Data augmentation is one of the most effective techniques to improve the generalization performance of deep neural networks. Yet, despite often facing limited data availability in medical image analysis, it is frequently underutilized. This appears to be due to a gap in our collective understanding of the efficacy of different augmentation techniques across medical imaging tasks and modalities. One domain where this is especially true is breast ultrasound images. This work addresses this issue by analyzing the effectiveness of different augmentation techniques for the classification of breast lesions in ultrasound images. We assess the generalizability of our findings across several datasets, demonstrate that certain augmentations are far more effective than others, and show that their usage leads to significant performance gains. ",
    "url": "https://arxiv.org/abs/2403.09828",
    "authors": [
      "Adam Tupper",
      "Christian Gagn\u00e9"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09869",
    "title": "Mind the GAP: Improving Robustness to Subpopulation Shifts with  Group-Aware Priors",
    "abstract": "Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance -- even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts. ",
    "url": "https://arxiv.org/abs/2403.09869",
    "authors": [
      "Tim G. J. Rudner",
      "Ya Shi Zhang",
      "Andrew Gordon Wilson",
      "Julia Kempe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2403.09942",
    "title": "Attention-Enhanced Hybrid Feature Aggregation Network for 3D Brain Tumor  Segmentation",
    "abstract": "Glioblastoma is a highly aggressive and malignant brain tumor type that requires early diagnosis and prompt intervention. Due to its heterogeneity in appearance, developing automated detection approaches is challenging. To address this challenge, Artificial Intelligence (AI)-driven approaches in healthcare have generated interest in efficiently diagnosing and evaluating brain tumors. The Brain Tumor Segmentation Challenge (BraTS) is a platform for developing and assessing automated techniques for tumor analysis using high-quality, clinically acquired MRI data. In our approach, we utilized a multi-scale, attention-guided and hybrid U-Net-shaped model -- GLIMS -- to perform 3D brain tumor segmentation in three regions: Enhancing Tumor (ET), Tumor Core (TC), and Whole Tumor (WT). The multi-scale feature extraction provides better contextual feature aggregation in high resolutions and the Swin Transformer blocks improve the global feature extraction at deeper levels of the model. The segmentation mask generation in the decoder branch is guided by the attention-refined features gathered from the encoder branch to enhance the important attributes. Moreover, hierarchical supervision is used to train the model efficiently. Our model's performance on the validation set resulted in 92.19, 87.75, and 83.18 Dice Scores and 89.09, 84.67, and 82.15 Lesion-wise Dice Scores in WT, TC, and ET, respectively. The code is publicly available at https://github.com/yaziciz/GLIMS. ",
    "url": "https://arxiv.org/abs/2403.09942",
    "authors": [
      "Ziya Ata Yaz\u0131c\u0131",
      "\u0130lkay \u00d6ks\u00fcz",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.09961",
    "title": "Thermal Earth Model for the Conterminous United States Using an  Interpolative Physics-Informed Graph Neural Network (InterPIGNN)",
    "abstract": "This study presents a data-driven spatial interpolation algorithm based on physics-informed graph neural networks used to develop national temperature-at-depth maps for the conterminous United States. The model was trained to approximately satisfy the three-dimensional heat conduction law by simultaneously predicting subsurface temperature, surface heat flow, and rock thermal conductivity. In addition to bottomhole temperature measurements, we incorporated other physical quantities as model inputs, such as depth, geographic coordinates, elevation, sediment thickness, magnetic anomaly, gravity anomaly, gamma-ray flux of radioactive elements, seismicity, and electric conductivity. We constructed surface heat flow, and temperature and thermal conductivity predictions for depths of 0-7 km at an interval of 1 km with spatial resolution of 18 km$^2$ per grid cell. Our model showed superior temperature, surface heat flow and thermal conductivity mean absolute errors of 4.8{\\deg} C, 5.817 mW/m$^2$ and 0.022 W/(C-m)$, respectively. The predictions were visualized in two-dimensional spatial maps across the modeled depths. This thorough modeling of the Earth's thermal processes is crucial to understanding subsurface phenomena and exploiting natural underground resources. ",
    "url": "https://arxiv.org/abs/2403.09961",
    "authors": [
      "Mohammad J. Aljubran",
      "Roland N. Horne"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.10067",
    "title": "Hybrid Convolutional and Attention Network for Hyperspectral Image  Denoising",
    "abstract": "Hyperspectral image (HSI) denoising is critical for the effective analysis and interpretation of hyperspectral data. However, simultaneously modeling global and local features is rarely explored to enhance HSI denoising. In this letter, we propose a hybrid convolution and attention network (HCANet), which leverages both the strengths of convolution neural networks (CNNs) and Transformers. To enhance the modeling of both global and local features, we have devised a convolution and attention fusion module aimed at capturing long-range dependencies and neighborhood spectral correlations. Furthermore, to improve multi-scale information aggregation, we design a multi-scale feed-forward network to enhance denoising performance by extracting features at different scales. Experimental results on mainstream HSI datasets demonstrate the rationality and effectiveness of the proposed HCANet. The proposed model is effective in removing various types of complex noise. Our codes are available at \\url{https://github.com/summitgao/HCANet}. ",
    "url": "https://arxiv.org/abs/2403.10067",
    "authors": [
      "Shuai Hu",
      "Feng Gao",
      "Xiaowei Zhou",
      "Junyu Dong",
      "Qian Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10270",
    "title": "Discrete functional inequalities on lattice graphs",
    "abstract": "In this thesis, we study problems at the interface of analysis and discrete mathematics. We discuss analogues of well known Hardy-type inequalities and Rearrangement inequalities on the lattice graphs $\\mathbb{Z}^d$, with a particular focus on behaviour of sharp constants and optimizers.In the first half of the thesis, we analyse Hardy inequalities on $\\mathbb{Z}^d$, first for $d=1$ and then for $d \\geq 3$. We prove a sharp weighted Hardy inequality on integers with power weights of the form $n^\\alpha$. This is done via two different methods, namely super-solution and Fourier method. We also use Fourier method to prove a weighted Hardy type inequality for higher order operators. After discussing the one dimensional case, we study the Hardy inequality in higher dimensions ($d \\geq 3$). In particular, we compute the asymptotic behaviour of the sharp constant in the discrete Hardy inequality, as $d \\rightarrow \\infty$. This is done by converting the inequality into a continuous Hardy-type inequality on a torus for functions having zero average. These continuous inequalities are new and interesting in themselves. In the second half, we focus our attention on analogues of Rearrangement inequalities on lattice graphs. We begin by analysing the situation in dimension one. We define various notions of rearrangements and prove the corresponding Polya-Szeg\\H{o} inequality. These inequalities are also applied to prove some weighted Hardy inequalities on integers. Finally, we study Rearrangement inequalities (Polya-Szeg\\H{o}) on general graphs, with a particular focus on lattice graphs $\\mathbb{Z}^d$, for $d \\geq 2$. We develop a framework to study these inequalities, using which we derive concrete results in dimension two. In particular, these results develop connections between Polya-Szeg\\H{o} inequality and various isoperimetric inequalities on graphs. ",
    "url": "https://arxiv.org/abs/2403.10270",
    "authors": [
      "Shubham Gupta"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2403.10362",
    "title": "CPGA: Coding Priors-Guided Aggregation Network for Compressed Video  Quality Enhancement",
    "abstract": "Recently, numerous approaches have achieved notable success in compressed video quality enhancement (VQE). However, these methods usually ignore the utilization of valuable coding priors inherently embedded in compressed videos, such as motion vectors and residual frames, which carry abundant temporal and spatial information. To remedy this problem, we propose the Coding Priors-Guided Aggregation (CPGA) network to utilize temporal and spatial information from coding priors. The CPGA mainly consists of an inter-frame temporal aggregation (ITA) module and a multi-scale non-local aggregation (MNA) module. Specifically, the ITA module aggregates temporal information from consecutive frames and coding priors, while the MNA module globally captures spatial information guided by residual frames. In addition, to facilitate research in VQE task, we newly construct the Video Coding Priors (VCP) dataset, comprising 300 videos with various coding priors extracted from corresponding bitstreams. It remedies the shortage of previous datasets on the lack of coding information. Experimental results demonstrate the superiority of our method compared to existing state-of-the-art methods. The code and dataset will be released at https://github.com/CPGA/CPGA.git. ",
    "url": "https://arxiv.org/abs/2403.10362",
    "authors": [
      "Qiang Zhu",
      "Jinhua Hao",
      "Yukang Ding",
      "Yu Liu",
      "Qiao Mo",
      "Ming Sun",
      "Chao Zhou",
      "Shuyuan Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.10368",
    "title": "Conformal Predictions for Probabilistically Robust Scalable Machine  Learning Classification",
    "abstract": "Conformal predictions make it possible to define reliable and robust learning algorithms. But they are essentially a method for evaluating whether an algorithm is good enough to be used in practice. To define a reliable learning framework for classification from the very beginning of its design, the concept of scalable classifier was introduced to generalize the concept of classical classifier by linking it to statistical order theory and probabilistic learning theory. In this paper, we analyze the similarities between scalable classifiers and conformal predictions by introducing a new definition of a score function and defining a special set of input variables, the conformal safety set, which can identify patterns in the input space that satisfy the error coverage guarantee, i.e., that the probability of observing the wrong (possibly unsafe) label for points belonging to this set is bounded by a predefined $\\varepsilon$ error level. We demonstrate the practical implications of this framework through an application in cybersecurity for identifying DNS tunneling attacks. Our work contributes to the development of probabilistically robust and reliable machine learning models. ",
    "url": "https://arxiv.org/abs/2403.10368",
    "authors": [
      "Alberto Carlevaro",
      "Teodoro Alamo Cantarero",
      "Fabrizio Dabbene",
      "Maurizio Mongelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.02256",
    "title": "Locally supported, quasi-interpolatory bases for the approximation of  functions on graphs",
    "abstract": " Comments: 21 pages, code included with ancillary files ",
    "url": "https://arxiv.org/abs/2101.02256",
    "authors": [
      "Edward J. Fuselier",
      "John Paul Ward"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ]
  },
  {
    "id": "arXiv:2106.03725",
    "title": "Stability to Deformations of Manifold Filters and Manifold Neural  Networks",
    "abstract": " Comments: 19 pages; 6 figures ",
    "url": "https://arxiv.org/abs/2106.03725",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08780",
    "title": "GraVoS: Voxel Selection for 3D Point-Cloud Detection",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2208.08780",
    "authors": [
      "Oren Shrout",
      "Yizhak Ben-Shabat",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04442",
    "title": "DPAR: Decoupled Graph Neural Networks with Node-Level Differential  Privacy",
    "abstract": " Comments: Accepted to The 2024 Web Conference ",
    "url": "https://arxiv.org/abs/2210.04442",
    "authors": [
      "Qiuchen Zhang",
      "Hong kyu Lee",
      "Jing Ma",
      "Jian Lou",
      "Carl Yang",
      "Li Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.05397",
    "title": "Analyzing the Expected Hitting Time of Evolutionary Computation-based  Neural Architecture Search Algorithms",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2210.05397",
    "authors": [
      "Zeqiong Lv",
      "Chao Qian",
      "Gary G. Yen",
      "Yanan Sun"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2301.02133",
    "title": "A note on highly connected $K_{2,\\ell}$-minor free graphs",
    "abstract": " Title: A note on highly connected $K_{2,\\ell}$-minor free graphs ",
    "url": "https://arxiv.org/abs/2301.02133",
    "authors": [
      "Nicolas Bousquet",
      "Th\u00e9o Pierron",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.10164",
    "title": "Lowering Detection in Sport Climbing Based on Orientation of the Sensor  Enhanced Quickdraw",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2211.02680 ",
    "url": "https://arxiv.org/abs/2301.10164",
    "authors": [
      "Sadaf Moaveninejad",
      "Andrea Janes",
      "Camillo Porcaro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2301.13770",
    "title": "Energy-Conserving Neural Network for Turbulence Closure Modeling",
    "abstract": " Comments: 26 pages, 15 figures, source code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2301.13770",
    "authors": [
      "Toby van Gastelen",
      "Wouter Edeling",
      "Benjamin Sanderse"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2302.01856",
    "title": "Entropy of Exchangeable Random Graphs",
    "abstract": " Title: Entropy of Exchangeable Random Graphs ",
    "url": "https://arxiv.org/abs/2302.01856",
    "authors": [
      "Anda Skeja",
      "Sofia C. Olhede"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2303.09234",
    "title": "NAISR: A 3D Neural Additive Model for Interpretable Shape Representation",
    "abstract": " Comments: 33 pages ",
    "url": "https://arxiv.org/abs/2303.09234",
    "authors": [
      "Yining Jiao",
      "Carlton Zdanski",
      "Julia Kimbell",
      "Andrew Prince",
      "Cameron Worden",
      "Samuel Kirse",
      "Christopher Rutter",
      "Benjamin Shields",
      "William Dunn",
      "Jisan Mahmud",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.13466",
    "title": "Mining Clinical Notes for Physical Rehabilitation Exercise Information:  Natural Language Processing Algorithm Development and Validation Study",
    "abstract": " Title: Mining Clinical Notes for Physical Rehabilitation Exercise Information:  Natural Language Processing Algorithm Development and Validation Study ",
    "url": "https://arxiv.org/abs/2303.13466",
    "authors": [
      "Sonish Sivarajkumar",
      "Fengyi Gao",
      "Parker E. Denny",
      "Bayan M. Aldhahwani",
      "Shyam Visweswaran",
      "Allyn Bove",
      "Yanshan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.09783",
    "title": "Application of attention-based Siamese composite neural network in  medical image recognition",
    "abstract": " Title: Application of attention-based Siamese composite neural network in  medical image recognition ",
    "url": "https://arxiv.org/abs/2304.09783",
    "authors": [
      "Zihao Huang",
      "Yue Wang",
      "Weixing Xin",
      "Xingtong Lin",
      "Huizhen Li",
      "Haowen Chen",
      "Yizhen Lao",
      "Xia Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08553",
    "title": "Distilling Knowledge for Short-to-Long Term Trajectory Prediction",
    "abstract": " Title: Distilling Knowledge for Short-to-Long Term Trajectory Prediction ",
    "url": "https://arxiv.org/abs/2305.08553",
    "authors": [
      "Sourav Das",
      "Guglielmo Camporese",
      "Shaokang Cheng",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.18702",
    "title": "Adversarial Adaptive Sampling: Unify PINN and Optimal Transport for the  Approximation of PDEs",
    "abstract": " Comments: ICLR, 2024 ",
    "url": "https://arxiv.org/abs/2305.18702",
    "authors": [
      "Kejun Tang",
      "Jiayu Zhai",
      "Xiaoliang Wan",
      "Chao Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.14009",
    "title": "Boosting Multitask Learning on Graphs through Higher-Order Task  Affinities",
    "abstract": " Comments: 16 pages. Appeared in KDD 2023 ",
    "url": "https://arxiv.org/abs/2306.14009",
    "authors": [
      "Dongyue Li",
      "Haotian Ju",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.16506",
    "title": "Equivariant Neural Networks for Indirect Measurements",
    "abstract": " Comments: 23 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2306.16506",
    "authors": [
      "Matthias Beckmann",
      "Nick Heilenk\u00f6tter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2307.07516",
    "title": "Voting-based Multimodal Automatic Deception Detection",
    "abstract": " Title: Voting-based Multimodal Automatic Deception Detection ",
    "url": "https://arxiv.org/abs/2307.07516",
    "authors": [
      "Lana Touma",
      "Mohammad Al Horani",
      "Manar Tailouni",
      "Anas Dahabiah",
      "Khloud Al Jallad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.09552",
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "abstract": " Comments: AISTATS 2024 ",
    "url": "https://arxiv.org/abs/2307.09552",
    "authors": [
      "Philipp M. Faller",
      "Leena Chennuru Vankadara",
      "Atalanti A. Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.08218",
    "title": "Expressivity of Spiking Neural Networks",
    "abstract": " Title: Expressivity of Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2308.08218",
    "authors": [
      "Manjot Singh",
      "Adalbert Fono",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.08374",
    "title": "Understanding the limitations of self-supervised learning for tabular  anomaly detection",
    "abstract": " Title: Understanding the limitations of self-supervised learning for tabular  anomaly detection ",
    "url": "https://arxiv.org/abs/2309.08374",
    "authors": [
      "Kimberly T. Mai",
      "Toby Davies",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13596",
    "title": "Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data  Collection to Model Development",
    "abstract": " Comments: Accepted by ICRA2024 ",
    "url": "https://arxiv.org/abs/2309.13596",
    "authors": [
      "Runkai Zhao",
      "Yuwen Heng",
      "Heng Wang",
      "Yuanda Gao",
      "Shilei Liu",
      "Changhao Yao",
      "Jiawen Chen",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13882",
    "title": "FC-Planner: A Skeleton-guided Planning Framework for Fast Aerial  Coverage of Complex 3D Scenes",
    "abstract": " Comments: Accepted to ICRA2024. Code: this https URL Video: this https URL&vd_source=0af61c122e5e37c944053b57e313025a. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2309.13882",
    "authors": [
      "Chen Feng",
      "Haojia Li",
      "Mingjie Zhang",
      "Xinyi Chen",
      "Boyu Zhou",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.02970",
    "title": "Fast, Expressive SE$(n)$ Equivariant Networks through Weight-Sharing in  Position-Orientation Space",
    "abstract": " Comments: Our code is publicly available at this https URL . Published at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.02970",
    "authors": [
      "Erik J Bekkers",
      "Sharvaree Vadgama",
      "Rob D Hesselink",
      "Putri A van der Linden",
      "David W Romero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)"
    ]
  },
  {
    "id": "arXiv:2310.04345",
    "title": "Neur2RO: Neural Two-Stage Robust Optimization",
    "abstract": " Title: Neur2RO: Neural Two-Stage Robust Optimization ",
    "url": "https://arxiv.org/abs/2310.04345",
    "authors": [
      "Justin Dumouchelle",
      "Esther Julien",
      "Jannis Kurtz",
      "Elias B. Khalil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05920",
    "title": "SimPLR: A Simple and Plain Transformer for Scaling-Efficient Object  Detection and Segmentation",
    "abstract": " Title: SimPLR: A Simple and Plain Transformer for Scaling-Efficient Object  Detection and Segmentation ",
    "url": "https://arxiv.org/abs/2310.05920",
    "authors": [
      "Duy-Kien Nguyen",
      "Martin R. Oswald",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06020",
    "title": "DyST: Towards Dynamic Neural Scene Representations on Real-World Videos",
    "abstract": " Comments: ICLR 2024 spotlight. Project website: this https URL ",
    "url": "https://arxiv.org/abs/2310.06020",
    "authors": [
      "Maximilian Seitzer",
      "Sjoerd van Steenkiste",
      "Thomas Kipf",
      "Klaus Greff",
      "Mehdi S. M. Sajjadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.11755",
    "title": "RGM: A Robust Generalizable Matching Model",
    "abstract": " Comments: Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2310.11755",
    "authors": [
      "Songyan Zhang",
      "Xinyu Sun",
      "Hao Chen",
      "Bo Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.11890",
    "title": "IRAD: Implicit Representation-driven Image Resampling against  Adversarial Attacks",
    "abstract": " Title: IRAD: Implicit Representation-driven Image Resampling against  Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2310.11890",
    "authors": [
      "Yue Cao",
      "Tianlin Li",
      "Xiaofeng Cao",
      "Ivor Tsang",
      "Yang Liu",
      "Qing Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19351",
    "title": "Seeking Flat Minima with Mean Teacher on Semi- and Weakly-Supervised  Domain Generalization for Object Detection",
    "abstract": " Title: Seeking Flat Minima with Mean Teacher on Semi- and Weakly-Supervised  Domain Generalization for Object Detection ",
    "url": "https://arxiv.org/abs/2310.19351",
    "authors": [
      "Ryosuke Furuta",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19791",
    "title": "LILO: Learning Interpretable Libraries by Compressing and Documenting  Code",
    "abstract": " Comments: ICLR 2024 camera-ready ",
    "url": "https://arxiv.org/abs/2310.19791",
    "authors": [
      "Gabriel Grand",
      "Lionel Wong",
      "Maddy Bowers",
      "Theo X. Olausson",
      "Muxin Liu",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2311.01357",
    "title": "Robust Identity Perceptual Watermark Against Deepfake Face Swapping",
    "abstract": " Comments: In peer review ",
    "url": "https://arxiv.org/abs/2311.01357",
    "authors": [
      "Tianyi Wang",
      "Mengxiao Huang",
      "Harry Cheng",
      "Bin Ma",
      "Yinglong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10112",
    "title": "zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with  Large Language Models",
    "abstract": " Comments: Accepted to NAACL 2024 main conference ",
    "url": "https://arxiv.org/abs/2311.10112",
    "authors": [
      "Zifeng Ding",
      "Heling Cai",
      "Jingpei Wu",
      "Yunpu Ma",
      "Ruotong Liao",
      "Bo Xiong",
      "Volker Tresp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.14024",
    "title": "Creating and Leveraging a Synthetic Dataset of Cloud Optical Thickness  Measures for Cloud Detection in MSI",
    "abstract": " Comments: Published in the journal Remote Sensing (2024). Code, data and models available at this https URL ",
    "url": "https://arxiv.org/abs/2311.14024",
    "authors": [
      "Aleksis Pirinen",
      "Nosheen Abid",
      "Nuria Agues Paszkowsky",
      "Thomas Ohlson Timoudas",
      "Ronald Scheirer",
      "Chiara Ceccobello",
      "Gy\u00f6rgy Kov\u00e1cs",
      "Anders Persson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.14120",
    "title": "Weight fluctuations in (deep) linear neural networks and a derivation of  the inverse-variance flatness relation",
    "abstract": " Comments: 26 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2311.14120",
    "authors": [
      "Markus Gross",
      "Arne P. Raulf",
      "Christoph R\u00e4th"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2311.14155",
    "title": "GigaPose: Fast and Robust Novel Object Pose Estimation via One  Correspondence",
    "abstract": " Comments: CVPR 2024 ",
    "url": "https://arxiv.org/abs/2311.14155",
    "authors": [
      "Van Nguyen Nguyen",
      "Thibault Groueix",
      "Mathieu Salzmann",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17248",
    "title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse  Problems",
    "abstract": " Comments: Published IEEE TCI. Main article has 16 pages, 7 figures, 3 tables, and 1 algorithm. Supplementary material has 4 pages and 5 figures ",
    "url": "https://arxiv.org/abs/2311.17248",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.17643",
    "title": "Neural Fields with Thermal Activations for Arbitrary-Scale  Super-Resolution",
    "abstract": " Title: Neural Fields with Thermal Activations for Arbitrary-Scale  Super-Resolution ",
    "url": "https://arxiv.org/abs/2311.17643",
    "authors": [
      "Alexander Becker",
      "Rodrigo Caye Daudt",
      "Nando Metzger",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.01490",
    "title": "GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment  Draping",
    "abstract": " Title: GAPS: Geometry-Aware, Physics-Based, Self-Supervised Neural Garment  Draping ",
    "url": "https://arxiv.org/abs/2312.01490",
    "authors": [
      "Ruochen Chen",
      "Liming Chen",
      "Shaifali Parashar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.03050",
    "title": "HIG: Hierarchical Interlacement Graph Approach to Scene Graph Generation  in Video Understanding",
    "abstract": " Comments: Accepted to CVPR 2024 ",
    "url": "https://arxiv.org/abs/2312.03050",
    "authors": [
      "Trong-Thuan Nguyen",
      "Pha Nguyen",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.03419",
    "title": "Synthesizing Physical Backdoor Datasets: An Automated Framework  Leveraging Deep Generative Models",
    "abstract": " Title: Synthesizing Physical Backdoor Datasets: An Automated Framework  Leveraging Deep Generative Models ",
    "url": "https://arxiv.org/abs/2312.03419",
    "authors": [
      "Sze Jue Yang",
      "Chinh D. La",
      "Quang H. Nguyen",
      "Kok-Seng Wong",
      "Anh Tuan Tran",
      "Chee Seng Chan",
      "Khoa D. Doan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.08515",
    "title": "Simplicial Representation Learning with Neural $k$-Forms",
    "abstract": " Comments: Accepted at ICLR 2024 (this https URL) ",
    "url": "https://arxiv.org/abs/2312.08515",
    "authors": [
      "Kelly Maggs",
      "Celia Hacker",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2401.00587",
    "title": "Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms,  and Energy-Based Uncertainty Prediction",
    "abstract": " Comments: 11 pages, 6 figures, code available at this https URL, submitted to Computers in Biology and Medicine ",
    "url": "https://arxiv.org/abs/2401.00587",
    "authors": [
      "Zachary Schwehr",
      "Sriman Achanta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.01085",
    "title": "Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control",
    "abstract": " Title: Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control ",
    "url": "https://arxiv.org/abs/2401.01085",
    "authors": [
      "Ka-Ho Chow",
      "Wenqi Wei",
      "Lei Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2401.02379",
    "title": "Detection and Discovery of Misinformation Sources using Attributed  Webgraphs",
    "abstract": " Title: Detection and Discovery of Misinformation Sources using Attributed  Webgraphs ",
    "url": "https://arxiv.org/abs/2401.02379",
    "authors": [
      "Peter Carragher",
      "Evan M. Williams",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2401.06443",
    "title": "BOK-VQA: Bilingual outside Knowledge-Based Visual Question Answering via  Graph Representation Pretraining",
    "abstract": " Title: BOK-VQA: Bilingual outside Knowledge-Based Visual Question Answering via  Graph Representation Pretraining ",
    "url": "https://arxiv.org/abs/2401.06443",
    "authors": [
      "Minjun Kim",
      "Seungwoo Song",
      "Youhan Lee",
      "Haneol Jang",
      "Kyungtae Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2401.14005",
    "title": "Cyber-Twin: Digital Twin-boosted Autonomous Attack Detection for  Vehicular Ad-Hoc Networks",
    "abstract": " Comments: 6 pages, 5 figures, IEEE International Conference on Communications (ICC) 2024 ",
    "url": "https://arxiv.org/abs/2401.14005",
    "authors": [
      "Yagmur Yigit",
      "Ioannis Panitsas",
      "Leandros Maglaras",
      "Leandros Tassiulas",
      "Berk Canberk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2401.16352",
    "title": "Adversarial Training on Purification (AToP): Advancing Both Robustness  and Generalization",
    "abstract": " Title: Adversarial Training on Purification (AToP): Advancing Both Robustness  and Generalization ",
    "url": "https://arxiv.org/abs/2401.16352",
    "authors": [
      "Guang Lin",
      "Chao Li",
      "Jianhai Zhang",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.16433",
    "title": "Within-basket Recommendation via Neural Pattern Associator",
    "abstract": " Comments: 13 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2401.16433",
    "authors": [
      "Kai Luo",
      "Tianshu Shen",
      "Lan Yao",
      "Ga Wu",
      "Aaron Liblong",
      "Istvan Fehervari",
      "Ruijian An",
      "Jawad Ahmed",
      "Harshit Mishra",
      "Charu Pujari"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.00038",
    "title": "Detecting Brain Tumors through Multimodal Neural Networks",
    "abstract": " Comments: Presented at NeroPRAI 2024 (co-located with ICPRAM 2024). This version did not undergo peer review: refer to the open access version of record (see DOI) ",
    "url": "https://arxiv.org/abs/2402.00038",
    "authors": [
      "Antonio Curci",
      "Andrea Esposito"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2402.08073",
    "title": "Grounding Data Science Code Generation with Input-Output Specifications",
    "abstract": " Title: Grounding Data Science Code Generation with Input-Output Specifications ",
    "url": "https://arxiv.org/abs/2402.08073",
    "authors": [
      "Yeming Wen",
      "Pengcheng Yin",
      "Kensen Shi",
      "Henryk Michalewski",
      "Swarat Chaudhuri",
      "Alex Polozov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2402.10877",
    "title": "Robust agents learn causal world models",
    "abstract": " Comments: ICLR 2024 (oral). Proofs in appendix simplified ",
    "url": "https://arxiv.org/abs/2402.10877",
    "authors": [
      "Jonathan Richens",
      "Tom Everitt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2402.10948",
    "title": "Zero-shot Explainable Mental Health Analysis on Social Media by  Incorporating Mental Scales",
    "abstract": " Comments: 4 pages,2 figures ",
    "url": "https://arxiv.org/abs/2402.10948",
    "authors": [
      "Wenyu Li",
      "Yinuo Zhu",
      "Xin Lin",
      "Ming Li",
      "Ziyue Jiang",
      "Ziqian Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2402.15656",
    "title": "Learning Semilinear Neural Operators : A Unified Recursive Framework For  Prediction And Data Assimilation",
    "abstract": " Comments: ICLR 2024 ",
    "url": "https://arxiv.org/abs/2402.15656",
    "authors": [
      "Ashutosh Singh",
      "Ricardo Augusto Borsoi",
      "Deniz Erdogmus",
      "Tales Imbiriba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2402.19119",
    "title": "VIXEN: Visual Text Comparison Network for Image Difference Captioning",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2402.19119",
    "authors": [
      "Alexander Black",
      "Jing Shi",
      "Yifei Fan",
      "Tu Bui",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2403.00895",
    "title": "End-to-End Graph-Sequential Representation Learning for Accurate  Recommendations",
    "abstract": " Comments: 4 pages, 1 figure, submitted to WWW'24, short-paper track ",
    "url": "https://arxiv.org/abs/2403.00895",
    "authors": [
      "Vladimir Baikalov",
      "Evgeny Frolov"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.02769",
    "title": "HUNTER: Unsupervised Human-centric 3D Detection via Transferring  Knowledge from Synthetic Instances to Real Scenes",
    "abstract": " Comments: Accepted by CVPR 2024 ",
    "url": "https://arxiv.org/abs/2403.02769",
    "authors": [
      "Yichen Yao",
      "Zimo Jiang",
      "Yujing Sun",
      "Zhencai Zhu",
      "Xinge Zhu",
      "Runnan Chen",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.03359",
    "title": "RACE-SM: Reinforcement Learning Based Autonomous Control for Social  On-Ramp Merging",
    "abstract": " Comments: Updated explanation of TTC, page 7 ",
    "url": "https://arxiv.org/abs/2403.03359",
    "authors": [
      "Jordan Poots"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.04293",
    "title": "MKF-ADS: Multi-Knowledge Fusion Based Self-supervised Anomaly Detection  System for Control Area Network",
    "abstract": " Comments: 14 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2403.04293",
    "authors": [
      "Pengzhou Cheng",
      "Zongru Wu",
      "Gongshen Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2403.04982",
    "title": "A 28.6 mJ/iter Stable Diffusion Processor for Text-to-Image Generation  with Patch Similarity-based Sparsity Augmentation and Text-based  Mixed-Precision",
    "abstract": " Comments: Accepted at 2024 IEEE International Symposium on Circuits and Systems (ISCAS) ",
    "url": "https://arxiv.org/abs/2403.04982",
    "authors": [
      "Jiwon Choi",
      "Wooyoung Jo",
      "Seongyon Hong",
      "Beomseok Kwon",
      "Wonhoon Park",
      "Hoi-Jun Yoo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2403.05050",
    "title": "DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for  Streaming Perception",
    "abstract": " Title: DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for  Streaming Perception ",
    "url": "https://arxiv.org/abs/2403.05050",
    "authors": [
      "Xiang Huang",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Wangmeng Xiang",
      "Baigui Sun",
      "Xiao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2403.05407",
    "title": "Algorithmic Identification of Essential Exogenous Nodes for Causal  Sufficiency in Brain Networks",
    "abstract": " Title: Algorithmic Identification of Essential Exogenous Nodes for Causal  Sufficiency in Brain Networks ",
    "url": "https://arxiv.org/abs/2403.05407",
    "authors": [
      "Abdolmahdi Bagheri",
      "Mahdi Dehshiri",
      "Babak Nadjar Araabi",
      "Alireza Akhondi Asl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.05972",
    "title": "C3D: Cascade Control with Change Point Detection and Deep Koopman  Learning for Autonomous Surface Vehicles",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2403.05972",
    "authors": [
      "Jianwen Li",
      "Hyunsang Park",
      "Wenjian Hao",
      "Lei Xin",
      "Jalil Chavez-Galaviz",
      "Ajinkya Chaudhary",
      "Meredith Bloss",
      "Kyle Pattison",
      "Christopher Vo",
      "Devesh Upadhyay",
      "Shreyas Sundaram",
      "Shaoshuai Mou",
      "Nina Mahmoudian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2403.06487",
    "title": "Multilingual Turn-taking Prediction Using Voice Activity Projection",
    "abstract": " Comments: This paper has been accepted for presentation at The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) and represents the author's version of the work ",
    "url": "https://arxiv.org/abs/2403.06487",
    "authors": [
      "Koji Inoue",
      "Bing'er Jiang",
      "Erik Ekstedt",
      "Tatsuya Kawahara",
      "Gabriel Skantze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2403.07392",
    "title": "ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature  Interaction for Dense Predictions",
    "abstract": " Comments: CVPR2024 ",
    "url": "https://arxiv.org/abs/2403.07392",
    "authors": [
      "Chunlong Xia",
      "Xinliang Wang",
      "Feng Lv",
      "Xin Hao",
      "Yifeng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.07420",
    "title": "DragAnything: Motion Control for Anything using Entity Representation",
    "abstract": " Comments: The project website is at: this https URL . The code is at: this https URL ",
    "url": "https://arxiv.org/abs/2403.07420",
    "authors": [
      "Weijia Wu",
      "Zhuang Li",
      "Yuchao Gu",
      "Rui Zhao",
      "Yefei He",
      "David Junhao Zhang",
      "Mike Zheng Shou",
      "Yan Li",
      "Tingting Gao",
      "Di Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.07706",
    "title": "Fast and Simple Explainability for Point Cloud Networks",
    "abstract": " Title: Fast and Simple Explainability for Point Cloud Networks ",
    "url": "https://arxiv.org/abs/2403.07706",
    "authors": [
      "Meir Yossef Levi",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2403.08082",
    "title": "Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis  in the Energy Industry",
    "abstract": " Title: Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis  in the Energy Industry ",
    "url": "https://arxiv.org/abs/2403.08082",
    "authors": [
      "Zongxian Wang",
      "Jie Song"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2403.08281",
    "title": "Mastering Text, Code and Math Simultaneously via Fusing Highly  Specialized Language Models",
    "abstract": " Title: Mastering Text, Code and Math Simultaneously via Fusing Highly  Specialized Language Models ",
    "url": "https://arxiv.org/abs/2403.08281",
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xingtai Lv",
      "Ruobing Xie",
      "Bowen Zhou",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08838",
    "title": "Predictive Clustering of Vessel Behavior Based on Hierarchical  Trajectory Representation",
    "abstract": " Title: Predictive Clustering of Vessel Behavior Based on Hierarchical  Trajectory Representation ",
    "url": "https://arxiv.org/abs/2403.08838",
    "authors": [
      "Rui Zhang",
      "Hanyue Wu",
      "Zhenzhong Yin",
      "Zhu Xiao",
      "Yong Xiong",
      "Kezhong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.08947",
    "title": "Robust COVID-19 Detection in CT Images with CLIP",
    "abstract": " Title: Robust COVID-19 Detection in CT Images with CLIP ",
    "url": "https://arxiv.org/abs/2403.08947",
    "authors": [
      "Li Lin",
      "Yamini Sri Krubha",
      "Zhenhuan Yang",
      "Cheng Ren",
      "Thuc Duy Le",
      "Irene Amerini",
      "Xin Wang",
      "Shu Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.08987",
    "title": "A Constrained Tracking Controller for Ramp and Sinusoidal Reference  Signals using Robust Positive Invariance",
    "abstract": " Comments: Preprint of the conference paper submitted to the 2024 American Control Conference ",
    "url": "https://arxiv.org/abs/2403.08987",
    "authors": [
      "Geovana Franca dos Santos",
      "Eugenio B. Castelan",
      "Walter Lucia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.09108",
    "title": "CardioCaps: Attention-based Capsule Network for Class-Imbalanced  Echocardiogram Classification",
    "abstract": " Comments: 8 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2403.09108",
    "authors": [
      "Hyunkyung Han",
      "Jihyeon Seong",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09303",
    "title": "Rethinking Autoencoders for Medical Anomaly Detection from A Theoretical  Perspective",
    "abstract": " Title: Rethinking Autoencoders for Medical Anomaly Detection from A Theoretical  Perspective ",
    "url": "https://arxiv.org/abs/2403.09303",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]